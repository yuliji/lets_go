<doc id="1217" url="https://en.wikipedia.org/wiki?curid=1217" title="Anguilla">
Anguilla

Anguilla ( ) is a British overseas territory in the Caribbean. It is one of the most northerly of the Leeward Islands in the Lesser Antilles, lying east of Puerto Rico and the Virgin Islands and directly north of Saint Martin. The territory consists of the main island of Anguilla, approximately long by wide at its widest point, together with a number of much smaller islands and cays with no permanent population. The island's capital is The Valley. The total land area of the territory is , with a population of approximately ( estimate).

Anguilla has become a popular tax haven, having no capital gains, estate, profit, sales, or corporate taxes. In April 2011, faced with a mounting deficit, it introduced a 3% "Interim Stabilisation Levy", Anguilla's first form of income tax. Anguilla also has a 0.75% property tax.

The name Anguilla is from the Italian "" meaning "eel" (in turn from the Latin "anguilla", diminutive of "anguis", snake) in reference to the island's shape. It is believed by most sources to have been named by Christopher Columbus. For similar reasons, it was also known as "Snake" or "Snake Island".

Anguilla was first settled by Indigenous Amerindian peoples who migrated from South America. The earliest Native American artefacts found on Anguilla have been dated to around 1300 ; remains of settlements date from  600. The Arawak name for the island seems to have been "Malliouhana". The date of European colonisation is uncertain: some sources claim that Columbus sighted the island during his second voyage in 1493, while others state that the island's first European explorer was the French Huguenot nobleman and merchant mariner René Goulaine de Laudonnière in 1564. The Dutch West India Company established a fort on the island in 1631. The Dutch withdrew after the destruction of the fort by Spanish forces in 1633.

Traditional accounts state that Anguilla was first colonized by English settlers from Saint Kitts beginning in 1650. In this early colonial period, however, Anguilla sometimes served as a place of refuge and recent scholarship focused on Anguilla has placed greater significance on other Europeans and creoles migrating from St. Christopher, Barbados, Nevis and Antigua. The French temporarily took over the island in 1666 but returned it to English control under the terms of the Treaty of Breda the next year. A Major John Scott who visited in September 1667, wrote of leaving the island "in good condition" and noted that in July 1668, "200 or 300 people fled thither in time of war".

It is likely that some of these early Europeans brought enslaved Africans with them. Historians confirm that African slaves lived in the region in the early 17th century. For example, Africans from Senegal lived in St. Christopher in 1626. By 1672 a slave depot existed on the island of Nevis, serving the Leeward Islands. While the time of African arrival in Anguilla is difficult to place precisely, archival evidence indicates a substantial African presence of at least 100 enslaved people by 1683. These seem to have come from Central Africa as well as West Africa.

Attempts by the French to capture the island during the War of Austrian Succession (1745) and the Napoleonic Wars (1796) ended in failure.

During the early colonial period, Anguilla was administered by the British through Antigua; in 1825, it was placed under the administrative control of nearby Saint Kitts. In 1967, Britain granted Saint Kitts and Nevis full internal autonomy. Anguilla was also incorporated into the new unified dependency, named Saint Christopher-Nevis-Anguilla, against the wishes of many Anguillians. This led to two Anguillian Revolutions in 1967 and 1969 headed by Atlin Harrigan and Ronald Webster. The island briefly operated as the independent "Republic of Anguilla". The goal of the revolution was not independence per se, but rather independence from Saint Kitts and Nevis and a return to being a British colony. British authority was fully restored in July 1971; in 1980, Anguilla was finally allowed to secede from Saint Kitts and Nevis and become a separate British Crown colony (now a British overseas territory).

Anguilla is an internally self-governing overseas territory of the United Kingdom. Its politics take place in a framework of a parliamentary representative democratic dependency, whereby the Premier is the head of government, and of a pluriform multi-party system.

The United Nations Committee on Decolonization includes Anguilla on the United Nations list of Non-Self-Governing Territories. The territory's constitution is Anguilla Constitutional Order 1 April 1982 (amended 1990). Executive power is exercised by the government. Legislative power is vested in both the government and the House of Assembly. The judiciary is independent of the executive and the legislature. 

As a dependency of the UK, the UK is responsible for Anguilla's military defence, although there are no active garrisons or armed forces present. Anguilla has a small marine police force, comprising around 32 personnel, which operates one VT Halmatic M160-class 52-foot fast patrol boat.

The majority of residents (90.08%) are black, the descendants of slaves transported from Africa. Minorities include whites at 3.74% and people of mixed race at 4.65% (figures from 2001 census).

72% of the population is Anguillian while 28% is non-Anguillian (2001 census). Of the non-Anguillian population, many are citizens of the United States, United Kingdom, St Kitts & Nevis, the Dominican Republic, Jamaica and Nigeria.

2006 and 2007 saw an influx of large numbers of Chinese, Indian and Mexican workers, brought in as labour for major tourist developments due to the local population not being large enough to support the labour requirements.

Christian churches did not have a consistent or strong presence during the initial period of English colonisation. Spiritual and religious practices of Europeans and Africans tended to reflect their regional origins. As early as 1813, Christian ministers formally ministered to enslaved Africans and promoted literacy among converts. The Wesleyan (Methodist) Missionary Society of England built churches and schools in 1817.

According to the 2001 census, Christianity is Anguilla's predominant religion, with 29 percent of the population practising Anglicanism. Another 23.9 percent are Methodist. Other churches on the island include Seventh-day Adventist, Baptist, Roman Catholic (served by the Diocese of Saint John's–Basseterre, with see at Saint John on Antigua and Barbuda) and a community of Jehovah's Witnesses (0.7%). Between 1992 and 2001 the number of followers of the Church of God and Pentecostals increased considerably. There are at least 15 churches on the island. Although a minority on the island, it is an important location to followers of Rastafarian religion—Anguilla is the birthplace of Robert Athlyi Rogers, author of the "Holy Piby" which has had a strong influence on Rastafarian beliefs. Various other religions are practised as well. More recently, a Muslim cultural centre has opened on the island.

Today most people in Anguilla speak a British-influenced variety of standard English. Other languages are also spoken on the island, including varieties of Spanish, Chinese and the languages of other immigrants. However, the most common language other than Standard English is the island's own English-lexifier Creole language (not to be confused with Antillean Creole ('French Creole'), spoken in French islands such as Martinique and Guadeloupe). It is referred to locally by terms such as "dialect" (pronounced "dialek"), Anguilla Talk or "Anguillian". It has its main roots in early varieties of English and West African languages, and is similar to the dialects spoken in English-speaking islands throughout the Eastern Caribbean, in terms of its structural features and to the extent of being considered one single language.

Linguists who are interested in the origins of Anguillian and other Caribbean Creoles point out that some of its grammatical features can be traced to African languages while others can be traced to European languages. Three areas have been identified as significant for the identification of the linguistic origins of those forced migrants who arrived before 1710: the Gold Coast, the Slave Coast and the Windward Coast.

Sociohistorical information from Anguilla's archives suggest that Africans and Europeans formed two distinct, but perhaps overlapping speech communities in the early phases of the island's colonisation. "Anguillian" is believed to have emerged as the language of the masses as time passed, slavery was abolished and locals began to see themselves as "belonging" to Anguillian society.

There are six government primary schools, one government secondary school (Albena Lake Hodge Comprehensive School), and two private schools. There is a single library, the Edison L. Hughes Education & Library Complex of the Anguilla Public Library. A branch of the Saint James School of Medicine was established in 2011 in Anguilla. It is a private, for-profit medical school headquartered in Park Ridge, Illinois.

There is a University of the West Indies Open campus site in the island.

The Anguilla National Trust (ANT) was established in 1988 and opened its offices in 1993 charged with the responsibility of preserving the heritage of the island, including its cultural heritage. The Trust has programmes encouraging Anguillian writers and the preservation of the island's history. In 2015, "Where I See The Sun – Contemporary Poetry in Anguilla" A New Anthology by Lasana M. Sekou was published by House of Nehesi Publishers. Among the forty three poets in the collection are Rita Celestine-Carty, Bankie Banx, John T. Harrigan, Patricia J. Adams, Fabian Fahie, Dr. Oluwakemi Linda Banks, and Reuel Ben Lewi.

The island's cultural history begins with the Taino Native Americans. Artifacts have been found around the island, telling of life before European settlers arrived by the Arawak and Carib peoples.

As throughout the Caribbean, holidays are a cultural fixture. Anguilla's most important holidays are of historic as much as cultural importance – particularly the anniversary of the emancipation (previously August Monday in the Park), celebrated as the Summer Festival. British festivities, such as the Queen's Birthday, are also celebrated.

Anguillian cuisine is influenced by native Caribbean, African, Spanish, French and English cuisines. Seafood is abundant, including prawns, shrimp, crab, spiny lobster, conch, mahi-mahi, red snapper, marlin and grouper. Salt cod is a staple food eaten on its own and used in stews, casseroles and soups. Livestock is limited due to the small size of the island and people there use poultry, pork, goat and mutton, along with imported beef. Goat is the most commonly eaten meat, used in a variety of dishes.

A significant amount of the island's produce is imported due to limited land suitable for agriculture production; much of the soil is sandy and infertile. Among the agriculture produced in Anguilla includes tomatoes, peppers, limes and other citrus fruits, onion, garlic, squash, pigeon peas and callaloo. Starch staple foods include imported rice and other foods that are imported or locally grown, including yams, sweet potatoes and breadfruit.

Due to its internationally recognised culinary community, the island has enjoyed a reputation as "the culinary capital of the Caribbean". This reputation was reinforced with the publication of the "(WE) Are Anguilla Cookbook", a guide to the cuisine of Anguilla featuring emerging and established local chefs, who share both their signature dishes and personal anecdotes regarding the island's epicurean culture. A publishing contract was secured by The Britto Agency, which had conceived the idea for the book itself.

The island's burgeoning musical community made history with the recording of "Sounds of Anguilla (Volume 1)", the first album ever composed solely of artists from a single Caribbean island representing multiple musical genres: pop, reggae, hip-hop, soca music and R&B. The album, featuring Anguillian musicians such as Bankie Banx, Amalia Watty, True Intentions and Gerswin Lake and The Parables, was released on iTunes in June 2015.

Boat racing has deep roots in Anguillian culture and is the national sport.

There are regular sailing regattas on national holidays, such as Carnival, which are contested by locally built and designed boats. These boats have names and have sponsors that print their logo on their sails.

As in many other former British colonies, cricket is also a popular sport. Anguilla is the home of Omari Banks, who played for the West Indies Cricket Team, while Cardigan Connor played first-class cricket for English county side Hampshire and was 'chef de mission' (team manager) for Anguilla's Commonwealth Games team in 2002.

Rugby union is represented in Anguilla by the Anguilla Eels RFC, who were formed in April 2006. The Eels have been finalists in the St. Martin tournament in November 2006 and semi-finalists in 2007, 2008, 2009 and Champions in 2010. The Eels were formed in 2006 by Scottish club national second row Martin Welsh, Club Sponsor and President of the AERFC Ms. Jacquie Ruan, and Canadian standout Scrumhalf Mark Harris (Toronto Scottish RFC).

Anguilla is the birthplace of sprinter Zharnel Hughes who has represented Great Britain since 2015, and England at the 2018 Commonwealth Games. He won the 100 metres at the 2018 European Athletics Championships, the 4 x 100 metres at the same championships, and the 4 x 100 metres for England at the 2018 Commonwealth Games.

Shara Proctor, British Long Jump Silver Medalist in World Championships in Beijing first represented Anguilla in the event until 2010 when she began to represent Great Britain and England. Under the Anguillian Flag she achieved several medals in the NACAC games.

Keith Connor, triple jumper, is also an Anguillian. He represented Great Britain and England and achieved several international titles including Commonwealth and European Games gold medals and an Olympic bronze medal. Keith later became Head Coach of Australia Athletics.

Chesney Hughes, is a West Indian cricketer who plays for Derbyshire. He was born in Anguilla. Having signed for the side in June 2009, and holding a British passport, Hughes made his List A debut for the side during the 2009 Pro40 League against Warwickshire.

Anguilla has habitat for the Cuban tree frogs ("Osteopilus septentrionalis"). The red-footed tortoise ("Chelonoidis carbonaria") is a species of tortoise found here, it somehow came from South America. Hurricanes led to over-water dispersal for the green iguanas ("Iguana iguana") to colonise Anguilla. All three animals are introduced.

Five species of bats are known in the literature from Anguilla – the threatened insular single leaf bat ("Monophyllus plethodon"), the Antillean fruit-eating bat ("Brachyphylla cavernarum"), the Jamaican fruit bat ("Artibeus jamaicensis"), the Mexican funnel-eared bat ("Natalus stramineus"), and the velvety free-tailed bat ("Molossus molossus").

Anguilla is a flat, low-lying island of coral and limestone in the Caribbean Sea, east of Puerto Rico and the Virgin Islands. It is directly north of Saint Martin, separated from that island by the Anguilla Channel. The soil is generally thin and poor, supporting scrub, tropical and forest vegetation.

Anguilla is noted for its spectacular and ecologically important coral reefs and beaches. Apart from the main island of Anguilla itself, the territory includes a number of other smaller islands and cays, mostly tiny and uninhabited. Some of these are:

Anguilla has a volcanic origin and has been submerged repeatedly from climate change.

Northeastern trade winds keep this tropical island relatively cool and dry. Average annual temperature is . July–October is its hottest period, December–February, its coolest.

Rainfall averages annually, although the figures vary from season to season and year to year. The island is subject to both sudden tropical storms and hurricanes, which occur in the period from July to November. The island suffered damage in 1995 from Hurricane Luis and severe flooding 5–20 feet from Hurricane Lenny.

Anguilla's thin arid soil being largely unsuitable for agriculture, the island has few land-based natural resources. Its main industries are tourism, offshore incorporation and management, offshore banking, captive insurance and fishing.

Anguilla's currency is the East Caribbean dollar, though the US dollar is also widely accepted. The exchange rate is fixed to the US dollar at US$1 = EC$2.70.

The economy, and especially the tourism sector, suffered a setback in late 1995 due to the effects of Hurricane Luis in September. Hotels were hit particularly hard but a recovery occurred the following year. Another economic setback occurred during the aftermath of Hurricane Lenny in 2000. Before the 2008 worldwide crisis the economy of Anguilla was growing strongly, especially the tourism sector which was driving major new developments in partnerships with multi-national companies.

Anguilla's financial system comprises 7 banks, 2 money services businesses, more than 40 company managers, more than 50 insurers, 12 brokers, more than 250 captive intermediaries, more than 50 mutual funds and 8 trust companies.

Anguilla's tourism industry received a major boost when it was selected to host the World Travel Awards in December 2014. Known as "the Oscars of the travel industry", the awards ceremony was held at the CuisinArt Resort and Spa and was hosted by Vivica A. Fox. Anguilla was voted the World's Leading Luxury Island Destination from a short list of top-tier candidates such as St. Barts, Maldives and Mauritius.

Anguilla aims to obtain 15% of its energy from solar power to become less reliant on expensive imported diesel. The Climate & Development Knowledge Network is helping the government gather the information it needs to change the territory's legislation, so it can integrate renewables into its grid. Barbados has also made good progress in switching to renewables, but many other Small Island Developing States are still at the early stages of planning how to integrate renewable energy into their grids. "For a small island we're very far ahead," said Beth Barry, Coordinator of the Anguilla Renewable Energy Office. "We've got an Energy Policy and a draft Climate Change policy and have been focussing efforts on the question of sustainable energy supply for several years now. As a result, we have a lot of information we can share with other islands."

Anguilla is served by Clayton J. Lloyd International Airport (prior to 4 July 2010 known as Wallblake Airport). The primary runway at the airport is in length and can accommodate moderate-sized aircraft. Services connect to various other Caribbean islands via regional carrier LIAT, local charter airlines and others. Although there are no direct scheduled flights to or from continental America or Europe, Tradewind Aviation and Cape Air provide scheduled air service to San Juan, Puerto Rico. The airport can handle large narrow-body jets such as the Boeing 727, Boeing 737 and Boeing 757.

Aside from taxis, there is no public transport on the island. Cars drive on the left.

There are regular ferries from Saint Martin to Anguilla. It is a 20-minute crossing from Marigot, St. Martin to Blowing Point, Anguilla. Ferries commence service from 7:00 am. There is also a charter service, from Blowing Point, Anguilla to Princess Juliana Airport to make travel easier. This way of travel is the most common method of transport between Anguilla and St. Martin or St. Maarten.






</doc>
<doc id="1223" url="https://en.wikipedia.org/wiki?curid=1223" title="Telecommunications in Anguilla">
Telecommunications in Anguilla

This article is about communications systems in Anguilla.

Telephones - main lines in use: 6,200 (2002)

Telephones - mobile cellular: 1,800 (2002)

Telephone system:
<br>"Domestic:" Modern internal telephone system
<br>"International:" EAST CARIBBEAN FIBRE SYSTEM ECFS (cable system)
" microwave radio relay to island of Saint Martin (Guadeloupe and Netherlands Antilles)

Mobile Phone Operators:

Mobiles: ? (2007)

Radio broadcast stations: AM 3, FM 7, shortwave 0 (2007)
Radios: 3,000 (1997)

Television broadcast stations: 1 (1997)

Televisions: 1,000 (1997)

Internet country code: .ai (Top level domain)

Internet Service Providers (ISPs): 3 (Cable & Wireless - , Weblinks - , Caribbean Cable Communications - )

Internet hosts: 205 (2008)

Internet: users: 3,000 (2002)



</doc>
<doc id="1227" url="https://en.wikipedia.org/wiki?curid=1227" title="Ashmore and Cartier Islands">
Ashmore and Cartier Islands

The Territory of Ashmore and Cartier Islands is an uninhabited external territory of Australia consisting of four low-lying tropical islands in two separate reefs, and the 12 nautical mile territorial sea generated by the islands. The territory is located in the Indian Ocean situated on the edge of the continental shelf, about off the northwest coast of Australia and south of the Indonesian island of Rote.

Ashmore Reef is called "Pulau Pasir" by Indonesians and "Nusa Solokaek" in the Rotenese language. Both names have the meaning "sand island".

The Territory comprises Ashmore Reef, which includes West, Middle, and East Islands, and two lagoons, and Cartier Reef, which includes Cartier Island. Ashmore Reef covers approximately and Cartier Reef , both measurements extending to the limits of the reefs.

West, Middle, and East Islands have a combined land area variously reported as 54 ha, 93 ha, and 112 ha (1 hectare is 0.01 km, or about 2.5 acres). Cartier Island has a reported land area of 0.4 ha.

Cartier Island was discovered by Captain Nash in 1800, and named after his ship "Cartier". Ashmore Island was discovered by Captain Samuel Ashmore in 1811 from his ship HMS "Hibernia", and named after him. Ashmore Island was annexed by the United Kingdom in 1878, as was Cartier Island in 1909.

By a British Order-in-council dated 23 July 1931, Ashmore and Cartier Islands were placed under the authority of the Commonwealth of Australia, but Australia officially accepted the Territory on 10 May 1934 when the "Ashmore and Cartier Islands Acceptance Act 1933" came into operation. The Act authorised the Governor of Western Australia to make Ordinances for the Territory. In July 1938 the Territory was annexed to the Northern Territory, then also administered by the Commonwealth, whose laws, ordinances and regulations applied to the Territory. When self-government was granted to the Northern Territory on 1 July 1978, administration of the Territory was retained by the Commonwealth.

In 1983 the Territory was declared a nature reserve under the "National Parks and Wildlife Conservation Act 1975", now replaced by the "Environment Protection and Biodiversity Conservation Act 1999".

After the islands became a first point of contact with the Australian migration zone, in September 2001, the Australian government excised the Ashmore and Cartier Islands from the Australian migration zone.

Ashmore has been regularly visited and fished by Indonesian fishermen since the early eighteenth century. A 1974 Memorandum of Understanding between Australia and Indonesia sets out arrangements by which traditional fishers can access resources in Australia's territorial sea in the region. This allows traditional Indonesian fishermen to access parts of Ashmore for shelter, freshwater and to visit grave sites. The area, known as the MOU Box, contains the Ashmore and Cartier Islands Territory.

Some Indonesian groups claim Ashmore Reef to be part of Rote Ndao Regency of East Nusa Tenggara province.

Today, the Territory is administered from Canberra by the Department of Infrastructure, Regional Development and Cities, which is also responsible for the administration of the territories of Christmas Island, Cocos (Keeling) Islands, the Coral Sea Islands, Jervis Bay Territory and Norfolk Island.

The Attorney-General's Department had been responsible for the administration of Australian territories until the 2010 federal election. In that year the responsibility for Australian territories was transferred to the then Department of Regional Australia, Local Government, Arts and Sport, and from 18 September 2013 the Department of Infrastructure and Regional Development has administered Australian territories.

Defence of Ashmore and Cartier Islands is the responsibility of Australia, with periodic visits by the Royal Australian Navy, Royal Australian Air Force and Australian Customs and Border Protection Service.

Nearby Hibernia Reef, northeast of Ashmore Reef, is not part of the Territory, but belongs to Western Australia. It has no permanently dry land area, although large parts of the reef become exposed during low tide.


There is no economic activity in the Territory, Ashmore and Cartier Islands being uninhabited. Cartier Island is an unvegetated sand island. Access to Cartier Island is prohibited because of the risk of unexploded ordnances. There are no ports or harbours, only offshore anchorage. The customs vessel ACV "Ashmore Guardian" is stationed off the reef for up to 330 days per year. The islands are also visited by seasonal caretakers and occasional scientific researchers.

The area has been a traditional fishing ground of Indonesian fishermen for centuries, and continues. In the 1850s, American whalers operated in the region. Mining of phosphate deposits took place on Ashmore Island in the latter half of the 19th century. Today, all the wells in the Territory are infected with cholera or contaminated and undrinkable.

Petroleum extraction activities take place at the Jabiru and Challis oil fields, which are adjacent to the Territory, and which are administered by the Northern Territory Department of Mines and Energy on behalf of the Commonwealth.

As Ashmore Reef is the closest point of Australian territory to Indonesia, it was a popular target for people smugglers transporting asylum seekers en route to Australia. Once they had landed on Ashmore Island, asylum seekers could claim to have entered Australian migration zone and request to be processed as refugees. The use of Ashmore Island for this purpose created great notoriety during late 2001, when refugee arrivals became a major political issue in Australia. The Australian Government argued that as Australia was not the country of first asylum for these "boat people", Australia did not have a responsibility to accept them.

A number of things were done to discourage the use of the Territory for this purpose, such as attempting to have the people smugglers arrested in Indonesia; the so-called Pacific Solution of processing them in third countries; the boarding and forced turnaround of the boats by Australian military forces; and finally excising the Territory and many other small islands from the Australian migration zone.

Two boatloads of asylum seekers were each detained for several days in the lagoon at Ashmore Island after failed attempts by the Royal Australian Navy to turn them back to Indonesia in October 2001.




</doc>
<doc id="1234" url="https://en.wikipedia.org/wiki?curid=1234" title="Acoustic theory">
Acoustic theory

Acoustic theory is a scientific field that relates to the description of sound waves. It derives from fluid dynamics. See acoustics for the engineering approach.

Propagation of sound waves in a fluid (such as water) can be modeled by an equation of continuity (conservation of mass) and an equation of motion (conservation of momentum) . With some simplifications, in particular constant density, they can be given as follows:
where formula_2 is the acoustic pressure and formula_3 is the flow velocity vector, formula_4 is the vector of spatial coordinates formula_5, formula_6 is the time, formula_7 is the static mass density of the medium and formula_8 is the bulk modulus of the medium. The bulk modulus can be expressed in terms of the density and the speed of sound in the medium (formula_9) as
If the flow velocity field is irrotational, formula_11, then the acoustic wave equation is a combination of these two sets of balance equations and can be expressed as
where we have used the vector Laplacian, formula_13
The acoustic wave equation (and the mass and momentum balance equations) are often expressed in terms of a scalar potential formula_14 where formula_15. In that case the acoustic wave equation is written as
and the momentum balance and mass balance are expressed as

The derivations of the above equations for waves in an acoustic medium are given below.

The equations for the conservation of linear momentum for a fluid medium are
where formula_19 is the body force per unit mass, formula_20 is the pressure, and formula_21 is the deviatoric stress. If formula_22 is the Cauchy stress, then
where formula_24 is the rank-2 identity tensor.

We make several assumptions to derive the momentum balance equation for an acoustic medium. These assumptions and the resulting forms of the momentum equations are outlined below.

In acoustics, the fluid medium is assumed to be Newtonian. For a Newtonian fluid, the deviatoric stress tensor is related to the flow velocity by
where formula_26 is the shear viscosity and formula_27 is the bulk viscosity.

Therefore, the divergence of formula_21 is given by
Using the identity formula_30, we have
The equations for the conservation of momentum may then be written as

For most acoustics problems we assume that the flow is irrotational, that is, the vorticity is zero. In that case
and the momentum equation reduces to

Another frequently made assumption is that effect of body forces on the fluid medium is negligible. The momentum equation then further simplifies to

Additionally, if we assume that there are no viscous forces in the medium (the bulk and shear viscosities are zero), the momentum equation takes the form

An important simplifying assumption for acoustic waves is that the amplitude of the disturbance of the field quantities is small. This assumption leads to the linear or small signal acoustic wave equation. Then we can express the variables as the sum of the (time averaged) mean field (formula_37) that varies in space and a small fluctuating field (formula_38) that varies in space and time. That is
and
Then the momentum equation can be expressed as
Since the fluctuations are assumed to be small, products of the fluctuation terms can be neglected (to first order) and we have

Next we assume that the medium is homogeneous; in the sense that the time averaged variables
formula_43 and formula_44 have zero gradients, i.e.,
The momentum equation then becomes

At this stage we assume that the medium is at rest, which implies that the mean flow velocity is zero, i.e., formula_47. Then the balance of momentum reduces to
Dropping the tildes and using formula_49, we get the commonly used form of the acoustic momentum equation

The equation for the conservation of mass in a fluid volume (without any mass sources or sinks) is given by
where formula_52 is the mass density of the fluid and formula_53 is the flow velocity.

The equation for the conservation of mass for an acoustic medium can also be derived in a manner similar to that used for the conservation of momentum.

From the assumption of small disturbances we have
and
Then the mass balance equation can be written as
If we neglect higher than first order terms in the fluctuations, the mass balance equation becomes

Next we assume that the medium is homogeneous, i.e.,
Then the mass balance equation takes the form

At this stage we assume that the medium is at rest, i.e., formula_47. Then the mass balance equation can be expressed as

To close the system of equations we need an equation of state for the pressure. To do that we assume that the medium is an ideal gas and all acoustic waves compress the medium in an adiabatic and reversible manner. The equation of state can then be expressed in the form of the differential equation:
where formula_63 is the specific heat at constant pressure, formula_64 is the specific heat at constant volume, and formula_65 is the wave speed. The value of formula_66 is 1.4 if the acoustic medium is air.

For small disturbances
where formula_9 is the speed of sound in the medium.

Therefore,
The balance of mass can then be written as
Dropping the tildes and defining formula_71 gives us the commonly used expression for the balance of mass in an acoustic medium:

If we use a cylindrical coordinate system formula_73 with basis vectors formula_74, then the gradient of formula_20 and the divergence of formula_76 are given by
where the flow velocity has been expressed as formula_78.

The equations for the conservation of momentum may then be written as
In terms of components, these three equations for the conservation of momentum in cylindrical coordinates are

The equation for the conservation of mass can similarly be written in cylindrical coordinates as

The acoustic equations for the conservation of momentum and the conservation of mass are often expressed in time harmonic form (at fixed frequency). In that case, the pressures and the flow velocity are assumed to be time harmonic functions of the form
where formula_83 is the frequency. Substitution of these expressions into the governing equations in cylindrical coordinates gives us the fixed frequency form of the conservation of momentum
and the fixed frequency form of the conservation of mass

In the special case where the field quantities are independent of the z-coordinate we can eliminate formula_86 to get
Assuming that the solution of this equation can be written as
we can write the partial differential equation as
The left hand side is not a function of formula_90 while the right hand side is not a function of formula_91. Hence,
where formula_93 is a constant. Using the substitution
we have
The equation on the left is the Bessel equation, which has the general solution
where formula_97 is the cylindrical Bessel function of the first kind and formula_98 are undetermined constants. The equation on the right has the general solution
where formula_100 are undetermined constants. Then the solution of the acoustic wave equation is
Boundary conditions are needed at this stage to determine formula_102 and the other undetermined constants.



</doc>
<doc id="1235" url="https://en.wikipedia.org/wiki?curid=1235" title="Alexander Mackenzie (politician)">
Alexander Mackenzie (politician)

Alexander Mackenzie, (January 28, 1822April 17, 1892) was a Scottish-Canadian politician who served as the second prime minister of Canada, in office from 1873 to 1878.

Mackenzie was born in Logierait, Perthshire, Scotland. He left school at the age of 13, following his father's death to help his widowed mother, and trained as a stonemason. Mackenzie immigrated to Canada when he was 19, settling in what became Ontario. His masonry business prospered, allowing him to pursue other interests – such as the editorship of a pro-Reformist of a newspaper called the" Lambton Shield". Mackenzie was elected to the Legislative Assembly of the Province of Canada in 1861, as a supporter of George Brown.

In 1867, Mackenzie was elected to the new House of Commons of Canada for the Liberal Party. He became leader of the party (thus Leader of the Opposition) in mid-1873, and a few months later succeeded John A. Macdonald as prime minister, following Macdonald's resignation in the aftermath of the Pacific Scandal. Mackenzie and the Liberals won a clear majority at the 1874 election. He was popular among the general public for his humble background and apparent democratic tendencies.

As prime minister, Mackenzie continued the nation-building programme that had been begun by his predecessor. His government established the Supreme Court of Canada and Royal Military College of Canada, and created the District of Keewatin to better administer Canada's newly acquired western territories. However, it made little progress on the transcontinental railway, and struggled to deal with the aftermath of the Panic of 1873. At the 1878 election, Mackenzie's government suffered a landslide defeat. He remained leader of the Liberal Party for another two years, and continued on as a member of parliament until his death, due to a stroke.

Mackenzie was born on 28 January 1822 in Logierait, Perthshire, Scotland, the son of Mary Stewart (Fleming) and Alexander Mackenzie, Sr., who were married in 1817. The site of his birthplace is known as Clais-'n-deoir "The Hollow of the Weeping", where families said their goodbyes as the convicted were led to nearby Gallows Hill. The house in which he was born was built by his father and is still standing in 2019. He was the third of 10 boys, seven of whom survived infancy. Alexander Mackenzie, Sr., was a carpenter and ship's joiner who had to move around frequently for work after the end of the Napoleonic Wars in 1815. Mackenzie's father died on 7 March 1836 and at the age of 13, Alexander Mackenzie, Jr., was thus forced to end his formal education to help support his family. He apprenticed as a stonemason and met his future wife, Helen Neil, in Irvine, where her father was also a stonemason. The Neils were Baptist and shortly thereafter, Mackenzie converted from Presbyterianism to Baptist beliefs. Together with the Neils, he immigrated to Canada in 1842 to seek a better life. Mackenzie's faith was to link him to the increasingly influential temperance cause, particularly strong in Canada West where he lived, a constituency of which he was to represent in the Parliament of Canada.

The Neils and Mackenzie settled in Kingston, Ontario. The limestone in the area proved too hard for his stonemason tools, and not having money to buy new tools, Mackenzie took a job as a labourer constructing a building on Princess Street. The contractor on the job claimed financial difficulty, so Mackenzie accepted a promissory note for summer wages. The note later proved to be worthless. Subsequently, Mackenzie won a contract building a bomb-proof arch at Fort Henry. He later became a foreman on the construction of Kingston's four Martello Towers - Murney Tower, Fort Frederick, Cathcart Tower, and Shoal Tower. He was also a foreman on the construction of the Welland Canal and the Lachine Canal. While working on the Beauharnois Canal, a one-ton stone fell and crushed one of his legs. He recovered, but never regained the strength in that leg. While in Kingston, Mackenzie became a vocal opponent of religious and political entitlement and corruption in government.

Mackenzie married Helen Neil (1826–52) in 1845 and with her had three children, with only one girl, Mary, surviving infancy. Helen and he moved to Sarnia, Ontario (known as Canada West) in 1847 and Mary was born in 1848. They were soon joined from Scotland by the rest of Mackenzie's brothers and his mother. He began working as a general contractor, earning a reputation for being a hard-working, honest man, as well as having a working man's view on fiscal policy. Mackenzie helped construct many courthouses and jails across southern Ontario. A number of these still stand today, including the Sandwich Courthouse and Jail now known as the Mackenzie Hall Cultural Centre in Windsor, Ontario, and the Kent County Courthouse and Jail in Chatham, Ontario. He even bid, unsuccessfully, on the construction of the Parliament buildings in Ottawa in 1859. Helen died in 1852, finally succumbing to the effects of excessive doses of mercury-based calomel used to treat a fever while in Kingston. In 1853, he married Jane Sym (1825–93).

Mackenzie involved himself in politics almost from the moment he arrived in Canada. He fought passionately for equality and the elimination of all forms of class distinction. In 1851, he became the secretary for the Reform Party for Lambton. After convincing him to run in Kent/Lambton, Mackenzie campaigned relentlessly for George Brown, owner of the Reformist paper "The Globe" in the 1851 election, helping Brown to win his first seat in the Legislative Assembly. Mackenzie and Brown remained the closest of friends and colleagues for the rest of their lives. In 1852, Mackenzie became editor of another reformist paper, the "Lambton Shield". As editor, Mackenzie was perhaps a little too vocal, leading the paper to a lawsuit for libel against the local conservative candidate. Because a key witness claimed Cabinet Confidence and would not testify, the paper lost the suit and was forced to fold due to financial hardship. After his brother, Hope Mackenzie, declined to run, Alexander was petitioned to run and won his first seat in the Legislative Assembly as a supporter of George Brown in 1861. When Brown resigned from the Great Coalition in 1865 over reciprocity negotiations with the United States, Mackenzie was invited to replace him as the president of the council. Wary of Macdonald's motivations and true to his principles, Mackenzie declined.

He entered the House of Commons of Canada in 1867, representing the Lambton, Ontario, riding. No cohesive national Liberal Party of Canada existed at the time and with Brown not winning his seat, no official leader emerged. Mackenzie did not believe he was the best qualified for the position, and although he resisted offers of the position, he nevertheless sat as the "de facto" leader of the Official Opposition.

When the Macdonald government fell due to the Pacific Scandal in 1873, the Governor General, Lord Dufferin, called upon Mackenzie, who had been chosen as the leader of the Liberal Party a few months earlier, to form a new government. Mackenzie formed a government and asked the Governor General to call an election for January 1874. The Liberals won, having garnered 53.8% of the popular vote. The voter support of 53.8% remains the record in Canada for all federal elections. Mackenzie remained prime minister until the 1878 election when Macdonald's Conservatives returned to power with a majority government.

For a man of Mackenzie's humble origins to attain such a position was unusual in an age which generally offered such opportunity only to the privileged. Lord Dufferin, the current Governor General, expressed early misgivings about a stonemason taking over government, but on meeting Mackenzie, Dufferin revised his opinions:

However narrow and inexperienced Mackenzie may be, I imagine he is a thoroughly upright, well-principled, and well-meaning man.

Mackenzie served concurrently as Minister of Public Works and oversaw the completion of the Parliament buildings. While drawing up the plans for the West Block, he included a circular staircase leading directly from his office to the outside of the building, which allowed him to escape the patronage-seekers waiting for him in his ante-chamber. Proving Dufferin's reflections on his character to be true, Mackenzie disliked intensely the patronage inherent in politics. Nevertheless, he found it a necessary evil to maintain party unity and ensure the loyalty of his fellow Liberals.
In keeping with his democratic ideals, Mackenzie refused the offer of a knighthood three times, and was thus the only one of Canada's first eight Prime Ministers not to be knighted. He also declined appointment to the UK Privy Council and hence does not bear the title "Right Honourable". His pride in his working class origins never left him. Once, while touring Fort Henry as prime minister, he asked the soldier accompanying him if he knew the thickness of the wall beside them. The embarrassed escort confessed that he didn't and Mackenzie replied, "I do. It is five feet, ten inches. I know, because I built it myself!"

As Prime Minister, Alexander Mackenzie strove to reform and simplify the machinery of government, achieving a remarkable record of reform legislation. He introduced the secret ballot; advised the creation of the Supreme Court of Canada; the establishment of the Royal Military College of Canada in Kingston in 1874; and the creation of the Office of the Auditor General in 1878. He completed the Intercolonial Railway, but struggled to progress on the national railway due to a worldwide economic depression, almost coming to blows with the then Governor General Lord Dufferin over imperial interference. Mackenzie stood up for the rights of Canada as a nation and fought for the supremacy of Parliament and honesty in government. Above all else, he was known and loved for his honesty and integrity.

However, his term was marked by economic depression that had grown out of the Panic of 1873, which Mackenzie's government was unable to alleviate. In 1874, Mackenzie negotiated a new free trade agreement with the United States, eliminating the high protective tariffs on Canadian goods in US markets. However, this action did not bolster the economy, and construction of the CPR slowed drastically due to lack of funding. In 1876, the Conservative opposition announced a National Policy of protective tariffs, which resonated with voters. When an election was held at the conclusion of Mackenzie's five-year term, the Conservatives were swept back into office in a landslide victory.

Mackenzie chose the following jurists to be appointed as justices of the Supreme Court of Canada by the Governor General:

After his government's defeat, Mackenzie remained Leader of the Opposition for another two years, until 1880. He was soon struck with a mysterious ailment that sapped his strength and all but took his voice. Sitting in silence, he nevertheless remained an undefeated MP until his death in 1892 from a stroke that resulted from hitting his head during a fall. He died in Toronto and was buried in Lakeview Cemetery in Sarnia, Ontario.

Mackenzie's first biography in 1892 referred to him as Canada's Stainless Statesman. Here are a number of other references to his character. He was a devout Baptist and teetotaller who found refuge in, and drew strength from, his family, friends, and faith. He was also a loyal friend and an incorrigible prankster (stuffed chimney on young in-laws; rolled boulder down Thunder Cape towards friend A. McKellar; burned Tory campaign placards in hotel woodstove early in morning). Unpretentious and down to earth, his public official austerity was in striking contrast to private compassion and giving nature. He was the soul of honour and integrity, a proud man who sought no recognition or personal enrichment and accepted gifts reluctantly. He preferred to follow than lead (unreferenced - many times he refused leadership offers) and often found duty outweighed heavy burden of office. He was uncompromising on his principles, perhaps too much so. An historian at the time said, “He was, and ever will remain, the Sir Galahad of Canadian politics.”

Very proud of his Scottish heritage, he was forever a Scot “"Nemo me impune lacessit"” (no one attacks me with impunity). The Upper Canada rebellion leader W.L. Mackenzie referred to him, “He is every whit a self-made, self-educated man. Has large mental capacity and indomitable energy.” Canada's Governor General, Lord Dufferin, said of him, he is “as pure as crystal, and as true as steel, with lots of common sense.” A close friend, Chief Justice Sir Louis Davies, said he was “the best debater the House of Commons has ever known.” A friend and colleague in Cabinet who went on to become prime minister of Canada, Sir Wilfred Laurier, said he was “one of the truest and strongest characters to be met within Canadian history. He was endowed with a warm heart and a copious and rich fancy, though veiled by a somewhat reticent exterior, and he was of friends the most tender and true.” Another friend and colleague, who went on to become premier of Ontario, Sir George Ross, said, “Mackenzie was "sui generis" a debater. His humorous sallies blistered like a blast from a flaming smelter. His sterling honesty is a great heritage, and will keep his memory green to all future generations.” At his eulogy, Rev. Dr. Thomas compared him to the Duke of Wellington, who “stood four square, to all the winds that blow.”

Newspaper around the world and in Canada had this to say about him. "The London Times" – the untiring energy, the business-like accuracy, the keen perception and reliable judgment, and above all the inflexible integrity, which marked his private life, he carried without abatement of one jot into his public career. " The Westminster Review" – a man, who although, through failing health and failing voice, he had virtually passed out of public life, yet retained to the last the affectionate veneration of the Canadian people as no other man of the time can be said to have done. The" Charlottetown Patriot" – in all that constitutes the real man, the honest statesman, the true patriot, the warm friend, and sincere Christian, he had few equals. Possessed of a clear intellect, a retentive memory, and a ready command of appropriate words, he was one of the most logical and powerful speakers we have ever heard. The" St. John Telegraph" – he was loved by the people and his political opponents were compelled to respect him even above their own chosen leader. As a statesman, he has had few equals. The "Montreal Star" – it is one of the very foremost architects of the Canadian nationality that we mourn. In the dark days of ’73, Canadians were in a state of panic, distrusting the stability of their newly-built Dominion; no one can tell what would have happened had not the stalwart form of Alexander Mackenzie lifted itself above the screaming, vociferating and denying mass of politicians, and all Canada felt at once, there was a man who could be trusted. The "Toronto Globe" – he was a man who loved the people and fought for their rights against privilege and monopoly in every form. The "Philadelphia Record" – Like Caesar, who twice refused a knightly crown, Alexander Mackenzie refused knighthood three times. Unlike Caesar, he owed his political overthrow to his incorruptible honesty and unswerving integrity.

In their 1999 study of the Prime Ministers of Canada, which included the results of a survey of Canadian historians, J.L. Granatstein and Norman Hillmer found that Mackenzie was in 11th place just after John Sparrow David Thompson.

The following are named in honour of Alexander Mackenzie:






 


</doc>
<doc id="1239" url="https://en.wikipedia.org/wiki?curid=1239" title="Ashoka">
Ashoka

Ashoka (; IAST: Aśoka, Brāhmi: 𑀅𑀲𑁄𑀓, Asoka), sometimes Ashoka the Great, was an Indian emperor of the Maurya Dynasty, who ruled almost all of the Indian subcontinent from to 232 BCE. The grandson of the founder of the Maurya Dynasty, Chandragupta Maurya, Ashoka promoted the spread of Buddhism across ancient Asia. Considered by many to be one of India's greatest emperors, Ashoka expanded Chandragupta's empire to reign over a realm stretching from present-day Afghanistan in the west to Bangladesh in the east. It covered the entire Indian subcontinent except for parts of present-day Tamil Nadu, Karnataka and Kerala. The empire's capital was Pataliputra (in Magadha, present-day Patna), with provincial capitals at Taxila and Ujjain.

Ashoka waged a destructive war against the state of Kalinga (modern Odisha), which he conquered in about 260 BCE. In about 263 BCE, he converted to Buddhism after witnessing the mass deaths of the Kalinga War, which he had waged out of a desire for conquest and which reportedly directly resulted in more than 100,000 deaths and 150,000 deportations. He is remembered for the Ashoka pillars and edicts, for sending Buddhist monks to Sri Lanka and Central Asia, and for establishing monuments marking several significant sites in the life of Gautama Buddha.

Beyond the Edicts of Ashoka, biographical information about him relies on legends written centuries later, such as the 2nd-century CE "Ashokavadana" (""Narrative of Ashoka"", a part of the "Divyavadana"), and in the Sri Lankan text "Mahavamsa" (""Great Chronicle""). The emblem of the modern Republic of India is an adaptation of the Lion Capital of Ashoka. His Sanskrit name "" means "painless, without sorrow" (the "a" privativum and "śoka", "pain, distress"). In his edicts, he is referred to as ' (Pali ' or "the Beloved of the Gods"), and ' (Pali ' or "He who regards everyone with affection"). His fondness for his name's connection to the "Saraca asoca" tree, or "Ashoka tree", is also referenced in the "Ashokavadana". In "The Outline of History", H.G. Wells wrote, "Amidst the tens of thousands of names of monarchs that crowd the columns of history, their majesties and graciousnesses and serenities and royal highnesses and the like, the name of Ashoka shines, and shines, almost alone, a star."

Ashoka was born to the Mauryan emperor, Bindusara and Subhadrangī (or Dharmā). He was the grandson of Chandragupta Maurya, founder of the Maurya dynasty, who was born in a humble family, and with the counsel of Chanakya ultimately built one of the largest empires in ancient India. According to Roman historian Appian, Chandragupta had made a "marital alliance" with Seleucus; there is thus a slight possibility that Ashoka had a Seleucid Greek grandmother. An Indian Puranic source, the Pratisarga Parva of the Bhavishya Purana, also described the marriage of Chandragupta with a Greek ("Yavana") princess, daughter of Seleucus. Although there are no evidence showing if the Seleucid princess, as one of the many consorts of the Mauryan harem, had any children, let alone giving birth to Bindusara

The ancient Buddhist, Hindu, and Jain texts provide varying biographical accounts. The Avadana texts mention that his mother was queen Subhadrangī. According to the Ashokavadana, she was the daughter of a Brahmin from the city of Champa. She gave him the name Ashoka, meaning "one without sorrow". The "Divyāvadāna" tells a similar story, but gives the name of the queen as Janapadakalyānī. Ashoka had several elder siblings, all of whom were his half-brothers from the other wives of his father Bindusara. Ashoka was given royal military training.

The Buddhist text "Divyavadana" describes Ashoka putting down a revolt due to activities of wicked ministers. This may have been an incident in Bindusara's times. Taranatha's account states that Chanakya, Bindusara's chief advisor, destroyed the nobles and kings of 16 towns and made himself the master of all territory between the eastern and the western seas. Some historians consider this as an indication of Bindusara's conquest of the Deccan while others consider it as suppression of a revolt.

Following this, Ashoka was stationed at Ujain, the capital of Malwa, as governor. A commemorative inscription found in Saru Maru, Madhya Pradesh, mentions the visit of Piyadasi (honorific name used by Ashoka in his inscriptions) as he was still an unmarried Prince. This inscription confirms Ashoka's presence in Madhya Pradesh as a young man, and his status while he was there.

Bindusara's death in 272 BCE led to a war over succession. According to the "Divyavadana", Bindusara wanted his elder son Susima to succeed him but Ashoka was supported by his father's ministers, who found Susima to be arrogant and disrespectful towards them. A minister named Radhagupta seems to have played an important role in Ashoka's rise to the throne. The Ashokavadana recounts Radhagupta's offering of an old royal elephant to Ashoka for him to ride to the Garden of the Gold Pavilion where King Bindusara would determine his successor. Ashoka later got rid of the legitimate heir to the throne by tricking him into entering a pit filled with live coals. Radhagupta, according to the Ashokavadana, would later be appointed prime minister by Ashoka once he had gained the throne. The "Dipavansa" and "Mahavansa" refer to Ashoka's killing 99 of his brothers, sparing only one, named Vitashoka or Tissa, although there is no clear proof about this incident (many such accounts are saturated with mythological elements). The coronation happened in 269 BCE, four years after his succession to the throne.
Buddhist legends state that Ashoka was bad-tempered and of a wicked nature. He built Ashoka's Hell, an elaborate torture chamber described as a "Paradisal Hell" due to the contrast between its beautiful exterior and the acts carried out within by his appointed executioner, Girikaa. This earned him the name of "Chanda Ashoka" () meaning "Ashoka the Fierce" in Sanskrit. Professor Charles Drekmeier cautions that the Buddhist legends tend to dramatise the change that Buddhism brought in him, and therefore, exaggerate Ashoka's past wickedness and his piousness after the conversion.

Ascending the throne, Ashoka expanded his empire over the next eight years, from the present-day Assam in the East to Balochistan in the West; from the Pamir Knot in Afghanistan in the north to the peninsula of southern India except for present day Tamil Nadu and Kerala which were ruled by the three ancient Tamil kingdoms.

From the various sources that speak of his life, Ashoka is believed to have had five wives. They were named Devi (or Vedisa-Mahadevi-Shakyakumari), the second queen, Karuvaki, Asandhimitra (designated "" or "chief queen"), Padmavati, and Tishyarakshita. He is similarly believed to have had four sons and two daughters: a son by Devi named Mahendra (Pali: "Mahinda"), Tivara (son of Karuvaki), Kunala (son of Padmavati, and Jalauka (mentioned in the Kashmir Chronicle), a daughter of Devi named Sanghamitra (Pali: "Sanghamitta"), and another daughter named Charumati.

According to one version of the "Mahavamsa", the Buddhist chronicle of Sri Lanka, Ashoka, when he was heir-apparent and was journeying as Viceroy to Ujjain, is said to have halted at Vidisha (10 kilometers from Sanchi), and there married the daughter of a local banker. She was called Devi and later gave Ashoka two sons, Ujjeniya and Mahendra, and a daughter Sanghamitta. After Ashoka's accession, Mahendra headed a Buddhist mission, sent probably under the auspices of the Emperor, to Sri Lanka.

While the early part of Ashoka's reign was apparently quite bloodthirsty, he became a follower of the Buddha's teachings after his conquest of the Kalinga on the east coast of India in the present-day states of Odisha and North Coastal Andhra Pradesh. Kalinga was a state that prided itself on its sovereignty and democracy. With its monarchical parliamentary democracy it was quite an exception in ancient Bharata where there existed the concept of Rajdharma. Rajdharma means the duty of the rulers, which was intrinsically entwined with the concept of bravery and dharma. The Kalinga War happened eight years after his coronation. From his 13th inscription, we come to know that the battle was a massive one and caused the deaths of more than 100,000 soldiers and many civilians who rose up in defence; over 150,000 were deported.

Edict 13 of the Edicts of Ashoka Rock Inscriptions expresses the great remorse the king felt after observing the destruction of Kalinga:

Legend says that one day after the war was over, Ashoka ventured out to roam the city and all he could see were burnt houses and scattered corpses. The lethal war with Kalinga transformed the vengeful Emperor Ashoka to a stable and peaceful emperor and he became a patron of Buddhism. According to the prominent Indologist, A. L. Basham, Ashoka's personal religion became Buddhism, if not before, then certainly after the Kalinga war. However, according to Basham, the Dharma officially propagated by Ashoka was not Buddhism at all. Nevertheless, his patronage led to the expansion of Buddhism in the Mauryan empire and other kingdoms during his rule, and worldwide from about 250 BCE. Prominent in this cause were his son Mahinda (Mahendra) and daughter Sanghamitra (whose name means "friend of the Sangha"), who established Buddhism in Ceylon (now Sri Lanka).

Ashoka ruled for an estimated 36 years and died in 232 BCE. Legend states that during his cremation, his body burned for seven days and nights. After his death, the Mauryan dynasty lasted just fifty more years until his empire stretched over almost all of the Indian subcontinent. Ashoka had many wives and children, but many of their names are lost to time. His chief consort ("agramahisi") for the majority of his reign was his wife, Asandhimitra, who apparently bore him no children.

In his old age, he seems to have come under the spell of his youngest wife Tishyaraksha. It is said that she had got Ashoka's son Kunala, the regent in Takshashila and the heir presumptive to the throne, blinded by a wily stratagem. The official executioners spared Kunala and he became a wandering singer accompanied by his favourite wife Kanchanmala. In Pataliputra, Ashoka heard Kunala's song, and realised that Kunala's misfortune may have been a punishment for some past sin of the emperor himself. He condemned Tishyaraksha to death, restoring Kunala to the court. In the Ashokavadana, Kunala is portrayed as forgiving Tishyaraksha, having obtained enlightenment through Buddhist practice. While he urges Ashoka to forgive her as well, Ashoka does not respond with the same forgiveness.

The reign of Ashoka Maurya might have disappeared into history as the ages passed by, had he not left behind records of his reign. These records are in the form of sculpted pillars and rocks inscribed with a variety of actions and teachings he wished to be published under his name. The language used for inscription was in one of the Prakrit "common" languages etched in a Brahmi script.

In the year 185 BCE, about fifty years after Ashoka's death, the last Maurya ruler, Brihadratha, was assassinated by the commander-in-chief of the Mauryan armed forces, Pushyamitra Shunga, while he was taking the Guard of Honor of his forces. Pushyamitra Shunga founded the Shunga dynasty (185-75 BCE) and ruled just a fragmented part of the Mauryan Empire. Many of the northwestern territories of the Mauryan Empire (modern-day Afghanistan and Northern Pakistan) became the Indo-Greek Kingdom.

King Ashoka, the third monarch of the Indian Mauryan dynasty, is also considered as one of the most exemplary rulers who ever lived.

One of the more enduring legacies of Ashoka was the model that he provided for the relationship between Buddhism and the state. Emperor Ashoka was seen as a role model to leaders within the Buddhist community. He not only provided guidance and strength, but he also created personal relationships with his supporters. Throughout Theravada Southeastern Asia, the model of rulership embodied by Ashoka replaced the notion of divine kingship that had previously dominated (in the Angkor kingdom, for instance). Under this model of 'Buddhist kingship', the king sought to legitimise his rule not through descent from a divine source, but by supporting and earning the approval of the Buddhist "sangha". Following Ashoka's example, kings established monasteries, funded the construction of stupas, and supported the ordination of monks in their kingdom. Many rulers also took an active role in resolving disputes over the status and regulation of the sangha, as Ashoka had in calling a conclave to settle a number of contentious issues during his reign. This development ultimately led to a close association in many Southeast Asian countries between the monarchy and the religious hierarchy, an association that can still be seen today in the state-supported Buddhism of Thailand and the traditional role of the Thai king as both a religious and secular leader. Ashoka also said that all his courtiers always governed the people in a moral manner.

According to the legends mentioned in the 2nd-century CE text "Ashokavadana", Ashoka was not non-violent after adopting Buddhism. In one instance, a non-Buddhist in Pundravardhana drew a picture showing the Buddha bowing at the feet of Nirgrantha Jnatiputra (identified with Mahavira, 24th Tirthankara of Jainism). On complaint from a Buddhist devotee, Ashoka issued an order to arrest him, and subsequently, another order to kill all the Ajivikas in Pundravardhana. Around 18,000 followers of the Ajivika sect were executed as a result of this order. Sometime later, another Nirgrantha follower in Pataliputra drew a similar picture. Ashoka burnt him and his entire family alive in their house. He also announced an award of one dinara (silver coin) to anyone who brought him the head of a Nirgrantha heretic. According to "Ashokavadana", as a result of this order, his own brother was mistaken for a heretic and killed by a cowherd. However, for several reasons, scholars say, these stories of persecutions of rival sects by Ashoka appear to be clear fabrications arising out of sectarian propaganda.

Ashoka had almost been forgotten, but in the 19th century James Prinsep contributed in the revelation of historical sources. After deciphering the Brahmi script, Prinsep had originally identified the "Priyadasi" of the inscriptions he found with the King of Ceylon Devanampiya Tissa. However, in 1837, George Turnour discovered an important Sri Lankan manuscript (Dipavamsa, or "Island Chronicle" ) associating Piyadasi with Ashoka:

Since then, the association of "Devanampriya Priyadarsin" with Ashoka was confirmed through various inscriptions, and especially confirmed in the Minor Rock Edict inscription discovered in Maski, directly associating Ashoka with his regnal title Devanampriya ("Beloved-of-the-Gods"):

Another important historian was British archaeologist John Hubert Marshall, who was director-General of the Archaeological Survey of India. His main interests were Sanchi and Sarnath, in addition to Harappa and Mohenjodaro. Sir Alexander Cunningham, a British archaeologist and army engineer, and often known as the father of the Archaeological Survey of India, unveiled heritage sites like the Bharhut Stupa, Sarnath, Sanchi, and the Mahabodhi Temple. Mortimer Wheeler, a British archaeologist, also exposed Ashokan historical sources, especially the Taxila.
Information about the life and reign of Ashoka primarily comes from a relatively small number of Buddhist sources. In particular, the Sanskrit "Ashokavadana" ('Story of Ashoka'), written in the 2nd century, and the two Pāli chronicles of Sri Lanka (the Dipavamsa and "Mahavamsa") provide most of the currently known information about Ashoka. Additional information is contributed by the Edicts of Ashoka, whose authorship was finally attributed to the Ashoka of Buddhist legend after the discovery of dynastic lists that gave the name used in the edicts ("Priyadarshi"—'He who regards everyone with affection') as a title or additional name of Ashoka Maurya. Architectural remains of his period have been found at Kumhrar, Patna, which include an 80-pillar hypostyle hall.

Edicts of Ashoka -The Edicts of Ashoka are a collection of 33 inscriptions on the Pillars of Ashoka, as well as boulders and cave walls, made by Ashoka during his reign. These inscriptions are dispersed throughout modern-day Pakistan and India, and represent the first tangible evidence of Buddhism. The edicts describe in detail the first wide expansion of Buddhism through the sponsorship of one of the most powerful kings of Indian history, offering more information about Ashoka's proselytism, moral precepts, religious precepts, and his notions of social and animal welfare.

Ashokavadana – The "Aśokāvadāna" is a 2nd-century CE text related to the legend of Ashoka. The legend was translated into Chinese by Fa Hien in 300 CE. It is essentially a Hinayana text, and its world is that of Mathura and North-west India. The emphasis of this little known text is on exploring the relationship between the king and the community of monks (the Sangha) and setting up an ideal of religious life for the laity (the common man) by telling appealing stories about religious exploits. The most startling feature is that Ashoka's conversion has nothing to do with the Kalinga war, which is not even mentioned, nor is there a word about his belonging to the Maurya dynasty. Equally surprising is the record of his use of state power to spread Buddhism in an uncompromising fashion. The legend of Veetashoka provides insights into Ashoka's character that are not available in the widely known Pali records.

"Mahavamsa" -The "Mahavamsa" ("Great Chronicle") is a historical poem written in the Pali language of the kings of Sri Lanka. It covers the period from the coming of King Vijaya of Kalinga (ancient Odisha) in 543 BCE to the reign of King Mahasena (334–361). As it often refers to the royal dynasties of India, the "Mahavamsa" is also valuable for historians who wish to date and relate contemporary royal dynasties in the Indian subcontinent. It is very important in dating the consecration of Ashoka.

Dwipavamsa -The Dwipavamsa, or "Dweepavamsa", (i.e., Chronicle of the Island, in Pali) is the oldest historical record of Sri Lanka. The chronicle is believed to be compiled from Atthakatha and other sources around the 3rd or 4th century CE. King Dhatusena (4th century) had ordered that the Dipavamsa be recited at the Mahinda festival held annually in Anuradhapura.

The caduceus appears as a symbol of the punch-marked coins of the Maurya Empire in India, in the 3rd-2nd century BCE. Numismatic research suggests that this symbol was the symbol of king Ashoka, his personal "Mudra". This symbol was not used on the pre-Mauryan punch-marked coins, but only on coins of the Maurya period, together with the three arched-hill symbol, the "peacock on the hill", the triskelis and the Taxila mark.

The use of Buddhist sources in reconstructing the life of Ashoka has had a strong influence on perceptions of Ashoka, as well as the interpretations of his Edicts. Building on traditional accounts, early scholars regarded Ashoka as a primarily Buddhist monarch who underwent a conversion to Buddhism and was actively engaged in sponsoring and supporting the Buddhist monastic institution. Some scholars have tended to question this assessment. Romila Thappar writes about Ashoka that "We need to see him both as a statesman in the context of inheriting and sustaining an empire in a particular historical period, and as a person with a strong commitment to changing society through what might be called the propagation of social ethics." The only source of information not attributable to Buddhist sources are the Ashokan Edicts, and these do not explicitly state that Ashoka was a Buddhist. In his edicts, Ashoka expresses support for all the major religions of his time: Buddhism, Brahmanism, Jainism, and Ajivikaism, and his edicts addressed to the population at large (there are some addressed specifically to Buddhists; this is not the case for the other religions) generally focus on moral themes members of all the religions would accept. For example, Amartya Sen writes, "The Indian Emperor Ashoka in the third century BCE presented many political inscriptions in favor of tolerance and individual freedom, both as a part of state policy and in the relation of different people to each other".

However, the edicts alone strongly that he was a Buddhist. In one edict he belittles rituals, and he banned Vedic animal sacrifices; these strongly suggest that he at least did not look to the Vedic tradition for guidance. Furthermore, many edicts are expressed to Buddhists alone; in one, Ashoka declares himself to be an "upasaka", and in another he demonstrates a close familiarity with Buddhist texts. He erected rock pillars at Buddhist holy sites, but did not do so for the sites of other religions. He also used the word "dhamma" to refer to qualities of the heart that underlie moral action; this was an exclusively Buddhist use of the word. However, he used the word more in the spirit than as a strict code of conduct. Romila Thappar writes, "His dhamma did not derive from divine inspiration, even if its observance promised heaven. It was more in keeping with the ethic conditioned by the logic of given situations. His logic of Dhamma was intended to influence the conduct of categories of people, in relation to each other. Especially where they involved unequal relationships." Finally, he promotes ideals that correspond to the first three steps of the Buddha's graduated discourse.

The Ashokavadana presents an alternate view of the familiar Ashoka; one in which his conversion has nothing to do with the Kalinga war or about his descent from the Maurya dynasty. Instead, Ashoka's reason for adopting non-violence appears much more personal. The Ashokavadana shows that the main source of Ashoka's conversion and the acts of welfare that followed are rooted instead in intense personal anguish at its core, from a wellspring inside himself rather than spurred by a specific event. It thereby illuminates Ashoka as more humanly ambitious and passionate, with both greatness and flaws. "This" Ashoka is very different from the "shadowy do-gooder" of later Pali chronicles.

Much of the knowledge about Ashoka comes from the several inscriptions that he had carved on pillars and rocks throughout the empire. All his inscriptions present him as compassionate and loving. In the Kalinga rock edits, he addresses his people as his "children" and mentions that as a father he desires their good. These inscriptions promoted Buddhist morality and encouraged nonviolence and adherence to dharma (duty or proper behaviour), and they talk of his fame and conquered lands as well as the neighbouring kingdoms holding up his might. One also gets some primary information about the Kalinga War and Ashoka's allies plus some useful knowledge on the civil administration. The Ashoka Pillar at Sarnath is the most notable of the relics left by Ashoka. Made of sandstone, this pillar records the visit of the emperor to Sarnath, in the 3rd century BCE. It has a four-lion capital (four lions standing back to back), which was adopted as the emblem of the modern Indian republic. The lion symbolises both Ashoka's imperial rule and the kingship of the Buddha. In translating these monuments, historians learn the bulk of what is assumed to have been true fact of the Mauryan Empire. It is difficult to determine whether or not some events ever actually happened, but the stone etchings clearly depict how Ashoka wanted to be thought of and remembered.

Recently scholarly analysis determined that the three major foci of debate regarding Ashoka involve the nature of the Maurya empire; the extent and impact of Ashoka's pacifism; and what is referred to in the Inscriptions as "dhamma" or dharma, which connotes goodness, virtue, and charity. Some historians have argued that Ashoka's pacifism undermined the "military backbone" of the Maurya empire, while others have suggested that the extent and impact of his pacifism have been "grossly exaggerated". The "dhamma" of the Edicts has been understood as concurrently a Buddhist lay ethic, a set of politico-moral ideas, a "sort of universal religion", or as an Ashokan innovation. On the other hand, it has also been interpreted as an "essentially political" ideology that sought to knit together a vast and diverse empire. Scholars are still attempting to analyse both the expressed and implied political ideas of the Edicts (particularly in regard to imperial vision), and make inferences pertaining to how that vision was grappling with problems and political realities of a "virtually subcontinental, and culturally and economically highly variegated, 3rd century BCE Indian empire. Nonetheless, it remains clear that Ashoka's Inscriptions represent the earliest corpus of royal inscriptions in the Indian subcontinent, and therefore prove to be a very important innovation in royal practices."

Until the Ashokan inscriptions were discovered and deciphered, stories about Ashoka were based on the legendary accounts of his life and not strictly on historical facts. These legends were found in Buddhist textual sources such as the text of "Ashokavadana". The "Ashokavadana" is a subset of a larger set of legends in the "Divyavadana", though it could have existed independently as well. Following are some of the legends narrated in the "Ashokavadana" about Ashoka:

1) One of the stories talks about an event that occurred in a past life of Ashoka, when he was a small child named Jaya. Once when Jaya was playing on the roadside, the Buddha came by. The young child put a handful of earth in the Buddha's begging bowl as his gift to the saint and declared his wish to one day become a great emperor and follower of the Buddha. The Buddha is said to have smiled a smile that “illuminated the universe with its rays of light”. These rays of light are then said to have re-entered the Buddha's left palm, signifying that this child Jaya would, in his next life, become a great emperor. The Buddha is said to have even turned to his disciple Ananda and is said to have predicted that this child would be “a great, righteous chakravarti king, who would rule his empire from his capital at Pataliputra”.

2) Another story aims to portray Ashoka as an evil person in order to convey the importance of his transformation into a good person upon adopting Buddhism. It begins by stating that due to Ashoka's physical ugliness he was disliked by his father Bindusara. Ashoka wanted to become king and so he got rid of the heir by tricking him into entering a pit filled with live coals. He became famous as “Ashoka the Fierce” because of his wicked nature and bad temper. He is said to have subjected his ministers to a test of loyalty and then have 500 of them killed for failing it. He is said to have burnt his entire harem to death when certain women insulted him. He is supposed to have derived sadistic pleasure from watching other people suffer. And for this he built himself an elaborate and horrific torture chamber where he amused himself by torturing other people. The story then goes on to narrate how it was only after an encounter with a pious Buddhist monk that Ashoka himself transformed into "Ashoka the pious". A Chinese traveler who visited India in the 7th century CE, Xuan Zang recorded in his memoirs that he visited the place where the supposed torture chamber stood.

3) Another story is about events that occurred towards the end of Ashoka's time on earth. Ashoka is said to have started gifting away the contents of his treasury to the Buddhist "sangha". His ministers however were scared that his eccentricity would be the downfall of the empire and so denied him access to the treasury. As a result, Ashoka started giving away his personal possessions and was eventually left with nothing and so died peacefully.

At this point it is important to note that the "Ashokavadana" being a Buddhist text in itself sought to gain new converts for Buddhism and so used all these legends. Devotion to the Buddha and loyalty to the "sangha" are stressed. Such texts added to the perception that Ashoka was essentially the ideal Buddhist monarch who deserved both admiration and emulation.

According to Buddhist legend, particularly the Mahaparinirvana, the relics of the Buddha had been shared among eight countries following his death. Ashoka endeavoured to take back the relics and share them among 84,000 stupas. This story is amply depicted in the reliefs of Sanchi and Bharhut. According to the legend, Ashoka obtained the ashes from seven of the countries, but failed to take the ashes from the Nagas at Ramagrama. This scene is depicted on the tranversal portion of the southern gateway at Sanchi.

According to Indian historian Romila Thapar, Ashoka emphasized respect for all religious teachers, and harmonious relationship between parents and children, teachers and pupils, and employers and employees. Ashoka's religion contained gleanings from all religions. He emphasized the virtues of "Ahimsa", respect to all religious teachers, equal respect for and study of each other's scriptures, and rational faith.

As a Buddhist emperor, Ashoka believed that Buddhism is beneficial for all human beings as well as animals and plants, so he built a number of stupas, Sangharama, viharas, chaitya, and residences for Buddhist monks all over South Asia and Central Asia. According to the Ashokavadana, he ordered the construction of 84,000 stupas to house the Buddha's relics. In the Aryamanjusrimulakalpa, Ashoka takes offerings to each of these stupas traveling in a chariot adorned with precious metals. He gave donations to viharas and mathas. He sent his only daughter Sanghamitra and son Mahindra to spread Buddhism in Sri Lanka (then known as Tamraparni).

According to the "Mahavamsa" (XII, 1st paragraph), in the 17th year of his reign, at the end of the Third Buddhist Council, Ashoka sent Buddhist missionaries to nine parts of the world (eight parts of Southern Asia, and the "country of the Yonas (Greeks)") to propagate Buddhism.

Ashoka also invited Buddhists and non-Buddhists for religious conferences. He inspired the Buddhist monks to compose the sacred religious texts, and also gave all types of help to that end. Ashoka also helped to develop viharas (intellectual hubs) such as Nalanda and Taxila. Ashoka helped to construct Sanchi and Mahabodhi Temple. Ashoka also gave donations to non-Buddhists. As his reign continued his even-handedness was replaced with special inclination towards Buddhism. Ashoka helped and respected both Shramanas (Buddhists monks) and Brahmins (Vedic monks). Ashoka also helped to organise the Third Buddhist council () at Pataliputra (today's Patna), conducted by the monk Moggaliputta-Tissa.

Emperor Ashoka's son, Mahinda, also helped with the spread of Buddhism by translating the Buddhist Canon into a language that could be understood by the people of Sri Lanka.

It is well known that Ashoka sent "dütas" or emissaries to convey messages or letters, written or oral (rather both), to various people. The VIth Rock Edict about "oral orders" reveals this. It was later confirmed that it was not unusual to add oral messages to written ones, and the content of Ashoka's messages can be inferred likewise from the XIIIth Rock Edict: They were meant to spread his "dhammavijaya," which he considered the highest victory and which he wished to propagate everywhere (including far beyond India). There is obvious and undeniable trace of cultural contact through the adoption of the Kharosthi script, and the idea of installing inscriptions might have travelled with this script, as Achaemenid influence is seen in some of the formulations used by Ashoka in his inscriptions. This indicates to us that Ashoka was indeed in contact with other cultures, and was an active part in mingling and spreading new cultural ideas beyond his own immediate walls.

In his rock edicts, Ashoka states that he had encouraged the transmission of Buddhism to the Hellenistic kingdoms to the west and that the Greeks in his dominion were converts to Buddhism and recipients of his envoys:

It is not too far-fetched to imagine, however, that Ashoka received letters from Greek rulers and was acquainted with the Hellenistic royal orders in the same way as he perhaps knew of the inscriptions of the Achaemenid kings, given the presence of ambassadors of Hellenistic kings in India (as well as the "dütas" sent by Ashoka himself). Dionysius is reported to have been such a Greek ambassador at the court of Ashoka, sent by Ptolemy II Philadelphus, who himself is mentioned in the Edicts of Ashoka as a recipient of the Buddhist proselytism of Ashoka. Some Hellenistic philosophers, such as Hegesias of Cyrene, who probably lived under the rule of King Magas, one of the supposed recipients of Buddhist emissaries from Asoka, are sometimes thought to have been influenced by Buddhist teachings.

The Greeks in India even seem to have played an active role in the propagation of Buddhism, as some of the emissaries of Ashoka, such as Dharmaraksita, are described in Pali sources as leading Greek (Yona) Buddhist monks, active in spreading Buddhism (the "Mahavamsa", XII).

Some Greeks (Yavana) may have played an administrative role in the territories ruled by Ashoka. The Girnar inscription of Rudradaman records that during the rule of Ashoka, a Yavana Governor was in charge in the area of Girnar, Gujarat, mentioning his role in the construction of a water reservoir.

Ashoka's military power was strong, but after his conversion to Buddhism, he maintained friendly relations with three major Tamil kingdoms in the South—namely, Cheras, Cholas and Pandyas—the post-Alexandrian empire, Tamraparni, and Suvarnabhumi. His edicts state that he made provisions for medical treatment of humans and animals in his own kingdom as well as in these neighbouring states. He also had wells dug and trees planted along the roads for the benefit of the common people.

Ashoka's rock edicts declare that injuring living things is not good, and no animal should be sacrificed for slaughter. However, he did not prohibit common cattle slaughter or beef eating.

He imposed a ban on killing of "all four-footed creatures that are neither useful nor edible", and of specific animal species including several birds, certain types of fish and bulls among others. He also banned killing of female goats, sheep and pigs that were nursing their young; as well as their young up to the age of six months. He also banned killing of all fish and castration of animals during certain periods such as Chaturmasa and Uposatha.

Ashoka also abolished the royal hunting of animals and restricted the slaying of animals for food in the royal residence. Because he banned hunting, created many veterinary clinics and eliminated meat eating on many holidays, the Mauryan Empire under Ashoka has been described as "one of the very few instances in world history of a government treating its animals as citizens who are as deserving of its protection as the human residents".

The Ashoka Chakra (the wheel of Ashoka) is a depiction of the Dharmachakra (the Wheel of Dharma). The wheel has 24 spokes which represent the 12 Laws of Dependent Origination and the 12 Laws of Dependent Termination. The Ashoka Chakra has been widely inscribed on many relics of the Mauryan Emperor, most prominent among which is the Lion Capital of Sarnath and The Ashoka Pillar. The most visible use of the Ashoka Chakra today is at the centre of the National flag of the Republic of India (adopted on 22 July 1947), where it is rendered in a Navy-blue color on a White background, by replacing the symbol of Charkha (spinning wheel) of the pre-independence versions of the flag. The Ashoka Chakra can also been seen on the base of the Lion Capital of Ashoka which has been adopted as the National Emblem of India.

The Ashoka Chakra was created by Ashoka during his reign. Chakra is a Sanskrit word which also means "cycle" or "self-repeating process". The process it signifies is the cycle of time—as in how the world changes with time.

A few days before India became independent in August 1947, the specially-formed Constituent Assembly decided that the flag of India must be acceptable to all parties and communities. A flag with three colours, Saffron, White and Green with the Ashoka Chakra was selected.

Ashoka is often credited with the beginning of stone architecture in India, possibly following the introduction of stone-building techniques by the Greeks after Alexander the Great. Before Ashoka's time, buildings were probably built in non-permanent material, such as wood, bamboo or thatch. Ashoka may have rebuilt his palace in Pataliputra by replacing wooden material by stone, and may also have used the help of foreign craftmen. Ashoka also innovated by using the permanent qualities of stone for his written edicts, as well as his pillars with Buddhist symbolism.

The pillars of Ashoka are a series of columns dispersed throughout the northern Indian subcontinent, and erected by Ashoka during his reign in the 3rd century BCE. Originally, there must have been many pillars of Ashoka although only ten with inscriptions still survive. Averaging between forty and fifty feet in height, and weighing up to fifty tons each, all the pillars were quarried at Chunar, just south of Varanasi and dragged, sometimes hundreds of miles, to where they were erected. The first Pillar of Ashoka was found in the 16th century by Thomas Coryat in the ruins of ancient Delhi. The wheel represents the sun time and Buddhist law, while the swastika stands for the cosmic dance around a fixed center and guards against evil.

The Lion capital of Ashoka is a sculpture of four lions standing back to back. It was originally placed atop the Ashoka pillar at Sarnath, now in the state of Uttar Pradesh, India. The pillar, sometimes called the Ashoka Column, is still in its original location, but the Lion Capital is now in the Sarnath Museum. This Lion Capital of Ashoka from Sarnath has been adopted as the National Emblem of India and the wheel ("Ashoka Chakra") from its base was placed onto the center of the National Flag of India.

The capital contains four lions (Indian / Asiatic Lions), standing back to back, mounted on a short cylindrical abacus, with a frieze carrying sculptures in high relief of an elephant, a galloping horse, a bull, and a lion, separated by intervening spoked chariot-wheels over a bell-shaped lotus. Carved out of a single block of polished sandstone, the capital was believed to be crowned by a 'Wheel of Dharma' (Dharmachakra popularly known in India as the "Ashoka Chakra"). The Sarnath pillar bears one of the Edicts of Ashoka, an inscription against division within the Buddhist community, which reads, "No one shall cause division in the order of monks."

The four animals in the Sarnath capital are believed to symbolise different steps of Lord Buddha's life.

Besides the religious interpretations, there are some non-religious interpretations also about the symbolism of the Ashoka capital pillar at Sarnath. According to them, the four lions symbolise Ashoka's rule over the four directions, the wheels as symbols of his enlightened rule (Chakravartin) and the four animals as symbols of four adjoining territories of India.

The British restoration was done under guidance from Weligama Sri Sumangala.





</doc>
<doc id="1241" url="https://en.wikipedia.org/wiki?curid=1241" title="American (word)">
American (word)

The meaning of the word American in the English language varies according to the historical, geographical, and political context in which it is used. "American" is derived from "America", a term originally denoting all of the New World (also called the Americas). In some expressions, it retains this Pan-American sense, but its usage has evolved over time and, for various historical reasons, the word came to denote people or things specifically from the United States of America.

In modern English, "American" generally refers to persons or things related to the United States of America; among native English speakers this usage is almost universal, with any other use of the term requiring specification. However, this usage is seen by some as a semantic "misappropriation" by those who argue that "American" should be widened in English to also include people or things from anywhere in the American continents.

The word can be used as either an adjective or a noun (viz. a demonym). In adjectival use, it means "of or relating to the United States"; for example, "Elvis Presley was an American singer" or "the man prefers American English". In its noun form, the word generally means a resident or citizen of the US, or occasionally someone whose ethnic identity is simply "American". The noun is rarely used in English to refer to people not connected to the United States. When used with a grammatical qualifier, the adjective "American" can mean "of or relating to the Americas", as in Latin American or Indigenous American. Less frequently, the adjective can take this meaning without a qualifier, as in "American Spanish dialects and pronunciation differ by country", or the name of the Organization of American States. A third use of the term pertains specifically to the indigenous peoples of the Americas, for instance, "In the 16th century, many Americans died from imported diseases during the European conquest".

Compound constructions such as "African Americans" likewise refer exclusively to people in or from the United States of America, as does the prefix "Americo-". For instance, the Americo-Liberians and their language Merico derive their name from the fact that they are descended from African American settlers, i.e. former slaves in the United States of America.

French, German, Italian, Japanese, Hebrew, Arabic, and Russian speakers may use cognates of "American" to refer to inhabitants of the Americas or to U.S. nationals. They generally have other terms specific to U.S. nationals, such as the German ', French ', Japanese , Arabic ' ( as opposed to ' ), and Italian "". These specific terms may be less common than the term "American".

In French, ', ' or ', from ' ("United States of America"), is a rarely used word that distinguishes U.S. things and persons from the adjective "", which denotes persons and things from the United States, but may also refer to "the Americas".

Likewise, German's use of ' and ' observe said cultural distinction, solely denoting U.S. things and people. Note that in normal parlance, the adjective "American" and its direct cognates are usually used if the context renders the nationality of the person clear.

This differentiation is prevalent in German-speaking countries, as indicated by the style manual of the "Neue Zürcher Zeitung" (one of the leading German-language newspapers in Switzerland) which dismisses the term ' as both ′unnecessary′ and ′artificial′ and recommends replacing it with "amerikanisch". The respective guidelines of the foreign ministries of Austria, Germany and Switzerland all prescribe "Amerikaner" and "amerikanisch" in reference to the United States for official usage, making no mention of ' or "".

Portuguese has ', denoting both a person or thing from the Americas and a U.S. national. For referring specifically to a U.S. national and things, some words used are ' (also spelled ', "United States person"), from ', and ' ("Yankee")—both usages exist in Brazil, but are uncommon in Portugal—but the term most often used, and the only one in Portugal, is ', even though it could, as with its Spanish equivalent, apply to Canadians, Mexicans, etc. as well.

In Spanish, ' denotes geographic and cultural origin in the New World, as well as (infrequently) a U.S. citizen; the more common term is ' ("United States person"), which derives from ' ("United States of America"). The Spanish term ' ("North American") is frequently used to refer things and persons from the United States, but this term can also denote people and things from Canada and Mexico. Among Spanish-speakers, North America generally doesn't include Central America or the Caribbean.

In other languages, however, there is no possibility for confusion. For example, the Chinese word for "U.S. national" is ' () is derived from a word for the United States, ', where ' is an abbreviation for "Yàměilìjiā" ("America") and ' is "country". The name for the American continents is ', from ' plus ' ("continent"). Thus, a ' is an American in the continent sense, and a "" is an American in the U.S. sense.

Conversely, in Czech, there is no possibility for disambiguation. "Američan" (m.) and "američanka" (f.) can refer to persons from the United States or from the continents of the Americas, and there is no specific word capable of distinguishing the two meanings. For this reason, the latter meaning is very rarely used, and word "američan(ka)" is used almost exclusively to refer to persons from the United States. The usage is exactly parallel to the English word.

Korean and Vietnamese also use unambiguous terms, with Korean having ' () for the country versus ' () for the continents, and Vietnamese having ' for the country versus ' for the continents. Japanese has such terms as well (' [ versus ' []), but they are found more in newspaper headlines than in speech, where "" predominates.

In Swahili, ' means specifically the United States, and ' is a U.S. national, whereas the international form ' refers to the continents, and ' would be an inhabitants thereof. Likewise, the Esperanto word ' refers to the continents. For the country there is the term '. Thus, a citizen of the United States is an ', whereas an ' is an inhabitant of the Americas.

In Hungarian the term amerikai (American) refers to a person or a thing from the United States.

The name "America" was coined by Martin Waldseemüller from "Americus Vespucius", the Latinized version of the name of Amerigo Vespucci (1454–1512), the Italian explorer who mapped South America's east coast and the Caribbean Sea in the early 16th century. Later, Vespucci's published letters were the basis of Waldseemüller's 1507 map, which is the first usage of "America". The adjective "American" subsequently denoted the New World.

16th-century European usage of "American" denoted the native inhabitants of the New World. The earliest recorded use of this term in English is in Thomas Hacket's 1568 translation of André Thévet's book "France Antarctique"; Thévet himself had referred to the natives as "Ameriques". In the following century, the term was extended to European settlers and their descendants in the Americas. The earliest recorded use of "English-American" dates to 1648, in Thomas Gage's "The English-American his travail by sea and land: or, a new survey of the West India's".

In English, "American" was used especially for people in the British America. Samuel Johnson, the leading English lexicographer, wrote in 1775, before the United States declared independence: "That the Americans are able to bear taxation is indubitable." The Declaration of Independence of July 1776 refers to "[the] unanimous Declaration of the thirteen United States of America" adopted by the "Representatives of the United States of America" on July 4, 1776. The official name of the country was reaffirmed on November 15, 1777, when the Second Continental Congress adopted the Articles of Confederation, the first of which says, "The Stile of this Confederacy shall be 'The United States of America'". The Articles further state:
Sam Haselby, a history professor in Lebanon and Egypt, claims it was British officials who first called the colonists "Americans". When the drafters of the "Declaration"—Thomas Jefferson from Virginia, for example, or John Adams from Massachusetts—talked about "my country", they meant Virginia or Massachusetts, respectively. This situation was changed by the Revolution and the impulse toward nationalism. Jefferson, newly elected president in May 1801 wrote, "I am sure the measures I mean to pursue are such as would in their nature be approved by every American who can emerge from preconceived prejudices; as for those who cannot, we must take care of them as of the sick in our hospitals. The medicine of time and fact may cure some of them."

In "The Federalist Papers" (1787–88), Alexander Hamilton and James Madison used the adjective "American" with two different meanings: one political and one geographic; "the American republic" in Federalist No. 51 and in Federalist No. 70, and, in Federalist No. 24, Hamilton used "American" to denote the lands beyond the U.S.'s political borders.

Early official U.S. documents show inconsistent usage; the 1778 Treaty of Alliance with France used "the United States of North America" in the first sentence, then "the said United States" afterwards; "the United States of America" and "the United States of North America" derive from "the United Colonies of America" and "the United Colonies of North America". The Treaty of Peace and Amity of September 5, 1795, between the United States and the Barbary States contains the usages "the United States of North America", "citizens of the United States", and "American Citizens".
U.S. President George Washington, in his 1796 "Farewell Address", declaimed that "The name of American, which belongs to you in your national capacity, must always exalt the just pride of patriotism more than any appellation." Political scientist Virginia L. Arbery notes that, in his "Farewell Address": "...Washington invites his fellow citizens to view themselves now as Americans who, out of their love for the truth of liberty, have replaced their maiden names (Virginians, South Carolinians, New Yorkers, etc.) with that of “American”. Get rid of, he urges, “any appellation derived from local discriminations.” By defining himself as an American rather than as a Virginian, Washington set the national standard for all citizens. "Over and over, Washington said that America must be something set apart. As he put it to Patrick Henry, 'In a word, I want an "American" character, that the powers of Europe may be convinced we act for "ourselves" and not for "others".'" As the historian Garry Wills has noted: "This was a theme dear to Washington. He wrote to Timothy Pickering that the nation 'must never forget that we are Americans; the remembrance of which will convince us we ought not to be French or English'." Washington's countrymen subsequently embraced his exhortation with notable enthusiasm.

This semantic divergence among North American anglophones, however, remained largely unknown in the Spanish-American colonies. In 1801, the document titled "Letter to American Spaniards"—published in French (1799), in Spanish (1801), and in English (1808)—might have influenced Venezuela's Act of Independence and its 1811 constitution.

The Latter-day Saints' Articles of Faith refer to the American continents as where they are to build Zion. 
Common short forms and abbreviations are the "United States", the "U.S.", the "U.S.A.", and "America"; colloquial versions include the "U.S. of A." and "the States". The term "Columbia" (from the Columbus surname) was a popular name for the U.S. and for the entire geographic Americas; its usage is present today in the District of Columbia's name. Moreover, the womanly personification of Columbia appears in some official documents, including editions of the U.S. dollar.

Use of the term "American" for U.S. nationals is common at the United Nations, and financial markets in the United States are referred to as "American financial markets".

"American Samoa" is a recognized territorial name at the United Nations.

The use of "American" as a national demonym for U.S. nationals is challenged, primarily by Hispanic Americans. Spanish speakers in Spain and Latin America use the term ' to refer to people and things from the United States (from '), while ' refers to the continents as a whole. The term ' is also accepted in many parts of Latin America to refer to a person or something from the United States, however this term may be ambiguous in certain parts. Up to and including the 1992 edition, the ', published by the Real Academia Española, did not include the United States definition in the entry for '; this was added in the 2001 edition. The Real Academia Española advised against using "" exclusively for U.S. nationals:
Modern Canadians typically refer to people from the United States as "Americans", though they seldom refer to the United States as "America"; they use the terms "the United States", "the U.S.", or (informally) "the States" instead. Canadians rarely apply the term "American" to themselves – some Canadians resent either being referred to as Americans because of mistaken assumptions that they are U.S. citizens or others' inability, particularly of those overseas, to distinguish Canadian from American accents. Some Canadians have protested the use of "American" as a national demonym. People of U.S. ethnic origin in Canada are categorized as "Other North American origins" by Statistics Canada for purposes of census counts.

Generally, ' denotes "U.S. citizen" in Portugal. Usage of ' to exclusively denote people and things of the U.S. is discouraged by the Lisbon Academy of Sciences, because the specific word ' (also ') clearly denotes a person from the United States. The term currently used by the Portuguese press is ".

In Brazil, the term ' is used to address both that which pertains to both American continents and, in current speech, that which pertains to the U.S.; the particular meaning is deduced from context. Alternatively, the term ' ("North American") is also used in more informal contexts, while ' (of the U.S.) is the preferred form in academia. Use of the three terms is common in schools, government, and media. The term ' is used almost exclusively for the continents, and the U.S. is called ' ("United States") or ' ("United States of America"), often abbreviated ".

The Getting Through Customs website advises business travelers not to use "in America" as a U.S. reference when conducting business in Brazil.

"American" in the 1994 "Associated Press Stylebook" was defined as, "An acceptable description for a resident of the United States. It also may be applied to any resident or citizen of nations in North or South America." Elsewhere, the "AP Stylebook" indicates that "United States" must "be spelled out when used as a noun. Use U.S. (no space) only as an adjective."

The entry for "America" in "The New York Times Manual of Style and Usage" from 1999 reads:
Media releases from the Pope and Holy See frequently use "America" to refer to the United States, and "American" to denote something or someone from the United States.

At least one international law uses "U.S. citizen" in defining a citizen of the United States rather than "American citizen"; for example, the English version of the North American Free Trade Agreement includes:
Many international treaties use the terms "American" and "American citizen":

Products that are labeled, advertised, and marketed in the U.S. as "Made in the USA" must be, as set by the Federal Trade Commission (FTC), "all or virtually all made in the U.S." The FTC, to prevent deception of customers and unfair competition, considers an unqualified claim of "American Made" to expressly claim exclusive manufacture in the U.S: "The FTC Act gives the Commission the power to bring law enforcement actions against false or misleading claims that a product is of U.S. origin."

There are a number of alternatives to the demonym "American" as a citizen of the United States that do not simultaneously mean any inhabitant of the Americas. One uncommon alternative is "Usonian", which usually describes a certain style of residential architecture designed by Frank Lloyd Wright. Other alternatives have also surfaced, but most have fallen into disuse and obscurity. "Merriam-Webster's Dictionary of English Usage" says:

Nevertheless, no alternative to "American" is common.




</doc>
<doc id="1242" url="https://en.wikipedia.org/wiki?curid=1242" title="Ada (programming language)">
Ada (programming language)

Ada is a structured, statically typed, imperative, and object-oriented high-level computer programming language, extended from Pascal and other languages. It has built-in language support for design-by-contract, extremely strong typing, explicit concurrency, tasks, synchronous message passing, protected objects, and non-determinism. Ada improves code safety and maintainability by using the compiler to find errors in favor of runtime errors. Ada is an international standard; the current version (known as Ada 2012) is defined by ISO/IEC 8652:2012.

Ada was originally designed by a team led by French computer scientist Jean Ichbiah of CII Honeywell Bull under contract to the United States Department of Defense (DoD) from 1977 to 1983 to supersede over 450 programming languages used by the DoD at that time. Ada was named after Ada Lovelace (1815–1852), who has been credited as the first computer programmer.

Ada was originally targeted at embedded and real-time systems. The Ada 95 revision, designed by S. Tucker Taft of Intermetrics between 1992 and 1995, improved support for systems, numerical, financial, and object-oriented programming (OOP).

Features of Ada include: strong typing, modularity mechanisms (packages), run-time checking, parallel processing (tasks, synchronous message passing, protected objects, and nondeterministic select statements), exception handling, and generics. Ada 95 added support for object-oriented programming, including dynamic dispatch.

The syntax of Ada minimizes choices of ways to perform basic operations, and prefers English keywords (such as "or else" and "and then") to symbols (such as "||" and "&&"). Ada uses the basic arithmetical operators "+", "-", "*", and "/", but avoids using other symbols. Code blocks are delimited by words such as "declare", "begin", and "end", where the "end" (in most cases) is followed by the identifier of the block it closes (e.g., "if ... end if", "loop ... end loop"). In the case of conditional blocks this avoids a "dangling else" that could pair with the wrong nested if-expression in other languages like C or Java.

Ada is designed for development of very large software systems. Ada packages can be compiled separately. Ada package specifications (the package interface) can also be compiled separately without the implementation to check for consistency. This makes it possible to detect problems early during the design phase, before implementation starts.

A large number of compile-time checks are supported to help avoid bugs that would not be detectable until run-time in some other languages or would require explicit checks to be added to the source code. For example, the syntax requires explicitly named closing of blocks to prevent errors due to mismatched end tokens. The adherence to strong typing allows detection of many common software errors (wrong parameters, range violations, invalid references, mismatched types, etc.) either during compile-time, or otherwise during run-time. As concurrency is part of the language specification, the compiler can in some cases detect potential deadlocks. Compilers also commonly check for misspelled identifiers, visibility of packages, redundant declarations, etc. and can provide warnings and useful suggestions on how to fix the error.

Ada also supports run-time checks to protect against access to unallocated memory, buffer overflow errors, range violations, off-by-one errors, array access errors, and other detectable bugs. These checks can be disabled in the interest of runtime efficiency, but can often be compiled efficiently. It also includes facilities to help program verification. For these reasons, Ada is widely used in critical systems, where any anomaly might lead to very serious consequences, e.g., accidental death, injury or severe financial loss. Examples of systems where Ada is used include avionics, air traffic control, railways, banking, military and space technology.

Ada's dynamic memory management is high-level and type-safe. Ada does not have generic or untyped pointers; nor does it implicitly declare any pointer type. Instead, all dynamic memory allocation and deallocation must take place through explicitly declared "access types".
Each access type has an associated "storage pool" that handles the low-level details of memory management; the programmer can either use the default storage pool or define new ones (this is particularly relevant for Non-Uniform Memory Access). It is even possible to declare several different access types that all designate the same type but use different storage pools.
Also, the language provides for "accessibility checks", both at compile time and at run time, that ensures that an "access value" cannot outlive the type of the object it points to.

Though the semantics of the language allow automatic garbage collection of inaccessible objects, most implementations do not support it by default, as it would cause unpredictable behaviour in real-time systems. Ada does support a limited form of region-based memory management; also, creative use of storage pools can provide for a limited form of automatic garbage collection, since destroying a storage pool also destroys all the objects in the pool.

A double-dash ("--"), resembling an em dash, denotes comment text. Comments stop at end of line, to prevent unclosed comments from accidentally voiding whole sections of source code. Disabling a whole block of code now requires the prefixing of each line (or column) individually with "--". While clearly denoting disabled code with a column of repeated "--" down the page this renders the experimental dis/re-enablement of large blocks a more drawn out process.

The semicolon (";") is a statement terminator, and the null or no-operation statement is codice_1. A single codice_2 without a statement to terminate is not allowed.

Unlike most ISO standards, the Ada language definition (known as the "Ada Reference Manual" or "ARM", or sometimes the "Language Reference Manual" or "LRM") is free content. Thus, it is a common reference for Ada programmers and not just programmers implementing Ada compilers. Apart from the reference manual, there is also an extensive rationale document which explains the language design and the use of various language constructs. This document is also widely used by programmers. When the language was revised, a new rationale document was written.

One notable free software tool that is used by many Ada programmers to aid them in writing Ada source code is the GNAT Programming Studio.

In the 1970s, the US Department of Defense (DoD) was concerned by the number of different programming languages being used for its embedded computer system projects, many of which were obsolete or hardware-dependent, and none of which supported safe modular programming. In 1975, a working group, the High Order Language Working Group (HOLWG), was formed with the intent to reduce this number by finding or creating a programming language generally suitable for the department's and the UK Ministry of Defence requirements. After many iterations beginning with an original Straw man proposal the eventual programming language was named Ada. The total number of high-level programming languages in use for such projects fell from over 450 in 1983 to 37 by 1996.

The HOLWG working group crafted the Steelman language requirements, a series of documents stating the requirements they felt a programming language should satisfy. Many existing languages were formally reviewed, but the team concluded in 1977 that no existing language met the specifications.

Requests for proposals for a new programming language were issued and four contractors were hired to develop their proposals under the names of Red (Intermetrics led by Benjamin Brosgol), Green (CII Honeywell Bull, led by Jean Ichbiah), Blue (SofTech, led by John Goodenough) and Yellow (SRI International, led by Jay Spitzen). In April 1978, after public scrutiny, the Red and Green proposals passed to the next phase. In May 1979, the Green proposal, designed by Jean Ichbiah at CII Honeywell Bull, was chosen and given the name Ada—after Augusta Ada, Countess of Lovelace. This proposal was influenced by the programming language LIS that Ichbiah and his group had developed in the 1970s. The preliminary Ada reference manual
was published in ACM SIGPLAN Notices in June 1979. The Military Standard reference manual was approved on December 10, 1980 (Ada Lovelace's birthday), and
given the number MIL-STD-1815 in honor of Ada Lovelace's birth year. In 1981, C. A. R. Hoare took advantage of his Turing Award speech to criticize Ada for being overly complex and hence unreliable, but subsequently seemed to recant in the foreword he wrote for an Ada textbook.

Ada attracted much attention from the programming community as a whole during its early days. Its backers and others predicted that it might become a dominant language for general purpose programming and not just defense-related work. Ichbiah publicly stated that within ten years, only two programming languages would remain, Ada and Lisp. Early Ada compilers struggled to implement the large, complex language, and both compile-time and run-time performance tended to be slow and tools primitive. Compiler vendors expended most of their efforts in passing the massive, language-conformance-testing, government-required "ACVC" validation suite that was required in another novel feature of the Ada language effort. The Jargon File, a dictionary of computer hacker slang originating in 1975-1983, notes in an entry on Ada that "it is precisely what one might expect given that kind of endorsement by fiat; designed by committee...difficult to use, and overall a disastrous, multi-billion-dollar boondoggle...Ada Lovelace...would almost certainly blanch at the use her name has been latterly put to; the kindest thing that has been said about it is that there is probably a good small language screaming to get out from inside its vast, {elephantine} bulk."

The first validated Ada implementation was the NYU Ada/Ed translator, certified on April 11, 1983. NYU Ada/Ed is implemented in the high-level set language SETL. A number of commercial companies began offering Ada compilers and associated development tools, including Alsys, TeleSoft, DDC-I, Advanced Computer Techniques, Tartan Laboratories, TLD Systems, Verdix, and others.
In 1991, the US Department of Defense began to require the use of Ada (the "Ada mandate") for all software, though exceptions to this rule were often granted. The Department of Defense Ada mandate was effectively removed in 1997, as the DoD began to embrace COTS technology. Similar requirements existed in other NATO countries: Ada was required for NATO systems involving command and control and other functions, and Ada was the mandated or preferred language for defense-related applications in countries such as Sweden, Germany, and Canada.

By the late 1980s and early 1990s, Ada compilers had improved in performance, but there were still barriers to full exploitation of Ada's abilities, including a tasking model that was different from what most real-time programmers were used to.

Because of Ada's safety-critical support features, it is now used not only for military applications, but also in commercial projects where a software bug can have severe consequences, e.g., avionics and air traffic control, commercial rockets such as the Ariane 4 and 5, satellites and other space systems, railway transport and banking.
For example, the Airplane Information Management System, the fly-by-wire system software in the Boeing 777, was written in Ada. Developed by Honeywell Air Transport Systems in collaboration with consultants from DDC-I, it became arguably the best-known of any Ada project, civilian or military. The Canadian Automated Air Traffic System was written in 1 million lines of Ada (SLOC count). It featured advanced distributed processing, a distributed Ada database, and object-oriented design. Ada is also used in other air traffic systems, e.g., the UK's next-generation Interim Future Area Control Tools Support (iFACTS) air traffic control system is designed and implemented using SPARK Ada.
It is also used in the French TVM in-cab signalling system on the TGV high-speed rail system, and the metro suburban trains in Paris, London, Hong Kong and New York City.

The language became an ANSI standard in 1983 (ANSI/MIL-STD 1815A), and after translation in French and without any further changes in English became
an ISO standard in 1987 (ISO-8652:1987). This version of the language is commonly known as Ada 83, from the date of its adoption by ANSI, but is sometimes referred to also as Ada 87, from the date of its adoption by ISO.

Ada 95, the joint ISO/ANSI standard (ISO-8652:1995) was published in February 1995, making Ada 95 the first ISO standard object-oriented programming language. To help with the standard revision and future acceptance, the US Air Force funded the development of the GNAT Compiler. Presently, the GNAT Compiler is part of the GNU Compiler Collection.

Work has continued on improving and updating the technical content of the Ada programming language. A Technical Corrigendum to Ada 95 was published in October 2001, and a major Amendment, ISO/IEC 8652:1995/Amd 1:2007 was published on March 9, 2007. At the Ada-Europe 2012 conference in Stockholm, the Ada Resource Association (ARA) and Ada-Europe announced the completion of the design of the latest version of the Ada programming language and the submission of the reference manual to the International Organization for Standardization (ISO) for approval. ISO/IEC 8652:2012 was published in December 2012.

Other related standards include ISO 8651-3:1988 "Information processing systems—Computer graphics—Graphical Kernel System (GKS) language bindings—Part 3: Ada".

Ada is an ALGOL-like programming language featuring control structures with reserved words such as "if", "then", "else", "while", "for", and so on. However, Ada also has many data structuring facilities and other abstractions which were not included in the original ALGOL 60, such as type definitions, records, pointers, enumerations. Such constructs were in part inherited from or inspired by Pascal.

A common example of a language's syntax is the Hello world program:

with Ada.Text_IO; use Ada.Text_IO;
procedure Hello is
begin
end Hello;

This program can be compiled by using the freely available open source compiler GNAT, by executing
gnatmake hello.adb

Ada's type system is not based on a set of predefined primitive types but allows users to declare their own types. This declaration in turn is not based on the internal representation of the type but on describing the goal which should be achieved. This allows the compiler to determine a suitable memory size for the type, and to check for violations of the type definition at compile time and run time (i.e., range violations, buffer overruns, type consistency, etc.). Ada supports numerical types defined by a range, modulo types, aggregate types (records and arrays), and enumeration types. Access types define a reference to an instance of a specified type; untyped pointers are not permitted.
Special types provided by the language are task types and protected types.

For example, a date might be represented as:
type Day_type is range 1 .. 31;
type Month_type is range 1 .. 12;
type Year_type is range 1800 .. 2100;
type Hours is mod 24;
type Weekday is (Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday);

type Date is
Types can be refined by declaring subtypes:

subtype Working_Hours is Hours range 0 .. 12; -- at most 12 Hours to work a day
subtype Working_Day is Weekday range Monday .. Friday; -- Days to work

Work_Load: constant array(Working_Day) of Working_Hours -- implicit type declaration

Types can have modifiers such as "limited, abstract, private" etc. Private types can only be accessed and limited types can only be modified or copied within the scope of the package that defines them.
Ada 95 adds additional features for object-oriented extension of types.

Ada is a structured programming language, meaning that the flow of control is structured into standard statements. All standard constructs and deep level early exit are supported so the use of the also supported 'go to' commands is seldom needed.
-- while a is not equal to b, loop.
while a /= b loop
end loop;

if a > b then
else
end if;

for i in 1 .. 10 loop
end loop;

loop
end loop;

case i is
end case;

for aWeekday in Weekday'Range loop -- loop over an enumeration
end loop;
Among the parts of an Ada program are packages, procedures and functions.

Example:
Package specification (example.ads)

package Example is
end Example;

Package body (example.adb)

with Ada.Text_IO;
package body Example is

-- package initialization executed when the package is elaborated
begin
end Example;

This program can be compiled, e.g., by using the freely available open source compiler GNAT, by executing
gnatmake -z example.adb

Packages, procedures and functions can nest to any depth and each can also be the logical outermost block.

Each package, procedure or function can have its own declarations of constants, types, variables, and other procedures, functions and packages, which can be declared in any order.

Ada has language support for task-based concurrency. The fundamental concurrent unit in Ada is a "task", which is a built-in limited type. Tasks are specified in two parts – the task declaration defines the task interface (similar to a type declaration), the task body specifies the implementation of the task.
Depending on the implementation, Ada tasks are either mapped to operating system threads or processes, or are scheduled internally by the Ada runtime.

Tasks can have entries for synchronisation (a form of synchronous message passing). Task entries are declared in the task specification. Each task entry can have one or more "accept" statements within the task body. If the control flow of the task reaches an accept statement, the task is blocked until the corresponding entry is called by another task (similarly, a calling task is blocked until the called task reaches the corresponding accept statement). Task entries can have parameters similar to procedures, allowing tasks to synchronously exchange data. In conjunction with "select" statements it is possible to define "guards" on accept statements (similar to Dijkstra's guarded commands).

Ada also offers "protected objects" for mutual exclusion. Protected objects are a monitor-like construct, but use guards instead of conditional variables for signaling (similar to conditional critical regions). Protected objects combine the data encapsulation and safe mutual exclusion from monitors, and entry guards from conditional critical regions. The main advantage over classical monitors is that conditional variables are not required for signaling, avoiding potential deadlocks due to incorrect locking semantics. Like tasks, the protected object is a built-in limited type, and it also has a declaration part and a body.

A protected object consists of encapsulated private data (which can only be accessed from within the protected object), and procedures, functions and entries which are guaranteed to be mutually exclusive (with the only exception of functions, which are required to be side effect free and can therefore run concurrently with other functions). A task calling a protected object is blocked if another task is currently executing inside the same protected object, and released when this other task leaves the protected object. Blocked tasks are queued on the protected object ordered by time of arrival.

Protected object entries are similar to procedures, but additionally have "guards". If a guard evaluates to false, a calling task is blocked and added to the queue of that entry; now another task can be admitted to the protected object, as no task is currently executing inside the protected object. Guards are re-evaluated whenever a task leaves the protected object, as this is the only time when the evaluation of guards can have changed.

Calls to entries can be "requeued" to other entries with the same signature. A task that is requeued is blocked and added to the queue of the target entry; this means that the protected object is released and allows admission of another task.

The "select" statement in Ada can be used to implement non-blocking entry calls and accepts, non-deterministic selection of entries (also with guards), time-outs and aborts.

The following example illustrates some concepts of concurrent programming in Ada.

with Ada.Text_IO; use Ada.Text_IO;

procedure Traffic is

begin
end Traffic;
A pragma is a compiler directive that conveys information to the compiler to allow specific manipulation of compiled output. Certain pragmas are built into the language while others are implementation-specific.

Examples of common usage of compiler pragmas would be to disable certain features, such as run-time type checking or array subscript boundary checking, or to instruct the compiler to insert object code in lieu of a function call (as C/C++ does with inline functions).







</doc>
<doc id="1247" url="https://en.wikipedia.org/wiki?curid=1247" title="Alfonso Cuarón">
Alfonso Cuarón

Alfonso Cuarón Orozco (; ; born 28 November 1961) is a Mexican film director, screenwriter, producer, cinematographer, and editor. His work has received critical acclaim and many accolades. He has been nominated for 10 Academy Awards and won five, including two Best Director awards for "Gravity" (2013) and "Roma" (2018). He is the first Latin American director to receive the award for Best Director. He has also received Academy Awards for Best Film Editing for "Gravity" and Best Cinematography for "Roma". Cuarón's other notable films include the family drama "A Little Princess" (1995), the erotic drama "Y Tu Mamá También" (2001), the fantasy film "Harry Potter and the Prisoner of Azkaban" (2004), and the dystopian thriller "Children of Men" (2006).

Alfonso Cuarón Orozco was born in Mexico City on 28 November 1961, the son of Alfredo Cuarón, a doctor specializing in nuclear medicine, and Cristina Orozco, a pharmaceutical biochemist. He has two brothers, Carlos, also a filmmaker, and Alfredo, a conservation biologist. Cuarón studied philosophy at the National Autonomous University of Mexico (UNAM) and filmmaking at CUEC (Centro Universitario de Estudios Cinematográficos), a school within the same university. There, he met the director Carlos Marcovich and cinematographer Emmanuel Lubezki, and they made what would be his first short film, "Vengeance Is Mine".

Cuarón began working on television in Mexico, first as a technician and then as a director. His television work led to assignments as an assistant director for several film productions including "La Gran Fiesta", "" and "Romero", and in 1991, he landed his first big-screen directorial assignment.

"Sólo con Tu Pareja" is a sex comedy about a womanizing businessman (played by Daniel Giménez Cacho) who, after having sex with an attractive nurse, is fooled into believing he's contracted AIDS. In addition to writing, producing and directing, Cuarón co-edited the film with Luis Patlán.

The film, which also starred cabaret singer Astrid Hadad and model/actress Claudia Ramírez (with whom Cuarón was linked between 1989 and 1993), was a big hit in Mexico. After this success, director Sydney Pollack hired Cuarón to direct an episode of "Fallen Angels", a series of neo-noir stories produced for the Showtime premium cable network in 1993; other directors who worked on the series included Steven Soderbergh, Jonathan Kaplan, Peter Bogdanovich and Tom Hanks.

In 1995, Cuarón released his first feature film produced in the United States, "A Little Princess", an adaptation of Frances Hodgson Burnett's classic novel. Cuarón's next feature was also a literary adaptation, a modernized version of Charles Dickens's "Great Expectations" starring Ethan Hawke, Gwyneth Paltrow and Robert De Niro.

Cuarón's next project found him returning to Mexico with a Spanish-speaking cast to film "Y Tu Mamá También", starring Gael García Bernal, Diego Luna and Maribel Verdú. It was a provocative and controversial road comedy about two sexually obsessed teenagers who take an extended road trip with an attractive married woman who is much older than them. The film's open portrayal of sexuality and frequent rude humor, as well as the politically and socially relevant asides, made the film an international hit and a major success with critics. Cuarón shared an Academy Award nomination for Best Original Screenplay with co-writer and brother Carlos Cuarón.

In 2004, Cuarón directed the third film in the successful "Harry Potter" series, "Harry Potter and the Prisoner of Azkaban". Cuarón faced criticism from some "Harry Potter" fans for his approach to the film. At the time of the movie's release, however, author J. K. Rowling, who had seen and loved Cuarón's film "Y Tu Mamá También", said that it was her personal favorite from the series so far. Critically, the film was also better received than the first two installments, with some critics remarking its new tone and for being the first "Harry Potter" film to truly capture the essence of the novels.

Cuarón's feature "Children of Men", an adaptation of the P. D. James novel starring Clive Owen, Julianne Moore and Michael Caine, received wide critical acclaim, including three Academy Award nominations. Cuarón himself received two nominations for his work on the film in Best Film Editing (with Alex Rodríguez) and Best Adapted Screenplay (with several collaborators).

He created the production and distribution company Esperanto Filmoj ("Esperanto Films", named because of his support for the international language Esperanto), which has credits in the films "Duck Season", "Pan's Labyrinth", and "Gravity".

Cuarón also directed the controversial public service announcement "I Am Autism" for Autism Speaks that was criticized by disability rights groups for its negative portrayal of autism.

In 2010, Cuarón began to develop the film "Gravity", a drama set in space. He was joined by producer David Heyman, with whom Cuarón worked on "Harry Potter and the Prisoner of Azkaban". Starring Sandra Bullock and George Clooney, the film was released in the fall of 2013 and opened the 70th Venice International Film Festival in August. On 12 January 2014, Alfonso accepted the Golden Globe Award in the category of Best Director. The film received ten Academy Award nominations, including Best Picture and Best Director. Cuarón won for Best Directing, becoming the first Latin American to win the award, while he and Mark Sanger received the award for Best Film Editing.

In 2013, Cuarón created "Believe", a science fiction/fantasy/adventure series that was broadcast as part of the 2013–14 United States network television schedule on NBC as a mid-season entry. The series was created by Cuarón for Bad Robot Productions and Warner Bros. Television. In 2014, "TIME" placed him in its list of "100 Most Influential People in the World" – Pioneers.

In May 2015, Cuarón was announced as the President of the Jury for the 72nd Venice International Film Festival.

Production began in fall 2016 for Cuarón's eighth film, "Roma", a semi-autobiographical tale of a housekeeper for a middle class Mexican family in 1970s Mexico City. The project was produced by Cuarón, Gabriela Rodríguez and Nicolás Celis. The film debuted at 75th Venice International Film Festival, where it won the Golden Lion, and was distributed to select theaters in Mexico and United States before its online release on Netflix. "Roma" was highly acclaimed upon release; among its accolades are two Golden Globes (Best Foreign Language Film and Best Director for Cuarón) and three Academy Awards (Best Director, Best Foreign Language Film, and Best Cinematography for Cuarón) out of a leading ten nominations.

Cuarón is a vegetarian and has been living in London since 2000. 

Cuarón's first marriage was to Mariana Elizondo, with whom he has a son, Jonás Cuarón, born in 1981, who is also a film director, known for "Year of the Nail" and "Desierto". His second marriage, from 2001 to 2008, was to Italian actress and freelance journalist Annalisa Bugliani, with whom he has two children.

He has publicly shown his fascination for the Esperanto language and his support for the Esperanto movement. In fact, he called his production company "Esperanto Filmoj".

Producer Only




</doc>
<doc id="1252" url="https://en.wikipedia.org/wiki?curid=1252" title="Arianism">
Arianism

Arianism is a nontrinitarian Christological doctrine which asserts the belief that Jesus Christ is the Son of God who was begotten by God the Father at a point in time, a creature distinct from the Father and is therefore subordinate to him, but the Son is also God (i.e. God the Son). Arian teachings were first attributed to Arius (c. AD 256–336), a Christian presbyter in Alexandria of Egypt. The term "Arian" is derived from the name Arius; and like "Christian", it was not a self-chosen designation but bestowed by hostile opponents—and never accepted by those on whom it had been imposed. The nature of Arius's teaching and his supporters were opposed to the theological views held by Homoousian Christians, regarding the nature of the Trinity and the nature of Christ. The Arian concept of Christ is based on the belief that the Son of God did not always exist but was begotten within time by God the Father.

There was a dispute between two interpretations of Jesus' divinity (Homoousianism and Arianism) based upon the theological orthodoxy of the time, one trinitarian and the other non-trinitarian, and both of them attempted to solve its respective theological dilemmas. So there were, initially, two equally orthodox interpretations which initiated a conflict in order to attract adepts and define the new orthodoxy. The two interpretations initiated a broader conflict as to which belief was the successor of Christian theology from its inception. The former was formally affirmed by the first two Ecumenical Councils, and in the past several centuries, Arianism has continued to be viewed as "the heresy or sect of Arius". As such, all mainstream branches of Christianity now consider Arianism to be heterodox and heretical. The trinitarianism, or homoousianism viewpoint, was promulgated by Athanasius of Alexandria, who insisted that Homoousianism theology was both the true nature of God and the teaching of Jesus. Arius stated: "If the Father begat the Son, then he who was begotten had a beginning in existence, and from this it follows there was a time when the Son was not." Nonetheless, the Ecumenical First Council of Nicaea of 325, convened by Emperor Constantine to ensure Church unity, deemed Arianism to be a heresy." According to Everett Ferguson, "The great majority of Christians had no clear views about the nature of the Trinity and they did not understand what was at stake in the issues that surrounded it." 

Ten years later, however, Constantine the Great, who was himself baptized by the Arian bishop Eusebius of Nicomedia, convened another gathering of Church leaders at the regional First Synod of Tyre in 335 (attended by 310 bishops), to address various charges mounted against Athanasius by his pro-Arius detractors, such as "murder, illegal taxation, sorcery, and treason", following his refusal to readmit Arius into fellowship. Athanasius was exiled to Trier (in modern Germany) following his conviction at Tyre of conspiracy, and Arius was, effectively, exonerated. Athanasius eventually returned to Alexandria in 346 A.D., two years after the deaths of both Arius and Constantine; though "Arianism" had spread, Athanasius and other trinitarian Church leaders crusaded against the theology, and Arius was again anathemised and pronounced a heretic once more at the Ecumenical First Council of Constantinople of 381 (attended by 150 bishops). The Roman Emperors Constantius II (337–361) and Valens (364–378) were Arians or Semi-Arians, as was the first King of Italy, Odoacer (433?–493), and the Lombards were also Arians or Semi-Arians until the 7th century. Visigothic Spain was Arian until 581. Many Goths when they converted to Christianity adopted Arian beliefs. The Vandal regime in North Africa actively imposed Arianism.

Arianism is also used to refer to other nontrinitarian theological systems of the 4th century, which regarded Jesus Christ—the Son of God, the Logos—as either a begotten creature (as in Arianism proper and Anomoeanism) or as neither uncreated nor created in the sense other beings are created (as in Semi-Arianism).

Arius had been a pupil of Lucian of Antioch at Lucian's private academy in Antioch and inherited from him a modified form of the teachings of Paul of Samosata. He taught that God the Father and the Son of God did not always exist together eternally.

Arians taught that the Logos was a divine being begotten by God the Father before the creation of the world, made him a medium through whom everything else was created, and that the Son of God is subordinate to God the Father. A verse from Proverbs was also used: "The Lord created me at the beginning of his work" (Proverbs ). Therefore, the Son was rather the very first and the most perfect of God's creatures, and he was made "God" only by the Father's permission and power.

Controversy over Arianism arose in the late 3rd century and persisted throughout most of the 4th century. It involved most church members—from simple believers, priests, and monks to bishops, emperors, and members of Rome's imperial family. Two Roman emperors, Constantius II and Valens, became Arians or Semi-Arians, as did prominent Gothic, Vandal, and Lombard warlords both before and after the fall of the Western Roman Empire. Such a deep controversy within the Church during this period of its development could not have materialized without significant historical influences providing a basis for the Arian doctrines. Of the roughly three hundred bishops in attendance at the Council of Nicea, two bishops did not sign the Nicene Creed that condemned Arianism. Emperor Constantine also ordered a penalty of death for those who refused to surrender the Arian writings:

Reconstructing what Arius actually taught, and why, is a formidable task, both because little of his own work survives except in quotations selected for polemical purposes by his opponents, and also because there is no certainty about what theological and philosophical traditions formed his thought.

Arians do not believe in the traditional doctrine of the Trinity. The letter of Arian Auxentius regarding the Arian missionary Ulfilas gives a picture of Arian beliefs. Arian Ulfilas, who was ordained a bishop by Arian Eusebius of Nicomedia and returned to his people to work as a missionary, believed: God, the Father, ("unbegotten" God; Almighty God) always existing and who is the only true God (). The Son of God, Jesus Christ, ("only-begotten God" ), Mighty God (); begotten before time began (, , ) and who is Lord/Master (). The Holy Spirit (the illuminating and sanctifying power, who is neither God the Father nor Lord/Master. was cited as proof text:

The creed of Arian Ulfilas (c. 311–383), which concludes a letter praising him written by Auxentius, distinguishes God the Father ("unbegotten"), who is the only true God from Son of God ("only-begotten"), who is Lord/Master; and the Holy Spirit, the illuminating and sanctifying power, who is neither God the Father nor Lord/Master:

A letter from Arius (c. 250–336) to the Arian Eusebius of Nicomedia (died 341) succinctly states the core beliefs of the Arians:

Principally, the dispute between Trinitarianism and Arianism was about:

Arianism had several different variants, including Eunomianism and Homoian Arianism. Homoian Arianism is associated with Akakius and Eudoxius. Homoian Arianism avoided the use of the word "ousia" to describe the relation of Father to Son, and described these as "like" each other. Hanson lists twelve creeds that reflect the Homoian faith:

In 321, Arius was denounced by a synod at Alexandria for teaching a heterodox view of the relationship of Jesus to God the Father. Because Arius and his followers had great influence in the schools of Alexandria—counterparts to modern universities or seminaries—their theological views spread, especially in the eastern Mediterranean.

By 325, the controversy had become significant enough that the Emperor Constantine called an assembly of bishops, the First Council of Nicaea, which condemned Arius's doctrine and formulated the original Nicene Creed of 325. The Nicene Creed's central term, used to describe the relationship between the Father and the Son, is Homoousios (), or Consubstantiality, meaning "of the same substance" or "of one being" (the Athanasian Creed is less often used but is a more overtly anti-Arian statement on the Trinity).

The focus of the Council of Nicaea was the nature of the Son of God and his precise relationship to God the Father (see Paul of Samosata and the Synods of Antioch). Arius taught that Jesus Christ was divine/holy and was sent to earth for the salvation of mankind but that Jesus Christ was not equal to God the Father (infinite, primordial origin) in rank "and" that God the Father and the Son of God were not equal to the Holy Spirit (power of God the Father). Under Arianism, Christ was instead not consubstantial with God the Father since both the Father and the Son under Arius were made of "like" essence or being (see homoiousia) but not of the same essence or being (see homoousia).

In the Arian view, God the Father is a Deity and is divine "and" the Son of God is not a Deity but divine (I, the LORD, am Deity alone. Isaiah 46:9). God the Father sent Jesus to earth for salvation of mankind (John 17:3). Ousia is essence or being, in Eastern Christianity, and is the aspect of God that is completely incomprehensible to mankind and human perception. It is all that subsists by itself and which has not its being in another, God the Father and God the Son and God the Holy Spirit all being uncreated.

According to the teaching of Arius, the preexistent Logos and thus the incarnate Jesus Christ was a begotten being; only the Son was directly begotten by God the Father, before ages, but was of a distinct, though similar, essence or substance from the Creator. His opponents argued that this would make Jesus less than God and that this was heretical. Much of the distinction between the differing factions was over the phrasing that Christ expressed in the New Testament to express submission to God the Father. The theological term for this submission is kenosis. This Ecumenical council declared that Jesus Christ was a distinct being of God in existence or reality (hypostasis), which the Latin fathers translated as persona. Jesus was God in essence, being and nature (ousia), which the Latin fathers translated as substantia.

Constantine is believed to have exiled those who refused to accept the Nicean creed—Arius himself, the deacon Euzoios, and the Libyan bishops Theonas of Marmarica and Secundus of Ptolemais—and also the bishops who signed the creed but refused to join in condemnation of Arius, Eusebius of Nicomedia and Theognis of Nicaea. The Emperor also ordered all copies of the "Thalia", the book in which Arius had expressed his teachings, to be burned. However, there is no evidence that his son and ultimate successor, Constantius II, who was a Semi-Arian Christian, was exiled.

Although he was committed to maintaining what the church had defined at Nicaea, Constantine was also bent on pacifying the situation and eventually became more lenient toward those condemned and exiled at the council. First, he allowed Eusebius of Nicomedia, who was a protégé of his sister, and Theognis to return once they had signed an ambiguous statement of faith. The two, and other friends of Arius, worked for Arius's rehabilitation.

At the First Synod of Tyre in AD 335, they brought accusations against Athanasius, now bishop of Alexandria, the primary opponent of Arius. After this, Constantine had Athanasius banished since he considered him an impediment to reconciliation. In the same year, the Synod of Jerusalem under Constantine's direction readmitted Arius to communion in AD 336. Arius died on the way to this event in Constantinople. Some scholars suggest that Arius may have been poisoned by his opponents. Eusebius and Theognis remained in the Emperor's favor, and when Constantine, who had been a catechumen much of his adult life, accepted baptism on his deathbed, it was from Eusebius of Nicomedia.

The Council of Nicaea did not end the controversy, as many bishops of the Eastern provinces disputed the "homoousios", the central term of the Nicene Creed, as it had been used by Paul of Samosata, who had advocated a monarchianist Christology. Both the man and his teaching, including the term "homoousios", had been condemned by the Synods of Antioch in 269.

Hence, after Constantine's death in 337, open dispute resumed again. Constantine's son Constantius II, who had become Emperor of the eastern part of the Empire, actually encouraged the Arians and set out to reverse the Nicene Creed. His advisor in these affairs was Eusebius of Nicomedia, who had already at the Council of Nicea been the head of the Arian party, who also was made the bishop of Constantinople.

Constantius used his power to exile bishops adhering to the Nicene Creed, especially St Athanasius of Alexandria, who fled to Rome. In 355 Constantius became the sole Emperor and extended his pro-Arian policy toward the western provinces, frequently using force to push through his creed, even exiling Pope Liberius and installing Antipope Felix II.

The third Council of Sirmium in 357 was the high point of Arianism. The Seventh Arian Confession (Second Sirmium Confession) held that both "homoousios" (of one substance) and "homoiousios" (of similar substance) were unbiblical and that the Father is greater than the Son. (This confession was later known as the Blasphemy of Sirmium.)
But since many persons are disturbed by questions concerning what is called in Latin "substantia", but in Greek "ousia", that is, to make it understood more exactly, as to 'coessential,' or what is called, 'like-in-essence,' there ought to be no mention of any of these at all, nor exposition of them in the Church, for this reason and for this consideration, that in divine Scripture nothing is written about them, and that they are above men's knowledge and above men's understanding;

As debates raged in an attempt to come up with a new formula, three camps evolved among the opponents of the Nicene Creed. The first group mainly opposed the Nicene terminology and preferred the term "homoiousios" (alike in substance) to the Nicene "homoousios", while they rejected Arius and his teaching and accepted the equality and co-eternality of the persons of the Trinity. Because of this centrist position, and despite their rejection of Arius, they were called "semi-Arians" by their opponents. The second group also avoided invoking the name of Arius, but in large part followed Arius' teachings and, in another attempted compromise wording, described the Son as being like ("homoios") the Father. A third group explicitly called upon Arius and described the Son as unlike ("anhomoios") the Father. Constantius wavered in his support between the first and the second party, while harshly persecuting the third.

Epiphanius of Salamis labeled the party of Basil of Ancyra in 358 "Semi-Arianism". This is considered unfair by Kelly who states that some members of the group were virtually orthodox from the start but disliked the adjective "homoousios" while others had moved in that direction after the out-and-out Arians had come into the open.

The debates among these groups resulted in numerous synods, among them the Council of Sardica in 343, the Council of Sirmium in 358 and the double Council of Rimini and Seleucia in 359, and no fewer than fourteen further creed formulas between 340 and 360, leading the pagan observer Ammianus Marcellinus to comment sarcastically: "The highways were covered with galloping bishops." None of these attempts were acceptable to the defenders of Nicene orthodoxy: writing about the latter councils, Saint Jerome remarked that the world "awoke with a groan to find itself Arian."

After Constantius' death in 361, his successor Julian, a devotee of Rome's pagan gods, declared that he would no longer attempt to favor one church faction over another, and allowed all exiled bishops to return; this resulted in further increasing dissension among Nicene Christians. The Emperor Valens, however, revived Constantius' policy and supported the "Homoian" party, exiling bishops and often using force. During this persecution many bishops were exiled to the other ends of the Empire (e.g., St Hilary of Poitiers to the Eastern provinces). These contacts and the common plight subsequently led to a rapprochement between the Western supporters of the Nicene Creed and the "homoousios" and the Eastern semi-Arians.

It was not until the co-reigns of Gratian and Theodosius that Arianism was effectively wiped out among the ruling class and elite of the Eastern Empire. Theodosius' wife St Flacilla was instrumental in his campaign to end Arianism. Valens died in the Battle of Adrianople in 378 and was succeeded by Theodosius I, who adhered to the Nicene Creed. This allowed for settling the dispute.

Two days after Theodosius arrived in Constantinople, 24 November 380, he expelled the Homoiousian bishop, Demophilus of Constantinople, and surrendered the churches of that city to Gregory Nazianzus, the leader of the rather small Nicene community there, an act which provoked rioting. Theodosius had just been baptized, by bishop Acholius of Thessalonica, during a severe illness, as was common in the early Christian world. In February he and Gratian had published an edict that all their subjects should profess the faith of the bishops of Rome and Alexandria (i.e., the Nicene faith), or be handed over for punishment for not doing so.

Although much of the church hierarchy in the East had opposed the Nicene Creed in the decades leading up to Theodosius' accession, he managed to achieve unity on the basis of the Nicene Creed. In 381, at the Second Ecumenical Council in Constantinople, a group of mainly Eastern bishops assembled and accepted the Nicene Creed of 381, which was supplemented in regard to the Holy Spirit, as well as some other changes: see Comparison between Creed of 325 and Creed of 381. This is generally considered the end of the dispute about the Trinity and the end of Arianism among the Roman, non-Germanic peoples.

During the time of Arianism's flowering in Constantinople, the Gothic convert and Arian bishop Ulfilas (later the subject of the letter of Auxentius cited above) was sent as a missionary to the Gothic tribes across the Danube, a mission favored for political reasons by the Emperor Constantius II. Ulfilas' translation of the Bible in Gothic language and his initial success in converting the Goths to Arianism was strengthened by later events; the conversion of Goths led to a widespread diffusion of Arianism among other Germanic tribes as well (Vandals, Longobards, Svevi and Burgundians). When the Germanic peoples entered the provinces of the Western Roman Empire and began founding their own kingdoms there, most of them were Arian Christians.
The conflict in the 4th century had seen Arian and Nicene factions struggling for control of Western Europe. In contrast, among the Arian German kingdoms established in the collapsing Western Empire in the 5th century were entirely separate Arian and Nicene Churches with parallel hierarchies, each serving different sets of believers. The Germanic elites were Arians, and the Romance majority population was Nicene.
The Arian Germanic tribes were generally tolerant towards Nicene Christians and other religious minorities, including the Jews. However, the Vandals tried for several decades to force their Arian beliefs on their North African Nicene subjects, exiling Nicene clergy, dissolving monasteries, and exercising heavy pressure on non-conforming Nicene Christians.
The apparent resurgence of Arianism after Nicaea was more an anti-Nicene reaction exploited by Arian sympathizers than a pro-Arian development. By the end of the 4th century it had surrendered its remaining ground to Trinitarianism. In Western Europe, Arianism, which had been taught by Ulfilas, the Arian missionary to the Germanic tribes, was dominant among the Goths, Longobards and Vandals. By the 8th century, it had ceased to be the tribes' mainstream belief as the tribal rulers gradually came to adopt Nicene orthodoxy. This trend began in 496 with Clovis I of the Franks, then Reccared I of the Visigoths in 587 and Aripert I of the Lombards in 653.

The Franks and the Anglo-Saxons were unlike the other Germanic peoples in that they entered the Western Roman Empire as Pagans and were forcibly converted to Chalcedonian Christianity by their kings, Clovis I and Æthelberht of Kent (see also Christianity in Gaul and Christianisation of Anglo-Saxon England). The remaining tribes – the Vandals and the Ostrogoths – did not convert as a people nor did they maintain territorial cohesion. Having been militarily defeated by the armies of Emperor Justinian I, the remnants were dispersed to the fringes of the empire and became lost to history. The Vandalic War of 533–534 dispersed the defeated Vandals. Following their final defeat at the Battle of Mons Lactarius in 553, the Ostrogoths went back north and (re)settled in south Austria.
Much of south-eastern Europe and central Europe, including many of the Goths and Vandals respectively, had embraced Arianism (the Visigoths converted to Arian Christianity in 376), which led to Arianism being a religious factor in various wars in the Roman Empire. In the west, organized Arianism survived in North Africa, in Hispania, and parts of Italy until it was finally suppressed in the 6th and 7th centuries. Visigothic Spain converted to Catholicism at the Third Council of Toledo in 589. Grimwald, King of the Lombards (662–671), and his young son and successor Garibald (671), were the last Arian kings in Europe.

Following the Protestant Reformation from 1517, it did not take long for Arian and other nontrinitarian views to resurface. The first recorded English antitrinitarian was John Assheton, who was forced to recant before Thomas Cranmer in 1548. At the Anabaptist Council of Venice 1550, the early Italian instigators of the Radical Reformation committed to the views of Miguel Servetus, who was burned alive by the orders of John Calvin in 1553, and these were promulgated by Giorgio Biandrata and others into Poland and Transylvania.

The antitrinitarian wing of the Polish Reformation separated from the Calvinist "ecclesia maior" to form the "ecclesia minor" or Polish Brethren. These were commonly referred to as "Arians" due to their rejection of the Trinity, though in fact the Socinians, as they were later known, went further than Arius to the position of Photinus. The epithet "Arian" was also applied to the early Unitarians such as John Biddle, though in denial of the pre-existence of Christ they were again largely Socinians, not Arians.

In 1683, when Anthony Ashley Cooper, 1st Earl of Shaftesbury, lay dying in Amsterdam – driven into exile by his outspoken opposition to King Charles II – he spoke to the minister Robert Ferguson, and professed himself an Arian.

In the 18th century the "dominant trend" in Britain, particularly in Latitudinarianism, was towards Arianism, with which the names of Samuel Clarke, Benjamin Hoadly, William Whiston and Isaac Newton are associated. To quote the "Encyclopædia Britannica" article on Arianism: "In modern times some Unitarians are virtually Arians in that they are unwilling either to reduce Christ to a mere human being or to attribute to him a divine nature identical with that of the Father." However, their doctrines cannot be considered representative of traditional Arian doctrines or vice versa.

A similar view was held by the ancient anti-Nicene Pneumatomachi (Greek: , "breath" or "spirit" and "fighters", combining as "fighters against the spirit"), so called because they opposed the deifying of the Nicene Holy Ghost. Although the Pneumatomachi's beliefs were somewhat reminiscent of Arianism, they were a distinct group.

The teachings of the first two ecumenical councils – which entirely reject Arianism – are held by the Catholic Church, the Eastern Orthodox Church, the Oriental Orthodox Churches, the Assyrian Church of the East and all churches founded during the Reformation in the 16th century or influenced by it (Lutheran, Reformed/Presbyterian, and Anglican). Also, nearly all Protestant groups (such as Methodists, Baptists, and most Pentecostals) entirely reject the teachings associated with Arianism. Modern groups which currently appear to embrace some of the principles of Arianism include Unitarians and Jehovah's Witnesses. Although the origins of their beliefs are not necessarily attributed to the teachings of Arius, many of the core beliefs of Unitarians and Jehovah's Witnesses are very similar to them.

The doctrine of The Church of Jesus Christ of Latter-day Saints (LDS Church) concerning the nature of the Godhead teaches a nontrinitarian theology. The church's 1st Article of Faith states: "We believe in God, the Eternal Father, and in His Son, Jesus Christ, and in the Holy Ghost." The Doctrine and Covenants 130:22 states: "The Father has a body of flesh and bones as tangible as man's; the Son also; but the Holy Ghost has not a body of flesh and bones, but is a personage of Spirit. Were it not so, the Holy Ghost could not dwell in us." Similarities between LDS doctrines and Arianism were noted as early as 1846.

The LDS church's view of the Godhead breaks with Nicene Creed tradition and believes it returns to the teachings taught by Jesus. Similarly, LDS doctrine does not accept the creed's definition of Trinity that the three are "consubstantial" nor agree with the Athanasian Creed's statement that God and Christ are "incomprehensible". In contrast, the view of the LDS Church view is that it is self-evident in the Bible that the Father, the Son, and the Holy Ghost are separate persons: three divine beings as illustrated in the of Jesus, his baptism at the hands of John, his transfiguration, and the martyrdom of Stephen.

Jehovah's Witnesses are often referred to as "modern-day Arians" or they are sometimes referred to as "Semi-Arians", usually by their opponents. While there are some significant similarities in theology and doctrine, the Witnesses differ from Arians by saying that the Son can fully know the Father (something which Arius himself denied), and by their denial of personality to the Holy Spirit. The original Arians also generally prayed directly to Jesus, whereas the Witnesses pray to God, through Jesus as a mediator.

The Church of God (7th day) - Salem Conference, a line of Sabbatarian Adventists hold views similar to Arianism:
Other groups which oppose the belief in the Trinity are not necessarily Arian.





</doc>
<doc id="1254" url="https://en.wikipedia.org/wiki?curid=1254" title="August 1">
August 1





</doc>
<doc id="1256" url="https://en.wikipedia.org/wiki?curid=1256" title="Antoninus Pius">
Antoninus Pius

Antoninus Pius (; ; 19 September 867 March 161), also known as Antoninus, was Roman emperor from 138 to 161. He was one of the Five Good Emperors in the Nerva–Antonine dynasty and the Aurelii.

Born into a senatorial family, Antoninus held various offices during the reign of emperor Hadrian, who adopted him as his son and successor shortly before his death. Antoninus acquired the cognomen Pius after his accession to the throne, either because he compelled the Senate to deify his adoptive father, or because he had saved senators sentenced to death by Hadrian in his later years. His reign is notable for the peaceful state of the Empire, with no major revolts or military incursions during this time, and for his governing without ever leaving Italy. A successful military campaign in southern Scotland early in his reign resulted in the construction of the Antonine Wall. Antoninus was an effective administrator, leaving his successors a large surplus in the treasury, expanding free access to drinking water throughout the Empire, encouraging legal conformity, and facilitating the enfranchisement of freed slaves. He died of illness in 161 and was succeeded by his adopted sons Marcus Aurelius and Lucius Verus as co-emperors.

He was born as the only child of Titus Aurelius Fulvus, consul in 86, whose family came from Nemausus (modern Nîmes). Titus Aurelius Fulvius was the son of a senator of the same name, who, as legate of Legio III Gallica, had supported Vespasian in his bid to the Imperial office and been rewarded with a suffect consulship, plus an ordinary one under Domitian in 85. The Aurelii Fulvii were therefore a relatively new senatorial family from Gallia Narbonensis whose rise to prominence was supported by the Flavians. The link between Antoninus' family and their home province explains the increasing importance of the post of Proconsul of Gallia Narbonensis during the late Second Century.

Antoninus was born near Lanuvium and his mother was Arria Fadilla. Antoninus’ father died shortly after his 89 ordinary consulship, and Antoninus was raised by his maternal grandfather Gnaeus Arrius Antoninus, reputed by contemporaries to be a man of integrity and culture and a friend of Pliny the Younger. The Arrii Antonini were an older senatorial family from Italy, very influential during Nerva's reign. Arria Fadilla, Antoninus' mother, married afterwards Publius Julius Lupus, suffect consul in 98; from that marriage came two daughters, Arria Lupula and Julia Fadilla.

Some time between 110 and 115, Antoninus married Annia Galeria Faustina the Elder. They are believed to have enjoyed a happy marriage. Faustina was the daughter of consul Marcus Annius Verus and Rupilia Faustina (a half-sister to the Empress Vibia Sabina). Faustina was a beautiful woman, and despite (basically unproven) rumours about her character, it is clear that Antoninus cared for her deeply.

Faustina bore Antoninus four children, two sons and two daughters. They were:

When Faustina died in 141, Antoninus was greatly distressed. In honour of her memory, he asked the Senate to deify her as a goddess, and authorised the construction of a temple to be built in the Roman Forum in her name, with priestesses serving in her temple. He had various coins with her portrait struck in her honor. These coins were scripted ‘"DIVA FAUSTINA"’ and were elaborately decorated. He further created a charity which he founded and called it "Puellae Faustinianae" or "Girls of Faustina", which assisted destitute girls of good family. Finally, Antoninus created a new "alimenta" (see Grain supply to the city of Rome).

The emperor never remarried. Instead, he lived with Galena Lysistrata, one of Faustina's freed women. Concubinage was a form of female companionship sometimes chosen by powerful men in Ancient Rome, especially widowers like Vespasian, and Marcus Aurelius. Their union could not produce any legitimate offspring who could threaten any heirs, such as those of Antoninus. Also, as one could not have a wife and an official concubine (or two concubines) at the same time, Antoninus avoided being pressed into a marriage with a noblewoman from another family (later, Marcus Aurelius would also reject the advances of his former fiancée Ceionia Fabia, Lucius Verus's sister, on the grounds of protecting his children from a stepmother, and took a concubine instead).

Having filled the offices of quaestor and praetor with more than usual success, he obtained the consulship in 120. He was next appointed by the Emperor Hadrian as one of the four proconsuls to administer Italia, then greatly increased his reputation by his conduct as proconsul of Asia, probably during 134–135.

He acquired much favor with Hadrian, who adopted him as his son and successor on 25 February 138, after the death of his first adopted son Lucius Aelius, on the condition that Antoninus would in turn adopt Marcus Annius Verus, the son of his wife's brother, and Lucius, son of Lucius Aelius, who afterwards became the emperors Marcus Aurelius and Lucius Verus.

On his accession, Antoninus' name and style became "Imperator Caesar Titus Aelius Hadrianus Antoninus Augustus Pontifex Maximus". One of his first acts as Emperor was to persuade the Senate to grant divine honours to Hadrian, which they had at first refused; his efforts to persuade the Senate to grant these honours is the most likely reason given for his title of "Pius" (dutiful in affection; compare "pietas"). Two other reasons for this title are that he would support his aged father-in-law with his hand at Senate meetings, and that he had saved those men that Hadrian, during his period of ill-health, had condemned to death.

Immediately after Hadrian's death, Antoninus approached Marcus and requested that his marriage arrangements be amended: Marcus' betrothal to Ceionia Fabia would be annulled, and he would be betrothed to Faustina, Antoninus' daughter, instead. Faustina's betrothal to Ceionia's brother Lucius Commodus would also have to be annulled. Marcus consented to Antoninus' proposal.

Antoninus built temples, theaters, and mausoleums, promoted the arts and sciences, and bestowed honours and financial rewards upon the teachers of rhetoric and philosophy. Antoninus made few initial changes when he became emperor, leaving intact as far as possible the arrangements instituted by Hadrian. Epigraphical and prosopographical research has revealed that Antoninus' imperial ruling team centered around a group of closely knit senatorial families, most of them members of the priestly congregation for the cult of Hadrian, the "sodales Hadrianales". According to the German historian H.G. Pflaum, prosopographical research of Antoninus' ruling team allows us to grasp the deeply conservative character of the ruling senatorial caste.

There are no records of any military related acts in his time in which he participated. One modern scholar has written "It is almost certain not only that at no time in his life did he ever see, let alone command, a Roman army, but that, throughout the twenty-three years of his reign, he never went within five hundred miles of a legion".

His reign was the most peaceful in the entire history of the Principate, notwithstanding the fact that there were several military disturbances throughout the Empire in his time. Such disturbances happened in Mauretania – where a senator was named as governor of Mauretania Tingitana in place of the usual equestrian procurator and cavalry reinforcements from Pannonia were brought in, towns such as Sala and Tipasa being fortified. Similar disturbances took place in Judea, and amongst the Brigantes in Britannia, none of them being considered serious. It was however in Britain that Antoninus decided to follow a new, more aggressive path, with the appointment of a new governor in 139, Quintus Lollius Urbicus, a native of Numidia and previously governor of Germania Inferior.

Under instructions from the emperor, Lollius undertook an invasion of southern Scotland, winning some significant victories, and constructing the Antonine Wall from the Firth of Forth to the Firth of Clyde. The wall, however, was soon gradually decommissioned during the mid-150s and eventually abandoned late during the reign (early 160s), for reasons that are still not quite clear. Antonine's Wall is mentioned in just one literary source, Antoninus' biography in the Historia Augusta. Pausanias makes a brief and confused mention of a war in Britain. In one inscription honoring Antoninus, erected by Legio II Augusta, which participated in the building of the Wall, a relief showing four naked prisoners, one of them beheaded, seems to stand for some actual warfare.
Although Antonine's Wall was, in principle, much shorter and at first sight more defensible than Hadrian's Wall, the additional area that it enclosed within the Empire was barren, with the effect that supply lines to it were strained enough that the costs from maintaining the additional territory outweighed the benefits of doing so. It has been therefore speculated that the invasion of Lowland Scotland and the building of the wall had to do mostly with internal politics, that is, offering Antoninus an opportunity to gain some modicum of necessary military prestige at the start of his reign. Actually, the campaign in Britannia was followed by an Imperial salutation – that is, by Antoninus formally taking for the second (and last) time the title of Imperator – in 142. The fact that around the same time coins were struck announcing a victory in Britain points to Antoninus' need to publicize his achievements. The orator Fronto was later to say that, although Antoninus bestowed the direction of the British campaign to others, he should be regarded as the helmsman who directed the voyage, whose glory, therefore, belonged to him.

That this quest for some military achievement responded to an actual need is proved by the fact that, although generally peaceful, Antoninus' reign was not free from attempts at usurpation: Historia Augusta mentions two, made by the senators Cornelius Priscianus (by the way, Lollius Urbicus' successor as governor of Britain) and Atilius Rufius Titianus – both confirmed by the Fasti Ostienses as well as by the erasing of Priscianus' name from an inscription. In both cases, Antoninus was not in formal charge of the ensuing repression: Priscianus committed suicide and Titianus was found guilty by the Senate, with Antoninus abstaining from sequestering their families' properties.

There were also some troubles in Dacia Inferior which required the granting of additional powers to the procurator governor and the dispatch of additional soldiers to the province. On the Northern Black Sea coast, the Greek city of Olbia was held against the Scythians. Also during his reign the governor of Upper Germany, probably Caius Popillius Carus Pedo, built new fortifications in the Agri Decumates, advancing the Limes Germanicus fifteen miles forward in his province and neighboring Raetia. In the East, Roman suzerainty over Armenia was retained by the choice in AD 140 of Arsacid scion Sohaemus as client king.

Nevertheless, Antoninus was virtually unique among emperors in that he dealt with these crises without leaving Italy once during his reign, but instead dealt with provincial matters of war and peace through their governors or through imperial letters to the cities such as Ephesus (of which some were publicly displayed). This style of government was highly praised by his contemporaries and by later generations.

Antoninus was the last Roman Emperor recognised by the Indian Kingdoms. Raoul McLaughlin quotes Aurelius Victor as saying "The Indians, the Bactrians and the Hyrcanians all sent ambassadors to Antoninus. They had all heard about the spirit of justice held by this great emperor, justice that was heightened by his handsome and grave countenance, and his slim and vigorous figure." Due to the outbreak of the Antonine epidemic and wars against northern Germanic tribes, the reign of Marcus Aurelius was forced to alter the focus of foreign policies, and matters relating to the Far East were increasingly abandoned in favour of those directly concerning the Empire's survival.

Antoninus was regarded as a skilled administrator and as a builder. In spite of an extensive building directive – the free access of the people of Rome to drinking water was expanded with the construction of aqueducts, not only in Rome but throughout the Empire, as well as bridges and roads – the emperor still managed to leave behind a sizable public treasury of around two and a half million sesterces (Rome would not witness another Emperor leaving his successor with a surplus for a long time). But this treasury was depleted almost immediately after Antoninus's reign due to the plague brought back by soldiers after the Parthian victory.

The Emperor also famously suspended the collection of taxes from cities affected by natural disasters, such as when fires struck Rome and Narbona, and earthquakes affected Rhodes and the Province of Asia. He offered hefty financial grants for rebuilding and recovery of various Greek cities after two serious earthquakes: the first, "circa" 140, which affected mostly Rhodes and other islands; the second, in 152, which hit Cyzicus (where the huge and newly built Temple to Hadrian was destroyed), Ephesus, and Smyrna. Antoninus' financial help earned him praise by Greek writers such as Aelius Aristides and Pausanias. These cities received from Antoninus the usual honorific accolades, such as when he commanded that all governors of Asia should enter the province, when taking office, by way of Ephesus. Ephesus was specially favoured by Antoninus, who confirmed and upheld its first place in the list of imperial honor titles, as opposed to Smyrna and Pergamon.

In his dealings with Greek-speaking cities, Antoninus followed the policy adopted by Hadrian of ingratiating himself with local elites, especially with local intellectuals: philosophers, teachers of literature, rhetoricians and physicians were explicitly exempted from any duties involving private spending for civic purposes – a privilege granted by Hadrian that Antoninus confirmed by means of an edict preserved in the Digest (27.1.6.8). Antoninus also created a chair for the teaching of rhetoric in Athens.

Antoninus was known as an avid observer of rites of religion and of formal celebrations – both Roman and foreign. He is known for having increasingly formalized the official cult offered to the Great Mother, which from his reign onwards included a bull sacrifice, a taurobolium, formerly only a private ritual, now being also performed for the sake of the Emperor's welfare. Antoninus also offered patronage to the worship of Mithras, to whom he erected a temple in Ostia. In 148, he presided over the celebrations of the 900th anniversary of the founding of Rome.

Antoninus tried to portray himself as a magistrate of the "res publica", no matter how extended and ill-defined his competencies were. He is credited with the splitting of the imperial treasury, the Fiscus. This splitting had to do with the division of imperial properties into two parts: firstly, the fiscus itself – or "patrimonium", meaning the properties of the "Crown", the hereditary properties of each succeeding person that sat on the throne, transmitted to his successors in office, regardless of their membership in the imperial family; secondly, the "res privata", the "private" properties tied to the personal maintenance of the Emperor and his family. An anecdote in the Historia Augusta biography, where Antoninus replies to Faustina – who complained about his stinginess – that "we have gained an empire [and] lost even what we had before" possibly relates to Antoninus' actual concerns at the creation of the "res privata". While still a private citizen, Antoninus had increased his personal fortune greatly by mean of various legacies, the consequence – we are told – of his caring scrupulously for his relatives.

The "res privata" lands could be sold and/or given away, while the "patrimonium" properties were regarded as public. It was a way of pretending that the Imperial function – and most properties attached to it – was a public one, formally subject to the authority of the Senate and the Roman people. That the distinction played no part in subsequent political history – that the "personal" power of the princeps absorbed his role as office-holder – proves that the autocratic logic of the imperial order had already subsumed the old republican institutions.

Of the public transactions of this period there is only the scantiest of information, but, to judge by what is extant, those twenty-two years were not remarkably eventful in comparison to those before and after the reign. However, Antoninus did take a great interest in the revision and practice of the law throughout the empire. One of his chief concerns was to having local communities conform their legal procedures to existing Roman norms: in a case concerning repression of banditry by local police officers ("irenarchs") in Asia Minor, Antoninus ordered that these officers should not treat suspects as already condemned, and also keep a detailed copy of their interrogations, to be used in the possibility of an appeal to the Roman governor. Also, although Antoninus was not an innovator, he would not always follow the absolute letter of the law; rather he was driven by concerns over humanity and equality, and introduced into Roman law many important new principles based upon this notion.

In this, the emperor was assisted by five chief lawyers: L. Fulvius Aburnius Valens, an author of legal treatises; L. Ulpius Marcellus, a prolific writer; and three others. These last three included L. Volusius Maecianus, a former military officer turned by Antoninus into a civil procurator, and who, in view of his subsequent career (discovered on the basis of epigraphical and prosopographical research), was the Emperor's most important legal adviser. Maecianus would eventually be chosen to occupy various prefectures (see below) as well as to conduct the legal studies of Marcus Aurelius. He was also the author of a large work on Fidei Commissa (Testamentary Trusts). As a hallmark of the increased connection between jurists and the imperial government, Antoninus' reign also saw the appearance of the "Institutes of Gaius", an elementary legal manual for beginners (see Gaius (jurist)).

Antoninus passed measures to facilitate the enfranchisement of slaves. Mostly, he favoured the principle of "favor libertatis", giving the putative freedman the benefit of the doubt when the claim to freedom was not clearcut. Also, he punished the killing of a slave by his/her master without previous trial and determined that slaves could be forcibly sold to another master by a proconsul in cases of consistent mistreatment. Antoninus upheld the enforcement of contracts for selling of female slaves forbidding their further employment in prostitution. In criminal law, Antoninus introduced the important principle that accused persons are not to be treated as guilty before trial – as in the case of the irenarchs (see above). It was to Antonius that the Christian apologist Justin Martyr addressed his defense of the Christian faith, reminding him of his father's (Emperor Hadrian's) rule that accusations against Christians required proof. He also asserted the principle that the trial was to be held, and the punishment inflicted, in the place where the crime had been committed. He mitigated the use of torture in examining slaves by certain limitations. Thus he prohibited the application of torture to children under fourteen years, though this rule had exceptions. However, it must be stressed that Antoninus "extended", by means of a rescript, the use of torture as a means of obtaining evidence to pecuniary cases, when it had been applied up until then only in criminal cases. Also, already at the time torture of free men of low status ("humiliores") had become legal, as proved by the fact that Antoninus exempted town councillors expressly from it, and also free men of high rank ("honestiores") in general.

One highlight during his reign occurred in 148, with the nine-hundredth anniversary of the foundation of Rome being celebrated by the hosting of magnificent games in Rome. It lasted a number of days, and a host of exotic animals were killed, including elephants, giraffes, tigers, rhinoceroses, crocodiles and hippopotami. While this increased Antoninus's popularity, the frugal emperor had to debase the Roman currency. He decreased the silver purity of the denarius from 89% to 83.5% – the actual silver weight dropping from 2.88 grams to 2.68 grams.

Scholars name Antoninus Pius as the leading candidate for an individual identified as a friend of Rabbi Judah the Prince. According to the Talmud (Avodah Zarah 10a–b), Rabbi Judah was very wealthy and greatly revered in Rome. He had a close friendship with "Antoninus", possibly Antoninus Pius, who would consult Rabbi Judah on various worldly and spiritual matters.

In 156, Antoninus Pius turned 70. He found it difficult to keep himself upright without stays. He started nibbling on dry bread to give him the strength to stay awake through his morning receptions. Marcus Aurelius had already been created consul with Antoninus in 140, receiving the title of Caesar – i.e., heir apparent. As Antoninus aged, Marcus would take on more administrative duties, more still after the deathin 156 or 157of one of Antoninus' most trusted advisers, Gavius Maximus, who had been praetorian prefect (an office that was as much secretarial as military) for twenty years. Gavius Maximus, who had been one of the most important members of Antoninus' "team" of long standing advisers, had been awarded with the consular insignia and the honors due a senator. He had developed a reputation as a most strict disciplinarian ("vir severissimus", according to "Historia Augusta") as well as some lasting grudges among fellow equestrian procurators – one of them, by predeceasing Gavius and vilifying him in his will, created a serious embarrassment to one of the heirs, the orator Fronto. Gavius Maximus' death offered the opportunity to a welcome change in the ruling team, and it has been speculated that it was the legal adviser Volusius Maecianus who—after a brief spell as Praefect of Egypt, and a subsequent term as Praefectus annonae in Rome – assumed the role of grey eminence precisely in order to prepare the incoming – and altogether new – joint succession. In 160, Marcus and Lucius were designated joint consuls for the following year. Perhaps Antoninus was already ill; in any case, he died before the year was out.
Two days before his death, the biographer reports, Antoninus was at his ancestral estate at Lorium, in Etruria, about twelve miles (19 km) from Rome. He ate Alpine Gruyere cheese at dinner quite greedily. In the night he vomited; he had a fever the next day. The day after that, 7 March 161, he summoned the imperial council, and passed the state and his daughter to Marcus. The emperor gave the keynote to his life in the last word that he uttered: when the tribune of the night-watch came to ask the password, he responded, "aequanimitas" (equanimity). He then turned over, as if going to sleep, and died. His death closed out the longest reign since Augustus (surpassing Tiberius by a couple of months). His record for the second-longest reign would be unbeaten for 168 years, until 329 when it was surpassed by Constantine the Great.

Antoninus Pius' funeral ceremonies were, in the words of the biographer, "elaborate". If his funeral followed the pattern of past funerals, his body would have been incinerated on a pyre at the Campus Martius, while his spirit would rise to the gods' home in the heavens. However, it seems that this was not the case: according to his Historia Augusta biography (which seems to reproduce an earlier, detailed report) Antoninus' body (and not his ashes) was buried in Hadrian's mausoleum. After a seven-day interval ("justitium"), Marcus and Lucius nominated their father for deification. In contrast to their behavior during Antoninus' campaign to deify Hadrian, the senate did not oppose the emperors' wishes. A "flamen", or cultic priest, was appointed to minister the cult of the deified Antoninus, now "Divus Antoninus".

A column was dedicated to Antoninus on the Campus Martius, and the temple he had built in the Forum in 141 to his deified wife Faustina was rededicated to the deified Faustina and the deified Antoninus. It survives as the church of San Lorenzo in Miranda.

The first group of people claiming to be an ambassadorial mission of Romans to China was recorded in 166 AD by the "Hou Hanshu". The embassy came to Emperor Huan of Han China from "Andun" (; Emperor Antoninus Pius), "king of Daqin" (Rome). As Antoninus Pius died in 161, leaving the empire to his adoptive son Marcus Aurelius (Antoninus), and the envoy arrived in 166, confusion remains about who sent the mission given that both Emperors were named 'Antoninus'. The Roman mission came from the south (therefore probably by sea), entering China by the frontier province of Jiaozhi at Rinan or Tonkin (present-day northern Vietnam). It brought presents of rhinoceros horns, ivory, and tortoise shell, probably acquired in Southern Asia. The text specifically states that it was the first time there had been direct contact between the two countries.

Furthermore, a piece of Republican-era Roman glassware has been found at a Western Han tomb in Guangzhou along the South China Sea, dated to the early 1st century BC. Roman golden medallions made during the reign of Antoninus Pius and perhaps even Marcus Aurelius have been found at Óc Eo in southern Vietnam, then part of the Kingdom of Funan near the Chinese province of Jiaozhi. This may have been the port city of Kattigara, described by Ptolemy (c. 150) as being visited by a Greek sailor named Alexander and lying beyond the Golden Chersonese (i.e., Malay Peninsula). Roman coins from the reigns of Tiberius to Aurelian have been discovered in Xi'an, China (site of the Han capital Chang'an), although the significantly greater amount of Roman coins unearthed in India suggest the Roman maritime trade for purchasing Chinese silk was centered there, not in China or even the overland Silk Road running through ancient Iran.

The only intact account of his life handed down to us is that of the "Augustan History", an unreliable and mostly fabricated work. Nevertheless, it still contains information that is considered reasonably sound – for instance, it is the only source that mentions the erection of the Antonine Wall in Britain. Antoninus is unique among Roman emperors in that he has no other biographies.

Antoninus in many ways was the ideal of the landed gentleman praised not only by ancient Romans, but also by later scholars of classical history, such as Edward Gibbon or the author of the article on Antoninus Pius in the "Encyclopædia Britannica" Eleventh Edition.
Some historians have a less positive view of his reign. According to the historian J. B. Bury, 

German historian Ernst Kornemann has had it in his "Römische Geschichte" [2 vols., ed. by H. Bengtson, Stuttgart 1954] that the reign of Antoninus comprised "a succession of grossly wasted opportunities", given the upheavals that were to come. There is more to this argument, given that the Parthians in the East were themselves soon to make no small amount of mischief after Antoninus' passing. Kornemann's brief is that Antoninus might have waged preventive wars to head off these outsiders. Michael Grant agrees that it is possible that had Antoninus acted decisively sooner (it appears that, on his death bed, he was preparing a large-scale action against the Parthians), the Parthians might have been unable to choose their own time, but current evidence is not conclusive. Grant opines that Antoninus and his officers did act in a resolute manner dealing with frontier disturbances of his time, although conditions for long-lasting peace were not created. On the whole, according to Grant, Marcus Aurelius' eulogistic picture of Antoninus seems deserved, and Antoninus appears to have been a conservative and nationalistic (although he respected and followed Hadrian's example of Philhellenism moderately) Emperor who was not tainted by the blood of either citizen or foe, combined and maintained Numa Pompilius' good fortune, pacific dutifulness and religious scrupulousness, and whose laws removed anomalies and softened harshnesses.

Krzysztof Ulanowski argues that the claims of military inability are exaggerated, considering that although the sources praise Antoninus' love for peace and his efforts "rather to defend, than enlarge the provinces", he could hardly be considered a pacifist, as shown by the conquest of the Lowlands, the building of the Antonine Wall and the expansion of Germania Superior. Ulianowski also praises Antoninus for being successful in deterrence by diplomatic means.

Although only one of his four children survived to adulthood, Antoninus came to be ancestor to four generations of prominent Romans, including the Emperor Commodus. Hans-Georg Pflaum has identified five direct descendants of Antoninus and Faustina who were consuls in the first half of the third century.




</doc>
<doc id="1259" url="https://en.wikipedia.org/wiki?curid=1259" title="August 3">
August 3





</doc>
<doc id="1260" url="https://en.wikipedia.org/wiki?curid=1260" title="Advanced Encryption Standard">
Advanced Encryption Standard

The Advanced Encryption Standard (AES), also known by its original name Rijndael (), is a specification for the encryption of electronic data established by the U.S. National Institute of Standards and Technology (NIST) in 2001.

AES is a subset of the Rijndael block cipher developed by two Belgian cryptographers, Vincent Rijmen and Joan Daemen, who submitted a proposal to NIST during the AES selection process. Rijndael is a family of ciphers with different key and block sizes.

For AES, NIST selected three members of the Rijndael family, each with a block size of 128 bits, but three different key lengths: 128, 192 and 256 bits.

AES has been adopted by the U.S. government and is now used worldwide. It supersedes the Data Encryption Standard (DES), which was published in 1977. The algorithm described by AES is a symmetric-key algorithm, meaning the same key is used for both encrypting and decrypting the data.

In the United States, AES was announced by the NIST as U.S. FIPS PUB 197 (FIPS 197) on November 26, 2001. This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable (see Advanced Encryption Standard process for more details).

AES became effective as a federal government standard on May 26, 2002, after approval by the Secretary of Commerce. AES is included in the ISO/IEC 18033-3 standard. AES is available in many different encryption packages, and is the first (and only) publicly accessible cipher approved by the National Security Agency (NSA) for top secret information when used in an NSA approved cryptographic module (see Security of AES, below).

The Advanced Encryption Standard (AES) is defined in each of:


AES is based on a design principle known as a substitution–permutation network, and is efficient in both software and hardware. Unlike its predecessor DES, AES does not use a Feistel network. AES is a variant of Rijndael which has a fixed block size of 128 bits, and a key size of 128, 192, or 256 bits. By contrast, Rijndael "per se" is specified with block and key sizes that may be any multiple of 32 bits, with a minimum of 128 and a maximum of 256 bits.

AES operates on a 4 × 4 column-major order array of bytes, termed the "state". Most AES calculations are done in a particular finite field.

For instance, if there are 16 bytes, formula_1, these bytes are represented as this two-dimensional array:

The key size used for an AES cipher specifies the number of transformation rounds that convert the input, called the plaintext, into the final output, called the ciphertext. The number of rounds are as follows:


Each round consists of several processing steps, including one that depends on the encryption key itself. A set of reverse rounds are applied to transform ciphertext back into the original plaintext using the same encryption key.


In the step, each byte formula_3 in the "state" array is replaced with a formula_4 using an 8-bit substitution box. This operation provides the non-linearity in the cipher. The S-box used is derived from the multiplicative inverse over , known to have good non-linearity properties. To avoid attacks based on simple algebraic properties, the S-box is constructed by combining the inverse function with an invertible affine transformation. The S-box is also chosen to avoid any fixed points (and so is a derangement), i.e., formula_5, and also any opposite fixed points, i.e., formula_6.
While performing the decryption, the step (the inverse of ) is used, which requires first taking the inverse of the affine transformation and then finding the multiplicative inverse.

The step operates on the rows of the state; it cyclically shifts the bytes in each row by a certain offset. For AES, the first row is left unchanged. Each byte of the second row is shifted one to the left. Similarly, the third and fourth rows are shifted by offsets of two and three respectively. In this way, each column of the output state of the step is composed of bytes from each column of the input state. The importance of this step is to avoid the columns being encrypted independently, in which case AES degenerates into four independent block ciphers.

In the step, the four bytes of each column of the state are combined using an invertible linear transformation. The function takes four bytes as input and outputs four bytes, where each input byte affects all four output bytes. Together with , provides diffusion in the cipher.

During this operation, each column is transformed using a fixed matrix (matrix left-multiplied by column gives new value of column in the state):

Matrix multiplication is composed of multiplication and addition of the entries. Entries are 8-bit bytes treated as coefficients of polynomial of order formula_8. Addition is simply XOR. Multiplication is modulo irreducible polynomial formula_9. If processed bit by bit, then, after shifting, a conditional XOR with 1B should be performed if the shifted value is larger than FF (overflow must be corrected by subtraction of generating polynomial). These are special cases of the usual multiplication in formula_10.

In more general sense, each column is treated as a polynomial over formula_10 and is then multiplied modulo formula_12 with a fixed polynomial formula_13. The coefficients are displayed in their hexadecimal equivalent of the binary representation of bit polynomials from formula_14. The step can also be viewed as a multiplication by the shown particular MDS matrix in the finite field formula_10. This process is described further in the article Rijndael MixColumns.

In the step, the subkey is combined with the state. For each round, a subkey is derived from the main key using Rijndael's key schedule; each subkey is the same size as the state. The subkey is added by combining each byte of the state with the corresponding byte of the subkey using bitwise XOR.

On systems with 32-bit or larger words, it is possible to speed up execution of this cipher by combining the and steps with the step by transforming them into a sequence of table lookups. This requires four 256-entry 32-bit tables (together occupying 4096 bytes). A round can then be performed with 16 table lookup operations and 12 32-bit exclusive-or operations, followed by four 32-bit exclusive-or operations in the step. Alternatively, the table lookup operation can be performed with a single 256-entry 32-bit table (occupying 1024 bytes) followed by circular rotation operations.

Using a byte-oriented approach, it is possible to combine the , , and steps into a single round operation.

Until May 2009, the only successful published attacks against the full AES were side-channel attacks on some specific implementations. The National Security Agency (NSA) reviewed all the AES finalists, including Rijndael, and stated that all of them were secure enough for U.S. Government non-classified data. In June 2003, the U.S. Government announced that AES could be used to protect classified information:
The design and strength of all key lengths of the AES algorithm (i.e., 128, 192 and 256) are sufficient to protect classified information up to the SECRET level. TOP SECRET information will require use of either the 192 or 256 key lengths. The implementation of AES in products intended to protect national security systems and/or information must be reviewed and certified by NSA prior to their acquisition and use.

AES has 10 rounds for 128-bit keys, 12 rounds for 192-bit keys, and 14 rounds for 256-bit keys.

By 2006, the best known attacks were on 7 rounds for 128-bit keys, 8 rounds for 192-bit keys, and 9 rounds for 256-bit keys.

For cryptographers, a cryptographic "break" is anything faster than a brute-force attack – i.e., performing one trial decryption for each possible key in sequence (see Cryptanalysis). A break can thus include results that are infeasible with current technology. Despite being impractical, theoretical breaks can sometimes provide insight into vulnerability patterns. The largest successful publicly known brute-force attack against a widely implemented block-cipher encryption algorithm was against a 64-bit RC5 key by distributed.net in 2006.

The key space increases by a factor of 2 for each additional bit of key length, and if every possible value of the key is equiprobable, this translates into a doubling of the average brute-force key search time. This implies that the effort of a brute-force search increases exponentially with key length. Key length in itself does not imply security against attacks, since there are ciphers with very long keys that have been found to be vulnerable.

AES has a fairly simple algebraic framework. In 2002, a theoretical attack, named the "XSL attack", was announced by Nicolas Courtois and Josef Pieprzyk, purporting to show a weakness in the AES algorithm, partially due to the low complexity of its nonlinear components. Since then, other papers have shown that the attack, as originally presented, is unworkable; see XSL attack on block ciphers.

During the AES selection process, developers of competing algorithms wrote of Rijndael's algorithm "...we are concerned about [its] use ... in security-critical applications." In October 2000, however, at the end of the AES selection process, Bruce Schneier, a developer of the competing algorithm Twofish, wrote that while he thought successful academic attacks on Rijndael would be developed someday, he did not "believe that anyone will ever discover an attack that will allow someone to read Rijndael traffic".

In 2009, a new related-key attack was discovered that exploits the simplicity of AES's key schedule and has a complexity of 2. In December 2009 it was improved to 2. This is a follow-up to an attack discovered earlier in 2009 by Alex Biryukov, Dmitry Khovratovich, and Ivica Nikolić, with a complexity of 2 for one out of every 2 keys. However, related-key attacks are not of concern in any properly designed cryptographic protocol, as a properly designed protocol (i.e., implementational software) will take care not to allow related keys, essentially by constraining an attacker's means of selecting keys for relatedness.

Another attack was blogged by Bruce Schneier
on July 30, 2009, and released as a preprint
on August 3, 2009. This new attack, by Alex Biryukov, Orr Dunkelman, Nathan Keller, Dmitry Khovratovich, and Adi Shamir, is against AES-256 that uses only two related keys and 2 time to recover the complete 256-bit key of a 9-round version, or 2 time for a 10-round version with a stronger type of related subkey attack, or 2 time for an 11-round version. 256-bit AES uses 14 rounds, so these attacks aren't effective against full AES.

The practicality of these attacks with stronger related keys has been criticized, for instance, by the paper on "chosen-key-relations-in-the-middle" attacks on AES-128 authored by Vincent Rijmen in 2010.

In November 2009, the first known-key distinguishing attack against a reduced 8-round version of AES-128 was released as a preprint.
This known-key distinguishing attack is an improvement of the rebound, or the start-from-the-middle attack, against AES-like permutations, which view two consecutive rounds of permutation as the application of a so-called Super-Sbox. It works on the 8-round version of AES-128, with a time complexity of 2, and a memory complexity of 2. 128-bit AES uses 10 rounds, so this attack isn't effective against full AES-128.

The first key-recovery attacks on full AES were due to Andrey Bogdanov, Dmitry Khovratovich, and Christian Rechberger, and were published in 2011. The attack is a biclique attack and is faster than brute force by a factor of about four. It requires 2 operations to recover an AES-128 key. For AES-192 and AES-256, 2 and 2 operations are needed, respectively. This result has been further improved to 2 for AES-128, 2 for AES-192 and 2 for AES-256, which are the current best results in key recovery attack against AES.

This is a very small gain, as a 126-bit key (instead of 128-bits) would still take billions of years to brute force on current and foreseeable hardware. Also, the authors calculate the best attack using their technique on AES with a 128 bit key requires storing 2 bits of data. That works out to about 38 trillion terabytes of data, which is more than all the data stored on all the computers on the planet in 2016. As such, there are no practical implications on AES security. The space complexity has later been improved to 2 bits, which is 9007 terabytes.

According to the Snowden documents, the NSA is doing research on whether a cryptographic attack based on tau statistic may help to break AES.

At present, there is no known practical attack that would allow someone without knowledge of the key to read data encrypted by AES when correctly implemented.

Side-channel attacks do not attack the cipher as a black box, and thus are not related to cipher security as defined in the classical context, but are important in practice. They attack implementations of the cipher on hardware or software systems that inadvertently leak data. There are several such known attacks on various implementations of AES.

In April 2005, D.J. Bernstein announced a cache-timing attack that he used to break a custom server that used OpenSSL's AES encryption. The attack required over 200 million chosen plaintexts. The custom server was designed to give out as much timing information as possible (the server reports back the number of machine cycles taken by the encryption operation); however, as Bernstein pointed out, "reducing the precision of the server's timestamps, or eliminating them from the server's responses, does not stop the attack: the client simply uses round-trip timings based on its local clock, and compensates for the increased noise by averaging over a larger number of samples."

In October 2005, Dag Arne Osvik, Adi Shamir and Eran Tromer presented a paper demonstrating several cache-timing attacks against the implementations in AES found in OpenSSL and Linux's codice_1 partition encryption function. One attack was able to obtain an entire AES key after only 800 operations triggering encryptions, in a total of 65 milliseconds. This attack requires the attacker to be able to run programs on the same system or platform that is performing AES.

In December 2009 an attack on some hardware implementations was published that used differential fault analysis and allows recovery of a key with a complexity of 2.

In November 2010 Endre Bangerter, David Gullasch and Stephan Krenn published a paper which described a practical approach to a "near real time" recovery of secret keys from AES-128 without the need for either cipher text or plaintext. The approach also works on AES-128 implementations that use compression tables, such as OpenSSL. Like some earlier attacks this one requires the ability to run unprivileged code on the system performing the AES encryption, which may be achieved by malware infection far more easily than commandeering the root account.

In March 2016, Ashokkumar C., Ravi Prakash Giri and Bernard Menezes presented a very efficient side-channel attack on AES implementations that can recover the complete 128-bit AES key in just 6–7 blocks of plaintext/ciphertext which is a substantial improvement over previous works that require between 100 and a million encryptions. The proposed attack requires standard user privilege as previous attacks and key-retrieval algorithms run under a minute.

Many modern CPUs have built-in hardware instructions for AES, which would protect against timing-related side-channel attacks.

The Cryptographic Module Validation Program (CMVP) is operated jointly by the United States Government's National Institute of Standards and Technology (NIST) Computer Security Division and the Communications Security Establishment (CSE) of the Government of Canada. The use of cryptographic modules validated to NIST FIPS 140-2 is required by the United States Government for encryption of all data that has a classification of Sensitive but Unclassified (SBU) or above. From NSTISSP #11, National Policy Governing the Acquisition of Information Assurance: "Encryption products for protecting classified information will be certified by NSA, and encryption products intended for protecting sensitive information will be certified in accordance with NIST FIPS 140-2."

The Government of Canada also recommends the use of FIPS 140 validated cryptographic modules in unclassified applications of its departments.

Although NIST publication 197 ("FIPS 197") is the unique document that covers the AES algorithm, vendors typically approach the CMVP under FIPS 140 and ask to have several algorithms (such as Triple DES or SHA1) validated at the same time. Therefore, it is rare to find cryptographic modules that are uniquely FIPS 197 validated and NIST itself does not generally take the time to list FIPS 197 validated modules separately on its public web site. Instead, FIPS 197 validation is typically just listed as an "FIPS approved: AES" notation (with a specific FIPS 197 certificate number) in the current list of FIPS 140 validated cryptographic modules.

The Cryptographic Algorithm Validation Program (CAVP) allows for independent validation of the correct implementation of the AES algorithm at a reasonable cost. Successful validation results in being listed on the NIST validations page. This testing is a pre-requisite for the FIPS 140-2 module validation described below. However, successful CAVP validation in no way implies that the cryptographic module implementing the algorithm is secure. A cryptographic module lacking FIPS 140-2 validation or specific approval by the NSA is not deemed secure by the US Government and cannot be used to protect government data.

FIPS 140-2 validation is challenging to achieve both technically and fiscally. There is a standardized battery of tests as well as an element of source code review that must be passed over a period of a few weeks. The cost to perform these tests through an approved laboratory can be significant (e.g., well over $30,000 US) and does not include the time it takes to write, test, document and prepare a module for validation. After validation, modules must be re-submitted and re-evaluated if they are changed in any way. This can vary from simple paperwork updates if the security functionality did not change to a more substantial set of re-testing if the security functionality was impacted by the change.

Test vectors are a set of known ciphers for a given input and key. NIST distributes the reference of AES test vectors as AES Known Answer Test (KAT) Vectors.

High speed and low RAM requirements were criteria of the AES selection process. As the chosen algorithm, AES performed well on a wide variety of hardware, from 8-bit smart cards to high-performance computers.

On a Pentium Pro, AES encryption requires 18 clock cycles per byte, equivalent to a throughput of about 11 Mbit/s for a 200 MHz processor. On a 1.7 GHz Pentium M throughput is about 60 Mbit/s.

On Intel Core i3/i5/i7 and AMD Ryzen CPUs supporting AES-NI instruction set extensions, throughput can be multiple GB/s (even over 10 GB/s).




</doc>
<doc id="1261" url="https://en.wikipedia.org/wiki?curid=1261" title="April 26">
April 26





</doc>
<doc id="1264" url="https://en.wikipedia.org/wiki?curid=1264" title="Anisotropy">
Anisotropy

Anisotropy , is the property of being directionally dependent, which implies different properties in different directions, as opposed to isotropy. It can be defined as a difference, when measured along different axes, in a material's physical or mechanical properties (absorbance, refractive index, conductivity, tensile strength, etc.) 

An example of anisotropy is light coming through a polarizer. Another is wood, which is easier to split along its grain than across it.

In the field of computer graphics, an anisotropic surface changes in appearance as it rotates about its geometric normal, as is the case with velvet.

Anisotropic filtering (AF) is a method of enhancing the image quality of textures on surfaces that are far away and steeply angled with respect to the point of view. Older techniques, such as bilinear and trilinear filtering, do not take into account the angle a surface is viewed from, which can result in aliasing or blurring of textures. By reducing detail in one direction more than another, these effects can be reduced.

A chemical anisotropic filter, as used to filter particles, is a filter with increasingly smaller interstitial spaces in the direction of filtration so that the proximal regions filter out larger particles and distal regions increasingly remove smaller particles, resulting in greater flow-through and more efficient filtration.

In NMR spectroscopy, the orientation of nuclei with respect to the applied magnetic field determines their chemical shift. In this context, anisotropic systems refer to the electron distribution of molecules with abnormally high electron density, like the pi system of benzene. This abnormal electron density affects the applied magnetic field and causes the observed chemical shift to change.

In fluorescence spectroscopy, the fluorescence anisotropy, calculated from the polarization properties of fluorescence from samples excited with plane-polarized light, is used, e.g., to determine the shape of a macromolecule.
Anisotropy measurements reveal the average angular displacement of the fluorophore that occurs between absorption and subsequent emission of a photon.

Images of a gravity-bound or man-made environment are particularly anisotropic in the orientation domain, with more image structure located at orientations parallel with or orthogonal to the direction of gravity (vertical and horizontal).

Physicists from University of California, Berkeley reported about their detection of the cosine anisotropy in cosmic microwave background radiation in 1977. Their experiment demonstrated the Doppler shift caused by the movement of the earth with respect to the early Universe matter, the source of the radiation. Cosmic anisotropy has also been seen in the alignment of galaxies' rotation axes and polarisation angles of quasars.

Physicists use the term anisotropy to describe direction-dependent properties of materials. Magnetic anisotropy, for example, may occur in a plasma, so that its magnetic field is oriented in a preferred direction. Plasmas may also show "filamentation" (such as that seen in lightning or a plasma globe) that is directional.

An "anisotropic liquid" has the fluidity of a normal liquid, but has an average structural order relative to each other along the molecular axis, unlike water or chloroform, which contain no structural ordering of the molecules. Liquid crystals are examples of anisotropic liquids.

Some materials conduct heat in a way that is isotropic, that is independent of spatial orientation around the heat source. Heat conduction is more commonly anisotropic, which implies that detailed geometric modeling of typically diverse materials being thermally managed is required. The materials used to transfer and reject heat from the heat source in electronics are often anisotropic.

Many crystals are anisotropic to light ("optical anisotropy"), and exhibit properties such as birefringence. Crystal optics describes light propagation in these media. An "axis of anisotropy" is defined as the axis along which isotropy is broken (or an axis of symmetry, such as normal to crystalline layers). Some materials can have multiple such optical axes.

Seismic anisotropy is the variation of seismic wavespeed with direction. Seismic anisotropy is an indicator of long range order in a material, where features smaller than the seismic wavelength (e.g., crystals, cracks, pores, layers or inclusions) have a dominant alignment. This alignment leads to a directional variation of elasticity wavespeed. Measuring the effects of anisotropy in seismic data can provide important information about processes and mineralogy in the Earth; indeed, significant seismic anisotropy has been detected in the Earth's crust, mantle and inner core.

Geological formations with distinct layers of sedimentary material can exhibit electrical anisotropy; electrical conductivity in one direction (e.g. parallel to a layer), is different from that in another (e.g. perpendicular to a layer). This property is used in the gas and oil exploration industry to identify hydrocarbon-bearing sands in sequences of sand and shale. Sand-bearing hydrocarbon assets have high resistivity (low conductivity), whereas shales have lower resistivity. Formation evaluation instruments measure this conductivity/resistivity and the results are used to help find oil and gas in wells.

The hydraulic conductivity of aquifers is often anisotropic for the same reason. When calculating groundwater flow to drains or to wells, the difference between horizontal and vertical permeability must be taken into account, otherwise the results may be subject to error.

Most common rock-forming minerals are anisotropic, including quartz and feldspar. Anisotropy in minerals is most reliably seen in their optical properties. An example of an isotropic mineral is garnet.

Anisotropy is also a well-known property in medical ultrasound imaging describing a different resulting echogenicity of soft tissues, such as tendons, when the angle of the transducer is changed. Tendon fibers appear hyperechoic (bright) when the transducer is perpendicular to the tendon, but can appear hypoechoic (darker) when the transducer is angled obliquely. This can be a source of interpretation error for inexperienced practitioners.

Anisotropy, in materials science, is a material's directional dependence of a physical property. This is a critical consideration for materials selection in engineering applications. For monocrystalline material, anisotropy is associated with the crystal symmetry. Tensor descriptions of material properties can be used to determine the directional dependence of that property. When a material is polycrystalline, the directional dependence on properties is often related to the processing techniques it has undergone. A material with randomly oriented grains will be isotropic, whereas materials with texture will be often be anisotropic. Textured materials are often the result of processing techniques like hot rolling, wire-drawing, and heat treatments. 

Mechanical properties of materials, such as Young’s modulus, creep, are often dependent on the direction of measurement. Fourth rank tensor properties, like the elastic constants, are anisotropic, even for materials with cubic symmetry. The Young’s modulus relates stress and strain when an isotropic material is elastically deformed; to describe elasticity in an anisotropic material, stiffness (or compliance) tensors are used instead. In metals, anisotropic elasticity behavior is prevalent in all single crystals, with the exception of Tungsten, due to the fact there are only two independent stiffness coefficients in the stiffness tensor (while other cubic crystals have three). For face centered cubic materials like Copper, the elastic modulus is highest along the <111> direction, normal to the close packed planes. 

The anisotropy ratio is a value computed to compare elastic anisotropy in materials. It is given by the following expression:

formula_1

where the C values are stiffness coefficients in Voight notation. For an isotropic material, the ratio is one. 

Fiber-reinforced or layered composite materials exhibit anisotropic mechanical properties, due to orientation of the reinforcement material. In many fiber-reinforced composites like carbon fiber or glass fiber based composites, the weave of the material (e.g. unidirectional or plain weave) can determine the extent of the anisotropy of the bulk material. The tunability of orientation of the fibers, allows for application-based designs of composite materials, depending on the direction of stresses applied onto the material. 

Amorphous materials such as glass and polymers are typically isotropic. Due to the highly randomized orientation of macromolecules in polymeric materials, polymers are in general described as isotropic. However, polymers can be engineered to have directionally dependent properties through processing techniques or introduction of anisotropy-inducing elements. Researchers have built composite materials with aligned fibers and voids to generate anisotropic hydrogels, in order to mimic hierarchically ordered biological soft matter. 3D printing, especially Fused Deposition Modeling, can introduce anisotropy into printed parts. This is due to the fact that FDM is designed to extrude and print layers of thermoplastic materials. This creates materials that are strong when tensile stress is applied in parallel to the layers and weak when the material is perpendicular to the layers.

Anisotropic etching techniques (such as deep reactive ion etching) are used in microfabrication processes to create well defined microscopic features with a high aspect ratio. These features are commonly used in MEMS and microfluidic devices, where the anisotropy of the features is needed to impart desired optical, electrical, or physical properties to the device. Anisotropic etching can also refer to certain chemical etchants used to etch a certain material preferentially over certain crystallographic planes (e.g., KOH etching of silicon [100] produces pyramid-like structures)

Diffusion tensor imaging is an MRI technique that involves measuring the fractional anisotropy of the random motion (Brownian motion) of water molecules in the brain. Water molecules located in fiber tracts are more likely to be anisotropic, since they are restricted in their movement (they move more in the dimension parallel to the fiber tract rather than in the two dimensions orthogonal to it), whereas water molecules dispersed in the rest of the brain have less restricted movement and therefore display more isotropy. This difference in fractional anisotropy is exploited to create a map of the fiber tracts in the brains of the individual.

Radiance fields (see BRDF) from a reflective surface are often not isotropic in nature. This makes calculations of the total energy being reflected from any scene a difficult quantity to calculate. In remote sensing applications, anisotropy functions can be derived for specific scenes, immensely simplifying the calculation of the net reflectance or (thereby) the net irradiance of a scene.
For example, let the BRDF be formula_2 where 'i' denotes incident direction and 'v' denotes viewing direction (as if from a satellite or other instrument). And let P be the Planar Albedo, which represents the total reflectance from the scene.

It is of interest because, with knowledge of the anisotropy function as defined, a measurement of the BRDF from a single viewing direction (say, formula_5) yields a measure of the total scene reflectance (Planar Albedo) for that specific incident geometry (say, formula_6).




</doc>
<doc id="1267" url="https://en.wikipedia.org/wiki?curid=1267" title="Alpha decay">
Alpha decay

Alpha decay or α-decay is a type of radioactive decay in which an atomic nucleus emits an alpha particle (helium nucleus) and thereby transforms or 'decays' into a different atomic nucleus, with a mass number that is reduced by four and an atomic number that is reduced by two. An alpha particle is identical to the nucleus of a helium-4 atom, which consists of two protons and two neutrons. It has a charge of and a mass of . For example, uranium-238 decays to form thorium-234. Alpha particles have a charge , but as a nuclear equation describes a nuclear reaction without considering the electrons – a convention that does not imply that the nuclei necessarily occur in neutral atoms – the charge is not usually shown.

Alpha decay typically occurs in the heaviest nuclides. Theoretically, it can occur only in nuclei somewhat heavier than nickel (element 28), where the overall binding energy per nucleon is no longer a minimum and the nuclides are therefore unstable toward spontaneous fission-type processes. In practice, this mode of decay has only been observed in nuclides considerably heavier than nickel, with the lightest known alpha emitters being the lightest isotopes (mass numbers 104–109) of tellurium (element 52). Exceptionally, however, beryllium-8 decays to two alpha particles.

Alpha decay is by far the most common form of cluster decay, where the parent atom ejects a defined daughter collection of nucleons, leaving another defined product behind. It is the most common form because of the combined extremely high nuclear binding energy and relatively small mass of the alpha particle. Like other cluster decays, alpha decay is fundamentally a quantum tunneling process. Unlike beta decay, it is governed by the interplay between both the nuclear force and the electromagnetic force.

Alpha particles have a typical kinetic energy of 5 MeV (or ≈ 0.13% of their total energy, 110 TJ/kg) and have a speed of about 15,000,000 m/s, or 5% of the speed of light. There is surprisingly small variation around this energy, due to the heavy dependence of the half-life of this process on the energy produced (see equations in the Geiger–Nuttall law). Because of their relatively large mass, electric charge of and relatively low velocity, alpha particles are very likely to interact with other atoms and lose their energy, and their forward motion can be stopped by a few centimeters of air. Approximately 99% of the helium produced on Earth is the result of the alpha decay of underground deposits of minerals containing uranium or thorium. The helium is brought to the surface as a by-product of natural gas production.

Alpha particles were first described in the investigations of radioactivity by Ernest Rutherford in 1899, and by 1907 they were identified as He ions.

By 1928, George Gamow had solved the theory of alpha decay via tunneling. The alpha particle is trapped in a potential well by the nucleus. Classically, it is forbidden to escape, but according to the (then) newly discovered principles of quantum mechanics, it has a tiny (but non-zero) probability of "tunneling" through the barrier and appearing on the other side to escape the nucleus. Gamow solved a model potential for the nucleus and derived, from first principles, a relationship between the half-life of the decay, and the energy of the emission, which had been previously discovered empirically, and was known as the Geiger–Nuttall law.

The nuclear force holding an atomic nucleus together is very strong, in general much stronger than the repulsive electromagnetic forces between the protons. However, the nuclear force is also short range, dropping quickly in strength beyond about 1 femtometre, while the electromagnetic force has unlimited range. The strength of the attractive nuclear force keeping a nucleus together is thus proportional to the number of nucleons, but the total disruptive electromagnetic force trying to break the nucleus apart is roughly proportional to the square of its atomic number. A nucleus with 210 or more nucleons is so large that the strong nuclear force holding it together can just barely counterbalance the electromagnetic repulsion between the protons it contains. Alpha decay occurs in such nuclei as a means of increasing stability by reducing size.

One curiosity is why alpha particles, helium nuclei, should be preferentially emitted as opposed to other particles like a single proton or neutron or other atomic nuclei. Part of the answer comes from conservation of wave function symmetry, which prevents a particle from spontaneously changing from exhibiting Bose–Einstein statistics (if it had an even number of nucleons) to Fermi–Dirac statistics (if it had an odd number of nucleons) or vice versa. Single proton emission, or the emission of any particle with an odd number of nucleons would violate this conservation law. The rest of the answer comes from the very high binding energy of the alpha particle. Computing the total disintegration energy given by the equation:
Where formula_2 is the initial mass of the nucleus, formula_3 is the mass of the nucleus after particle emission, and formula_4 is the mass of the emitted particle, shows that alpha particle emission will usually be possible just with energy from the nucleus itself, while other decay modes will require additional energy. For example, performing the calculation for uranium-232 shows that alpha particle emission would need only 5.4 MeV, while a single proton emission would require 6.1 MeV. Most of this disintegration energy becomes the kinetic energy of the alpha particle itself, although to maintain conservation of momentum part of this energy becomes the recoil of the nucleus itself. However, since the mass numbers of most alpha emitting radioisotopes exceed 210, far greater than the mass number of the alpha particle (4) the part of the energy going to the recoil of the nucleus is generally quite small.

These disintegration energies however are substantially smaller than the potential barrier provided by the nuclear force, which prevents the alpha particle from escaping. The energy needed is generally in the range of about 25 MeV, the amount of work that must be done against electromagnetic repulsion to bring an alpha particle from infinity to a point near the nucleus just outside the range of the nuclear force's influence. An alpha particle can be thought of as being inside a potential barrier whose walls are 25 MeV. However, decay alpha particles only have kinetic energies of 4 MeV to about 9 MeV, far less than the energy needed to escape.

Quantum mechanics, however, provides a ready explanation, via the mechanism of quantum tunnelling. The quantum tunnelling theory of alpha decay, independently developed by George Gamow and Ronald Wilfred Gurney and Edward Condon in 1928, was hailed as a very striking confirmation of quantum theory. Essentially, the alpha particle escapes from the nucleus by quantum tunnelling its way out. Gurney and Condon made the following observation in their paper on it:
It has hitherto been necessary to postulate some special arbitrary ‘instability’ of the nucleus; but in the following note it is pointed out that disintegration is a natural consequence of the laws of quantum mechanics without any special hypothesis... Much has been written of the explosive violence with which the α-particle is hurled from its place in the nucleus. But from the process pictured above, one would rather say that the α-particle almost slips away unnoticed.
The theory supposes that the alpha particle can be considered an independent particle within a nucleus that is in constant motion, but held within the nucleus by nuclear forces. At each collision with the potential barrier of the nuclear force, there is a small non-zero probability that it will tunnel its way out. An alpha particle with a speed of 1.5×10 m/s within a nuclear diameter of approximately 10 m will collide with the barrier more than 10 times per second. However, if the probability of escape at each collision is very small, the half-life of the radioisotope will be very long, since it is the time required for the total probability of escape to reach 50%. As an extreme example, the half-life of the isotope bismuth-209 is 1.9 x 10 years.

The isotopes in beta-decay stable isobars that are also stable with regards to double beta decay with mass number "A" = 5, "A" = 8, 143 ≤ "A" ≤ 155, 160 ≤ "A" ≤ 162, and "A" ≥ 165 are theorized to undergo alpha decay ("5" decay to helium-4 and a proton or a neutron, and "8" decay to two helium-4, the half-life of them (helium-5, lithium-5, and beryllium-8) are very short, unlike the half-life for all other such nuclides with "A" ≤ 209, which are very long. All other such nuclides with "A" ≤ 209 are primordial nuclides except "A" = 146). However, only such nuclides with "A" = 5, 8, 144, 146, 147, 148, 151, 186, and ≥ 209 have been observed to alpha decay (the decay has also been searched for such nuclides with "A" = 145, 149, 182, 183, 184, 192, 204, and 208). All other mass numbers (isobars) have exactly one theoretically stable nuclide).

Working out the details of the theory leads to an equation relating the half-life of a radioisotope to the decay energy of its alpha particles, a theoretical derivation of the empirical Geiger–Nuttall law.

Americium-241, an alpha emitter, is used in smoke detectors. The alpha particles ionize air in an open ion chamber and a small current flows through the ionized air. Smoke particles from fire that enter the chamber reduce the current, triggering the smoke detector's alarm.

Alpha decay can provide a safe power source for radioisotope thermoelectric generators used for space probes and were used for artificial heart pacemakers. Alpha decay is much more easily shielded against than other forms of radioactive decay.

Static eliminators typically use polonium-210, an alpha emitter, to ionize air, allowing the 'static cling' to dissipate more rapidly.

Highly charged and heavy, alpha particles lose their several MeV of energy within a small volume of material, along a very short mean free path. This increases the chance of double-strand breaks to the DNA in cases of internal contamination, when ingested, inhaled, injected or introduced through the skin. Otherwise, touching an alpha source is typically not harmful, as alpha particles are effectively shielded by a few centimeters of air, a piece of paper, or the thin layer of dead skin cells that make up the epidermis; however, many alpha sources are also accompanied by beta-emitting radio daughters, and both are often accompanied by gamma photon emission.

RBE relative biological effectiveness quantifies the ability of radiation to cause certain biological effects, notably either cancer or cell-death, for equivalent radiation exposure. Alpha radiation has high linear energy transfer (LET) coefficient, which is about one ionization of a molecule/atom for every angstrom of travel by the alpha particle. The RBE has been set at the value of 20 for alpha radiation by various government regulations. The RBE is set at 10 for neutron irradiation, and at 1 for beta radiation and ionizing photons.

However, the recoil of the parent nucleus (alpha recoil) gives it a significant amount of energy, which also causes ionization damage (see ionizing radiation). This energy is roughly the weight of the alpha (4 u) divided by the weight of the parent (typically about 200 u) times the total energy of the alpha. By some estimates, this might account for most of the internal radiation damage, as the recoil nucleus is part of an atom that is much larger than an alpha particle, and causes a very dense trail of ionization; the atom is typically a heavy metal, which preferentially collect on the chromosomes. In some studies, this has resulted in an RBE approaching 1,000 instead of the value used in governmental regulations.

The largest natural contributor to public radiation dose is radon, a naturally occurring, radioactive gas found in soil and rock. If the gas is inhaled, some of the radon particles may attach to the inner lining of the lung. These particles continue to decay, emitting alpha particles, which can damage cells in the lung tissue. The death of Marie Curie at age 66 from aplastic anemia was probably caused by prolonged exposure to high doses of ionizing radiation, but it is not clear if this was due to alpha radiation or X-rays. Curie worked extensively with radium, which decays into radon, along with other radioactive materials that emit beta and gamma rays. However, Curie also worked with unshielded X-ray tubes during World War I, and analysis of her skeleton during a reburial showed a relatively low level of radioisotope burden.

The Russian dissident Alexander Litvinenko's 2006 murder by radiation poisoning is thought to have been carried out with polonium-210, an alpha emitter.




</doc>
<doc id="1270" url="https://en.wikipedia.org/wiki?curid=1270" title="Extreme poverty">
Extreme poverty

Extreme poverty, abject poverty, absolute poverty, destitution, or penury, was defined by the United Nations (UN) in its 1995 report of the World Summit for Social Development as "a condition characterized by severe deprivation of basic human needs, including food, safe drinking water, sanitation facilities, health, shelter, education and information. It depends not only on income but also on access to services."

Historically, other definitions have been proposed within the United Nations. In July 1993, Leandro Despouy, the then UN Special Rapporteur on extreme poverty and human rights made use of a definition he adapted from a 1987 report to the French Economic and Social Council by Fr. Joseph Wresinski, founder of the International Movement ATD Fourth World, distinguishing "lack of basic security" (poverty) and "chronic poverty" (extreme poverty), linking the eradication of extreme poverty by allowing people currently experiencing it a real opportunity to exercise all their human rights:

"The lack of basic security connotes the absence of one or more factors enabling individuals and families to assume basic responsibilities and to enjoy fundamental rights. The situation may become widespread and result in more serious and permanent consequences. The lack of basic security leads to chronic poverty when it simultaneously affects several aspects of people’s lives, when it is prolonged and when it severely compromises people’s chances of regaining their rights and of reassuming their responsibilities in the foreseeable future."

This definition was mentioned previously, in June 1989, in the preliminary report on the realization of economic, social and cultural rights by the UN Special Rapporteur Danilo Türk. It is still in use today, among others, in the current UN Guiding Principles on Extreme Poverty and Human Rights adopted by the Human Rights Council in September 2012.

In 2018, extreme poverty widely refers to an income below the international poverty line of $1.90 per day (in 2011 prices, ), set by the World Bank. In October 2015, the World Bank updated the international poverty line, a global absolute minimum, to $1.90 a day. This is the equivalent of $1.00 a day in 1996 US prices, hence the widely used expression "living on less than a dollar a day". The vast majority of those in extreme poverty — 96 percent — reside in South Asia, Sub-Saharan Africa, the West Indies, East Asia, and the Pacific; nearly half live in India and China alone. As of 2018, it is estimated that the country with the most people living in extreme poverty is Nigeria, at 86 million.

In the past, the vast majority of the world population lived in conditions of extreme poverty. 
The percentage of the global population living in absolute poverty fell from over 80% in 1800 to 10% by 2015.According to United Nations estimates, roughly 734 million people or 10% remained under those conditions. The number had previously been measured as 1.9 billion in 1990, and 1.2 billion in 2008. Despite the significant number of individuals still below the international poverty line, these figures represent significant progress for the international community, as they reflect a decrease of more than one billion people over 15 years. 

In public opinion surveys around the world, people surveyed tend to incorrectly think that extreme poverty has not decreased.

The reduction of extreme poverty and hunger was the first Millennium Development Goal (MDG1), as set by the United Nations in 2000. Specifically, the target was to reduce the extreme poverty rate by half by 2015, a goal that was met five years ahead of schedule. In the Sustainable Development Goals, which succeeded the MDGs, the goal is to end extreme poverty in all its forms everywhere. With this declaration the international community, including the UN and the World Bank have adopted the target of ending extreme poverty by 2030. 

Extreme poverty is defined by the international community as living on less than $1.90 a day, as measured in 2011 international prices (equivalent to $2.12 in 2018). This number, also known as the international poverty line, is periodically updated to account for inflation and differences in the cost of living; it was originally defined at $1.00 a day in 1996. The updates are made according to new price data to portray the costs of basic food, clothing, and shelter around the world as accurately as possible. The latest revision was made in 2015 when the World Bank increased the line to international-$1.90.

Because many of the world's poorest people do not have a monetary income, the poverty measurement is based on the monetary value of a person's "consumption". Otherwise the poverty measurement would be missing the home production of subsistence farmers that consume largely their own production.

The $1.90/day extreme poverty line remains the most widely used metric as it highlights the reality of those in the most severe conditions. Although widely used by most international organizations, it has come under scrutiny due to a variety of factors. For example, it does not account for how far below the line people are, referred to as the depth of poverty. For this purpose, the same institutions publish data on the poverty gap.

The international poverty line is designed to stay constant over time, to allow comparisons between different years. It is therefore a measure of absolute poverty and is not measuring relative poverty. It is also not designed to capture how people view their own financial situation (known as the socially subjective poverty line). Moreover, the calculation of the poverty line relies on information about consumer prices to calculate purchasing power parity, which are very hard to measure and are necessarily debatable. As with all other metrics, there may also be missing data from the poorest and most fragile countries.

Several alternative instruments for measuring extreme poverty have been suggested which incorporate other factors such as malnutrition and lack of access to a basic education. The Multidimensional Poverty Index (MPI), based on the Alkire-Foster Method, is published by the Oxford Poverty & Human Development Initiative (OPHI): it measures deprivation in basic needs and can be broken down to reflect both the incidence and the intensity of poverty. For example, under conventional measures, in both Ethiopia and Uzbekistan about 40% of the population is considered extremely poor, but based on the MPI, 90% of Ethiopians but only 2% of Uzbekistanis are in multidimensional poverty. The MPI is useful for development officials to determine the most likely causes of poverty within a region, using the M0 measure of the method (which is calculated by multiplying the fraction of people in poverty by the fraction of dimensions they are deprived in). For example, in the Gaza Strip of Palestine, using the M0 measure of the Alkire-Foster method reveals that poverty in the region is primarily caused by a lack of access to electricity, lack of access to drinking water, and widespread overcrowding. In contrast, data from the Chhukha District of Bhutan reveals that income is a much larger contributor to poverty as opposed to other dimensions within the region. However, the MPI only presents data from 105 countries, so it cannot be used for global measurements.

Using the World Bank definition of $1.90/day, , roughly 734 million people remained in extreme poverty (or roughly 1 in 10 people worldwide). Nearly half of them live in India and China, with more than 85% living in just 20 countries. Since the mid-1990s, there has been a steady decline in both the worldwide poverty rate and the total number of extreme poor. In 1990, the percentage of the global population living in extreme poverty was 43%, but in 2011, that percentage had dropped down to 21%. This halving of the extreme poverty rate falls in line with the first Millennium Development Goal (MDG1) proposed by former UN Secretary-General Kofi Annan, who called on the international community at the turn of the century to reduce the percentage of people in extreme poverty by half by 2015.

This reduction in extreme poverty took place most notably in China, Indonesia, India, Pakistan and Vietnam. These five countries accounted for the alleviation of 715 million people out of extreme poverty between 1990 and 2010 – more than the global net total of roughly 700 million. This statistical oddity can be explained by the fact that the number of people living in extreme poverty in Sub-Saharan Africa rose from 290 million to 414 million over the same period. However, there have been many positive signs for extensive, global poverty reduction as well. Since 1999, the total number of extreme poor has declined by an average of 50 million per year. Moreover, in 2005, for the first time in recorded history, poverty rates began to fall in every region of the world, including Africa.

As aforementioned, the number of people living in extreme poverty has reduced from 1.9 billion to 766 million over the span of the last decades. If we remain on our current trajectory, many economists predict we could reach global zero by 2030–2035, thus ending extreme poverty. Global zero entails a world in which fewer than 3% of the global population lives in extreme poverty (projected under most optimistic scenarios to be fewer than 200 million people). This zero figure is set at 3% in recognition of the fact that some amount of frictional (temporary) poverty will continue to exist, whether it is caused by political conflict or unexpected economic fluctuations, at least for the foreseeable future. However, the Brookings Institution notes that any projection about poverty more than a few years into the future runs the risk of being highly uncertain. This is because changes in consumption and distribution throughout the developing world over the next two decades could result in monumental shifts in global poverty, for better or worse.

Others are more pessimistic about this possibility, predicting a range of 193 million to 660 million people still living in extreme poverty by 2035. Additionally, some believe the rate of poverty reduction will slow down in the developing world, especially in Africa, and as such it will take closer to five decades to reach global zero. Despite these reservations, several prominent international and national organizations, including the UN, the World Bank and the United States Federal Government (via USAID), have set a target of reaching global zero by the end of 2030.

There are a variety of factors that may reinforce or instigate the existence of extreme poverty, such as weak institutions, cycles of violence and a low level of growth. Recent World Bank research shows that some countries can get caught in a "fragility trap", in which self-reinforcing factors prevent the poorest nations from emerging from low-level equilibrium in the long run. Moreover, most of the reduction in extreme poverty over the past twenty years has taken place in countries that have not experienced a civil conflict or have had governing institutions with a strong capacity to actually govern. Thus, to end extreme poverty, it is also important to focus on the interrelated problems of fragility and conflict.

USAID defines fragility as a government's lack of both legitimacy (the perception the government is adequate at doing its job) and effectiveness (how good the government is at maintaining law and order, in an equitable manner). As fragile nations are unable to equitably and effectively perform the functions of a state, these countries are much more prone to violent unrest and mass inequality. Additionally, in countries with high levels of inequality (a common problem in countries with inadequate governing institutions), much higher growth rates are needed to reduce the rate of poverty when compared with other nations. Additionally, if China and India are removed from the equation, up to 70% of the world's poor live in fragile states by some definitions of fragility. Some analysts project that extreme poverty will be increasingly concentrated in fragile, low-income states like Haiti, Yemen and the Central African Republic. However, some academics, such as Andy Sumner, say that extreme poverty will be increasingly concentrated in middle-income countries, creating a paradox where the world's poor don't actually live in the poorest countries.

To help low-income, fragile states make the transition towards peace and prosperity, the New Deal for Engagement in Fragile States, endorsed by roughly forty countries and multilateral institutions, was created in 2011. This represents an important step towards redressing the problem of fragility as it was originally articulated by self-identified fragile states who called on the international community to not only "do things differently", but to also "do different things".

Civil conflict also remains a prime cause for the perpetuation of poverty throughout the developing world. Armed conflict can have severe effects on economic growth for many reasons such as the destruction of assets, destruction of livelihoods, creation of unwanted mass migration, and diversion of public resources towards war. Significantly, a country that experienced major violence during 1981–2005 had extreme poverty rates 21 percentage points higher than a country with no violence. On average, each civil conflict will cost a country roughly 30 years of GDP growth. Therefore, a renewed commitment from the international community to address the deteriorating situation in highly fragile states is necessary to both prevent the mass loss of life, but to also prevent the vicious cycle of extreme poverty.

Population trends and dynamics (e.g. population growth) can also have a large impact on prospects for poverty reduction. According to the United Nations, "in addition to improving general health and well-being, analysis shows that meeting the reproductive health and contraceptive needs of all women in the developing world more than pays for itself").

In 2013, a prevalent finding in a report by the World Bank was that extreme poverty is most prevalent in low-income countries. In these countries, the World Bank found that progress in poverty reduction is the slowest, the poor live under the worst conditions, and the most affected persons are children age 12 and under.

In September 2000, world leaders gathered at the Millennium Summit held in New York, launching the United Nations Millennium Project suggested by then UN Secretary-General Kofi Annan. Prior to the launch of the conference, the office of Secretary-General Annan released a report entitled We The Peoples: The Role of the United Nations in the 21st Century. In this document, now widely known as the Millennium Report, Kofi Annan called on the international community to reduce the proportion of people in extreme poverty by half by 2015, a target that would affect over 1 billion people. Citing the close correlation between economic growth and the reduction of poverty in poor countries, Annan urged international leaders to indiscriminately target the problem of extreme poverty across every region. In charge of managing the project was Jeffrey Sachs, a noted development economist, who in 2005 released a plan for action called "Investing in Development: A Practical Plan to Achieve the Millennium Development Goals." Thomas Pogge criticized the 2000 Millennium Declaration for being less ambitious than a previous declaration from the World Food Summit due to using 1990 as the benchmark rather than 1996.

The 2005 World Summit, held in September and was organized to measure international progress towards fulfilling the Millennium Development Goals (MDGs). Notably, the conference brought together more than 170 Heads of State. While world leaders at the summit were encouraged by the reduction of poverty in some nations, they were concerned by the uneven decline of poverty within and among different regions of the globe. However, at the end of the summit, the conference attendees reaffirmed the UN's commitment to achieve the MDGs by 2015 and urged all supranational, national and non-governmental organizations to follow suit.

As the expiration of the Millennium Development Goals approached in 2015, the UN convened a panel to advise on a Post-2015 Development Agenda, which led to a new set of goals for 2030 titled the Sustainable Development Goals.

Overall, there has been significant progress towards reducing extreme poverty, with the MDG1 target of reducing extreme poverty rates by half being met five years early, representing 700 million people being lifted out of extreme poverty from 1990 to 2010, with 1.2 billion people still remaining under those conditions. The notable exception to this trend was in Sub-Saharan Africa, the only region where the number of people living in extreme poverty rose from 290 million in 1990 to 414 million in 2010, comprising more than a third of those living in extreme poverty worldwide.

The HLP report, entitled A New Global Partnership: Eradicate Poverty and Transform Economies Through Sustainable Development, was published in May 2013. In the report, the HLP wrote that:

Thus, the report determined that a central goal of the Post-Millennium Development agenda is to eradicate extreme poverty by 2030. However, the report also emphasized that the MDGs were not enough on their own, as they did not "focus on the devastating effects of conflict and violence on development…the importance to development of good governance and institution…nor the need for inclusive growth..." Consequently, there now exists synergy between the policy position papers put forward by the United States (through USAID), the World Bank and the UN itself in terms of viewing fragility and a lack of good governance as exacerbating extreme poverty. However, in a departure from the views of other organizations, the commission also proposed that the UN focus not only on extreme poverty (a line drawn at $1.25), but also on a higher target, such as $2. The report notes this change could be made to reflect the fact that escaping extreme poverty is only a first step.

In addition to the UN, a host of other supranational and national actors such as the European Union and the African Union have published their own positions or recommendations on what should be incorporated in the Post-2015 agenda. The European Commission's communication, published in A decent Life for all: from vision to collective action, affirmed the UN's commitment to "eradicate extreme poverty in our lifetime and put the world on a sustainable path to ensure a decent life for all by 2030". A unique vision of the report was the Commission's environmental focus (in addition to a plethora of other goals such as combating hunger and gender inequality). Specifically, the Commission argued, "long-term poverty reduction…requires inclusive and sustainable growth. Growth should create decent jobs, take place with resource efficiency and within planetary boundaries, and should support efforts to mitigate climate change." The African Union's report, entitled Common African Position (CAP) on the Post-2015 Development Agenda, likewise encouraged the international community to focus on eradicating the twin problems of poverty and exclusion in our lifetime. Moreover, the CAP pledged that "no person – regardless of ethnicity, gender, geography, disability, race or other status – is denied universal human rights and basic economic opportunities".

The UN Least Developed Country (LDC) conferences were a series of summits organized by the UN to promote the substantial and even development of the world's least developed countries.

1st UN LDC Conference

Held between September 1 and September 14, 1981, in Paris, the first UN LDC Conference was organized to finalize the UN's "Substantial New Programme of Action" for the 1980s in Least Developed Countries. This program, which was unanimously adopted by the conference attendees, argued for internal reforms in LDCs (meant to encourage economic growth) to be complemented by strong international measures. However, despite the major economic and policy reforms initiated many of these LDCs, in addition to strong international aid, the economic situation of these countries worsened as a whole in the 1980s. This prompted the organization of a 2nd UN LDC conference almost a decade later.

2nd UN LDC Conference

Held between September 3 and September 14, 1990, once again in Paris, the second UN LDC Conference was convened to measure the progress made by the LDCs towards fulfilling their development goals during the 1980s. Recognizing the problems that plagued the LDCs over the past decade, the conference formulated a new set of national and international policies to accelerate the growth rates of the poorest nations. These new principles were embodied in the "Paris Declaration and Programme of Action for the Least Developed Countries for the 1990s".

4th UN LDC Conference

The most recent conference, held in May 2011 in Istanbul, recognized that the nature of development had fundamentally changed since the 1st conference held almost 30 years earlier. In the 21st century, the capital flow into emerging economies has increasingly become dominated by foreign direct investment and remittances, as opposed to bilateral and multilateral assistance. Moreover, since the 80s, significant structural changes have taken place on the international stage. With the creation of the G-20 conference of the largest economic powers, including many nations in the Global South, formerly undeveloped nations are now able to have a much larger say in international relations. Furthermore, the conference recognized that in the midst of a deep global recession, coupled with multiple crises (energy, climate, food, etc.), the international community would have fewer resources to aid the LDCs. Thus, the UN considered the participation of a wide range of stakeholders (not least the LDCs themselves), crucial to the formulation of the conference.

In 2013, the Board of Governors of the World Bank Group (WBG) set two overriding goals for the WBG to commit itself to in the future. First, to end extreme poverty by 2030, an objective that echoes the sentiments of the UN and the Obama administration. Additionally, the WBG set an interim target of reducing extreme poverty to below 9 percent by 2020. Second, to focus on growth among the bottom 40 percent of people, as opposed to standard GDP growth. This commitment ensures that the growth of the developing world lifts people out of poverty, rather than exacerbating inequality.

As the World Bank's primary focus is on delivering economic growth to enable equitable prosperity, its developments programs are primarily commercial-based in nature, as opposed to the UN. Since the World Bank recognizes better jobs will result in higher income and thus, less poverty, the WBG seeks to support employment training initiatives, small business development programs and strong labor protection laws. However, since much of the growth in the developing world has been inequitable, the World Bank has also begun teaming with client states to map out trends in inequality and to propose public policy changes that can level the playing field.

Moreover, the World Bank engages in a variety of nutritional, transfer payments and transport-based initiatives. Children who experience under-nutrition from conception to two years of age have a much higher risk of physical and mental disability. Thus, they are often trapped in poverty and are unable to make a full contribution to the social and economic development of their communities as adults. The WBG estimates that as much as 3% of GDP can be lost as a result of under-nutrition among the poorest nations. To combat undernutrition, the WBG has partnered with UNICEF and the WHO to ensure all small children are fully fed. The WBG also offers conditional cash transfers to poor households who meet certain requirements such as maintaining children's healthcare or ensuring school attendance. Finally, the WBG understands investment in public transportation and better roads is key to breaking rural isolation, improving access to healthcare and providing better job opportunities for the World's poor.

1. OCHA (Office for the Coordination of Humanitarian Affairs): The Office for the Coordination of Humanitarian Affairs (OCHA) of the United Nations works to synchronize the disparate international, national and non-governmental efforts to contest poverty. The OCHA seeks to prevent "confusion" in relief operations and to ensure that the humanitarian response to disaster situations has greater accountability and predictability. To do so, OCHA has begun deploying Humanitarian Coordinators and Country Teams to provide a solid architecture for the international community to work through.

2. UNICEF (United Nations Children's Fund): The United Nation's Children's Fund (UNICEF) was created by the UN to provide food, clothing and healthcare to European children facing famine and disease in the immediate aftermath of World War II. After the UN General Assembly extended UNICEF's mandate indefinitely in 1953, it actively worked to help children in extreme poverty in more than 190 countries and territories to overcome the obstacles that poverty, violence, disease and discrimination place in a child's path. Its current focus areas are 1) Child survival & development 2) Basic education & gender equality 3) Children and HIV/AIDS and 4) Child protection.

3. UNHCR (The UN Refugee Agency): The UN Refugee Agency (UNHCR) is mandated to lead and coordinate international action to protect refugees worldwide. Its primary purpose is to safeguard the rights of refugees by ensuring anyone can exercise the right to seek asylum in another state, with the option to return home voluntarily, integrate locally or resettle in a third country. The UNHCR operates in over 125 countries, helping approximately 33.9 million persons.

4. WFP (World Food Program): The World Food Program (WFP) is the largest agency dedicated to fighting hunger worldwide. On average, WFP brings food assistance to more than 90 million people in 75 countries. The WFP not only strives to prevent hunger in the present, but also in the future by developing stronger communities which will make food even more secure on their own. The WFP has a range of expertise from Food Security Analysis, Nutrition, Food Procurement and Logistics.

5. WHO (World Health Organization): The World Health Organization (WHO) is responsible for providing leadership on global health matters, shaping the health research agenda, articulating evidence-based policy decisions and combating diseases that are induced from poverty, such as HIV/AIDS, malaria and tuberculosis. Moreover, the WHO deals with pressing issues ranging from managing water safety, to dealing with maternal and newborn health.

The U.S. Agency for International Development (USAID) is the lead U.S. government agency dedicated to ending extreme poverty. Currently the largest bilateral donor in the world, the United States channels the majority of its development assistance through USAID and the U.S. Department of State. In President Obama's 2013 State of the Union address, he declared "So the United States will join with our allies to eradicate such extreme poverty in the next two decades...which is within our reach." In response to Obama's call to action, USAID has made ending extreme poverty central to its mission statement. Under its New Model of Development, USAID seeks to eradicate extreme poverty through the use of innovation in science and technology, by putting a greater emphasis on evidence based decision-making, and through leveraging the ingenuity of the private sector and global citizens.

A major initiative of the Obama Administration is Power Africa, which aims to bring energy to 20 million people in Sub-Saharan Africa. By reaching out to its international partners, whether commercial or public, the US has leveraged over $14 billion in outside commitments after investing only US$7 billion of its own. To ensure that Power Africa reaches the region's poorest, the initiative engages in a transaction based approach to create systematic change. This includes expanding access to electricity to more than 20,000 additional households which already live without power.

In terms of specific programming, USAID works in a variety of fields from preventing hunger, reducing HIV/AIDS, providing general health assistance and democracy assistance, as well as dealing with gender issues. To deal with food security, which affects roughly 842 million people (who go to bed hungry each night), USAID coordinates the Feed the Future Initiative (FtF). FtF aims to reduce poverty and undernutrition each by 20 percent over five years. Thanks to the President's Emergency Plan for AIDS Relief (PEPFAR) and a variety of congruent actors, the incidence of AIDS and HIV, which used to ravage Africa, has reduced in scope and intensity. Through PEPFAR, the United States has ensured over five million people have received life-saving antiviral drugs, a significant proportion of the eight million people receiving treatment in relatively poor nations.

In terms of general health assistance, USAID has worked to reduce maternal mortality by 30 percent, under-five child mortality by 35 percent, and has accomplished a host of other goals. USAID also supports the gamut of democratic initiatives, from promoting human rights and accountable, fair governance, to supporting free and fair elections and the rule of law. In pursuit of these goals, USAID has increased global political participation by training more than 9,800 domestic election observers and providing civic education to more than 6.5 million people. Since 2012, the Agency has begun integrating critical gender perspectives across all aspects of its programming to ensure all USAID initiatives work to eliminate gender disparities. To do so, USAID seeks to increase the capability of women and girls to realize their rights and determine their own life outcomes. Moreover, USAID supports additional programs to improve women's access to capital and markets, builds theirs skills in agriculture, and supports women's desire to own businesses.

The Department for International Development (DfID) is the UK's lead agency for eradicating extreme poverty. To do so, DfID focuses on the creation of jobs, empowering women, and rapidly responding to humanitarian emergencies.

Some specific examples of DfID projects include governance assistance, educational initiatives, and funding cutting-edge research. In 2014 alone, DfID will help to ensure free and fair elections in 13 countries. DfID will also help provide 10 million women with access to justice through strengthened judicial systems and will help 40 million people make their authorities more accountable. By 2015, DfID will have helped 9 million children attend primary school, at least half of which will be girls. Furthermore, through the Research4Development (R4D) project, DfID has funded over 35,000 projects in the name of creating new technologies to help the world's poorest. These technologies include: vaccines for diseases of African cattle, better diagnostic methods for tuberculosis, new drugs for combating malaria, and developing flood-resistant rice. In addition to technological research, the R4D is also used to fund projects that seek to understand what, specifically, about governance structures can be changed to help the world's poorest.

A multitude of non-governmental organizations operate in the field of extreme poverty, actively working to alleviate the poorest of the poor of their deprivation. To name but a few notable organizations: Save the Children, The Overseas Development Institute, Concern Worldwide, ONE, trickleUP and Oxfam have all done a considerable amount of work in extreme poverty.

Save the Children is the leading international organization dedicated to helping the world's indigent children. In 2013, Save the Children reached over 143 million children through their work, including over 52 million children directly. Save the Children also recently released their own report titled "Getting to Zero", in which they argued the international community could feasibly do more than lift the world's poor above $1.25/day. The Overseas Development Institute (ODI) is the premier UK based think tank on international development and humanitarian issues. ODI is dedicated to alleviating the suffering of the world's poor by providing high-quality research and practical policy advice to the World's development officials. ODI also recently released a paper entitled, "The Chronic Poverty Report 2014–2015: The road to zero extreme poverty", in which its authors assert that though the international communities' goal of ending extreme poverty by 2030 is laudable, much more targeted resources will be necessary to reach said target. The report states that "To eradicate extreme poverty, massive global investment is required in social assistance, education and pro-poorest economic growth".

Concern Worldwide is an international humanitarian organization whose mission is to end extreme poverty by influencing decision makers at all levels of government (local -> international). Concern has also produced a report on extreme poverty in which they explain their own conception of extreme poverty from a NGO's standpoint. In this paper, named "How Concern Understands Extreme Poverty]", the report's creators write that extreme poverty entails more than just living under $1.25/day, it also includes having a small number of assets and being vulnerable to severe negative shocks (whether natural or man made).

ONE, the organization cofounded by Bono, is a non-profit organization funded almost entirely by foundations, individual philanthropists and corporations. ONE's goals include raising public awareness and working with political leaders to fight preventable diseases, increase government accountability and increase investment in nutrition. Finally, trickleUp is a microenterprise development program targeted at those living on under $1.25/day, which provides the indigent with resources to build a sustainable livelihood through both direct financing and considerable training efforts.

Another NGO that works to end extreme poverty is Oxfam. This non-governmental organization works prominently in Africa; their mission is to improve local community organizations and it works to reduce impediments to the development of the country. Oxfam helps families suffering from poverty receive food and healthcare to survive. There are many children in Africa experiencing growth stunting, and this is one example of an issue that Oxfam targets and aims to resolve.





</doc>
<doc id="1271" url="https://en.wikipedia.org/wiki?curid=1271" title="Analytical Engine">
Analytical Engine

The Analytical Engine was a proposed mechanical general-purpose computer designed by English mathematician and computer pioneer Charles Babbage. It was first described in 1837 as the successor to Babbage's difference engine, a design for a simpler mechanical computer.

The Analytical Engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as Turing-complete. In other words, the logical structure of the Analytical Engine was essentially the same as that which has dominated computer design in the electronic era.. The Analytical Engine is one of the most successful achievements of Charles Babbage.

Babbage was never able to complete construction of any of his machines due to conflicts with his chief engineer and inadequate funding. It was not until 1941 that the first general-purpose computer, Z3, was actually built, more than a century after Babbage had proposed the pioneering Analytical Engine in 1837.

Babbage's first attempt at a mechanical computing device, the Difference Engine, was a special-purpose machine designed to tabulate logarithms and trigonometric functions by evaluating finite differences to create approximating polynomials. Construction of this machine was never completed; Babbage had conflicts with his chief engineer, Joseph Clement, and ultimately the British government withdrew its funding for the project.

During this project, he realized that a much more general design, the Analytical Engine, was possible. The work on the design of the Analytical Engine started in c. 1833.

The input, consisting of programs and data ("formulae" and "data") was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the Jacquard loom. For output, the machine would have a printer, a curve plotter and a bell. The machine would also be able to punch numbers onto cards to be read in later. It employed ordinary base-10 fixed-point arithmetic.

There was to be a store (that is, a memory) capable of holding 1,000 numbers of 40 decimal digits each (ca. 16.2 kB). An arithmetic unit (the "mill") would be able to perform all four arithmetic operations, plus comparisons and optionally square roots. Initially (1838) it was conceived as a difference engine curved back upon itself, in a generally circular layout, with the long store exiting off to one side. Later drawings (1858) depict a regularized grid layout. Like the central processing unit (CPU) in a modern computer, the mill would rely upon its own internal procedures, to be stored in the form of pegs inserted into rotating drums called "barrels", to carry out some of the more complex instructions the user's program might specify.

The programming language to be employed by users was akin to modern day assembly languages. Loops and conditional branching were possible, and so the language as conceived would have been Turing-complete as later defined by Alan Turing. Three different types of punch cards were used: one for arithmetical operations, one for numerical constants, and one for load and store operations, transferring numbers from the store to the arithmetical unit or back. There were three separate readers for the three types of cards. Babbage developed some two dozen programs for the Analytical Engine between 1837 and 1840, and one program later. These programs treat polynomials, iterative formulas, Gaussian elimination, and Bernoulli numbers.

In 1842, the Italian mathematician Luigi Federico Menabrea published a description of the engine based on a lecture by Babbage in French. In 1843, the description was translated into English and extensively annotated by Ada Lovelace, who had become interested in the engine eight years earlier. In recognition of her additions to Menabrea's paper, which included a way to calculate Bernoulli numbers using the machine (widely considered to be the first complete computer program), she has been described as the first computer programmer.

Late in his life, Babbage sought ways to build a simplified version of the machine, and assembled a small part of it before his death in 1871.

In 1878, a committee of the British Association for the Advancement of Science described the Analytical Engine as "a marvel of mechanical ingenuity", but recommended against constructing it. The committee acknowledged the usefulness and value of the machine, but could not estimate the cost of building it, and were unsure whether the machine would function correctly after being built.

Intermittently from 1880 to 1910, Babbage's son Henry Prevost Babbage was constructing a part of the mill and the printing apparatus. In 1910 it was able to calculate a (faulty) list of multiples of pi. This constituted only a small part of the whole engine; it was not programmable and had no storage. (Popular images of this section have sometimes been mislabelled, implying that it was the entire mill or even the entire engine.) Henry Babbage's "Analytical Engine Mill" is on display at the Science Museum in London. Henry also proposed building a demonstration version of the full engine, with a smaller storage capacity: "perhaps for a first machine ten (columns) would do, with fifteen wheels in each". Such a version could manipulate 20 numbers of 25 digits each, and what it could be told to do with those numbers could still be impressive. "It is only a question of cards and time", wrote Henry Babbage in 1888, "... and there is no reason why (twenty thousand) cards should not be used if necessary, in an Analytical Engine for the purposes of the mathematician".

In 1991, the London Science Museum built a complete and working specimen of Babbage's Difference Engine No. 2, a design that incorporated refinements Babbage discovered during the development of the Analytical Engine. This machine was built using materials and engineering tolerances that would have been available to Babbage, quelling the suggestion that Babbage's designs could not have been produced using the manufacturing technology of his time.

In October 2010, John Graham-Cumming started a "Plan 28" campaign to raise funds by "public subscription" to enable serious historical and academic study of Babbage's plans, with a view to then build and test a fully working virtual design which will then in turn enable construction of the physical Analytical Engine. As of May 2016, actual construction had not been attempted, since no consistent understanding could yet be obtained from Babbage's original design drawings. In particular it was unclear whether it could handle the indexed variables which were required for Lovelace's Bernoulli program. By 2017, the "Plan 28" effort reported that a searchable database of all catalogued material was available, and an initial review of Babbage's voluminous Scribbling Books had been completed.

Babbage is not known to have written down an explicit set of instructions for the engine in the manner of a modern processor manual. Instead he showed his programs as lists of states during their execution, showing what operator was run at each step with little indication of how the control flow would be guided.

Allan G. Bromley has assumed that the card deck could be read in forwards and backwards directions as a function of conditional branching after testing for conditions, which would make the engine Turing-complete:

...the cards could be ordered to move forward and reverse (and hence to loop)...

The introduction for the first time, in 1845, of user operations for a variety of service functions including, most importantly, an effective system for user control of looping in user programs.

There is no indication how the direction of turning of the operation and variable cards is specified. In the absence of other evidence I have had to adopt the minimal default assumption that both the operation and variable cards can only be turned backward as is necessary to implement the loops used in Babbage’s sample programs. There would be no mechanical or microprogramming difficulty in placing the direction of motion under the control of the user.

In their emulator of the engine, Fourmilab say:

The Engine's Card Reader is not constrained to simply process the cards in a chain one after another from start to finish. It can, in addition, directed by the very cards it reads and advised by the whether the Mill's run-up lever is activated, either advance the card chain forward, skipping the intervening cards, or backward, causing previously-read cards to be processed once again.

This emulator does provide a written symbolic instruction set, though this has been constructed by its authors rather than based on Babbage's original works. For example, a factorial program would be written as:

where the CB is the conditional branch instruction or "combination card" used to make the control flow jump, in this case backwards by 11 cards.

Babbage understood that the existence of an automatic computer would kindle interest in the field now known as algorithmic efficiency, writing in his "Passages from the Life of a Philosopher", "As soon as an Analytical Engine exists, it will necessarily guide the future course of the science. Whenever any result is sought by its aid, the question will then arise—By what course of calculation can these results be arrived at by the machine in the "shortest time"?"

From 1872 Henry continued diligently with his father's work and then intermittently in retirement in 1875.

Percy Ludgate wrote about the engine in 1914 and designed his own Analytical Engine (it was drawn up in detail, but never built) about 1907–1909. Ludgate's engine would be much smaller than Babbage's of about , and hypothetically would be capable of multiplying two 20-decimal-digit numbers in about six seconds.

Torres y Quevedo wrote about Babbage's engines in "Essays on Automatics" (1913). Book contains design for an electromechanical machine capable of calculating completely automatically the value of a function.

Vannevar Bush's paper "Instrumental Analysis" (1936) included several references to Babbage's work. In the same year started Rapid Arithmetical Machine project to investigate the problems of constructing an electronic digital computer.

Despite this groundwork, Babbage's work fell into historical obscurity, and the Analytical Engine was unknown to builders of electro-mechanical and electronic computing machines in the 1930s and 1940s when they began their work, resulting in the need to re-invent many of the architectural innovations Babbage had proposed. Howard Aiken, who built the quickly-obsoleted electromechanical calculator, the Harvard Mark I, between 1937 and 1945, praised Babbage's work likely as a way of enhancing his own stature, but knew nothing of the Analytical Engine's architecture during the construction of the Mark I, and considered his visit to the constructed portion of the Analytical Engine "the greatest disappointment of my life". The Mark I showed no influence from the Analytical Engine and lacked the Analytical Engine's most prescient architectural feature, conditional branching. J. Presper Eckert and John W. Mauchly similarly were not aware of the details of Babbage's Analytical Engine work prior to the completion of their design for the first electronic general-purpose computer, the ENIAC.

If the Analytical Engine had been built, it would have been digital, programmable and Turing-complete. It would, however, have been very slow. Luigi Federico Menabrea reported in "Sketch of the Analytical Engine": "Mr. Babbage believes he can, by his engine, form the product of two numbers, each containing twenty figures, in three minutes".
By comparison the Harvard Mark I could perform the same task in just six seconds. A modern PC can do the same thing in well under a billionth of a second.




</doc>
<doc id="1273" url="https://en.wikipedia.org/wiki?curid=1273" title="Augustus">
Augustus

Augustus (; 23 September 63 BC – 19 August AD 14) was a Roman statesman and military leader who was the first emperor of the Roman Empire, reigning from 27 BC until his death in AD 14. His status as the founder of the Roman Principate has consolidated an enduring legacy as one of the most effective and controversial leaders in human history. The reign of Augustus initiated an era of relative peace known as the "Pax Romana". The Roman world was largely free from large-scale conflict for more than two centuries, despite continuous wars of imperial expansion on the Empire's frontiers and the year-long civil war known as the "Year of the Four Emperors" over the imperial succession.

Augustus was born Gaius Octavius Thurinus into an old and wealthy equestrian branch of the plebeian "gens" Octavia. His maternal great-uncle Julius Caesar was assassinated in 44 BC, and Octavius was named in Caesar's will as his adopted son and heir. Along with Mark Antony and Marcus Lepidus, he formed the Second Triumvirate to defeat the assassins of Caesar. Following their victory at the Battle of Philippi, the Triumvirate divided the Roman Republic among themselves and ruled as military dictators. The Triumvirate was eventually torn apart by the competing ambitions of its members. Lepidus was driven into exile and stripped of his position, and Antony committed suicide following his defeat at the Battle of Actium by Octavian in 31 BC.

After the demise of the Second Triumvirate, Augustus restored the outward façade of the free Republic, with governmental power vested in the Roman Senate, the executive magistrates, and the legislative assemblies. In reality, however, he retained his autocratic power over the Republic as a military dictator. By law, Augustus held a collection of powers granted to him for life by the Senate, including supreme military command, and those of tribune and censor. It took several years for Augustus to develop the framework within which a formally republican state could be led under his sole rule. He rejected monarchical titles, and instead called himself "Princeps Civitatis" ("First Citizen of the State"). The resulting constitutional framework became known as the Principate, the first phase of the Roman Empire.

Augustus dramatically enlarged the Empire, annexing Egypt, Dalmatia, Pannonia, Noricum, and Raetia, expanding possessions in Africa, and completing the conquest of Hispania, but suffered a major setback in Germania. Beyond the frontiers, he secured the Empire with a buffer region of client states and made peace with the Parthian Empire through diplomacy. He reformed the Roman system of taxation, developed networks of roads with an official courier system, established a standing army, established the Praetorian Guard, created official police and fire-fighting services for Rome, and rebuilt much of the city during his reign. Augustus died in AD 14 at the age of 75, probably from natural causes. However, there were unconfirmed rumors that his wife Livia poisoned him. He was succeeded as emperor by his adopted son (also stepson and former son-in-law) Tiberius.

As a consequence of Roman customs, society, and personal preference, Augustus (; ) was known by many names throughout his life:

While his paternal family was from the town of Velletri, approximately from Rome, Augustus was born in the city of Rome on 23 September 63 BC. He was born at Ox Head, a small property on the Palatine Hill, very close to the Roman Forum. He was given the name Gaius Octavius Thurinus, his cognomen possibly commemorating his father's victory at Thurii over a rebellious band of slaves. Suetonius wrote: "There are many indications that the Octavian family was in days of old a distinguished one at Velitrae; for not only was a street in the most frequented part of town long ago called Octavian, but an altar was shown there besides, consecrated by an Octavius. This man was leader in a war with a neighbouring town ..." 

Due to the crowded nature of Rome at the time, Octavius was taken to his father's home village at Velletri to be raised. Octavius mentions his father's equestrian family only briefly in his memoirs. His paternal great-grandfather Gaius Octavius was a military tribune in Sicily during the Second Punic War. His grandfather had served in several local political offices. His father, also named Gaius Octavius, had been governor of Macedonia. His mother, Atia, was the niece of Julius Caesar.
In 59 BC, when he was four years old, his father died. His mother married a former governor of Syria, Lucius Marcius Philippus. Philippus claimed descent from Alexander the Great, and was elected consul in 56 BC. Philippus never had much of an interest in young Octavius. Because of this, Octavius was raised by his grandmother, Julia, the sister of Julius Caesar. Julia died in 52 or 51 BC, and Octavius delivered the funeral oration for his grandmother. From this point, his mother and stepfather took a more active role in raising him. He donned the "toga virilis" four years later, and was elected to the College of Pontiffs in 47 BC. The following year he was put in charge of the Greek games that were staged in honor of the Temple of Venus Genetrix, built by Julius Caesar. According to Nicolaus of Damascus, Octavius wished to join Caesar's staff for his campaign in Africa, but gave way when his mother protested. In 46 BC, she consented for him to join Caesar in Hispania, where he planned to fight the forces of Pompey, Caesar's late enemy, but Octavius fell ill and was unable to travel.

When he had recovered, he sailed to the front, but was shipwrecked; after coming ashore with a handful of companions, he crossed hostile territory to Caesar's camp, which impressed his great-uncle considerably. Velleius Paterculus reports that after that time, Caesar allowed the young man to share his carriage. When back in Rome, Caesar deposited a new will with the Vestal Virgins, naming Octavius as the prime beneficiary.

Octavius was studying and undergoing military training in Apollonia, Illyria, when Julius Caesar was killed on the Ides of March (15 March) 44 BC. He rejected the advice of some army officers to take refuge with the troops in Macedonia and sailed to Italy to ascertain whether he had any potential political fortunes or security. Caesar had no living legitimate children under Roman law, and so had adopted Octavius, his grand-nephew, making him his primary heir. Mark Antony later charged that Octavian had earned his adoption by Caesar through sexual favours, though Suetonius describes Antony's accusation as political slander. This form of slander was popular during this time in the Roman Republic to demean and discredit political opponents by accusing them of having an inappropriate sexual affair. After landing at Lupiae near Brundisium, Octavius learned the contents of Caesar's will, and only then did he decide to become Caesar's political heir as well as heir to two-thirds of his estate.

Upon his adoption, Octavius assumed his great-uncle's name Gaius Julius Caesar. Roman citizens adopted into a new family usually retained their old nomen in cognomen form (e.g., "Octavianus" for one who had been an Octavius, "Aemilianus" for one who had been an Aemilius, etc.). However, though some of his contemporaries did, there is no evidence that Octavius ever himself officially used the name "Octavianus", as it would have made his modest origins too obvious. Historians usually refer to the new Caesar as "Octavian" during the time between his adoption and his assumption of the name Augustus in 27 BC in order to avoid confusing the dead dictator with his heir.

Octavian could not rely on his limited funds to make a successful entry into the upper echelons of the Roman political hierarchy. After a warm welcome by Caesar's soldiers at Brundisium, Octavian demanded a portion of the funds that were allotted by Caesar for the intended war against the Parthian Empire in the Middle East. This amounted to 700 million sesterces stored at Brundisium, the staging ground in Italy for military operations in the east.

A later senatorial investigation into the disappearance of the public funds took no action against Octavian, since he subsequently used that money to raise troops against the Senate's arch enemy Mark Antony. Octavian made another bold move in 44 BC when, without official permission, he appropriated the annual tribute that had been sent from Rome's Near Eastern province to Italy.

Octavian began to bolster his personal forces with Caesar's veteran legionaries and with troops designated for the Parthian war, gathering support by emphasizing his status as heir to Caesar. On his march to Rome through Italy, Octavian's presence and newly acquired funds attracted many, winning over Caesar's former veterans stationed in Campania. By June, he had gathered an army of 3,000 loyal veterans, paying each a salary of 500 denarii.

Arriving in Rome on 6 May 44 BC, Octavian found consul Mark Antony, Caesar's former colleague, in an uneasy truce with the dictator's assassins. They had been granted a general amnesty on 17 March, yet Antony had succeeded in driving most of them out of Rome with an inflammatory eulogy at Caesar's funeral, mounting public opinion against the assassins.

Mark Antony was amassing political support, but Octavian still had opportunity to rival him as the leading member of the faction supporting Caesar. Mark Antony had lost the support of many Romans and supporters of Caesar when he initially opposed the motion to elevate Caesar to divine status. Octavian failed to persuade Antony to relinquish Caesar's money to him. During the summer, he managed to win support from Caesarian sympathizers and also made common with the Optimates, the former enemies of Caesar, who saw him as the lesser evil and hoped to manipulate him. In September, the leading Optimate orator Marcus Tullius Cicero began to attack Antony in a series of speeches portraying him as a threat to the Republican order.

With opinion in Rome turning against him and his year of consular power nearing its end, Antony attempted to pass laws that would assign him the province of Cisalpine Gaul. Octavian meanwhile built up a private army in Italy by recruiting Caesarian veterans and, on 28 November, he won over two of Antony's legions with the enticing offer of monetary gain.

In the face of Octavian's large and capable force, Antony saw the danger of staying in Rome and, to the relief of the Senate, he left Rome for Cisalpine Gaul, which was to be handed to him on 1 January. However, the province had earlier been assigned to Decimus Junius Brutus Albinus, one of Caesar's assassins, who now refused to yield to Antony. Antony besieged him at Mutina and rejected the resolutions passed by the Senate to stop the fighting. The Senate had no army to enforce their resolutions. This provided an opportunity for Octavian, who already was known to have armed forces. Cicero also defended Octavian against Antony's taunts about Octavian's lack of noble lineage and aping of Julius Caesar's name, stating "we have no more brilliant example of traditional piety among our youth."

At the urging of Cicero, the Senate inducted Octavian as senator on 1 January 43 BC, yet he also was given the power to vote alongside the former consuls. In addition, Octavian was granted "propraetor" "imperium" (commanding power) which legalized his command of troops, sending him to relieve the siege along with Hirtius and Pansa (the consuls for 43 BC). In April 43 BC, Antony's forces were defeated at the battles of Forum Gallorum and Mutina, forcing Antony to retreat to Transalpine Gaul. Both consuls were killed, however, leaving Octavian in sole command of their armies.

The senate heaped many more rewards on Decimus Brutus than on Octavian for defeating Antony, then attempted to give command of the consular legions to Decimus Brutus. In response, Octavian stayed in the Po Valley and refused to aid any further offensive against Antony. In July, an embassy of centurions sent by Octavian entered Rome and demanded the consulship left vacant by Hirtius and Pansa and also that the decree should be rescinded which declared Antony a public enemy. When this was refused, he marched on the city with eight legions. He encountered no military opposition in Rome, and on 19 August 43 BC was elected consul with his relative Quintus Pedius as co-consul. Meanwhile, Antony formed an alliance with Marcus Aemilius Lepidus, another leading Caesarian.

In a meeting near Bologna in October 43 BC, Octavian, Antony, and Lepidus formed the Second Triumvirate. This explicit arrogation of special powers lasting five years was then legalised by law passed by the plebs, unlike the unofficial First Triumvirate formed by Pompey, Julius Caesar, and Marcus Licinius Crassus. The triumvirs then set in motion proscriptions, in which between 130 and 300 senators and 2,000 "equites" were branded as outlaws and deprived of their property and, for those who failed to escape, their lives. This decree issued by the triumvirate was motivated in part by a need to raise money to pay the salaries of their troops for the upcoming conflict against Caesar's assassins, Marcus Junius Brutus and Gaius Cassius Longinus. Rewards for their arrest gave incentive for Romans to capture those proscribed, while the assets and properties of those arrested were seized by the triumvirs.

Contemporary Roman historians provide conflicting reports as to which triumvir was most responsible for the proscriptions and killing. However, the sources agree that enacting the proscriptions was a means by all three factions to eliminate political enemies. Marcus Velleius Paterculus asserted that Octavian tried to avoid proscribing officials whereas Lepidus and Antony were to blame for initiating them. Cassius Dio defended Octavian as trying to spare as many as possible, whereas Antony and Lepidus, being older and involved in politics longer, had many more enemies to deal with.

This claim was rejected by Appian, who maintained that Octavian shared an equal interest with Lepidus and Antony in eradicating his enemies. Suetonius said that Octavian was reluctant to proscribe officials, but did pursue his enemies with more vigor than the other triumvirs. Plutarch described the proscriptions as a ruthless and cutthroat swapping of friends and family among Antony, Lepidus, and Octavian. For example, Octavian allowed the proscription of his ally Cicero, Antony the proscription of his maternal uncle Lucius Julius Caesar (the consul of 64 BC), and Lepidus his brother Paullus.

On 1 January 42 BC, the Senate posthumously recognized Julius Caesar as a divinity of the Roman state, "Divus Iulius". Octavian was able to further his cause by emphasizing the fact that he was "Divi filius", "Son of the Divine". Antony and Octavian then sent 28 legions by sea to face the armies of Brutus and Cassius, who had built their base of power in Greece. After two battles at Philippi in Macedonia in October 42, the Caesarian army was victorious and Brutus and Cassius committed suicide. Mark Antony later used the examples of these battles as a means to belittle Octavian, as both battles were decisively won with the use of Antony's forces. In addition to claiming responsibility for both victories, Antony also branded Octavian as a coward for handing over his direct military control to Marcus Vipsanius Agrippa instead.

After Philippi, a new territorial arrangement was made among the members of the Second Triumvirate. Gaul and the province of Hispania were placed in the hands of Octavian. Antony traveled east to Egypt where he allied himself with Queen Cleopatra VII, the former lover of Julius Caesar and mother of Caesar's infant son Caesarion. Lepidus was left with the province of Africa, stymied by Antony, who conceded Hispania to Octavian instead.

Octavian was left to decide where in Italy to settle the tens of thousands of veterans of the Macedonian campaign, whom the triumvirs had promised to discharge. The tens of thousands who had fought on the republican side with Brutus and Cassius could easily ally with a political opponent of Octavian if not appeased, and they also required land. There was no more government-controlled land to allot as settlements for their soldiers, so Octavian had to choose one of two options: alienating many Roman citizens by confiscating their land, or alienating many Roman soldiers who could mount a considerable opposition against him in the Roman heartland. Octavian chose the former. There were as many as eighteen Roman towns affected by the new settlements, with entire populations driven out or at least given partial evictions.

There was widespread dissatisfaction with Octavian over these settlements of his soldiers, and this encouraged many to rally at the side of Lucius Antonius, who was brother of Mark Antony and supported by a majority in the Senate. Meanwhile, Octavian asked for a divorce from Clodia Pulchra, the daughter of Fulvia (Mark Antony's wife) and her first husband Publius Clodius Pulcher. He returned Clodia to her mother, claiming that their marriage had never been consummated. Fulvia decided to take action. Together with Lucius Antonius, she raised an army in Italy to fight for Antony's rights against Octavian. Lucius and Fulvia took a political and martial gamble in opposing Octavian, however, since the Roman army still depended on the triumvirs for their salaries. Lucius and his allies ended up in a defensive siege at Perusia (modern Perugia), where Octavian forced them into surrender in early 40 BC.
Lucius and his army were spared, due to his kinship with Antony, the strongman of the East, while Fulvia was exiled to Sicyon. Octavian showed no mercy, however, for the mass of allies loyal to Lucius; on 15 March, the anniversary of Julius Caesar's assassination, he had 300 Roman senators and equestrians executed for allying with Lucius. Perusia also was pillaged and burned as a warning for others. This bloody event sullied Octavian's reputation and was criticized by many, such as Augustan poet Sextus Propertius.

Sextus Pompeius, the son of Pompey and still a renegade general following Julius Caesar's victory over his father, had established himself in Sicily and Sardinia as part of an agreement reached with the Second Triumvirate in 39 BC. Both Antony and Octavian were vying for an alliance with Pompeius. Octavian succeeded in a temporary alliance in 40 BC when he married Scribonia, a sister or daughter of Pompeius' father-in-law Lucius Scribonius Libo. Scribonia gave birth to Octavian's only natural child, Julia, the same day that he divorced her to marry Livia Drusilla, little more than a year after their marriage.

While in Egypt, Antony had been engaged in an affair with Cleopatra and had fathered three children with her. Aware of his deteriorating relationship with Octavian, Antony left Cleopatra; he sailed to Italy in 40 BC with a large force to oppose Octavian, laying siege to Brundisium. This new conflict proved untenable for both Octavian and Antony, however. Their centurions, who had become important figures politically, refused to fight due to their Caesarian cause, while the legions under their command followed suit. Meanwhile, in Sicyon, Antony's wife Fulvia died of a sudden illness while Antony was en route to meet her. Fulvia's death and the mutiny of their centurions allowed the two remaining triumvirs to effect a reconciliation.
In the autumn of 40, Octavian and Antony approved the Treaty of Brundisium, by which Lepidus would remain in Africa, Antony in the East, Octavian in the West. The Italian Peninsula was left open to all for the recruitment of soldiers, but in reality, this provision was useless for Antony in the East. To further cement relations of alliance with Mark Antony, Octavian gave his sister, Octavia Minor, in marriage to Antony in late 40 BC.

Sextus Pompeius threatened Octavian in Italy by denying shipments of grain through the Mediterranean Sea to the peninsula. Pompeius' own son was put in charge as naval commander in the effort to cause widespread famine in Italy. Pompeius' control over the sea prompted him to take on the name "Neptuni filius", "son of Neptune". A temporary peace agreement was reached in 39 BC with the treaty of Misenum; the blockade on Italy was lifted once Octavian granted Pompeius Sardinia, Corsica, Sicily, and the Peloponnese, and ensured him a future position as consul for 35 BC.

The territorial agreement between the triumvirate and Sextus Pompeius began to crumble once Octavian divorced Scribonia and married Livia on 17 January 38 BC. One of Pompeius' naval commanders betrayed him and handed over Corsica and Sardinia to Octavian. Octavian lacked the resources to confront Pompeius alone, however, so an agreement was reached with the Second Triumvirate's extension for another five-year period beginning in 37 BC.

In supporting Octavian, Antony expected to gain support for his own campaign against the Parthian Empire, desiring to avenge Rome's defeat at Carrhae in 53 BC. In an agreement reached at Tarentum, Antony provided 120 ships for Octavian to use against Pompeius, while Octavian was to send 20,000 legionaries to Antony for use against Parthia. Octavian sent only a tenth of those promised, however, which Antony viewed as an intentional provocation.

Octavian and Lepidus launched a joint operation against Sextus in Sicily in 36 BC. Despite setbacks for Octavian, the naval fleet of Sextus Pompeius was almost entirely destroyed on 3 September by General Agrippa at the naval Battle of Naulochus. Sextus fled to the east with his remaining forces, where he was captured and executed in Miletus by one of Antony's generals the following year. As Lepidus and Octavian accepted the surrender of Pompeius' troops, Lepidus attempted to claim Sicily for himself, ordering Octavian to leave. Lepidus' troops deserted him, however, and defected to Octavian since they were weary of fighting and were enticed by Octavian's promises of money.

Lepidus surrendered to Octavian and was permitted to retain the office of "Pontifex Maximus" (head of the college of priests), but was ejected from the Triumvirate, his public career at an end, and effectively was exiled to a villa at Cape Circei in Italy. The Roman dominions were now divided between Octavian in the West and Antony in the East. Octavian ensured Rome's citizens of their rights to property in order to maintain peace and stability in his portion of the Empire. This time, he settled his discharged soldiers outside of Italy, while also returning 30,000 slaves to their former Roman owners—slaves who had fled to join Pompeius' army and navy. Octavian had the Senate grant him, his wife, and his sister tribunal immunity, or "sacrosanctitas", in order to ensure his own safety and that of Livia and Octavia once he returned to Rome.

Meanwhile, Antony's campaign turned disastrous against Parthia, tarnishing his image as a leader, and the mere 2,000 legionaries sent by Octavian to Antony were hardly enough to replenish his forces. On the other hand, Cleopatra could restore his army to full strength; he already was engaged in a romantic affair with her, so he decided to send Octavia back to Rome. Octavian used this to spread propaganda implying that Antony was becoming less than Roman because he rejected a legitimate Roman spouse for an "Oriental paramour". In 36 BC, Octavian used a political ploy to make himself look less autocratic and Antony more the villain by proclaiming that the civil wars were coming to an end, and that he would step down as triumvir—if only Antony would do the same. Antony refused.

Roman troops captured the Kingdom of Armenia in 34 BC, and Antony made his son Alexander Helios the ruler of Armenia. He also awarded the title "Queen of Kings" to Cleopatra, acts that Octavian used to convince the Roman Senate that Antony had ambitions to diminish the preeminence of Rome. Octavian became consul once again on 1 January 33 BC, and he opened the following session in the Senate with a vehement attack on Antony's grants of titles and territories to his relatives and to his queen.

The breach between Antony and Octavian prompted a large portion of the Senators, as well as both of that year's consuls, to leave Rome and defect to Antony. However, Octavian received two key deserters from Antony in the autumn of 32 BC: Munatius Plancus and Marcus Titius. These defectors gave Octavian the information that he needed to confirm with the Senate all the accusations that he made against Antony.

Octavian forcibly entered the temple of the Vestal Virgins and seized Antony's secret will, which he promptly publicized. The will would have given away Roman-conquered territories as kingdoms for his sons to rule, and designated Alexandria as the site for a tomb for him and his queen. In late 32 BC, the Senate officially revoked Antony's powers as consul and declared war on Cleopatra's regime in Egypt.
In early 31 BC, Antony and Cleopatra were temporarily stationed in Greece when Octavian gained a preliminary victory: the navy successfully ferried troops across the Adriatic Sea under the command of Agrippa. Agrippa cut off Antony and Cleopatra's main force from their supply routes at sea, while Octavian landed on the mainland opposite the island of Corcyra (modern Corfu) and marched south. Trapped on land and sea, deserters of Antony's army fled to Octavian's side daily while Octavian's forces were comfortable enough to make preparations.

Antony's fleet sailed through the bay of Actium on the western coast of Greece in a desperate attempt to break free of the naval blockade. It was there that Antony's fleet faced the much larger fleet of smaller, more maneuverable ships under commanders Agrippa and Gaius Sosius in the Battle of Actium on 2 September 31 BC. Antony and his remaining forces were spared only due to a last-ditch effort by Cleopatra's fleet that had been waiting nearby.

Octavian pursued them and defeated their forces in Alexandria on 1 August 30 BC—after which Antony and Cleopatra committed suicide. Antony fell on his own sword and was taken by his soldiers back to Alexandria where he died in Cleopatra's arms. Cleopatra died soon after, reputedly by the venomous bite of an asp or by poison. Octavian had exploited his position as Caesar's heir to further his own political career, and he was well aware of the dangers in allowing another person to do the same. He therefore followed the advice of Arius Didymus that "two Caesars are one too many", ordering Caesarion, Julius Caesar's son by Cleopatra, killed, while sparing Cleopatra's children by Antony, with the exception of Antony's older son. Octavian had previously shown little mercy to surrendered enemies and acted in ways that had proven unpopular with the Roman people, yet he was given credit for pardoning many of his opponents after the Battle of Actium.

After Actium and the defeat of Antony and Cleopatra, Octavian was in a position to rule the entire Republic under an unofficial principate—but he had to achieve this through incremental power gains. He did so by courting the Senate and the people while upholding the republican traditions of Rome, appearing that he was not aspiring to dictatorship or monarchy. Marching into Rome, Octavian and Marcus Agrippa were elected as dual consuls by the Senate.

Years of civil war had left Rome in a state of near lawlessness, but the Republic was not prepared to accept the control of Octavian as a despot. At the same time, Octavian could not simply give up his authority without risking further civil wars among the Roman generals and, even if he desired no position of authority whatsoever, his position demanded that he look to the well-being of the city of Rome and the Roman provinces. Octavian's aims from this point forward were to return Rome to a state of stability, traditional legality, and civility by lifting the overt political pressure imposed on the courts of law and ensuring free elections—in name at least.

In 27 BC, Octavian made a show of returning full power to the Roman Senate and relinquishing his control of the Roman provinces and their armies. Under his consulship, however, the Senate had little power in initiating legislation by introducing bills for senatorial debate. Octavian was no longer in direct control of the provinces and their armies, but he retained the loyalty of active duty soldiers and veterans alike. The careers of many clients and adherents depended on his patronage, as his financial power was unrivaled in the Roman Republic. Historian Werner Eck states:

To a large extent, the public were aware of the vast financial resources that Octavian commanded. He failed to encourage enough senators to finance the building and maintenance of networks of roads in Italy in 20 BC, but he undertook direct responsibility for them. This was publicized on the Roman currency issued in 16 BC, after he donated vast amounts of money to the "aerarium Saturni", the public treasury.
According to H. H. Scullard, however, Octavian's power was based on the exercise of "a predominant military power and ... the ultimate sanction of his authority was force, however much the fact was disguised." The Senate proposed to Octavian, the victor of Rome's civil wars, that he once again assume command of the provinces. The Senate's proposal was a ratification of Octavian's extra-constitutional power. Through the Senate, Octavian was able to continue the appearance of a still-functional constitution. Feigning reluctance, he accepted a ten-year responsibility of overseeing provinces that were considered chaotic.

The provinces ceded to Augustus for that ten-year period comprised much of the conquered Roman world, including all of Hispania and Gaul, Syria, Cilicia, Cyprus, and Egypt. Moreover, command of these provinces provided Octavian with control over the majority of Rome's legions.

While Octavian acted as consul in Rome, he dispatched senators to the provinces under his command as his representatives to manage provincial affairs and ensure that his orders were carried out. The provinces not under Octavian's control were overseen by governors chosen by the Roman Senate. Octavian became the most powerful political figure in the city of Rome and in most of its provinces, but he did not have a monopoly on political and martial power.

The Senate still controlled North Africa, an important regional producer of grain, as well as Illyria and Macedonia, two strategic regions with several legions. However, the Senate had control of only five or six legions distributed among three senatorial proconsuls, compared to the twenty legions under the control of Octavian, and their control of these regions did not amount to any political or military challenge to Octavian. The Senate's control over some of the Roman provinces helped maintain a republican façade for the autocratic Principate. Also, Octavian's control of entire provinces followed Republican-era precedents for the objective of securing peace and creating stability, in which such prominent Romans as Pompey had been granted similar military powers in times of crisis and instability.

On 16 January 27 BC the Senate gave Octavian the new titles of "Augustus" and "Princeps". "Augustus" is from the Latin word "Augere" (meaning to increase) and can be translated as "the illustrious one". It was a title of religious authority rather than political authority. His new title of Augustus was also more favorable than "Romulus", the previous one which he styled for himself in reference to the story of the legendary founder of Rome, which symbolized a second founding of Rome. The title of "Romulus" was associated too strongly with notions of monarchy and kingship, an image that Octavian tried to avoid. The title "princeps senatus" originally meant the member of the Senate with the highest precedence, but in the case of Augustus, it became an almost regnal title for a leader who was first in charge. Augustus also styled himself as "Imperator Caesar divi filius", "Commander Caesar son of the deified one". With this title, he boasted his familial link to deified Julius Caesar, and the use of "Imperator" signified a permanent link to the Roman tradition of victory. He transformed "Caesar", a cognomen for one branch of the Julian family, into a new family line that began with him.

Augustus was granted the right to hang the "corona civica" above his door, the "civic crown" made from oak, and to have laurels drape his doorposts. However, he renounced flaunting insignia of power such as holding a scepter, wearing a diadem, or wearing the golden crown and purple toga of his predecessor Julius Caesar. If he refused to symbolize his power by donning and bearing these items on his person, the Senate nonetheless awarded him with a golden shield displayed in the meeting hall of the Curia, bearing the inscription "virtus", "pietas", "clementia", "iustitia"—"valor, piety, clemency, and justice."

By 23 BC, some of the un-Republican implications were becoming apparent concerning the settlement of 27 BC. Augustus' retention of an annual consulate drew attention to his "de facto" dominance over the Roman political system, and cut in half the opportunities for others to achieve what was still nominally the preeminent position in the Roman state. Further, he was causing political problems by desiring to have his nephew Marcus Claudius Marcellus follow in his footsteps and eventually assume the Principate in his turn, alienating his three greatest supporters – Agrippa, Maecenas, and Livia. He appointed noted Republican Calpurnius Piso (who had fought against Julius Caesar and supported Cassius and Brutus) as co-consul in 23 BC, after his choice Aulus Terentius Varro Murena died unexpectedly.

In the late spring Augustus suffered a severe illness, and on his supposed deathbed made arrangements that would ensure the continuation of the Principate in some form, while allaying senators' suspicions of his anti-republicanism. Augustus prepared to hand down his signet ring to his favored general Agrippa. However, Augustus handed over to his co-consul Piso all of his official documents, an account of public finances, and authority over listed troops in the provinces while Augustus' supposedly favored nephew Marcellus came away empty-handed. This was a surprise to many who believed Augustus would have named an heir to his position as an unofficial emperor.

Augustus bestowed only properties and possessions to his designated heirs, as an obvious system of institutionalized imperial inheritance would have provoked resistance and hostility among the republican-minded Romans fearful of monarchy. With regards to the Principate, it was obvious to Augustus that Marcellus was not ready to take on his position; nonetheless, by giving his signet ring to Agrippa, Augustus intended to signal to the legions that Agrippa was to be his successor, and that constitutional procedure notwithstanding, they should continue to obey Agrippa.
Soon after his bout of illness subsided, Augustus gave up his consulship. The only other times Augustus would serve as consul would be in the years 5 and 2 BC, both times to introduce his grandsons into public life. This was a clever ploy by Augustus; ceasing to serve as one of two annually elected consuls allowed aspiring senators a better chance to attain the consular position, while allowing Augustus to exercise wider patronage within the senatorial class. Although Augustus had resigned as consul, he desired to retain his consular "imperium" not just in his provinces but throughout the empire. This desire, as well as the Marcus Primus Affair, led to a second compromise between him and the Senate known as the Second Settlement.

The primary reasons for the Second Settlement were as follows. First, after Augustus relinquished the annual consulship, he was no longer in an official position to rule the state, yet his dominant position remained unchanged over his Roman, 'imperial' provinces where he was still a proconsul. When he annually held the office of consul, he had the power to intervene with the affairs of the other provincial proconsuls appointed by the Senate throughout the empire, when he deemed necessary.

A second problem later arose showing the need for the Second Settlement in what became known as the "Marcus Primus Affair". In late 24 or early 23 BC, charges were brought against Marcus Primus, the former proconsul (governor) of Macedonia, for waging a war without prior approval of the Senate on the Odrysian kingdom of Thrace, whose king was a Roman ally. He was defended by Lucius Lucinius Varro Murena, who told the trial that his client had received specific instructions from Augustus, ordering him to attack the client state. Later, Primus testified that the orders came from the recently deceased Marcellus.

Such orders, had they been given, would have been considered a breach of the Senate's prerogative under the Constitutional settlement of 27 BC and its aftermath—i.e., before Augustus was granted "imperium proconsulare maius"—as Macedonia was a Senatorial province under the Senate's jurisdiction, not an imperial province under the authority of Augustus. Such an action would have ripped away the veneer of Republican restoration as promoted by Augustus, and exposed his fraud of merely being the first citizen, a first among equals. Even worse, the involvement of Marcellus provided some measure of proof that Augustus' policy was to have the youth take his place as Princeps, instituting a form of monarchy – accusations that had already played out.
The situation was so serious that Augustus himself appeared at the trial, even though he had not been called as a witness. Under oath, Augustus declared that he gave no such order. Murena disbelieved Augustus' testimony and resented his attempt to subvert the trial by using his "auctoritas". He rudely demanded to know why Augustus had turned up to a trial to which he had not been called; Augustus replied that he came in the public interest. Although Primus was found guilty, some jurors voted to acquit, meaning that not everybody believed Augustus' testimony, an insult to the 'August One'.

The Second Constitutional Settlement was completed in part to allay confusion and formalize Augustus' legal authority to intervene in Senatorial provinces. The Senate granted Augustus a form of general "imperium proconsulare", or proconsular imperium (power) that applied throughout the empire, not solely to his provinces. Moreover, the Senate augmented Augustus' proconsular imperium into "imperium proconsulare maius", or proconsular imperium applicable throughout the empire that was more (maius) or greater than that held by the other proconsuls. This in effect gave Augustus constitutional power superior to all other proconsuls in the empire. Augustus stayed in Rome during the renewal process and provided veterans with lavish donations to gain their support, thereby ensuring that his status of proconsular imperium maius was renewed in 13 BC.

During the second settlement, Augustus was also granted the power of a tribune ("tribunicia potestas") for life, though not the official title of tribune. For some years, Augustus had been awarded "tribunicia sacrosanctitas", the immunity given to a Tribune of the Plebs. Now he decided to assume the full powers of the magistracy, renewed annually, in perpetuity. Legally, it was closed to patricians, a status that Augustus had acquired some years earlier when adopted by Julius Caesar.

This power allowed him to convene the Senate and people at will and lay business before them, to veto the actions of either the Assembly or the Senate, to preside over elections, and to speak first at any meeting. Also included in Augustus' tribunician authority were powers usually reserved for the Roman censor; these included the right to supervise public morals and scrutinize laws to ensure that they were in the public interest, as well as the ability to hold a census and determine the membership of the Senate.

With the powers of a censor, Augustus appealed to virtues of Roman patriotism by banning all attire but the classic toga while entering the Forum. There was no precedent within the Roman system for combining the powers of the tribune and the censor into a single position, nor was Augustus ever elected to the office of censor. Julius Caesar had been granted similar powers, wherein he was charged with supervising the morals of the state. However, this position did not extend to the censor's ability to hold a census and determine the Senate's roster. The office of the "tribunus plebis" began to lose its prestige due to Augustus' amassing of tribunal powers, so he revived its importance by making it a mandatory appointment for any plebeian desiring the praetorship.
Augustus was granted sole "imperium" within the city of Rome itself, in addition to being granted proconsular imperium maius and tribunician authority for life. Traditionally, proconsuls (Roman province governors) lost their proconsular "imperium" when they crossed the Pomerium – the sacred boundary of Rome – and entered the city. In these situations, Augustus would have power as part of his tribunician authority but his constitutional imperium within the Pomerium would be less than that of a serving consul. That would mean that, when he was in the city, he might not be the constitutional magistrate with the most authority. Thanks to his prestige or "auctoritas", his wishes would usually be obeyed, but there might be some difficulty. To fill this power vacuum, the Senate voted that Augustus' imperium proconsulare maius (superior proconsular power) should not lapse when he was inside the city walls. All armed forces in the city had formerly been under the control of the urban praetors and consuls, but this situation now placed them under the sole authority of Augustus.

In addition, the credit was given to Augustus for each subsequent Roman military victory after this time, because the majority of Rome's armies were stationed in imperial provinces commanded by Augustus through the legatus who were deputies of the princeps in the provinces. Moreover, if a battle was fought in a Senatorial province, Augustus' proconsular imperium maius allowed him to take command of (or credit for) any major military victory. This meant that Augustus was the only individual able to receive a triumph, a tradition that began with Romulus, Rome's first King and first triumphant general. Lucius Cornelius Balbus was the last man outside Augustus' family to receive this award, in 19 BC. Tiberius, Augustus' eldest stepson by Livia, was the only other general to receive a triumph—for victories in Germania in 7 BC.

Many of the political subtleties of the Second Settlement seem to have evaded the comprehension of the Plebeian class, who were Augustus' greatest supporters and clientele. This caused them to insist upon Augustus' participation in imperial affairs from time to time. Augustus failed to stand for election as consul in 22 BC, and fears arose once again that he was being forced from power by the aristocratic Senate. In 22, 21, and 19 BC, the people rioted in response, and only allowed a single consul to be elected for each of those years, ostensibly to leave the other position open for Augustus.

Likewise, there was a food shortage in Rome in 22 BC which sparked panic, while many urban plebs called for Augustus to take on dictatorial powers to personally oversee the crisis. After a theatrical display of refusal before the Senate, Augustus finally accepted authority over Rome's grain supply "by virtue of his proconsular "imperium"", and ended the crisis almost immediately. It was not until AD 8 that a food crisis of this sort prompted Augustus to establish a "praefectus annonae", a permanent prefect who was in charge of procuring food supplies for Rome.

There were some who were concerned by the expansion of powers granted to Augustus by the Second Settlement, and this came to a head with the apparent conspiracy of Fannius Caepio. Some time prior to 1 September 22 BC, a certain Castricius provided Augustus with information about a conspiracy led by Fannius Caepio. Murena was named among the conspirators, the outspoken Consul who defended Primus in the Marcus Primus Affair. The conspirators were tried in absentia with Tiberius acting as prosecutor; the jury found them guilty, but it was not a unanimous verdict. All the accused were sentenced to death for treason and executed as soon as they were captured—without ever giving testimony in their defence. Augustus ensured that the facade of Republican government continued with an effective cover-up of the events.

In 19 BC, the Senate granted Augustus a form of 'general consular imperium', which was probably 'imperium consulare maius', like the proconsular powers that he received in 23 BC. Like his tribune authority, the consular powers were another instance of gaining power from offices that he did not actually hold. In addition, Augustus was allowed to wear the consul's insignia in public and before the Senate, as well as to sit in the symbolic chair between the two consuls and hold the fasces, an emblem of consular authority. This seems to have assuaged the populace; regardless of whether or not Augustus was a consul, the importance was that he both appeared as one before the people and could exercise consular power if necessary. On 6 March 12 BC, after the death of Lepidus, he additionally took up the position of pontifex maximus, the high priest of the college of the Pontiffs, the most important position in Roman religion. On 5 February 2 BC, Augustus was also given the title "pater patriae", or "father of the country".

A final reason for the Second Settlement was to give the Principate constitutional stability and staying power in case something happened to Princeps Augustus. His illness of early 23 BC and the Caepio conspiracy showed that the regime's existence hung by the thin thread of the life of one man, Augustus himself, who suffered from several severe and dangerous illnesses throughout his life. If he were to die from natural causes or fall victim to assassination, Rome could be subjected to another round of civil war. The memories of Pharsalus, the Ides of March, the proscriptions, Philippi, and Actium, barely twenty-five years distant, were still vivid in the minds of many citizens. Proconsular imperium was conferred upon Agrippa for five years, similar to Augustus' power, in order to accomplish this constitutional stability. The exact nature of the grant is uncertain but it probably covered Augustus' imperial provinces, east and west, perhaps lacking authority over the provinces of the Senate. That came later, as did the jealously guarded tribunicia potestas. Augustus' accumulation of powers were now complete. In fact, he dated his 'reign' from the completion of the Second Settlement, 1 July 23 BC.

Augustus chose "Imperator" ("victorious commander") to be his first name, since he wanted to make an emphatically clear connection between himself and the notion of victory, and consequently became known as "Imperator Caesar Divi Filius Augustus". By the year 13, Augustus boasted 21 occasions where his troops proclaimed "imperator" as his title after a successful battle. Almost the entire fourth chapter in his publicly released memoirs of achievements known as the "Res Gestae" was devoted to his military victories and honors.

Augustus also promoted the ideal of a superior Roman civilization with a task of ruling the world (to the extent to which the Romans knew it), a sentiment embodied in words that the contemporary poet Virgil attributes to a legendary ancestor of Augustus: "tu regere imperio populos, Romane, memento"—"Roman, remember by your strength to rule the Earth's peoples!" The impulse for expansionism was apparently prominent among all classes at Rome, and it is accorded divine sanction by Virgil's Jupiter in Book 1 of the "Aeneid", where Jupiter promises Rome "imperium sine fine", "sovereignty without end".

By the end of his reign, the armies of Augustus had conquered northern Hispania (modern Spain and Portugal) and the Alpine regions of Raetia and Noricum (modern Switzerland, Bavaria, Austria, Slovenia), Illyricum and Pannonia (modern Albania, Croatia, Hungary, Serbia, etc.), and had extended the borders of the Africa Province to the east and south. Judea was added to the province of Syria when Augustus deposed Herod Archelaus, successor to client king Herod the Great (73–4 BC). Syria (like Egypt after Antony) was governed by a high prefect of the equestrian class rather than by a proconsul or legate of Augustus.
Again, no military effort was needed in 25 BC when Galatia (modern Turkey) was converted to a Roman province shortly after Amyntas of Galatia was killed by an avenging widow of a slain prince from Homonada. The rebellious tribes of Asturias and Cantabria in modern-day Spain were finally quelled in 19 BC, and the territory fell under the provinces of Hispania and Lusitania. This region proved to be a major asset in funding Augustus' future military campaigns, as it was rich in mineral deposits that could be fostered in Roman mining projects, especially the very rich gold deposits at Las Medulas.
Conquering the peoples of the Alps in 16 BC was another important victory for Rome, since it provided a large territorial buffer between the Roman citizens of Italy and Rome's enemies in Germania to the north. Horace dedicated an ode to the victory, while the monumental Trophy of Augustus near Monaco was built to honor the occasion. The capture of the Alpine region also served the next offensive in 12 BC, when Tiberius began the offensive against the Pannonian tribes of Illyricum, and his brother Nero Claudius Drusus moved against the Germanic tribes of the eastern Rhineland. Both campaigns were successful, as Drusus' forces reached the Elbe River by 9 BC—though he died shortly after by falling off his horse. It was recorded that the pious Tiberius walked in front of his brother's body all the way back to Rome.
To protect Rome's eastern territories from the Parthian Empire, Augustus relied on the client states of the east to act as territorial buffers and areas that could raise their own troops for defense. To ensure security of the Empire's eastern flank, Augustus stationed a Roman army in Syria, while his skilled stepson Tiberius negotiated with the Parthians as Rome's diplomat to the East. Tiberius was responsible for restoring Tigranes V to the throne of the Kingdom of Armenia.

Yet arguably his greatest diplomatic achievement was negotiating with Phraates IV of Parthia (37–2 BC) in 20 BC for the return of the battle standards lost by Crassus in the Battle of Carrhae, a symbolic victory and great boost of morale for Rome. Werner Eck claims that this was a great disappointment for Romans seeking to avenge Crassus' defeat by military means. However, Maria Brosius explains that Augustus used the return of the standards as propaganda symbolizing the submission of Parthia to Rome. The event was celebrated in art such as the breastplate design on the statue Augustus of Prima Porta and in monuments such as the Temple of Mars Ultor ('Mars the Avenger') built to house the standards.

Parthia had always posed a threat to Rome in the east, but the real battlefront was along the Rhine and Danube rivers. Before the final fight with Antony, Octavian's campaigns against the tribes in Dalmatia were the first step in expanding Roman dominions to the Danube. Victory in battle was not always a permanent success, as newly conquered territories were constantly retaken by Rome's enemies in Germania.

A prime example of Roman loss in battle was the Battle of Teutoburg Forest in AD 9, where three entire legions led by Publius Quinctilius Varus were destroyed by Arminius, leader of the Cherusci, an apparent Roman ally. Augustus retaliated by dispatching Tiberius and Drusus to the Rhineland to pacify it, which had some success although the battle of AD 9 brought the end to Roman expansion into Germany. Roman general Germanicus took advantage of a Cherusci civil war between Arminius and Segestes; they defeated Arminius, who fled that Battle of Idistaviso in AD 16 but was killed later in 21 due to treachery.

The illness of Augustus in 23 BC brought the problem of succession to the forefront of political issues and the public. To ensure stability, he needed to designate an heir to his unique position in Roman society and government. This was to be achieved in small, undramatic, and incremental ways that did not stir senatorial fears of monarchy. If someone was to succeed to Augustus' unofficial position of power, he would have to earn it through his own publicly proven merits.

Some Augustan historians argue that indications pointed toward his sister's son Marcellus, who had been quickly married to Augustus' daughter Julia the Elder. Other historians dispute this due to Augustus' will being read aloud to the Senate while he was seriously ill in 23 BC, instead indicating a preference for Marcus Agrippa, who was Augustus' second in charge and arguably the only one of his associates who could have controlled the legions and held the Empire together.

After the death of Marcellus in 23 BC, Augustus married his daughter to Agrippa. This union produced five children, three sons and two daughters: Gaius Caesar, Lucius Caesar, Vipsania Julia, Agrippina the Elder, and Postumus Agrippa, so named because he was born after Marcus Agrippa died. Shortly after the Second Settlement, Agrippa was granted a five-year term of administering the eastern half of the Empire with the "imperium" of a proconsul and the same "tribunicia potestas" granted to Augustus (although not trumping Augustus' authority), his seat of governance stationed at Samos in the eastern Aegean. This granting of power showed Augustus' favor for Agrippa, but it was also a measure to please members of his Caesarian party by allowing one of their members to share a considerable amount of power with him.
Augustus' intent became apparent to make Gaius and Lucius Caesar his heirs when he adopted them as his own children. He took the consulship in 5 and 2 BC so that he could personally usher them into their political careers, and they were nominated for the consulships of AD 1 and 4. Augustus also showed favor to his stepsons, Livia's children from her first marriage Nero Claudius Drusus Germanicus (henceforth referred to as Drusus) and Tiberius Claudius (henceforth Tiberius), granting them military commands and public office, though seeming to favor Drusus. After Agrippa died in 12 BC, Tiberius was ordered to divorce his own wife Vipsania Agrippina and marry Agrippa's widow, Augustus' daughter Julia—as soon as a period of mourning for Agrippa had ended. Drusus' marriage to Augustus' niece Antonia was considered an unbreakable affair, whereas Vipsania was "only" the daughter of the late Agrippa from his first marriage.

Tiberius shared in Augustus' tribune powers as of 6 BC, but shortly thereafter went into retirement, reportedly wanting no further role in politics while he exiled himself to Rhodes. No specific reason is known for his departure, though it could have been a combination of reasons, including a failing marriage with Julia, as well as a sense of envy and exclusion over Augustus' apparent favouring of his young grandchildren-turned-sons Gaius and Lucius. (Gaius and Lucius joined the college of priests at an early age, were presented to spectators in a more favorable light, and were introduced to the army in Gaul.)

After the early deaths of both Lucius and Gaius in AD 2 and 4 respectively, and the earlier death of his brother Drusus (9 BC), Tiberius was recalled to Rome in June AD 4, where he was adopted by Augustus on the condition that he, in turn, adopt his nephew Germanicus. This continued the tradition of presenting at least two generations of heirs. In that year, Tiberius was also granted the powers of a tribune and proconsul, emissaries from foreign kings had to pay their respects to him, and by AD 13 was awarded with his second triumph and equal level of "imperium" with that of Augustus.
The only other possible claimant as heir was Postumus Agrippa, who had been exiled by Augustus in AD 7, his banishment made permanent by senatorial decree, and Augustus officially disowned him. He certainly fell out of Augustus' favor as an heir; the historian Erich S. Gruen notes various contemporary sources that state Postumus Agrippa was a "vulgar young man, brutal and brutish, and of depraved character".

On 19 August AD 14, Augustus died while visiting Nola where his father had died. Both Tacitus and Cassius Dio wrote that Livia was rumored to have brought about Augustus' death by poisoning fresh figs. This element features in many modern works of historical fiction pertaining to Augustus' life, but some historians view it as likely to have been a salacious fabrication made by those who had favoured Postumus as heir, or other of Tiberius' political enemies. Livia had long been the target of similar rumors of poisoning on the behalf of her son, most or all of which are unlikely to have been true.

Alternatively, it is possible that Livia did supply a poisoned fig (she did cultivate a variety of fig named for her that Augustus is said to have enjoyed), but did so as a means of assisted suicide rather than murder. Augustus' health had been in decline in the months immediately before his death, and he had made significant preparations for a smooth transition in power, having at last reluctantly settled on Tiberius as his choice of heir. It is likely that Augustus was not expected to return alive from Nola, but it seems that his health improved once there; it has therefore been speculated that Augustus and Livia conspired to end his life at the anticipated time, having committed all political process to accepting Tiberius, in order to not endanger that transition.

Augustus' famous last words were, "Have I played the part well? Then applaud as I exit"—referring to the play-acting and regal authority that he had put on as emperor. Publicly, though, his last words were, "Behold, I found Rome of clay, and leave her to you of marble." An enormous funerary procession of mourners traveled with Augustus' body from Nola to Rome, and on the day of his burial all public and private businesses closed for the day. Tiberius and his son Drusus delivered the eulogy while standing atop two "rostra". Augustus' body was coffin-bound and cremated on a pyre close to his mausoleum. It was proclaimed that Augustus joined the company of the gods as a member of the Roman pantheon.

Historian D. C. A. Shotter states that Augustus' policy of favoring the Julian family line over the Claudian might have afforded Tiberius sufficient cause to show open disdain for Augustus after the latter's death; instead, Tiberius was always quick to rebuke those who criticized Augustus. Shotter suggests that Augustus' deification obliged Tiberius to suppress any open resentment that he might have harbored, coupled with Tiberius' "extremely conservative" attitude towards religion. Also, historian R. Shaw-Smith points to letters of Augustus to Tiberius which display affection towards Tiberius and high regard for his military merits. Shotter states that Tiberius focused his anger and criticism on Gaius Asinius Gallus (for marrying Vipsania after Augustus forced Tiberius to divorce her), as well as toward the two young Caesars, Gaius and Lucius—instead of Augustus, the real architect of his divorce and imperial demotion.

Augustus' reign laid the foundations of a regime that lasted, in one form or another, for nearly fifteen hundred years through the ultimate decline of the Western Roman Empire and until the Fall of Constantinople in 1453. Both his adoptive surname, Caesar, and his title "Augustus" became the permanent titles of the rulers of the Roman Empire for fourteen centuries after his death, in use both at Old Rome and at New Rome. In many languages, "Caesar" became the word for "Emperor", as in the German "Kaiser" and in the Bulgarian and subsequently Russian "Tsar" (sometimes Csar or Czar). The cult of "Divus Augustus" continued until the state religion of the Empire was changed to Christianity in 391 by Theodosius I. Consequently, there are many excellent statues and busts of the first emperor. He had composed an account of his achievements, the "Res Gestae Divi Augusti", to be inscribed in bronze in front of his mausoleum. Copies of the text were inscribed throughout the Empire upon his death. The inscriptions in Latin featured translations in Greek beside it, and were inscribed on many public edifices, such as the temple in Ankara dubbed the "Monumentum Ancyranum", called the "queen of inscriptions" by historian Theodor Mommsen.

The "Res Gestae" is the only work to have survived from antiquity, though Augustus is also known to have composed poems entitled "Sicily", "Epiphanus", and "Ajax", an autobiography of 13 books, a philosophical treatise, and a written rebuttal to Brutus' "Eulogy of Cato". Historians are able to analyze excerpts of letters penned by Augustus, preserve in other works, to others for additional facts or clues about his personal life.

Many consider Augustus to be Rome's greatest emperor; his policies certainly extended the Empire's life span and initiated the celebrated "Pax Romana" or "Pax Augusta". The Roman Senate wished subsequent emperors to "be more fortunate than Augustus and better than Trajan". Augustus was intelligent, decisive, and a shrewd politician, but he was not perhaps as charismatic as Julius Caesar and was influenced on occasion by Livia (sometimes for the worse). Nevertheless, his legacy proved more enduring. The city of Rome was utterly transformed under Augustus, with Rome's first institutionalized police force, fire fighting force, and the establishment of the municipal prefect as a permanent office. The police force was divided into cohorts of 500 men each, while the units of firemen ranged from 500 to 1,000 men each, with 7 units assigned to 14 divided city sectors.

A "praefectus vigilum", or "Prefect of the Watch" was put in charge of the vigiles, Rome's fire brigade and police. With Rome's civil wars at an end, Augustus was also able to create a standing army for the Roman Empire, fixed at a size of 28 legions of about 170,000 soldiers. This was supported by numerous auxiliary units of 500 non-citizen soldiers each, often recruited from recently conquered areas.

With his finances securing the maintenance of roads throughout Italy, Augustus also installed an official courier system of relay stations overseen by a military officer known as the "praefectus vehiculorum". Besides the advent of swifter communication among Italian polities, his extensive building of roads throughout Italy also allowed Rome's armies to march swiftly and at an unprecedented pace across the country. In the year 6 Augustus established the "aerarium militare", donating 170 million sesterces to the new military treasury that provided for both active and retired soldiers.

One of the most enduring institutions of Augustus was the establishment of the Praetorian Guard in 27 BC, originally a personal bodyguard unit on the battlefield that evolved into an imperial guard as well as an important political force in Rome. They had the power to intimidate the Senate, install new emperors, and depose ones they disliked; the last emperor they served was Maxentius, as it was Constantine I who disbanded them in the early 4th century and destroyed their barracks, the Castra Praetoria.
Although the most powerful individual in the Roman Empire, Augustus wished to embody the spirit of Republican virtue and norms. He also wanted to relate to and connect with the concerns of the plebs and lay people. He achieved this through various means of generosity and a cutting back of lavish excess. In the year 29 BC, Augustus gave 400 sesterces (equal to 1/10 of a Roman pound of gold) each to 250,000 citizens, 1,000 sesterces each to 120,000 veterans in the colonies, and spent 700 million sesterces in purchasing land for his soldiers to settle upon. He also restored 82 different temples to display his care for the Roman pantheon of deities. In 28 BC, he melted down 80 silver statues erected in his likeness and in honor of him, an attempt of his to appear frugal and modest.
The longevity of Augustus' reign and its legacy to the Roman world should not be overlooked as a key factor in its success. As Tacitus wrote, the younger generations alive in AD 14 had never known any form of government other than the Principate. Had Augustus died earlier (in 23 BC, for instance), matters might have turned out differently. The attrition of the civil wars on the old Republican oligarchy and the longevity of Augustus, therefore, must be seen as major contributing factors in the transformation of the Roman state into a de facto monarchy in these years. Augustus' own experience, his patience, his tact, and his political acumen also played their parts. He directed the future of the Empire down many lasting paths, from the existence of a standing professional army stationed at or near the frontiers, to the dynastic principle so often employed in the imperial succession, to the embellishment of the capital at the emperor's expense. Augustus' ultimate legacy was the peace and prosperity the Empire enjoyed for the next two centuries under the system he initiated. His memory was enshrined in the political ethos of the Imperial age as a paradigm of the good emperor. Every Emperor of Rome adopted his name, Caesar Augustus, which gradually lost its character as a name and eventually became a title. The Augustan era poets Virgil and Horace praised Augustus as a defender of Rome, an upholder of moral justice, and an individual who bore the brunt of responsibility in maintaining the empire.

However, for his rule of Rome and establishing the principate, Augustus has also been subjected to criticism throughout the ages. The contemporary Roman jurist Marcus Antistius Labeo (d. AD 10/11), fond of the days of pre-Augustan republican liberty in which he had been born, openly criticized the Augustan regime. In the beginning of his "Annals", the Roman historian Tacitus (c. 56–c.117) wrote that Augustus had cunningly subverted Republican Rome into a position of slavery. He continued to say that, with Augustus' death and swearing of loyalty to Tiberius, the people of Rome simply traded one slaveholder for another. Tacitus, however, records two contradictory but common views of Augustus:

According to the second opposing opinion:
In a 2006 biography on Augustus, Anthony Everitt asserts that through the centuries, judgments on Augustus' reign have oscillated between these two extremes but stresses that:

Tacitus was of the belief that Nerva (r. 96–98) successfully "mingled two formerly alien ideas, principate and liberty". The 3rd-century historian Cassius Dio acknowledged Augustus as a benign, moderate ruler, yet like most other historians after the death of Augustus, Dio viewed Augustus as an autocrat. The poet Marcus Annaeus Lucanus (AD 39–65) was of the opinion that Caesar's victory over Pompey and the fall of Cato the Younger (95 BC–46 BC) marked the end of traditional liberty in Rome; historian Chester G. Starr, Jr. writes of his avoidance of criticizing Augustus, "perhaps Augustus was too sacred a figure to accuse directly."

The Anglo-Irish writer Jonathan Swift (1667–1745), in his "Discourse on the Contests and Dissentions in Athens and Rome", criticized Augustus for installing tyranny over Rome, and likened what he believed Great Britain's virtuous constitutional monarchy to Rome's moral Republic of the 2nd century BC. In his criticism of Augustus, the admiral and historian Thomas Gordon (1658–1741) compared Augustus to the puritanical tyrant Oliver Cromwell (1599–1658). Thomas Gordon and the French political philosopher Montesquieu (1689–1755) both remarked that Augustus was a coward in battle. In his "Memoirs of the Court of Augustus", the Scottish scholar Thomas Blackwell (1701–1757) deemed Augustus a Machiavellian ruler, "a bloodthirsty vindicative usurper", "wicked and worthless", "a mean spirit", and a "tyrant".

Augustus' public revenue reforms had a great impact on the subsequent success of the Empire. Augustus brought a far greater portion of the Empire's expanded land base under consistent, direct taxation from Rome, instead of exacting varying, intermittent, and somewhat arbitrary tributes from each local province as Augustus' predecessors had done. This reform greatly increased Rome's net revenue from its territorial acquisitions, stabilized its flow, and regularized the financial relationship between Rome and the provinces, rather than provoking fresh resentments with each new arbitrary exaction of tribute.

The measures of taxation in the reign of Augustus were determined by population census, with fixed quotas for each province. Citizens of Rome and Italy paid indirect taxes, while direct taxes were exacted from the provinces. Indirect taxes included a 4% tax on the price of slaves, a 1% tax on goods sold at auction, and a 5% tax on the inheritance of estates valued at over 100,000 sesterces by persons other than the next of kin.

An equally important reform was the abolition of private tax farming, which was replaced by salaried civil service tax collectors. Private contractors who collected taxes for the State were the norm in the Republican era. Some of them were powerful enough to influence the number of votes for men running for offices in Rome. These tax farmers called publicans were infamous for their depredations, great private wealth, and the right to tax local areas.

The use of Egypt's immense land rents to finance the Empire's operations resulted from Augustus' conquest of Egypt and the shift to a Roman form of government. As it was effectively considered Augustus' private property rather than a province of the Empire, it became part of each succeeding emperor's patrimonium. Instead of a legate or proconsul, Augustus installed a prefect from the equestrian class to administer Egypt and maintain its lucrative seaports; this position became the highest political achievement for any equestrian besides becoming Prefect of the Praetorian Guard. The highly productive agricultural land of Egypt yielded enormous revenues that were available to Augustus and his successors to pay for public works and military expeditions. During his reign the circus games resulted in the killing of 3,500 elephants.

The month of August (Latin: "Augustus") is named after Augustus; until his time it was called Sextilis (named so because it had been the sixth month of the original Roman calendar and the Latin word for six is "sex"). Commonly repeated lore has it that August has 31 days because Augustus wanted his month to match the length of Julius Caesar's July, but this is an invention of the 13th century scholar Johannes de Sacrobosco. Sextilis in fact had 31 days before it was renamed, and it was not chosen for its length (see Julian calendar). According to a "senatus consultum" quoted by Macrobius, Sextilis was renamed to honor Augustus because several of the most significant events in his rise to power, culminating in the fall of Alexandria, fell in that month.

On his deathbed, Augustus boasted "I found a Rome of bricks; I leave to you one of marble." Although there is some truth in the literal meaning of this, Cassius Dio asserts that it was a metaphor for the Empire's strength. Marble could be found in buildings of Rome before Augustus, but it was not extensively used as a building material until the reign of Augustus.

Although this did not apply to the Subura slums, which were still as rickety and fire-prone as ever, he did leave a mark on the monumental topography of the centre and of the Campus Martius, with the Ara Pacis (Altar of Peace) and monumental sundial, whose central gnomon was an obelisk taken from Egypt. The relief sculptures decorating the Ara Pacis visually augmented the written record of Augustus' triumphs in the "Res Gestae". Its reliefs depicted the imperial pageants of the praetorians, the Vestals, and the citizenry of Rome.

He also built the Temple of Caesar, the Baths of Agrippa, and the Forum of Augustus with its Temple of Mars Ultor. Other projects were either encouraged by him, such as the Theatre of Balbus, and Agrippa's construction of the Pantheon, or funded by him in the name of others, often relations (e.g. Portico of Octavia, Theatre of Marcellus). Even his Mausoleum of Augustus was built before his death to house members of his family. To celebrate his victory at the Battle of Actium, the Arch of Augustus was built in 29 BC near the entrance of the Temple of Castor and Pollux, and widened in 19 BC to include a triple-arch design.
After the death of Agrippa in 12 BC, a solution had to be found in maintaining Rome's water supply system. This came about because it was overseen by Agrippa when he served as aedile, and was even funded by him afterwards when he was a private citizen paying at his own expense. In that year, Augustus arranged a system where the Senate designated three of its members as prime commissioners in charge of the water supply and to ensure that Rome's aqueducts did not fall into disrepair.

In the late Augustan era, the commission of five senators called the "curatores locorum publicorum iudicandorum" (translated as "Supervisors of Public Property") was put in charge of maintaining public buildings and temples of the state cult. Augustus created the senatorial group of the "curatores viarum" (translated as "Supervisors for Roads") for the upkeep of roads; this senatorial commission worked with local officials and contractors to organize regular repairs.

The Corinthian order of architectural style originating from ancient Greece was the dominant architectural style in the age of Augustus and the imperial phase of Rome. Suetonius once commented that Rome was unworthy of its status as an imperial capital, yet Augustus and Agrippa set out to dismantle this sentiment by transforming the appearance of Rome upon the classical Greek model.

His biographer Suetonius, writing about a century after Augustus' death, described his appearance as: "... unusually handsome and exceedingly graceful at all periods of his life, though he cared nothing for personal adornment. He was so far from being particular about the dressing of his hair, that he would have several barbers working in a hurry at the same time, and as for his beard he now had it clipped and now shaved, while at the very same time he would either be reading or writing something ... He had clear, bright eyes ... His teeth were wide apart, small, and ill-kept; his hair was slightly curly and inclined to golden; his eyebrows met. His ears were of moderate size, and his nose projected a little at the top and then bent ever so slightly inward. His complexion was between dark and fair. He was short of stature, although Julius Marathus, his freedman and keeper of his records, says that he was five feet and nine inches (just under 5 ft. 7 in., or 1.70 meters, in modern height measurements), but this was concealed by the fine proportion and symmetry of his figure, and was noticeable only by comparison with some taller person standing beside him...", adding that "his shoes [were] somewhat high-soled, to make him look taller than he really was". Scientific analysis of traces of paint found in his official statues show that he most likely had light brown hair and eyes (his hair and eyes were depicted as the same color).

His official images were very tightly controlled and idealized, drawing from a tradition of Hellenistic royal portraiture rather than the tradition of realism in Roman portraiture. He first appeared on coins at the age of 19, and from about 29 BC "the explosion in the number of Augustan portraits attests a concerted propaganda campaign aimed at dominating all aspects of civil, religious, economic and military life with Augustus' person." The early images did indeed depict a young man, but although there were gradual changes his images remained youthful until he died in his seventies, by which time they had "a distanced air of ageless majesty". Among the best known of many surviving portraits are the Augustus of Prima Porta, the image on the Ara Pacis, and the Via Labicana Augustus, which shows him as a priest. Several cameo portraits include the Blacas Cameo and "Gemma Augustea".

Primary sources

Secondary source material


</doc>
<doc id="1274" url="https://en.wikipedia.org/wiki?curid=1274" title="Geography of Antarctica">
Geography of Antarctica

The geography of Antarctica is dominated by its south polar location and, thus, by ice. The Antarctic continent, located in the Earth's southern hemisphere, is centered asymmetrically around the South Pole and largely south of the Antarctic Circle. It is washed by the Southern (or Antarctic) Ocean or, depending on definition, the southern Pacific, Atlantic, and Indian Oceans. It has an area of more than 14 million km².

Some 98% of Antarctica is covered by the Antarctic ice sheet, the world's largest ice sheet and also its largest reservoir of fresh water. Averaging at least 1.6 km thick, the ice is so massive that it has depressed the continental bedrock in some areas more than 2.5 km below sea level; subglacial lakes of liquid water also occur (e.g., Lake Vostok). Ice shelves and rises populate the ice sheet on the periphery.

In September 2018, researchers at the National Geospatial-Intelligence Agency released a high resolution terrain map (detail down to the size of a car, and less in some areas) of Antarctica, named the "Reference Elevation Model of Antarctica" (REMA).

Physically, Antarctica is divided in two by Transantarctic Mountains close to the neck between the Ross Sea and the Weddell Sea. Western Antarctica and Eastern Antarctica correspond roughly to the eastern and western hemispheres relative to the Greenwich meridian. This usage has been regarded as Eurocentric by some, and the alternative terms Lesser Antarctica and Greater Antarctica (respectively) are sometimes preferred.

Lesser Antarctica is covered by the West Antarctic Ice Sheet. There has been some concern about this ice sheet, because there is a small chance that it will collapse. If it does, ocean levels would rise by a few metres in a very short period of time.

Volcanoes that occur underneath glacial ice sheets are known by the term "Glaciovolcanism", or subglacial volcanoes. An article published in 2017 claims that researchers from Edinburgh University recently discovered 91 new volcanoes below the Antarctic ice sheet, adding to the 47 volcanoes that were already known. As of today, there have been 138 possible volcanoes identified in West Antarctica. There is limited knowledge about West Antarctic Volcanoes due to the presence of the West Antarctic Ice Sheet, which heavily covers the West Antarctic Rift System -- a likely hub for volcanic activity. Researchers find it difficult to properly identify volcanic activity due to the comprehensive ice covering.

East Antarctica is significantly larger than West Antarctica, and similarly remains widely unexplored in terms of its volcanic potential. While there are some indications that there is volcanic activity under the East Antarctic Ice Sheet, there is not a significant amount of present information on the subject.

Mount Erebus is one of the most notable cites in the study of Antarctic Volcanism, in that it is the southernmost historically active volcanic cite on the planet.

Deception Island is another active Antarctic volcano. It is one of the most protected areas in the Antarctic, given its situation between the South Shetland Islands and the Antarctic Peninsula. As the most active volcano in the Antarctic peninsula, it has been studied closely since its initial discovery in 1820.

There are four volcanoes on the mainland of Antarctica that are
considered to be active on the basis of observed fumarolic activity or 
"recent" tephra deposits: 
Mount Melbourne (2,730 m) (74°21'S., 164°42'E.), a stratovolcano; 
Mount Berlin (3,500 m) (76°03'S., 135°52'W.), a stratovolcano; 
Mount Kauffman (2,365 m) (75°37'S., 132°25'W.), a stratovolcano; and 
Mount Hampton (3,325 m) (76°29'S., 125°48'W.), a volcanic caldera.
Several volcanoes on offshore islands have records of historic activity.
Mount Erebus (3,795 m), a stratovolcano on
Ross Island with 10 known eruptions and 1 suspected eruption.
On the opposite side of the continent, 
Deception Island
(62°57'S., 60°38'W.), a volcanic caldera with 10 known
and 4 suspected eruptions, have been the most active.
Buckle Island in the Balleny Islands (66°50'S., 163°12'E.), 
Penguin Island (62°06'S., 57°54'W.), 
Paulet Island (63°35'S., 55°47'W.), and 
Lindenberg Island (64°55'S., 59°40'W.) are also 
considered to be active. In 2017, the researchers of Edinburgh University discovered 91 underwater volcanoes under West Antarctica.

The definition of Glaciovolcanism is “the interactions of magma with ice in all its forms, including snow, firn and any meltwater.” It defines a special field of volcanic that is specifically centered around ice and ice melt. This field of science is less than 100 years old, and thus continuously makes new discoveries. Glaciovolcanism is characterized by three kinds of eruptions: sub-glacial eruptions, supraglacial volcanism, and ice-marginal volcanism.

The study of glaciovolcanism is vital to the understanding of ice sheet formation. It is also a valuable tool to predict volcanic hazards, such as the ash hazard following the Eyjafjallajökull eruption in Iceland.

The Marie Byrd Land is an incredibly large portion of West Antarctica, consisting of the Area below the Antarctic Peninsula. The Marie Byrd land is a large formation of volcanic rock, characterized by 18 exposed and subglacial volcanoes. 16 of the 18 volcanoes are entirely covered by the antarctic ice sheet. There have been no eruptions recorded from any of the volcanoes in this area, however scientists believe that some of the volcanoes may be potentially active.
Scientists and researchers debate whether or not the 138 identified possible volcanoes are active or dormant. It is very hard to definitively say, given that many of these volcanic structures are buried underneath several kilometers of ice. However, ash layers within the West Antarctic Ice Sheet, as well as deformations in the ice surface indicate that the West Antarctic Rift System could be active and contain erupting volcanoes. Additionally, seismic activity in the region hints at magma movement beneath the crust, a sign of volcanic activity. Despite this, however, there is not yet definitive evidence of presently active volcanoes.

Subglacial volcanism is often characterized by ice melt and subglaical water. Though there are other sources of subglacial water, such as geothermal heat, it almost always is a condition of volcanism. Scientists remain uncertain about the presence of water underneath the West Antarctic Ice Sheet, with some claiming to have found evidence indicating the existence.

In West Antarctica's Marie Byrd Land, volcanoes are typically composed of alkaline and basaltic lava. Sometimes, the volcanoes are entirely basaltic in composition. Due to the geographic similarity of the Marie Byrd Land, it is believed that the volcanoes in the West African Rift System are also composed of basalt.

Above-ice basaltic volcanoes, also known as subaerial basaltic volcanoes, generally form in tall, broad cone shapes. Since they are formed from repeated piling of liquid magma sourced from the center, they spread widely and grow upwards relatively slowly. However, West Antarctic Volcanoes form underneath ice sheets, and are thus categorized as subglacial volcanoes. Subglacial volcanoes that are monogenetic are far more narrow, steeper, flat topped structures. Polygenetic subglacial volcanoes have a wider variety of shapes and sizes due to being made up of many different eruptions. Often, they look more cone shaped, like statovolcanoes.

Little has been studied about the implications of volcanic ash from eruptions within the Antarctic Circle. It is likely that an eruption at lower latitudes would cause global health and aviation hazards due to ash disbursement. The clockwise air circulation around the low pressure system at the South Pole forces air upwards, hypothetically sending ash upwards towards the Stratospheric jet streams, and thus quickly dispersing it throughout the globe.

Recently, in 2017, a study found evidence of subglacial volcanic activity within the West Antarctic Ice Sheet. This activity poses a threat to the stability of the Ice Sheet, as volcanic activity leads to increased melting. This could possibly plunge the West Antarctic Ice Sheet into a positive feedback loop of rising temperatures and increased melting.

There are three vast canyons that run for hundreds of kilometers, cutting through tall mountains. None of the canyons are visible at the snow-covered surface of the continent since they are buried under hundreds of meters of ice. The largest of the canyons is called Foundation Trough and is over 350km long and 35km wide. The Patuxent Trough is more than 300km long and over 15km wide, while the Offset Rift Basin is 150km long and 30km wide. These three troughs all lie under and cross the so-called "ice divide" - the high ice ridge that runs all the way from the South Pole out towards the coast of West Antarctica.

West Antarctica is the smaller part of the continent, divided into:



Larger ice shelves are:
For all ice shelves see List of Antarctic ice shelves.

For a list of all Antarctic islands see List of Antarctic and sub-Antarctic islands.

East Antarctica is the larger part of the continent, both the South Magnetic Pole and geographic South Pole are situated here. Divided into:



Larger ice shelves are:
For all ice shelves see List of Antarctic ice shelves.

For a list of all Antarctic islands see List of Antarctic and sub-Antarctic islands.

Seven nations have made official Territorial claims in Antarctica.






</doc>
<doc id="1279" url="https://en.wikipedia.org/wiki?curid=1279" title="Transport in Antarctica">
Transport in Antarctica

Transport in Antarctica has transformed from explorers crossing the isolated remote area of Antarctica by foot to a more open era due to human technologies enabling more convenient and faster transport, predominantly by air and water, as well as land. 
Transportation technologies on a remote area like Antarctica need to be able to deal with extremely low temperatures and continuous winds to ensure the travelers' safety. Due to the fragility of the Antarctic environment, only a limited amount of transport movements can take place and sustainable transportation technologies have to be used to reduce the ecological footprint.
The infrastructure of land, water and air transport needs to be safe and sustainable. 
Currently thousands of tourists and hundreds of scientists a year depend on the Antarctic transportation system.

Winds continuously blow snow on roads in Antarctica.

The South Pole Traverse (McMurdo–South Pole highway) is approximately long and links the United States' McMurdo Station on the coast to the Amundsen–Scott South Pole Station. It was constructed by leveling snow and filling in crevasses, but is not paved. There are flags to mark the route.

Also, the United States Antarctic Program maintains two ice roads during the austral summer. One provides access to Pegasus Field on the Ross Ice Shelf. The ice road between Pegasus Field and McMurdo Station is about 14 miles. The other road provides access to the Ice Runway, which is on sea ice. The road between the Ice Runway and McMurdo Station varies in length from year to year depending on many factors, including ice stability. These roads are critical for resupplying McMurdo Station, Scott Base, and Amundsen–Scott South Pole Station.

The scarcity and poor quality of road infrastructure limits land transportation by conventional vehicles.

A normal car on tires has very limited capability for Antarctic conditions. Scientific bases are often built on snow free areas (oases) close to the
ocean. Around these stations and on a hard packed snow or ice, tire based vehicles can drive but on deeper and softer snow, a normal tire based vehicle cannot travel. Due to these limitation vehicles on belts have been the preferred option in Antarctica. In 1997 two specialized cars with very large tires running tire pressure as low as 1.5psi/0.1bar travelled onto the high Antarctica Plateau, giving strong indication that tire based vehicles could be an option for efficient travelling in Antarctica.

Mawson Station started using classic Volkswagen Beetles, the first production cars to be used in Antarctica. The first of these was named "Antarctica 1".

In December 1997 into February 1998 two AT44, 4x4 cars (built in Iceland by Arctic Trucks with tire size of 44-inch tall) joined an expedition by the Swedish Polar Institution (SWEA). The cars got used to transport people and supplies from the Ice shelf to WASA station, to perform scanning of the snow and support a drilling expedition to on the Antarctica Plateau 76°S 8°03'W. This is the first time tire based vehicles successfully travel on the Antarctica high plateau.

In 2006 a team of six people took part in the Ice Challenger Expedition. Travelling in a specially designed six wheel drive vehicle, the team completed the journey from the Antarctic coast at Patriot Hills to the geographic South Pole in 69 hours. In doing so they easily beat the previous record of 24 days. They arrived at the South Pole on December 12, 2005.

The team members on that expedition were Andrew Regan, Jason De Carteret, Andrew Moon, Richard Griffiths, Gunnar Egilsson and Andrew Miles. The expedition successfully showed that wheeled transport on the continent is not only possible but also often more practical. The expedition also hoped to raise awareness about global warming and climate change.

From start of December 2008 into February 2009, four AT44, 4x4 cars were used to support a ski race by Amundsen Omega 3, from S82° 41' E17° 43' to South Pole. A film was made of this race by BBC called "On Thin Ice" with Ben Fogle and James Cracknell. The cars started from Novo airbase at S70° 49' E11° 38', establish a route onto the plateau through the crevasse areas in the Shcherbakov Mountain Range driving nearly 1500 km to the start line of the ski race. For the return journey each car covered between 5400 and 5800 km with one fuel depot on the way.

From 2008 to date (Dec 2015) tire based cars, AT44 4x4 and AT44 6x6 have been used every season to support various NGO and scientific expedition/projects, supporting flights, fuel drops, filming, skiers, biker, a tractor, collecting snow samples and more. The combined distance covered on the Antarctica Plateau is over 220 thousand km and even though towing capacity is much lower than for most belt based vehicles, the tire based cars multiply the travel speed and use only a fraction of the fuel making this an option for some expeditions/projects.

A second expedition led by Andrew Regan and Andrew Moon departed in November 2010. The Moon-Regan Trans Antarctic Expedition this time traversed the entire continent twice, using two six-wheel-drive vehicles and a Concept Ice Vehicle designed by Lotus. This time the team used the expedition to raise awareness about the global environmental importance of the Antarctic region and to show that biofuel can be a viable and environmentally friendly option.

Antarctica's only harbour is at McMurdo Station. Most coastal stations have offshore anchorages, and supplies are transferred from ship to shore by small boats, barges, and helicopters. A few stations have a basic wharf facility. All ships at port are subject to inspection in accordance with Article 7, Antarctic Treaty. Offshore anchorage is sparse and intermittent, but poses no problem to sailboats designed for the ice, typically with lifting keels and long shorelines.
McMurdo Station (), Palmer Station (); government use only except by permit (see Permit Office under "Legal System"). A number of tour boats, ranging from large motorized vessels to small sailing yachts, visit the Antarctic Peninsula during the summer months (January–March). Most are based in Ushuaia, Argentina.

Transport in Antarctica takes place by air, using fixed-wing aircraft and helicopters.
Runways and helicopter pads have to be kept snow free to ensure safe take off and landing conditions.

Antarctica has 20 airports, but there are no developed public-access airports or landing facilities. Thirty stations, operated by 16 national governments party to the Antarctic Treaty, have landing facilities for either helicopters and/or fixed-wing aircraft; commercial enterprises operate two additional air facilities.

Helicopter pads are available at 27 stations; runways at 15 locations are gravel, sea-ice, blue-ice, or compacted snow suitable for landing wheeled, fixed-wing aircraft; of these, one is greater than 3 km in length, six are between 2 km and 3 km in length, 3 are between 1 km and 2 km in length, three are less than 1 km in length, and two are of unknown length; snow surface skiways, limited to use by ski-equipped, fixed-wing aircraft, are available at another 15 locations; of these, four are greater than 3 km in length, three are between 2 km and 3 km in length, two are between 1 km and 2 km in length, two are less than 1 km in length, and data is unavailable for the remaining four.

Antarctic airports are subject to severe restrictions and limitations resulting from extreme seasonal and geographic conditions; they do not meet ICAO standards, and advance approval from the respective governmental or nongovernmental operating organization is required for landing (1999 est.) Flights to the continent in the permanent darkness of the winter are normally only undertaken in an emergency, with burning barrels of fuel to outline a runway. On September 11, 2008, a United States Air Force C-17 Globemaster III successfully completed the first landing in Antarctica using night-vision goggles at Pegasus Field.

In April 2001 an emergency evacuation of Dr. Ronald Shemenski was needed from Amundsen–Scott South Pole Station when he contracted pancreatitis. Three C-130 Hercules were called back before their final leg because of weather. Organizers then called on Kenn Borek Air based in Calgary, Alberta. Two de Havilland Twin Otters were dispatched out of Calgary with one being back-up. Twin Otters are specifically designed for the Canadian north and Kenn Borek Air's motto is "Anywhere, Anytime, World-Wide". The mission was a success but not without difficulties and drawbacks. Ground crews needed to create a 2 km runway with tracked equipment not designed to operate in the low temperatures at that time of year, the aircraft controls had to be "jerry-rigged" when the flaps were frozen in position after landing, and instruments were not reliable because of the cold. When they saw a "faint pink line on the horizon" they knew they were going in the right direction. This was the first rescue from the South Pole during winter. Canada honoured the Otter crew for bravery.




</doc>
<doc id="1285" url="https://en.wikipedia.org/wiki?curid=1285" title="Geography of Alabama">
Geography of Alabama

The geography of Alabama describes a state in the Southeastern United States in North America. Alabama is 30th in size and borders four U.S. states: Mississippi, Tennessee, Georgia, and Florida. It also borders the Gulf of Mexico.

Extending entirely across the state of Alabama for about northern boundary, and in the middle stretching farther south, is the Cumberland Plateau, or Tennessee Valley region, broken into broad tablelands by the dissection of rivers. In the northern part of this plateau, west of Jackson county, there are about of level highlands from above sea level. South of these highlands, occupying a narrow strip on each side of the Tennessee River, is a country of gentle rolling lowlands varying in elevation from . To the northeast of these highlands and lowlands is a rugged section with steep mountain-sides, deep narrow coves and valleys, and flat mountain-tops. Its elevations range from . In the remainder of this region, the southern portion, the most prominent feature is "Little Mountain", extending about from east to west between two valleys, and rising precipitously on the north side above them or above the sea.

Adjoining the Cumberland Plateau region on the southeast is the Appalachian Valley (locally known as Coosa Valley) region, which is the southern extremity of the Appalachian Mountains, and occupies an area within the state of about . This is a limestone belt with parallel hard rock ridges left standing by erosion to form mountains. Although the general direction of the mountains, ridges, and valleys is northeast and southwest, irregularity is one of the most prominent characteristics. In the northeast are several flat-topped mountains, of which Raccoon and Lookout are the most prominent, having a maximum elevation near the Georgia line of little more than and gradually decreasing in height toward the southwest, where Sand Mountain is a continuation of Raccoon. South of these the mountains are marked by steep northwest sides, sharp crests and gently sloping southeast sides.

Southeast of the Appalachian Valley region, the Piedmont Plateau also crosses the Alabama border from the N.E. and occupies a small triangular-shaped section of which Randolph and Clay counties, together with the northern part of Tallapoosa and Chambers, form the principal portion. Its surface is gently undulating and has an elevation of about above sea level. The Piedmont Plateau is a lowland worn down by erosion on hard crystalline rocks, then uplifted to form a plateau.

The remainder of the state is occupied by the "Coastal Plain". This is crossed by foothills and rolling prairies in the central part of the state, where it has a mean elevation of about , becomes lower and more level toward the southwest, and in the extreme south is flat and but slightly elevated above the sea.
The Cumberland Plateau region is drained to the west-northwest by the Tennessee River and its tributaries; all other parts of the state are drained to the southwest. In the Appalachian Valley region the Coosa River is the principal river; and in the Piedmont Plateau, the Tallapoosa River. In the Coastal Plain are the Tombigbee River in the west, the Alabama River (formed by the Coosa and Tallapoosa) in the western central, and in the east the Chattahoochee River, which forms almost half of the Georgia boundary. The Tombigbee and Alabama rivers unite near the southwest corner of the state, their waters discharging into Mobile Bay by the Mobile and Tensas rivers. The Black Warrior River is a considerable stream which joins the Tombigbee from the east.

The valleys in the north and northeast are usually deep and narrow, but in the Coastal Plain they are broad and in most cases rise in three successive terraces above the stream. The harbour of Mobile was formed by the drowning of the lower part of the valley of the Alabama and Tombigbee rivers as a result of the sinking of the land here, such sinking having occurred on other parts of the Gulf coast.

The fauna and flora of Alabama are similar to those of the Gulf states in general and have no distinctive characteristics. However, the Mobile River system has a high incidence of endemism among freshwater mollusks and biodiversity is high.

In Alabama, vast forests of pine constitute the largest proportion of the state's forest growth. There is also an abundance of cypress, hickory, oak, populus, and eastern redcedar trees. In other areas, hemlock growths in the north and southern white cedar in the southwest. Other native trees include ash, hackberry, and holly. In the Gulf region of the state grow various species of palmetto and palm. In Alabama there are more than 150 shrubs, including mountain laurel and rhododendron. Among cultivated plants are wisteria and camellia.

While in the past the state enjoyed a variety of mammals such as plains bison, eastern elk, North American cougar, bear, and deer, only the white-tailed deer remains abundant. Still fairly common are the bobcat, American beaver, muskrat, raccoon, Virginia opossum, rabbit, squirrel, red and gray foxes, and long-tailed weasel. Coypu and nine-banded armadillo have been introduced to the state and now also common.

Alabama's birds include golden and bald eagles, osprey and other hawks, yellow-shafted flickers, and black-and-white warblers. Game birds include bobwhite quail, duck, wild turkey, and goose. Freshwater fish such as bream, shad, bass, and sucker are common. Along the Gulf Coast there are seasonal runs of tarpon, pompano, red drum, and bonito.

The U.S. Fish and Wildlife Service lists as endangered 99 animals, fish, and birds, and 18 plant species. The endangered animals include the Alabama beach mouse, gray bat, Alabama red-bellied turtle, fin and humpback whales, bald eagle, and wood stork.

American black bear, racking horse, yellow-shafted flicker, wild turkey, Atlantic tarpon, largemouth bass, southern longleaf pine, eastern tiger swallowtail, monarch butterfly, Alabama red-bellied turtle, Red Hills salamander, camellia, oak-leaf hydrangea, peach, pecan, and blackberry are Alabama's state symbols.

The climate of Alabama is humid subtropical.

The heat of summer is tempered in the south by the winds from the Gulf of Mexico, and in the north by the elevation above the sea. The average annual temperature is highest in the southwest along the coast, and lowest in the northeast among the highlands. Thus at Mobile the annual mean is , the mean for the summer , and for the winter ; and at Valley Head, in De Kalb county, the annual mean is , the mean for the summer , and for the winter . At Montgomery, in the central region, the average annual temperature is , with a winter average of , and a summer average of . The average winter minimum for the entire state is , and there is an average of 35 days in each year in which the thermometer falls below the freezing-point. At extremely rare intervals the thermometer has fallen below zero (-18 °C), as was the case in the remarkable cold wave of the 12th-13 February 1899, when an absolute minimum of was registered at Valley Head. The highest temperature ever recorded was in Talladega county in 1902.

The amount of precipitation is greatest along the coast (62 inches/1,574 mm) and evenly distributed through the rest of the state (about 52 inches/1,320 mm). During each winter there is usually one fall of snow in the south and two in the north; but the snow quickly disappears, and sometimes, during an entire winter, the ground is not covered with snow. Heavy snowfall can occur, such as during the New Year's Eve 1963 snowstorm and the 1993 Storm of the Century. Hailstorms occur occasionally in the spring and summer, but are seldom destructive. Heavy fogs are rare, and are confined chiefly to the coast. Thunderstorms occur throughout the year - they are most common in the summer, but most severe in the spring and fall, when destructive winds and tornadoes occasionally occur. The prevailing winds are from the news. Hurricanes are quite common in the state, especially in the southern part, and major hurricanes occasionally strike the coast which can be very destructive.

As regards its soil, Alabama may be divided into four regions. Extending from the Gulf northward for about is the outer belt of the Coastal Plain, also called the "Timber Belt," whose soil is sandy and poor, but responds well to fertilization. North of this is the inner lowland of the Coastal Plain, or the "Black Prairie," which includes some and seventeen counties. It receives its name from its soil (weathered from the weak underlying limestone), which is black in colour, almost destitute of sand and loam, and rich in limestone and marl formations, especially adapted to the production of cotton; hence the region is also called the "Cotton Belt." Between the "Cotton Belt" and the Tennessee Valley is the mineral region, the "Old Land" area—a region of resistant rocks—whose soils, also derived from weathering in silu, are of varied fertility, the best coming from the granites, sandstones and limestones, the poorest from the gneisses, schists and slates. North of the mineral region is the "Cereal Belt," embracing the Tennessee Valley and the counties beyond, whose richest soils are the red clays and dark loams of the river valley; north of which are less fertile soils, produced by siliceous and sandstone formations.

Wetumpka is the home of "Alabama's greatest natural disaster." A -wide meteorite hit the area about 80 million years ago. The hills just east of downtown showcase the eroded remains of the wide impact crater that was blasted into the bedrock, with the area labeled the Wetumpka crater or astrobleme ("star-wound") for the concentric rings of fractures and zones of shattered rock can be found beneath the surface. In 2002, Christian Koeberl with the Institute of Geochemistry University of Vienna published evidence and established the site as an internationally recognized impact crater.

Alabama includes several types of public use lands. These include four national forests and one national preserve within state borders that provide over 25% of the state's public recreation land.





</doc>
<doc id="1286" url="https://en.wikipedia.org/wiki?curid=1286" title="List of governors of Alabama">
List of governors of Alabama

The Governor of Alabama is the chief executive of the U.S. state of Alabama. The governor is the head of the executive branch of Alabama's state government and is charged with enforcing state laws.

There have officially been 54 governors of the state of Alabama; this official numbering skips acting and military governors. The first governor, William Wyatt Bibb, served as the only governor of the Alabama Territory. Five people have served as acting governor, bringing the total number of people serving as governor to 59, spread over 63 distinct terms. Four governors have served multiple non-consecutive terms: Bibb Graves, Jim Folsom, and Fob James each served two, and George Wallace served three non-consecutive periods. Officially, these non-consecutive terms are numbered only with the number of their first term. William D. Jelks also served non-consecutive terms, but his first term was in an acting capacity.

The longest-serving governor was George Wallace, who served 16 years over four terms. The shortest term for a non-acting governor was that of Hugh McVay, who served four and a half months after replacing the resigning Clement Comer Clay. Lurleen Wallace, wife of George Wallace, was the first woman to serve as governor of Alabama, and the third woman to serve as governor of any state. The current governor is Republican Kay Ivey, who took office on April 10, 2017 following Governor Robert J. Bentley's court-mandated resignation following a guilty plea-deal amidst a corruption scandal. She is the second female governor of Alabama.

Alabama Territory was formed on March 3, 1817, from Mississippi Territory. It had only one governor appointed by the President of the United States before it became a state; he became the first state governor.

Alabama was admitted to the Union on December 14, 1819. It seceded from the Union on January 11, 1861, and was a founding member of the Confederate States of America on February 4, 1861. Following the end of the American Civil War, Alabama during Reconstruction was part of the Third Military District, which exerted some control over governor appointments and elections. Alabama was readmitted to the Union on July 14, 1868.

The first Alabama Constitution, ratified in 1819, provided that a governor be elected every two years, limited to serve no more than four out of every six years. This limit remained in place until the constitution of 1868, which simply allowed governors to serve terms of two years. The current constitution of 1901 increased terms to four years, but prohibited governors from succeeding themselves. Amendment 282 to the constitution, passed in 1968, allowed governors to succeed themselves once; a governor serving two consecutive terms can run again after waiting out the next term. The constitution had no set date for the commencement of a governor's term until 1901, when it was set at the first Monday after the second Tuesday in the January following an election. However, the Alabama Supreme Court ruled in 1911 that a governor's term ends at midnight at the end of Monday, and the next governor's term begins the next day, regardless of if they were sworn in on Monday.

The office of lieutenant governor was created in 1868, abolished in 1875, and recreated in 1901. According to the current constitution, should the governor be out of the state for more than 20 days, the lieutenant governor becomes acting governor, and if the office of governor becomes vacant the lieutenant governor ascends to the governorship. Earlier constitutions said the powers of the governor devolved upon the successor, rather than them necessarily becoming governor, but the official listing includes these as full governors. The governor and lieutenant governor are not elected on the same ticket.

Alabama was a strongly Democratic state before the Civil War, electing only candidates from the Democratic-Republican and Democratic parties. It had two Republican governors following Reconstruction, but after the Democratic Party re-established control, 112 years passed before voters chose another Republican.




</doc>
<doc id="1288" url="https://en.wikipedia.org/wiki?curid=1288" title="Apocrypha">
Apocrypha

Apocrypha are works, usually written, of unknown authorship or of doubtful origin. Biblical apocrypha is a set of texts included in the Latin Vulgate and Septuagint but not in the Hebrew Bible. While Catholic tradition considers some of these texts to be deuterocanonical, Protestants consider them apocryphal. Thus, Protestant bibles do not include the books within the Old Testament but have often included them in a separate section, usually called the Apocrypha. Other non-canonical apocryphal texts are generally called pseudepigrapha, a term that means "false attribution".

The word's origin is the Medieval Latin adjective "apocryphus", "secret, or non-canonical", from the Greek adjective ("apokryphos"), "obscure", from the verb ("apokryptein"), "to hide away".

The term "Apocrypha" commonly appears in Christian religious contexts concerning disagreements about biblical canonicity. Apocryphal writings are a class of documents rejected by some as being either pseudepigraphical or unworthy to be properly called Scripture, though, as with other writings, they may sometimes be referenced for support, such as the lost Book of Jasher. While writings that are now accepted by Christians as Scripture were recognized as being such by various believers early on, the establishment of a largely settled uniform canon was a process of centuries, and what the term "canon" (as well as "apocrypha") precisely meant also saw development. The canonical process took place with believers recognizing writings as being inspired by God from known or accepted origins, subsequently being followed by official affirmation of what had become largely established through the study and debate of the writings. The Catholic Church provided its first dogmatic definition of its entire canon in 1546, which put a stop to doubts and disagreements about the status of the Apocrypha. The leader of the Protestant Reformation, Martin Luther, like the Catholic Church father Jerome (and certain others), favored the Masoretic canon for the Old Testament, excluding apocryphal books in his non-binding canon as unworthy to be properly called Scripture, but included most of them in a separate section, as per Jerome. Luther did not include the deuterocanonical books in his Old Testament, terming them "Apocrypha, that are books which are not considered equal to the Holy Scriptures, but are useful and good to read."

The Eastern Orthodox Church accepts a few more books than appear in the Catholic canon.

The word "apocryphal" () was first applied to writings which were kept secret because they were the vehicles of esoteric knowledge considered too profound or too sacred to be disclosed to anyone other than the initiated. For example, the disciples of the Gnostic Prodicus boasted that they possessed the secret () books of Zoroaster. The term in general enjoyed high consideration among the Gnostics (see Acts of Thomas, pp. 10, 27, 44).

Sinologist Anna Seidel refers to texts and even items produced by ancient Chinese sages as apocryphal and studied their uses during Six Dynasties China (A.D. 220 to 589). These artifacts were used as symbols legitimizing and guaranteeing the Emperor's Heavenly Mandate. Examples of these include talismans, charts, writs, tallies, and registers. The first examples were stones, jade pieces, bronze vessels and weapons, but came to include talismans and magic diagrams. From their roots in Zhou era China (1066 to 256 B.C.) these items came to be surpassed in value by texts by the Han dynasty (206 B.C. to A.D. 220). Most of these texts have been destroyed as Emperors, particularly during the Han dynasty, collected these legitimizing objects and proscribed, forbade and burnt nearly all of them to prevent them from falling into the hands of political rivals. It is therefore fitting with the Greek root of the word, as these texts were obviously hidden away to protect the ruling Emperor from challenges to his status as Heaven's choice as sovereign.

"Apocrypha" was also applied to writings that were hidden not because of their divinity but because of their questionable value to the church. Many in Protestant traditions cite Revelation 22:18–19 as a potential curse for those who attach any canonical authority to extra-biblical writings such as the Apocrypha. However, a strict explanation of this text would indicate it was meant for only the Book of Revelation. Rv.22:18–19f. (KJV) states: "For I testify unto every man that heareth the words of the prophecy of this book, If any man shall add unto these things, God shall add unto him the plagues that are written in this book: And if any man shall take away from the words of the book of this prophecy, God shall take away his part out of the book of life, and out of the holy city, and from the things which are written in this book." In the context of Revelation, a book predicting the future atrocities of man, it means that God will strip them of the goodness of life ("from the things written in this book") and that they will be removed from heaven ("out of the book of life"). The early Christian theologian Origen, in his "Commentaries on Matthew", distinguishes between writings which were read by the churches and apocryphal writings: ("writing not found on the common and published books in one hand, actually found on the secret ones on the other"). The meaning of αποκρυφος is here practically equivalent to "excluded from the public use of the church", and prepares the way for an even less favourable use of the word.

In general use, the word "apocrypha" came to mean "false, spurious, bad, or heretical." This meaning also appears in Origen's prologue to his commentary on the Song of Songs, of which only the Latin translation survives: "De scripturis his, quae appellantur apocriphae, pro eo quod multa in iis corrupta et contra fidem veram inveniuntur a maioribus tradita non placuit iis dari locum nec admitti ad auctoritatem." "Concerning these scriptures, which are called apocryphal, for the reason that many things are found in them corrupt and against the true faith handed down by the elders, it has pleased them that they not be given a place nor be admitted to authority."

Other uses of "apocrypha" developed over the history of Western Christianity. The Gelasian Decree (generally held now as being the work of an anonymous scholar between 519 and 553) refers to religious works by church fathers Eusebius, Tertullian and Clement of Alexandria as apocrypha. Augustine defined the word as meaning simply "obscurity of origin," implying that any book of unknown authorship or questionable authenticity would be considered apocryphal. On the other hand, Jerome (in "Protogus Galeatus") declared that all books outside the Hebrew canon were apocryphal. In practice, Jerome treated some books outside the Hebrew canon as if they were canonical, and the Western Church did not accept Jerome's definition of apocrypha, instead retaining the word's prior meaning ("see: Deuterocanon"). As a result, various church authorities labeled different books as apocrypha, treating them with varying levels of regard.
Origen (who stated that "the canonical books, as the Hebrews have handed them down, are twenty-two"), Clement and others cited some apocryphal books as "scripture," "divine scripture," "inspired," and the like. On the other hand, teachers connected with Palestine and familiar with the Hebrew canon excluded from the canon all of the Old Testament not found there. This view is reflected in the canon of Melito of Sardis, and in the prefaces and letters of Jerome. A third view was that the books were not as valuable as the canonical scriptures of the Hebrew collection, but were of value for moral uses, as introductory texts for new converts from paganism, and to be read in congregations. They were referred to as "ecclesiastical" works by Rufinus.

These three opinions regarding the apocryphal books prevailed until the Protestant Reformation, when the idea of what constitutes canon became a matter of primary concern for Roman Catholics and Protestants alike. In 1546 the Catholic Council of Trent reconfirmed the canon of Augustine, dating to the second and third centuries, declaring "He is also to be anathema who does not receive these entire books, with all their parts, as they have been accustomed to be read in the Catholic Church, and are found in the ancient editions of the Latin Vulgate, as sacred and canonical." The whole of the books in question, with the exception of 1 Esdras and 2 Esdras and the Prayer of Manasseh, were declared canonical at Trent. The Protestants, in comparison, were diverse in their opinion of the deuterocanon early on. Some considered them divinely inspired, others rejected them. Anglicans took a position between the Catholic Church and the Protestant Churches; they kept them as Christian intertestamental readings and a part of the Bible, but no doctrine should be based on them. John Wycliffe, a 14th-century Christian Humanist, had declared in his biblical translation that "whatever book is in the Old Testament besides these twenty-five shall be set among the apocrypha, that is, without authority or belief." Nevertheless, his translation of the Bible included the apocrypha and the Epistle of the Laodiceans.

Martin Luther did not class apocryphal books as being Scripture, but in both the German (1534) translation of the Bible, the apocrypha are published in a separate section from the other books, although the Lutheran and Anglican lists are different. In some editions (like the Westminster), readers were warned that these books were not "to be any otherwise approved or made use of than other human writings." A milder distinction was expressed elsewhere, such as in the "argument" introducing them in the Geneva Bible, and in the Sixth Article of the Church of England, where it is said that "the other books the church doth read for example of life and instruction of manners," though not to establish doctrine. Among some other Protestants, the term "apocryphal" began to take on extra or altered connotations: not just of dubious authenticity, but having spurious or false content, not just obscure but having hidden or suspect motives. Protestants were (and are) not unanimous in adopting those meanings. The Church of England agreed, and that view continues today throughout the Lutheran Church, the worldwide Anglican Communion, and many other denominations. Whichever implied meaning is intended, "Apocrypha" was (and is) used primarily by Protestants, in reference to the books of questioned canonicity. Catholics and Orthodox sometimes avoid using the term in contexts where it might be disputatious or be misconstrued as yielding on the point of canonicity. Thus the respect accorded to apocryphal books varied between Protestant denominations. Most Protestant published Bibles that include the apocryphal books will relocate them into a separate section (rather like an appendix), so as not to intermingle them with their canonical books.

According to the Orthodox Anglican Church:
With few exceptions, the 66-book Protestant canon (such as listed in the Westminster Confession of 1646) has been well established for centuries, and with many today contending against the Apocrypha using various arguments.

The adjective "apocryphal" is commonly used in modern English to refer to any text or story considered to be of dubious veracity or authority, although it may contain some moral truth. In this broader metaphorical sense, the word suggests a claim that is in the nature of folklore, factoid or urban legend.

Although Orthodox Jews believe in the exclusive canonization of the current 24 books in the Tanakh, they also consider the Oral Torah to be authoritative, which they believe was handed down from Moses. The Sadducees—unlike the Pharisees but like the Samaritans—seem to have maintained an earlier and smaller number of texts as canonical, preferring to hold to only what was written in the Law of Moses (making most of the presently accepted canon, both Jewish and Christian, "apocryphal" in their eyes). Certain circles in Judaism, such as the Essenes in Judea and the Therapeutae in Egypt, were said to have a secret literature (see Dead Sea scrolls). Other traditions maintained different customs regarding canonicity. The Ethiopic Jews, for instance, seem to have retained a spread of canonical texts similar to the Ethiopian Orthodox Christians, cf "Encyclopaedia Judaica", Vol 6, p 1147.

During the birth of Christianity many Jewish texts of Hellenistic origin existed within Judaism and were frequently used by Christians. Catholic Christians incorporated several of these books into the canon of the Christian Bible, calling them the "apocrypha" or the "hidden books" of the Bible. Patristic authorities frequently recognized these books as important to the emergence of apostolic Christianity, but the inspired authority and value of the apocrypha remained widely disputed. In the sixteenth century, during the Protestant reformation, some authorities began using term "deuterocanonical" to refer to this traditional intertestamental collection as books of "the second canon." These books are often seen as "intertestamental" because reading them helps explain the theological and cultural transitions which took place between the Old and New Testaments. They are also sometimes called "intertestamental" by religious groups who do not recognize Hellenistic Judaism as belonging with either "Jewish" or "Christian" testaments.

Slightly varying collections of apocryphal, deuterocanonical, or intertestamental books of the Bible form part of the Roman Catholic, Eastern Orthodox and Oriental Orthodox canons (cf Development of the Old Testament canon). The deuterocanonical or intertestamental books of the Catholic Church include 1-2 Esdras, Tobit, Judith, Additions to Esther, the Wisdom of Solomon, Ecclesiasticus, Baruch, the Letter of Jeremiah, the Prayer of Azariah, Susanna, Bel and the Dragon, the Prayer of Manasseh, and 1-2 Maccabees.

The Book of Enoch is included in the biblical canon of the Oriental Orthodox churches of Ethiopia and Eritrea. The Epistle of Jude quotes the book of Enoch, and some believe the use of this book also appears in the four gospels and 1 Peter. The genuineness and inspiration of Enoch were believed in by the writer of the Epistle of Barnabas, Irenaeus, Tertullian and Clement of Alexandria and much of the early church. The epistles of Paul and the gospels also show influences from the Book of Jubilees, which is part of the Ethiopian canon, as well as the Assumption of Moses and the Testaments of the Twelve Patriarchs, which are included in no biblical canon.

The canonical validity of the intertestamental books was challenged in the 16th century by Protestants. The Protestant removal of the deuterocanonical books of the Bible did not happen immediately as part of the Reformation, but rather happened in waves over time. The apocryphal books were in fact translated as part of the King James Version of the Bible. Eventually they were effectively removed by Protestants during the 1800s, with some Protestants arguing against their inclusion for theological reasons, and with other Protestants citing the cost of publishing the hidden books as a major factor in removing them. Today it is possible to find Protestant Bibles which now include the Apocrypha. The status of the deuterocanonicals remains unchanged in Catholic and Orthodox Christianities.

The actual status of the books which the Catholic church terms "Deuterocanonicals" (second canon) and Protestantism refers to as "Apocrypha" has been an issue of disagreement which preceded the Reformation. Many believe that the pre-Christian-era Jewish translation (into Greek) of holy scriptures known as the Septuagint, a Greek translation of the Hebrew Scriptures originally compiled around 280 B.C., originally included the apocryphal writings in dispute, with little distinction made between them and the rest of the Old Testament. Others argue that the Septuagint of the first century did not contain these books but were added later by Christians, The earliest extant manuscripts of the Septuagint are from the fourth century, and suffer greatly from a lack of uniformity as regards containing apocryphal books, and some also contain books classed as Pseudepigrapha, from which texts were cited by some early writers in the second and later centuries as being Scripture.

While a few scholars conclude that the Jewish canon was the achievement of the Hasmonean dynasty, it is generally considered not to have been finalized until about 100 A.D. or somewhat later, at which time considerations of Greek language and beginnings of Christian acceptance of the Septuagint weighed against some of the texts. Some were not accepted by the Jews as part of the Hebrew Bible canon and the Apocrypha is not part of the historical Jewish canon.

Early church fathers such as Athanasius, Melito, Origen, and Cyril of Jerusalem, spoke against the canonicity of much or all of the apocrypha, but the most weighty opposition was the fourth century Catholic scholar Jerome who preferred the Hebrew canon, whereas Augustine and others preferred the wider (Greek) canon, with both having followers in the generations that followed. The "Catholic Encyclopedia" states as regards the Middle Ages,

The wider Christian canon accepted by Augustine became the more established canon in the western Church after being promulgated for use in the Easter Letter of Athanasius (circa 372 A.D.), the Synod of Rome (382 A.D., but its Decretum Gelasianum is generally considered to be a much later addition ) and the local councils of Carthage and Hippo in north Africa (391 and 393 A.D). Athanasius called canonical all books of the Hebrew Bible including Baruch, while excluding Esther. He adds that "there are certain books which the Fathers had appointed to be read to catechumens for edification and instruction; these are the Wisdom of Solomon, the Wisdom of Sirach (Ecclesiasticus), Esther, Judith, Tobias, the Didache, or Doctrine of the Apostles, and the Shepherd of Hermas. All others are apocrypha and the inventions of heretics (Festal Epistle for 367)".

Nevertheless, none of these constituted indisputable definitions, and significant scholarly doubts and disagreements about the nature of the Apocrypha continued for centuries and even into Trent, which provided the first infallible definition of the Catholic canon in 1546. This canon came to see appropriately 1,000 years of nearly uniform use by the majority, even after the 11th-century schism that separated the church into the branches known as the Roman Catholic and Eastern Orthodox churches.

In the 16th century, the Protestant reformers challenged the canonicity of the books and partial-books found in the surviving Septuagint but not in the Masoretic Text. In response to this challenge, after the death of Martin Luther (February 8, 1546) the ecumenical Council of Trent officially ("infallibly") declared these books (called "deuterocanonical" by Catholics) to be part of the canon in April, 1546 A.D. While the Protestant Reformers rejected the parts of the canon that were not part of the Hebrew Bible, they included the four New Testament books Luther held as doubtful canonicity along with the Apocrypha in his non-binding canon (though most were separately included in his bible, as they were in some editions of the KJV bible until 1947). Protestantism therefore established a 66 book canon with the 39 books based on the ancient Hebrew canon, along with the traditional 27 books of the New Testament. Protestants also rejected the Catholic term "deuterocanonical" for these writings, preferring to apply the term "apocryphal" which was already in use for other early and disputed writings. As today (but along with others reasons), various reformers argued that those books contained doctrinal or other errors and thus should not have been added to the canon for that reason. The differences between canons can be seen under Biblical canon and Development of the Christian biblical canon. 
Explaining the Eastern Orthodox Church's canon is made difficult because of differences of perspective with the Roman Catholic church in the interpretation of how it was done. Those differences (in matters of jurisdictional authority) were contributing factors in the separation of the Roman Catholics and Orthodox around 1054, but the formation of the canon which Trent would later officially definitively settle was largely complete by the fifth century, in not settled, six centuries before the separation. In the eastern part of the church, it took much of the fifth century also to come to agreement, but in the end it was accomplished. The canonical books thus established by the undivided church became the predominate canon for what was later to become Roman Catholic and Eastern Orthodox alike. The East did already differ from the West in not considering every question of canon yet settled, and it subsequently adopted a few more books into its Old Testament. It also allowed consideration of yet a few more to continue not fully decided, which led in some cases to adoption in one or more jurisdictions, but not all. Thus, there are today a few remaining differences of canon among Orthodox, and all Orthodox accept a few more books than appear in the Catholic canon. The Psalms of Solomon, 3 Maccabees, 4 Maccabees, the Epistle of Jeremiah the Book of Odes, the Prayer of Manasseh and Psalm 151 are included in some copies of the Septuagint, some of which are accepted as canonical by Eastern Orthodox and some other churches. Protestants accept none of these additional books as canon either, but see them having roughly the same status as the other Apocrypha.

New Testament apocrypha—books similar to those in the New Testament but almost universally rejected by Catholics, Orthodox and Protestants—include several gospels and lives of apostles. Some were written by early Jewish Christians (see the Gospel according to the Hebrews). Others of these were produced by Gnostic authors or members of other groups later defined as heterodox. Many texts believed lost for centuries were unearthed in the 19th and 20th centuries, producing lively speculation about their importance in early Christianity among religious scholars, while many others survive only in the form of quotations from them in other writings; for some, no more than the title is known. Artists and theologians have drawn upon the New Testament apocrypha for such matters as the names of Dismas and Gestas and details about the Three Wise Men. The first explicit mention of the perpetual virginity of Mary is found in the pseudepigraphical Infancy Gospel of James.

Before the fifth century, the Christian writings that were then under discussion for inclusion in the canon but had not yet been accepted were classified in a group known as the ancient antilegomenae. These were all candidates for the New Testament and included several books which were eventually accepted, such as: The Epistle to the Hebrews, 2 Peter, 3 John and the Revelation of John (Apocalypse). None of those accepted books can be considered Apocryphal now, since all Christendom accepts them as canonical. Of the uncanonized ones, the Early Church considered some heretical but viewed others quite well. Some Christians, in an extension of the meaning, might also consider the non-heretical books to be "apocryphal" along the manner of Martin Luther: not canon, but useful to read. This category includes books such as the Epistle of Barnabas, the Didache, and The Shepherd of Hermas which are sometimes referred to as the Apostolic Fathers.
The Gnostic tradition was a prolific source of apocryphal gospels. While these writings borrowed the characteristic poetic features of apocalyptic literature from Judaism, Gnostic sects largely insisted on allegorical interpretations based on a secret apostolic tradition. With them, these apocryphal books were highly esteemed. A well-known Gnostic apocryphal book is the Gospel of Thomas, the only complete text of which was found in the Egyptian town of Nag Hammadi in 1945. The Gospel of Judas, a Gnostic gospel, also received much media attention when it was reconstructed in 2006.

Roman Catholics and Orthodox Christians as well as Protestants generally agree on the canon of the New Testament, see Development of the New Testament canon. The Ethiopian Orthodox have in the past also included I & II Clement and Shepherd of Hermas in their New Testament canon.

The List of Sixty, dating to around the 7th century, lists the sixty books of the Bible. The unknown author also lists several apocryphal books that are not included amongst the sixty. These books are:

Prophetic texts called the "Ch'an-wei" () were written by Han Dynasty (206 BCE to 220 CE) Taoist priests to legitimize as well as curb imperial power. They deal with treasure objects that were part of the Zhou (1066 to 256 BCE) royal treasures. Emerging from the instability of the Warring States period (476–221 BCE), ancient Chinese scholars saw the centralized rule of the Zhou as an ideal model for the new Han empire to emulate. The "Ch'an-wei" are therefore texts written by Han scholars about the Zhou royal treasures, only they were not written to record history for its own sake, but for legitimizing the current imperial reign. These texts took the form of stories about texts and objects being conferred upon the Emperors by Heaven and comprising these ancient sage-king's (this is how the Zhou emperors were referred to by this time, about 500 years after their peak) royal regalia. The desired effect was to confirm the Han emperor's Heavenly Mandate through the continuity offered by his possession of these same sacred talismans. It is because of this politicized recording of their history that it is difficult to retrace the exact origins of these objects. What is known is that these texts were most likely produced by a class of literati called the "fangshi". These were a class of nobles who were not part of the state administration; they were considered specialists or occultists, for example diviners, astrologers, alchemists or healers. It is from this class of nobles that the first Taoist priests are believed to have emerged. Seidel points out however that the scarcity of sources relating to the formation of early Taoism make the exact link between the apocryphal texts and the Taoist beliefs unclear.

Apocryphal Jatakas of the Pali Buddhist canon, such as those belonging to the Paññāsajātaka collection, have been adapted to fit local culture in certain Southeast Asian countries and have been retold with amendments to the plots to better reflect Buddhist morals.

Within the Pali tradition, the apocryphal Jatakas of later composition (some dated even to the 19th century) are treated as a separate category of literature from the "Official" Jataka stories that have been more-or-less formally canonized from at least the 5th century—as attested to in ample epigraphic and archaeological evidence, such as extant illustrations in bas relief from ancient temple walls.




</doc>
<doc id="1291" url="https://en.wikipedia.org/wiki?curid=1291" title="Antarctic Treaty System">
Antarctic Treaty System

The Antarctic Treaty and related agreements, collectively known as the Antarctic Treaty System (ATS), regulate international relations with respect to Antarctica, Earth's only continent without a native human population. For the purposes of the treaty system, Antarctica is defined as all of the land and ice shelves south of 60°S latitude. The treaty entered into force in 1961 and currently has 54 parties. The treaty sets aside Antarctica as a scientific preserve, establishes freedom of scientific investigation, and bans military activity on the continent. The treaty was the first arms control agreement established during the Cold War. Since September 2004, the Antarctic Treaty Secretariat headquarters has been located in Buenos Aires, Argentina.

The main treaty was opened for signature on December 1, 1959, and officially entered into force on June 23, 1961. The original signatories were the 12 countries active in Antarctica during the International Geophysical Year (IGY) of 1957–58. The twelve countries that had significant interests in Antarctica at the time were: Argentina, Australia, Belgium, Chile, France, Japan, New Zealand, Norway, South Africa, the Soviet Union, the United Kingdom, and the United States. These countries had established over 55 Antarctic stations for the IGY. The treaty was a diplomatic expression of the operational and scientific co-operation that had been achieved "on the ice".


1. Antarctica shall be used for peaceful purposes only. There shall be prohibited, inter alia, any measures of a military nature, such as the establishment of military bases and fortifications, the carrying out of military maneuvers, as well as the testing of any type of weapons. 

2. The present treaty shall not prevent the use of military personnel or equipment for scientific research or for any other peaceful purposes.

Freedom of scientific investigation in Antarctica and cooperation toward that end, as applied during the International Geophysical Year, shall continue, subject to the provisions of the present treaty.

1. In order to promote international cooperation in scientific investigation in Antarctica, as provided for in Article II of the present treaty, the Contracting Parties agree that, to the greatest extent feasible and practicable: 

(a) information regarding plans for scientific programs in Antarctica shall be exchanged to permit maximum economy and efficiency of operations; 

(b) scientific personnel shall be exchanged in Antarctica between expeditions and stations; 

(c) scientific observations and results from Antarctica shall be exchanged and made freely available. 

2. In implementing this Article, every encouragement shall be given to the establishment of cooperative working relations with those Specialized Agencies of the United Nations and other international organizations having a scientific or technical interest in Antarctica.

1. Nothing contained in the present treaty shall be interpreted as: 

(a) a renunciation by any Contracting Party of previously asserted rights of or claims to territorial sovereignty in Antarctica; 

(b) a renunciation or diminution by any Contracting Party of any basis of claim to territorial sovereignty in Antarctica which it may have whether as a result of its activities or those of its nationals in Antarctica, or otherwise; 

(c) prejudicing the position of any Contracting Party as regards its recognition or non-recognition of any other States right of or claim or basis of claim to territorial sovereignty in Antarctica. 

2. No acts or activities taking place while the present treaty is in force shall constitute a basis for asserting, supporting or denying a claim to territorial sovereignty in Antarctica or create any rights of sovereignty in Antarctica. No new claim, or enlargement of an existing claim, to territorial sovereignty in Antarctica shall be asserted while the present treaty is in force.

1. Any nuclear explosions in Antarctica and the disposal there of radioactive waste material shall be prohibited. 

2. In the event of the conclusion of international agreements concerning the use of nuclear energy, including nuclear explosions and the disposal of radioactive waste material, to which all of the Contracting Parties whose representatives are entitled to participate in the meetings provided for under Article IX are parties, the rules established under such agreements shall apply in Antarctica.

The provisions of the present treaty shall apply to the area south of 60 degree South Latitude, including all ice shelves, but nothing in the present treaty shall prejudice or in any way affect the rights, or the exercise of the rights, of any State under international law with regard to the high seas within that area.

1. In order to promote the objectives and ensure the observance of the provisions of the present treaty, each Contracting Party whose representatives are entitled to participate in the meetings referred to in Article IX of the treaty shall have the right to designate observers to carry out any inspection provided for by the present Article. Observers shall be nationals of the Contracting Parties which designate them. The names of observers shall be communicated to every other Contracting Party having the right to designate observers, and like notice shall be given of the termination of their appointment. 

2. Each observer designated in accordance with the provisions of paragraph 1 of this Article shall have complete freedom of access at any time to any or all areas of Antarctica. 

3. All areas of Antarctica, including all stations, installations and equipment within those areas, and all ships and aircraft at points of discharging or embarking cargoes or personnel in Antarctica, shall be open at all times to inspection by any observers designated in accordance with paragraph 1 of this Article. 

4. Aerial observation may be carried out at any time over any or all areas of Antarctica by any of the Contracting Parties having the right to designate observers. 

5. Each Contracting Party shall, at the time when the present treaty enters into force for it, inform the other Contracting Parties, and thereafter shall give them notice in advance, of 

(a) all expeditions to and within Antarctica, on the part of its ships or nationals, and all expeditions to Antarctica organized in or proceeding from its territory; 

(b) all stations in Antarctica occupied by its nationals; and 

(c) any military personnel or equipment intended to be introduced by it into Antarctica subject to the conditions prescribed in paragraph 2 of Article I of the present treaty.

1. In order to facilitate the exercise of their functions under the present treaty, and without prejudice to the respective positions of the Contracting Parties relating to jurisdiction over all other persons in Antarctica, observers designated under paragraph 1 of Article VII and scientific personnel exchanged under subparagraph 1(b) of Article III of the treaty, and members of the staffs accompanying any such persons, shall be subject only to the jurisdiction of the Contracting Party of which they are nationals in respect of all acts or omissions occurring while they are in Antarctica for the purpose of exercising their functions. 

2. Without prejudice to the provisions of paragraph 1 of this Article, and pending the adoption of measures in pursuance of subparagraph 1(e) of Article IX, the Contracting Parties concerned in any case of dispute with regard to the exercise of jurisdiction in Antarctica shall immediately consult together with a view to reaching a mutually acceptable solution.

1. Representatives of the Contracting Parties named in the preamble to the present treaty shall meet at the City of Canberra within two months after the date of entry into force of the treaty, and thereafter at suitable intervals and places, for the purpose of exchanging information, consulting together on matters of common interest pertaining to Antarctica, and formulating and considering, and recommending to their Governments, measures in furtherance of the principles and objectives of the treaty, including measures regarding: 

(a) use of Antarctica for peaceful purposes only; 

(b) facilitation of scientific research in Antarctica; 

(c) facilitation of international scientific cooperation in Antarctica; 

(d) facilitation of the exercise of the rights of inspection provided for in Article VII of the treaty; 

(e) questions relating to the exercise of jurisdiction in Antarctica; 

(f) preservation and conservation of living resources in Antarctica. 

2. Each Contracting Party which has become a party to the present treaty by accession under Article XIII shall be entitled to appoint representatives to participate in the meetings referred to in paragraph 1 of the present Article, during such time as that Contracting Party demonstrates its interest in Antarctica by conducting substantial scientific research activity there, such as the establishment of a scientific station or the despatch of a scientific expedition. 

3. Reports from the observers referred to in Article VII of the present treaty shall be transmitted to the representatives of the Contracting Parties participating in the meetings referred to in paragraph 1 of the present Article. 

4. The measures referred to in paragraph 1 of this Article shall become effective when approved by all the Contracting Parties whose representatives were entitled to participate in the meetings held to consider those measures. 

5. Any or all of the rights established in the present treaty may be exercised from the date of entry into force of the treaty whether or not any measures facilitating the exercise of such rights have been proposed, considered or approved as provided in this Article.

Each of the Contracting Parties undertakes to exert appropriate efforts, consistent with the Charter of the United Nations, to the end that no one engages in any activity in Antarctica contrary to the principles or purposes of the present treaty.

1. If any dispute arises between two or more of the Contracting Parties concerning the interpretation or application of the present treaty, those Contracting Parties shall consult among themselves with a view to having the dispute resolved by negotiation, inquiry, mediation, conciliation, arbitration, judicial settlement or other peaceful means of their own choice. 

2. Any dispute of this character not so resolved shall, with the consent, in each case, of all parties to the dispute, be referred to the International Court of Justice for settlement; but failure to reach agreement on reference to the International Court shall not absolve parties to the dispute from the responsibility of continuing to seek to resolve it by any of the various peaceful means referred to in paragraph 1 of this Article.

The main objective of the ATS is to ensure in the interests of all humankind that Antarctica shall continue forever to be used exclusively for peaceful purposes and shall not become the scene or object of international discord. Pursuant to Article 1, the treaty forbids any measures of a military nature, but not the presence of military personnel or equipment for the purposes of scientific research.

Other agreements — some 200 recommendations adopted at treaty consultative meetings and ratified by governments — include:


The Antarctic Treaty System's yearly "Antarctic Treaty Consultative Meetings (ATCM)" are the international forum for the administration and management of the region. Only 29 of the 54 parties to the agreements have the right to participate in decision-making at these meetings, though the other 24 are still allowed to attend. The decision-making participants are the "Consultative Parties" and, in addition to the 12 original signatories, include 17 countries that have demonstrated their interest in Antarctica by carrying out substantial scientific activity there.

As of 2019, there are 54 states party to the treaty, 29 of which, including all 12 original signatories to the treaty, have consultative (voting) status. Consultative members include the seven nations that claim portions of Antarctica as national territory. The 46 non-claimant nations either do not recognize the claims of others, or have not stated their positions. 40 parties to the Antarctic Treay have also ratified the "Protocol on Environmental Protection to the Antarctic Treaty".

The "Antarctic Treaty Secretariat" was established in Buenos Aires, Argentina in September 2004 by the Antarctic Treaty Consultative Meeting (ATCM). Jan Huber (Netherlands) served as the first Executive Secretary for five years until August 31, 2009. He was succeeded on September 1, 2009, by Manfred Reinke (Germany).

The tasks of the Antarctic Treaty Secretariat can be divided into the following areas:

Antarctica currently has no permanent population and therefore it has no citizenship nor government. All personnel present on Antarctica at any time are citizens or nationals of some sovereignty outside Antarctica, as there is no Antarctic sovereignty. The majority of Antarctica is claimed by one or more countries, but most countries do not explicitly recognize those claims. The area on the mainland between 90 degrees west and 150 degrees west is the only major land on Earth not claimed by any country. Until 2015 the interior of the Norwegian Sector, the extent of which had never been officially defined, was considered to be unclaimed. That year, Norway formally laid claim to the area between its Queen Maud Land and the South Pole.

Governments that are party to the Antarctic Treaty and its Protocol on Environmental Protection implement the articles of these agreements, and decisions taken under them, through national laws. These laws generally apply only to their own citizens, wherever they are in Antarctica, and serve to enforce the consensus decisions of the consultative parties: about which activities are acceptable, which areas require permits to enter, what processes of environmental impact assessment must precede activities, and so on. The Antarctic Treaty is often considered to represent an example of the common heritage of mankind principle.

Since the designation of the Australian Antarctic Territory pre-dated the signing of the Antarctic Treaty, Australian laws that relate to Antarctica date from more than two decades before the Antarctic Treaty era. In terms of criminal law, the laws that apply to the Jervis Bay Territory (which follows the laws of the Australian Capital Territory) apply to the Australian Antarctic Territory. Key Australian legislation applying Antarctic Treaty System decisions include the "Antarctic Treaty Act 1960", the "Antarctic Treaty (Environment Protection) Act 1980" and the "Antarctic Marine Living Resources Conservation Act 1981".

The law of the United States, including certain criminal offences by or against U.S. nationals, such as murder, may apply to areas not under jurisdiction of other countries. To this end, the United States now stations special deputy U.S. Marshals in Antarctica to provide a law enforcement presence.

Some U.S. laws directly apply to Antarctica. For example, the Antarctic Conservation Act, Public Law 95-541, "et seq.", provides civil and criminal penalties for the following activities, unless authorized by regulation or statute:

Violation of the Antarctic Conservation Act carries penalties of up to US$10,000 in fines and one year in prison. The Departments of the Treasury, Commerce, Transportation, and the Interior share enforcement responsibilities. The Act requires expeditions from the U.S. to Antarctica to notify, in advance, the Office of Oceans and Polar Affairs of the State Department, which reports such plans to other nations as required by the Antarctic Treaty. Further information is provided by the Office of Polar Programs of the National Science Foundation.

In 2006, the New Zealand police reported that jurisdictional issues prevented them issuing warrants for potential American witnesses who were reluctant to testify during the Christchurch Coroner's investigation into the death by poisoning of Australian astrophysicist Rodney Marks at the South Pole base in May 2000. Dr. Marks died while wintering over at the United States' Amundsen–Scott South Pole Station located at the geographic South Pole. Prior to autopsy, the death was attributed to natural causes by the National Science Foundation and the contractor administering the base. However, an autopsy in New Zealand revealed that Dr. Marks died from methanol poisoning. The New Zealand Police launched an investigation. In 2006, frustrated by lack of progress, the Christchurch Coroner said that it was unlikely that Dr. Marks ingested the methanol knowingly, although there is no certainty that he died as the direct result of the act of another person. During media interviews, the police detective in charge of the investigation criticized the National Science Foundation and contractor Raytheon for failing to co-operate with the investigation.

South African law applies to all South African citizens in Antarctica, and they are subject to the jurisdiction of the magistrate's court in Cape Town. In regard to violations of the Antarctic Treaty and related agreements, South Africa also asserts jurisdiction over South African residents and members of expeditions organised in South Africa.





</doc>
<doc id="1293" url="https://en.wikipedia.org/wiki?curid=1293" title="Alfred Lawson">
Alfred Lawson

Alfred William Lawson (March 24, 1869 – November 29, 1954) was a professional baseball player, manager, and league promoter from 1887 through 1916 and went on to play a pioneering role in the U.S. aircraft industry. He published two early aviation trade journals.

He is frequently cited as the inventor of the airliner and was awarded several of the first air mail contracts, which he ultimately could not fulfill. He founded the Lawson Aircraft Company in Green Bay, Wisconsin, to build military training aircraft and later the Lawson Airplane Company in South Milwaukee, Wisconsin, to build airliners.

The crash of his ambitious Lawson L-4 "Midnight Liner" during its trial flight takeoff on May 8, 1921, ended his best chance for commercial aviation success.

In 1904 he wrote a novel, "Born Again", in which he developed the philosophy which later became Lawsonomy.

He made one start for the Boston Beaneaters and two for the Pittsburgh Alleghenys during the 1890 season. His minor league playing career lasted through 1895. He later managed in the minors from 1905 to 1907.

In 1908 he started a new professional baseball league known as the Union Professional League. The league took the field in April but folded one month later owing to financial difficulties.

An early advocate or rather evangelist of aviation, in October 1908 Mr. Lawson started the magazine "Fly" to stimulate public interest and educate readers in the fundamentals of the new science of aviation. It sold for 10 cents a copy from newsstands across the country. In 1910, moving to New York City, he renamed the magazine "Aircraft" and published it until 1914. The magazine chronicled the technical developments of the early aviation pioneers. He was the first advocate for commercial air travel, coining the term "airline." He also advocated for a strong American flying force, lobbying Congress in 1913 to expand its appropriations for Army aircraft.

In early 1913, he learned to fly the Sloan-Deperdussin and the Moisant-Bleriot monoplanes, becoming an accomplished pilot. Later that year he bought a Thomas flying boat and became the first air commuter regularly flying from his country house in Seidler's Beach NJ to the foot of 75th Street in NYC (about 35 miles). In 1917, utilizing the knowledge gained from 10 years advocating aviation, he built his first airplane, the Lawson Military Tractor 1 (MT-1) trainer, and founded the Lawson Aircraft Corporation. The company's plant was sited at Green Bay, Wisconsin. There he secured a contract and built the Lawson MT-2. He also designed the steel fuselage Lawson Armored Battler, which never got beyond the drafting board, given doubts within the Army aviation community and the signing of the armistice.
After the war, in 1919 Lawson started a project to build America's first airline. He secured financial backing, and in five months he had built and demonstrated in flight his biplane airliner, the 18-passenger Lawson L-2. He demonstrated its capabilities in a 2000-mile multi-city tour from Milwaukee to Chicago-Toledo-Cleveland-Buffalo-Syracuse-New york City-Washington, D.C.-Collinsville-Dayton-Chicago and back to Milwaukee, creating a buzz of positive press. The publicity allowed him to secure an additional $1 million to build the 26-passenger Midnight Liner. The aircraft crashed on takeoff on its maiden flight. In late 1920, he secured government contracts for three airmail routes and to deliver 10 war planes, but owing to the fall 1920 recession, he could not secure the necessary $100,000 in cash reserves called for in the contracts and had to decline them. In 1926 he started his last airliner, the 56-seat, two-tier Lawson super airliner.
In this phase of his life, he was considered one of the leading thinkers in the budding American commercial aviation community, but his troubles with getting financial backing for his ideas led him to turn to economics, philosophy, and organization.

In the 1920s, he promoted health practices, including vegetarianism, and claimed to have found the secret of living to 200. He also developed his own highly unusual theories of physics, according to which such concepts as "penetrability", "suction and pressure" and "zig-zag-and-swirl" were discoveries on par with Einstein's Theory of Relativity. He published numerous books on these concepts, all set in a distinctive typography. Lawson repeatedly predicted the worldwide adoption of Lawsonian principles by the year 2000.

He later propounded his own philosophy, Lawsonomy, and the Lawsonian religion. He also developed, during the Great Depression, the populist economic theory of "Direct Credits", according to which banks are the cause of all economic woes, the oppressors of both capital and labour. Lawson believed that the government should replace banks as the provider of loans to business and workers. His rallies and lectures attracted thousands of listeners in the early 1930s, mainly in the upper Midwest, but by the late 1930s the crowds had dwindled.

In 1943, he founded the University of Lawsonomy in Des Moines to spread his teachings and offer the degree of "Knowledgian", but after various IRS and other investigations it was closed and finally sold in 1954, the year of Lawson's death. Lawson's financial arrangements remain mysterious to this day, and in later years he seems to have owned little property, moving from city to city as a guest of his farflung acolytes. In 1952, he was brought before a United States Senate investigative committee on allegations that his organization had bought war surplus machines and then sold them for a profit, despite claiming non-profit status. His attempt to explain Lawsonomy to the senators ended in mutual frustration and bafflement.

A farm near Racine, Wisconsin, is the only remaining university facility, although a tiny handful of churches may yet survive in places such as Wichita, Kansas. The large sign, formerly reading "University of Lawsonomy", was a familiar landmark for motorists in the region for many years and was visible from Interstate 94 about north of the Illinois state line, on the east side of the highway. Although the sign still exists, the "of" has now been replaced by the URL of the Lawsonomy website. A storm in the spring of 2009 destroyed the sign, although the supporting posts are still visible. On the northbound side of Interstate 94, a sign on the roof of the building nearest the freeway said "Study Natural Law" until being shingled over in October 2014.

Lawson's brother, George H. Lawson, founded the United States League in 1910. The new professional baseball league had the intent to racially integrate. The league lasted less than a season, but it was revived for one season by George Lawson's associates in 1912.





</doc>
<doc id="1298" url="https://en.wikipedia.org/wiki?curid=1298" title="Ames, Iowa">
Ames, Iowa

Ames is a city in central Iowa approximately north of Des Moines. It is best known as the home of Iowa State University (ISU), with leading Agriculture, Design, Engineering, and Veterinary Medicine colleges. A United States Department of Energy national laboratory, Ames Laboratory, is located on the ISU campus.

In 2017, Ames had a population of 66,498. Iowa State University is home to 36,321 students (Fall 2017), which make up approximately one half of the city's population.

Ames also hosts United States Department of Agriculture (USDA) sites: the largest federal animal disease center in the United States, USDA's Agricultural Research Service's National Animal Disease Center (NADC)., as well as, one of two national USDA sites for the Animal and Plant Health Inspection Service (APHIS), which comprises the National Veterinary Services Laboratory and the Center for Veterinary Biologics. Ames has the headquarters for the Iowa Department of Transportation.

In 2010, Ames was ranked ninth on CNNMoney's "Best Places to Live" list.

The city was founded in 1864 as a station stop on the Cedar Rapids and Missouri Railroad and was named after 19th century U.S. Congressman Oakes Ames of Massachusetts, who was influential in the building of the transcontinental railroad. Ames was founded by local resident Cynthia Olive Duff (née Kellogg) and railroad magnate John Insley Blair, near a location that was deemed favorable for a railroad crossing of the Skunk River.

Ames is located along the western edge of Story County, Iowa, United States. It is located roughly north of the state capital Des Moines, near the intersection of Interstate 35 and U.S. Route 30. A smaller highway, U.S. Route 69, runs through the town. Also passing through Ames is the cross country line of the Union Pacific Railroad & two small streams (the South Skunk River and Squaw Creek). 

According to the United States Census Bureau, the city has a total area of , of which is land and is water.
Campustown is the neighborhood directly south of Iowa State University Central Campus bordered by Lincoln Way on the north. Campustown is a high-density mixed-use neighborhood that is home to many student apartments, nightlife venues, restaurants, and numerous other establishments, most of which are unique to Ames. 

Ames has a humid continental climate (Köppen climate classification "Dfa"). On average, the warmest month is July and the coldest is January. The highest recorded temperature was in 1988 and the lowest was −28 °F in 1996.

As of the census of 2010, there were 58,965 people, 22,759 households, and 9,959 families residing in the city. The population density was . There were 23,876 housing units at an average density of . The racial makeup of the city was 84.5% White, 3.4% African American, 0.2% Native American, 8.8% Asian, 1.1% from other races, and 2.0% from two or more races. Hispanic or Latino of any race were 3.4% of the population.

There were 22,759 households of which 19.1% had children under the age of 18 living with them, 35.6% were married couples living together, 5.4% had a female householder with no husband present, 2.7% had a male householder with no wife present, and 56.2% were non-families. 30.5% of all households were made up of individuals and 6.2% had someone living alone who was 65 years of age or older. The average household size was 2.25 and the average family size was 2.82.

The median age in the city was 23.8 years. 13.4% of residents were under the age of 18; 40.5% were between the ages of 18 and 24; 22.9% were from 25 to 44; 15% were from 45 to 64; and 8.1% were 65 years of age or older. The gender makeup of the city was 53.0% male and 47.0% female.

As of the census of 2000, there were 50,731 people, 18,085 households, and 8,970 families residing in the city. The population density was 2,352.3 people per square mile (908.1/km). There were 18,757 housing units at an average density of 869.7 per square mile (335.7/km). The racial makeup of the city was 87.34% White, 7.70% Asian, 2.65% African American, 0.04% Native American, 0.76% Pacific Islander and other races, and 1.36% from two or more races. Hispanic or Latino of any race were 1.98% of the population.

There were 18,085 households out of which 22.3% had children under the age of 18 living with them, 42.0% were married couples living together, 5.3% had a female householder with no husband present, and 50.4% were non-families. 28.5% of all households were made up of individuals and 5.9% had someone living alone who was 65 years of age or older. The average household size was 2.30 and the average family size was 2.85.

Age spread: 14.6% under the age of 18, 40.0% from 18 to 24, 23.7% from 25 to 44, 13.9% from 45 to 64, and 7.7% who were 65 years of age or older. The median age was 24 years. For every 100 females, there were 109.3 males. For every 100 females age 18 and over, there were 109.9 males.

The median income for a household in the city was $36,042, and the median income for a family was $56,439. Males had a median income of $37,877 versus $28,198 for females. The per capita income for the city was $18,881. About 7.6% of families and 20.4% of the population were below the poverty line, including 9.2% of those under age 18 and 4.1% of those age 65 or over.

The U.S. Census Bureau designates the Ames metropolitan statistical area as encompassing all of Story County. While Ames is the largest city in Story County, the county seat is in the nearby city of Nevada east of Ames.

Ames metropolitan statistical area combined with the Boone, Iowa micropolitan statistical area (Boone County, Iowa) make up the larger Ames-Boone combined statistical area. Ames is the larger principal city of the Combined Statistical Area that includes all of Story County, Iowa and Boone County, Iowa. which had a combined population of 106,205 at the 2000 census.

Ames is home of Iowa State University of Science and Technology, a public land-grant and space-grant research university, and member of the prestigious Association of American Universities. At its founding in 1858, Iowa State was formerly known as the Iowa State College of Agriculture and Mechanic Arts. Ames is the home of the closely allied U.S. Department of Agriculture's National Animal Disease Center (See Ames strain), the U.S. Department of Energy's Ames Laboratory (a major materials research and development facility), and the main offices of the Iowa Department of Transportation. State and Federal institutions are the largest employers in Ames.

Other area employers include a 3M manufacturing plant; Danfoss Power Solutions, a hydraulics manufacturer; Barilla, a pasta manufacturer; Ball, a manufacturer of canning jars and plastic bottles; Renewable Energy Group, America's largest producer of biomass-based diesel; and the National Farmers Organization.

The Iowa State University Research Park is a not-for-profit, business development incubator located in Ames, and affiliated with Iowa State University.

In 2015, Ames was ranked in the top 15 "Cities That Have Done the Best Since the Recession" by Bloomberg Businessweek.

The Bureau of Labor Statistics ranked Ames and Boulder, CO as having the lowest unemployment rate (2.5%) of any metropolitan area in the US in 2016. By June 2018, unemployment in Ames had fallen even further, to 1.5%, and wage increases for workers were not keeping pace with rising rents.

According to Ames's 2017 Comprehensive Annual Financial Report, the top employers in the city are:

Velma Wallace Rayness
Ames, Iowa was home to Gerard M. and Velma Wallace Rayness.
Both artists taught art and were nationally recognized artists.
Their art was exhibited nationally as well as abroad.
Gerard died in the 1940s. Velma Wallace Rayness died in 1977.
Velma Wallace Rayness usually signed her paintings "V.W. Rayness"




The Iowa State University Cyclones play a variety of sports in the Ames area. The Cyclones' football team plays at Jack Trice Stadium near Ames. Also, the Cyclones' Men's and Women's Basketball teams and Volleyball team play at Hilton Coliseum just across the street from Jack Trice Stadium. The Iowa State Cyclones are a charter member of the Big 12 Conference in all sports and compete in NCAA Division I-A.

The Ames Figure Skating Club provides recreational to professional level skating opportunities. The club sponsors the Learn to Skate Program. Coaches provide on and off ice lessons or workshops. The club hosts the figure skating portion of the Iowa Games competition every summer. In the fall the club hosts Cyclone Country Championships. Every year the club puts on the Winter Gala. The big event is the annual Spring Ice Show where young to adult skaters can perform their best moves.

The Ames area has a large number of parks and arboretums.

Specialized Parks:

Community Parks:

Neighborhood Parks:

Ames High School: Grades 9–12



Iowa State University of Science and Technology, more commonly known as Iowa State University (ISU), is a public land-grant and space-grant research university located in Ames. Iowa State University is the birthplace of the Atanasoff–Berry Computer, the world's first electronic digital computer. Iowa State has produced a number of astronauts, scientists, Nobel laureates, Pulitzer Prize winners, and a variety of other notable individuals in their respective fields. Until 1945 it was known as the Iowa State College of Agriculture and Mechanic Arts. The university is a member of the American Association of Universities and the Big 12 Conference.

ISU is the nation's first designated land-grant university In 1856, the Iowa General Assembly enacted legislation to establish the State Agricultural College and Model Farm. Story County was chosen as the location on June 21, 1859, from proposals by Johnson, Kossuth, Marshall, Polk, and Story counties. When Iowa accepted the provisions of the Morrill Act of 1862, Iowa State became the first institution in nation designated as a land-grant college. The institution was coeducational from the first preparatory class admitted in 1868. The formal admitting of students began the following year, and the first graduating class of 1872 consisted of 24 men and 2 women.

The first building on the Iowa State campus was Farm House. Built in the 1860s, it currently serves as a museum and National Historic Landmark. Today, Iowa State has over 60 notable buildings, including Beardshear Hall, Morrill Hall, Memorial Union, Catt Hall, Curtiss Hall, Carver Hall, Parks Library, the Campanile, Hilton Coliseum, C.Y. Stephens Auditorium, Fisher Theater, Jack Trice Stadium, Lied Recreation Center, numerous residence halls, and many buildings specific to ISU's many different majors and colleges. 

The official mascot for ISU is Cy the Cardinal. The official school colors are cardinal and gold. The Iowa State Cyclones play in the NCAA's Division I-A as a member of the Big 12 Conference.

Ames is also served by stations in the Des Moines media market, which includes Clear Channel's 50,000-watt talk station WHO, music stations KAZR, KDRB, KGGO, KKDM, KDXA, KHKI, KIOA, KJJY, KRNT, KSPZ and KSTZ, talk station KWQW, and sports station KXNO, 
Like radio, Ames is served by the Des Moines media market. WOI-DT, the ABC affiliate in central Iowa, was originally owned and operated by Iowa State University until the 1990s. The station is still licensed to Ames, but studio's are located in West Des Moines. Other stations serving Ames include KCCI, KDIN-TV, WHO-DT, KCWI-TV, KDMI, KDSM-TV and KFPX-TV.

The town is served by U.S. Highways 30 and 69 and Interstate 35. Ames is the only town in Iowa with a population of greater than 50,000 that does not have a state highway serving it. , Ames currently has three roundabouts constructed on University Avenue/530th Avenue. The first is at the intersection of Airport Road (Oakwood Rd.) and University Avenue, the second at the intersection of Cottonwood Road and 530th Avenue and the third at Collaboration Place and 530th Avenue.

Ames was serviced by the Fort Dodge, Des Moines and Southern Railroad via a branch from Kelley to Iowa State University and to downtown Ames. The tracks were removed in the 1960s. The Chicago and North Western Transportation Company twin mainline runs east and west bisecting the town and running just south of the downtown business district. The C&NW used to operate a branch to Des Moines. This line was removed in the 1980s when the Spine Line through Nevada was purchased from the Rock Island Railroad after its bankruptcy. The Union Pacific, successor to the C&NW, still runs 60–70 trains a day through Ames on twin mainlines, which leads to some traffic delays. There is also a branch to Eagle Grove that leaves Ames to the north. The Union Pacific maintains a small yard called Ames Yard east of Ames between Ames and Nevada. Ames has been testing automatic train horns at several of its crossings. These directional horns which are focused down the streets are activated when the crossing signals turn on and are shut off after the train crosses the crossing. This system cancels out the need for the trains to blow their horns. Train noise had been a problem in the residential areas to the west and northwest of downtown.

Ames Municipal Airport is located southeast of the city. The current (and only) FBO is Hap's Air Service, a company which has been based at the airport since 1975. The airport has two runways – 01/19, which is , and 13/31, which is .

The City of Ames offers a transit system throughout town, called CyRide, that is funded jointly by Iowa State University, the ISU Government of the Student Body, and the City of Ames. Rider fares are subsidized through this funding, and are free for children under five. Students pay a set cost as part of their tuition.

In 2009, the Ames metropolitan statistical area (MSA) ranked as the third highest in the United States for percentage of commuters who walked to work (10.4 percent).

Ames has the headquarters of the Iowa Department of Transportation.

Ames is served by Mary Greeley Medical Center, a 220-bed regional referral hospital which is adjacent to McFarland Clinic PC, central Iowa's largest physician-owned multi-specialty clinic, and also Iowa Heart Center.

This is a list of notable people associated with Ames, Iowa arranged by career and in alphabetical order.










No. 1 Best U.S. Job Market (CNBC, 2018)<br>
No. 1 Best College Towns in America (24/7 Wall St., 2018)
No. 1 Top Cities for Career Opportunities in 2018 (SmartAsset, 2018)
No. 2 Top 10 Best College Towns (Livability, 2018)
Top 5 Small Metro Areas for Retirees to Age Successfully (Investopedia, 2018)
The Most Fitness Friendly Places of 2018 (SmartAsset, 2017)
Best Public High School in the State (24/7 Wall St., 2017)
Technology Community of the Year (Technology Association of Iowa, 2017)
Top 5 Small Metro Areas for Successful Aging (NCOA, 2017)
Top 3 Cities Where Job Growth is Happening (NationalSwell, 2017)
Best School District in Iowa (Business Insider, 2017)
Best School District in the State (Niche, 2017)
No. 8 of the 25 Best Cities for Entrepreneurs (Entrepreneur Magazine, 2017)
Best Places to Live 2016 (Money, 2016)
Best Small Cities for New Grads (Online Degrees, 2016)
Most Charitable Cities (The Beacon, 2016)
No. 9 of the Top 10 College Towns to Live In (SmartAsset, 2016)
Top 10 Cities for Career Opportunities in 2016 (SmartAsset, 2016)
No. 3 Healthiest Cities in America (24/7 Wall St., 2016)
Best College in Iowa, Iowa State University (Money, 2016)
No. 3 Best College Towns in America (Business Insider, 2016)
No. 5 Medium City of Top U.S. Cities for Public Transportation (Save on Energy, 2016)
U.S. City with the Lowest Unemployment Rate (Forbes, 2016)
No. 4 Best Small City to Make a Living (MoneyGeek, 2016)
No. 35 of the Top 100 Best Places to Live in 2016 (Livability.com, 2016)
No. 3 Best-Performing Small Cities: Where America's Jobs are Created and Sustained List (Milken Institute, 2015)
No. 8 Best Cities in America to Get a Job in 2015 (Business Insider, 2015)
No. 1 of the 15 Cities That Have Done the Best Since the Recession (Bloomberg, 2015)
Top 25 Nationally, Best Places for STEM Grads (Nerdwallet, 2015)
No. 8 Best Towns for Millenials in America (Niche Rankings, 2015)
No. 1 Best College Town in 2014(Livability.com, 2014)

Iowa is a political "battleground state" that has trended slightly Democratic in recent years, and Ames, like Iowa City, also trends Democratic. Iowa is the first caucus state and Ames is a college town. It is the site of many political appearances, debates and events, especially during election years.

From 1979 through 2011, Ames was the location of the Ames Straw Poll, which was held every August prior to a presidential election year in which the Republican presidential nomination was undecided (meaning there was no Republican president running for re-election—as in 2011, 2007, 1999, 1995, 1987, and 1979). The poll would gauge support for the various Republican candidates amongst attendees of a fundraising dinner benefiting the Iowa Republican Party. The straw poll was frequently seen by national media and party insiders as a first test of organizational strength in Iowa. In 2015, the straw poll was to be moved to nearby Boone before the Iowa Republican Party eventually decided to cancel it altogether.




</doc>
<doc id="1300" url="https://en.wikipedia.org/wiki?curid=1300" title="Abalone">
Abalone

Abalone ( or ; via Spanish "", from Rumsen "aulón") is a common name for any of a group of small to very large sea snails, marine gastropod molluscs in the family Haliotidae.

Other common names are ear shells, sea ears, and muttonfish or muttonshells in Australia, ormer in England, abalone in South Africa, and in New Zealand.

Abalone are marine snails. Their taxonomy puts them in the family Haliotidae, which contains only one genus, "Haliotis", which once contained six subgenera. These subgenera have become alternate representations of "Haliotis". The number of species recognized worldwide ranges between 30 and 130 with over 230 species-level taxa described. The most comprehensive treatment of the family considers 56 species valid, with 18 additional subspecies.

The shells of abalones have a low, open spiral structure, and are characterized by several open respiratory pores in a row near the shell's outer edge. The thick inner layer of the shell is composed of nacre (mother-of-pearl), which in many species is highly iridescent, giving rise to a range of strong, changeable colors, which make the shells attractive to humans as decorative objects, jewelry, and as a source of colorful mother-of-pearl.

The flesh of abalones is widely considered to be a desirable food, and is consumed raw or cooked by a variety of cultures.

Abalone vary in size from ("Haliotis pulcherrima") to while "Haliotis rufescens" is the largest of the genus at .

The shell of abalones is convex, rounded to oval in shape, and may be highly arched or very flattened. The shell of the majority of species has a small, flat spire and two to three whorls. The last whorl, known as the body whorl, is auriform, meaning that the shell resembles an ear, giving rise to the common name "ear shell". "Haliotis asinina" has a somewhat different shape, as it is more elongated and distended. The shell of "Haliotis cracherodii cracherodii" is also unusual as it has an ovate form, is imperforate, shows an exserted spire, and has prickly ribs.

A mantle cleft in the shell impresses a groove in the shell, in which are the row of holes characteristic of the genus. These holes are respiratory apertures for venting water from the gills and for releasing sperm and eggs into the water column. They make up what is known as the selenizone, which forms as the shell grows. This series of eight to 38 holes is near the anterior margin. Only a small number is generally open. The older holes are gradually sealed up as the shell grows and new holes form. Each species has a typical number of open holes, between four and 10, in the selenizone. An abalone has no operculum. The aperture of the shell is very wide and nacreous.

The exterior of the shell is striated and dull. The color of the shell is very variable from species to species, which may reflect the animal's diet. The iridescent nacre that lines the inside of the shell varies in color from silvery white, to pink, red and green-red to deep blue, green to purple.

The animal has fimbriated head lobes and side lobes that are fimbriated and cirrated. The radula has small median teeth, and the lateral teeth are single and beam-like. They have about 70 uncini, with denticulated hooks, the first four very large. The rounded foot is very large in comparison to most molluscs. The soft body is coiled around the columellar muscle, and its insertion, instead of being on the columella, is on the middle of the inner wall of the shell. The gills are symmetrical and both well developed.

These snails cling solidly with their broad, muscular foot to rocky surfaces at sublittoral depths, although some species such as "Haliotis cracherodii" used to be common in the intertidal zone. Abalones reach maturity at a relatively small size. Their fecundity is high and increases with their size, laying from 10,000 to 11 million eggs at a time. The spermatozoa are filiform and pointed at one end, and the anterior end is a rounded head.

The adults provide no further assistance to the larvae and they are described as lecithotrophic. The adults are herbivorous and feed with their rhipidoglossan radula on macroalgae, preferring red or brown algae.

The haliotid family has a worldwide distribution, along the coastal waters of every continent, except the Pacific coast of South America, the East Coast of the United States, the Arctic, and Antarctica. The majority of abalone species are found in cold waters, such as off the coasts of New Zealand, South Africa, Australia, Western North America, and Japan.

The shell of the abalone is exceptionally strong and is made of microscopic calcium carbonate tiles stacked like bricks. Between the layers of tiles is a clingy protein substance. When the abalone shell is struck, the tiles slide instead of shattering and the protein stretches to absorb the energy of the blow. Material scientists around the world are studying this tiled structure for insight into stronger ceramic products such as body armor. The dust created by grinding and cutting abalone shell is dangerous; appropriate safeguards must be taken to protect people from inhaling these particles.

Abalones are subject to various diseases. The Victorian Department of Primary Industries said in 2007 that ganglioneuritis killed up to 90% of stock in affected regions. Abalone are also severe hemophiliacs as their fluids will not clot in the case of a laceration or puncture wound. Members of the Spionidae of the polychaetes are known as pests of abalone.

The meat (foot muscle) of abalone is used for food, and the shells of abalone are used as decorative items and as a source of mother of pearl for jewelry, buttons, buckles, and inlay. Abalone shells have been found in archaeological sites around the world, ranging from 100,000-year-old deposits at Blombos Cave in South Africa to historic Chinese abalone middens on California's Northern Channel Islands. On the Channel Islands (California), where abalones were harvested by Native Americans for at least 12,000 years, the size of red abalone shells found in middens declines significantly after about 4000 years ago, probably due to human predation. Worldwide, abalone pearls have also been collected for centuries.

Farming of abalone began in the late 1950s and early 1960s in Japan and China. Since the mid-1990s, there have been many increasingly successful endeavors to commercially farm abalone for the purpose of consumption. Overfishing and poaching have reduced wild populations to such an extent that farmed abalone now supplies most of the abalone meat consumed. The principal abalone farming regions are China, Taiwan, Japan, and Korea. Abalone is also farmed in Australia, Canada, Chile, France, Iceland, Ireland, Mexico, Namibia, New Zealand, South Africa, Spain, Thailand, and the United States.

After trials in 2012, a commercial "sea ranch" was set up in Flinders Bay, Western Australia to raise abalone. The ranch is based on an artificial reef made up of 5000 () separate concrete units called "abitats" (abalone habitats). The habitats can host 400 abalone each. The reef is seeded with young abalone from an onshore hatchery.

The abalone feed on seaweed that has grown naturally on the habitats; with the ecosystem enrichment of the bay also resulting in growing numbers of dhufish, pink snapper, wrasse, Samson fish among other species.

Brad Adams, from the company, has emphasised the similarity to wild abalone and the difference from shore-based aquaculture. "We're not aquaculture, we're ranching, because once they're in the water they look after themselves."

Abalones have long been a valuable food source for humans in every area of the world where a species is abundant. The meat of this mollusc is considered a delicacy in certain parts of Latin America (particularly Chile), France, New Zealand, East Asia and Southeast Asia. In the Greater China region and among Overseas Chinese communities, abalone is commonly known as "bao yu", and sometimes forms part of a Chinese banquet. In the same way as shark fin soup or bird's nest soup, abalone is considered a luxury item, and is traditionally reserved for special occasions such as weddings and other celebrations. However, the availability of commercially farmed abalone has allowed more common consumption of this once rare delicacy.

Abalone started to become popular after the Panama–Pacific International Exposition in 1915.

As abalone became more popular and less common, the prices adjusted accordingly. In the 1920s, a restaurant-served portion of abalone, about 4 ounces, would cost (in inflation adjusted dollars) about $7; by 2004, the price had risen to $75. In America, prior to this time, abalone was predominantly eaten, gathered, and prepared by Chinese immigrants. Before that, abalone were collected to be eaten, and used for other purposes by Native American tribes. By 1900, laws were passed in California to outlaw the taking of abalone above the intertidal zone. This forced the Chinese out of the market and the Japanese perfected diving, with or without gear, to enter the market. By the time of the exposition, Americans were starting to discover abalone. The popularity of abalone, along with many other fish and shellfish, increased as the exposition exhibited 365 varieties of fish with cooking demonstrations, and a 1300-seat dining hall.

In Japan, live and raw abalones are used in awabi sushi, or served steamed, salted, boiled, chopped, or simmered in soy sauce. Salted, fermented abalone entrails are the main component of "tottsuru", a local dish from Honshū. "Tottsuru" is mainly enjoyed with sake.

In California, abalone meat can be found on pizza, sautéed with caramelized mango, or in steak form dusted with cracker meal and flour.

Tasmania supplies about 25% of the yearly world abalone harvest. Around 12,500 Tasmanians recreationally fish for blacklip and greenlip abalone. For blacklip abalone, the size limit varies between for the southern end of the state and for the northern end of the state. Greenlip abalones have a minimum size of , except for an area around Perkins Bay in the north of the state where the minimum size is . With a recreational abalone licence, the bag limit is 10 per day, with a total possession limit of 20. Scuba diving for abalone is allowed, and has a rich history in Australia. (Scuba diving for abalone in the states of New South Wales and Western Australia is illegal; a free-diving catch limit of two is allowed).

Victoria has had an active abalone fishery since the late 1950s. The state is sectioned into three fishing zones, Eastern, Central and Western, with each fisher required a zone-allocated licence. Harvesting is performed by divers using surface-supplied air "hookah" systems operating from runabout-style, outboard-powered boats. While the diver seeks out colonies of abalone amongst the reef beds, the deckhand operates the boat, known as working "live" and stays above where the diver is working. Bags of abalone pried from the rocks are brought to the surface by the diver or by way of "shot line", where the deckhand drops a weighted rope for the catch bag to be connected then retrieved. Divers measure each abalone before removing from the reef and the deckhand remeasures each abalone and removes excess weed growth from the shell. Since 2002, the Victorian industry has seen a significant decline in catches, with the total allowable catch reduced from 1440 to 787 tonnes for the 2011/12 fishing year, due to dwindling stocks and most notably the abalone virus ganglioneuritis, which is fast-spreading and lethal to abalone stocks.

Sport harvesting of red abalone is permitted with a California fishing license and an abalone stamp card. In 2008, the abalone card also came with a set of 24 tags. This was reduced to 18 abalone per year in 2014, and as of 2017 the limit has been reduced to 12, only nine of which may be taken south of Mendocino County. Legal-size abalone must be tagged immediately. Abalone may only be taken using breath-hold techniques or shorepicking; scuba diving for abalone is strictly prohibited. Taking of abalone is not permitted south of the mouth of the San Francisco Bay. A size minimum of measured across the shell is in place. A person may be in possession of only three abalone at any given time.

As of 2017, Abalone season is May to October, excluding July. Transportation of abalone may only legally occur while the abalone is still attached in the shell. Sale of sport-obtained abalone is illegal, including the shell. Only red abalone may be taken, as black, white, pink, flat, green, and pinto abalone are protected by law. In 2018, The California Fish and Game Commission closed recreational abalone season due to dramatically declining populations. That year, they extended the moratorium to last through April, 2021.

An abalone diver is normally equipped with a thick wetsuit, including a hood, bootees, and gloves, and usually also a mask, snorkel, weight belt, abalone iron, and abalone gauge. Alternatively, the rock picker can feel underneath rocks at low tides for abalone. Abalone are mostly taken in depths from a few inches up to ; less common are freedivers who can work deeper than . Abalone are normally found on rocks near food sources such as kelp. An abalone iron is used to pry the abalone from the rock before it has time to fully clamp down. Divers dive from boats, kayaks, tube floats, or directly off the shore.

The largest abalone recorded in California is , caught by John Pepper somewhere off the coast of San Mateo County in September 1993.

The mollusc "Concholepas concholepas" is often sold in the United States under the name "Chilean abalone", though it is not an abalone, but a muricid.

In New Zealand, abalone is called "pāua" (, from the Māori language). "Haliotis iris" (or blackfoot "pāua") is the ubiquitous New Zealand "pāua", the highly polished nacre of which is extremely popular as souvenirs with its striking blue, green, and purple iridescence. "Haliotis australis" and "Haliotis virginea" are also found in New Zealand waters, but are less popular than "H. iris".

Like all New Zealand shellfish, recreational harvesting of "pāua" does not require a permit provided catch limits, size restrictions, and seasonal and local restrictions set by the Ministry for Primary Industries (MPI) are followed. The legal recreational daily limit is 10 per diver, with a minimum shell length of for "H. iris" and for "H. australis". In addition, no person may be in possession, even on land, of more than 20 "pāua" or more than of "pāua" meat at any one time. "Pāua" can only be caught by free-diving; it is illegal to catch them using scuba gear.

An extensive global black market exists in collecting and exporting abalone meat. This can be a particularly awkward problem where the right to harvest "pāua" can be granted legally under Māori customary rights. When such permits to harvest are abused, it is frequently difficult to police. The limit is strictly enforced by roving Ministry for Primary Industries fishery officers with the backing of the New Zealand Police. Poaching is a major industry in New Zealand with many thousands being taken illegally, often undersized. Convictions have resulted in seizure of diving gear, boats, and motor vehicles and fines and in rare cases, imprisonment.

The largest abalone in South Africa, "Haliotis midae", occurs along roughly two-thirds of the country's coastline. Abalone-diving has been a recreational activity for many years, but stocks are currently being threatened by illegal commercial harvesting. In South Africa, all persons harvesting this shellfish need permits that are issued annually, and no abalone may be harvested using scuba gear.

For the last few years, however, no permits have been issued for collecting abalone, but commercial harvesting still continues as does illegal collection by syndicates.
In 2007, because of widespread poaching of abalone, the South African government listed abalone as an endangered species according to the CITES section III appendix, which requests member governments to monitor the trade in this species. This listing was removed from CITES in June 2010 by the South African government and South African abalone is no longer subject to CITES trade controls. Export permits are still required, however.
The abalone meat from South Africa is prohibited for sale in the country to help reduce poaching; however, much of the illegally harvested meat is sold in Asian countries. As of early 2008, the wholesale price for abalone meat was approximately US$40.00 per kilogram. There is an active trade in the shells, which sell for more than US$1,400 per metric tonne.

Ormers ("Haliotis tuberculata") are considered a delicacy in the British Channel Islands as well as in adjacent areas of France, and are pursued with great alacrity by the locals. This, and a recent lethal bacterial disease, has led to a dramatic depletion in numbers since the latter half of the 19th century, and "ormering" is now strictly regulated in order to preserve stocks. The gathering of ormers is now restricted to a number of 'ormering tides', from January 1 to April 30, which occur on the full or new moon and two days following. No ormers may be taken from the beach that are under in shell length. Gatherers are not allowed to wear wetsuits or even put their heads underwater. Any breach of these laws is a criminal offense and can lead to fine of up to £5,000 or six months in prison. The demand for ormers is such that they led to the world's first underwater arrest, when Mr. Kempthorne-Leigh of Guernsey was arrested by a police officer in full diving gear when illegally diving for ormers.

The highly iridescent inner nacre layer of the shell of abalone has traditionally been used as a decorative item, in jewelry, buttons, and as inlay in furniture and in musical instruments such as on fret boards and binding of guitars, etc.

Abalone pearl jewelry is very popular in New Zealand and Australia, in no minor part due to the marketing and farming efforts of pearl companies. Unlike the Oriental Natural, the Akoya pearl, and the South Sea and Tahitian cultured pearls, abalone pearls are not primarily judged by their roundness. The inner shell of the abalone is an iridescent swirl of intense colours, ranging from deep cobalt blue and peacock green to purples, creams and pinks. Therefore, each pearl, natural or cultured, will have its own unique collage of colours.

The shells of abalone are occasionally used in New Age smudging ceremonies to catch falling ash. They have also been used as incense burners.

Abalone has been an important staple in native cultures around the world, specifically in Africa and on the North American West coast. The meat was used as food, and the shell was used as currency for many tribes.

Abalones have been identified as one of the many classes of organism threatened with extinction due to overfishing and the acidification of oceans from anthropogenic carbon dioxide, as reduced pH erodes their shells. It is predicted that abalones will become extinct in the wild within 200 years at current rates of carbon dioxide production. Currently the white, pink, and green abalone are on the federal endangered species list, and possible restoration sites have been proposed for the San Clemente Island and Santa Barbara Island areas. The possibility of farming abalone to be reintroduced into the wild has also been proposed, with these abalone having special tags to help track the population.

The number of species that are recognized within the genus "Haliotis" has fluctuated over time, and depends on the source that is consulted. The number of recognized species range from 30 to 130. This list finds a compromise using the "WoRMS database", plus some species that have been added, for a total of 57. The majority of abalone have not been rated for conservation status. Those that have been reviewed tend to show that the abalone in general is an animal that is declining in numbers, and will need protection throughout the globe.






</doc>
<doc id="1301" url="https://en.wikipedia.org/wiki?curid=1301" title="Abbess">
Abbess

In Catholicism, an abbess (Latin "abbatissa", feminine form of "abbas," abbot) is the female superior of a community of nuns, which is often an abbey.

In the Catholic Church (both the Latin Church and Eastern Catholic), Eastern Orthodox, Coptic and Anglican abbeys, the mode of election, position, rights, and authority of an abbess correspond generally with those of an abbot. She must be at least 40 years old and have been a nun for 10 years. The age requirement in the Catholic Church has evolved over time, ranging from 30 to 60. The requirement of 10 years as a nun is only 8 in Catholicism. In the rare case of there not being a nun with the qualifications, the requirements may be lowered to 30 years of age and 5 of those in an "upright manner", as determined by the superior. A woman who is of illegitimate birth, is not a virgin, has undergone non-salutory public penance, is a widow, or is blind or deaf, is typically disqualified for the position, saving by permission of the Holy See. The office is elective, the choice being by the secret votes of the nuns belonging to the community. Like an abbot, after being confirmed in her office by the Holy See, an abbess is solemnly admitted to her office by a formal blessing, conferred by the bishop in whose territory the monastery is located, or by an abbot or another bishop with appropriate permission. Unlike the abbot, the abbess receives only the ring, the crosier, and a copy of the rule of the order. She does not receive a mitre as part of the ceremony. The abbess also traditionally adds a pectoral cross to the outside of her habit as a symbol of office, though she continues to wear a modified form of her religious habit or dress, as she is unordained—females cannot be ordained—and so does not vest or use choir dress in the liturgy. An abbess serves for life, except in Italy and some adjacent islands.

Abbesses are, like abbots, major superiors according to canon law, the equivalents of abbots or bishops (the ordained male members of the church hierarchy who have, by right of their own office, executive jurisdiction over a building, diocesan territory, or a communal or non-communal group of persons—juridical entities under church law). They receive the vows of the nuns of the abbey; they may admit candidates to their order's novitiate; they may send them to study; and they may send them to do pastoral or missionary, or to work or assist—to the extent allowed by canon and civil law—in the administration and ministry of a parish or diocese (these activities could be inside or outside the community's territory). They have full authority in its administration.

However, there are significant limitations. They may not administer the sacraments, whose celebration is reserved to bishops, priests, deacons (clerics), namely, those in Holy Orders. They may make provision for an ordained cleric to help train and to admit some of their members, if needed, as altar servers, extraordinary ministers of Holy Communion, or lectors—all ministries which are now open to the unordained. They may not serve as a witness to a marriage except by special rescript. They may not administer Penance (Reconciliation), Anointing of the Sick (Extreme Unction), or function as an ordained celebrant or concelebrant of the Mass (by virtue of their office and their training and institution, they may act, if the need arises, as altar servers, lectors, ushers, porters, or extraordinary ministers of Holy Communion, and if need be, the Host). They may preside over the Liturgy of the Hours which they are obliged to say with their community, speak on Scripture to their community, and give certain types of blessings not reserved to the clergy. On the other hand, they may not ordinarily preach a sermon or homily, nor read the Gospel during Mass. As they do not receive episcopal ordination in the Catholic, Orthodox and Oriental Churches, they do not possess the ability to ordain others, nor do they exercise the authority they do possess under canon law over any territories outside of their monastery and its territory (though non-cloistered, non-contemplative female religious members who are based in a convent or monastery but who participate in external affairs may assist as needed by the diocesan bishop and local secular clergy and laity, in certain pastoral ministries and administrative and non-administrative functions not requiring ordained ministry or status as a male cleric in those churches or programs). There are exigent circumstances, where due to Apostolical privilege, certain Abbesses have been granted rights and responsibilities above the normal, such as the Abbess of the Cistercian Monastery of the Abbey of Santa María la Real de Las Huelgas near Burgos, Spain. Also granted exceptional rights was the Abbess of the Cistercian order in Conversano Italy. She was granted the ability to appoint her own vicar-general, select and approve the confessors, along with the practice of receiving the public homage of her clergy. This practice continued until some of the duties were modified due to an appeal by the clergy to Rome. Finally in 1750, the public homage was abolished.

Historically, in some Celtic monasteries, abbesses presided over joint-houses of monks and nuns, the most famous example being Saint Brigid of Kildare's leadership in the founding of the monastery at Kildare in Ireland. This custom accompanied Celtic monastic missions to France, Spain, and even to Rome itself. In 1115, Robert, the founder of Fontevraud Abbey near Chinon and Saumur, France, committed the government of the whole order, men as well as women, to a female superior.

In Lutheran churches, the title of abbess (German "Äbtissin") has in some cases (e.g. ) survived to designate the heads of abbeys which since the Protestant Reformation have continued as monasteries or convents (German "Stifte"). These positions continued, merely changing from Catholic to Lutheran. The first to make this change was the Abbey of Quedlinburg, whose last Catholic Abbess died in 1514. These are collegiate foundations, which provide a home and an income for unmarried ladies, generally of noble birth, called canonesses (German "Kanonissinen") or more usually "Stiftsdamen" or "Kapitularinnen". The office of abbess is of considerable social dignity, and in the past, was sometimes filled by princesses of the reigning houses. Until the dissolution of Holy Roman Empire and mediatisation of smaller imperial fiefs by Napoleon, the evangelical Abbess of Quedlinburg was also per officio the head of that "reichsunmittelbar" state. The last such ruling abbess was Sofia Albertina, Princess of Sweden.

In the Hradčany of Prague is a Catholic institute whose mistress is titled an Abbess. It was founded in 1755 by the Empress Maria Theresa, and traditionally was responsible for the coronation of the Queen of Bohemia. The Abbess is required to be an Austrian Archduchess.

During the Middle Ages abbesses were known to attempt usurpation of the spiritual power forbidden them. Attempts were made to bless, give penance, make the sign of the cross on the foreheads of men, even administer the sacrament. The pope has categorized these forays into the forbidden as "unheard of, most indecorous, and highly preposterous," adding that "these Abbesses had evidently overrated their spiritual powers a trifle." The Roman Catholic Church has around 200 abbesses at present. The oldest women's abbey in Germany being St. Marienthal Abbey of Cistercian nuns, near Ostritz, established during the early 13th-century.

On September 10, 2018, the priory of Our Lady of Ephesus in Gower, MO was elevated to an Abbey and the prioress, Mother Cecilia Snell, OSB, was consecrated as the first abbess. The Benedictines of Mary Queen of Apostles are a traditional order of Benedictines nuns whose monastery is in the Diocese of Kansas City-St. Joseph.




</doc>
<doc id="1303" url="https://en.wikipedia.org/wiki?curid=1303" title="Abdominal surgery">
Abdominal surgery

The term abdominal surgery broadly covers surgical procedures that involve opening the abdomen (laparotomy). Surgery of each abdominal organ is dealt with separately in connection with the description of that organ (see stomach, kidney, liver, etc.) Diseases affecting the abdominal cavity are dealt with generally under their own names (e.g. appendicitis).

The most common abdominal surgeries are described below.


Complications of abdominal surgery include, but are not limited to:

Sterile technique, aseptic post-operative care, antibiotics, use of the WHO Surgical Safety Checklist, and vigilant post-operative monitoring greatly reduce the risk of these complications. Planned surgery performed under sterile conditions is much less risky than that performed under emergency or unsterile conditions. The contents of the bowel are unsterile, and thus leakage of bowel contents, as from trauma, substantially increases the risk of infection.

Globally, there are few studies comparing perioperative mortality following abdominal surgery across different health systems. One major prospective study of 10,745 adult patients undergoing emergency laparotomy from 357 centres in 58 high-, middle-, and low-income countries found that mortality is three times higher in low- compared with high-HDI countries even when adjusted for prognostic factors. In this study the overall global mortality rate was 1·6 per cent at 24 hours (high 1·1 per cent, middle 1·9 per cent, low 3·4 per cent; P < 0·001), increasing to 5·4 per cent by 30 days (high 4·5 per cent, middle 6·0 per cent, low 8·6 per cent; P < 0·001). Of the 578 patients who died, 404 (69·9 per cent) did so between 24 h and 30 days following surgery (high 74·2 per cent, middle 68·8 per cent, low 60·5 per cent). Patient safety factors were suggested to play an important role, with use of the WHO Surgical Safety Checklist associated with reduced mortality at 30 days.

Taking a similar approach, a unique global study of 1,409 children undergoing emergency laparotomy from 253 centres in 43 countries showed that adjusted mortality in children following surgery may be as high as 7 times greater in low-HDI and middle-HDI countries compared with high-HDI countries, translating to 40 excess deaths per 1000 procedures performed in these settings. Internationally, the most common operations performed were appendectomy, small bowel resection, pyloromyotomy and correction of intussusception. After adjustment for patient and hospital risk factors, child mortality at 30 days was significantly higher in low-HDI (adjusted OR 7.14 (95% CI 2.52 to 20.23), p<0.001) and middle-HDI (4.42 (1.44 to 13.56), p=0.009) countries compared with high-HDI countries.



</doc>
<doc id="1304" url="https://en.wikipedia.org/wiki?curid=1304" title="Abduction">
Abduction

Abduction may refer to:







</doc>
<doc id="1305" url="https://en.wikipedia.org/wiki?curid=1305" title="Abensberg">
Abensberg

Abensberg () is a town in the Lower Bavarian district of Kelheim, in Bavaria, Germany, lying around 30 km southwest of Regensburg, 40 km east of Ingolstadt, 50 northwest of Landshut and 100 km north of Munich. It is situated on the Abens river, a tributary of the Danube.

The town lies on the Abens river, a tributary of the Danube, around eight kilometres from the river's source. The area around Abensberg is characterized by the narrow valley of the Danube, where the Weltenburg Abbey stands, the valley of the Altmühl in the north, a left tributary of the Danube, and the famous Hallertau hops-planting region in the south. The town is divided into the municipalities of Abensberg, Arnhofen, Holzharlanden, Hörlbach, Offenstetten, Pullach and Sandharland.

Since the administrative reforms in Bavaria in the 1970s, the town also encompasses the following "Ortsteile":

There had been settlement on this part of the Abens river since long before the High Middle Ages, dating back to Neolithic times. Of particular interest and national importance are the Neolithic flint mines at Arnhofen, where, around 7,000 years ago, Stone Age people made flint, which was fashioned into drills, blades and arrowheads, and was regarded as the steel of the Stone Age. Traces of over 20,000 individuals were found on this site. The modern history of Abensberg, which is often incorrectly compared with that of the 3rd century Roman castra (military outpost) of Abusina, begins with Gebhard, who was the first to mention Abensberg as a town, in the middle of the 12th century. The earliest written reference to the town, under the name of "Habensperch", came from this time, in around 1138. Gebhard was from the Babonen clan.

In 1256, the castrum of "Abensprech" was first mentioned, and on 12 June 1348, Margrave Ludwig of Brandenburg, and his brother, Duke Stephen of Bavaria, raised Abensberg to the status of a city, giving it the right to operate lower courts, enclose itself with a wall and hold markets. The wall was built by Count Ulrich III of Abensberg. Some of the thirty-two round towers and eight turrets are still preserved to this day.

In the Middle Ages, the people of Abensberg enjoyed a level of autonomy above their lord. They elected a city council, although only a small number of rich families were eligible for election.

In around 1390, the Carmelite Monastery of Our Lady of Abensberg was founded by Count John II and his wife, Agnes. Although Abensberg was an autonomous city, it remained dependent on the powerful Dukes of Bavaria. The last Lord of Abensberg, Niclas, Graf von Abensberg, supposedly named after his godfather, Nicholas of Kues, a Catholic cardinal, was murdered in 1485 by Christopher, a Duke of Bavaria-Munich. The year before, Niclas had unchivalrously taken Christopher captive as he bathed before a tournament in Munich. Although Christopher renounced his claim for revenge, he lay in wait for Niclas in Freising. When the latter arrived, he was killed by Seitz von Frauenberg. He is buried in the former convent of Abensberg. 

Abensberg then lost its independence and became a part of the Duchy of Bavaria, and from then on was administered by a ducal official, the so-called caretaker. The castle of Abensberg was destroyed during the Thirty Years' War, although the city had bought a guarantee of protection from the Swedish general, Carl Gustaf Wrangel. During the War of the Spanish Succession emperor Leopold I, who had occupied Bavaria, granted the fief of Abensberg to count Ernst von Abensperg und Traun (1608–1668) from an Austrian noble family named Traun that now received the name of the former counts of Abensberg (who were believed to be distant relatives). After the occupation ended, he was however dispossessed. 

Johannes Aventinus (1477–1534) is the city's most famous son, the founder of the study of history in Bavaria. Aventinus, whose name was real name is Johann or Johannes Turmair ("Aventinus" being the Latin name of his birthplace) wrote the "Annals of Bavaria", a valuable record of the early history of Germany and the first major written work on the subject. He is commemorated in the Walhalla temple, a monument near Regensburg to the distinguished figures of German history. Until 1800, Abensberg was a municipality belonging to the Straubing district of the Electorate of Bavaria. Abensberg also contained a magistrates' court. In the Battle of Abensberg on 19–20 April 1809, Napoleon gained a significant victory over the Austrians under Archduke Ludwig of Austria and General Johann von Hiller.

The arms of the city are divided into two halves. On the left are the blue and white rhombuses of Bavaria, while the right half is split into two silver and black triangles. Two diagonally-crossed silver swords with golden handles rest on top.

The town has had a coat of arms since 1338, that of the Counts of Abensberg. With the death of the last Count, Nicholas of Abensberg, in 1485, the estates fell to the Duchy of Bavaria-Munich, meaning that henceforth only the Bavarian coat of arms was ever used.

On 31 December 1809, a decree of King Maximilian of Bavaria granted the city a new coat of arms, as a recognition of their (mainly humanitarian and logistic) services in the Battle of Abensberg the same year. The diagonally divided field in silver and black came from the old crest of the Counts of Abensberg, while the white and blue diamonds came from that of the House of Wittelsbach, the rulers of Bavaria. The swords recall the Battle of Abensberg.

The district of Offenstetten previously possessed its own coat of arms.


The area around Abensberg, the so-called sand belt between Siegburg, Neustadt an der Donau, Abensberg and Langquaid, is used for the intensive farming of asparagus, due to the optimal soil condition and climate. 212 hectares of land can produce ninety-four asparagus plants. Abensberg asparagus enjoys a reputation among connoisseurs as a particular delicacy. In addition to asparagus, the production of hops plays a major role locally, the region having its own label, and there are still three independent breweries in the area. The town of Abensberg marks the start of the "Deutsche Hopfenstraße" ("German Hops Road"), a nickname given to the Bundesstraße 301, a German federal highway which runs through the heartland of Germany's hops-growing industry, ending in Freising.

The Abensberg railway station is located on the Danube Valley Railway from Regensburg to Ingolstadt. The city can be reached via the A-93 Holledau-Regensburg road (exit Abensberg). Three Bundesstraße (German federal highways) cross south of Abensberg: B 16, B 299 and B 301.

Abensberg has a Grundschule (primary school) and Hauptschule (open admission secondary school), and the Johann-Turmair-Realschule(secondary modern school). There is also a College of Agriculture and Home Economics. Since 2007, the Kelheim Berufsschule has had a campus in Abensberg, and outside the state sector is the St. Francis Vocational Training Centre, run by a Catholic youth organisation.

In 2008, a former goods shed by the main railway station of Abensberg was converted into a theatre by local volunteers. The "Theater am Bahnhof" ("Theatre at the Railway Station") is mostly used by the "Theatergruppe Lampenfieber" and was opened on 19 October 2008.

Abensberg has a long tradition of museums. In the nineteenth century, Nicholas Stark und Peter Paul Dollinger began a collection based on local history. This collection and the collection of the "Heimatverein" (local history society) were united in 1963 into the Aventinus Museum, in the cloister of the former Carmelite monastery. On 7 July 2006, the new Town Museum of Abensberg was opened in the former duke's castle in the town.

Two blocks west of the Old Town is the Kuchlbauer Brewery and beer garden featuring the Kuchlbauer Tower, a colorful and unconventional observation tower designed by Viennese architect Friedensreich Hundertwasser. The brewery and tower are open to the public.

Up until the 1950s, Abensberg and the surrounding villages contained a number of graves of victims of a Death March in the Spring of 1945 from the Hersbruck sub-camp of the Dachau concentration camp, who were either murdered by the SS or died of exhaustion. They were originally buried where they died, but were later moved on the orders of the US military government to the cemeteries of their previous homes. At the cemetery in what is now the district of Pullach stood a memorial stone which was mentioned as recently as 1967, but which is no longer at the site. The suffering of ten unknown victims of the camp was recorded on the stone.







</doc>
<doc id="1306" url="https://en.wikipedia.org/wiki?curid=1306" title="Arminianism">
Arminianism

Arminianism is a branch of Protestantism based on the theological ideas of the Dutch Reformed theologian Jacobus Arminius (1560–1609) and his historic supporters known as Remonstrants. His teachings held to the five solae of the Reformation, but they were distinct from particular teachings of Martin Luther, Huldrych Zwingli, John Calvin, and other Protestant Reformers. Jacobus Arminius (Jakob Harmenszoon) was a student of Theodore Beza (Calvin's successor) at the Theological University of Geneva. Arminianism is known to some as a soteriological diversification of Calvinism; to others, Arminianism is a reclamation of early Church theological consensus.

Dutch Arminianism was originally articulated in the Remonstrance (1610), a theological statement signed by 45 ministers and submitted to the States General of the Netherlands. The Synod of Dort (1618–19) was called by the States General to consider the Five Articles of Remonstrance. These articles asserted that


"These points", note Keith D. Stanglin and Thomas H. McCall, "are consistent with the views of Arminius; indeed, some come verbatim from his "Declaration of Sentiments". Those who signed this remonstrance and others who supported its theology have since been known as Remonstrants."

Many Christian denominations have been influenced by Arminian views on the will of man being freed by Grace prior to regeneration, notably the Baptists in the 16th century, the Methodists in the 18th century and the Seventh-day Adventist Church in the 19th century. Some falsely assert that Universalists and Unitarians in the 18th and 19th centuries were theologically linked with Arminianism. Denominations such as the Anabaptists (beginning in 1525), Waldensians (pre-Reformation), and other groups prior to the Reformation have also affirmed that each person may choose the contingent response of either resisting God's grace or yielding to it.

The original beliefs of Jacobus Arminius himself are commonly defined as Arminianism, but more broadly, the term may embrace the teachings of Hugo Grotius, John Wesley, and others as well. Classical Arminianism, to which Arminius is the main contributor, and Wesleyan Arminianism, to which John Wesley is the main contributor, are the two main schools of thought. Wesleyan Arminianism is often identical with Methodism. Some schools of thought, notably semi-Pelagianism—which teaches that the first step of Salvation is by human will—are confused as being Arminian in nature. But classical Arminianism holds that the first step of Salvation is solely the grace of God. Historically, the Council of Orange (529) condemned semi-Pelagian thought (as well as Supralapsarian Calvinism), and is accepted by some as a document which can be understood as teaching a doctrine between Augustinian thought and semi-Pelagian thought, relegating Arminianism to the orthodoxy of the early Church fathers.

The two systems of Calvinism and Arminianism share both history and many doctrines, and the history of Christian theology. Arminianism is related to Calvinism historically. However, because of their differences over the doctrines of divine predestination and election, many people view these schools of thought as opposed to each other. The distinction is whether God allows His desire to save all to be resisted by an individual's will (in the Arminian doctrine) or if God's grace is irresistible and limited to only some (in Calvinism). Put another way, is God's sovereignty shown, in part, through His allowance of free decisions? Some Calvinists assert that the Arminian perspective presents a synergistic system of Salvation and therefore is not only by Grace, while Arminians firmly reject this conclusion. Many consider the theological differences to be crucial differences in doctrine, while others find them to be relatively minor.

Jacobus Arminius was a Dutch pastor and theologian in the late 16th and early 17th centuries. He was taught by Theodore Beza, Calvin's hand-picked successor, but after examination of the scriptures, he rejected his teacher's theology that it is God who unconditionally elects some for salvation. Instead Arminius proposed that the election of God was "of believers", thereby making it conditional on faith. Arminius's views were challenged by the Dutch Calvinists, especially Franciscus Gomarus, but Arminius died before a national synod could occur.

Arminius's followers, not wanting to adopt their leader's name, called themselves the Remonstrants. When Arminius died before he could satisfy Holland's State General's request for a 14-page paper outlining his views, the Remonstrants replied in his stead crafting the Five articles of Remonstrance. After some political maneuvering, the Dutch Calvinists were able to convince Prince Maurice of Nassau to deal with the situation. Maurice systematically removed Arminian magistrates from office and called a national synod at Dordrecht. This Synod of Dort was open primarily to Dutch Calvinists (Arminians were excluded) with Calvinist representatives from other countries, and in 1618 published a condemnation of Arminius and his followers as heretics. Part of this publication was the famous Five points of Calvinism in response to the five articles of Remonstrance.

Arminians across Holland were removed from office, imprisoned, banished, and sworn to silence. Twelve years later Holland officially granted Arminianism protection as a religion, although animosity between Arminians and Calvinists continued.
The debate between Calvin's followers and Arminius's followers is distinctive of post-Reformation church history. The emerging Baptist movement in 17th-century England, for example, was a microcosm of the historic debate between Calvinists and Arminians. The first Baptists—called "General Baptists" because of their confession of a "general" or unlimited atonement—were Arminians. The Baptist movement originated with Thomas Helwys, who left his mentor John Smyth (who had moved into shared belief and other distinctives of the Dutch Waterlander Mennonites of Amsterdam) and returned to London to start the first English Baptist Church in 1611. Later General Baptists such as John Griffith, Samuel Loveday, and Thomas Grantham defended a Reformed Arminian theology that reflected more the Arminianism of Arminius than that of the later Remonstrants or the English Arminianism of Arminian Puritans like John Goodwin or Anglican Arminians such as Jeremy Taylor and Henry Hammond. The General Baptists encapsulated their Arminian views in numerous confessions, the most influential of which was the Standard Confession of 1660. In the 1640s the Particular Baptists were formed, diverging strongly from Arminian doctrine and embracing the strong Calvinism of the Presbyterians and Independents. Their robust Calvinism was publicized in such confessions as the London Baptist Confession of 1644 and the Second London Confession of 1689. The London Confession of 1689 was later used by Calvinistic Baptists in America (called the Philadelphia Baptist Confession), whereas the Standard Confession of 1660 was used by the American heirs of the English General Baptists, who soon came to be known as Free Will Baptists.

This same dynamic between Arminianism and Calvinism can be seen in the heated discussions between friends and fellow Anglican ministers John Wesley and George Whitefield. Wesley was a champion of Arminian teachings, defending his soteriology in a periodical titled "The Arminian" and writing articles such as "Predestination Calmly Considered". He defended Arminianism against charges of semi-Pelagianism, holding strongly to beliefs in original sin and total depravity. At the same time, Wesley attacked the determinism that he claimed characterized unconditional election and maintained a belief in the ability to lose salvation. Wesley also clarified the doctrine of prevenient grace and preached the ability of Christians to attain to perfection (fully mature, not "sinlessness"). While Wesley freely made use of the term "Arminian," he did not self-consciously root his soteriology in the theology of Arminius but was highly influenced by 17th-century English Arminianism and thinkers such as John Goodwin, Jeremy Taylor and Henry Hammond of the Anglican "Holy Living" school, and the Remonstrant Hugo Grotius.

Advocates of both Arminianism and Calvinism find a home in many Protestant denominations, and sometimes both exist within the same denomination. Faiths leaning at least in part in the Arminian direction include Methodists, Free Will Baptists, Christian Churches and Churches of Christ, General Baptists, the Seventh-day Adventist Church, Church of the Nazarene, The Wesleyan Church, The Salvation Army, Conservative Mennonites, Old Order Mennonites, Amish and Charismatics. Denominations leaning in the Calvinist direction are grouped as the Reformed churches and include Particular Baptists, Reformed Baptists, Presbyterians, and Congregationalists. The majority of Southern Baptists, including Billy Graham, accept Arminianism with an exception allowing for a doctrine of perseverance of the saints ("eternal security"). Many see Calvinism as growing in acceptance, and some prominent Reformed Baptists, such as Albert Mohler and Mark Dever, have been pushing for the Southern Baptist Convention to adopt a more Calvinistic orientation (no Baptist church is bound by any resolution adopted by the Southern Baptist Convention). Lutherans espouse a view of salvation and election distinct from both the Calvinist and Arminian schools of soteriology.

The current scholarly support for Arminianism is wide and varied. One particular thrust is a return to the teachings of Arminius. F. Leroy Forlines, Robert Picirilli, Stephen Ashby and Matthew Pinson (see citations) are four of the more prominent supporters. Forlines has referred to this type of Arminianism as "Classical Arminianism," while Picirilli, Pinson, and Ashby have termed it "Reformation Arminianism" or "Reformed Arminianism." Through Methodism, Wesley's teachings also inspire a large scholarly following, with vocal proponents including J. Kenneth Grider, Stanley Hauerwas, Thomas Oden, Thomas Jay Oord, and William Willimon.

Recent influence of the New Perspective on Paul movement has also reached Arminianism—primarily through a view of corporate election. The New Perspective scholars propose that the 1st-century Second Temple Judaism understood election primarily as national (Israelites) and racial (Jews), not as individual. Their conclusion is thus that Paul's writings on election should be interpreted in a similar corporate light.

Arminian theology usually falls into one of two groups—Classical Arminianism, drawn from the teaching of Jacobus Arminius—and Wesleyan Arminian, drawing primarily from Wesley. Both groups overlap substantially.

Classical Arminianism is the theological system that was presented by Jacobus Arminius and maintained by some of the Remonstrants; its influence serves as the foundation for all Arminian systems. A list of beliefs is given below:


On whether a believer could commit apostasy (i.e., desert Christ by cleaving again to this evil world, losing a good conscience, or by failing to hold on to sound doctrine), Arminius declared that this matter required further study in the Scriptures. Nevertheless, Arminius believed the Scriptures taught that believers are graciously empowered by Christ and the Holy Spirit "to fight against Satan, sin, the world and their own flesh, and to gain the victory over these enemies." Furthermore, Christ and the Spirit are ever present to aid and assist believers through various temptations. But this security was not unconditional but conditional—"provided they [believers] stand prepared for the battle, implore his help, and be not wanting to themselves, Christ preserves them from falling." Arminius goes on to say, "I never taught that a true believer can, either totally or finally fall away from the faith, and perish; yet I will not conceal, that there are passages of scripture which seem to me to wear this aspect; and those answers to them which I have been permitted to see, are not of such a kind as to approve themselves on all points to my understanding."

After the death of Arminius in 1609, the Remonstrants maintained their leader's view on conditional security and his uncertainty regarding the possibility of believers committing apostasy. This is evidenced in the fifth article drafted by its leaders in 1610. However, sometime between 1610, and the official proceeding of the Synod of Dort (1618), the Remonstrants became fully persuaded in their minds that the Scriptures taught that a true believer was capable of falling away from faith and perishing eternally as an unbeliever. They formalized their views in "The Opinion of the Remonstrants" (1618).

Picirilli remarks: "Ever since that early period, then, when the issue was being examined again, Arminians have taught that those who are truly saved need to be warned against apostasy as a real and possible danger."

The core beliefs of Jacobus Arminius and the Remonstrants are summarized as such by theologian Stephen Ashby:


John Wesley has historically been the most influential advocate for the teachings of Arminian soteriology. Wesley thoroughly agreed with the vast majority of what Arminius himself taught, maintaining strong doctrines of original sin, total depravity, conditional election, prevenient grace, unlimited atonement, and the possibility of apostasy.

Wesley departs from Classical Arminianism primarily on three issues:

Since the time of Arminius his name has come to represent a very large variety of beliefs. Some of these beliefs, such as Pelagianism and semi-Pelagianism (see below) are not considered to be within Arminian orthodoxy and are dealt with elsewhere. Some doctrines, however, do adhere to the Arminian foundation and, while minority views, are highlighted below.

The doctrine of open theism states that God is omnipresent, omnipotent, and omniscient, but differs on the nature of the future. Open theists claim that the future is not completely determined (or "settled") because people have not made their free decisions yet. God therefore knows the future partially in possibilities (human free actions) rather than solely certainties (divinely determined events). As such, open theists resolve the issue of human free will and God's sovereignty by claiming that God is sovereign because he does not ordain each human choice, but rather works in cooperation with his creation to bring about his will. This notion of sovereignty and freedom is foundational to their understanding of love since open theists believe that love is not genuine unless it is freely chosen. The power of choice under this definition has the potential for as much harm as it does good, and open theists see free will as the best answer to the problem of evil. Well-known proponents of this theology are Greg Boyd, Clark Pinnock, Thomas Jay Oord, William Hasker, and John E. Sanders.

Some Arminians, such as professor and theologian Robert Picirilli, reject the doctrine of open theism as a "deformed Arminianism". Joseph Dongell stated that "open theism actually moves beyond classical Arminianism towards process theology." There are also some Arminians, like Roger Olson, who believe Open theism to be an alternative view that a Christian can have. The majority Arminian view accepts classical theism—the belief that God's power, knowledge, and presence have no external limitations, that is, outside of his divine nature. Most Arminians reconcile human free will with God's sovereignty and foreknowledge by holding three points:

The majority Arminian view is that election is individual and based on God's foreknowledge of faith, but a second perspective deserves mention. These Arminians reject the concept of individual election entirely, preferring to understand the doctrine in corporate terms. According to this corporate election, God never chose individuals to elect to salvation, but rather He chose to elect the believing church to salvation. Dutch Reformed theologian Herman Ridderbos says "[The certainty of salvation] does not rest on the fact that the church belongs to a certain "number", but that it belongs to Christ, from before the foundation of the world. Fixity does not lie in a hidden decree, therefore, but in corporate unity of the Church with Christ, whom it has come to know in the gospel and has learned to embrace in faith."

Corporate election draws support from a similar concept of corporate election found in the Old Testament and Jewish law. Indeed most biblical scholarship is in agreement that Judeo-Greco-Roman thought in the 1st century was opposite of the Western world's "individual first" mantra—it was very collectivist or communitarian in nature. Identity stemmed from membership in a group more than individuality. According to Romans 9–11, supporters claim, Jewish election as the chosen people ceased with their national rejection of Jesus as Messiah. As a result of the new covenant, God's chosen people are now the corporate body of Christ, the church (sometimes called "spiritual Israel"—see also Covenant theology). The pastor and theologian Brian Abasciano claims "What Paul says about Jews, Gentiles, and Christians, whether of their place in God’s plan, or their election, or their salvation, or how they should think or behave, he says from a corporate perspective which views the group as primary and those he speaks about as embedded in the group. These individuals act as members of the group to which they belong, and what happens to them happens by virtue of their membership in the group."

These scholars also maintain that Jesus was the only human ever elected and that individuals must be "in Christ" (Eph 1:3–4) through faith to be part of the elect. This was, in fact, Swiss Reformed theologian, Karl Barth's, understanding of the doctrine of election. Joseph Dongell, professor at Asbury Theological Seminary, states "the most conspicuous feature of Ephesians 1:3–2:10 is the phrase 'in Christ', which occurs twelve times in Ephesians 1:3–14 alone...this means that Jesus Christ himself is the chosen one, the predestined one. Whenever one is incorporated into him by grace through faith, one comes to share in Jesus' special status as chosen of God." Markus Barth illustrates the inter-connectedness: "Election in Christ must be understood as the election of God's people. Only as members of that community do individuals share in the benefits of God's gracious choice."

Understanding Arminianism is aided by understanding the theological alternatives: Pelagianism, semi-Pelagianism, Lutheranism, and Calvinism. Arminianism, like any major belief system, is frequently misunderstood both by critics and would-be supporters.

The following are Arminian beliefs compared to other Protestants.



Ever since Arminius and his followers revolted against Calvinism in the early 17th century, Protestant soteriology has been largely divided between Calvinism and Arminianism. The extreme of Calvinism is hyper-Calvinism, which insists that signs of election must be sought before evangelization of the unregenerate takes place and that the eternally damned have no obligation to repent and believe, and on the extreme of Arminianism is Pelagianism, which rejects the doctrine of original sin on grounds of moral accountability; but the overwhelming majority of Protestant, evangelical pastors and theologians hold to one of these two systems or somewhere in between.








</doc>
<doc id="1307" url="https://en.wikipedia.org/wiki?curid=1307" title="The Alan Parsons Project">
The Alan Parsons Project

The Alan Parsons Project were an English rock band active between 1975 and 1990, whose core membership consisted of Alan Parsons and Eric Woolfson. They were accompanied by a varying number of session musicians and some relatively consistent band members such as guitarist Ian Bairnson, arranger Andrew Powell, bassist and vocalist David Paton, drummer Stuart Elliott, and vocalists Lenny Zakatek and Chris Rainbow. Parsons was an audio engineer and producer by profession, but also a musician and a composer. A songwriter by profession, Woolfson was also a composer, a pianist, and a singer. Almost all the songs on the Project's albums are credited to "Woolfson/Parsons". The Alan Parsons Project released eleven studio albums in its 15-year career (the twelfth, "The Sicilian Defence" - which was originally recorded in 1979 - was released posthumously in 2014), and some of their most notable songs are "The Raven", "(The System of) Dr. Tarr and Professor Fether", "I Wouldn't Want to Be Like You", "Games People Play", "Time", "Snake Eyes", "Eye in the Sky", "Old and Wise" and "Don't Answer Me".

Alan Parsons met Eric Woolfson in the canteen of Abbey Road Studios in the summer of 1974. Parsons had already acted as Assistant Engineer on the Beatles' albums "Abbey Road" (1969) and "Let It Be" (1970), had recently engineered Pink Floyd's "The Dark Side of the Moon" (1973), and had produced several acts for EMI Records. Woolfson, a songwriter and composer, was working as a session pianist; he had also composed material for a concept album idea based on the work of Edgar Allan Poe.

When Parsons asked Woolfson to become his manager, he accepted and subsequently managed Parsons's career as a producer and engineer through a string of successes, including Pilot, Steve Harley, Cockney Rebel, John Miles, Al Stewart, Ambrosia, and the Hollies. Parsons commented at the time that he felt frustrated in having to accommodate the views of some of the musicians, which he felt interfered with his production. Woolfson came up with the idea of making an album based on developments in the film industry, where the focal point of the films' promotion shifted from film stars to directors such as Alfred Hitchcock and Stanley Kubrick. If the film industry was becoming a director's medium, Woolfson felt the music business might well become a producer's medium.

Recalling his earlier Edgar Allan Poe material, Woolfson saw a way to combine his and Parsons's respective talents. Parsons would produce and engineer songs written and composed by the two, and the first Alan Parsons Project was begun. The Project's first album, "Tales of Mystery and Imagination" (1976), which was released by 20th Century Fox Records and included major contributions by all members of Pilot and Ambrosia, was a success, reaching the Top 40 in the US "Billboard" 200 chart. The song "The Raven" featured lead vocals by the actor Leonard Whiting, and, according to the 2007 remastered album liner notes, was the first rock song to use a digital vocoder, with Alan Parsons speaking lyrics through it.

Arista Records then signed the Alan Parsons Project participants for further albums. Through the late 1970s and early 1980s, the Project's popularity continued to grow. (However, the Project was always more popular in North America, Ibero-America, and Continental Europe than in Parsons's home country, never achieving a UK Top 40 single or Top 20 album). The singles "I Wouldn't Want to Be Like You", "Games People Play", "Damned If I Do", "Time" (the first single to feature Woolfson's lead vocal) and "Eye in the Sky" had a notable impact on the "Billboard" Hot 100. "Don't Answer Me" became the Project's last successful single in the United States; it reached the top 15 on the American charts in 1984. After those successes, however, the Project began to fade from view. There were fewer hit singles, and declining album sales. 1987's "Gaudi" would be the Project's final release, though it had planned to record an album called "Freudiana" (1990) next.

Even though the studio version of "Freudiana" was produced by Parsons (and featured the regular Project backing musicians, making it an 'unofficial' Project album), it was primarily Woolfson's idea to turn it into a musical. This eventually led to a rift between the two artists. While Parsons pursued his own solo career and took many members of the Project on the road for the first time in a successful worldwide tour, Woolfson went on to produce musical plays influenced by the Project's music. "Freudiana", "Gaudi", and "Gambler" were three musicals that included some Project songs like "Eye in the Sky", "Time", "Inside Looking Out", and "Limelight". The live music from "Gambler" was only distributed at the performance site in Mönchengladbach, Germany.

In 1979, Parsons, Woolfson, and their record label Arista, had been stalled in contract renegotiations when the two submitted an all-instrumental album tentatively titled "The Sicilian Defence", named after an aggressive opening move in chess, arguably to get out of their recording contract. Arista's refusal to release the album had two known effects: the negotiations led to a renewed contract, and the album was not released at that time.

In interviews he gave before his death in 2009, Woolfson said he planned to release one track from the "Sicilian" album, which in 2008 appeared as a bonus track on a CD re-issue of the "Eve" album. Sometime later, after he had relocated the original tapes, Parsons had completely changed his mind about the album and announced that it would finally be released on an upcoming Project box set called "The Complete Albums Collection" in 2014 for the first time as a bonus disc.

Parsons released titles under his name; these were "Try Anything Once" (1993), "On Air" (1996), "The Time Machine" (1999), "A Valid Path" (2004) and " The Secret" (2019). Meanwhile, Woolfson made concept albums titled "Freudiana" (1990), about Sigmund Freud's work on psychology, and "" (2003); this continued from the Alan Parsons Project's first album about Edgar Allan Poe's literature.

"Tales of Mystery and Imagination" (1976) was first remixed in 1987 for release on CD, and included narration by Orson Welles which had been recorded in 1975, but arrived too late to be included on the original album. On the 2007 deluxe edition release, it is revealed that parts of this tape were used for the 1976 Griffith Park Planetarium launch of the original album, the 1987 remix, and various radio spots, all of which were included as bonus material.

"Sirius", eventually became the best-known, or, at least, the most frequently heard, of all Parsons songs. It was used as entrance music by various American sports teams, most notably by the Chicago Bulls during their 1990s NBA dynasty. It was also used as the entrance theme for Ricky Steamboat in pro wrestling of the mid-1980s. In addition, "Sirius" has been played in a variety of TV shows and movies including the BBC series Record Breakers, the episode "Vanishing Act" of "" and the 2009 film "Cloudy with a Chance of Meatballs".

Lead vocal duties were shared by guest vocalists chosen by their style to complement each song. In later years, Woolfson sang lead on many of the group's hits, including "Time", "Eye in the Sky", and "Don't Answer Me". The record company pressured Parsons to use him more. However, Parsons preferred to use more technically polished and proficient singers, which Woolfson admitted he was not. In addition to Woolfson, vocalists Chris Rainbow, Lenny Zakatek, John Miles, David Paton, and Colin Blunstone made regular appearances. Other singers, such as Arthur Brown, Steve Harley, Gary Brooker, Dave Terry a.k.a. Elmer Gantry, Vitamin Z's Geoff Barradale, and Marmalade's Dean Ford, have recorded only once or twice with the Project. Parsons himself only sang lead on one song ("The Raven") through a vocoder and backing on a few others, including "To One in Paradise". Both of those songs appeared on "Tales of Mystery and Imagination" (1976).

A small number of musicians worked with the Alan Parsons Project regularly. These core musicians contributed to the recognisable style of a Project song in spite of the varied singer line-up. Together with Parsons and Woolfson, the Project originally consisted of the group Pilot, with Ian Bairnson (guitar), David Paton (bass) and Stuart Tosh (drums). Pilot's keyboardist Billy Lyall also contributed. From "Pyramid" (1978) onwards, Tosh was replaced by Stuart Elliott of Cockney Rebel. Bairnson played on all albums, and Paton stayed almost until the end. Andrew Powell appeared as arranger of orchestra (and often choirs) on all albums except "Vulture Culture" (1985), when he was composing the score of Richard Donner's film "Ladyhawke" (1985). This score was partly in the Project style, recorded by most of the Project regulars, and produced and engineered by Parsons. Powell also composed some material for the first two Project albums. From "Vulture Culture" onwards, Richard Cottle played as a regular member on synthesizers and saxophone.
Except for one occasion, the Project never played live during its original incarnation. This was because Woolfson and Parsons saw themselves mainly in the roles of writing and production, and also because of the technical difficulties of reproducing on stage the complex instrumentation used in the studio. In the 1990s things changed with the technology of digital samplers. The one occasion where the band was introduced as 'The Alan Parsons Project' in a live performance was at Night of the Proms in October 1990 (at the time of the group's break-up), featuring all Project regulars except Woolfson, who was present but behind the scenes, while Parsons stayed at the mixer except during the last song, where he played acoustic guitar.

Since 1993, a new version of the band has toured, with Parsons performing live acoustic guitar, keyboards and vocals, with various line-ups. This latest incarnation was called Alan Parsons, later renamed the Alan Parsons Live Project to be distinct from 'The Alan Parsons Project', due to founder Parsons' break-up with Woolfson. The band currently features lead singer P.J. Olsson, guitarist Jeffrey Kollman, drummer Danny Thompson, keyboardist Tom Brooks, bass guitarist Guy Erez, vocalist and saxophonist Todd Cooper, and guitarist and vocalist Dan Tracey. In 2013, Alan Parsons Live Project played Colombia with a full choir and orchestra (the Medellin Philharmonic) as 'Alan Parsons Symphonic Project'. A 2-CD live set and a DVD version of this concert were released in May 2016.




"The Simpsons" episode "Homerpalooza" features Homer explaining 1970s rock music to Lisa, Bart and Milhouse: "Grand Funk Railroad paved the way for Jefferson Airplane, which cleared the way for Jefferson Starship. The stage was now set for the Alan Parsons Project, which I believe was some sort of hovercraft."

In the 1999 comedy film "", the weapon that Dr. Evil has installed on the moon is referred to as 'The Alan Parsons Project', to which his son Scott Evil makes fun of him for using the name and informing him of the band.



</doc>
<doc id="1309" url="https://en.wikipedia.org/wiki?curid=1309" title="Almost all">
Almost all

In mathematics, the term "almost all" means "all but a negligible amount". More precisely, if X is a set, "almost all elements of X" means "all elements of X but those in a negligible subset of X". The meaning of "negligible" depends on the mathematical context; for instance, it can mean finite, countable, or null.

In contrast, "almost no" means "a negligible amount"; that is, "almost no elements of X" means "the elements of some negligible subset of X".

Throughout mathematics, "almost all" is sometimes used to mean "all (elements of an infinite set) but finitely many". This use occurs in philosophy as well. Similarly, "almost all" can mean "all (elements of an uncountable set) but countably many".

Examples:

When speaking about the reals, sometimes "almost all" means "all reals but a null set". Similarly, if S is some set of reals, "almost all numbers in S" can mean "all numbers in S but those in a null set". The real line can be thought of as a one-dimensional Euclidean space. In the more general case of an n-dimensional space (where n is a positive integer), these definitions can be generalised to "all points but those in a null set" or "all points in S but those in a null set" (this time, S is a set of points in the space). Even more generally, "almost all" is sometimes used in the sense of "almost everywhere" in measure theory, or in the closely related sense of "almost surely" in probability theory.

Examples:

In number theory, "almost all positive integers" can mean "the positive integers in a set whose natural density is 1". That is, if A is a set of positive integers, and if the proportion of positive integers below n that are in A (out of all positive integers below n) tends to 1 as n tends to infinity, then almost all positive integers are in A. More generally, let S be an infinite set of positive integers, such as the set of even positive numbers or of primes. If A is a subset of S, and if the proportion of elements of S below n that are in A (out of all elements of S below n) tends to 1 as n tends to infinity, then it can be said that almost all elements of S are in A.

Examples:

In graph theory, if A is a set of (finite labelled) graphs, it can be said to contain almost all graphs if the proportion of graphs with n vertices that are in A tends to 1 as n tends to infinity. However, it is sometimes easier to work with probabilities, so the definition is reformulated as follows. The proportion of graphs with n vertices that are in A equals the probability that a random graph with n vertices (chosen with the uniform distribution) is in A, and choosing a graph in this way has the same outcome as generating a graph by flipping a coin for each pair of vertices to decide whether to connect them. Therefore, equivalently to the preceding definition, A contains almost all graphs if the probability that a coin flip-generated graph with n vertices is in A tends to 1 as n tends to infinity. Sometimes the latter definition is modified so that the graph is chosen randomly in some other way, where not all graphs with n vertices have the same probability, and those modified definitions are not always equivalent to the main one.

The use of the term "almost all" in graph theory is not standard; the term "asymptotically almost surely" is more commonly used for this concept.

Example:

In topology and especially dynamical systems theory (including applications in economics), "almost all" of a topological space's points can mean "all of the space's points but those in a meagre set". Some use a more limited definition, where a subset only contains almost all of the space's points if it contains some open dense set.

Example:

In abstract algebra and mathematical logic, if U is an on a set X, "almost all elements of X" sometimes means "the elements of some "element" of U". For any partition of X into two disjoint sets, one of them necessarily contains almost all elements of X. It is possible to think of the elements of a filter on X as containing almost all elements of X even if it isn't an ultrafilter.


</doc>
<doc id="1313" url="https://en.wikipedia.org/wiki?curid=1313" title="Aromatic hydrocarbon">
Aromatic hydrocarbon

An aromatic hydrocarbon or arene (or sometimes aryl hydrocarbon) is a hydrocarbon with sigma bonds and delocalized pi electrons between carbon atoms forming a circle. In contrast, aliphatic hydrocarbons lack this delocalization. The term "aromatic" was assigned before the physical mechanism determining aromaticity was discovered; the term was coined as such simply because many of the compounds have a sweet or pleasant odour. The configuration of six carbon atoms in aromatic compounds is known as a benzene ring, after the simplest possible such hydrocarbon, benzene. Aromatic hydrocarbons can be "monocyclic" (MAH) or "polycyclic" (PAH).

Some non-benzene-based compounds called heteroarenes, which follow Hückel's rule (for monocyclic rings: when the number of its π electrons equals 4"n" + 2, where "n" = 0, 1, 2, 3, ...), are also called aromatic compounds. In these compounds, at least one carbon atom is replaced by one of the heteroatoms oxygen, nitrogen, or sulfur. Examples of non-benzene compounds with aromatic properties are furan, a heterocyclic compound with a five-membered ring that includes a single oxygen atom, and pyridine, a heterocyclic compound with a six-membered ring containing one nitrogen atom.

Benzene, CH, is the least complex aromatic hydrocarbon, and it was the first one named as such. The nature of its bonding was first recognized by August Kekulé in the 19th century. Each carbon atom in the hexagonal cycle has four electrons to share. One goes to the hydrogen atom, and one to each of the two neighbouring carbons. This leaves one electron to share with one of the two neighbouring carbon atoms, thus creating a double bond with one carbon and leaving a single bond with the other, which is why the benzene molecule is drawn with alternating single and double bonds around the hexagon.

The structure is alternatively illustrated as a circle around the inside of the ring to show six electrons floating around in delocalized molecular orbitals the size of the ring itself. This depiction represents the equivalent nature of the six carbon–carbon bonds all of bond order 1.5; the equivalency is explained by resonance forms. The electrons are visualized as floating above and below the ring with the electromagnetic fields they generate acting to keep the ring flat.

General properties of aromatic hydrocarbons:


The circle symbol for aromaticity was introduced by Sir Robert Robinson and his student James Armit in 1925 and popularized starting in 1959 by the Morrison & Boyd textbook on organic chemistry. The proper use of the symbol is debated; it is used to describe any cyclic π system in some publications, or only those π systems that obey Hückel's rule in others. Jensen argues that, in line with Robinson's original proposal, the use of the circle symbol should be limited to monocyclic 6 π-electron systems. In this way the circle symbol for a six-center six-electron bond can be compared to the Y symbol for a three-center two-electron bond.

A reaction that forms an arene compound from an unsaturated or partially unsaturated cyclic precursor is simply called an aromatization. Many laboratory methods exist for the organic synthesis of arenes from non-arene precursors. Many methods rely on cycloaddition reactions. Alkyne trimerization describes the [2+2+2] cyclization of three alkynes, in the Dötz reaction an alkyne, carbon monoxide and a chromium carbene complex are the reactants. Diels–Alder reactions of alkynes with pyrone or cyclopentadienone with expulsion of carbon dioxide or carbon monoxide also form arene compounds. In Bergman cyclization the reactants are an enyne plus a hydrogen donor.

Another set of methods is the aromatization of cyclohexanes and other aliphatic rings: reagents are catalysts used in hydrogenation such as platinum, palladium and nickel (reverse hydrogenation), quinones and the elements sulfur and selenium.

Arenes are reactants in many organic reactions.

In aromatic substitution one substituent on the arene ring, usually hydrogen, is replaced by another substituent. The two main types are electrophilic aromatic substitution when the active reagent is an electrophile and nucleophilic aromatic substitution when the reagent is a nucleophile. In radical-nucleophilic aromatic substitution the active reagent is a radical. An example of electrophilic aromatic substitution is the nitration of salicylic acid:

In coupling reactions a metal catalyses a coupling between two formal radical fragments. Common coupling reactions with arenes result in the formation of new carbon–carbon bonds e.g., alkylarenes, vinyl arenes, biraryls, new carbon–nitrogen bonds (anilines) or new carbon–oxygen bonds (aryloxy compounds). An example is the direct arylation of perfluorobenzenes 

Hydrogenation of arenes create saturated rings. The compound 1-naphthol is completely reduced to a mixture of decalin-ol isomers.
The compound resorcinol, hydrogenated with Raney nickel in presence of aqueous sodium hydroxide forms an enolate which is alkylated with methyl iodide to 2-methyl-1,3-cyclohexandione:

Cycloaddition reaction are not common. Unusual thermal Diels–Alder reactivity of arenes can be found in the Wagner-Jauregg reaction. Other photochemical cycloaddition reactions with alkenes occur through excimers.

In dearomatization reactions the aromaticity of the reactant is permanently lost.

Benzene derivatives have from one to six substituents attached to the central benzene core. Examples of benzene compounds with just one substituent are phenol, which carries a hydroxyl group, and toluene with a methyl group. When there is more than one substituent present on the ring, their spatial relationship becomes important for which the arene substitution patterns "ortho", "meta", and "para" are devised. For example, three isomers exist for cresol because the methyl group and the hydroxyl group can be placed next to each other ("ortho"), one position removed from each other ("meta"), or two positions removed from each other ("para"). Xylenol has two methyl groups in addition to the hydroxyl group, and, for this structure, 6 isomers exist.

The arene ring has an ability to stabilize charges. This is seen in, for example, phenol (CH–OH), which is acidic at the hydroxyl (OH), since a charge on this oxygen (alkoxide –O) is partially delocalized into the benzene ring.

Other monocyclic aromatic hydrocarbon include Cyclotetradecaheptaene or Cyclooctadecanonaene.

Polycyclic aromatic hydrocarbons (PAHs) are aromatic hydrocarbons that consist of fused aromatic rings and do not contain heteroatoms or carry substituents. Naphthalene is the simplest example of a PAH. PAHs occur in oil, coal, and tar deposits, and are produced as byproducts of fuel burning (whether fossil fuel or biomass). As pollutants, they are of concern because some compounds have been identified as carcinogenic, mutagenic, and teratogenic. PAHs are also found in cooked foods. Studies have shown that high levels of PAHs are found, for example, in meat cooked at high temperatures such as grilling or barbecuing, and in smoked fish.

They are also found in the interstellar medium, in comets, and in meteorites and are a candidate molecule to act as a basis for the earliest forms of life. In graphene the PAH motif is extended to large 2D sheets.



</doc>
<doc id="1315" url="https://en.wikipedia.org/wiki?curid=1315" title="Abbey">
Abbey

An abbey is a complex of buildings used by members of a religious order under the governance of an abbot or abbess. It provides a place for religious activities, work, and housing of Christian monks and nuns. 

The concept of the abbey has developed over many centuries from the early monastic ways of religious men and women where they would live isolated from the lay community about them. Religious life in an abbey may be monastic. An abbey may be the home of an enclosed religious order or may be open to visitors. The layout of the church and associated buildings of an abbey often follows a set plan determined by the founding religious order. 

Abbeys are often self-sufficient while using any abundance of produce or skill to provide care to the poor and needy, refuge to the persecuted, or education to the young. Some abbeys offer accommodation to people who are seeking spiritual retreat. There are many famous abbeys across Europe.

The earliest known Christian monasteries were groups of huts built near the residence of a famous ascetic or other holy person. Disciples wished to be close to their holy man or woman in order to study their doctrine or imitate their way of life.

In the earliest times of Christian monasticism, ascetics would live in social isolation but near a village church. They would subsist whilst donating any excess produce to the poor. However, increasing religious fervor about the ascetic's ways and or persecution of them would drive them further away from their community and further into solitude. For instance, the cells and huts of anchorites (religious recluses) have been found in the deserts of Egypt.

In 312 AD, Anthony the Great retired to the Thebaid region of Egypt to escape the persecution of the Emperor Maximian. Anthony was the best known of the anchorites of his time due to his degree of austerity, sanctity and his powers of exorcism. The deeper he withdrew into the wilderness, the more numerous his disciples became. They refused to be separated from him and built their cells close to him. This became a first true monastic community. Anthony, according to Johann August Wilhelm Neander, inadvertently became the founder of a new mode of living in common, Coenobitism.

At Tabennae on the Nile, in Upper Egypt, Saint Pachomius laid the foundations for the coenobitical life by arranging everything in an organized manner. He built several monasteries, each with about 1,600 separate cells laid out in lines. These cells formed an encampment where the monks slept and performed some of their manual tasks. There were nearby large halls such as the church, refectory, kitchen, infirmary, and guest house for the monk's common needs. An enclosure protecting all these buildings gave the settlement the appearance of a walled village. This layout, known as the "laurae" (lanes), became popular throughout Palestine.

As well as the "laurae", communities known as "caenobia" developed. These were monasteries where monks lived a common life together. The monks were not permitted to retire to the cells of a laurae before they had undergone a lengthy period of training. In time, this form of common life superseded that of the older laurae.

In the late 300s AD, Palladius visited the Egyptian monasteries. He described three hundred members of the coenobium of Panopolis. There were fifteen tailors, seven smiths, four carpenters, twelve camel-drivers and fifteen tanners. These people were divided into subgroups, each with its own "oeconomus". A chief steward was at the head of the monastery.

The produce of the monastery was brought to Alexandria for sale. The moneys raised were used to purchase stores for the monastery or were given away as charity. Twice in the year, the superiors of several coenobia met at the chief monastery, under the presidency of an "archimandrite" (the "chief of the fold" from the word, "miandra" (a sheepfold)) in order to make their reports. Chrysostom recorded the workings of a coenobia in the vicinity of Antioch. The monks lived in separate huts ("kalbbia") which formed a religious hamlet on the mountainside. They were subject to an abbot, and observed a common rule.

The layout of the monastic coenobium was influenced by a number of factors. These included a need for defence, economy of space, and convenience of access. The layout of buildings became compact and orderly. Larger buildings were erected and defence was provided by strong outside walls. Within the walls, the buildings were arranged around one or more open courts surrounded by cloisters. The usual arrangement for monasteries of the Eastern world is exemplified in the plan of the convent of the Great Lavra at Mount Athos.

With reference to the diagram, right, the convent of the Great Lavra is enclosed within a strong and lofty blank stone wall. The area within the wall is between three and four acres (12,000 and 16,000 m²). The longer side is about in length. There is only one entrance, which is located on the north side (A), defended by three iron doors. Near the entrance is a large tower (M), a constant feature in the monasteries of the Levant (Eastern Mediterranean area). There is a small postern gate at L.

The enceinte comprises two large open courts, surrounded with buildings connected with cloister galleries of wood or stone. The outer court, which is the larger by far, contains the granaries and storehouses (K), the kitchen (H) and other offices connected with the refectory (G). Immediately adjacent to the gateway is a two-storied guest-house, entered from a cloister (C). The inner court is surrounded by a cloister (EE) from which one enters the monks' cells (II).

In the centre of this court stands the katholikon or conventual church, a square building with an apse of the cruciform domical Byzantine type, approached by a domed narthex. In front of the church stands a marble fountain (F), covered by a dome supported on columns.

Opening from the western side of the cloister, but actually standing in the outer court, is the refectory (G), a large cruciform (cross shaped) building, about square, decorated within with frescoes of saints. At the upper end is a semicircular recess, similar to the triclinium of the Lateran Palace in Rome, in which is placed the seat of the hegumenos or abbot. This apartment is chiefly used as a meeting place, with the monks usually taking their meals in their separate cells.

Monasticism in the West began with the activities of Benedict of Nursia (born 480 AD). Near Nursia, a town in Perugia, Italy, a first abbey was established at Monte Cassino (529 AD). Between 520 and 700 AD, monasteries were built which were spacious and splendid. All the city states of Italy hosted a Benedictine convent as did the cities of England, France and Spain. By 1415 AD, the time of the Council of Constance, 15,070 Benedictine monasteries had been established.

The early Benedictine monasteries, including the first at Monte Cassino, were constructed on the plan of the Roman villa. The layout of the Roman villa was quite consistent throughout the Roman Empire and where possible, the monks reused available villas in sound repair. This was done at Monte Cassino.

However, over time, changes to the common villa lay out occurred. The monks required buildings which suited their religious and day-to-day activities. No overriding specification was demanded of the monks but the similarity of their needs resulted in uniformity of design of abbeys across Europe. Eventually, the buildings of a Benedictine abbey were built in a uniform lay out, modified where necessary, to accommodate local circumstances.

The plan of the Abbey of Saint Gall (719 AD) indicates the general arrangement of a Benedictine monastery of its day. According to the architect Robert Willis (architect) (1800–1875) the Abbey's lay out is that of a town of individual houses with streets running between them. The abbey was planned in compliance with the Benedictine rule that, if possible, a monastery should be self-contained. For instance, there was a mill, a bakehouse, stables, and cattle stalls. In all, there were thirty-three separate structures; mostly one level wooden buildings.

The Abbey church occupied the centre of a quadrangular area, about square. On the eastern side of the north transept of the church was the "scriptorium" or writing-room, with a library above.

The church and nearby buildings ranged about the cloister, a court about which there was a covered arcade which allowed sheltered movement between the buildings. The nave of the church was on the north boundary of the cloister.

On the east side of the cloister, on the ground floor, was the "pisalis" or "calefactory". This was a common room, warmed by flues beneath the floor. Above the common room was the dormitory. The dormitory opened onto the cloister and also onto the south transept of the church. This enabled the monks to attend nocturnal services. A passage at the other end of the dormitory lead to the "necessarium" (latrines).

On the south side of the cloister was the refectory. The kitchen, at the west end of the refectory was accessed via an anteroom and a long passage. Nearby were the bake house, brew house and the sleeping-rooms of the servants. The upper story of the refectory was called the "vestiarium" (a room where the ordinary clothes of the monks were stored).

On the western side of the cloister was another two-story building with a cellar on the ground floor and the larder and store-room on the upper floor. Between this building and the church was a parlour for receiving visitors. One door of the parlour led to the cloisters and the other led to the outer part of the Abbey.

Against the outer wall of the church was a school and headmaster's house. The school consisted of a large schoolroom divided in the middle by a screen or partition, and surrounded by fourteen little rooms, the "dwellings of the scholars". The abbott's home was near the school.

To the north of the church and to the right of the main entrance to the Abbey, was a residence for distinguished guests. To the left of the main entrance was a building to house poor travellers and pilgrims. There was also a building to receive visiting monks. These "hospitia" had a large common room or refectory surrounded by bed rooms. Each hospitium had its own brewhouse and bakehouse, and the building for more prestigious travellers had a kitchen and storeroom, with bedrooms for the guests' servants and stables for their horses. The monks of the Abbey lived in a house built against the north wall of the church.

The whole of the southern and western areas of the Abbey were devoted to workshops, stables and farm-buildings including stables, ox-sheds, goatstables, piggeries, and sheep-folds, as well as the servants' and labourers' quarters.

In the eastern part of the Abbey there was a group of buildings representing in layout, two complete miniature monasteries. That is, each had a covered cloister surrounded by the usual buildings such as the church, the refectory, the dormitory and so on. A detached building belonging to each contained a bathroom and a kitchen.

One of the miniature complexes was called the "oblati". These were the buildings for the novices. The other complex was a hospital or infirmary for the care of sick monks. This infirmary complex included a physician's residence, a physic garden, a drug store, and a chamber for the critically ill. There was also a room for bloodletting and purging. The physic garden occupied the north east corner of the Abbey.

In the southern most area of the abbey was the workshop containing utilities for shoemakers, saddlers (or shoemakers, sellarii), cutlers and grinders, trencher-makers, tanners, curriers, fullers, smiths and goldsmiths. The tradesmen's living quarters were at the rear of the workshop. Here, there were also farm buildings, a large granary and threshing-floor, mills, and malthouse. At the south-east corner of the Abbey were hen and duck houses, a poultry-yard, and the dwelling of the keeper. Nearby was the kitchen garden which complemented the physic garden and a cemetery orchard.

Every large monastery had priories. A priory was a smaller structure or entities which depended on the monastery. Some were small monasteries accommodating five or ten monks. Others were no more than a single building serving as residence or a farm offices. The outlying farming establishments belonging to the monastic foundations were known as "villae" or "granges". They were usually staffed by lay-brothers, sometimes under the supervision of a monk.

Many of today's cathedrals in England were originally Benedictine monasteries. These included Canterbury, Chester, Durham, Ely, Gloucester, Norwich, Peterborough, Rochester, Winchester, and Worcester. Shrewsbury Abbey in Shropshire was founded as a Benedictine monastery by the Normans in 1083.

Westminster Abbey was founded in the tenth century by St. Dunstan who established a community of Benedictine monks. The only traces of St. Dunstan's monastery remaining are round arches and massive supporting columns of the undercroft and the Pyx Chamber.

The cloister and buildings lie directly to the south of the church. Parallel to the nave, on the south side of the cloister, was a refectory, with a lavatory at the door. On the eastern side, there was a dormitory, raised on a vaulted substructure and communicating with the south transept and a chapter house (meeting room). A small cloister lay to the south-east of the large cloister. Beyond that was an infirmary with a table hall and a refectory for those who were able to leave their chambers. At the west entrance to the Abbey, there was a house and a small courtyard for the abbott. 

In 1055, St Mary's Abbey, York was built in England's north by the Order of Saint Benedict. It followed the common plan. The entrance to the abbey was through a strong gate on the northern side. Close to the entrance was a chapel. This was for visitors arriving at the Abbey to make their devotions. Near the gate was the hospitium (guest hall). The buildings are completely ruined, but the walls of the nave and the cloisters are still visible on the grounds of the Yorkshire Museum.

The Abbey was surrounded by fortified walls on three sides. The River Ouse bordered the fourth side. The stone walls remain as an excellent example of English abbey walls.

The Abbey of Cluny was founded by William I, Duke of Aquitaine in 910 AD at Cluny, Saône-et-Loire, France. The Abbey was built in the Romanesque style. The Abbey was noted for its strict observance of the Rule of Saint Benedict. However, reforms resulted in many departures from this precedent. The Cluniac reforms brought focus to the traditions of monastic life, encouraging art and the caring of the poor. The Cluniac reforms quickly spread by the founding of new abbey complexes and also by adoption of the reforms by existing abbeys. By the twelfth century, the Abbey of Cluny was the head of an order consisting of 314 monasteries.

The church at the Abbey was commenced in 1089 AD by St. Hugh, the sixth abbot. It was finished and consecrated by Pope Innocent II around 1132 AD. The church was regarded as one of the wonders of the Middle Ages. At in length, it was the largest church in Christendom until the completion of St. Peter's Basilica at Rome. The church consisted of five naves, a narthex (ante-church) which was added in 1220 AD, and several towers. Together with the conventual buildings, it covered an area of twenty-five acres.

In the Dechristianization of France during the French Revolution in 1790 AD, the Abbey church was bought by the town and almost entirely destroyed.

The first English house of the Cluniac order was built at Lewes, Sussex. It was founded by William de Warenne, 1st Earl of Surrey in about 1077 AD. All but one of the Cluniac houses in Britain were known as priories, symbolizing their subordination to the Abbey of Cluny. All the Cluniac houses in England and Scotland were French colonies, governed by French priors who travelled to the Abbey of Cluny to consult or be consulted (unless the abbot of Cluny chose to come to Britain, which happened rarely). The priory at Paisley was an exception. In 1245 AD it was raised to the status of an abbey, answerable only to the Pope.

The Austin canons were an order of regular clergy within the hierarchy of the Catholic church. They held a position between monks and secular canons. They were known as "Black canons" because of the colour of their habits. In 1105 AD, the first house of the order was established at St. Botolph's Priory, Colchester, Essex.

The canons built very long naves to accommodate large congregations. The choirs were also long. Sometimes, as at Llanthony and Christchurch, Dorset(Twynham), the choir was closed from the aisles. At other abbeys of the order, such as Bolton or Kirkham, there were no aisles. The nave in the northern houses of the order often had only a north aisle (this is the case at Bolton, Brinkburn and Lanercost). The arrangement of the monastic buildings followed the ordinary plan. The prior's lodge was usually attached to the southwest angle of the nave.

The Austin canons' house at Thornton, Lincolnshire had a large and magnificent gatehouse. The upper floors of the gatehouse formed the guest-house. The chapter-house was octagonal in shape.

The plan of the Abbey of St Augustine's at Bristol (now the Bristol Cathedral) demonstrates the arrangement of the buildings by this order. The plan departs very little from the ordinary Benedictine type.

The Premonstratensian regular canons, or "White canons", were of an order founded in 1119 AD by Norbert of Xanten. The order was a reformed branch of the Augustinian canons. From a marshy area in the Forest of Coucy in the diocese of Laon, the order spread widely. Even in Norbert's lifetime, the order had built abbeys in Aleppo, Syria and in the Kingdom of Jerusalem. Of the Abbey of Saint Samuel, Denys Pringle wrote, "The Premonstatensian abbey of Saint Samuel was a daughter house of Prémontré itself. Its abbot had the status of a suffragan of the patriarch of Jerusalem, with the right to a cross, but not to a mitre nor a ring." It long maintained its rigid austerity, though in later years the abbey grew wealthier, and its members indulged in more frequent luxuries.

Just after 1140 AD, the Premonstratensians were brought to England. Their first settlement was at Newhouse, Lincolnshire, near the Humber tidal estuary. There were as many as thirty-five Premonstratensian abbeys in England. The head abbey in England was at Welbeck but the best preserved are Easby Abbey in Yorkshire, and Bayham Old Abbey in Kent.

The lay out of Easby Abbey is irregular due to its position on the edge of a steep river bank. The cloister is duly placed on the south side of the church, and the chief buildings occupy their usual positions around it. However, the cloister garth (quadrangle), as at Chichester, is not rectangular, and thus, all the surrounding buildings are positioned in an awkward fashion. The church follows the plan adopted by the Austin canons in their northern abbeys, and has only one aisle to the north of the nave, while the choir is long, narrow and without an aisle. Each transept has an aisle to the east, forming three chapels.

The church at Bayham Old Abbey had no aisles in the nave or the choir. The latter terminated in a three-sided apse. The church is remarkable for its extreme narrowness in proportion to its length. While the building is long, it is not more than wide. Premonstratensian canons did not care to have congregations nor possessions. Therefore, they built their churches in the shape of a long room.

The Cistercians, a Benedictine reform group, were established at Cîteaux in 1098 AD by Robert of Molesme, Abbot of Molesme, for the purpose of restoring, as far as possible, the literal observance of the Rule of Saint Benedict. La Ferté, Pontigny, Clairvaux, and Morimond were the first four abbeys to follow Cîteaux's example and others followed. The monks of Cîteaux created the well known vineyards of Clos-Vougeot and Romanée in Burgundy.

The Cistercian principle of rigid self-abnegation carried over to the design of the order's churches and buildings. The defining architectural characteristic of the Cistercian abbeys was extreme simplicity and plainness. Only a single, central tower was permitted, and that was usually very low. Unnecessary pinnacles and turrets were prohibited. The triforium was omitted. The windows were usually plain and undivided, and it was forbidden to decorate them with stained glass. All needless ornament was proscribed. The crosses were made of wood and the candlesticks of iron.

The same principle governed the choice of site for Cistercian abbeys in that a most dismal site might be improved by the building of an abbey. The Cistercian monasteries were founded in deep, well-watered valleys, always standing at a stream's edge. The building might extend over the water as is the case at Fountains Abbey. These valleys, now rich and productive, had a very different appearance when the brethren first chose them as their place of retreat. Wide swamps, deep morasses, tangled thickets, and wild, impassable forests were their prevailing features. Clara Vallis of St Bernard, now the "bright valley" was originally, the "Valley of Wormwood". It was an infamous den of robbers.

See also:

The plan of a Coptic Orthodox monastery, from Lenoir, shows a church of three aisles, with cellular apses, and two ranges of cells on either side of an oblong gallery.






</doc>
<doc id="1316" url="https://en.wikipedia.org/wiki?curid=1316" title="Annales school">
Annales school

The "Annales" school () is a group of historians associated with a style of historiography developed by French historians in the 20th century to stress long-term social history. It is named after its scholarly journal "Annales d'histoire économique et sociale", which remains the main source of scholarship, along with many books and monographs. The school has been highly influential in setting the agenda for historiography in France and numerous other countries, especially regarding the use of social scientific methods by historians, emphasizing social and economic rather than political or diplomatic themes.

The school deals primarily with late medieval and early modern Europe (before the French Revolution), with little interest in later topics. It has dominated French social history and influenced historiography in Europe and Latin America. Prominent leaders include co-founders Lucien Febvre (1878–1956), Henri Hauser (1866-1946) and Marc Bloch (1886–1944). The second generation was led by Fernand Braudel (1902–1985) and included Georges Duby (1919–1996), Pierre Goubert (1915–2012), Robert Mandrou (1921–1984), Pierre Chaunu (1923–2009), Jacques Le Goff (1924–2014), and Ernest Labrousse (1895–1988). Institutionally it is based on the "Annales" journal, the SEVPEN publishing house, the (FMSH), and especially the 6th Section of the École pratique des hautes études, all based in Paris. A third generation was led by Emmanuel Le Roy Ladurie (1929– ) and includes Jacques Revel, and Philippe Ariès (1914–1984), who joined the group in 1978. The third generation stressed history from the point of view of mentalities, or "mentalités". The fourth generation of Annales historians, led by Roger Chartier (1945– ), clearly distanced itself from the mentalities approach, replaced by the cultural and linguistic turn, which emphasize analysis of the social history of cultural practices.
The main scholarly outlet has been the journal "Annales d'Histoire Economique et Sociale" ("Annals of Economic and Social History"), founded in 1929 by Lucien Febvre and Marc Bloch, which broke radically with traditional historiography by insisting on the importance of taking all levels of society into consideration and emphasized the collective nature of mentalities. Its contributors viewed events as less fundamental than the mental frameworks that shaped decisions and practices
Janmesh Kokate was editor of "Annales committee " from 2003 to present, followed by the medievalist Jacques Le Goff. However, informal successor as head of the school was Le Roy Ladurie. Noting the political upheavals in Europe and especially in France in 1968, Eric Hobsbawm argues that "in France the virtual hegemony of Braudelian history and the "Annales" came to an end after 1968, and the international influence of the journal dropped steeply." Multiple responses were attempted by the school. Scholars moved in multiple directions, covering in disconnected fashion the social, economic, and cultural history of different eras and different parts of the globe. By the time of crisis the school was building a vast publishing and research network reaching across France, Europe, and the rest of the world. Influence indeed spread out from Paris, but few new ideas came in. Much emphasis was given to quantitative data, seen as the key to unlocking all of social history. However, the Annales ignored the developments in quantitative studies underway in the U.S. and Britain, which reshaped economic, political, and demographic research. An attempt to require an "Annales"-written textbook for French schools was rejected by the government. By 1980 postmodern sensibilities undercut confidence in overarching metanarratives. As Jacques Revel notes, the success of the Annales School, especially its use of social structures as explanatory forces, contained the seeds of its own downfall, for there is "no longer any implicit consensus on which to base the unity of the social, identified with the real." The Annales School kept its infrastructure, but lost its "mentalités".

The journal began in Strasbourg as "Annales d'histoire économique et sociale"; it moved to Paris and kept the same name from 1929 to 1939. It was successively renamed "Annales d'histoire sociale" (1939–1942, 1945), "Mélanges d'histoire sociale" (1942–1944), "Annales. Economies, sociétés, civilisations" (1946–1994), and "Annales. Histoire, Sciences Sociales" (1994– ).

In 1962 Braudel and Gaston Berger used Ford Foundation money and government funds to create a new independent foundation, the (FMSH), which Braudel directed from 1970 until his death. In 1970 the 6th Section and the "Annales" relocated to the FMSH building. FMSH set up elaborate international networks to spread the "Annales" gospel across Europe and the world. In 2013 it began publication of an English language edition, with all the articles translated.

The scope of topics covered by the journal is vast and experimental—there is a search for total history and new approaches. The emphasis is on social history, and very long-term trends, often using quantification and paying special attention to geography and to the intellectual world view of common people, or "mentality" ("mentalité"). Little attention is paid to political, diplomatic, or military history, or to biographies of famous men. Instead the "Annales" focused attention on the synthesizing of historical patterns identified from social, economic, and cultural history, statistics, medical reports, family studies, and even psychoanalysis.

The "Annales" was founded and edited by Marc Bloch and Lucien Febvre in 1929, while they were teaching at the University of Strasbourg and later in Paris. These authors, the former a medieval historian and the latter an early modernist, quickly became associated with the distinctive "Annales" approach, which combined geography, history, and the sociological approaches of the "Année Sociologique" (many members of which were their colleagues at Strasbourg) to produce an approach which rejected the predominant emphasis on politics, diplomacy and war of many 19th and early 20th-century historians as spearheaded by historians whom Febvre called Les Sorbonnistes. Instead, they pioneered an approach to a study of long-term historical structures ("la longue durée") over events and political transformations. Geography, material culture, and what later Annalistes called "mentalités," or the psychology of the epoch, are also characteristic areas of study. The goal of the Annales was to undo the work of the Sorbonnistes, to turn French historians away from the narrowly political and diplomatic toward the new vistas in social and economic history.

Co-founder Marc Bloch (1886–1944) was a quintessential modernist who studied at the elite École Normale Supérieure, and in Germany, serving as a professor at the University of Strasbourg until he was called to the Sorbonne in Paris in 1936 as professor of economic history. Bloch's interests were highly interdisciplinary, influenced by the geography of Paul Vidal de la Blache (1845–1918) and the sociology of Émile Durkheim (1858–1917). His own ideas, especially those expressed in his masterworks, "French Rural History" ("Les caractères originaux de l'histoire rurale française," 1931) and "Feudal Society", were incorporated by the second-generation Annalistes, led by Fernand Braudel.

Georges Duby, a leader of the school, wrote that the history he taught:
The Annalistes, especially Lucien Febvre, advocated a "histoire totale", or "histoire tout court", a complete study of a historic problem.

Bloch was shot by the Gestapo during the German occupation of France in World War II for his active membership of the French Resistance, and Febvre carried on the "Annales" approach in the 1940s and 1950s. It was during this time that he mentored Braudel, who would become one of the best-known exponents of this school. Braudel's work came to define a "second" era of "Annales" historiography and was very influential throughout the 1960s and 1970s, especially for his work on the Mediterranean region in the era of Philip II of Spain. 
Braudel developed the idea, often associated with Annalistes, of different modes of historical time: "l'histoire quasi immobile" (the quasi motionless history) of historical geography, the history of social, political and economic structures ("la longue durée"), and the history of men and events, in the context of their structures.

While authors such as Emmanuel Le Roy Ladurie, Marc Ferro and Jacques Le Goff continue to carry the "Annales" banner, today the "Annales" approach has been less distinctive as more and more historians do work in cultural history, political history and economic history.

Bloch's "Les Rois Thaumaturges" (1924) looked at the long-standing folk belief that the king could cure scrofula by his thaumaturgic touch. The kings of France and England indeed regularly practiced the ritual. Bloch was not concerned with the effectiveness of the royal touch—he acted instead like an anthropologist in asking why people believed it and how it shaped relations between king and commoner. The book was highly influential in introducing comparative studies (in this case France and England), as well as long durations ("longue durée") studies spanning several centuries, even up to a thousand years, downplaying short-term events. Bloch's revolutionary charting of mentalities, or "mentalités", resonated with scholars who were reading Freud and Proust. In the 1960s, Robert Mandrou and Georges Duby harmonized the concept of "mentalité" history with Fernand Braudel's structures of historical time and linked mentalities with changing social conditions. A flood of "mentalité" studies based on these approaches appeared during the 1970s and 1980s. By the 1990s, however, "mentalité" history had become interdisciplinary to the point of fragmentation, but still lacked a solid theoretical basis. While not explicitly rejecting "mentalité" history, younger historians increasingly turned to other approaches.

Fernand Braudel became the leader of the second generation after 1945. He obtained funding from the Rockefeller Foundation in New York and founded the 6th Section of the Ecole Pratique des Hautes Etudes, which was devoted to the study of history and the social sciences. It became an independent degree-granting institution in 1975 under the name École des Hautes Études en Sciences Sociales (EHESS). Braudel's followers admired his use of the longue durée approach to stress slow, and often imperceptible effects of space, climate and technology on the actions of human beings in the past. The "Annales" historians, after living through two world wars and incredible political upheavals in France, were deeply uncomfortable with the notion that multiple ruptures and discontinuities created history. They preferred to stress inertia and the longue durée. Special attention was paid to geography, climate, and demography as long-term factors. They believed the continuities of the deepest structures were central to history, beside which upheavals in institutions or the superstructure of social life were of little significance, for history lies beyond the reach of conscious actors, especially the will of revolutionaries. They rejected the Marxist idea that history should be used as a tool to foment and foster revolutions. In turn the Marxists called them conservatives.

Braudel's first book, "La Méditerranée et le Monde Méditerranéen à l'Epoque de Philippe II" (1949) ("The Mediterranean and the Mediterranean World in the Age of Philip II") was his most influential. This vast panoramic view used ideas from other social sciences, employed effectively the technique of the longue durée, and downplayed the importance of specific events and individuals. It stressed geography but not "mentalité". It was widely admired, but most historians did not try to replicate it and instead focused on their specialized monographs. The book dramatically raised the worldwide profile of the Annales School.

Before "Annales," French history supposedly happened in Paris. Febvre broke decisively with this paradigm in 1912, with his sweeping doctoral thesis on "Philippe II et la Franche-Comté." The geography and social structure of this region overwhelmed and shaped the king's policies.

The "Annales" historians did not try to replicate Braudel's vast geographical scope in "La Méditerranée." Instead they focused on regions in France over long stretches of time. The most important was the study of the "Peasants of Languedoc" by Braudel's star pupil and successor Emmanuel Le Roy Ladurie. The regionalist tradition flourished especially in the 1960s and 1970s in the work of Pierre Goubert in 1960 on Beauvais and René Baehrel on Basse-Provence. "Annales" historians in the 1970s and 1980s turned to urban regions, including Pierre Deyon (Amiens), Maurice Garden (Lyon), Jean-Pierre Bardet (Rouen), Georges Freche (Toulouse), Gregory Hanlon (Agen and Layrac), and Jean-Claude Perrot (Caen). By the 1970s the shift was underway from the earlier economic history to cultural history and the history of mentalities.

The "Annales" school systematically reached out to create an impact on other countries. Its success varied widely. The "Annales" approach was especially well received in Italy and Poland. Franciszek Bujak (1875–1953) and Jan Rutkowski (1886–1949), the founders of modern economic history in Poland and of the journal "Roczniki Dziejów Spolecznych i Gospodarczych" (1931– ), were attracted to the innovations of the Annales school. Rutkowski was in contact with Bloch and others, and published in the "Annales." After the Communists took control in the 1940s Polish scholars were safer working on the Middle Ages and the early modern era rather than contemporary history. After the "Polish October" of 1956 the Sixth Section in Paris welcomed Polish historians and exchanges between the circle of the "Annales" and Polish scholars continued until the early 1980s. The reciprocal influence between the French school and Polish historiography was particularly evident in studies on the Middle Ages and the early modern era studied by Braudel.

In South America the "Annales" approach became popular. From the 1950s Federico Brito Figueroa was the founder of a new Venezuelan historiography based largely on the ideas of the Annales School. Brito Figueroa carried his conception of the field to all levels of university study, emphasizing a systematic and scientific approach to history and placing it squarely in the social sciences. Spanish historiography was influenced by the "Annales School" starting in 1950 with Jaime Vincens Vives (1910–1960). In Mexico, exiled Republican intellectuals extended the Annales approach, particularly from the Center for Historical Studies of El Colegio de México, the leading graduate studies institution of Latin America.

British historians, apart from a few Marxists, were generally hostile. Academic historians decidedly sided with Geoffrey Elton's "The Practice of History" against Edward Hallett Carr's "What Is History?" One of the few British historians who were sympathetic towards the work of the "Annales" school was Hugh Trevor-Roper. American, German, Indian, Russian and Japanese scholars generally ignored the school. The Americans developed their own form of "new social history" from entirely different roots Both the American and the "Annales" historians picked up important family reconstitution techniques from French demographer Louis Henry.

The Wageningen school centered on Bernard Slicher van Bath was viewed internationally as a Dutch counterpart of the Annales school, although Slicher van Bath himself vehemently rejected the idea of a quantitative "school" of historiography.

Has been cited as a key influence in the development of World Systems Theory by sociologist Immanuel Wallerstein.

The current leader is Roger Chartier, who is Directeur d'Études at the École des Hautes Études en Sciences Sociales in Paris, Professeur in the Collège de France, and Annenberg Visiting Professor of History at the University of Pennsylvania. He frequently lectures and teaches in the United States, Spain, Mexico, Brazil and Argentina. His work in Early Modern European History focuses on the history of education, the history of the book and the history of reading. Recently, he has been concerned with the relationship between written culture as a whole and literature (particularly theatrical plays) for France, England and Spain. His work in this specific field (based on the criss-crossing between literary criticism, bibliography, and sociocultural history) is connected to broader historiographical and methodological interests which deal with the relation between history and other disciplines: philosophy, sociology, anthropology.

Chartier's typical undergraduate course focuses upon the making, remaking, dissemination, and reading of texts in early modern Europe and America. Under the heading of "practices," his class considers how readers read and marked up their books, forms of note-taking, and the interrelation between reading and writing from copying and translating to composing new texts. Under the heading of "materials," his class examines the relations between different kinds of writing surfaces (including stone, wax, parchment, paper, walls, textiles, the body, and the heart), writing implements (including styluses, pens, pencils, needles, and brushes), and material forms (including scrolls, erasable tables, codices, broadsides and printed forms and books). Under the heading of "places," his class explores where texts were made, read, and listened to, including monasteries, schools and universities, offices of the state, the shops of merchants and booksellers, printing houses, theaters, libraries, studies, and closets. The texts for his course include the "Bible", translations of Ovid, "Hamlet", "Don Quixote", Montaigne's essays, Pepys's diary, Richardson's "Pamela", and Franklin's autobiography.







</doc>
<doc id="1317" url="https://en.wikipedia.org/wiki?curid=1317" title="Antimatter">
Antimatter

In modern physics, antimatter is defined as a material composed of the antiparticles (or "partners") of the corresponding particles of ordinary matter. Minuscule numbers of antiparticles are generated daily at particle accelerators – total production has been only a few nanograms – and in natural processes like cosmic ray collisions and some types of radioactive decay, but only a tiny fraction of these have successfully been bound together in experiments to form anti-atoms. No macroscopic amount of antimatter has ever been assembled due to the extreme cost and difficulty of production and handling.

In theory, a particle and its anti-particle (for example, proton and antiproton) have the same mass, but opposite electric charge and other differences in quantum numbers. For example, a proton has positive charge while an antiproton has negative charge.

A collision between any particle and its anti-particle partner leads to their "mutual annihilation", giving rise to various proportions of intense photons (gamma rays), neutrinos, and sometimes less-massive particle-antiparticle pairs. Annihilation usually results in a release of energy that becomes available for heat or work. The amount of the released energy is usually proportional to the total mass of the collided matter and antimatter, in accordance with the mass–energy equivalence equation, .

Antimatter particles bind with one another to form antimatter, just as ordinary particles bind to form normal matter. For example, a positron (the antiparticle of the electron) and an antiproton (the antiparticle of the proton) can form an antihydrogen atom. The nuclei of antihelium have been artificially produced with difficulty, and these are the most complex anti-nuclei so far observed. Physical principles indicate that complex antimatter atomic nuclei are possible, as well as anti-atoms corresponding to the known chemical elements.

There is strong evidence that the observable universe is composed almost entirely of ordinary matter, as opposed to an equal mixture of matter and antimatter.
This asymmetry of matter and antimatter in the visible universe is one of the great unsolved problems in physics. The process by which this inequality between matter and antimatter particles developed is called baryogenesis.

Antimatter particles can be defined by their negative baryon number or lepton number, while "normal" (non-antimatter) matter particles have a positive baryon or lepton number. These two classes of particles are the antiparticle partners of one another.

The idea of negative matter appears in past theories of matter that have now been abandoned. Using the once popular vortex theory of gravity, the possibility of matter with negative gravity was discussed by William Hicks in the 1880s. Between the 1880s and the 1890s, Karl Pearson proposed the existence of "squirts" and sinks of the flow of aether. The squirts represented normal matter and the sinks represented negative matter. Pearson's theory required a fourth dimension for the aether to flow from and into.

The term antimatter was first used by Arthur Schuster in two rather whimsical letters to "Nature" in 1898, in which he coined the term. He hypothesized antiatoms, as well as whole antimatter solar systems, and discussed the possibility of matter and antimatter annihilating each other. Schuster's ideas were not a serious theoretical proposal, merely speculation, and like the previous ideas, differed from the modern concept of antimatter in that it possessed negative gravity.

The modern theory of antimatter began in 1928, with a paper by Paul Dirac. Dirac realised that his relativistic version of the Schrödinger wave equation for electrons predicted the possibility of antielectrons. These were discovered by Carl D. Anderson in 1932 and named positrons (a portmanteau of "positive electron"). Although Dirac did not himself use the term antimatter, its use follows on naturally enough from antielectrons, antiprotons, etc. A complete periodic table of antimatter was envisaged by Charles Janet in 1929.

The Feynman–Stueckelberg interpretation states that antimatter and antiparticles are regular particles traveling backward in time.

One way to denote an antiparticle is by adding a bar over the particle's symbol. For example, the proton and antiproton are denoted as and , respectively. The same rule applies if one were to address a particle by its constituent components. A proton is made up of quarks, so an antiproton must therefore be formed from antiquarks. Another convention is to distinguish particles by their electric charge. Thus, the electron and positron are denoted simply as and respectively. However, to prevent confusion, the two conventions are never mixed.

There are compelling theoretical reasons to believe that, aside from the fact that antiparticles have different signs on all charges (such as electric and baryon charges), matter and antimatter have exactly the same properties. This means a particle and its corresponding antiparticle must have identical masses and decay lifetimes (if unstable). It also implies that, for example, a star made up of antimatter (an "antistar") will shine just like an ordinary star. This idea was tested experimentally in 2016 by the ALPHA experiment, which measured the transition between the two lowest energy states of antihydrogen. The results, which are identical to that of hydrogen, confirmed the validity of quantum mechanics for antimatter.

Almost all matter observable from the Earth seems to be made of matter rather than antimatter. If antimatter-dominated regions of space existed, the gamma rays produced in annihilation reactions along the boundary between matter and antimatter regions would be detectable.

Antiparticles are created everywhere in the universe where high-energy particle collisions take place. High-energy cosmic rays impacting Earth's atmosphere (or any other matter in the Solar System) produce minute quantities of antiparticles in the resulting particle jets, which are immediately annihilated by contact with nearby matter. They may similarly be produced in regions like the center of the Milky Way and other galaxies, where very energetic celestial events occur (principally the interaction of relativistic jets with the interstellar medium). The presence of the resulting antimatter is detectable by the two gamma rays produced every time positrons annihilate with nearby matter. The frequency and wavelength of the gamma rays indicate that each carries 511 keV of energy (that is, the rest mass of an electron multiplied by "c").

Observations by the European Space Agency's INTEGRAL satellite may explain the origin of a giant antimatter cloud surrounding the galactic center. The observations show that the cloud is asymmetrical and matches the pattern of X-ray binaries (binary star systems containing black holes or neutron stars), mostly on one side of the galactic center. While the mechanism is not fully understood, it is likely to involve the production of electron–positron pairs, as ordinary matter gains kinetic energy while falling into a stellar remnant.

Antimatter may exist in relatively large amounts in far-away galaxies due to cosmic inflation in the primordial time of the universe. Antimatter galaxies, if they exist, are expected to have the same chemistry and absorption and emission spectra as normal-matter galaxies, and their astronomical objects would be observationally identical, making them difficult to distinguish. NASA is trying to determine if such galaxies exist by looking for X-ray and gamma-ray signatures of annihilation events in colliding superclusters.

In October 2017, scientists working on the BASE experiment at CERN reported a measurement of the antiproton magnetic moment to a precision of 1.5 parts per billion. It is consistent with the most precise measurement of the proton magnetic moment (also made by BASE in 2014), which supports the hypothesis of CPT symmetry. This measurement represents the first time that a property of antimatter is known more precisely than the equivalent property in matter.

Positrons are produced naturally in β decays of naturally occurring radioactive isotopes (for example, potassium-40) and in interactions of gamma quanta (emitted by radioactive nuclei) with matter. Antineutrinos are another kind of antiparticle created by natural radioactivity (β decay). Many different kinds of antiparticles are also produced by (and contained in) cosmic rays. In January 2011, research by the American Astronomical Society discovered antimatter (positrons) originating above thunderstorm clouds; positrons are produced in gamma-ray flashes created by electrons accelerated by strong electric fields in the clouds. Antiprotons have also been found to exist in the Van Allen Belts around the Earth by the PAMELA module.

Antiparticles are also produced in any environment with a sufficiently high temperature (mean particle energy greater than the pair production threshold). It is hypothesized that during the period of baryogenesis, when the universe was extremely hot and dense, matter and antimatter were continually produced and annihilated. The presence of remaining matter, and absence of detectable remaining antimatter, is called baryon asymmetry. The exact mechanism which produced this asymmetry during baryogenesis remains an unsolved problem. One of the necessary conditions for this asymmetry is the violation of CP symmetry, which has been experimentally observed in the weak interaction.

Recent observations indicate black holes and neutron stars produce vast amounts of positron-electron plasma via the jets.

Satellite experiments have found evidence of positrons and a few antiprotons in primary cosmic rays, amounting to less than 1% of the particles in primary cosmic rays. This antimatter cannot all have been created in the Big Bang, but is instead attributed to have been produced by cyclic processes at high energies. For instance, electron-positron pairs may be formed in pulsars, as a magnetized neutron star rotation cycle shears electron-positron pairs from the star surface. Therein the antimatter forms a wind which crashes upon the ejecta of the progenitor supernovae. This weathering takes place as "the cold, magnetized relativistic wind launched by the star hits the non-relativistically expanding ejecta, a shock wave system forms in the impact: the outer one propagates in the ejecta, while a reverse shock propagates back towards the star." The former ejection of matter in the outer shock wave and the latter production of antimatter in the reverse shock wave are steps in a space weather cycle.

Preliminary results from the presently operating Alpha Magnetic Spectrometer ("AMS-02") on board the International Space Station show that positrons in the cosmic rays arrive with no directionality, and with energies that range from 10 GeV to 250 GeV. In September, 2014, new results with almost twice as much data were presented in a talk at CERN and published in Physical Review Letters. A new measurement of positron fraction up to 500 GeV was reported, showing that positron fraction peaks at a maximum of about 16% of total electron+positron events, around an energy of 275 ± 32 GeV. At higher energies, up to 500 GeV, the ratio of positrons to electrons begins to fall again. The absolute flux of positrons also begins to fall before 500 GeV, but peaks at energies far higher than electron energies, which peak about 10 GeV. These results on interpretation have been suggested to be due to positron production in annihilation events of massive dark matter particles.

Cosmic ray antiprotons also have a much higher energy than their normal-matter counterparts (protons). They arrive at Earth with a characteristic energy maximum of 2 GeV, indicating their production in a fundamentally different process from cosmic ray protons, which on average have only one-sixth of the energy.

There is no evidence of complex antimatter atomic nuclei, such as antihelium nuclei (that is, anti-alpha particles), in cosmic rays. These are actively being searched for, because the detection of natural antihelium implies the existence of large antimatter structures such as an antistar. A prototype of the "AMS-02" designated "AMS-01", was flown into space aboard the on STS-91 in June 1998. By not detecting any antihelium at all, the "AMS-01" established an upper limit of 1.1×10 for the antihelium to helium flux ratio.

Positrons were reported in November 2008 to have been generated by Lawrence Livermore National Laboratory in larger numbers than by any previous synthetic process. A laser drove electrons through a gold target's nuclei, which caused the incoming electrons to emit energy quanta that decayed into both matter and antimatter. Positrons were detected at a higher rate and in greater density than ever previously detected in a laboratory. Previous experiments made smaller quantities of positrons using lasers and paper-thin targets; however, new simulations showed that short bursts of ultra-intense lasers and millimeter-thick gold are a far more effective source.

The existence of the antiproton was experimentally confirmed in 1955 by University of California, Berkeley physicists Emilio Segrè and Owen Chamberlain, for which they were awarded the 1959 Nobel Prize in Physics. An antiproton consists of two up antiquarks and one down antiquark (). The properties of the antiproton that have been measured all match the corresponding properties of the proton, with the exception of the antiproton having opposite electric charge and magnetic moment from the proton. Shortly afterwards, in 1956, the antineutron was discovered in proton–proton collisions at the Bevatron (Lawrence Berkeley National Laboratory) by Bruce Cork and colleagues.

In addition to antibaryons, anti-nuclei consisting of multiple bound antiprotons and antineutrons have been created. These are typically produced at energies far too high to form antimatter atoms (with bound positrons in place of electrons). In 1965, a group of researchers led by Antonino Zichichi reported production of nuclei of antideuterium at the Proton Synchrotron at CERN. At roughly the same time, observations of antideuterium nuclei were reported by a group of American physicists at the Alternating Gradient Synchrotron at Brookhaven National Laboratory.

In 1995, CERN announced that it had successfully brought into existence nine hot antihydrogen atoms by implementing the SLAC/Fermilab concept during the PS210 experiment. The experiment was performed using the Low Energy Antiproton Ring (LEAR), and was led by Walter Oelert and Mario Macri. Fermilab soon confirmed the CERN findings by producing approximately 100 antihydrogen atoms at their facilities. The antihydrogen atoms created during PS210 and subsequent experiments (at both CERN and Fermilab) were extremely energetic and were not well suited to study. To resolve this hurdle, and to gain a better understanding of antihydrogen, two collaborations were formed in the late 1990s, namely, ATHENA and ATRAP.

In 1999, CERN activated the Antiproton Decelerator, a device capable of decelerating antiprotons from to —still too "hot" to produce study-effective antihydrogen, but a huge leap forward. In late 2002 the ATHENA project announced that they had created the world's first "cold" antihydrogen. The ATRAP project released similar results very shortly thereafter. The antiprotons used in these experiments were cooled by decelerating them with the Antiproton Decelerator, passing them through a thin sheet of foil, and finally capturing them in a Penning–Malmberg trap. The overall cooling process is workable, but highly inefficient; approximately 25 million antiprotons leave the Antiproton Decelerator and roughly 25,000 make it to the Penning–Malmberg trap, which is about or 0.1% of the original amount.

The antiprotons are still hot when initially trapped. To cool them further, they are mixed into an electron plasma. The electrons in this plasma cool via cyclotron radiation, and then sympathetically cool the antiprotons via Coulomb collisions. Eventually, the electrons are removed by the application of short-duration electric fields, leaving the antiprotons with energies less than . While the antiprotons are being cooled in the first trap, a small cloud of positrons is captured from radioactive sodium in a Surko-style positron accumulator. This cloud is then recaptured in a second trap near the antiprotons. Manipulations of the trap electrodes then tip the antiprotons into the positron plasma, where some combine with antiprotons to form antihydrogen. This neutral antihydrogen is unaffected by the electric and magnetic fields used to trap the charged positrons and antiprotons, and within a few microseconds the antihydrogen hits the trap walls, where it annihilates. Some hundreds of millions of antihydrogen atoms have been made in this fashion.

In 2005, ATHENA disbanded and some of the former members (along with others) formed the ALPHA Collaboration, which is also based at CERN. The ultimate goal of this endeavour is to test CPT symmetry through comparison of the atomic spectra of hydrogen and antihydrogen (see hydrogen spectral series).

In 2016 a new antiproton decelerator and cooler called ELENA (E Low Energy Antiproton decelerator) was built. It takes the antiprotons from the antiproton decelerator and cools them to 90 keV, which is "cold" enough to study. This machine works by using high energy and accelerating the particles within the chamber. More than one hundred antiprotons can be captured per second, a huge improvement, but it would still take several thousand years to make a nanogram of antimatter.

Most of the sought-after high-precision tests of the properties of antihydrogen could only be performed if the antihydrogen were trapped, that is, held in place for a relatively long time. While antihydrogen atoms are electrically neutral, the spins of their component particles produce a magnetic moment. These magnetic moments can interact with an inhomogeneous magnetic field; some of the antihydrogen atoms can be attracted to a magnetic minimum. Such a minimum can be created by a combination of mirror and multipole fields. Antihydrogen can be trapped in such a magnetic minimum (minimum-B) trap; in November 2010, the ALPHA collaboration announced that they had so trapped 38 antihydrogen atoms for about a sixth of a second. This was the first time that neutral antimatter had been trapped.

On 26 April 2011, ALPHA announced that they had trapped 309 antihydrogen atoms, some for as long as 1,000 seconds (about 17 minutes). This was longer than neutral antimatter had ever been trapped before. ALPHA has used these trapped atoms to initiate research into the spectral properties of the antihydrogen.

The biggest limiting factor in the large-scale production of antimatter is the availability of antiprotons. Recent data released by CERN states that, when fully operational, their facilities are capable of producing ten million antiprotons per minute. Assuming a 100% conversion of antiprotons to antihydrogen, it would take 100 billion years to produce 1 gram or 1 mole of antihydrogen (approximately atoms of anti-hydrogen).

Antihelium-3 nuclei () were first observed in the 1970s in proton–nucleus collision experiments at the Institute for High Energy Physics by Y. Prockoshkin's group (Protvino near Moscow, USSR) and later created in nucleus–nucleus collision experiments. Nucleus–nucleus collisions produce antinuclei through the coalescence of antiprotons and antineutrons created in these reactions. In 2011, the STAR detector reported the observation of artificially created antihelium-4 nuclei (anti-alpha particles) () from such collisions.

Antimatter cannot be stored in a container made of ordinary matter because antimatter reacts with any matter it touches, annihilating itself and an equal amount of the container. Antimatter in the form of charged particles can be contained by a combination of electric and magnetic fields, in a device called a Penning trap. This device cannot, however, contain antimatter that consists of uncharged particles, for which atomic traps are used. In particular, such a trap may use the dipole moment (electric or magnetic) of the trapped particles. At high vacuum, the matter or antimatter particles can be trapped and cooled with slightly off-resonant laser radiation using a magneto-optical trap or magnetic trap. Small particles can also be suspended with optical tweezers, using a highly focused laser beam.

In 2011, CERN scientists were able to preserve antihydrogen for approximately 17 minutes. A proposal was made in 2018, to develop containment technology advanced enough to contain a billion anti-protons in a portable device to be driven to another lab for further experimentation.

Scientists claim that antimatter is the costliest material to make. In 2006, Gerald Smith estimated $250 million could produce 10 milligrams of positrons (equivalent to $25 billion per gram); in 1999, NASA gave a figure of $62.5 trillion per gram of antihydrogen. This is because production is difficult (only very few antiprotons are produced in reactions in particle accelerators) and because there is higher demand for other uses of particle accelerators. According to CERN, it has cost a few hundred million Swiss francs to produce about 1 billionth of a gram (the amount used so far for particle/antiparticle collisions). In comparison, to produce the first atomic weapon, the cost of the Manhattan Project was estimated at $23 billion with inflation during 2007.

Several studies funded by the NASA Institute for Advanced Concepts are exploring whether it might be possible to use magnetic scoops to collect the antimatter that occurs naturally in the Van Allen belt of the Earth, and ultimately, the belts of gas giants, like Jupiter, hopefully at a lower cost per gram.

Matter–antimatter reactions have practical applications in medical imaging, such as positron emission tomography (PET). In positive beta decay, a nuclide loses surplus positive charge by emitting a positron (in the same event, a proton becomes a neutron, and a neutrino is also emitted). Nuclides with surplus positive charge are easily made in a cyclotron and are widely generated for medical use. Antiprotons have also been shown within laboratory experiments to have the potential to treat certain cancers, in a similar method currently used for ion (proton) therapy.

Isolated and stored anti-matter could be used as a fuel for interplanetary or interstellar travel as part of an antimatter catalyzed nuclear pulse propulsion or other antimatter rocketry, such as the redshift rocket. Since the energy density of antimatter is higher than that of conventional fuels, an antimatter-fueled spacecraft would have a higher thrust-to-weight ratio than a conventional spacecraft.

If matter–antimatter collisions resulted only in photon emission, the entire rest mass of the particles would be converted to kinetic energy. The energy per unit mass () is about 10 orders of magnitude greater than chemical energies, and about 3 orders of magnitude greater than the nuclear potential energy that can be liberated, today, using nuclear fission (about per fission reaction or ), and about 2 orders of magnitude greater than the best possible results expected from fusion (about for the proton–proton chain). The reaction of of antimatter with of matter would produce (180 petajoules) of energy (by the mass–energy equivalence formula, ), or the rough equivalent of 43 megatons of TNT – slightly less than the yield of the 27,000 kg Tsar Bomba, the largest thermonuclear weapon ever detonated.

Not all of that energy can be utilized by any realistic propulsion technology because of the nature of the annihilation products. While electron–positron reactions result in gamma ray photons, these are difficult to direct and use for thrust. In reactions between protons and antiprotons, their energy is converted largely into relativistic neutral and charged pions. The neutral pions decay almost immediately (with a lifetime of 85 attoseconds) into high-energy photons, but the charged pions decay more slowly (with a lifetime of 26 nanoseconds) and can be deflected magnetically to produce thrust.

Charged pions ultimately decay into a combination of neutrinos (carrying about 22% of the energy of the charged pions) and unstable charged muons (carrying about 78% of the charged pion energy), with the muons then decaying into a combination of electrons, positrons and neutrinos (cf. muon decay; the neutrinos from this decay carry about 2/3 of the energy of the muons, meaning that from the original charged pions, the total fraction of their energy converted to neutrinos by one route or another would be about ).

Antimatter has been considered as a trigger mechanism for nuclear weapons. A major obstacle is the difficulty of producing antimatter in large enough quantities, and there is no evidence that it will ever be feasible. However, the U.S. Air Force funded studies of the physics of antimatter in the Cold War, and began considering its possible use in weapons, not just as a trigger, but as the explosive itself.





</doc>
<doc id="1322" url="https://en.wikipedia.org/wiki?curid=1322" title="Casa Batlló">
Casa Batlló

Casa Batlló () is a building in the center of Barcelona. It was designed by Antoni Gaudí, and is considered one of his masterpieces. A remodel of a previously built house, it was redesigned in 1904 by Gaudí and has been refurbished several times after that. Gaudí's assistants Domènec Sugrañes i Gras, Josep Canaleta and Joan Rubió also contributed to the renovation project. 

The local name for the building is "Casa dels ossos" (House of Bones), as it has a visceral, skeletal organic quality. It is located on the Passeig de Gràcia in the Eixample district, and forms part of a row of houses known as the "Illa de la Discòrdia" (or "Mansana de la Discòrdia", the "Block of Discord"), which consists of four buildings by noted "Modernista" architects of Barcelona.

Like everything Gaudí designed, Casa Batlló is only identifiable as Modernisme or Art Nouveau in the broadest sense. The ground floor, in particular, has unusual tracery, irregular oval windows and flowing sculpted stone work. There are few straight lines, and much of the façade is decorated with a colorful mosaic made of broken ceramic tiles (trencadís). The roof is arched and was likened to the back of a dragon or dinosaur. A common theory about the building is that the rounded feature to the left of centre, terminating at the top in a turret and cross, represents the lance of Saint George (patron saint of Catalonia, Gaudí's home), which has been plunged into the back of the dragon.

The building that is now Casa Batlló was built in 1877, commissioned by Lluís Sala Sánchez. It was a classical building without remarkable characteristics within the eclecticism traditional by the end of the 19th century. The building had a basement, a ground floor, four other floors and a garden in the back.

The house was bought by Josep Batlló in 1900. The design of the house made the home undesirable to buyers but the Batlló family decided to buy the place due to its centralized location. It is located in the middle of Passeig de Gracia, which in the early 20th century was known as a very prestigious and fashionable area. It was an area where the prestigious family could draw attention to themselves.

In 1906 Josep Batlló still owned the home. The Batlló family was very well known in Barcelona for its contribution to the textile industry in the city. Mr. Josep Batlló I Casanovas was a textile industrialist who owned a few factories in the city. Mr. Batlló married Amalia Godo Belaunzaran, from the family that founded the newspaper La Vanguardia. Josep wanted an architect that would design a house that was like no other and stood out as being audacious and creative. Both Josep and his wife were open to anything and they decided not to limit Gaudí. Josep did not want his house to resemble any of the houses of the rest of the Batlló family, such as Casa Pía, built by the Josep Vilaseca. He chose the architect who had designed Park Güell because he wanted him to come up with a risky plan. The family lived on the Noble Floor of Casa Batlló until the middle of the 1950s.

In 1904 Josep Batlló hired Gaudí to design his home; at first his plans were to tear down the building and construct a completely new house. Gaudí convinced Josep that a renovation was sufficient and was also able to submit the planning application the same year. The building was completed and refurbished in 1906. He completely changed the main apartment which became the residence for the Batlló family. He expanded the central well in order to supply light to the whole building and also added new floors. In the same year the Barcelona City Council selected the house as a candidate for that year's best building award. The award was given to another architect that year despite Gaudí's design.

Josep Batlló died in 1934 and the house was kept in order by the wife until her death in 1940 . After the death of the two parents, the house was kept and managed by the children until 1954. In 1954 an insurance company named Seguros Iberia acquired Casa Batlló and set up offices there. In 1970, the first refurbishment occurred mainly in several of the interior rooms of the house. In 1983, the exterior balconies were restored to their original colour and a year later the exterior façade was illuminated in the ceremony of La Mercè.

In 1993, the current owners of Casa Batlló bought the home and continued refurbishments throughout the whole building. Two years later, in 1995, Casa Batlló began to hire out its facilities for different events. More than 2,500 square meters of rooms within the building were rented out for many different functions. Due to the building's location and the beauty of the facilities being rented, the rooms of Casa Batlló were in very high demand and hosted many important events for the city.

The local name for the building is "Casa dels ossos" (House of Bones), as it has a visceral, skeletal organic quality. The building looks very remarkable — like everything Gaudí designed, only identifiable as Modernisme or Art Nouveau in the broadest sense. The ground floor, in particular, is rather astonishing with tracery, irregular oval windows and flowing sculpted stone work.

It seems that the goal of the designer was to avoid straight lines completely. Much of the façade is decorated with a mosaic made of broken ceramic tiles (trencadís) that starts in shades of golden orange moving into greenish blues. The roof is arched and was likened to the back of a dragon or dinosaur. A common theory about the building is that the rounded feature to the left of centre, terminating at the top in a turret and cross, represents the lance of Saint George (patron saint of Catalonia, Gaudí's home), which has been plunged into the back of the dragon.

The loft is considered to be one of the most unusual spaces. It was formerly a service area for the tenants of the different apartments in the building which contained laundry rooms and storage areas. It is known for its simplicity of shapes and its Mediterranean influence through the use of white on the walls. It contains a series of sixty catenary arches that creates a space which represents the ribcage of an animal. Some people believe that the “ribcage” design of the arches is a ribcage for the dragon's spine that is represented in the roof.

The noble floor is larger than seven-hundred square meters. It is the main floor of the building. The noble floor is accessed through a private entrance hall that utilizes skylights resembling tortoise shells and vaulted walls in curving shapes. On the noble floor, there is a spacious landing with direct views to the blue tiling of the building well. On the Passeig de Gracia side is Mr. Batlló's study, a dining room, and a secluded spot for courting couples, decorated with a mushroom-shaped fireplace. The elaborate and animal-like décor continues throughout the whole noble floor.

In 2002, the house opened its doors to the public, and people were allowed to visit the noble floor. The building was opened to the public as part of the celebration of the International Year of Gaudí. Casa Batlló met with very much unanticipated success, and visitors became eager to see the rest of the house. Two years later, in celebration of the one hundredth anniversary of the beginning of work on Casa Batlló the fifth floor was restored, and the house extended its visit to the loft and the well. In 2005, Casa Batlló became a Unesco World Heritage Site.

The roof terrace is one of the most popular features of the entire house due to its famous dragon back design. Gaudí represents an animal's spine by using tiles of different colors on one side. The roof is decorated with four chimney stacks, that are designed to prevent backdraughts.

The facade has three distinct sections which are harmoniously integrated. The lower ground floor with the main floor and two first-floor galleries are contained in a structure of Montjuïc sandstone with undulating lines. The central part, which reaches the last floor, is a multicolored section with protruding balconies. The top of the building is a crown, like a huge gable, which is at the same level as the roof and helps to conceal the room where there used to be water tanks. This room is currently empty. The top displays a trim with ceramic pieces that has attracted multiple interpretations.


The roof's arched profile recalls the spine of a dragon with ceramic tiles for scales, and a small triangular window towards the right of the structure simulates the eye. Legend has it that it was once possible to see the Sagrada Familia through this window, which was being built simultaneously. The view of the Sagrada Familia is now blocked from this vantage point by newer buildings. The tiles were given a metallic sheen to simulate the varying scales of the monster, with the color grading from green on the right side, where the head begins, to deep blue and violet in the center, to red and pink on the left side of the building.

One of the highlights of the facade is a tower topped with a cross of four arms oriented to the cardinal directions. It is a bulbous, root-like structure that evokes plant life. There is a second bulb-shaped structure similarly reminiscent of a thalamus flower, which is represented by a cross with arms that are actually buds announcing the next flowering. The tower is decorated with monograms of Jesus (JHS), Maria (M with the ducal crown) and Joseph (JHP), made of ceramic pieces that stand out golden on the green background that covers the facade. These symbols show the deep religiosity of Gaudi, who was inspired by the contemporaneous construction of his basilica to choose the theme of the holy family.

The bulb was broken when it was delivered, perhaps during transportation. Although the manufacturer committed to re-do the broken parts, Gaudí liked the aesthetic of the broken masonry and asked that the pieces be stuck to the main structure with lime mortar and held in with a brass ring.


The central part of the facade evokes the surface of a lake with water lilies, reminiscent of Monet's Nymphéas, with gentle ripples and reflections caused by the glass and ceramic mosaic. It is a great undulating surface covered with plaster fragments of colored glass discs combined with 330 rounds of polychrome pottery. The discs were designed by Gaudí and Jujol between tests during their stay in Majorca, while working on the restoration of the Cathedral of Palma.

Finally, above the central part of the facade is a smaller balcony, also iron, with a different exterior aesthetic, closer to a local type of lily. Two iron arms were installed here to support a pulley to raise and lower furniture.

The facade of the main floor, made entirely in sandstone, and is supported by two columns. The design is complemented by joinery windows set with multicolored stained glass. In front of the large windows, as if they were pillars that support the complex stone structure, there are six fine columns that seem to simulate the bones of a limb, with an apparent central articulation; in fact, this is a floral decoration. The rounded shapes of the gaps and the lip-like edges carved into the stone surrounding them create a semblance of a fully open mouth, for which the Casa Batlló has been nicknamed the "house of yawns." The structure repeats on the first floor and in the design of two windows at the ends forming galleries, but on the large central window there are two balconies as described above.





</doc>
<doc id="1324" url="https://en.wikipedia.org/wiki?curid=1324" title="Park Güell">
Park Güell

The Park Güell ( ; ) is a public park system composed of gardens and architectonic elements located on Carmel Hill, in Barcelona, Catalonia, Spain. Carmel Hill belongs to the mountain range of Collserola – the Parc del Carmel is located on the northern face. Park Güell is located in La Salut, a neighborhood in the Gràcia district of Barcelona. With urbanization in mind, Eusebi Güell assigned the design of the park to Antoni Gaudí, a renowned architect and the face of Catalan modernism. 

The park was built from 1900 to 1914 and was officially opened as a public park in 1926. In 1984, UNESCO declared the park a World Heritage Site under "Works of Antoni Gaudí".

Park Güell is the reflection of Gaudí's artistic plenitude, which belongs to his naturalist phase (first decade of the 20th century). During this period, the architect perfected his personal style through inspiration from organic shapes. He put into practice a series of new structural solutions rooted in the analysis of geometry. To that, the Catalan artist adds creative liberty and an imaginative, ornamental creation. Starting from a sort of baroquism, his works acquire a structural richness of forms and volumes, free of the rational rigidity or any sort of classic premises. In the design of Park Güell, Gaudí unleashed all his architectonic genius and put to practice much of his innovative structural solutions that would become the symbol of his organic style and that would culminate in the creation of the Basilica and Expiatory Church of the Holy Family (Catalan: Sagrada Familia).

Güell and Gaudí conceived this park, situated within a natural park. They imagined an organized grouping of high-quality homes, decked out with all the latest technological advancements to ensure maximum comfort, finished off with an artistic touch. They also envisioned a community strongly influenced by symbolism, since, in the common elements of the park, they were trying to synthesize many of the political and religious ideals shared by patron and architect: therefore there are noticeable concepts originating from political Catalanism – especially in the entrance stairway where the Catalan countries are represented – and from Catholicism – the Monumento al Calvario, originally designed to be a chapel. The mythological elements are so important: apparently Güell and Gaudí's conception of the park was also inspired by the Temple of Apollo of Delphi.

On the other hand, many experts have tried to link the park to various symbols because of the complex iconography that Gaudí applied to the urban project. Such references go from political vindication to religious exaltation, passing through mythology, history and philosophy. Specifically, many studies claim to see references to Freemasonry, despite the deep religious beliefs of both Gaudí and Count Güell. These references have not been proven in the historiography of the modern architect. The multiplicity of symbols found in the Park Güell is, as previously mentioned, associated to political and religious signs, with a touch of mystery according to the preferences of that time for enigmas and puzzles.

The park was originally part of a commercially unsuccessful housing site, the idea of Count Eusebi Güell, after whom the park was named. It was inspired by the English garden city movement; hence the original English name "Park" (in Catalan the name is "Parc Güell"). The site was a rocky hill with little vegetation and few trees, called "Muntanya Pelada" (Bare Mountain). It already included a large country house called Larrard House or Muntaner de Dalt House and was next to a neighbourhood of upper-class houses called "La Salut" (The Health). The intention was to exploit the fresh air (well away from smoky factories) and beautiful views from the site, with sixty triangular lots being provided for luxury houses. Count Eusebi Güell added to the prestige of the development by moving in 1906 to live in Larrard House. Ultimately, only two houses were built, neither designed by Gaudí. One was intended to be a show house, but on being completed in 1904 was put up for sale, and as no buyers came forward, Gaudí, at Güell's suggestion, bought it with his savings and moved in with his family and his father in 1906. This house, where Gaudí lived from 1906 to 1926, was built by Francesc Berenguer in 1904. It contains original works by Gaudí and several of his collaborators. It is now the Gaudi House Museum (Casa Museu Gaudí) since 1963. In 1969 it was declared a historical artistic monument of national interest.

It has since been converted into a municipal garden. It can be reached by underground railway (although the stations are at a distance from the Park and at a much lower level below the hill), by city buses, or by commercial tourist buses. Since October 2013 there is an entrance fee to visit the Monumental Zone (main entrance, terrace, and the parts containing mosaics), but the entrance to the Park remains free. Gaudí's house, "la Torre Rosa," – containing furniture that he designed – can be only visited for another entrance fee. There is a reduced rate for those wishing to see both Gaudí's house and the Sagrada Família Church.

Park Güell is designed and composed to bring the peace and calm that one would expect from a park. The buildings flanking the entrance, though very original and remarkable with fantastically shaped roofs with unusual pinnacles, fit in well with the use of the park as pleasure gardens and seem relatively inconspicuous in the landscape when one considers the flamboyance of other buildings designed by Gaudí. One of these buildings houses a permanent exhibition of the Barcelona City History Museum MUHBA focused on the building itself, the park and the city.

The focal point of the park is the main terrace, surrounded by a long bench in the form of a sea serpent. The curves of the serpent bench form a number of enclaves, creating a more social atmosphere. Gaudí incorporated many motifs of Catalan nationalism, and elements from religious mysticism and ancient poetry, into the Park. Much of the design of the benches was the work not of Gaudí but of his often overlooked collaborator Josep Maria Jujol.

Roadways around the park to service the intended houses were designed by Gaudí as structures jutting out from the steep hillside or running on viaducts, with separate footpaths in arcades formed under these structures. This minimized the intrusion of the roads, and Gaudí designed them using local stone in a way that integrates them closely into the landscape. His structures echo natural forms, with columns like tree trunks supporting branching vaulting under the roadway, and the curves of vaulting and alignment of sloping columns designed in a similar way to his Church of Colònia Güell so that the inverted catenary arch shapes form perfect compression structures.

The large cross at the park's high-point offers the most complete view of Barcelona and the bay. It is possible to view the main city in panorama, with the Sagrada Família and the Montjuïc area visible at a distance.

The park supports a wide variety of wildlife, notably several of the non-native species of parrot found in the Barcelona area. Other birds can be seen from the park, with records including short-toed eagle. The park also supports a population of hummingbird hawk moths.



</doc>
<doc id="1325" url="https://en.wikipedia.org/wiki?curid=1325" title="Casa Milà">
Casa Milà

Casa Milà (, ), popularly known as "La Pedrera" () or "The stone quarry", a reference to its unconventional rough-hewn appearance, is a modernist building in Barcelona, Catalonia, Spain. It was the last private residence designed by architect Antoni Gaudí and was built between 1906 and 1912.

The building was commissioned in 1906 by and his wife . At the time, it was controversial because of its undulating stone facade, twisting wrought iron balconies and designed by Josep Maria Jujol. Several structural innovations include a self-supporting stone façade, and a free-plan floor, underground garage and the spectacular terrace on the roof.

In 1984, it was declared a World Heritage Site by UNESCO. From 2013 is the headquarters of the which manages the visit to the building, exhibitions and other cultural and educative activities at Casa Milà.

Casa Milà was built for Roser Segimón and her husband Pere Milà. Roser Segimón was the wealthy widow of Josep Guardiola, an "Indiano or Americano," or former colonist returned from South America, had made his fortune with a coffee plantation in Guatemala. Her second husband, Pere Milà was a developer known for his flamboyant lifestyle.

In 1905, Milà and Segimón married and on June 9, Roser Segimón bought a house with garden which occupied an area of 1,835 square meters, located on Paseo de Gracia, 92. In September, they commissioned Gaudí for building them a new house with the idea of living in the main floor and renting out the rest of the apartments. On February 2, 1906, the project was presented to the Barcelona City Council and the works began, demolishing the pre-existing building instead of reforming it, as in the case of the Casa Batlló.

The building was completed in December 1910 and the owner asked Gaudí to make a certificate to inhabit the main floor, which the City Council authorized in October 1911, and the couple moved in. On October 31, 1912, Gaudí issued the certificate stating that, in accordance with his plans and his direction, the work had been completed and the whole house was ready to be rented.

The building did not respect any rules of conventional style, for which Gaudí received much criticism. To begin with, the name "La Pedrera" is in fact a nickname assigned by the citizens who disapproved of its unusualness. The unique structure of the building and the relationship between the building's architect and Pere Milà became the object of ridicule for the people of Barcelona and many humorous publications of the time.

Gaudí, a Catholic and a devotee of the Virgin Mary, planned for the Casa Milà to be a spiritual symbol. Overt religious elements include an excerpt from the Rosary on the cornice and planned statues of Mary, specifically Our Lady of the Rosary, and two archangels, St. Michael and St. Gabriel.

However, the Casa Milà was not built entirely to Gaudí's specifications. The local government ordered the demolition of elements that exceeded the height standard for the city, and fined the Milàs for many infractions of building codes. After Semana Trágica, an outbreak of anticlericalism in the city, Milà prudently decided to forgo the religious statues. Gaudí contemplated abandoning the project but a priest persuaded him to continue.

In 1940, Milà died. Segimon sold the property in 1946 for 18 million pesetas to Josep Ballvé i Pellisé, known for his department stores on , in partnership with the family of Pío Rubert Laporta. The Compañía Inmobiliaria Provenza, SA (CIPSA) was founded to administer the building. Roser Segimon continued to live on the main floor until her death in 1964.
The new owners divided the first floor facing into five apartments instead of the original two. In 1953, they commissioned to convert 13 rubbish-filled attic laundry rooms to street-facing apartments, leaving a communal hallway on the side facing the courtyards. Some of these two or three room apartments had a loft and were designed and furnished in a typical early 1950s style using brick, ceramic and wood. Items of furniture, such as the , were reminiscent of Eero Saarinen's work.

The insurance company Northern took over the main floor in 1966. By then, Casa Milà had housed a bingo hall, an academy and the offices of Cementos Molins and Inoxcrom among others. Maintenance costs were high and the owners had allowed the building to become dilapidated, causing stones to loosen in 1971. Josep Anton Comas made some emergency repairs, especially to the paintings in the courtyards, while respecting the original design.

Gaudí's work was designated a historic and artistic monument on July 24, 1969. Casa Milà was in poor condition in the early 1980s. It had been painted a dreary brown and many of its interior color schemes had been abandoned or allowed to deteriorate, but it has been restored since and many of the original colors revived.

In 1984 the building became part of a World Heritage Site encompassing some of Gaudí's works. The Barcelonan city council tried to rent the main floor as an office for the 1992 Olympic bid. Finally, the day before Christmas 1986, Caixa Catalunya bought La Pedrera for 900 million pesetas. On February 19, 1987, urgently needed work began on the restoration and cleaning of the façade. The work was done by the architects Joseph Emilio Hernández-Cross and Rafael Vila. The renovated main floor opened in 1990 as part of the Cultural Olympiad of Barcelona. The floor became an exhibition room with an example of modernism in the Eixample.

The building is 1,323 m per floor on a plot of 1,620 m. Gaudí made the first sketches in his workshop in the Sagrada Família. He designed the house as a constant curve, both outside and inside, incorporating ruled geometry and naturalistic elements.
Casa Milà consists of two buildings, which are structured around two courtyards that provide light to the nine storeys: basement, ground floor, mezzanine, main (or noble) floor, four upper floors, and an attic. The basement was intended to be the garage, the main floor the residence of the Milàs (a flat of all 1,323 m), and the rest distributed over 20 apartments. The resulting layout is shaped like an asymmetrical "8" because of the different shapes and sizes of the courtyards. The attic housed the laundry and drying areas, forming an insulating space for the building and simultaneously determining the levels of the roof.

One of the most notable elements of the building is the roof, crowned with skylights, staircase exits, fans, and chimneys. All of these elements, constructed out of brick covered with lime, broken marble, or glass have a specific architectural function but are also real sculptures integrated into the building.

The apartments feature plastered ceilings with dynamic reliefs, handcrafted wooden doors, windows, and furniture, as well as hydraulic tiles and various ornamental elements.

The stairways were intended as service entries, with the main access to the apartments by elevator except for the noble floor, where Gaudí added a prominent interior staircase. Gaudí wanted the people who lived in the flats to all know each other. Therefore, there were only elevators on every other floor, so people on different floors would meet one another.

Casa Milà is characterized by its self-supporting stone facade, meaning that it is free of load-bearing walls. The facade connects to the internal structure of each floor by means of curved iron beams surrounding the perimeter of each floor. This construction system allows, on one hand, large openings in the facade which give light to the homes, and on the other, free structuring of the different levels, so that internal walls can be added and demolished without affecting the stability of the building. This allows the owners to change their minds at will and to modify, without problems, the interior layout of the homes.

The facade is composed of large blocks of limestone from the Garraf Massif on the first floor and from the Villefranche quarry for the higher levels. The blocks were cut to follow the plot of the projection of the model, then raised to their location and adjusted to align in a continuous curve to the pieces around them.

Viewed from the outside the building has three parts: the main body of the six-storey blocks with winding stone floors, two floors set a block back with a different curve, similar to waves, a smoother texture and whiter color, and with small holes that look like embrasures, and finally the body of the roof.

Gaudí's original facade had some of its lower-level ironwork removed. In 1928, the tailor Mosella opened the first store in La Pedrera, and he eliminated the bars. This did not concern anyone, because in the middle of twentieth century, wrought ironwork had little importance. The ironwork was lost until a few years later, when Americans donated one of them to the MoMa, where it is on display.

With restoration initiatives launched in 1987, the facade was rejoined to some pieces of stone that had fallen. In order to respect the fidelity of the original, material was obtained from the Villefranche quarry, even though by then it was no longer operating.

The building uses a completely original solution to solve the issue of a lobby being too closed and dark. Its open and airy courtyards provide a place of transit and are directly visible to those accessing the building. There are two patios on the side of the Passeig de Gracia and of the street Provence.


Patios, structurally, are key as supporting loads of interior facades. The floor of the courtyard is supported by pillars of cast iron. In the courtyard, there are traditional elliptical beams and girders but Gaudí applied an ingenious solution of using two concentric cylindrical beams with stretched radial beams, like the spokes of a bicycle. They form a point outside of the beam to two points above and below, making the function of the central girder a keystone and working in tension and compression simultaneously. This supported structure is twelve feet in diameter and is considered "the soul of the building" with a clear resemblance to Gothic crypts. The centerpiece was built in a shipyard by Josep Maria Carandell who copied a steering wheel, interpreting Gaudí's intent as to represent the helm of the ship of life.


Access is protected by a massive iron gate with a design attributed to Jujol. It was originally used by both people and cars, as access to the garage is in the basement, now an auditorium.

The two halls are fully polychrome with oil paintings on the plaster surfaces, with eclectic references to mythology and flowers.

During construction there was a problem including a basement as a garage for cars, the new invention that was thrilling the bourgeois at the time. The future neighbor Felix Anthony Meadows, owner of Industrial Linera, requested a change because his Rolls Royce could not access it. Gaudí agreed to remove a pillar on the ramp that led into the garage so that Felix, who was establishing sales and factory in Walls of Valles, could go to both places with his car from La Pedrera.

For the floors of Casa Milà, Gaudí used a model of floor forms of square timbers with two colors, and the hydraulic pavement hexagonal pieces of blue and sea motifs that had originally been designed for the Batllo house. The wax was designed in gray by John Bertrand under the supervision of Gaudí who "touched up with their own fingers," in the words of the manufacturer Josep Bay.

Like in Casa Batlló, Gaudí shows the application of the catenary arch as a support structure for the roof, a form which he had already used shortly after graduating in the wood frameworks of Mataró's cooperative known as "L'Obrera Mataronense." In this case, Gaudí used the Catalan technique of timbrel, imported from Italy in the fourteenth century.

The attic, where the laundry rooms were located, was a clear room under a Catalan vault roof supported by 270 parabolic vaults of different heights and spaced by about 80 cm. The roof resembles both the ribs of a huge animal and a palm, giving the roof-deck a very unconventional shape similar to a landscape of hills and valleys. The shape and location of the courtyards makes the arches higher when the space is narrowed and lower when the space expands.

The builder Bayó explained its construction: "First the face of a wide wall was filled with mortar and plastered. Then Canaleta indicated the opening of each arch and Bayó put a nail at each starting point of the arch at the top of the wall. From these nails was dangled a chain so that the lowest point coincided with the deflection of the arch. Then the profile displayed on the wall by the chain was drawn and on this profile the carpenter marked and placed the corresponding centering, and the timbrel vault was started with three rows of plane bricks. Gaudí wanted to add a longitudinal axis of bricks connecting all vaults at their keystones".

The work of Gaudí on the rooftop of La Pedrera brought his experience at Palau Güell together with solutions that were clearly more innovative – this time creating shapes and volumes with more body, more prominence, and less polychromasia.

On the rooftop there are six skylights/staircase exits (four of which were covered with broken pottery and some that ended in a double cross typical of Gaudí), twenty-eight chimneys in several groupings, two half-hidden vents whose function is to renew the air in the building, and four domes that discharged to the facade. The staircases also house the water tanks; some of which are snail-shaped.

The stepped roof of La Pedrera, called "the garden of warriors" by the poet Pere Gimferrer because the chimneys appear to be protecting the skylights, has undergone a radical restoration, removing chimneys added in interventions after Gaudí, television antennas, and other elements that degraded the space. The restoration brought back the splendor to the chimneys and the skylights that were covered with fragments of marble and broken Valencia tiles. One of the chimneys was topped with glass pieces – it was said that Gaudí did that the day after the inauguration of the building, taking advantage of the empty bottles from the party. It was restored with the bases of champagne bottles from the early twentieth century. The repair work has enabled the restoration of the original impact of the overhangs made of stone from Ulldecona with fragments of tiles. This whole set is more colorful than the facade, although here the creamy tones are dominant.

Gaudí, as he had done in Casa Batlló, designed furniture specifically for the main floor. This was part of the concept artwork itself integral to modernism in which the architect assumed responsibility for global issues such as the structure and the facade, as well as every detail of the decor, designing furniture and accessories such as lamps, planters, floors or ceilings.

This was another point of friction with Segimon, who complained that there was no straight wall to place her Steinway piano. Gaudí's response was blunt: "So play the violin." The result of these disagreements has been the loss of the decorative legacy of Gaudí, as most of the furniture was removed due to climate change and the changes she made to the main floor when Gaudí died. Some remain in private collections, including a curtain made of oak 4 m. long by 1.96 m. high in the Museum of Catalan Modernism; and a chair and desktop of Milà.

Gaudí carved oak doors similar to what he had done for the Casa y Bardes, but these were only included on two floors as when Segimon discovered the price, she decided there would be no more at that quality.

"Casa Milà" is part of the UNESCO World Heritage Site "Works of Antoni Gaudí". It was a predecessor of some buildings with a similar biomorphic appearance:

Free exhibitions often are held on the first floor, which also provides some opportunity to see the interior design. There is a charge for entrance to the apartment on the fourth floor and the roof. The other floors are not open to visitors.

Gaudí's La Pedrera was inspired by a mountain, but there is no agreement as to which mountain was the reference model. Joan Bergós thought it was the rocks of Fray Guerau in Prades mountains. Joan Matamala thought that the model could have been St. Miquel del Fai, while the sculptor Vicente Vilarubias believed it was inspired by the cliffs Torrent Pareis in Menorca. Other options include the mountains of Uçhisar in Cappadocia, suggested by Juan Goytisolo, or Mola Gallifa, suggested by Louis Permanyer, based on the fact that Gaudí visited the area in 1885 to escape an outbreak of cholera in Barcelona.

Some people say that the interior layout of La Pedrera comes from studies that Gaudí made of medieval fortresses. This image is reinforced by the seeming appearance of the rooftop chimneys as "sentinels" with great helmets. The structure of the iron door in the lobby does not follow any symmetry, straight or repetitive pattern. Rather, it evokes bubbles of soap that are formed between the hands or the structures of a plant cell.

The building's unconventional style made it the subject of much criticism. It was given the nickname "La Pedrera", meaning "the quarry". Casa Milà appeared in many satirical magazines. Joan Junceda presented it as a traditional "Easter cake" by means of cartoons in "Patufet". Joaquim Garcia made a joke about the difficulty of setting the damask wrought iron balconies in his magazine. Homeowners in Passeig de Gracia became angry with Milà and ceased to greet him, arguing that the weird building by Gaudí would lower the price of land in the area.

Casa Milà also caused some administrative problems. In December 1907 the City Hall stopped work on the building because of a pillar which occupied part of the sidewalk, not respecting the alignment of facades. Again on August 17, 1908, more problems occurred when the building surpassed the predicted height and borders of its construction site by . The Council called for a fine of 100,000 pesetas (approximately 25% of the cost of work) or for the demolition of the attic and roof. The dispute was resolved a year and a half later, December 28, 1909, when the Commission certified that it was a monumental building and thus not required to have a 'strict compliance' with the bylaws.

The owner entered La Pedrera in the annual sponsored by the Barcelona City Council ("Ayuntament"). Other entries in the competition included two works by Sagnier (Calle Mallorca 264, and one on Corsica and Av. Diagonal), the by architect , and the , designed by . Although the most dramatic and clear favorite was Casa Milà, the jury opined that even though the facades were complete, "there's still a lot left to do before it's fully completed, finalized and in a perfect state of appreciation." The winner in 1910 was Samanillo Perez, for his building which now houses the headquarters of the Circulo Ecuestre.

Gaudí's relations with Segimon deteriorated during the construction and decoration of the house. There were many disagreements between them, one example was the monumental bronze virgin del Rosario, which Gaudí wanted as the statue on the front of the building in homage to the name of the owner, that the artist Carles Mani i Roig was to sculpt. The statue was not made although the words ""Ave gratia M plena Dominus tecum"" were written at the top of the facade. Continuing disagreements led Gaudí to take Milà to court over his fees. The lawsuit was won by Gaudí in 1916, and he gave the 105,000 pesetas he won in the case to charity, stating that "the principles mattered more than money." Milà was having to pay the mortgage.

After Gaudí's death in 1926, Segimon got rid of most of the furniture that Gaudí had designed and covered over parts of Gaudí's designs with new decorations in the style of Louis XVI. La Pedrera was acquired in 1986 by and when restoration was done four years later, some of the original decorations re-emerged.

When the Civil War broke out in July 1936, the Milàs were on vacation. Part of the building was collectivized by the Unified Socialist Party of Catalonia; the Milàs fled the area with some artwork.






</doc>
<doc id="1327" url="https://en.wikipedia.org/wiki?curid=1327" title="Antiparticle">
Antiparticle

In particle physics, every type of particle has an associated antiparticle with the same mass but with opposite physical charges (such as electric charge). For example, the antiparticle of the electron is the antielectron (which is often referred to as "positron"). While the electron has a negative electric charge, the positron has a positive electric charge, and is produced naturally in certain types of radioactive decay. The opposite is also true: the antiparticle of the positron is the electron.

Some particles, such as the photon, are their own antiparticle. Otherwise, for each pair of antiparticle partners, one is designated as normal matter (the kind all matter usually interacted with is made of), and the other (usually given the prefix "anti-") as "antimatter".

Particle–antiparticle pairs can annihilate each other, producing photons; since the charges of the particle and antiparticle are opposite, total charge is conserved. For example, the positrons produced in natural radioactive decay quickly annihilate themselves with electrons, producing pairs of gamma rays, a process exploited in positron emission tomography.

The laws of nature are very nearly symmetrical with respect to particles and antiparticles. For example, an antiproton and a positron can form an antihydrogen atom, which is believed to have the same properties as a hydrogen atom. This leads to the question of why the formation of matter after the Big Bang resulted in a universe consisting almost entirely of matter, rather than being a half-and-half mixture of matter and antimatter. The discovery of Charge Parity violation helped to shed light on this problem by showing that this symmetry, originally thought to be perfect, was only approximate.

Because charge is conserved, it is not possible to create an antiparticle without either destroying another particle of the same charge (as is for instance the case when antiparticles are produced naturally via beta decay or the collision of cosmic rays with Earth's atmosphere), or by the simultaneous creation of both a particle "and" its antiparticle, which can occur in particle accelerators such as the Large Hadron Collider at CERN.

Although particles and their antiparticles have opposite charges, electrically neutral particles need not be identical to their antiparticles. The neutron, for example, is made out of quarks, the antineutron from antiquarks, and they are distinguishable from one another because neutrons and antineutrons annihilate each other upon contact. However, other neutral particles are their own antiparticles, such as photons, Z bosons,  mesons, and hypothetical gravitons and some hypothetical WIMPs.

In 1932, soon after the prediction of positrons by Paul Dirac, Carl D. Anderson found that cosmic-ray collisions produced these particles in a cloud chamber— a particle detector in which moving electrons (or positrons) leave behind trails as they move through the gas. The electric charge-to-mass ratio of a particle can be measured by observing the radius of curling of its cloud-chamber track in a magnetic field. Positrons, because of the direction that their paths curled, were at first mistaken for electrons travelling in the opposite direction. Positron paths in a cloud-chamber trace the same helical path as an electron but rotate in the opposite direction with respect to the magnetic field direction due to their having the same magnitude of charge-to-mass ratio but with opposite charge and, therefore, opposite signed charge-to-mass ratios.

The antiproton and antineutron were found by Emilio Segrè and Owen Chamberlain in 1955 at the University of California, Berkeley. Since then, the antiparticles of many other subatomic particles have been created in particle accelerator experiments. In recent years, complete atoms of antimatter have been assembled out of antiprotons and positrons, collected in electromagnetic traps.

Solutions of the Dirac equation contained negative energy quantum states. As a result, an electron could always radiate energy and fall into a negative energy state. Even worse, it could keep radiating infinite amounts of energy because there were infinitely many negative energy states available. To prevent this unphysical situation from happening, Dirac proposed that a "sea" of negative-energy electrons fills the universe, already occupying all of the lower-energy states so that, due to the Pauli exclusion principle, no other electron could fall into them. Sometimes, however, one of these negative-energy particles could be lifted out of this Dirac sea to become a positive-energy particle. But, when lifted out, it would leave behind a "hole" in the sea that would act exactly like a positive-energy electron with a reversed charge. These holes were interpreted as "negative-energy electrons" by Paul Dirac and by mistake he identified them with protons in his 1930 paper "A Theory of Electrons and Protons" However, these "negative-energy electrons" turned out to be positrons, and not protons.

This picture implied an infinite negative charge for the universe—a problem of which Dirac was aware. Dirac tried to argue that we would perceive this as the normal state of zero charge. Another difficulty was the difference in masses of the electron and the proton. Dirac tried to argue that this was due to the electromagnetic interactions with the sea, until Hermann Weyl proved that hole theory was completely symmetric between negative and positive charges. Dirac also predicted a reaction  +  →  + , where an electron and a proton annihilate to give two photons. Robert Oppenheimer and Igor Tamm proved that this would cause ordinary matter to disappear too fast. A year later, in 1931, Dirac modified his theory and postulated the positron, a new particle of the same mass as the electron. The discovery of this particle the next year removed the last two objections to his theory.

Within Dirac's theory, the problem of infinite charge of the universe remains. Some bosons also have antiparticles, but since bosons do not obey the Pauli exclusion principle (only fermions do), hole theory does not work for them. A unified interpretation of antiparticles is now available in quantum field theory, which solves both these problems by describing antimatter as negative energy states of the same underlying matter field i.e. particles moving backwards in time.

If a particle and antiparticle are in the appropriate quantum states, then they can annihilate each other and produce other particles. Reactions such as  +  →   +  (the two-photon annihilation of an electron-positron pair) are an example. The single-photon annihilation of an electron-positron pair,  +  → , cannot occur in free space because it is impossible to conserve energy and momentum together in this process. However, in the Coulomb field of a nucleus the translational invariance is broken and single-photon annihilation may occur. The reverse reaction (in free space, without an atomic nucleus) is also impossible for this reason. In quantum field theory, this process is allowed only as an intermediate quantum state for times short enough that the violation of energy conservation can be accommodated by the uncertainty principle. This opens the way for virtual pair production or annihilation in which a one particle quantum state may "fluctuate" into a two particle state and back. These processes are important in the vacuum state and renormalization of a quantum field theory. It also opens the way for neutral particle mixing through processes such as the one pictured here, which is a complicated example of mass renormalization.

Quantum states of a particle and an antiparticle can be interchanged by applying the charge conjugation (C), parity (P), and time reversal (T) operators. If formula_1 denotes the quantum state of a particle (n) with momentum p, spin J whose component in the z-direction is σ, then one has
where n denotes the charge conjugate state, that is, the antiparticle. This behaviour under CPT symmetry is the same as the statement that the particle and its antiparticle lie in the same irreducible representation of the Poincaré group. Properties of antiparticles can be related to those of particles through this. If T is a good symmetry of the dynamics, then
where the proportionality sign indicates that there might be a phase on the right hand side. In other words, particle and antiparticle must have

One may try to quantize an electron field without mixing the annihilation and creation operators by writing

where we use the symbol "k" to denote the quantum numbers "p" and σ of the previous section and the sign of the energy, "E(k)", and "a" denotes the corresponding annihilation operators. Of course, since we are dealing with fermions, we have to have the operators satisfy canonical anti-commutation relations. However, if one now writes down the Hamiltonian

then one sees immediately that the expectation value of "H" need not be positive. This is because "E(k)" can have any sign whatsoever, and the combination of creation and annihilation operators has expectation value 1 or 0.

So one has to introduce the charge conjugate "antiparticle" field, with its own creation and annihilation operators satisfying the relations

where "k" has the same "p", and opposite σ and sign of the energy. Then one can rewrite the field in the form

where the first sum is over positive energy states and the second over those of negative energy. The energy becomes

where "E" is an infinite negative constant. The vacuum state is defined as the state with no particle or antiparticle, "i.e.", formula_11 and formula_12. Then the energy of the vacuum is exactly "E". Since all energies are measured relative to the vacuum, H is positive definite. Analysis of the properties of "a" and "b" shows that one is the annihilation operator for particles and the other for antiparticles. This is the case of a fermion.

This approach is due to Vladimir Fock, Wendell Furry and Robert Oppenheimer. If one quantizes a real scalar field, then one finds that there is only one kind of annihilation operator; therefore, real scalar fields describe neutral bosons. Since complex scalar fields admit two different kinds of annihilation operators, which are related by conjugation, such fields describe charged bosons.

By considering the propagation of the negative energy modes of the electron field backward in time, Ernst Stueckelberg reached a pictorial understanding of the fact that the particle and antiparticle have equal mass m and spin J but opposite charges q. This allowed him to rewrite perturbation theory precisely in the form of diagrams. Richard Feynman later gave an independent systematic derivation of these diagrams from a particle formalism, and they are now called Feynman diagrams. Each line of a diagram represents a particle propagating either backward or forward in time. This technique is the most widespread method of computing amplitudes in quantum field theory today.

Since this picture was first developed by Stueckelberg, and acquired its modern form in Feynman's work, it is called the Feynman–Stueckelberg interpretation of antiparticles to honor both scientists.




</doc>
<doc id="1331" url="https://en.wikipedia.org/wiki?curid=1331" title="Arabian Prince">
Arabian Prince

Kim Renard Nazel (born June 17, 1965), better known by his stage names Arabian Prince or Professor X, is an American rapper, singer-songwriter, record producer, and DJ. He is best known as a founding member of N.W.A.

Nazel was born in Compton, California to the son of Joseph "Skippy" Nazel Jr., a prominent African-American author and radio talk show host. His musical background came from his mother, a piano teacher and classical musician. His family tried their best to shelter him, sending him to a Catholic school and keeping him busy with football to keep him away from the gangs. The younger Nazel got his first experience with making music at the radio station his father was hosting his talk show by using the station's equipment to put together mixtapes that he would sell at school. Nazel went on to graduate from Junípero Serra High School in nearby Gardena.

Nazel took the stage name of DJ Prince at first, out of respect for Prince, and started selling mixtapes at school. While working at a luggage store at the Del Amo Mall, its owner Sam Nassif would ask DJ Prince to dj a party at a community center, and because of his huge following from high school DJ Prince packed the place. He kept performing there for several weekends and the success persuaded Nassif to invest even more in the place, renaming it "The Cave", where Nazel would continue to host for over three years and even after his N.W.A. days. Nassif was also the one to fund DJ Prince first record, "Strange Life"
He changed his stage name when he was 15 years old at the Skateland USA, the same skating venue credited for launching the NWA a few years later, due to a fan's suggestion. He said about his name:

Arabian Prince started working with Bobby Jimmy & the Critters in 1984. He also produced the hit single and album for J.J. Fad, "Supersonic".

In 1986, he was a founding member of N.W.A but when fellow member Ice Cube came back from the Phoenix Institute of Technology in 1988, Arabian Prince soon after left over royalty and contract disagreements. "I started off as a solo artist", he said, " so I was aware of what a royalty statement was. I knew that when these many records were sold, there is a quarterly statement. When you look at it, you can see how much money was paid and then share it. This was not the case. We were also never paid for touring." Eazy-E, Ice Cube and MC Ren remained as the main performers, DJ Yella was the turntablist and Dr. Dre was the main producer.

After leaving N.W.A, Arabian Prince began a solo career. His first album, "Brother Arab", was released in 1989 with the hit single "She's Got A Big Posse"; "Where's My Bytches" followed in 1993.

In the mid-2000s, he started releasing music again, with his Professor X project on the Dutch label Clone Records. "I could not release the record under Arabian Prince", he said, "because I already had a single out, so I called myself Professor X on that record." In 2007 he performed as a DJ on the 2K Sports Holiday Bounce Tour with artists from the Stones Throw label. In 2008, Stones Throw released a compilation of his electro-rap material from the 1980s. One of his songs was included on the 2007 video game, "College Hoops 2K8".

In 2018, Arabian Prince appeared on the fourteenth studio album of industrial-metal band Ministry.

Aside from his music career, he worked in special effects, 3D animation and video games.

After the release of the NWA film, "Straight Outta Compton", in 2015, Arabian Prince said to VladTV: "A lot of the scenes in real life, I was there -I'm just not there in the film, which I'm like, if you're gonna write me out of a movie, shoot some other scenes. Don't write scenes where I was there." Some of the pivotal scenes would be choosing the name for the band, the tour and the infamous Detroit concert. He also remembers himself as the main opposer to Jerry Heller about the royalties and the money, a role that in the movie was instead given to Ice Cube.






</doc>
<doc id="1332" url="https://en.wikipedia.org/wiki?curid=1332" title="August 7">
August 7

This day marks the approximate midpoint of summer in the Northern Hemisphere and of winter in the Southern Hemisphere (starting the season at the June solstice).





</doc>
<doc id="1333" url="https://en.wikipedia.org/wiki?curid=1333" title="August 8">
August 8





</doc>
<doc id="1334" url="https://en.wikipedia.org/wiki?curid=1334" title="April 16">
April 16





</doc>
<doc id="1335" url="https://en.wikipedia.org/wiki?curid=1335" title="Associative property">
Associative property

In mathematics, the associative property is a property of some binary operations. In propositional logic, associativity is a valid rule of replacement for expressions in logical proofs.

Within an expression containing two or more occurrences in a row of the same associative operator, the order in which the operations are performed does not matter as long as the sequence of the operands is not changed. That is, (after rewriting the expression with parentheses and in infix notation if necessary) rearranging the parentheses in such an expression will not change its value. Consider the following equations:

Even though the parentheses were rearranged on each line, the values of the expressions were not altered. Since this holds true when performing addition and multiplication on any real numbers, it can be said that "addition and multiplication of real numbers are associative operations".

Associativity is not the same as commutativity, which addresses whether or not the order of two operands changes the result. For example, the order does not matter in the multiplication of real numbers, that is, , so we say that the multiplication of real numbers is a commutative operation.

Associative operations are abundant in mathematics; in fact, many algebraic structures (such as semigroups and categories) explicitly require their binary operations to be associative.

However, many important and interesting operations are non-associative; some examples include subtraction, exponentiation, and the vector cross product. In contrast to the theoretical properties of real numbers, the addition of floating point numbers in computer science is not associative, and the choice of how to associate an expression can have a significant effect on rounding error.

Formally, a binary operation ∗ on a set "S" is called associative if it satisfies the associative law:

Here, ∗ is used to replace the symbol of the operation, which may be any symbol, and even the absence of symbol (juxtaposition) as for multiplication.

The associative law can also be expressed in functional notation thus: .

If a binary operation is associative, repeated application of the operation produces the same result regardless how valid pairs of parenthesis are inserted in the expression. This is called the generalized associative law. For instance, a product of four elements may be written, without changing the order of the factors, in five possible ways:

If the product operation is associative, the generalized associative law says that all these formulas will yield the same result. So unless the formula with omitted parentheses already has a different meaning (see below), the parentheses can be considered unnecessary and "the" product can be written unambiguously as

As the number of elements increases, the number of possible ways to insert parentheses grows quickly, but they remain unnecessary for disambiguation.

An example where this does not work is the logical biconditional formula_9. It is associative, thus Aformula_9(Bformula_9C) is equivalent to (Aformula_9B)formula_9C, but Aformula_9Bformula_9C most commonly means (Aformula_9B and Bformula_9C), which is not equivalent.

Some examples of associative operations include the following.





In standard truth-functional propositional logic, "association", or "associativity" are two valid rules of replacement. The rules allow one to move parentheses in logical expressions in logical proofs. The rules (using logical connectives notation) are:
and
where "formula_25" is a metalogical symbol representing "can be replaced in a proof with."

"Associativity" is a property of some logical connectives of truth-functional propositional logic. The following logical equivalences demonstrate that associativity is a property of particular connectives. The following are truth-functional tautologies. 

Associativity of disjunction:
Associativity of conjunction:
Associativity of equivalence:

Joint denial is an example of a truth functional connective that is "not" associative.

A binary operation formula_32 on a set "S" that does not satisfy the associative law is called non-associative. Symbolically,

For such an operation the order of evaluation "does" matter. For example:
Also note that infinite sums are not generally associative, for example:
whereas

The study of non-associative structures arises from reasons somewhat different from the mainstream of classical algebra. One area within non-associative algebra that has grown very large is that of Lie algebras. There the associative law is replaced by the Jacobi identity. Lie algebras abstract the essential nature of infinitesimal transformations, and have become ubiquitous in mathematics.

There are other specific types of non-associative structures that have been studied in depth; these tend to come from some specific applications or areas such as combinatorial mathematics. Other examples are Quasigroup, Quasifield, Non-associative ring, Non-associative algebra and Commutative non-associative magmas.

In mathematics, addition and multiplication of real numbers is associative. By contrast, in computer science, the addition and multiplication of floating point numbers is "not" associative, as rounding errors are introduced when dissimilar-sized values are joined together.

To illustrate this, consider a floating point representation with a 4-bit mantissa:
(1.000×2 +
1.000×2) +
1.000×2 =
1.000×2 +
1.000×2 =
1.00×2
1.000×2 +
(1.000×2 +
1.000×2) =
1.000×2 +
1.00×2 =
1.00×2

Even though most computers compute with a 24 or 53 bits of mantissa, this is an important source of rounding error, and approaches such as the Kahan summation algorithm are ways to minimise the errors. It can be especially problematic in parallel computing.

In general, parentheses must be used to indicate the order of evaluation if a non-associative operation appears more than once in an expression (unless the notation specifies the order in another way, like formula_39). However, mathematicians agree on a particular order of evaluation for several common non-associative operations. This is simply a notational convention to avoid parentheses.

A left-associative operation is a non-associative operation that is conventionally evaluated from left to right, i.e.,
while a right-associative operation is conventionally evaluated from right to left:
Both left-associative and right-associative operations occur. Left-associative operations include the following:

Right-associative operations include the following:


Non-associative operations for which no conventional evaluation order is defined include the following.



</doc>
<doc id="1336" url="https://en.wikipedia.org/wiki?curid=1336" title="The Apache Software Foundation">
The Apache Software Foundation

The Apache Software Foundation (ASF) is an American non-profit corporation (classified as a 501(c)(3) organization in the United States) to support Apache software projects, including the Apache HTTP Server. The ASF was formed from the Apache Group and incorporated on March 25, 1999.

The Apache Software Foundation is a decentralized open source community of developers. The software they produce is distributed under the terms of the Apache License and is free and open-source software (FOSS). The Apache projects are characterized by a collaborative, consensus-based development process and an open and pragmatic software license. Each project is managed by a self-selected team of technical experts who are active contributors to the project. The ASF is a meritocracy, implying that membership of the foundation is granted only to volunteers who have actively contributed to Apache projects. The ASF is considered a second generation open-source organization, in that commercial support is provided without the risk of platform lock-in.

Among the ASF's objectives are: to provide legal protection to volunteers working on Apache projects; to prevent the "Apache" brand name from being used by other organizations without permission.

The ASF also holds several ApacheCon conferences each year, highlighting Apache projects and related technology.

According to ASF, products of Apache software foundation are subject to US export control, in contrast to Free software foundation, which clearly opposes "the application of US export control laws to free software".

The history of the Apache Software Foundation is linked to the Apache HTTP Server, development beginning in February 1993. A group of eight developers started working on enhancing the NCSA HTTPd daemon. They came to be known as the Apache Group. On March 25, 1999, the Apache Software Foundation was formed. The first official meeting of the Apache Software Foundation was held on April 13, 1999, and by general consent that the initial membership list of the Apache Software Foundation, would be: Brian Behlendorf, Ken Coar, Miguel Gonzales, Mark Cox, Lars Eilebrecht, Ralf S. Engelschall, Roy T. Fielding, Dean Gaudet, Ben Hyde, Jim Jagielski, Alexei Kosut, Martin Kraemer, Ben Laurie, Doug MacEachern, Aram Mirzadeh, Sameer Parekh, Cliff Skolnick, Marc Slemko, William (Bill) Stoddard, Paul Sutton, Randy Terbush and Dirk-Willem van Gulik. After a series of additional meetings to elect board members and resolve other legal matters regarding incorporation, the effective incorporation date of the Apache Software Foundation was set to June 1, 1999.

The foundation states that the name 'Apache' was chosen "from respect for the Native American Apache Nation, well known for their superior skills in warfare strategy and their inexhaustible endurance". It also makes a pun on "a patchy web server"—a server made from a series of patches—but this was not its origin. The group of developers who released this new software soon started to call themselves the "Apache Group".

Apache divides its software development activities into separate semi-autonomous areas called "top-level projects" (formally known as a "Project Management Committee" in the bylaws), some of which have a number of sub-projects. Unlike some other organizations that host FOSS projects, before a project is hosted at Apache it has to be licensed to the ASF with a grant or contributor agreement. In this way, the ASF gains the necessary intellectual property rights for the development and distribution of all its projects.

The ASF board of directors has responsibility for overseeing the ASF's activities and acting as a central point of contact and communication for its projects. The board assigns corporate issues, assigning resources to projects, and manages corporate services, including funds and legal issues. It does not make technical decisions about individual projects; these are made by the individual Project Management Committees. The board is elected annually by members of the foundation.





</doc>
<doc id="1338" url="https://en.wikipedia.org/wiki?curid=1338" title="Americans with Disabilities Act of 1990">
Americans with Disabilities Act of 1990

The Americans with Disabilities Act of 1990 () is a civil rights law that prohibits discrimination based on disability. It affords similar protections against discrimination to Americans with disabilities as the Civil Rights Act of 1964, which made discrimination based on race, religion, sex, national origin, and other characteristics illegal. In addition, unlike the Civil Rights Act, the ADA also requires covered employers to provide reasonable accommodations to employees with disabilities, and imposes accessibility requirements on public accommodations.

In 1986, the National Council on Disability had recommended enactment of an Americans with Disabilities Act (ADA) and drafted the first version of the bill which was introduced in the House and Senate in 1988. The final version of the bill was signed into law on July 26, 1990, by President George H. W. Bush. It was later amended in 2008 and signed by President George W. Bush with changes effective as of January 1, 2009.

ADA disabilities include both mental and physical medical conditions. A condition does not need to be severe or permanent to be a disability. Equal Employment Opportunity Commission regulations provide a list of conditions that should easily be concluded to be disabilities: deafness, blindness, an intellectual disability (formerly termed mental retardation), partially or completely missing limbs or mobility impairments requiring the use of a wheelchair, autism, cancer, cerebral palsy, diabetes, epilepsy, Human Immunodeficiency Virus (HIV) infection, multiple sclerosis, muscular dystrophy, major depressive disorder, bipolar disorder, post-traumatic stress disorder, obsessive compulsive disorder, and schizophrenia. Other mental or physical health conditions also may be disabilities, depending on what the individual's symptoms would be in the absence of "mitigating measures" (medication, therapy, assistive devices, or other means of restoring function), during an "active episode" of the condition (if the condition is episodic).

Certain specific conditions that are widely considered anti-social, or tend to result in illegal activity, such as kleptomania, pedophilia, exhibitionism, voyeurism, etc. are excluded under the definition of "disability" in order to prevent abuse of the statute's purpose. Additionally, other specific conditions, such as gender identity disorders, are also excluded under the definition of "disability".

See also US labor law and .
The ADA states that a "covered entity" shall not discriminate against "a qualified individual with a disability". This applies to job application procedures, hiring, advancement and discharge of employees, job training, and other terms, conditions, and privileges of employment. "Covered entities" include employers with 15 or more employees, as well as employment agencies, labor organizations, and joint labor-management committees. There are strict limitations on when a covered entity can ask job applicants or employees disability-related questions or require them to undergo medical examination, and all medical information must be kept confidential.

Prohibited discrimination may include, among other things, firing or refusing to hire someone based on a real or perceived disability, segregation, and harassment based on a disability. Covered entities are also required to provide reasonable accommodations to job applicants and employees with disabilities. A reasonable accommodation is a change in the way things are typically done that the person needs because of a disability, and can include, among other things, special equipment that allows the person to perform the job, scheduling changes, and changes to the way work assignments are chosen or communicated. An employer is not required to provide an accommodation that would involve undue hardship (significant difficulty or expense), and the individual who receives the accommodation must still perform the essential functions of the job and meet the normal performance requirements. An employee or applicant who currently engages in the illegal use of drugs is not considered qualified when a covered entity takes adverse action based on such use.

There are many ways to discriminate against people based on disabilities, including psychological ones. Anyone known to have a history of mental disorders can be considered disabled. Employers with more than 15 employees must take care to treat all employees fairly and with any accommodations needed. Even when an employee is doing a job exceptionally well, she or he is not necessarily no longer disabled; employers must continue to follow all policies for the disabled.

Part of Title I was found unconstitutional by the United States Supreme Court as it pertains to states in the case of "Board of Trustees of the University of Alabama v. Garrett" as violating the sovereign immunity rights of the several states as specified by the Eleventh Amendment to the United States Constitution. The Court determined that state employees cannot sue their employer for violating ADA rules. State employees can, however, file complaints at the Department of Justice or the Equal Employment Opportunity Commission, who can sue on their behalf.

Title II prohibits disability discrimination by all public entities at the local level, "e.g.", school district, municipal, city, or county, and at state level. Public entities must comply with Title II regulations by the U.S. Department of Justice. These regulations cover access to all programs and services offered by the entity. Access includes physical access described in the ADA Standards for Accessible Design and programmatic access that might be obstructed by discriminatory policies or procedures of the entity.

Title II applies to public transportation provided by public entities through regulations by the U.S. Department of Transportation. It includes the National Railroad Passenger Corporation (Amtrak), along with all other commuter authorities. This section requires the provision of paratransit services by public entities that provide fixed route services. ADA also sets minimum requirements for space layout in order to facilitate wheelchair securement on public transport.

Title II also applies to all state and local public housing, housing assistance, and housing referrals. The Office of Fair Housing and Equal Opportunity is charged with enforcing this provision.

Under Title III, no individual may be discriminated against on the basis of disability with regards to the full and equal enjoyment of the goods, services, facilities, or accommodations of any place of public accommodation by any person who owns, leases, or operates a place of public accommodation. Public accommodations include most places of lodging (such as inns and hotels), recreation, transportation, education, and dining, along with stores, care providers, and places of public displays.

Under Title III of the ADA, all new construction (construction, modification or alterations) after the effective date of the ADA (approximately July 1992) must be fully compliant with the Americans With Disabilities Act Accessibility Guidelines (ADAAG) found in the Code of Federal Regulations at 28 C.F.R., Part 36, Appendix "A".

Title III also has application to existing facilities. One of the definitions of "discrimination" under Title III of the ADA is a "failure to remove" architectural barriers in existing facilities. See . This means that even facilities that have not been modified or altered in any way after the ADA was passed still have obligations. The standard is whether "removing barriers" (typically defined as bringing a condition into compliance with the ADAAG) is "readily achievable", defined as "...easily accomplished without much difficulty or expense".

The statutory definition of "readily achievable" calls for a balancing test between the cost of the proposed "fix" and the wherewithal of the business and/or owners of the business. Thus, what might be "readily achievable" for a sophisticated and financially capable corporation might not be readily achievable for a small or local business.

There are exceptions to this title; many private clubs and religious organizations may not be bound by Title III. With regard to historic properties (those properties that are listed or that are eligible for listing in the National Register of Historic Places, or properties designated as historic under state or local law), those facilities must still comply with the provisions of Title III of the ADA to the "maximum extent feasible" but if following the usual standards would "threaten to destroy the historic significance of a feature of the building" then alternative standards may be used.

Under 2010 revisions of Department of Justice regulations, newly constructed or altered swimming pools, wading pools, and spas must have an accessible means of entrance and exit to pools for disabled people. However, the requirement is conditioned on whether providing access through a fixed lift is "readily achievable". Other requirements exist, based on pool size, include providing a certain number of accessible means of entry and exit, which are outlined in Section 242 of the standards. However, businesses are free to consider the differences in application of the rules depending on whether the pool is new or altered, or whether the swimming pool was in existence before the effective date of the new rule. Full compliance may not be required for existing facilities; Section 242 and 1009 of the 2010 Standards outline such exceptions.

The ADA provides explicit coverage for service animals. Guidelines have been developed not only to protect persons with disabilities, but also to indemnify businesses from damages related to granting access to service animals on their premises. Businesses are allowed to ask if the animal is a service animal and ask what tasks it is trained to perform, but they are not allowed to ask the service animal to perform the task nor ask for a special ID of the animal. They cannot ask what the person's disabilities are. A person with a disability cannot be removed from the premises unless either of two things happen: the animal is out of control and its owner cannot get it under control (e.g. a dog barking uncontrollably in a restaurant), or the animal is a direct threat to people's health and safety. Allergies and fear of animals would not be considered a threat to people's health and safety, so it would not be a valid reason to deny access to people with service animals. Businesses that prepare or serve food must allow service animals and their owners on the premises even if state or local health laws otherwise prohibit animals on the premises. In this case, businesses that prepare or serve food are not required to provide care or food for service animals, nor do they have to provide a designated area for the service animal to relieve itself. Lastly, people that require service dogs cannot be charged an extra fee for their service dog or be treated unfairly, for example, being isolated from people at a restaurant. People with disabilities cannot be treated as "less than" other customers. However, if a business normally charges for damages caused by the person to property, the customer with a disability will be charged for his/her service animal's damages to the property.

Title IV of the ADA amended the landmark Communications Act of 1934 primarily by adding section . This section requires that all telecommunications companies in the U.S. take steps to ensure functionally equivalent services for consumers with disabilities, notably those who are deaf or hard of hearing and those with speech impairments. When Title IV took effect in the early 1990s, it led to the installation of public teletypewriter (TTY) machines and other TDD (telecommunications devices for the deaf). Title IV also led to the creation, in all 50 states and the District of Columbia, of what were then called dual-party relay services and now are known as Telecommunications Relay Services (TRS), such as STS relay. Today, many TRS-mediated calls are made over the Internet by consumers who use broadband connections. Some are Video Relay Service (VRS) calls, while others are text calls. In either variation, communication assistants translate between the signed or typed words of a consumer and the spoken words of others. In 2006, according to the Federal Communications Commission (FCC), VRS calls averaged two million minutes a month.

Title V includes technical provisions. It discusses, for example, the fact that nothing in the ADA amends, overrides or cancels anything in Section 504. Additionally, Title V includes an anti-retaliation or coercion provision. The "Technical Assistance Manual" for the ADA explains this provision: 
"III-3.6000 Retaliation or coercion. Individuals who exercise their rights under the ADA, or assist others in exercising their rights, are protected from retaliation. The prohibition against retaliation or coercion applies broadly to any individual or entity that seeks to prevent an individual from exercising his or her rights or to retaliate against him or her for having exercised those rights ... Any form of retaliation or coercion, including threats, intimidation, or interference, is prohibited if it is intended to interfere."

The ADA has roots in Section 504 of the Rehabilitation Act of 1973.

The idea of federal legislation enhancing and extending civil rights legislation to millions of Americans with disabilities gained bipartisan support in late 1988 and early 1989. In early 1989 both Congress and the newly-inaugurated Bush White House worked separately, then jointly, to write legislation capable of expanding civil rights without imposing undue harm or costs on those already in compliance with existing rules and laws.

Over the years, key activists and advocates played an important role in lobbying members of the U.S. Congress to develop and pass the ADA, including Justin Whitlock Dart, Jr., Patrisha Wright and others.

Ms. Wright is known as "the General" for her work in coordinating the campaign to enact the ADA. She is widely considered the main force behind the campaign lobbying for the ADA.

About the importance of making employment opportunities inclusive, Shirley Davis, director of global diversity and inclusion at the Society for Human Resource Management, said: "People with disabilities represent a critical talent pool that is underserved and underutilized".

The debate over the Americans with Disabilities Act led some religious groups to take opposite positions. The Association of Christian Schools International, opposed the ADA in its original form. primarily because the ADA labeled religious institutions "public accommodations", and thus would have required churches to make costly structural changes to ensure access for all. The cost argument advanced by ACSI and others prevailed in keeping religious institutions from being labeled as "public accommodations".

Church groups such as the National Association of Evangelicals testified against the ADA's Title I employment provisions on grounds of religious liberty. The NAE believed the regulation of the internal employment of churches was "... an improper intrusion [of] the federal government."

Many members of the business community opposed the Americans with Disabilities Act. Testifying before Congress, Greyhound Bus Lines stated that the act had the potential to "deprive millions of people of affordable intercity public transportation and thousands of rural communities of their only link to the outside world." The US Chamber of Commerce argued that the costs of the ADA would be "enormous" and have "a disastrous impact on many small businesses struggling to survive." The National Federation of Independent Businesses, an organization that lobbies for small businesses, called the ADA "a disaster for small business." Pro-business conservative commentators joined in opposition, writing that the Americans with Disabilities Act was "an expensive headache to millions" that would not necessarily improve the lives of people with disabilities.

Shortly before the act was passed, disability rights activists with physical disabilities coalesced in front of the Capitol Building, shed their crutches, wheelchairs, powerchairs and other assistive devices, and immediately proceeded to crawl and pull their bodies up all 100 of the Capitol's front steps, without warning. As the activists did so, many of them chanted "ADA now", and "Vote, Now". Some activists who remained at the bottom of the steps held signs and yelled words of encouragement at the "Capitol Crawlers". Jennifer Keelan, a second grader with cerebral palsy, was videotaped as she pulled herself up the steps, using mostly her hands and arms, saying "I'll take all night if I have to." This direct action is reported to have "inconvenienced" several senators and to have pushed them to approve the act. While there are those who do not attribute much overall importance to this action, the "Capitol Crawl" of 1990 is seen by some present-day disability activists in the United States as a central act for encouraging the ADA into law.

Senator Tom Harkin (D-IA) authored what became the final bill and was its chief sponsor in the Senate. Harkin delivered part of his introduction speech in sign language, saying it was so his deaf brother could understand.

On signing the measure, George H. W. Bush said: 

The ADA defines a covered disability as a physical or mental impairment that substantially limits one or more major life activities, a history of having such an impairment, or being regarded as having such an impairment. The Equal Employment Opportunity Commission (EEOC) was charged with interpreting the 1990 law with regard to discrimination in employment. The EEOC developed regulations limiting an individual's impairment to one that "severely or significantly restricts" a major life activity. The ADAAA directed the EEOC to amend its regulations and replace "severely or significantly" with "substantially limits", a more lenient standard.

On September 25, 2008, President George W. Bush signed the ADA Amendments Act of 2008 (ADAAA) into law. The amendment broadened the definition of "disability", thereby extending the ADA's protections to a greater number of people. The ADAAA also added to the ADA examples of "major life activities" including, but not limited to, "caring for oneself, performing manual tasks, seeing, hearing, eating, sleeping, walking, standing, lifting, bending, speaking, breathing, learning, reading, concentrating, thinking, communicating, and working" as well as the operation of several specified "major bodily functions". The act overturned a 1999 US Supreme Court case that held that an employee was not disabled if the impairment could be corrected by mitigating measures; it specifically provides that such impairment must be determined without considering such ameliorative measures. It also overturned the court restriction that an impairment which substantially limits one major life activity must also limit others to be considered a disability.
In 2008, the United States House Committee on Education and Labor stated that the amendment "makes it absolutely clear that the ADA is intended to provide broad coverage to protect anyone who faces discrimination on the basis of disability." Thus the ADAAA led to broader coverage of impaired employees.

 the ADA had improved access to public services, the built environment (e.g., crosswalks with curb cuts and accessible pedestrian signals), understanding of the abilities of people with disabilities, established a right to equal access to public services and has demonstrated the contributions which people with disabilities can make to the economy. Disparities have remained in employment, earned income, Internet access, transportation, housing, and educational attainment and the disabled remain at a disadvantage with respect to health and health care.

The ADA has been criticized on the grounds that it decreases the employment rate for people with disabilities and raises the cost of doing business for employers, in large part due to the additional legal risks, which employers avoid by quietly avoiding hiring people with disabilities. Some researchers believe that the law has been ineffectual. Between 1991 (after the enactment of the ADA) and 1995, the employment rate of men with disabilities dropped by 7.8% regardless of age, educational level, or type of disability, with the most affected being young, less-educated and mentally disabled men. Despite the many criticisms, a causal link between the ADA and declining disabled employment over much of the 1990s has not been definitively identified.

In 2001, for men of all working ages and women under 40, Current Population Survey data showed a sharp drop in the employment of disabled workers, leading at least two economists to attribute the cause to the Act. By contrast, a study in 2003 found that while the Act may have led to short term reactions by employers, in the long term, there were either positive or neutral consequences for wages and employment. In 2005 the rate of employment among disabled people increased to 45% of the population of disabled people.

Since enforcement of the act began in July 1992, it has quickly become a major component of employment law. The ADA allows private plaintiffs to receive only injunctive relief (a court order requiring the public accommodation to remedy violations of the accessibility regulations) and attorneys' fees, and does not provide monetary rewards to private plaintiffs who sue non-compliant businesses. Unless a state law, such as the California Unruh Civil Rights Act, provides for monetary damages to private plaintiffs, persons with disabilities do not obtain direct financial benefits from suing businesses that violate the ADA.

The attorneys' fees provision of Title III does provide incentive for lawyers to specialize and engage in serial ADA litigation, but a disabled plaintiff does not obtain financial reward from attorneys' fees unless they act as their own attorney, or as mentioned above, a disabled plaintiff resides in a state that provides for minimum compensation and court fees in lawsuits. Moreover, there may be a benefit to these "private attorneys general" who identify and compel the correction of illegal conditions: they may increase the number of public accommodations accessible to persons with disabilities. "Civil rights law depends heavily on private enforcement. Moreover, the inclusion of penalties and damages is the driving force that facilitates voluntary compliance with the ADA." Courts have noted: 
As a result, most ADA suits are brought by a small number of private plaintiffs who view themselves as champions of the disabled. For the ADA to yield its promise of equal access for the disabled, it may indeed be necessary and desirable for committed individuals to bring serial litigation advancing the time when public accommodations will be compliant with the ADA."

However, in states that have enacted laws that allow private individuals to win monetary awards from non-compliant businesses (as of 2008, these include California, Florida, Hawaii, and Illinois), "professional plaintiffs" are typically found. At least one of these plaintiffs in California has been barred by courts from filing lawsuits unless he receives prior court permission. Through the end of fiscal year 1998, 86% of the 106,988 ADA charges filed with and resolved by the Equal Employment Opportunity Commission, were either dropped or investigated and dismissed by EEOC but not without imposing opportunity costs and legal fees on employers.

There have been some notable cases regarding the ADA. For example, two major hotel room marketers (Expedia.com and Hotels.com) with their business presence on the Internet were sued because its customers with disabilities could not reserve hotel rooms, through their websites without substantial extra efforts that persons without disabilities were not required to perform. These represent a major potential expansion of the ADA in that this, and other similar suits (known as "bricks vs. clicks"), seeks to expand the ADA's authority to cyberspace, where entities may not have actual physical facilities that are required to comply.

"National Federation of the Blind v. Target Corporation" was a case where a major retailer, Target Corp., was sued because their web designers failed to design its website to enable persons with low or no vision to use it.

"Board of Trustees of the University of Alabama v. Garrett" was a United States Supreme Court case about Congress's enforcement powers under the Fourteenth Amendment to the Constitution. It decided that Title I of the Americans with Disabilities Act was unconstitutional insofar as it allowed private citizens to sue states for money damages.

"Barden v. The City of Sacramento", filed in March 1999, claimed that the City of Sacramento failed to comply with the ADA when, while making public street improvements, it did not bring its sidewalks into compliance with the ADA. Certain issues were resolved in Federal Court. One issue, whether sidewalks were covered by the ADA, was appealed to the 9th Circuit Court of Appeals, which ruled that sidewalks were a "program" under ADA and must be made accessible to persons with disabilities. The ruling was later appealed to the U.S. Supreme Court, which refused to hear the case, letting stand the ruling of the 9th Circuit Court.

"Bates v. UPS" (begun in 1999) was the first equal opportunity employment class action brought on behalf of Deaf and Hard of Hearing (d/Deaf/HoH) workers throughout the country concerning workplace discrimination. It established legal precedence for d/Deaf/HoH Employees and Customers to be fully covered under the ADA. Key findings included
The outcome was that UPS agreed to pay a $5.8 million award and agreed to a comprehensive accommodations program that was implemented in their facilities throughout the country.

"Spector v. Norwegian Cruise Line Ltd." was a case that was decided by the United States Supreme Court in 2005. The defendant argued that as a vessel flying the flag of a foreign nation it was exempt from the requirements of the ADA. This argument was accepted by a federal court in Florida and, subsequently, the Fifth Circuit Court of Appeals. However, the U.S. Supreme Court reversed the ruling of the lower courts on the basis that Norwegian Cruise Lines was a business headquartered in the United States whose clients were predominantly Americans and, more importantly, operated out of port facilities throughout the United States.

"Olmstead v. L.C." was a case before the United States Supreme Court in 1999. The two plaintiffs L.C. and E.W. were institutionalized in Georgia for diagnosed mental retardation and schizophrenia. Clinical assessments by the state determined that the plaintiffs could be appropriately treated in a community setting rather than the state institution. The plaintiffs sued the state of Georgia and the institution for being inappropriately treated and housed in the institutional setting rather than being treated in one of the state's community based treatment facilities.

The Supreme Court decided under Title II of the ADA that mental illness is a form of disability and therefore covered under the ADA, and that unjustified institutional isolation of a person with a disability is a form of discrimination because it "...perpetuates unwarranted assumptions that persons so isolated are incapable or unworthy of participating in community life." The court added, "Confinement in an institution severely diminishes the everyday life activities of individuals, including family relations, social contacts, work options, economic independence, educational advancement, and cultural enrichment."

Therefore, under Title II no person with a disability can be unjustly excluded from participation in or be denied the benefits of services, programs or activities of any public entity.

This was a case filed before The United States District Court for the Eastern District of Michigan Southern Division on behalf of the Michigan Paralyzed Veterans of America against University of Michigan – Michigan Stadium claiming that Michigan Stadium violated the Americans with Disabilities Act in its $226-million renovation by failing to add enough seats for disabled fans or accommodate the needs for disabled restrooms, concessions and parking. Additionally, the distribution of the accessible seating was at issue, with nearly all the seats being provided in the end-zone areas. The U.S. Department of Justice assisted in the suit filed by attorney Richard Bernstein of The Law Offices of Sam Bernstein in Farmington Hills, Michigan, which was settled in March 2008. The settlement required the stadium to add 329 wheelchair seats throughout the stadium by 2010, and an additional 135 accessible seats in clubhouses to go along with the existing 88 wheelchair seats. This case was significant because it set a precedent for the uniform distribution of accessible seating and gave the DOJ the opportunity to clarify previously unclear rules. The agreement now is a blueprint for all stadiums and other public facilities regarding accessibility.

One of the first major ADA lawsuits, "Paralyzed Veterans of America (or "PVA") v. Ellerbe Becket Architects and Engineers" (1996) was focused on the wheelchair accessibility of a stadium project that was still in the design phase, MCI Center (now known as Capital One Arena) in Washington, D.C. Previous to this case, which was filed only five years after the ADA was passed, the DOJ was unable or unwilling to provide clarification on the distribution requirements for accessible wheelchair locations in large assembly spaces. While Section 4.33.3 of ADAAG makes reference to lines of sight, no specific reference is made to seeing over standing patrons. The MCI Center, designed by Ellerbe Becket Architects & Engineers, was designed with too few wheelchair and companion seats, and the ones that were included did not provide sight lines that would enable the wheelchair user to view the playing area while the spectators in front of them were standing. This case and another related case established precedent on seat distribution and sight lines issues for ADA enforcement that continues to present day.

"Toyota Motor Manufacturing, Kentucky, Inc. v. Williams", was a case in which the Supreme Court interpreted the meaning of the phrase "substantially impairs" as used in the Americans with Disabilities Act. It reversed a Sixth Court of Appeals decision to grant a partial summary judgment in favor of the respondent, Ella Williams, that qualified her inability to perform manual job-related tasks as a disability. The Court held that the "major life activity" definition in evaluating the performance of manual tasks focuses the inquiry on whether Williams was unable to perform a range of tasks central to most people in carrying out the activities of daily living. The issue is not whether Williams was unable to perform her specific job tasks. Therefore, the determination of whether an impairment rises to the level of a disability is not limited to activities in the workplace solely, but rather to manual tasks in life in general. When the Supreme Court applied this standard, it found that the Court of Appeals had incorrectly determined the presence of a disability because it relied solely on her inability to perform specific manual work tasks, which was insufficient in proving the presence of a disability. The Court of Appeals should have taken into account the evidence presented that Williams retained the ability to do personal tasks and household chores, such activities being the nature of tasks most people do in their daily lives, and placed too much emphasis on her job disability. Since the evidence showed that Williams was performing normal daily tasks, it ruled that the Court of Appeals erred when it found that Williams was disabled. This ruling is now, however, no longer good law—it was invalidated by the ADAAA. In fact, Congress explicitly cited Toyota v. Williams in the text of the ADAAA itself as one of its driving influences for passing the ADAAA.

Decided by the US Supreme Court in 2002, this case held that even requests for accommodation that might seem reasonable on their face, e.g., a transfer to a different position, can be rendered unreasonable because it would require a violation of the company's seniority system. While the court held that, in general, a violation of a seniority system renders an otherwise reasonable accommodation unreasonable, a plaintiff can present evidence that, despite the seniority system, the accommodation is reasonable in the specific case at hand, e.g., the plaintiff could offer evidence that the seniority system is so often disregarded that another exception wouldn't make a difference.

Importantly, the court held that the defendant need not provide proof that this particular application of the seniority system should prevail, and that, once the defendant showed that the accommodation violated the seniority system, it fell to Barnett to show it was nevertheless reasonable.

In this case, Barnett was a US Airways employee who injured his back, rendering him physically unable to perform his cargo-handling job. Invoking seniority, he transferred to a less-demanding mailroom job, but this position later became open to seniority-based bidding and was bid on by more senior employees. Barnett requested the accommodation of being allowed to stay on in the less-demanding mailroom job. US Airways denied his request, and he lost his job.

The Supreme Court decision invalidated both the approach of the district court, which found that the mere presence and importance of the seniority system was enough to warrant a summary judgment in favor of US Airways, as well as the circuit court's approach that interpreted 'reasonable accommodation' as 'effective accommodation.'

"Access Now v. Southwest Airlines" was a case where the District Court decided that the website of Southwest Airlines was not in violation of the Americans with Disabilities Act, because the ADA is concerned with things with a physical existence and thus cannot be applied to cyberspace. Judge Patricia A. Seitz found that the "virtual ticket counter" of the website was a virtual construct, and hence not a "public place of accommodation." As such, "To expand the ADA to cover 'virtual' spaces would be to create new rights without well-defined standards."

"Ouellette v. Viacom International Inc." followed in Access Now's footsteps by holding that a mere online presence does not subject a website to the ADA guidelines. Thus Myspace and YouTube were not liable for a dyslexic man's inability to navigate the site regardless of how impressive the "online theater" is.

"Authors Guild v. HathiTrust" was a case in which the District Court decided that the HathiTrust digital library was a transformative, fair use of copyrighted works, making a large number of written text available to those with print disability.

"Zamora-Quezada v. HealthTexas Medical Group" (begun in 1998) was the first time this act was used against HMOs when a novel lawsuit was filed by Texas attorney Robert Provan against five HMOs for their practice of revoking the contracts of doctors treating disabled patients.

"Campbell v. General Dynamics Government Systems Corp." (2005) concerned the enforceability of a mandatory arbitration agreement, contained in a dispute resolution policy linked to an e-mailed company-wide announcement, insofar as it applies to employment discrimination claims brought under the Americans with Disabilities Act.





</doc>
<doc id="1344" url="https://en.wikipedia.org/wiki?curid=1344" title="Apple I">
Apple I

Apple Computer 1, also known later as the Apple I, or Apple-1, is a desktop computer released by the Apple Computer Company (now Apple Inc.) in 1976. It was designed and hand-built by Steve Wozniak. The idea of selling the computer came from Wozniak's friend Steve Jobs. The Apple I was Apple's first product, and to finance its creation, Jobs sold his only motorized means of transportation, a VW Microbus, for a few hundred dollars, and Steve Wozniak sold his HP-65 calculator for $500; however, Wozniak said that Jobs planned to use his bicycle if necessary. It was demonstrated in July 1976 at the Homebrew Computer Club in Palo Alto, California.

Production was discontinued on September 30, 1977, after the June 10, 1977 introduction of its successor, the Apple II, which "Byte" magazine referred to as part of the "1977 Trinity" of personal computing (along with the PET 2001 and the TRS-80).

On March 5, 1975, Steve Wozniak attended the first meeting of the Homebrew Computer Club in Gordon French's garage. He was so inspired that he immediately set to work on what would become the Apple I computer. After building it for himself and showing it at the Club, he and Steve Jobs gave out schematics (technical designs) for the computer to interested club members and even helped some of them build and test out copies. Then, Steve Jobs suggested that they design and sell a single etched and silkscreened circuit board—just the bare board, with no electronic parts—that people could use to build the computers. Wozniak calculated that having the board design laid out would cost $1,000 and manufacturing would cost another $20 per board; he hoped to recoup his costs if 50 people bought the boards for $40 each. To fund this small venture—their first company—Jobs sold his van and Wozniak sold his HP-65 calculator. Very soon after, Steve Jobs arranged to sell "something like 50" completely built computers to the Byte Shop (a computer store in Mountain View, California) at $500 each. To fulfill the $25,000 order, they obtained $20,000 in parts at 30 days net and delivered the finished product in 10 days.

The Apple I went on sale in July 1976 at a price of , because Wozniak "liked repeating digits" and because of a one-third markup on the $500 wholesale price.

The first unit produced was used in a high school math class, and donated to Liza Loop's public-access computer center. About 200 units were produced, and all but 25 were sold within nine or ten months.

The Apple I's built-in computer terminal circuitry was distinctive. All one needed was a keyboard and a television set. Competing machines such as the Altair 8800 generally were programmed with front-mounted toggle switches and used indicator lights (red LEDs, most commonly) for output, and had to be extended with separate hardware to allow connection to a computer terminal or a teletypewriter machine. This made the Apple I an innovative machine for its day. In April 1977, the price was dropped to $475. It continued to be sold through August 1977, despite the introduction of the Apple II in April 1977, which began shipping in June of that year. In October 1977, the Apple I was officially discontinued and removed from Apple's price list. As Wozniak was the only person who could answer most customer support questions about the computer, the company offered Apple I owners discounts and trade-ins for Apple IIs to persuade them to return their computers. These recovered boards were then destroyed by Apple, contributing to their rarity today.

As of 2013, sixty-three Apple I computers have been confirmed to exist. Only six have been verified to be in working condition.

The Apple-1 Registry lists every known Apple I computer. This registry serves an additional purpose by including a list of all auctions since 2000.


Both Steve Jobs and Steve Wozniak have stated that Apple did not assign serial numbers to the Apple l. Several boards have been found with numbered stickers affixed to them, which appear to be inspection stickers from the PCB manufacturer/assembler. A batch of boards is known to have numbers hand-written in black permanent marker on the back; these usually appear as "01-00##" and anecdotal evidence suggests they are inventory control numbers added by the Byte Shop to the batch Apple sold them. These Byte Shop numbers have often erroneously been described as serial numbers by auction houses and in related press coverage.


Several Apple I clones and replicas have been released in recent years. These are all created by hobbyists and marketed to the hobbyist/collector community. Availability is usually limited to small runs in response to demand.








</doc>
<doc id="1346" url="https://en.wikipedia.org/wiki?curid=1346" title="Apatosaurus">
Apatosaurus

Apatosaurus (; meaning "deceptive lizard") is a genus of herbivorous sauropod dinosaur that lived in North America during the Late Jurassic period. Othniel Charles Marsh described and named the first-known species, A. ajax, in 1877, and a second species, A. louisae, was discovered and named by William H. Holland in 1916. "Apatosaurus" lived about 152 to 151 million years ago (mya), during the late Kimmeridgian to early Tithonian age, and are now known from fossils in the Morrison Formation of modern-day Colorado, Oklahoma, New Mexico, Wyoming, and Utah in the United States. "Apatosaurus" had an average length of , and an average mass of . A few specimens indicate a maximum length of 11–30% greater than average and a mass of .

The cervical vertebrae of "Apatosaurus" are less elongated and more heavily constructed than those of "Diplodocus", a diplodocid like "Apatosaurus", and the bones of the leg are much stockier despite being longer, implying that "Apatosaurus" was a more robust animal. The tail was held above the ground during normal locomotion. "Apatosaurus" had a single claw on each forelimb and three on each hindlimb. The "Apatosaurus" skull, long thought to be similar to "Camarasaurus", is much more similar to that of "Diplodocus". "Apatosaurus" was a generalized browser that likely held its head elevated. To lighten its vertebrae, "Apatosaurus" had air sacs that made the bones internally full of holes. Like that of other diplodocids, its tail may have been used as a whip to create loud noises.

The skull of "Apatosaurus" was confused with that of "Camarasaurus" and "Brachiosaurus" until 1909, when the holotype of "A. louisae" was found, and a complete skull just a few meters away from the front of the neck. Henry Fairfield Osborn disagreed with this association, and went on to mount a skeleton of "Apatosaurus" with a "Camarasaurus" skull cast. Until 1970, "Apatosaurus" skeletons were mounted with speculative skull casts, when McIntosh showed that more robust skulls assigned to "Diplodocus" were more likely from "Apatosaurus".

"Apatosaurus" is a genus in the family Diplodocidae. It is one of the more basal genera, with only "Amphicoelias" and possibly a new, unnamed genus more primitive. While the subfamily Apatosaurinae was named in 1929, the group was not used validly until an extensive 2015 study. Only "Brontosaurus" is also in the subfamily, with the other genera being considered synonyms or reclassified as diplodocines. "Brontosaurus" has long been considered a junior synonym of "Apatosaurus"; its only species was reclassified as "A.excelsus" in 1903. A 2015 study concluded that "Brontosaurus" is a valid genus of sauropod distinct from "Apatosaurus", but not all paleontologists agree with this division. As it existed in North America during the late Jurassic, "Apatosaurus" would have lived alongside dinosaurs such as "Allosaurus", "Camarasaurus", "Diplodocus", and "Stegosaurus".

"Apatosaurus" was a large, long-necked, quadrupedal animal with a long, whip-like tail. Its forelimbs were slightly shorter than its hindlimbs. Most size estimates are based on specimen CM3018, the type specimen of "A.louisae". In 1936 this was measured to be , by measuring the vertebral column. Current estimates are similar, finding that the individual was long and had a mass of . A 2015 study that estimated the mass of volumetric models of "Dreadnoughtus", "Apatosaurus", and "Giraffatitan" estimates CM3018 at , similar in mass to "Dreadnoughtus". Past estimates have put the creature's mass as high as . Some specimens of "A.ajax" (such as OMNH1670) represent individuals 1130% longer, suggesting masses twice that of CM3018 or , potentially rivalling the largest titanosaurs.
The skull is small in relation to the size of the animal. The jaws are lined with spatulate (chisel-like) teeth suited to an herbivorous diet. The snout of "Apatosaurus" and similar diplodocoids is squared, with only "Nigersaurus" having a squarer skull. The braincase of "Apatosaurus" is well preserved in specimen BYU17096, which also preserved much of the skeleton. A phylogenetic analysis found that the braincase had a morphology similar to those of other diplodocoids. Some skulls of "Apatosaurus" have been found still in articulation with their teeth. Those teeth that have the enamel surface exposed do not show any scratches on the surface; instead, they display a sugary texture and little wear.

Like those of other sauropods, the neck vertebrae are deeply bifurcated; they carried neural spines with a large trough in the middle, resulting in a wide, deep neck. The vertebral formula for the holotype of "A.louisae" is 15cervicals, 10dorsals, 5sacrals, and 82caudals. The caudal vertebra number may vary, even within species. The cervical vertebrae of "Apatosaurus" and "Brontosaurus" are stouter and more robust than those of other diplodocids and were found to be most similar to "Camarasaurus" by Charles Whitney Gilmore. In addition, they support cervical ribs that extend farther towards the ground than in diplodocines, and have vertebrae and ribs that are narrower towards the top of the neck, making the neck nearly triangular in cross-section. In "Apatosaurus louisae", the atlas-axis complex of the first cervicals is nearly fused. The dorsal ribs are not fused or tightly attached to their vertebrae and are instead loosely articulated. "Apatosaurus" has ten dorsal ribs on either side of the body. The large neck was filled with an extensive system of weight-saving air sacs. "Apatosaurus", like its close relative "Supersaurus", has tall neural spines, which make up more than half the height of the individual bones of its vertebrae. The shape of the tail is unusual for a diplodocid; it is comparatively slender because of the rapidly decreasing height of the vertebral spines with increasing distance from the hips. "Apatosaurus" also had very long ribs compared to most other diplodocids, giving it an unusually deep chest. As in other diplodocids, the tail transformed into a whip-like structure towards the end.
The limb bones are also very robust. Within Apatosaurinae, the scapula of "Apatosaurus louisae" is intermediate in morphology between those of "A.ajax" and "Brontosaurus excelsus". The arm bones are stout, so the humerus of "Apatosaurus" resembles that of "Camarasaurus", as well as "Brontosaurus". However, the humeri of "Brontosaurus" and "A.ajax" are more similar to each other than they are to "A.louisae". In 1936 Charles Gilmore noted that previous reconstructions of "Apatosaurus" forelimbs erroneously proposed that the radius and ulna could cross; in life they would have remained parallel. "Apatosaurus" had a single large claw on each forelimb, a feature shared by all sauropods more derived than "Shunosaurus". The first three toes had claws on each hindlimb. The phalangeal formula is 2-1-1-1-1, meaning the innermost finger (phalanx) on the forelimb has two bones and the next has one. The single manual claw bone (ungual) is slightly curved and squarely truncated on the anterior end. The pelvic girdle includes the robust ilia, and the fused (co-ossified) pubes and ischia. The femora of "Apatosaurus" are very stout and represent some of the most robust femora of any member of Sauropoda. The tibia and fibula bones are different from the slender bones of "Diplodocus" but are nearly indistinguishable from those of "Camarasaurus". The fibula is longer and slenderer than the tibia. The foot of "Apatosaurus" has three claws on the innermost digits; the digit formula is 3-4-5-3-2. The first metatarsal is the stoutest, a feature shared among diplodocids.

The name "Apatosaurus ajax" was coined in 1877 by Othniel Charles Marsh, Professor of Paleontology at Yale University, based on a nearly complete skeleton (holotype, YPM1860) discovered in the eastern foothills of the Rocky Mountains in Gunnison County, Colorado. The composite term "Apatosaurus" comes from the Greek words "apatē" ()/"apatēlos" () meaning "deception"/"deceptive", and "sauros" () meaning "lizard"; thus, "deceptive lizard". Marsh gave it this name based on the chevron bones, which are dissimilar to those of other dinosaurs; instead, the chevron bones of "Apatosaurus" showed similarities with those of mosasaurs. During excavation and transportation, the bones of the holotype skeleton were mixed with those of another "Apatosaurus" individual originally described as "Atlantosaurus immanis"; as a consequence, some elements cannot be ascribed to either specimen with confidence. Marsh distinguished the new genus "Apatosaurus" from "Atlantosaurus" on the basis of the number of sacral vertebrae, with "Apatosaurus" possessing three and "Atlantosaurus" four. Two years later, Marsh announced the discovery of a larger and more complete specimen at Como Bluff, Wyoming. He gave this specimen a new name based on the conventions of his age and the relatively sparse fossil record available at that time. It was later recognised that the features he had used to distinguish genera and species were in fact more widespread among sauropods. He named the new species "Brontosaurus excelsus". All specimens currently considered "Apatosaurus" were from the Morrison Formation, the location of the excavations of Marsh and his rival Edward Drinker Cope.
Another specimen, in the American Museum of Natural History under specimen number460, which is occasionally assigned to "Apatosaurus", is considered nearly complete; only the head, feet, and sections of the tail are missing, and it was the first sauropod skeleton mounted. The specimen was found north of Medicine Bow, Wyoming, in 1898 by Walter Granger, and took the entire summer to extract. To complete the mount, sauropod feet that were discovered at the same quarry and a tail fashioned to appear as Marsh believed it shouldbut which had too few vertebraewere added. In addition, a sculpted model of what the museum thought the skull of this massive creature might look like was made. This was not a delicate skull like that of "Diplodocus"which was later found to be more accuratebut was based on "the biggest, thickest, strongest skull bones, lower jaws and tooth crowns from three different quarries". These skulls were likely those of "Camarasaurus", the only other sauropod for which good skull material was known at the time. The mount construction was overseen by Adam Hermann, who failed to find "Apatosaurus" skulls. Hermann was forced to sculpt a stand-in skull by hand. Osborn said in a publication that the skull was "largely conjectural and based on that of "Morosaurus"" (now "Camarasaurus").

In 1903 Elmer Riggs published a study that described a well-preserved skeleton of a diplodocid from the Grand River Valley near Fruita, Colorado, Field Museum of Natural History specimen P25112. Riggs thought that the deposits were similar in age to those of the Como Bluff in Wyoming from which Marsh had described "Brontosaurus". Most of the skeleton was found, and after comparison with both "Brontosaurus" and "Apatosaurus ajax", Riggs realized that the holotype of "A.ajax" was immature, and thus the features distinguishing the genera were not valid. Since "Apatosaurus" was the earlier name, "Brontosaurus" should be considered a junior synonym of "Apatosaurus". Because of this, Riggs recombined "Brontosaurus excelsus" as "Apatosaurus excelsus". Based on comparisons with other species proposed to belong to "Apatosaurus", Riggs also determined that the Field Columbian Museum specimen was likely most similar to "A.excelsus".

Despite Riggs' publication, Henry Fairfield Osborn, who was a strong opponent of Marsh and his taxa, labeled the "Apatosaurus" mount of the American Museum of Natural History "Brontosaurus". Because of this decision the name "Brontosaurus" was commonly used outside of scientific literature for what Riggs considered "Apatosaurus", and the museum's popularity meant that "Brontosaurus" became one of the best known dinosaurs, even though it was invalid throughout nearly all of the 20th and early 21st centuries.

It was not until 1909 that an "Apatosaurus" skull was found during the first expedition, led by Earl Douglass, to what would become known as the Carnegie Quarry at Dinosaur National Monument. The skull was found a short distance from a skeleton (specimen CM3018) identified as the new species "Apatosaurus louisae", named after Louise Carnegie, wife of Andrew Carnegie, who funded field research to find complete dinosaur skeletons in the American West. The skull was designated CM11162; it was very similar to the skull of "Diplodocus". Another smaller skeleton of "A.louisae" was found nearby CM11162 and CM3018. The skull was accepted as belonging to the "Apatosaurus" specimen by Douglass and Carnegie Museum director William H. Holland, although other scientistsmost notably Osbornrejected this identification. Holland defended his view in 1914 in an address to the Paleontological Society of America, yet he left the Carnegie Museum mount headless. While some thought Holland was attempting to avoid conflict with Osborn, others suspected Holland was waiting until an articulated skull and neck were found to confirm the association of the skull and skeleton. After Holland's death in 1934, museum staff placed a cast of a "Camarasaurus" skull on the mount.

While most other museums were using cast or sculpted "Camarasaurus" skulls on "Apatosaurus" mounts, the Yale Peabody Museum decided to sculpt a skull based on the lower jaw of a "Camarasaurus", with the cranium based on Marsh's 1891 illustration of the skull. The skull also included forward-pointing nasalssomething different to any dinosaurand fenestrae differing from both the drawing and other skulls.

No "Apatosaurus" skull was mentioned in literature until the 1970s when John Stanton McIntosh and David Berman redescribed the skulls of "Diplodocus" and "Apatosaurus". They found that though he never published his opinion, Holland was almost certainly correct, that "Apatosaurus" had a "Diplodocus"-like skull. According to them, many skulls long thought to pertain to "Diplodocus" might instead be those of "Apatosaurus". They reassigned multiple skulls to "Apatosaurus" based on associated and closely associated vertebrae. Even though they supported Holland, it was noted that "Apatosaurus" might have possessed a "Camarasaurus"-like skull, based on a disarticulated "Camarasaurus"-like tooth found at the precise site where an "Apatosaurus" specimen was found years before. On October20, 1979, after the publications by McIntosh and Berman, the first true skull of "Apatosaurus" was mounted on a skeleton in a museum, that of the Carnegie. In 1998 it was suggested that the Felch Quarry skull that Marsh had included in his 1896 skeletal restoration instead belonged to "Brachiosaurus". In 2011 the first specimen of "Apatosaurus" where a skull was found articulated with its cervical vertebrae was described. This specimen, CMCVP7180, was found to differ in both skull and neck features from "A.louisae", but shared many features of the cervical vertebrae with "A.ajax". Another well-preserved skull is Brigham Young University specimen 17096, a well-preserved skull and skeleton, with a preserved braincase. The specimen was found in Cactus Park Quarry in western Colorado.

Almost all modern paleontologists agreed with Riggs that the two dinosaurs should be classified together in a single genus. According to the rules of the ICZN (which governs the scientific names of animals), the name "Apatosaurus", having been published first, has priority as the official name; "Brontosaurus" was considered a junior synonym and was therefore long discarded from formal use. Despite this, at least one paleontologistRobert T. Bakkerargued in the 1990s that "A.ajax" and "A.excelsus" were in fact sufficiently distinct for the latter to merit a separate genus.

In 2015 Emanuel Tschopp, Octávio Mateus, and Roger Benson released a paper on diplodocoid systematics, and proposed that genera could be diagnosed by thirteen differing characters, and species separated based on six. The minimum number for generic separation was chosen based on the fact that "A.ajax" and "A.louisae" differ in twelve characters, and "Diplodocus carnegiei" and "D.hallorum" differ in eleven characters. Thus, thirteen characters were chosen to validate the separation of genera. The six differing features for specific separation were chosen by counting the number of differing features in separate specimens generally agreed to represent one species, with only one differing character in "D.carnegiei" and "A.louisae", but five differing features in "B.excelsus". Therefore, Tschopp etal. argued that "Apatosaurus excelsus", originally classified as "Brontosaurus excelsus", had enough morphological differences from other species of "Apatosaurus" that it warranted being reclassified as a separate genus again. The conclusion was based on a comparison of 477 morphological characteristics across 81 different dinosaur individuals. Among the many notable differences are the widerand presumably strongerneck of "Apatosaurus" species compared to "B.excelsus". Other species previously assigned to "Apatosaurus", such as "Elosaurus parvus" and "Eobrontosaurus yahnahpin" were also reclassified as "Brontosaurus". Some features proposed to separate "Brontosaurus" from "Apatosaurus" include: posterior dorsal vertebrae with the centrum longer than wide; the scapula rear to the acromial edge and the distal blade being excavated; the acromial edge of the distal scapular blade bearing a rounded expansion; and the ratio of the proximodistal length to transverse breadth of the astragalus 0.55 or greater. Sauropod expert Michael Daniel D'Emic pointed out that the criteria chosen were to an extent arbitrary and that they would require abandoning the name "Brontosaurus" again if newer analyses obtained different results. Mammal palaeontologist Donald Prothero criticized the mass media reaction to this study as superficial and premature, concluding that he would keep "Brontosaurus" in quotes and not treat the name as a valid genus.

Many species of "Apatosaurus" have been designated from scant material. Marsh named as many species as he could, which resulted in many being based upon fragmentary and indistinguishable remains. In 2005 Paul Upchurch and colleagues published a study that analyzed the species and specimen relationships of "Apatosaurus". They found that "A.louisae" was the most basal species, followed by FMNHP25112, and then a polytomy of "A.ajax", "A.parvus", and "A.excelsus". Their analysis was revised and expanded with many additional diplodocid specimens in 2015, which resolved the relationships of "Apatosaurus" slightly differently, and also supported separating "Brontosaurus" from "Apatosaurus".


The cladogram below is the result of an analysis by Tschopp, Mateus, and Benson (2015). The authors analyzed most diplodocid type specimens separately to deduce which specimen belonged to which species and genus.


"Apatosaurus" is a member of the family Diplodocidae, a clade of gigantic sauropod dinosaurs. The family includes some of the longest creatures ever to walk the earth, including "Diplodocus", "Supersaurus", and "Barosaurus". "Apatosaurus" is sometimes classified in the subfamily Apatosaurinae, which may also include "Suuwassea", "Supersaurus", and "Brontosaurus". Othniel Charles Marsh described "Apatosaurus" as allied to "Atlantosaurus" within the now-defunct group Atlantosauridae. In 1878 Marsh raised his family to the rank of suborder, including "Apatosaurus", "Atlantosaurus", "Morosaurus" (="Camarasaurus") and "Diplodocus". He classified this group within Sauropoda, a group he erected in the same study. In 1903 Elmer S. Riggs said the name Sauropoda would be a junior synonym of earlier names; he grouped "Apatosaurus" within Opisthocoelia. Sauropoda is still used as the group name. In 2011, John Whitlock published a study that placed "Apatosaurus" a more basal diplodocid, sometimes less basal than "Supersaurus".

Cladogram of the Diplodocidae after Tschopp, Mateus, and Benson (2015).

It was believed throughout the 19th and early 20th centuries that sauropods like "Apatosaurus" were too massive to support their own weight on dry land. It was theorized that they lived partly submerged in water, perhaps in swamps. More recent findings do not support this; sauropods are now thought to have been fully terrestrial animals. A study of diplodocid snouts showed that the square snout, large proportion of pits, and fine, subparallel scratches of the teeth of "Apatosaurus" suggests it was a ground-height, nonselective browser. It may have eaten ferns, cycadeoids, seed ferns, horsetails, and algae. Stevens and Parish (2005) speculate that these sauropods fed from riverbanks on submerged water plants.

A 2015 study of the necks of "Apatosaurus" and "Brontosaurus" found many differences between them and other diplodocids, and that these variations may have shown that the necks of "Apatosaurus" and "Brontosaurus" were used for intraspecific combat. Various uses for the single claw on the forelimb of sauropods have been proposed. One suggestion is that they were used for defense, but their shape and size make this unlikely. It was also possible they were for feeding, but the most probable use for the claw was grasping objects such as tree trunks when rearing.

Trackways of sauropods like "Apatosaurus" show that they may have had a range of around per day, and that they could potentially have reached a top speed of per hour. The slow locomotion of sauropods may be due to their minimal muscling, or to recoil after strides. A trackway of a juvenile has led some to believe that they were capable of bipedalism, though this is disputed.

Diplodocids like "Apatosaurus" are often portrayed with their necks held high up in the air, allowing them to browse on tall trees. Some studies state diplodocid necks were less flexible than previously believed, because the structure of the neck vertebrae would not have allowed the neck to bend far upwards, and that sauropods like "Apatosaurus" were adapted to low browsing or ground feeding.

Other studies by Taylor find that all tetrapods appear to hold their necks at the maximum possible vertical extension when in a normal, alert posture; they argue the same would hold true for sauropods barring any unknown, unique characteristics that set the soft tissue anatomy of their necks apart from that of other animals. "Apatosaurus", like "Diplodocus", would have held its neck angled upwards with the head pointing downwards in a resting posture. Kent Stevens and Michael Parrish (1999 and 2005) state "Apatosaurus" had a great feeding range; its neck could bend into a U-shape laterally. The neck's range of movement would have also allowed the head to feed at the level of the feet.

Matthew Cobley et al. (2013) dispute this, finding that large muscles and cartilage would have limited movement of the neck. They state the feeding ranges for sauropods like "Diplodocus" were smaller than previously believed, and the animals may have had to move their whole bodies around to better access areas where they could browse vegetation. As such, they might have spent more time foraging to meet their minimum energy needs. The conclusions of Cobley etal. are disputed by Taylor, who analyzed the amount and positioning of intervertebral cartilage to determine the flexibility of the neck of "Apatosaurus" and "Diplodocus". He found that the neck of "Apatosaurus" was very flexible.

Given the large body mass and long neck of sauropods like "Apatosaurus", physiologists have encountered problems determining how these animals breathed. Beginning with the assumption that, like crocodilians, "Apatosaurus" did not have a diaphragm, the dead-space volume (the amount of unused air remaining in the mouth, trachea, and air tubes after each breath) has been estimated at about for a specimen. Paladino calculates its tidal volume (the amount of air moved in or out during a single breath) at with an avian respiratory system, if mammalian, and if reptilian.

On this basis, its respiratory system would likely have been parabronchi, with multiple pulmonary air sacs as in avian lungs, and a flow-through lung. An avian respiratory system would need a lung volume of about compared with a mammalian requirement of , which would exceed the space available. The overall thoracic volume of "Apatosaurus" has been estimated at , allowing for a , four-chambered heart and a lung capacity. That would allow about for the necessary tissue. Evidence for the avian system in "Apatosaurus" and other sauropods is also present in the pneumaticity of the vertebrae. Though this plays a role in reducing the weight of the animal, Wedel (2003) states they are also likely connected to air sacs, as in birds.

James Spotila et al. (1991) concludes that the large body size of sauropods would have made them unable to maintain high metabolic rates because they would not have been able to release enough heat. They assumed sauropods had a reptilian respiratory system. Wedel says that an avian system would have allowed it to dump more heat. Some scientists state that the heart would have had trouble sustaining sufficient blood pressure to oxygenate the brain. Others suggest that the near-horizontal posture of the head and neck would have eliminated the problem of supplying blood to the brain because it would not have been elevated.

James Farlow (1987) calculates that an "Apatosaurus"-sized dinosaur about would have possessed of fermentation contents. Assuming "Apatosaurus" had an avian respiratory system and a reptilian resting-metabolism, Frank Paladino etal. (1997) estimate the animal would have needed to consume only about of water per day.

A 1999 microscopic study of "Apatosaurus" and "Brontosaurus" bones concluded the animals grew rapidly when young and reached near-adult sizes in about 10years. In 2008, a study on the growth rates of sauropods was published by Thomas Lehman and Holly Woodward. They said that by using growth lines and length-to-mass ratios, "Apatosaurus" would have grown to 25t (25 long tons; 28 short tons) in 15years, with growth peaking at in a single year. An alternative method, using limb length and body mass, found "Apatosaurus" grew per year, and reached its full mass before it was about 70years old. These estimates have been called unreliable because the calculation methods are not sound; old growth lines would have been obliterated by bone remodelling. One of the first identified growth factors of "Apatosaurus" was the number of sacral vertebrae, which increased to five by the time of the creature's maturity. This was first noted in 1903 and again in 1936.

Long-bone histology enables researchers to estimate the age that a specific individual reached. A study by Eva Griebeler etal. (2013) examined long-bone histological data and concluded the "Apatosaurus" sp.SMA0014 weighed , reached sexual maturity at 21years, and died aged 28. The same growth model indicated "Apatosaurus" sp.BYU 601–17328 weighed , reached sexual maturity at 19years, and died aged 31.

Compared with most sauropods, a relatively large amount of juvenile material is known from "Apatosaurus". Multiple specimens in the OMNH are from juveniles of an undetermined species of "Apatosaurus"; this material includes partial shoulder and pelvic girdles, some vertebrae, and limb bones. OMNH juvenile material is from at least two different age groups and based on overlapping bones likely comes from more than three individuals. The specimens exhibit features that distinguish "Apatosaurus" from its relatives, and thus likely belong to the genus. Juvenile sauropods tend to have proportionally shorter necks and tails, and a more pronounced forelimb-hindlimb disparity than found in adult sauropods.

An article published in 1997 reported research of the mechanics of "Apatosaurus" tails by Nathan Myhrvold and paleontologist Philip J. Currie. Myhrvold carried out a computer simulation of the tail, which in diplodocids like "Apatosaurus" was a very long, tapering structure resembling a bullwhip. This computer modeling suggested diplodocids were capable of producing a whiplike cracking sound of over 200 decibels, comparable to the volume of a cannon being fired.

A pathology has been identified on the tail of "Apatosaurus", caused by a growth defect. Two caudal vertebrae are seamlessly fused along the entire articulating surface of the bone, including the arches of the neural spines. This defect might have been caused by the lack or inhibition of the substance that forms intervertebral disks or joints. It has been proposed that the whips could have been used in combat and defense, but the tails of diplodocids were quite light and narrow compared to "Shunosaurus" and mamenchisaurids, and thus to injure another animal with the tail would severely injure the tail itself.

The Morrison Formation is a sequence of shallow marine and alluvial sediments which, according to radiometric dating, dates from between 156.3mya at its base, and 146.8mya at the top, placing it in the late Oxfordian, Kimmeridgian, and early Tithonian stages of the Late Jurassic period. This formation is interpreted as originating in a locally semiarid environment with distinct wet and dry seasons. The Morrison Basin, where dinosaurs lived, stretched from New Mexico to Alberta and Saskatchewan; it was formed when the precursors to the Front Range of the Rocky Mountains started pushing up to the west. The deposits from their east-facing drainage basins were carried by streams and rivers and deposited in swampy lowlands, lakes, river channels, and floodplains. This formation is similar in age to the Lourinhã Formation in Portugal and the Tendaguru Formation in Tanzania.
"Apatosaurus" was the second most common sauropod in the Morrison Formation ecosystem, after "Camarasaurus". "Apatosaurus" may have been more solitary than other Morrison Formation dinosaurs. Fossils of the genus have only been found in the upper levels of the formation. Those of "Apatosaurus ajax" are known exclusively from the upper Brushy Basin Member, about 152–151 mya. "A.louisae" fossils are rare, known only from one site in the upper Brushy Basin Member; they date to the late Kimmeridgian stage, about 151mya. Additional "Apatosaurus" remains are known from similarly aged or slightly younger rocks, but they have not been identified as any particular species, and thus may instead belong to "Brontosaurus".

The Morrison Formation records a time when the local environment was dominated by gigantic sauropod dinosaurs. Dinosaurs known from the Morrison Formation include the theropods "Allosaurus", "Ceratosaurus", "Ornitholestes", "Saurophaganax", and "Torvosaurus"; the sauropods "Brontosaurus", "Brachiosaurus", "Camarasaurus", and "Diplodocus"; and the ornithischians "Camptosaurus", "Dryosaurus", and "Stegosaurus". "Apatosaurus" is commonly found at the same sites as "Allosaurus", "Camarasaurus", "Diplodocus", and "Stegosaurus". "Allosaurus" accounted for 70–75% of theropod specimens and was at the top trophic level of the Morrison food web. Many of the dinosaurs of the Morrison Formation are of the same genera as those seen in Portuguese rocks of the Lourinhã Formationmainly "Allosaurus", "Ceratosaurus", and "Torvosaurus"or have a close counterpart"Brachiosaurus" and "Lusotitan", "Camptosaurus" and "Draconyx", and "Apatosaurus" and "Dinheirosaurus". Other vertebrates that are known to have shared this paleo-environment include ray-finned fishes, frogs, salamanders, turtles, sphenodonts, lizards, terrestrial and aquatic crocodylomorphans, and several species of pterosaur. Shells of bivalves and aquatic snails are also common. The flora of the period has been evidenced in fossils of green algae, fungi, mosses, horsetails, cycads, ginkgoes, and several families of conifers. Vegetation varied from river-lining forests of tree ferns with fern understory (gallery forests), to fern savannas with occasional trees such as the "Araucaria"-like conifer "Brachyphyllum".



</doc>
<doc id="1347" url="https://en.wikipedia.org/wiki?curid=1347" title="Allosaurus">
Allosaurus

Allosaurus () is a genus of carnivorous theropod dinosaur that lived 155 to 150 million years ago during the late Jurassic period (Kimmeridgian to early Tithonian). The name ""Allosaurus"" means "different lizard" alluding to its unique concave vertebrae (at the time of its discovery). It is derived from the Greek /"allos" ("different, other") and /"sauros" ("lizard / generic reptile"). The first fossil remains that could definitively be ascribed to this genus were described in 1877 by paleontologist Othniel Charles Marsh. As one of the first well-known theropod dinosaurs, it has long attracted attention outside of paleontological circles. Indeed, it has been a top feature in several films and documentaries about prehistoric life.

"Allosaurus" was a large bipedal predator. Its skull was large and equipped with dozens of sharp, serrated teeth. It averaged in length, though fragmentary remains suggest it could have reached over . Relative to the large and powerful hindlimbs, its three-fingered forelimbs were small, and the body was balanced by a long and heavily muscled tail. It is classified as an allosaurid, a type of carnosaurian theropod dinosaur. The genus has a complicated taxonomy, and includes an uncertain number of valid species, the best known of which is "A. fragilis". The bulk of "Allosaurus" remains have come from North America's Morrison Formation, with material also known from Portugal and possibly Tanzania. It was known for over half of the 20th century as "Antrodemus", but a study of the copious remains from the Cleveland-Lloyd Dinosaur Quarry brought the name ""Allosaurus"" back to prominence and established it as one of the best-known dinosaurs.

As the most abundant large predator in the Morrison Formation, "Allosaurus" was at the top of the food chain, probably preying on contemporaneous large herbivorous dinosaurs, and perhaps even other predators. Potential prey included ornithopods, stegosaurids, and sauropods. Some paleontologists interpret "Allosaurus" as having had cooperative social behavior, and hunting in packs, while others believe individuals may have been aggressive toward each other, and that congregations of this genus are the result of lone individuals feeding on the same carcasses.

"Allosaurus" was a typical large theropod, having a massive skull on a short neck, a long, slightly sloping tail and reduced forelimbs. "Allosaurus fragilis", the best-known species, had an average length of , with the largest definitive "Allosaurus" specimen (AMNH 680) estimated at long, and an estimated weight of . In his 1976 monograph on "Allosaurus", James H. Madsen mentioned a range of bone sizes which he interpreted to show a maximum length of . As with dinosaurs in general, weight estimates are debatable, and since 1980 have ranged between , , and for modal adult weight (not maximum). John Foster, a specialist on the Morrison Formation, suggests that is reasonable for large adults of "A. fragilis", but that is a closer estimate for individuals represented by the average-sized thigh bones he has measured. Using the subadult specimen nicknamed "Big Al", researchers using computer modelling arrived at a best estimate of for the individual, but by varying parameters they found a range from approximately to approximately .

Several gigantic specimens have been attributed to "Allosaurus", but may in fact belong to other genera. The closely related genus "Saurophaganax" (OMNH 1708) reached perhaps in length, and its single species has sometimes been included in the genus "Allosaurus" as "Allosaurus maximus", though recent studies support it as a separate genus. Another potential specimen of "Allosaurus", once assigned to the genus "Epanterias" (AMNH 5767), may have measured in length. A more recent discovery is a partial skeleton from the Peterson Quarry in Morrison rocks of New Mexico; this large allosaurid may be another individual of "Saurophaganax".

David K. Smith, examining "Allosaurus" fossils by quarry, found that the Cleveland-Lloyd Dinosaur Quarry (Utah) specimens are generally smaller than those from Como Bluff (Wyoming) or Brigham Young University's Dry Mesa Quarry (Colorado), but the shapes of the bones themselves did not vary between the sites. A later study by Smith incorporating Garden Park (Colorado) and Dinosaur National Monument (Utah) specimens found no justification for multiple species based on skeletal variation; skull variation was most common and was gradational, suggesting individual variation was responsible. Further work on size-related variation again found no consistent differences, although the Dry Mesa material tended to clump together on the basis of the astragalus, an ankle bone. Kenneth Carpenter, using skull elements from the Cleveland-Lloyd site, found wide variation between individuals, calling into question previous species-level distinctions based on such features as the shape of the horns, and the proposed differentiation of "A. jimmadseni" based on the shape of the jugal.

The skull and teeth of "Allosaurus" were modestly proportioned for a theropod of its size. Paleontologist Gregory S. Paul gives a length of for a skull belonging to an individual he estimates at long. Each premaxilla (the bones that formed the tip of the snout), held five teeth with D-shaped cross-sections, and each maxilla (the main tooth-bearing bones in the upper jaw) had between 14 and 17 teeth; the number of teeth does not exactly correspond to the size of the bone. Each dentary (the tooth-bearing bone of the lower jaw) had between 14 and 17 teeth, with an average count of 16. The teeth became shorter, narrower, and more curved toward the back of the skull. All of the teeth had saw-like edges. They were shed easily, and were replaced continually, making them common fossils.

The skull had a pair of horns above and in front of the eyes. These horns were composed of extensions of the lacrimal bones, and varied in shape and size. There were also lower paired ridges running along the top edges of the nasal bones that led into the horns. The horns were probably covered in a keratin sheath and may have had a variety of functions, including acting as sunshades for the eye, being used for display, and being used in combat against other members of the same species (although they were fragile). There was a ridge along the back of the skull roof for muscle attachment, as is also seen in tyrannosaurids.

Inside the lacrimal bones were depressions that may have held glands, such as salt glands. Within the maxillae were sinuses that were better developed than those of more basal theropods such as "Ceratosaurus" and "Marshosaurus"; they may have been related to the sense of smell, perhaps holding something like Jacobson's organ. The roof of the braincase was thin, perhaps to improve thermoregulation for the brain. The skull and lower jaws had joints that permitted motion within these units. In the lower jaws, the bones of the front and back halves loosely articulated, permitting the jaws to bow outward and increasing the animal's gape. The braincase and frontals may also have had a joint.

"Allosaurus" had nine vertebrae in the neck, 14 in the back, and five in the sacrum supporting the hips. The number of tail vertebrae is unknown and varied with individual size; James Madsen estimated about 50, while Gregory S. Paul considered that to be too many and suggested 45 or less. There were hollow spaces in the neck and anterior back vertebrae. Such spaces, which are also found in modern theropods (that is, the birds), are interpreted as having held air sacs used in respiration. The rib cage was broad, giving it a barrel chest, especially in comparison to less derived theropods like "Ceratosaurus". "Allosaurus" had gastralia (belly ribs), but these are not common findings, and they may have ossified poorly. In one published case, the gastralia show evidence of injury during life. A furcula (wishbone) was also present, but has only been recognized since 1996; in some cases furculae were confused with gastralia. The ilium, the main hip bone, was massive, and the pubic bone had a prominent foot that may have been used for both muscle attachment and as a prop for resting the body on the ground. Madsen noted that in about half of the individuals from the Cleveland-Lloyd Dinosaur Quarry, independent of size, the pubes had not fused to each other at their foot ends. He suggested that this was a sexual characteristic, with females lacking fused bones to make egg-laying easier. This proposal has not attracted further attention, however.

The forelimbs of "Allosaurus" were short in comparison to the hindlimbs (only about 35% the length of the hindlimbs in adults) and had three fingers per hand, tipped with large, strongly curved and pointed claws. The arms were powerful, and the forearm was somewhat shorter than the upper arm (1:1.2 ulna/humerus ratio). The wrist had a version of the semilunate carpal also found in more derived theropods like maniraptorans. Of the three fingers, the innermost (or thumb) was the largest, and diverged from the others. The phalangeal formula is 2-3-4-0-0, meaning that the innermost finger (phalange) has two bones, the next has three, and the third finger has four. The legs were not as long or suited for speed as those of tyrannosaurids, and the claws of the toes were less developed and more hoof-like than those of earlier theropods. Each foot had three weight-bearing toes and an inner dewclaw, which Madsen suggested could have been used for grasping in juveniles. There was also what is interpreted as the splint-like remnant of a fifth (outermost) metatarsal, perhaps used as a lever between the Achilles tendon and foot.

The discovery and early study of "Allosaurus" is complicated by the multiplicity of names coined during the Bone Wars of the late 19th century. The first described fossil in this history was a bone obtained secondhand by Ferdinand Vandiveer Hayden in 1869. It came from Middle Park, near Granby, Colorado, probably from Morrison Formation rocks. The locals had identified such bones as "petrified horse hoofs". Hayden sent his specimen to Joseph Leidy, who identified it as half of a tail vertebra, and tentatively assigned it to the European dinosaur genus "Poekilopleuron" as "Poicilopleuron" "valens". He later decided it deserved its own genus, "Antrodemus".

"Allosaurus" itself is based on YPM 1930, a small collection of fragmentary bones including parts of three vertebrae, a rib fragment, a tooth, a toe bone, and, most useful for later discussions, the shaft of the right humerus (upper arm). Othniel Charles Marsh gave these remains the formal name "Allosaurus fragilis" in 1877. "Allosaurus" comes from the Greek "allos/αλλος", meaning "strange" or "different" and "sauros/σαυρος", meaning "lizard" or "reptile". It was named 'different lizard' because its vertebrae were different from those of other dinosaurs known at the time of its discovery. The species epithet "fragilis" is Latin for "fragile", referring to lightening features in the vertebrae. The bones were collected from the Morrison Formation of Garden Park, north of Cañon City. Marsh and Edward Drinker Cope, who were in scientific competition, went on to coin several other genera based on similarly sparse material that would later figure in the taxonomy of "Allosaurus". These include Marsh's "Creosaurus" and "Labrosaurus", and Cope's "Epanterias".

In their haste, Cope and Marsh did not always follow up on their discoveries (or, more commonly, those made by their subordinates). For example, after the discovery by Benjamin Mudge of the type specimen of "Allosaurus" in Colorado, Marsh elected to concentrate work in Wyoming; when work resumed at Garden Park in 1883, M. P. Felch found an almost complete "Allosaurus" and several partial skeletons. In addition, one of Cope's collectors, H. F. Hubbell, found a specimen in the Como Bluff area of Wyoming in 1879, but apparently did not mention its completeness, and Cope never unpacked it. Upon unpacking in 1903 (several years after Cope had died), it was found to be one of the most complete theropod specimens then known, and in 1908 the skeleton, now cataloged as AMNH 5753, was put on public view. This is the well-known mount poised over a partial "Apatosaurus" skeleton as if scavenging it, illustrated as such by Charles R. Knight. Although notable as the first free-standing mount of a theropod dinosaur, and often illustrated and photographed, it has never been scientifically described.

The multiplicity of early names complicated later research, with the situation compounded by the terse descriptions provided by Marsh and Cope. Even at the time, authors such as Samuel Wendell Williston suggested that too many names had been coined. For example, Williston pointed out in 1901 that Marsh had never been able to adequately distinguish "Allosaurus" from "Creosaurus". The most influential early attempt to sort out the convoluted situation was produced by Charles W. Gilmore in 1920. He came to the conclusion that the tail vertebra named "Antrodemus" by Leidy was indistinguishable from those of "Allosaurus", and "Antrodemus" thus should be the preferred name because as the older name it had priority. "Antrodemus" became the accepted name for this familiar genus for over fifty years, until James Madsen published on the Cleveland-Lloyd specimens and concluded that "Allosaurus" should be used because "Antrodemus" was based on material with poor, if any, diagnostic features and locality information (for example, the geological formation that the single bone of "Antrodemus" came from is unknown). ""Antrodemus"" has been used informally for convenience when distinguishing between the skull Gilmore restored and the composite skull restored by Madsen.

Although sporadic work at what became known as the Cleveland-Lloyd Dinosaur Quarry in Emery County, Utah had taken place as early as 1927, and the fossil site itself described by William L. Stokes in 1945, major operations did not begin there until 1960. Under a cooperative effort involving nearly 40 institutions, thousands of bones were recovered between 1960 and 1965. The quarry is notable for the predominance of "Allosaurus" remains, the condition of the specimens, and the lack of scientific resolution on how it came to be. The majority of bones belong to the large theropod "Allosaurus fragilis" (it is estimated that the remains of at least 46 "A. fragilis" have been found there, out of at minimum 73 dinosaurs), and the fossils found there are disarticulated and well-mixed. Nearly a dozen scientific papers have been written on the taphonomy of the site, suggesting numerous mutually exclusive explanations for how it may have formed. Suggestions have ranged from animals getting stuck in a bog, to becoming trapped in deep mud, to falling victim to drought-induced mortality around a waterhole, to getting trapped in a spring-fed pond or seep. Regardless of the actual cause, the great quantity of well-preserved "Allosaurus" remains has allowed this genus to be known in detail, making it among the best-known theropods. Skeletal remains from the quarry pertain to individuals of almost all ages and sizes, from less than to long, and the disarticulation is an advantage for describing bones usually found fused.

The period since Madsen's monograph has been marked by a great expansion in studies dealing with topics concerning "Allosaurus" in life (paleobiological and paleoecological topics). Such studies have covered topics including skeletal variation, growth, skull construction, hunting methods, the brain, and the possibility of gregarious living and parental care. Reanalysis of old material (particularly of large 'allosaur' specimens), new discoveries in Portugal, and several very complete new specimens have also contributed to the growing knowledge base.

In 1991 "Big Al" (MOR 693), a 95% complete, partially articulated specimen of "Allosaurus" was discovered. It measured about 8 meters (about 26 ft) in length. MOR 693 was excavated near Shell, Wyoming, by a joint Museum of the Rockies and University of Wyoming Geological Museum team. This skeleton was discovered by a Swiss team, led by Kirby Siber. In 1996 the same team discovered a second "Allosaurus", "Big Al Two", which is the best preserved skeleton of its kind to date.

The completeness, preservation, and scientific importance of this skeleton gave "Big Al" its name; the individual itself was below the average size for "Allosaurus fragilis", and was a subadult estimated at only 87% grown. The specimen was described by Breithaupt in 1996. Nineteen of its bones were broken or showed signs of infection, which may have contributed to "Big Al's" death. Pathologic bones included five ribs, five vertebrae, and four bones of the feet; several damaged bones showed osteomyelitis, a bone infection. A particular problem for the living animal was infection and trauma to the right foot that probably affected movement and may have also predisposed the other foot to injury because of a change in gait. Al had an infection on the first phalanx on the third toe that was afflicted by an involucrum. The infection was long lived, perhaps up to 6 months. Big Al Two is also known to have multiple injuries.

There are currently four valid and one undescribed species of "Allosaurus" ("A. amplus", "A. europaeus", the type species "A. fragilis", the as-yet not formally described "A. jimmadseni", and "A. lucasi").

"A. fragilis" is the type species and was named by Marsh in 1877. It is known from the remains of at least sixty individuals, all found in the Kimmeridgian–Tithonian Upper Jurassic-age Morrison Formation of the United States, spread across the states of Colorado, Montana, New Mexico, Oklahoma, South Dakota, Utah, and Wyoming. Details of the humerus (upper arm) of "A. fragilis" have been used as diagnostic among Morrison theropods, but the discovery of "A. jimmadseni" indicates that this will no longer be the case at the species level.

Daniel Chure's work on Morrison allosaurid remains has been responsible, directly or indirectly, for "A. jimmadseni" and "A. maximus". "A. jimmadseni" is the proposed name for a new species of Morrison allosaur, based on a nearly complete skeleton and skull. It differs from "A. fragilis" in several anatomical details including a jugal or cheekbone with a straight lower margin, and is confined to the Salt Wash Member of the Morrison Formation, while "A. fragilis" is only present in the higher Brushy Basin Member.

"A. fragilis", "A. jimmadseni", "A. amplus", and "A. lucasi" are all known from remains discovered in the Kimmeridgian–Tithonian Upper Jurassic-age Morrison Formation of the United States, spread across the states of Colorado, Montana, New Mexico, Oklahoma, South Dakota, Utah and Wyoming. "A. fragilis" is regarded as the most common, known from the remains of at least sixty individuals. For a while in the late 1980s and early 1990s it was common to recognize "A. fragilis" as the short-snouted species, with the long-snouted taxon being "A. atrox"; however, subsequent analysis of specimens from the Cleveland-Lloyd Dinosaur Quarry, Como Bluff, and Dry Mesa Quarry showed that the differences seen in the Morrison Formation material could be attributed to individual variation. A study of skull elements from the Cleveland-Lloyd site found wide variation between individuals, calling into question previous species-level distinctions based on such features as the shape of the lacrimal horns, and the proposed differentiation of "A. jimmadseni" based on the shape of the jugal. "A. europaeus" was found in the Kimmeridgian-age Porto Novo Member of the Lourinhã Formation, but may be the same as "A. fragilis".

"Allosaurus" material from Portugal was first reported in 1999 on the basis of MHNUL/AND.001, a partial skeleton including a quadrate, vertebrae, ribs, gastralia, chevrons, part of the hips, and hindlimbs. This specimen was assigned to "A. fragilis", but the subsequent discovery of a partial skull and neck (ML 415) near Lourinhã, in the Kimmeridgian-age Porto Novo Member of the Lourinhã Formation, spurred the naming of the new species "A. europaeus". It differs from other species of "Allosaurus" in cranial details. However, more material may show it to be "A. fragilis", as originally described.

The issue of species and potential synonyms is complicated by the type specimen of "Allosaurus fragilis" (catalog number YPM 1930) being extremely fragmentary, consisting of a few incomplete vertebrae, limb bone fragments, rib fragments, and a tooth. Because of this, several scientists have interpreted the type specimen as potentially dubious, and thus the genus "Allosaurus" itself or at least the species "A. fragilis" would be a "nomen dubium" ("dubious name", based on a specimen too incomplete to compare to other specimens or to classify). To address this situation, Gregory S. Paul and Kenneth Carpenter (2010) submitted a petition to the ICZN to have the name ""A. fragilis"" officially transferred to the more complete specimen USNM4734 (as a neotype). This request is currently pending review.

"Creosaurus", "Epanterias", and "Labrosaurus" are regarded as junior synonyms of "Allosaurus". Most of the species that are regarded as synonyms of "A. fragilis", or that were misassigned to the genus, are obscure and were based on scrappy remains. One exception is "Labrosaurus ferox", named in 1884 by Marsh for an oddly formed partial lower jaw, with a prominent gap in the tooth row at the tip of the jaw, and a rear section greatly expanded and turned down. Later researchers suggested that the bone was pathologic, showing an injury to the living animal, and that part of the unusual form of the rear of the bone was due to plaster reconstruction. It is now regarded as an example of "A. fragilis."

In his 1988 book "Predatory Dinosaurs of the World", the freelance dinosaurologist Gregory Paul proposed that "A. fragilis" had tall pointed horns and a slender build compared to a postulated second species "A. atrox", and was not a different gender due to rarity. "Allosaurus atrox" was originally named by Marsh in 1878 as the type species of its own genus, "Creosaurus", and is based on YPM 1890, an assortment of bones including a couple of pieces of the skull, portions of nine tail vertebrae, two hip vertebrae, an illium, and ankle and foot bones. Although the idea of two common Morrison allosaur species was followed in some semi-technical and popular works, the 2000 thesis on Allosauridae noted that Charles Gilmore mistakenly reconstructed USNM 4734 as having a shorter skull than the specimens referred by Paul to "atrox", refuting supposed differences between USNM 4734 and putative "A. atrox" specimens like DINO 2560, AMNH 600, and AMNH 666.

"Allosaurus agilis", seen in Zittel, 1887, and Osborn, 1912, is a typographical error for "A. fragilis." "Allosaurus ferox" is a typographical error by Marsh for "A. fragilis" in a figure caption for the partial skull YPM 1893, and YPM 1893 has been treated as a specimen of "A fragilis." Likewise, "Labrosaurus fragilis" is a typographical error by Marsh (1896) for "Labrosaurus ferox". "A. whitei" is a nomen nudum coined by Pickering in 1996 for the complete "Allosaurus" specimens that Paul referred to "A. atrox".

Several species initially classified within or referred to "Allosaurus" do not belong within the genus. "A. medius" was named by Marsh in 1888 for various specimens from the Early Cretaceous Arundel Formation of Maryland, although most of the remains were removed by Richard Swann Lull to the new ornithopod species "Dryosaurus grandis", except for a tooth. Gilmore considered the tooth nondiagnostic but transferred it to "Dryptosaurus", as "D. medius". The referral was not accepted in the most recent review, and "Allosaurus medius" was simply listed as a dubious species of theropod. It may be closely related to "Acrocanthosaurus".

"Allosaurus valens" is a new combination for "Antrodemus valens" used by Friedrich von Huene in 1932; "Antrodemus valens" itself may also pertain to "Allosaurus fragilis", as Gilmore suggested in 1920.

"A. lucaris", another Marsh name, was given to a partial skeleton in 1878. He later decided it warranted its own genus, "Labrosaurus", but this has not been accepted, and "A. lucaris" is also regarded as another specimen of "A. fragilis". "Allosaurus lucaris", is known mostly from vertebrae, sharing characters with "Allosaurus". Paul and Carpenter stated that the type specimen of this species, YPM 1931, was from a younger age than "Allosaurus", and might represent a different genus. However, they found that the specimen was undiagnostic, and thus "A. lucaris" was a "nomen dubium".

"Allosaurus sibiricus" was described in 1914 by A. N. Riabinin on the basis of a bone, later identified as a partial fourth metatarsal, from the Early Cretaceous of Buryatia, Russia. It was transferred to "Chilantaisaurus" in 1990, but is now considered a "nomen dubium" indeterminate beyond Theropoda.

"Allosaurus meriani" was a new combination by George Olshevsky for "Megalosaurus meriani" Greppin, 1870, based on a tooth from the Late Jurassic of Switzerland. However, a recent overview of "Ceratosaurus" included it in "Ceratosaurus" sp.

"Apatodon mirus", based on a scrap of vertebra Marsh first thought to be a mammalian jaw, has been listed as a synonym of "Allosaurus fragilis". However, it was considered indeterminate beyond Dinosauria by Dan Chure, and Mickey Mortimer believes that the synonymy of "Apatodon" with "Allosaurus" was due to correspondence to Ralph Molnar by John McIntosh, whereby the latter reportedly found a paper saying that Othniel Charles Marsh admitted that the "Apatodon" holotype was actually an allosaurid dorsal vertebra.

"A. amplexus" was named by Gregory S. Paul for giant Morrison allosaur remains, and included in his conception "Saurophagus maximus" (later "Saurophaganax"). "A. amplexus" was originally coined by Cope in 1878 as the type species of his new genus "Epanterias", and is based on what is now AMNH 5767, parts of three vertebrae, a coracoid, and a metatarsal. Following Paul's work, this species has been accepted as a synonym of "A. fragilis". A 2010 study by Paul and Kenneth Carpenter, however, indicates that "Epanterias" is temporally younger than the "A. fragilis" type specimen, so is a separate species at minimum.

"A. maximus" was a new combination by David K. Smith for Chure's "Saurophaganax maximus", a taxon created by Chure in 1995 for giant allosaurid remains from the Morrison of Oklahoma. These remains had been known as "Saurophagus", but that name was already in use, leading Chure to propose a substitute. Smith, in his 1998 analysis of variation, concluded that "S. maximus" was not different enough from "Allosaurus" to be a separate genus, but did warrant its own species, "A. maximus". This reassignment was rejected in the most recent review of basal tetanurans.

There are also several species left over from the synonymizations of "Creosaurus" and "Labrosaurus" with "Allosaurus". "Creosaurus potens" was named by Lull in 1911 for a vertebra from the Early Cretaceous of Maryland. It is now regarded as a dubious theropod. "Labrosaurus stechowi", described in 1920 by Janensch based on isolated "Ceratosaurus"-like teeth from the Tendaguru beds of Tanzania, Although Donald F. Glut listed it as a species of "Allosaurus", it is now considered a dubious ceratosaurian related to "Ceratosaurus". "L. sulcatus", named by Marsh in 1896 for a Morrison theropod tooth, which like "L. stechowi" is now regarded as a dubious "Ceratosaurus"-like ceratosaur.

"A. tendagurensis" was named in 1925 by Werner Janensch for a partial shin (MB.R.3620) found in the Kimmeridgian-age Tendaguru Formation in Mtwara, Tanzania. Although tabulated as a tentatively valid species of "Allosaurus" in the second edition of the Dinosauria, subsequent studies place it as indeterminate beyond Tetanurae, either a carcharodontosaurian or megalosaurid. Although obscure, it was a large theropod, possibly around 10 meters long (33 ft) and 2.5 metric tons (2.8 short tons) in weight.

Kurzanov and colleagues in 2003 designated six teeth from Siberia as "Allosaurus" sp. (meaning the authors found the specimens to be most like those of "Allosaurus", but did not or could not assign a species). Also, reports of "Allosaurus" in Shanxi, China go back to at least 1982.

An astragalus (ankle bone) thought to belong to a species of "Allosaurus" was found at Cape Paterson, Victoria in Early Cretaceous beds in southeastern Australia. It was thought to provide evidence that Australia was a refugium for animals that had gone extinct elsewhere. This identification was challenged by Samuel Welles, who thought it more resembled that of an ornithomimid, but the original authors defended their identification. With fifteen years of new specimens and research to look at, Daniel Chure reexamined the bone and found that it was not "Allosaurus", but could represent an allosauroid. Similarly, Yoichi Azuma and Phil Currie, in their description of "Fukuiraptor", noted that the bone closely resembled that of their new genus. This specimen is sometimes referred to as "Allosaurus robustus", an informal museum name. It may have belonged to something similar to, or the same as, "Australovenator", or it may represent an abelisaur.

"Allosaurus" was an allosaurid, a member of a family of large theropods within the larger group Carnosauria. The family name Allosauridae was created for this genus in 1878 by Othniel Charles Marsh, but the term was largely unused until the 1970s in favor of Megalosauridae, another family of large theropods that eventually became a wastebasket taxon. This, along with the use of "Antrodemus" for "Allosaurus" during the same period, is a point that needs to be remembered when searching for information on "Allosaurus" in publications that predate James Madsen's 1976 monograph. Major publications using the name "Megalosauridae" instead of "Allosauridae" include Gilmore, 1920, von Huene, 1926, Romer, 1956 and 1966, Steel, 1970, and Walker, 1964.

Following the publication of Madsen's influential monograph, Allosauridae became the preferred family assignment, but it too was not strongly defined. Semi-technical works used Allosauridae for a variety of large theropods, usually those that were larger and better-known than megalosaurids. Typical theropods that were thought to be related to "Allosaurus" included "Indosaurus", "Piatnitzkysaurus", "Piveteausaurus", "Yangchuanosaurus", "Acrocanthosaurus", "Chilantaisaurus", "Compsosuchus", "Stokesosaurus", and "Szechuanosaurus". Given modern knowledge of theropod diversity and the advent of cladistic study of evolutionary relationships, none of these theropods is now recognized as an allosaurid, although several, like "Acrocanthosaurus" and "Yangchuanosaurus", are members of closely related families.
Below is a cladogram by Benson "et al." in 2010.

Allosauridae is one of four families in Carnosauria; the other three are Neovenatoridae, Carcharodontosauridae and Sinraptoridae. Allosauridae has at times been proposed as ancestral to the Tyrannosauridae (which would make it paraphyletic), one recent example being Gregory S. Paul's "Predatory Dinosaurs of the World", but this has been rejected, with tyrannosaurids identified as members of a separate branch of theropods, the Coelurosauria. Allosauridae is the smallest of the carnosaur families, with only "Saurophaganax" and a currently unnamed French allosauroid accepted as possible valid genera besides "Allosaurus" in the most recent review. Another genus, "Epanterias", is a potential valid member, but it and "Saurophaganax" may turn out to be large examples of "Allosaurus". Recent reviews have kept the genus "Saurophaganax" and included "Epanterias" with "Allosaurus".

The wealth of "Allosaurus" fossils, from nearly all ages of individuals, allows scientists to study how the animal grew and how long its lifespan may have been. Remains may reach as far back in the lifespan as eggs—crushed eggs from Colorado have been suggested as those of "Allosaurus". Based on histological analysis of limb bones, bone deposition appears to stop at around 22 to 28 years, which is comparable to that of other large theropods like "Tyrannosaurus". From the same analysis, its maximum growth appears to have been at age 15, with an estimated growth rate of about 150 kilograms (330 lb) per year.

Medullary bone tissue (endosteally derived, ephemeral, mineralization located inside the medulla of the long bones in gravid female birds) has been reported in at least one "Allosaurus" specimen, a shin bone from the Cleveland-Lloyd Quarry. Today, this bone tissue is only formed in female birds that are laying eggs, as it is used to supply calcium to shells. Its presence in the "Allosaurus" individual has been used to establish sex and show it had reached reproductive age. However, other studies have called into question some cases of medullary bone in dinosaurs, including this "Allosaurus" individual. Data from extant birds suggested that the medullary bone in this "Allosaurus" individual may have been the result of a bone pathology instead. However, with the confirmation of medullary tissue indicating gender in a specimen of "Tyrannosaurus", it may be possible to ascertain whether or not the "Allosaurus" in question was indeed female.
The discovery of a juvenile specimen with a nearly complete hindlimb shows that the legs were relatively longer in juveniles, and the lower segments of the leg (shin and foot) were relatively longer than the thigh. These differences suggest that younger "Allosaurus" were faster and had different hunting strategies than adults, perhaps chasing small prey as juveniles, then becoming ambush hunters of large prey upon adulthood. The thigh bone became thicker and wider during growth, and the cross-section less circular, as muscle attachments shifted, muscles became shorter, and the growth of the leg slowed. These changes imply that juvenile legs has less predictable stresses compared with adults, which would have moved with more regular forward progression. Conversely, the skull bones appear to have generally grown isometrically, increasing in size without changing in proportion.

Paleontologists accept "Allosaurus" as an active predator of large animals. There is dramatic evidence for allosaur attacks on "Stegosaurus", including an "Allosaurus" tail vertebra with a partially healed puncture wound that fits a "Stegosaurus" tail spike, and a "Stegosaurus" neck plate with a U-shaped wound that correlates well with an "Allosaurus" snout. Sauropods seem to be likely candidates as both live prey and as objects of scavenging, based on the presence of scrapings on sauropod bones fitting allosaur teeth well and the presence of shed allosaur teeth with sauropod bones. However, as Gregory Paul noted in 1988, "Allosaurus" was probably not a predator of fully grown sauropods, unless it hunted in packs, as it had a modestly sized skull and relatively small teeth, and was greatly outweighed by contemporaneous sauropods. Another possibility is that it preferred to hunt juveniles instead of fully grown adults. Research in the 1990s and first decade of the 21st century may have found other solutions to this question. Robert T. Bakker, comparing "Allosaurus" to Cenozoic sabre-toothed carnivorous mammals, found similar adaptations, such as a reduction of jaw muscles and increase in neck muscles, and the ability to open the jaws extremely wide. Although "Allosaurus" did not have sabre teeth, Bakker suggested another mode of attack that would have used such neck and jaw adaptations: the short teeth in effect became small serrations on a saw-like cutting edge running the length of the upper jaw, which would have been driven into prey. This type of jaw would permit slashing attacks against much larger prey, with the goal of weakening the victim.

Similar conclusions were drawn by another study using finite element analysis on an "Allosaurus" skull. According to their biomechanical analysis, the skull was very strong but had a relatively small bite force. By using jaw muscles only, it could produce a bite force of 805 to 8,724 N, but the skull could withstand nearly 55,500 N of vertical force against the tooth row. The authors suggested that "Allosaurus" used its skull like a machete against prey, attacking open-mouthed, slashing flesh with its teeth, and tearing it away without splintering bones, unlike "Tyrannosaurus", which is thought to have been capable of damaging bones. They also suggested that the architecture of the skull could have permitted the use of different strategies against different prey; the skull was light enough to allow attacks on smaller and more agile ornithopods, but strong enough for high-impact ambush attacks against larger prey like stegosaurids and sauropods. Their interpretations were challenged by other researchers, who found no modern analogues to a hatchet attack and considered it more likely that the skull was strong to compensate for its open construction when absorbing the stresses from struggling prey. The original authors noted that "Allosaurus" itself has no modern equivalent, that the tooth row is well-suited to such an attack, and that articulations in the skull cited by their detractors as problematic actually helped protect the palate and lessen stress. Another possibility for handling large prey is that theropods like "Allosaurus" were "flesh grazers" which could take bites of flesh out of living sauropods that were sufficient to sustain the predator so it would not have needed to expend the effort to kill the prey outright. This strategy would also potentially have allowed the prey to recover and be fed upon in a similar way later. An additional suggestion notes that ornithopods were the most common available dinosaurian prey, and that allosaurs may have subdued them by using an attack similar to that of modern big cats: grasping the prey with their forelimbs, and then making multiple bites on the throat to crush the trachea. This is compatible with other evidence that the forelimbs were strong and capable of restraining prey. Studies done by Stephen Lautenschager "et al." from the University of Bristol also indicate "Allosaurus" could open its jaws quite wide and sustain considerable muscle force. When compared with "Tyrannosaurus" and the therizinosaurid "Erlikosaurus" in the same study, it was found that "Allosaurus" had a wider gape than either; the animal was capable of opening its jaws to a 92 degree angle at maximum. The findings also indicate that large carnivorous dinosaurs, like modern carnivores, had wider jaw gapes than herbivores.

A biomechanical study published in 2013 by Eric Snively and colleagues found that "Allosaurus" had an unusually low attachment point on the skull for the longissimus capitis superficialis neck muscle compared to other theropods such as "Tyrannosaurus". This would have allowed the animal to make rapid and forceful vertical movements with the skull. The authors found that vertical strikes as proposed by Bakker and Rayfield are consistent with the animal's capabilities. They also found that the animal probably processed carcasses by vertical movements in a similar manner to falcons, such as kestrels: the animal could have gripped prey with the skull and feet, then pulled back and up to remove flesh. This differs from the prey-handling envisioned for tyrannosaurids, which probably tore flesh with lateral shakes of the skull, similar to crocodilians. In addition, "Allosaurus" was able to "move its head and neck around relatively rapidly and with considerable control", at the cost of power.

Other aspects of feeding include the eyes, arms, and legs. The shape of the skull of "Allosaurus" limited potential binocular vision to 20° of width, slightly less than that of modern crocodilians. As with crocodilians, this may have been enough to judge prey distance and time attacks. The arms, compared with those of other theropods, were suited for both grasping prey at a distance or clutching it close, and the articulation of the claws suggests that they could have been used to hook things. Finally, the top speed of "Allosaurus" has been estimated at 30 to 55 kilometers per hour (19 to 34 miles per hour).

A new paper on the cranio-dental morphology of "Allosaurus" and how it worked has deemed the hatchet jaw attack unlikely, reinterpreting the unusually wide gape as an adaptation to allow Allosaurus to deliver a muscle-driven bite to large prey, with the weaker jaw muscles being a trade-off to allow for the widened gape.

It has been speculated since the 1970s that "Allosaurus" preyed on sauropods and other large dinosaurs by hunting in groups.
Such a depiction is common in semitechnical and popular dinosaur literature. Robert T. Bakker has extended social behavior to parental care, and has interpreted shed allosaur teeth and chewed bones of large prey animals as evidence that adult allosaurs brought food to lairs for their young to eat until they were grown, and prevented other carnivores from scavenging on the food. However, there is actually little evidence of gregarious behavior in theropods, and social interactions with members of the same species would have included antagonistic encounters, as shown by injuries to gastralia and bite wounds to skulls (the pathologic lower jaw named "Labrosaurus ferox" is one such possible example). Such head-biting may have been a way to establish dominance in a pack or to settle territorial disputes.

Although "Allosaurus" may have hunted in packs, it has been argued that "Allosaurus" and other theropods had largely aggressive interactions instead of cooperative interactions with other members of their own species. The study in question noted that cooperative hunting of prey much larger than an individual predator, as is commonly inferred for theropod dinosaurs, is rare among vertebrates in general, and modern diapsid carnivores (including lizards, crocodiles, and birds) rarely cooperate to hunt in such a way. Instead, they are typically territorial and will kill and cannibalize intruders of the same species, and will also do the same to smaller individuals that attempt to eat before they do when aggregated at feeding sites. According to this interpretation, the accumulation of remains of multiple "Allosaurus" individuals at the same site, e.g. in the Cleveland–Lloyd Quarry, are not due to pack hunting, but to the fact that "Allosaurus" individuals were drawn together to feed on other disabled or dead allosaurs, and were sometimes killed in the process. This could explain the high proportion of juvenile and subadult allosaurs present, as juveniles and subadults are disproportionally killed at modern group feeding sites of animals like crocodiles and Komodo dragons. The same interpretation applies to Bakker's lair sites. There is some evidence for cannibalism in "Allosaurus", including "Allosaurus" shed teeth found among rib fragments, possible tooth marks on a shoulder blade, and cannibalized allosaur skeletons among the bones at Bakker's lair sites.

The brain of "Allosaurus", as interpreted from spiral CT scanning of an endocast, was more consistent with crocodilian brains than those of the other living archosaurs, birds. The structure of the vestibular apparatus indicates that the skull was held nearly horizontal, as opposed to strongly tipped up or down. The structure of the inner ear was like that of a crocodilian, and so "Allosaurus" probably could have heard lower frequencies best, and would have had trouble with subtle sounds. The olfactory bulbs were large and seem to have been well suited for detecting odors, although the area for evaluating smells was relatively small.

In 2001, Bruce Rothschild and others published a study examining evidence for stress fractures and tendon avulsions in theropod dinosaurs and the implications for their behavior. Since stress fractures are caused by repeated trauma rather than singular events they are more likely to be caused by the behavior of the animal than other kinds of injury. Stress fractures and tendon avulsions occurring in the forelimb have special behavioral significance since while injuries to the feet could be caused by running or migration, resistant prey items are the most probable source of injuries to the hand. "Allosaurus" was one of only two theropods examined in the study to exhibit a tendon avulsion, and in both cases the avulsion occurred on the forelimb. When the researchers looked for stress fractures, they found that "Allosaurus" had a significantly greater number of stress fractures than "Albertosaurus", "Ornithomimus" or "Archaeornithomimus". Of the 47 hand bones the researchers studied, 3 were found to contain stress fractures. Of the feet, 281 bones were studied and 17 found to have stress fractures. The stress fractures in the foot bones "were distributed to the proximal phalanges" and occurred across all three weight-bearing toes in "statistically indistinguishable" numbers. Since the lower end of the third metatarsal would have contacted the ground first while an allosaur was running it would have borne the most stress. If the allosaurs' stress fractures were caused by damage accumulating while walking or running this bone should have experience more stress fractures than the others. The lack of such a bias in the examined "Allosaurus" fossils indicates an origin for the stress fractures from a source other than running. The authors conclude that these fractures occurred during interaction with prey, like an allosaur trying to hold struggling prey with its feet. The abundance of stress fractures and avulsion injuries in "Allosaurus" provide evidence for "very active" predation-based rather than scavenging diets.

The left scapula and fibula of an "Allosaurus fragilis" specimen catalogued as USNM 4734 are both pathological, both probably due to healed fractures. The specimen USNM 8367 preserved several pathological gastralia which preserve evidence of healed fractures near their middle. Some of the fractures were poorly healed and "formed pseudoarthroses". A specimen with a fractured rib was recovered from the Cleveland-Lloyd Quarry. Another specimen had fractured ribs and fused vertebrae near the end of the tail. An apparent subadult male "Allosaurus fragilis" was reported to have extensive pathologies, with a total of fourteen separate injuries. The specimen MOR 693 had pathologies on five ribs, the sixth neck vertebra the third eighth and thirteenth back vertebrae, the second tail vertebra and its chevron, the gastralia right scapula, manual phalanx I left ilium metatarsals III and V, the first phalanx of the third toe and the third phalanx of the second. The ilium had "a large hole... caused by a blow from above".The near end of the first phalanx of the third toe was afflicted by an involucrum.

Other pathologies reported in "Allosaurus" include: Willow breaks in two ribs. Healed fractures in the humerus and radius. Distortion of joint surfaces in the foot possibly due to osteoarthritis or developmental issues. Osteopetrosis along the endosteal surface of a tibia. Distortions of the joint surfaces of the tail vertebrae possibly due to osetoarthritis or developmental issues. "[E]xtensive 'neoplastic' ankylosis of caudals," possibly due to physical trauma as well as the fusion of chevrons to centra. Coossification of vertebral centra near the end of the tail. Amputation of a chevron and foot bone, both possibly a result of bites. "[E]xtensive exostoses" in the first phalanx of the third toe. Lesions similar to those caused by osteomyelitis in two scapulae. Bone spurs in a premaxilla, ungual, and two metacarpals. Exostosis in a pedal phalanx possibly attributable to an infectious disease. A metacarpal with a round depressed fracture.

"Allosaurus" was the most common large theropod in the vast tract of Western American fossil-bearing rock known as the Morrison Formation, accounting for 70 to 75% of theropod specimens, and as such was at the top trophic level of the Morrison food web. The Morrison Formation is interpreted as a semiarid environment with distinct wet and dry seasons, and flat floodplains. Vegetation varied from river-lining forests of conifers, tree ferns, and ferns (gallery forests), to fern savannas with occasional trees such as the "Araucaria"-like conifer "Brachyphyllum".

The Morrison Formation has been a rich fossil hunting ground. The flora of the period has been revealed by fossils of green algae, fungi, mosses, horsetails, ferns, cycads, ginkgoes, and several families of conifers. Animal fossils discovered include bivalves, snails, ray-finned fishes, frogs, salamanders, turtles, sphenodonts, lizards, terrestrial and aquatic crocodylomorphans, several species of pterosaur, numerous dinosaur species, and early mammals such as docodonts, multituberculates, symmetrodonts, and triconodonts. Dinosaurs known from the Morrison include the theropods "Ceratosaurus", "Ornitholestes", "Tanycolagreus", and "Torvosaurus", the sauropods "Haplocanthosaurus", "Camarasaurus", "Cathetosaurus", "Brachiosaurus", "Suuwassea", "Apatosaurus", "Brontosaurus", "Barosaurus", "Diplodocus", "Supersaurus", and "Amphicoelias", and the ornithischians "Camptosaurus", "Dryosaurus", and "Stegosaurus". "Allosaurus" is commonly found at the same sites as "Apatosaurus", "Camarasaurus", "Diplodocus", and "Stegosaurus". The Late Jurassic formations of Portugal where "Allosaurus" is present are interpreted as having been similar to the Morrison but with a stronger marine influence. Many of the dinosaurs of the Morrison Formation are the same genera as those seen in Portuguese rocks (mainly "Allosaurus", "Ceratosaurus", "Torvosaurus", and "Stegosaurus"), or have a close counterpart ("Brachiosaurus" and "Lusotitan", "Camptosaurus" and "Draconyx").

"Allosaurus" coexisted with fellow large theropods "Ceratosaurus" and "Torvosaurus" in both the United States and Portugal. The three appear to have had different ecological niches, based on anatomy and the location of fossils. Ceratosaurs and torvosaurs may have preferred to be active around waterways, and had lower, thinner bodies that would have given them an advantage in forest and underbrush terrains, whereas allosaurs were more compact, with longer legs, faster but less maneuverable, and seem to have preferred dry floodplains. "Ceratosaurus", better known than "Torvosaurus", differed noticeably from "Allosaurus" in functional anatomy by having a taller, narrower skull with large, broad teeth. "Allosaurus" was itself a potential food item to other carnivores, as illustrated by an "Allosaurus" pubic foot marked by the teeth of another theropod, probably "Ceratosaurus" or "Torvosaurus". The location of the bone in the body (along the bottom margin of the torso and partially shielded by the legs), and the fact that it was among the most massive in the skeleton, indicates that the "Allosaurus" was being scavenged.



</doc>
<doc id="1348" url="https://en.wikipedia.org/wiki?curid=1348" title="AK-47">
AK-47

The AK-47, officially known as the Avtomat Kalashnikova (; also known as the Kalashnikov and AK), is a gas-operated, 7.62×39mm assault rifle, developed in the Soviet Union by Mikhail Kalashnikov. It is the originating firearm of the Kalashnikov rifle (or "AK") family.

Design work on the AK-47 began in 1945. In 1946, the AK-47 was presented for official military trials, and in 1948, the fixed-stock version was introduced into active service with selected units of the Soviet Army. An early development of the design was the "AKS" (S—"Skladnoy" or "folding"), which was equipped with an underfolding metal shoulder stock. In early 1949, the AK-47 was officially accepted by the Soviet Armed Forces and used by the majority of the member states of the Warsaw Pact.

Even after almost seven decades, the model and its variants remain the most popular and widely used assault rifles in the world because of its reliability under harsh conditions, low production costs compared to contemporary Western weapons, availability in virtually every geographic region, and ease of use. The AK-47 has been manufactured in many countries and has seen service with armed forces as well as irregular forces and insurgencies worldwide, and was the basis for developing many other types of individual, crew-served and specialised firearms. , "Of the estimated 500 million firearms worldwide, approximately 100 million belong to the Kalashnikov family, three-quarters of which are AK-47s".

During World War II, the Sturmgewehr 44 assault rifle used by German forces made a deep impression on their Soviet counterparts. The select-fire rifle was chambered for a new intermediate cartridge, the 7.92×33mm Kurz, and combined the firepower of a submachine gun with the range and accuracy of a rifle. On 15 July 1943, an earlier model of the Sturmgewehr was demonstrated before the People's Commissariat of Arms of the USSR. The Soviets were impressed with the weapon and immediately set about developing an intermediate caliber fully automatic rifle of their own, to replace the PPSh-41 submachine guns and outdated Mosin–Nagant bolt-action rifles that armed most of the Soviet Army.

The Soviets soon developed the 7.62×39mm M43 cartridge, the semi-automatic SKS carbine and the RPD light machine gun. Shortly after World War II, the Soviets developed the AK-47 assault rifle, which would quickly replace the SKS in Soviet service. Introduced in 1959, the AKM is a lighter stamped steel version and the most ubiquitous variant of the entire AK series of firearms. In the 1960s, the Soviets introduced the RPK light machine gun, an AK type weapon with a stronger receiver, a longer heavy barrel, and a bipod, that would eventually replace the RPD light machine gun.

Mikhail Kalashnikov began his career as a weapon designer in 1941, while recuperating from a shoulder wound which he received during the Battle of Bryansk. Kalashnikov himself stated..."I was in the hospital, and a soldier in the bed beside me asked: 'Why do our soldiers have only one rifle for two or three of our men, when the Germans have automatics?' So I designed one. I was a soldier, and I created a machine gun for a soldier. It was called an Avtomat Kalashnikova, the automatic weapon of Kalashnikov—AK—and it carried the year of its first manufacture, 1947."

The AK-47 is best described as a hybrid of previous rifle technology innovations. "Kalashnikov decided to design an automatic rifle combining the best features of the American M1 and the German StG44." Kalashnikov's team had access to these weapons and had no need to "reinvent the wheel". Kalashnikov himself observed: "A lot of Russian Army soldiers ask me how one can become a constructor, and how new weaponry is designed. These are very difficult questions. Each designer seems to have his own paths, his own successes and failures. But one thing is clear: before attempting to create something new, it is vital to have a good appreciation of everything that already exists in this field. I myself have had many experiences confirming this to be so."

There are claims about Kalashnikov copying other designs, like Bulkin's TKB-415 or Simonov's AVS-31.

Kalashnikov started work on a submachine gun design in 1942 and with a light machine gun in 1943. "Early in 1944, Kalashnikov was given some 7.62×39mm M43 cartridges and informed that there were several designers working on weapons for this new Soviet small-arms cartridge. It was suggested to him that this new weapon might well lead to greater things, and he undertook work on the new rifle." In 1944, he entered a design competition with this new 7.62×39mm, semi-automatic, gas-operated, long stroke piston, carbine, strongly influenced by the American M1 Garand. "The rifle that Kalashnikov designed was in the same class as the familiar SKS-45 Simonov with fixed magazine and gas tube above the barrel." However, this new Kalashnikov design lost out to a Simonov design.

In 1946, a new design competition was initiated to develop a new assault rifle. Kalashnikov submitted an entry. It was gas-operated rifle with a short-stroke gas piston above the barrel, a breech-block mechanism similar to his 1944 carbine, and a curved 30-round magazine. Kalashnikov's rifles AK-1 (with a milled receiver) and AK-2 (with a stamped receiver) proved to be reliable weapons and were accepted to a second round of competition along with other designs.

These prototypes (also known as the AK-46) had a rotary bolt, a two-part receiver with separate trigger unit housing, dual controls (separate safety and fire selector switches) and a non-reciprocating charging handle located on the left side of the weapon. This design had many similarities to the STG 44. In late 1946, as the rifles were being tested, one of Kalashnikov's assistants, Aleksandr Zaitsev, suggested a major redesign to improve reliability. At first, Kalashnikov was reluctant, given that their rifle had already fared better than its competitors. Eventually, however, Zaitsev managed to persuade Kalashnikov.

In November 1947, the new prototypes (AK-47s) were completed. It used a long-stroke gas piston above the barrel. The upper and lower receivers were combined into a single receiver. The selector and safety were combined into a single control-lever/dust-cover on the right side of the rifle. And, the bolt-handle was simply attached to the bolt-carrier. This simplified the design and production of the rifle. The first army trial series began in early 1948. The new rifle proved to be reliable under a wide range of conditions with convenient handling characteristics. In 1949, it was adopted by the Soviet Army as "7.62 mm Kalashnikov assault rifle (AK)".

There were many difficulties during the initial phase of production. The first production models had stamped sheet metal receivers with a milled trunnion and butt stock insert, and a stamped body. Difficulties were encountered in welding the guide and ejector rails, causing high rejection rates. Instead of halting production, a heavy machined receiver was substituted for the sheet metal receiver. Even though production of these milled rifles started in 1951, they were officially referred to as AK-49, based on the date their development started, but they are much widely known in the collectors' and current commercial market as "Type 2 AK-47". This was a more costly process, but the use of machined receivers accelerated production as tooling and labor for the earlier Mosin–Nagant rifle's machined receiver were easily adapted. Partly because of these problems, the Soviets were not able to distribute large numbers of the new rifle to soldiers until 1956. During this time, production of the interim SKS rifle continued.

Once the manufacturing difficulties of non milled receivers had been overcome, a redesigned version designated the AKM (M for "modernized" or "upgraded"; in Russian: "Автомат Калашникова Модернизированный [Avtomat Kalashnikova Modernizirovanniy])" was introduced in 1959. This new model used a stamped sheet metal receiver and featured a slanted muzzle brake on the end of the barrel to compensate for muzzle rise under recoil. In addition, a hammer retarder was added to prevent the weapon from firing out of battery (without the bolt being fully closed), during rapid or fully automatic fire. This is also sometimes referred to as a "cyclic rate reducer", or simply "rate reducer", as it also has the effect of reducing the number of rounds fired per minute during fully automatic fire. It was also roughly one-third lighter than the previous model.

Both licensed and unlicensed production of the Kalashnikov weapons abroad were almost exclusively of the AKM variant, partially due to the much easier production of the stamped receiver. This model is the most commonly encountered, having been produced in much greater quantities. All rifles based on the Kalashnikov design are frequently referred to as AK-47s in the West, although this is only correct when applied to rifles based on the original three receiver types. In most former Eastern Bloc countries, the weapon is known simply as the "Kalashnikov" or "AK". The differences between the milled and stamped receivers includes the use of rivets rather than welds on the stamped receiver, as well as the placement of a small dimple above the magazine well for stabilization of the magazine.

In 1974, the Soviets began replacing their AK-47 and AKM rifles with a newer design, the AK-74, which uses 5.45×39mm ammunition. This new rifle and cartridge had only started to be manufactured in Eastern European nations when the Soviet Union collapsed, drastically slowing production of the AK-74 and other weapons of the former Soviet bloc.

The AK-47 was designed to be a simple, reliable fully automatic rifle that could be manufactured quickly and cheaply, using mass production methods that were state of the art in the Soviet Union during the late 1940s. The AK-47 uses a long stroke gas system that is generally associated with great reliability in adverse conditions. The large gas piston, generous clearances between moving parts, and tapered cartridge case design allow the gun to endure large amounts of foreign matter and fouling without failing to cycle.

The AK fires the 7.62×39mm cartridge with a muzzle velocity of .
The cartridge weight is , the projectile weight is . The original Soviet M43 bullets are 123 grain boat-tail bullets with a copper-plated steel jacket, a large steel core, and some lead between the core and the jacket. The AK has excellent penetration when shooting through heavy foliage, walls or a common vehicle's metal body and into an opponent attempting to use these things as cover. The 7.62×39mm M43 projectile does not generally fragment when striking an opponent and has an unusual tendency to remain intact even after making contact with bone. The 7.62×39mm round produces significant wounding in cases where the bullet tumbles (yaws) in tissue, but produces relatively minor wounds in cases where the bullet exits before beginning to yaw. In the absence of yaw, the M43 round can pencil through tissue with relatively little injury.

Most, if not all, of the 7.62×39mm ammunition found today is of the upgraded M67 variety. This variety deleted the steel insert, shifting the center of gravity rearward, and allowing the projectile to destabilize (or yaw) at about , nearly earlier in tissue than the M43 round. This change also reduces penetration in ballistic gelatin to ~ for the newer M67 round versus ~ for the older M43 round. However, the wounding potential of M67 is mostly limited to the small permanent wound channel the bullet itself makes, especially when the bullet yaws.

To fire, the operator inserts a loaded magazine, pulls back and releases the charging handle, and then pulls the trigger. In semi-automatic, the firearm fires only once, requiring the trigger to be released and depressed again for the next shot. In fully automatic, the rifle continues to fire automatically cycling fresh rounds into the chamber until the magazine is exhausted or pressure is released from the trigger. After ignition of the cartridge primer and propellant, rapidly expanding propellant gases are diverted into the gas cylinder above the barrel through a vent near the muzzle. The build-up of gases inside the gas cylinder drives the long-stroke piston and bolt carrier rearward and a cam guide machined into the underside of the bolt carrier, along with an ejector spur on the bolt carrier rail guide, rotates the bolt approximately 35° and unlocks it from the barrel extension via a camming pin on the bolt. The moving assembly has about of free travel, which creates a delay between the initial recoil impulse of the piston and the bolt unlocking sequence, allowing gas pressures to drop to a safe level before the seal between the chamber and the bolt is broken. The AK-47 does not have a gas valve; excess gases are ventilated through a series of radial ports in the gas cylinder. The Kalashnikov operating system offers no primary extraction upon bolt rotation, but uses an extractor claw to eject the spent cartridge case.

The rifle received a barrel with a chrome-lined bore and four right-hand grooves at a 240 mm (1 in 9.45 in) rifling twist rate. The gas block contains a gas channel that is installed at a slanted angle in relation to the bore axis. The muzzle is threaded for the installation of various muzzle devices such as a muzzle brake or a blank-firing adaptor.

The gas block of the AK-47 features a cleaning rod capture or sling loop. Gas relief ports that alleviate gas pressure are placed horizontally in a row on the gas cylinder.

The fire selector is a large lever located on the right side of the rifle, it acts as a dust-cover and prevents the charging handle from being pulled fully to the rear when it is on safe. It is operated by the shooter's right fore-fingers and has 3 settings: safe (up), full-auto (center), and semi-auto (down). The reason for this is that under stress a soldier will push the selector lever down with considerable force bypassing the full-auto stage and setting the rifle to semi-auto. To set the AK-47 to full-auto requires the deliberate action of centering the selector lever. To operate the fire selector lever, right handed shooters have to briefly remove their right hand from the pistol grip, which is ergonomically sub-optimal. Some AK-type rifles also have a more traditional selector lever on the left side of the receiver just above the pistol grip. This lever is operated by the shooter's right thumb and has three settings: safe (forward), full-auto (center), and semi-auto (backward).

The AK-47 uses a notched rear tangent iron sight calibrated in increments from . The front sight is a post adjustable for elevation in the field. Horizontal adjustment requires a special drift tool and is done by the armory before issue or if the need arises by an armorer after issue. The sight line elements are approximately over the bore axis. The "point-blank range" battle zero setting "П" standing for "постоянная" (constant) on the 7.62×39mm AK-47 rear tangent sight element corresponds to a zero. These settings mirror the Mosin–Nagant and SKS rifles, which the AK-47 replaced. For the AK-47 combined with service cartridges, the 300 m battle zero setting limits the apparent "bullet rise" within approximately relative to the line of sight. Soldiers are instructed to fire at any target within this range by simply placing the sights on the center of mass (the belt buckle, according to Russian and former Soviet doctrine) of the enemy target. Any errors in range estimation are tactically irrelevant, as a well-aimed shot will hit the torso of the enemy soldier. Some AK-type rifles have a front sight with a flip-up luminous dot that is calibrated at , for improved night fighting.

The AK-47 was originally equipped with a buttstock, handguard and an upper heat guard made from solid wood. With the introduction of the Type 3 receiver the buttstock, lower handguard and upper heatguard were manufactured from birch plywood laminates. Such engineered woods are stronger and resist warping better than the conventional one-piece patterns, do not require lengthy maturing, and are cheaper. The wooden furniture was finished with the Russian amber shellac finishing process. AKS and AKMS models featured a downward-folding metal butt-stock similar to that of the German MP40 submachine-gun, for use in the restricted space in the BMP infantry combat vehicle, as well as by paratroops. All 100 series AKs use plastic furniture with side-folding stocks.

The standard magazine capacity is 30 rounds. There are also 10, 20, and 40-round box magazines, as well as 75-round drum magazines.

The AK-47's standard 30-round magazines have a pronounced curve that allows them to smoothly feed ammunition into the chamber. Their heavy steel construction combined with "feed-lips" (the surfaces at the top of the magazine that control the angle at which the cartridge enters the chamber) machined from a single steel billet makes them highly resistant to damage. These magazines are so strong that "Soldiers have been known to use their mags as hammers, and even bottle openers". This contributes to the AK-47 magazine being more reliable, but makes it heavier than U.S. and NATO magazines.

The early slab-sided steel AK-47 30-round detachable box magazines had sheet-metal bodies and weigh empty. The later steel AKM 30-round magazines had lighter sheet-metal bodies with prominent reinforcing ribs weighing empty. To further reduce weight, a light weight magazine with an aluminum body with a prominent reinforcing waffle rib pattern weighing empty was developed for the AKM that proved to be too fragile and the small issued amount of these magazines were quickly withdrawn from service. As a replacement steel-reinforced 30-round plastic 7.62×39mm box magazines were introduced. These rust-colored magazines weigh empty and are often mistakenly identified as being made of Bakelite (a phenolic resin), but were actually fabricated from two-parts of AG-S4 molding compound (a glass-reinforced phenol-formaldehyde binder impregnated composite), assembled using an epoxy resin adhesive. Noted for their durability, these magazines did however compromise the rifle's camouflage and lacked the small horizontal reinforcing ribs running down both sides of the magazine body near the front that were added on all later plastic magazine generations. A second generation steel-reinforced dark-brown (color shades vary from maroon to plum to near black) 30-round 7.62×39mm magazine was introduced in the early 1980s, fabricated from ABS plastic. The third generation steel-reinforced 30-round 7.62×39mm magazine is similar to the second generation, but is darker colored and has a matte nonreflective surface finish. The current issue steel-reinforced matte true black nonreflective surface finished 7.62×39mm 30-round magazines, fabricated from ABS plastic weigh empty.

Early steel AK-47 magazines are long; the later ribbed steel AKM and newer plastic 7.62×39mm magazines are about shorter.

The transition from steel to mainly plastic magazines yields a significant weight reduction and allows a soldier to carry more ammunition for the same weight.

All 7.62×39mm AK magazines are backwards compatible with older AK variants.

10.12 kg (22.3 lb) is the maximum amount of ammo that the average soldier can comfortably carry. It also allows for best comparison of the three most common 7.62×39mm AK magazines.

Most Yugoslavian and some East German AK magazines were made with cartridge followers that hold the bolt open when empty; however, most AK magazine followers allow the bolt to close when the magazine is empty.

Accessories supplied with the rifle include a long 6H3 bayonet featuring a long spear point blade. The AK-47 bayonet is installed by slipping the diameter muzzle ring around the muzzle and latching the handle down on the bayonet lug under the front sight base.

All current model AKM rifles can mount under-barrel 40 mm grenade launchers such as the GP-25 and its variants, which can fire up to 20 rounds per minute and have an effective range of up to 400 metres. The main grenade is the VOG-25 (VOG-25M) fragmentation grenade which has a 6 m (9 m) (20 ft (30 ft)) lethality radius. The VOG-25P/VOG-25PM ("jumping") variant explodes above the ground.

The AK-47 can also mount a (rarely used) cup-type grenade launcher, the Kalashnikov grenade launcher that fires standard RGD-5 Soviet hand-grenades. The maximum effective range is approximately 150 meters. This launcher can also be used to launch tear-gas and riot control grenades.

All current AKs (100 series) and some older models, have side rails for mounting a variety of scopes and sighting devices, such as the PSO-1 Optical Sniper Sight. The side rails allow for the removal and remounting of optical accessories without interfering with the zeroing of the optic. However, the 100 series side folding stocks cannot be folded with the optics mounted.

The AK-47 and its variants have been and are made in dozens of countries, with "quality ranging from finely engineered weapons to pieces of questionable workmanship." As a result, the AK-47 has a service/system life of approximately 6,000, to 10,000, to 15,000 rounds. The AK-47 was designed to be a cheap, simple, easy to manufacture assault rifle, perfectly matching Soviet military doctrine that treats equipment and weapons as disposable items. As units are often deployed without adequate logistical support and dependent on "battlefield cannibalization" for resupply, it is actually more cost-effective to replace rather than repair weapons.

The AK-47 has small parts and springs that need to be replaced every few thousand rounds. However, "Every time it is disassembled beyond the field stripping stage, it will take some time for some parts to regain their fit, some parts may tend to shake loose and fall out when firing the weapon. Some parts of the AK-47 line are riveted together. Repairing these can be quite a hassle, since the end of the rivet has to be ground off and a new one set after the part is replaced."



For the further developed AK models, see Kalashnikov rifles.

Manufacturing countries of AK-47 and its variants in alphabetical order.
A private company Kalashnikov Concern (formerly Izhmash) from Russia has repeatedly claimed that the majority of foreign manufacturers are producing AK-type rifles without proper licensing.

The AK-47's accuracy has always been considered to be "good enough" to hit an adult male torso out to about , though even experts firing from prone or bench rest positions at this range were observed to have difficulty placing ten consecutive rounds on target. Later designs did not significantly improve its accuracy. An AK can fire a 10-shot group of at , and at The newer stamped-steel receiver AKM models, while more rugged and less prone to metal fatigue, are actually less accurate than the forged/milled receivers of their predecessors: the milled AK-47s are capable of shooting groups at , whereas the stamped AKMs are capable of shooting groups at .

The best shooters are able to hit a man-sized target at within five shots (firing from prone or bench rest position) or ten shots (standing).

The single-shot hit-probability on the NATO E-type Silhouette Target (a human upper body half and head silhouette) of the AK-47 and the later developed AK-74, M16A1 and M16A2 assault rifles were measured by the US military under ideal proving ground conditions in the 1980s as follows:

The following table represents the Russian method for determining accuracy, which is far more complex than Western methods. In the West, one fires a group of shots into the target and then simply measures the overall diameter of the group. The Russians, on the other hand, fire a group of shots into the target. They then draw two circles on the target, one for the maximum vertical dispersion of hits and one for the maximum horizontal dispersion of hits. They then disregard the hits on the outer part of the target and only count half of the hits (50% or R) on the inner part of the circles. This dramatically reduces the overall diameter of the groups. They then use both the vertical and horizontal measurements of the reduced groups to measure accuracy. This circular error probable method used by the Russians and other European militaries cannot be converted and is not comparable to US military methods for determining rifle accuracy. When the R results are doubled the hit probability increases to 93.7%.

The vertical and horizontal mean (R) deviations with service ammunition at for AK platforms are.


Throughout the world, the AK and its variants are commonly used by governments, revolutionaries, terrorists, criminals, and civilians alike. In some countries, such as Somalia, Rwanda, Mozambique, Congo and Tanzania, the prices for Black Market AKs are between $30 and $125 per weapon and prices have fallen in the last few decades due to mass counterfeiting. In Kenya, "an AK-47 fetches five head of cattle (about 10,000 Kenya shillings or 100 U.S. dollars) when offered for barter, but costs almost half that price when cash is paid". There are places around the world where AK type weapons can be purchased on the black market "for as little as $6, or traded for a chicken or a sack of grain".

The AK-47 has also spawned a cottage industry of sorts and has been copied and manufactured (one gun at a time) in small shops around the world (see Khyber Pass Copy). The estimated numbers of AK-type weapons vary greatly. The Small Arms Survey suggest that "between 70 and 100 million of these weapons have been produced since 1947". The World Bank estimates that out of the 500 million total firearms available worldwide, 100 million are of the Kalashnikov family, and 75 million are AK-47s. Because AK-type weapons have been made in many countries, often illicitly, it is impossible to know how many really exist.

The AK-47 has been used in the following conflicts:


During the Cold War, the Soviet Union and the People's Republic of China, as well as United States and other NATO nations supplied arms and technical knowledge to numerous countries and rebel forces around the world. During this time the Western countries used relatively expensive automatic rifles, such as the FN FAL, the HK G3, the M14, and the M16. In contrast, the Russians and Chinese used the AK-47; its low production cost and ease of manufacture allow them to make AKs in vast numbers.

In the pro-communist states, the AK-47 became a symbol of the Third World revolution. They were utilized in the Cambodian Civil War and the Cambodian–Vietnamese War. During the 1980s, the Soviet Union became the principal arms dealer to countries embargoed by Western nations, including Middle Eastern nations such as Iran, Libya, and Syria, which welcomed Soviet Union backing against Israel. After the fall of the Soviet Union, AK-47s were sold both openly and on the black market to any group with cash, including drug cartels and dictatorial states, and more recently they have been seen in the hands of Islamic groups such as Al-Qaeda, ISIL, and the Taliban in Afghanistan and Iraq, and FARC, Ejército de Liberación Nacional guerrillas in Colombia.

In Russia, the Kalashnikov is a tremendous source of national pride. "The family of the inventor of the world's most famous assault rifle, Mikhail Kalashnikov, has authorized German engineering company MMI to use the well-known Kalashnikov name on a variety of not-so-deadly goods." In recent years, Kalashnikov Vodka has been marketed with souvenir bottles in the shape of the AK-47 Kalashnikov. There are also Kalashnikov watches, umbrellas, and knives.

The Kalashnikov Museum (also called the AK-47 museum) opened on 4 November 2004 in Izhevsk, Udmurt Republic. This city is in the Ural Region of Russia. The museum chronicles the biography of General Kalashnikov and documents the invention of the AK-47. The museum complex of Kalashnikov's small arms, a series of halls, and multimedia exhibitions are devoted to the evolution of the AK-47 assault rifle and attracts 10,000 monthly visitors. Nadezhda Vechtomova, the museum director, stated in an interview that the purpose of the museum is to honor the ingenuity of the inventor and the hard work of the employees and to "separate the weapon as a weapon of murder from the people who are producing it and to tell its history in our country". Google Earth view of the Kalashnikov Museum

On 19 September 2017 a monument of Kalashnikov was unveiled in central Moscow. A protester, later detained by police, attempted to unfurl a banner reading "a creator of weapons is a creator of death".

The proliferation of this weapon is reflected by more than just numbers. The AK-47 is included in the flag of Mozambique and its emblem, an acknowledgment that the country gained its independence in large part through the effective use of their AK-47s. It is also found in the coats of arms of East Timor and the revolution era Burkina Faso, as well as in the flags of Hezbollah, Syrian Resistance, FARC-EP, the New People's Army, TKP/TIKKO and the International Revolutionary People's Guerrilla Forces.

Some Western countries associate the AK-47 with their enemies; both Cold War era and present-day. For example, Western movies often portray criminals, gang members and terrorists using AK-47s. For these reasons, in the U.S. and Western Europe, the AK-47 is stereotypically regarded as the weapon of choice of insurgents, gangsters and terrorists. Conversely, throughout the developing world, the AK-47 can be positively attributed with revolutionaries against foreign occupation, imperialism, or colonialism.

The AK-47 made an appearance in U.S. popular culture as a recurring focus in the Nicolas Cage film "Lord of War" (2005). Numerous monologues in the movie focus on the weapon, and its effects on global conflict and the gun running market.

In 2006, the Colombian musician and peace activist César López devised the "escopetarra", an AK converted into a guitar. One sold for US$17,000 in a fundraiser held to benefit the victims of anti-personnel mines, while another was exhibited at the United Nations' Conference on Disarmament.

In Mexico, the AK-47 is known as "Cuerno de Chivo" (literally "Goat's Horn") because of its curved magazine design. It is one of the weapons of choice of Mexican drug cartels. It is sometimes mentioned in Mexican folk music lyrics.





</doc>
<doc id="1349" url="https://en.wikipedia.org/wiki?curid=1349" title="Atanasoff–Berry computer">
Atanasoff–Berry computer

The Atanasoff–Berry computer (ABC) was the first automatic electronic digital computer, an early electronic digital computing device that has remained somewhat obscure. The ABC's priority is debated among historians of computer technology, because it was neither programmable, nor Turing-complete.

Conceived in 1937, the machine was built by Iowa State College mathematics and physics professor John Vincent Atanasoff with the help of graduate student Clifford Berry. It was designed only to solve systems of linear equations and was successfully tested in 1942. However, its intermediate result storage mechanism, a paper card writer/reader, was not perfected, and when John Vincent Atanasoff left Iowa State College for World War II assignments, work on the machine was discontinued. The ABC pioneered important elements of modern computing, including binary arithmetic and electronic switching elements, but its special-purpose nature and lack of a changeable, stored program distinguish it from modern computers. The computer was designated an IEEE Milestone in 1990.

Atanasoff and Berry's computer work was not widely known until it was rediscovered in the 1960s, amidst conflicting claims about the first instance of an electronic computer. At that time ENIAC, that had been created by John Mauchly and J. Presper Eckert, was considered to be the first computer in the modern sense, but in 1973 a U.S. District Court invalidated the ENIAC patent and concluded that the ENIAC inventors had derived the subject matter of the electronic digital computer from Atanasoff (see Patent dispute). When, in the mid-1970s, the secrecy surrounding the British World War II development of the Colossus computers that pre-dated ENIAC, was lifted and Colossus was described at a conference in Los Alamos, New Mexico in June 1976, John Mauchly and Konrad Zuse were reported to have been astonished.

According to Atanasoff's account, several key principles of the Atanasoff–Berry Computer were conceived in a sudden insight after a long nighttime drive to Rock Island, Illinois, during the winter of 1937–38. The ABC innovations included electronic computation, binary arithmetic, parallel processing, regenerative capacitor memory, and a separation of memory and computing functions. The mechanical and logic design was worked out by Atanasoff over the next year. A grant application to build a proof of concept prototype was submitted in March 1939 to the Agronomy department which was also interested in speeding up computation for economic and research analysis. $5,000 of further funding () to complete the machine came from the nonprofit Research Corporation of New York City.

The ABC was built by Atanasoff and Berry in the basement of the physics building at Iowa State College during 1939–42. The initial funds were released in September, and the 11-tube prototype was first demonstrated in October 1939. A December demonstration prompted a grant for construction of the full-scale machine. The ABC was built and tested over the next two years. A January 15, 1941 story in the "Des Moines Register" announced the ABC as "an electrical computing machine" with more than 300 vacuum tubes that would "compute complicated algebraic equations" (but gave no precise technical description of the computer). The system weighed more than . It contained approximately of wire, 280 dual-triode vacuum tubes, 31 thyratrons, and was about the size of a desk.

It was not a Turing complete computer, which distinguishes it from more general machines, like contemporary Konrad Zuse's Z3 (1941), or later machines like the 1946 ENIAC, the 1949 EDVAC, the University of Manchester designs, or Alan Turing's post-War design of ACE at NPL and elsewhere. Nor did it implement the stored program architecture that made practical fully general-purpose, reprogrammable computers.
The machine was, however, the first to implement three critical ideas that are still part of every modern computer:

The memory of the Atanasoff–Berry Computer was a system called "regenerative capacitor memory", which consisted of a pair of drums, each containing 1600 capacitors that rotated on a common shaft once per second. The capacitors on each drum were organized into 32 "bands" of 50 (30 active bands and two spares in case a capacitor failed), giving the machine a speed of 30 additions/subtractions per second. Data was represented as 50-bit binary fixed-point numbers. The electronics of the memory and arithmetic units could store and operate on 60 such numbers at a time (3000 bits).

The alternating current power line frequency of 60 Hz was the primary clock rate for the lowest-level operations.

The arithmetic logic functions were fully electronic, implemented with vacuum tubes. The family of logic gates ranged from inverters to two and three input gates. The input and output levels and operating voltages were compatible between the different gates. Each gate consisted of one inverting vacuum tube amplifier, preceded by a resistor divider input network that defined the logical function. The control logic functions, which only needed to operate once per drum rotation and therefore did not require electronic speed, were electromechanical, implemented with relays.

Although the Atanasoff–Berry Computer was an important step up from earlier calculating machines, it was not able to run entirely automatically through an entire problem. An operator was needed to operate the control switches to set up its functions, much like the electro-mechanical calculators and unit record equipment of the time. Selection of the operation to be performed, reading, writing, converting to or from binary to decimal, or reducing a set of equations was made by front panel switches and in some cases jumpers.

There were two forms of input and output: primary user input and output and an intermediate results output and input. The intermediate results storage allowed operation on problems too large to be handled entirely within the electronic memory. (The largest problem that could be solved without the use of the intermediate output and input was two simultaneous equations, a trivial problem.)

Intermediate results were binary, written onto paper sheets by electrostatically modifying the resistance at 1500 locations to represent 30 of the 50-bit numbers (one equation). Each sheet could be written or read in one second. The reliability of the system was limited to about 1 error in 100,000 calculations by these units, primarily attributed to lack of control of the sheets' material characteristics. In retrospect a solution could have been to add a parity bit to each number as written. This problem was not solved by the time Atanasoff left the university for war-related work.

Primary user input was decimal, via standard IBM 80-column punched cards and output was decimal, via a front panel display.

The ABC was designed for a specific purpose, the solution of systems of simultaneous linear equations. It could handle systems with up to twenty-nine equations, a difficult problem for the time. Problems of this scale were becoming common in physics, the department in which John Atanasoff worked. The machine could be fed two linear equations with up to twenty-nine variables and a constant term and eliminate one of the variables. This process would be repeated manually for each of the equations, which would result in a system of equations with one fewer variable. Then the whole process would be repeated to eliminate another variable.

George W. Snedecor, the head of Iowa State's Statistics Department, was very likely the first user of an electronic digital computer to solve real-world mathematics problems. He submitted many of these problems to Atanasoff.

On June 26, 1947, J. Presper Eckert and John Mauchly were the first to file for patent on a digital computing device (ENIAC), much to the surprise of Atanasoff. The ABC had been examined by John Mauchly in June 1941, and Isaac Auerbach, a former student of Mauchly's, alleged that it influenced his later work on ENIAC, although Mauchly denied this. The ENIAC patent did not issue until 1964, and by 1967 Honeywell sued Sperry Rand in an attempt to break the ENIAC patents, arguing the ABC constituted prior art. The United States District Court for the District of Minnesota released its judgement on October 19, 1973, finding in "Honeywell v. Sperry Rand" that the ENIAC patent was a derivative of John Atanasoff's invention.

Campbell-Kelly and Aspray conclude:
The case was legally resolved on October 19, 1973 when U.S. District Judge Earl R. Larson held the ENIAC patent invalid, ruling that the ENIAC derived many basic ideas from the Atanasoff–Berry Computer. Judge Larson explicitly stated,
Herman Goldstine, one of the original developers of ENIAC wrote:

The original ABC was eventually dismantled in 1948, when the University converted the basement to classrooms, and all of its pieces except for one memory drum were discarded.

In 1997, a team of researchers led by John Gustafson from Ames Laboratory (located on the Iowa State campus) finished building a working replica of the Atanasoff–Berry Computer at a cost of $350,000 (equivalent to $ million in ). The replica ABC is now on permanent display in the first floor lobby of the Durham Center for Computation and Communication at Iowa State University. , it is on loan to the Computer History Museum in Mountain View, California for a major exhibition.





</doc>
<doc id="1354" url="https://en.wikipedia.org/wiki?curid=1354" title="Andes">
Andes

The Andes or Andean Mountains () are the longest continental mountain range in the world, forming a continuous highland along the western edge of South America. The Andes also have the 2nd most elevated highest peak of any mountain range, only behind the Himalayas. The range is long, wide (widest between 18° south and 20° south latitude), and has an average height of about . The Andes extend from north to south through seven South American countries: Venezuela, Colombia, Ecuador, Peru, Bolivia, Chile and Argentina.

Along their length, the Andes are split into several ranges, separated by intermediate depressions. The Andes are the location of several high plateaus – some of which host major cities such as Quito, Bogotá, Cali, Arequipa, Medellín, Sucre, Mérida and La Paz. The Altiplano plateau is the world's second-highest after the Tibetan plateau. These ranges are in turn grouped into three major divisions based on climate: the Tropical Andes, the Dry Andes, and the Wet Andes.

The Andes Mountains are the world's highest mountain range outside Asia. The highest mountain outside Asia, Argentina's Mount Aconcagua, rises to an elevation of about above sea level. The peak of Chimborazo in the Ecuadorian Andes is farther from the Earth's center than any other location on the Earth's surface, due to the equatorial bulge resulting from the Earth's rotation. The world's highest volcanoes are in the Andes, including Ojos del Salado on the Chile-Argentina border, which rises to .

The Andes are also part of the American Cordillera, a chain of mountain ranges (cordillera) that consists of an almost continuous sequence of mountain ranges that form the western "backbone" of North America, Central America, South America and Antarctica.

The etymology of the word "Andes" has been debated. The majority consensus is that it derives from the Quechua word , which means "east" as in "Antisuyu" (Quechua for "east region"), one of the four regions of the Inca Empire.

The Andes can be divided into three sections:

In the northern part of the Andes, the isolated Sierra Nevada de Santa Marta range is often considered to be part of the Andes. The term "cordillera" comes from the Spanish word "cordel", meaning "rope". The Andes range is about wide throughout its length, except in the Bolivian flexure where it is about wide. The Leeward Antilles islands Aruba, Bonaire, and Curaçao, which lie in the Caribbean Sea off the coast of Venezuela, were thought to represent the submerged peaks of the extreme northern edge of the Andes range, but ongoing geological studies indicate that such a simplification does not do justice to the complex tectonic boundary between the South American and Caribbean plates.

The Andes are a Mesozoic–Tertiary orogenic belt of mountains along the Pacific Ring of Fire, a zone of volcanic activity that encompasses the Pacific rim of the Americas as well as the Asia-Pacific region. The Andes are the result of tectonic plate processes, caused by the subduction of oceanic crust beneath the South American Plate. It is the result of a convergent plate boundary between the Nazca Plate and the South American Plate. The main cause of the rise of the Andes is the compression of the western rim of the South American Plate due to the subduction of the Nazca Plate and the Antarctic Plate. To the east, the Andes range is bounded by several sedimentary basins, such as Orinoco, Amazon Basin, Madre de Dios and Gran Chaco, that separate the Andes from the ancient cratons in eastern South America. In the south, the Andes share a long boundary with the former Patagonia Terrane. To the west, the Andes end at the Pacific Ocean, although the Peru-Chile trench can be considered their ultimate western limit. From a geographical approach, the Andes are considered to have their western boundaries marked by the appearance of coastal lowlands and a less rugged topography. The Andes Mountains also contain large quantities of iron ore located in many mountains within the range.

The Andean orogen has a series of bends or oroclines. The Bolivian Orocline is a seaward concave bending in the coast of South America and the Andes Mountains at about 18° S. At this point, the orientation of the Andes turns from Northwest in Peru to South in Chile and Argentina. The Andean segment north and south of the orocline have been rotated 15° to 20° counter clockwise and clockwise respectively. The Bolivian Orocline area overlaps with the area of maximum width of the Altiplano Plateau and according to Isacks (1988) the orocline is related to crustal shortening. The specific point at 18° S where the coastline bends is known as the "Arica Elbow". Further south lies the Maipo Orocline a more subtle orocline between 30° S and 38°S with a seaward-concave break in trend at 33° S. Near the southern tip of the Andes lies the Patagonian orocline.

The western rim of the South American Plate has been the place of several pre-Andean orogenies since at least the late Proterozoic and early Paleozoic, when several terranes and microcontinents collided and amalgamated with the ancient cratons of eastern South America, by then the South American part of Gondwana.

The formation of the modern Andes began with the events of the Triassic when Pangaea began the break up that resulted in developing several rifts. The development continued through the Jurassic Period. It was during the Cretaceous Period that the Andes began to take their present form, by the uplifting, faulting and folding of sedimentary and metamorphic rocks of the ancient cratons to the east. The rise of the Andes has not been constant, as different regions have had different degrees of tectonic stress, uplift, and erosion.

Tectonic forces above the subduction zone along the entire west coast of South America where the Nazca Plate and a part of the Antarctic Plate are sliding beneath the South American Plate continue to produce an ongoing orogenic event resulting in minor to major earthquakes and volcanic eruptions to this day. In the extreme south, a major transform fault separates Tierra del Fuego from the small Scotia Plate. Across the wide Drake Passage lie the mountains of the Antarctic Peninsula south of the Scotia Plate which appear to be a continuation of the Andes chain.

The regions immediately east of the Andes experience a series of changes resulting from the Andean orogeny. Parts of the Sunsás Orogen in Amazonian craton disappeared from the surface of earth being overridden by the Andes.
The Sierras de Córdoba, where the effects of the ancient Pampean orogeny can be observed, owe their modern uplift and relief to the Andean orogeny in the Tertiary. Further south in southern Patagonia the onset of the Andean orogeny caused the Magallanes Basin to evolve from being an extensional back-arc basin in the Mesozoic to being a compressional foreland basin in the Cenozoic.

The Andes range has many active volcanoes distributed in four volcanic zones separated by areas of inactivity. The Andean volcanism is a result of subduction of the Nazca Plate and Antarctic Plate underneath the South American Plate. The belt is subdivided into four main volcanic zones that are separated from each other by volcanic gaps. The volcanoes of the belt are diverse in terms of activity style, products and morphology. While some differences can be explained by which volcanic zone a volcano belongs to, there are significant differences inside volcanic zones and even between neighbouring volcanoes. Despite being a type location for calc-alkalic and subduction volcanism, the Andean Volcanic Belt has a large range of volcano-tectonic settings, such as rift systems and extensional zones, transpressional faults, subduction of mid-ocean ridges and seamount chains apart from a large range of crustal thicknesses and magma ascent paths, and different amount of crustal assimilations.

The Andes Mountains host large ore and salt deposits and some of their eastern fold and thrust belt acts as traps for commercially exploitable amounts of hydrocarbons. In the forelands of the Atacama desert some of the largest porphyry copper mineralizations occurs making Chile and Peru the first and second largest exporters of copper in the world. Porphyry copper in the western slopes of the Andes has been generated by hydrothermal fluids (mostly water) during the cooling of plutons or volcanic systems. The porphyry mineralization further benefited from the dry climate that let them largely out of the disturbing actions of meteoric water. The dry climate in the central western Andes has also led to the creation of extensive saltpeter deposits which were extensively mined until the invention of synthetic nitrates. Yet another result of the dry climate are the salars of Atacama and Uyuni, the first one being the largest source of lithium today and the second the world's largest reserve of the element. Early Mesozoic and Neogene plutonism in Bolivia's Cordillera Central created the Bolivian tin belt as well as the famous, now depleted, deposits of Cerro Rico de Potosí.

The climate in the Andes varies greatly depending on latitude, altitude, and proximity to the sea. Temperature, atmospheric pressure and humidity decrease in higher elevations. The southern section is rainy and cool, the central section is dry. The northern Andes are typically rainy and warm, with an average temperature of in Colombia. The climate is known to change drastically in rather short distances. Rainforests exist just miles away from the snow-covered peak Cotopaxi. The mountains have a large effect on the temperatures of nearby areas. The snow line depends on the location. It is at between in the tropical Ecuadorian, Colombian, Venezuelan, and northern Peruvian Andes, rising to in the drier mountains of southern Peru south to northern Chile south to about 30°S, then descending to on Aconcagua at 32°S, at 40°S, at 50°S, and only in Tierra del Fuego at 55°S; from 50°S, several of the larger glaciers descend to sea level.

The Andes of Chile and Argentina can be divided in two climatic and glaciological zones: the Dry Andes and the Wet Andes. Since the Dry Andes extend from the latitudes of Atacama Desert to the area of Maule River, precipitation is more sporadic and there are strong temperature oscillations. The line of equilibrium may shift drastically over short periods of time, leaving a whole glacier in the ablation area or in the accumulation area.

In the high Andes of central Chile and Mendoza Province, rock glaciers are larger and more common than glaciers; this is due to the high exposure to solar radiation.

Though precipitation increases with the height, there are semiarid conditions in the nearly highest mountains of the Andes. This dry steppe climate is considered to be typical of the subtropical position at 32–34° S. The valley bottoms have no woods, just dwarf scrub. The largest glaciers, as e.g. the Plomo glacier and the Horcones glaciers, do not even reach in length and have an only insignificant ice thickness. At glacial times, however, c. 20,000 years ago, the glaciers were over ten times longer. On the east side of this section of the Mendozina Andes, they flowed down to and on the west side to about above sea level. The massifs of Cerro Aconcagua (), Cerro Tupungato () and Nevado Juncal () are tens of kilometres away from each other and were connected by a joint ice stream network. The Andes' dendritic glacier arms, i.e. components of valley glaciers, were up to long, over thick and overspanned a vertical distance of . The climatic glacier snowline (ELA) was lowered from to at glacial times.

The Andean region cuts across several natural and floristic regions due to its extension from Caribbean Venezuela to cold, windy and wet Cape Horn passing through the hyperarid Atacama Desert. Rainforests and tropical dry forests used to encircle much of the northern Andes but are now greatly diminished, especially in the Chocó and inter-Andean valleys of Colombia. Opposite of the humid Andean slopes are the relatively dry Andean slopes in most of western Peru, Chile and Argentina. Along with several Interandean Valles, they are typically dominated by deciduous woodland, shrub and xeric vegetation, reaching the extreme in the slopes near the virtually lifeless Atacama Desert.

About 30,000 species of vascular plants live in the Andes, with roughly half being endemic to the region, surpassing the diversity of any other hotspot. The small tree "Cinchona pubescens", a source of quinine which is used to treat malaria, is found widely in the Andes as far south as Bolivia. Other important crops that originated from the Andes are tobacco and potatoes. The high-altitude "Polylepis" forests and woodlands are found in the Andean areas of Colombia, Ecuador, Peru, Bolivia and Chile. These trees, by locals referred to as Queñua, Yagual and other names, can be found at altitudes of above sea level. It remains unclear if the patchy distribution of these forests and woodlands is natural, or the result of clearing which began during the Incan period. Regardless, in modern times the clearance has accelerated, and the trees are now considered to be highly endangered, with some believing that as little as 10% of the original woodland remains.

The Andes are rich in fauna: With almost 1,000 species, of which roughly 2/3 are endemic to the region, the Andes are the most important region in the world for amphibians.
The diversity of animals in the Andes is high, with almost 600 species of mammals (13% endemic), more than 1,700 species of birds (about 1/3 endemic), more than 600 species of reptile (about 45% endemic), and almost 400 species of fish (about 1/3 endemic).

The vicuña and guanaco can be found living in the Altiplano, while the closely related domesticated llama and alpaca are widely kept by locals as pack animals and for their meat and wool. The crepuscular (active during dawn and dusk) chinchillas, two threatened members of the rodent order, inhabit the Andes' alpine regions. The Andean condor, the largest bird of its kind in the Western Hemisphere, occurs throughout much of the Andes but generally in very low densities. Other animals found in the relatively open habitats of the high Andes include the huemul, cougar, foxes in the genus "Pseudalopex", and, for birds, certain species of tinamous (notably members of the genus "Nothoprocta"), Andean goose, giant coot, flamingos (mainly associated with hypersaline lakes), lesser rhea, Andean flicker, diademed sandpiper-plover, miners, sierra-finches and diuca-finches.

Lake Titicaca hosts several endemics, among them the highly endangered Titicaca flightless grebe and Titicaca water frog. A few species of hummingbirds, notably some hillstars, can be seen at altitudes above , but far higher diversities can be found at lower altitudes, especially in the humid Andean forests ("cloud forests") growing on slopes in Colombia, Ecuador, Peru, Bolivia and far northwestern Argentina. These forest-types, which includes the Yungas and parts of the Chocó, are very rich in flora and fauna, although few large mammals exist, exceptions being the threatened mountain tapir, spectacled bear and yellow-tailed woolly monkey.

Birds of humid Andean forests include mountain-toucans, quetzals and the Andean cock-of-the-rock, while mixed species flocks dominated by tanagers and furnariids commonly are seen – in contrast to several vocal but typically cryptic species of wrens, tapaculos and antpittas.

A number of species such as the royal cinclodes and white-browed tit-spinetail are associated with "Polylepis", and consequently also threatened.

The Andes Mountains form a north-south axis of cultural influences. A long series of cultural development culminated in the expansion of the Inca civilization and Inca Empire in the central Andes during the 15th century. The Incas formed this civilization through imperialistic militarism as well as careful and meticulous governmental management. The government sponsored the construction of aqueducts and roads in addition to preexisting installations. Some of these constructions are still in existence today.

Devastated by European diseases to which they had no immunity and civil wars, in 1532 the Incas were defeated by an alliance composed of tens of thousands of allies from nations they had subjugated (e.g. Huancas, Chachapoyas, Cañaris) and a small army of 180 Spaniards led by Francisco Pizarro. One of the few Inca sites the Spanish never found in their conquest was Machu Picchu, which lay hidden on a peak on the eastern edge of the Andes where they descend to the Amazon. The main surviving languages of the Andean peoples are those of the Quechua and Aymara language families. Woodbine Parish and Joseph Barclay Pentland surveyed a large part of the Bolivian Andes from 1826 to 1827.

In modern times, the largest cities in the Andes are Bogotá, Colombia, with a population of about eight million, Santiago, Chile, and Medellin, Colombia and Cali. Lima is a coastal city adjacent to the Andes and is the largest city of all Andean countries. It is the seat of the Andean Community of Nations.

La Paz, Bolivia's seat of government, is the highest capital city in the world, at an elevation of approximately . Parts of the La Paz conurbation, including the city of El Alto, extend up to . 

Other cities in or near the Andes include Arequipa, Cusco, Huancayo, Cajamarca, Juliaca, Huánuco, Huaraz, and Puno in Peru; Quito, Cuenca, Ambato, Loja, Riobamba, and Ibarra in Ecuador; Cochabamba, Oruro, Sucre, and Tarija in Bolivia; Calama and Rancagua in Chile; Armenia, Cúcuta, Bucaramanga, Ibagué, Pereira, Pasto, Palmira, Popayán, Tunja, Villavicencio, and Manizales in Colombia; and Barquisimeto, San Cristóbal, Mérida, and Valera in Venezuela and Mendoza, Tucumán, Salta, and San Juan in Argentina. The cities of Caracas, Valencia, and Maracay are in the Venezuelan Coastal Range, which is a debatable extension of the Andes at the northern extreme of South America.

Cities and large towns are connected with asphalt-paved roads, while smaller towns are often connected by dirt roads, which may require a four-wheel-drive vehicle.

The rough terrain has historically put the costs of building highways and railroads that cross the Andes out of reach of most neighboring countries, even with modern civil engineering practices. For example, the main crossover of the Andes between Argentina and Chile is still accomplished through the Paso Internacional Los Libertadores. Only recently the ends of some highways that came rather close to one another from the east and the west have been connected. Much of the transportation of passengers is done via aircraft.

However, there is one railroad that connects Chile with Peru via the Andes, and there are others that make the same connection via southern Bolivia. See railroad maps of that region.

There are multiple highways in Bolivia that cross the Andes. Some of these were built during a period of war between Bolivia and Paraguay, in order to transport Bolivian troops and their supplies to the war front in the lowlands of southeastern Bolivia and western Paraguay.

For decades, Chile claimed ownership of land on the eastern side of the Andes. However, these claims were given up in about 1870 during the War of the Pacific between Chile, the allied Bolivia and Peru, in a diplomatic deal to keep Peru out of the war. The Chilean Army and Chilean Navy defeated the combined forces of Bolivia and Peru, and Chile took over Bolivia's only province on the Pacific Coast, some land from Peru that was returned to Peru decades later. Bolivia has been a completely landlocked country ever since. It mostly uses seaports in eastern Argentina and Uruguay for international trade because its diplomatic relations with Chile have been suspended since 1978.

Because of the tortuous terrain in places, villages and towns in the mountains—to which travel via motorized vehicles is of little use—are still located in the high Andes of Chile, Bolivia, Peru, and Ecuador. Locally, the relatives of the camel, the llama, and the alpaca continue to carry out important uses as pack animals, but this use has generally diminished in modern times. Donkeys, mules, and horses are also useful.

The ancient peoples of the Andes such as the Incas have practiced irrigation techniques for over 6,000 years. Because of the mountain slopes, terracing has been a common practice. Terracing, however, was only extensively employed after Incan imperial expansions to fuel their expanding realm. The potato holds a very important role as an internally consumed staple crop. Maize was also an important crop for these people, and was used for the production of chicha, important to Andean native people. Currently, tobacco, cotton and coffee are the main export crops. Coca, despite eradication programmes in some countries, remains an important crop for legal local use in a mildly stimulating herbal tea, and, both controversially and illegally, for the production of cocaine.

In unirrigated land, pasture is the most common type of land use. In the rainy season (summer), part of the rangeland is used for cropping (mainly potatoes, barley, broad beans and wheat).

Irrigation is helpful in advancing the sowing data of the summer crops which guarantees an early yield in the period of food shortage. Also, by early sowing, maize can be cultivated higher up in the mountains (up to ). In addition it makes cropping in the dry season (winter) possible and allows the cultivation of frost resistant vegetable crops like onion and carrot.

The Andes rose to fame for their mineral wealth during the Spanish conquest of South America. Although Andean Amerindian peoples crafted ceremonial jewelry of gold and other metals, the mineralizations of the Andes were first mined in large scale after the Spanish arrival. Potosí in present-day Bolivia and Cerro de Pasco in Peru were one of the principal mines of the Spanish Empire in the New World. Río de la Plata and Argentina derive their names from the silver of Potosí.

Currently, mining in the Andes of Chile and Peru places these countries as the first and third major producers of copper in the world. Peru also contains the 4th largest goldmine in the world: the Yanacocha. The Bolivian Andes produce principally tin although historically silver mining had a huge impact on the economy of 17th century Europe.

There is a long history of mining in the Andes, from the Spanish silver mines in Potosí in the 16th century to the vast current porphyry copper deposits of Chuquicamata and Escondida in Chile and Toquepala in Peru. Other metals including iron, gold and tin in addition to non-metallic resources are important.

This list contains some of the major peaks in the Andes mountain range. The highest peak is Aconcagua of Argentina (see below).














</doc>
<doc id="1356" url="https://en.wikipedia.org/wiki?curid=1356" title="Ancylopoda">
Ancylopoda

Ancylopoda is a group of browsing, herbivorous, mammals in the Perissodactyla that show long, curved and cleft claws. Morphological evidence indicates the Ancylopoda diverged from the tapirs, rhinoceroses and horses (Euperissodactyla) after the Brontotheria, however earlier authorities such as Osborn sometimes considered the Ancylopoda to be outside Perissodactyla or, as was popular more recently, to be related to Brontotheria.

"Macrotherium", which is typically from the middle Miocene of Sansan, in Gers, France, may indicate a distinct genus. Limb-bones resembling those of Macrotherium, but relatively stouter, have been described from the Pliocene beds of Attica and Samos as "Ancylotherium". In the Americas, the names "Morothorium" and "Moropus" have been applied to similar bones, in the belief that they indicated Xenarthrans. "Macrotherium magnum" must have been an animal of about nine feet in length.

The South American genus "Homalodotherium" is sometimes placed in the Ancylopoda, but arguments against this have been given by Professor H. F. Osborn, who considers that the Ancylopoda are directly descended from the Condylarthra.


</doc>
<doc id="1358" url="https://en.wikipedia.org/wiki?curid=1358" title="Anchor">
Anchor

An anchor is a device, normally made of metal, used to connect a vessel to the bed of a body of water to prevent the craft from drifting due to wind or current. The word derives from Latin "ancora", which itself comes from the Greek ἄγκυρα ("ankura").

Anchors can either be temporary or permanent. Permanent anchors are used in the creation of a mooring, and are rarely moved; a specialist service is normally needed to move or maintain them. Vessels carry one or more temporary anchors, which may be of different designs and weights.

A sea anchor is a drogue, not in contact with the seabed. It is used to control a drifting vessel, or to limit the speed of a sailing yacht running "under bare poles" in a storm.

Anchors achieve holding power either by "hooking" into the seabed, or sheer mass, or a combination of the two. Permanent moorings use large masses (commonly a block or slab of concrete) resting on the seabed. Semi-permanent mooring anchors (such as mushroom anchors) and large ship's anchors derive a significant portion of their holding power from their mass, while also hooking or embedding in the bottom. Modern anchors for smaller vessels have metal "flukes" which hook on to rocks on the bottom or bury themselves in soft seabed.

The vessel is attached to the anchor by the "rode" (commonly called "cable" when made of rope, and made of chain in larger vessels), or a combination of these. The ratio of the length of rode to the water depth is known as the scope; generally, the rode should be between 5 and 10 times the depth of the seabed, giving a scope of 5:1 or 10:1; the larger the number, the shallower the angle is between the cable and the seafloor, and the less upwards force is acting on the anchor. A 10:1 scope gives the greatest holding power, but also allows for much more drifting due to the longer amount of cable paid out. Anchoring with sufficient scope and/or heavy chain rode brings the direction of strain close to parallel with the seabed. This is particularly important for light, modern anchors designed to bury in the bottom, where scopes of 5:1 to 7:1 are common, whereas heavy anchors and moorings can use a scope of 3:1, or less. Some modern anchors, such as the Ultra will hold with a scope of 3:1; but, unless the anchorage is crowded, a longer scope will always reduce shock stresses.

Since all anchors that embed themselves in the bottom require the strain to be along the seabed, anchors can be broken out of the bottom by shortening the rope until the vessel is directly above the anchor; at this point the anchor chain is "up and down", in naval parlance. If necessary, motoring slowly around the location of the anchor also helps dislodge it. Anchors are sometimes fitted with a tripping line attached to the crown, by which they can be unhooked from rocks or coral.

The term "aweigh" describes an anchor when it is hanging on the rope and is not resting on the bottom. This is linked to the term "to weigh anchor", meaning to lift the anchor from the sea bed, allowing the ship or boat to move. An anchor is described as "aweigh" when it has been broken out of the bottom and is being hauled up to be "stowed". "Aweigh" should not be confused with "under way", which describes a vessel which is not "moored" to a dock or "anchored", whether or not the vessel is moving through the water.

The earliest anchors were probably rocks, and many rock anchors have been found dating from at least the Bronze Age. Pre-European Maori waka (canoes) used one or more hollowed stones, tied with flax ropes, as anchors. Many modern moorings still rely on a large rock as the primary element of their design. However, using pure mass to resist the forces of a storm only works well as a permanent mooring; a large enough rock would be nearly impossible to move to a new location.

The ancient Greeks used baskets of stones, large sacks filled with sand, and wooden logs filled with lead. According to Apollonius Rhodius and Stephen of Byzantium, anchors were formed of stone, and Athenaeus states that they were also sometimes made of wood. Such anchors held the vessel merely by their weight and by their friction along the bottom. 

Iron was afterwards introduced for the construction of anchors, and an improvement was made by forming them with teeth, or "flukes", to fasten themselves into the bottom. This is the iconic anchor shape most familiar to non-sailors.

This form has been used since antiquity. The Roman Nemi ships of the 1st century AD used this form. The Viking Ladby ship (probably 10th century) used a fluked anchor of this type, made entirely of iron.

The Admiralty Pattern anchor, or simply "Admiralty", also known as a "Fisherman", consists of a central shank with a ring or shackle for attaching the rode. At the other end of the shank there are two arms, carrying the flukes, while the stock is mounted to the shackle end, at ninety degrees to the arms. When the anchor lands on the bottom, it will generally fall over with the arms parallel to the seabed. As a strain comes onto the rode, the stock will dig into the bottom, canting the anchor until one of the flukes catches and digs into the bottom.

The Admiralty Anchor is a reinvention of a classical design, as seen in one of the Nemi ship anchors. This basic design remained unchanged for centuries, with the most significant changes being to the overall proportions, and a move from stocks made of wood to iron stocks in the late 1830s and early 1840s. 

Since one fluke always protrudes up from the set anchor, there is a great tendency of the rode to foul the anchor as the vessel swings due to wind or current shifts. When this happens, the anchor may be pulled out of the bottom, and in some cases may need to be hauled up to be re-set. In the mid-19th century, numerous modifications were attempted to alleviate these problems, as well as improve holding power, including one-armed mooring anchors. The most successful of these "patent anchors", the Trotman Anchor, introduced a pivot where the arms join the shank, allowing the "idle" arm to fold against the shank.

Handling and storage of these anchors requires special equipment and procedures. Once the anchor is hauled up to the hawsepipe, the ring end is hoisted up to the end of a timber projecting from the bow known as the cathead. The crown of the anchor is then hauled up with a heavy tackle until one fluke can be hooked over the rail. This is known as "catting and fishing" the anchor. Before dropping the anchor, the fishing process is reversed, and the anchor is dropped from the end of the cathead.

The stockless anchor, patented in England in 1821, represented the first significant departure in anchor design in centuries. Though their holding-power-to-weight ratio is significantly lower than admiralty pattern anchors, their ease of handling and stowage aboard large ships led to almost universal adoption. In contrast to the elaborate stowage procedures for earlier anchors, stockless anchors are simply hauled up until they rest with the shank inside the hawsepipes, and the flukes against the hull (or inside a recess in the hull).

While there are numerous variations, stockless anchors consist of a set of heavy flukes connected by a pivot or ball and socket joint to a shank. Cast into the crown of the anchor is a set of tripping palms, projections that drag on the bottom, forcing the main flukes to dig in.

Until the mid-20th century, anchors for smaller vessels were either scaled-down versions of admiralty anchors, or simple grapnels. As new designs with greater holding-power-to-weight ratios, a great variety of anchor designs has emerged. Many of these designs are still under patent, and other types are best known by their original trademarked names.

A traditional design, the grapnel is merely a shank with four or more tines. It has a benefit in that, no matter how it reaches the bottom, one or more tines will be aimed to set. In coral, or rock, it is often able to set quickly by hooking into the structure, but may be more difficult to retrieve. A grapnel is often quite light, and may have additional uses as a tool to recover gear lost overboard. Its weight also makes it relatively easy to move and carry, however its shape is generally not very compact and it may be awkward to stow unless a collapsing model is used.

Grapnels rarely have enough fluke area to develop much hold in sand, clay, or mud. It is not unknown for the anchor to foul on its own rode, or to foul the tines with refuse from the bottom, preventing it from digging in. On the other hand, it is quite possible for this anchor to find such a good hook that, without a trip line from the crown, it is impossible to retrieve.

Designed by famous yacht designer L. Francis Herreshoff, this is essentially the same pattern as an admiralty anchor, albeit with small diamond shaped flukes or palms. The novelty of the design lay in the means by which it could be broken down into three pieces for stowage. In use, it still presents all the issues of the admiralty pattern anchor.

Originally designed as a lightweight anchor for seaplanes, this design consists of two plough-like blades mounted to a shank, with a folding stock crossing through the crown of the anchor.

Many manufacturers produce a plough-type anchor, so-named after to its resemblance to an agricultural plough. All such anchors are copied from the original CQR ""secure"", a 1933 design patented in the UK by mathematician Geoffrey Ingram Taylor. 

Plough anchors stow conveniently in a roller at the bow, and have been popular with cruising sailors and private boaters. Ploughs are generally good in all types of seafloor, though not exceptional in any. Contrary to popular belief, the CQR's hinged shank is not to allow the anchor to turn with direction changes rather than breaking out, but actually to prevent the shank's weight from disrupting the fluke's orientation while setting. The hinge can wear out and may trap a sailor's fingers. Some later plough anchors have a rigid shank, such as the Lewmar's "Delta".

A plough anchor has a fundamental flaw: like it namesake, the agricultural plough, it will dig in but then tends to break out back to the surface. Plough anchors sometimes have difficulty setting at all, and instead skip across the seafloor. By contrast, modern efficient anchors tend to be "spade" types that dig ever deeper.

The Delta was developed in the 1980s for commercialization by British marine manufacturer Simpson–Lawrence. It is a plough anchor with a rigid, arched shank. It is described as "self-launching" because it can be dropped from a bow roller simply by paying out the rode, without manual assistance.

American Richard Danforth invented the Danforth pattern in the 1940s for use aboard landing craft. It uses a stock at the crown to which two large flat triangular flukes are attached. The stock is hinged so the flukes can orient toward the bottom (and on some designs may be adjusted for an optimal angle depending on the bottom type). Tripping palms at the crown act to tip the flukes into the seabed. The design is a burying variety, and once well set can develop high resistance. Its lightweight and compact flat design make it easy to retrieve and relatively easy to store; some anchor rollers and hawsepipes can accommodate a fluke-style anchor.

A Danforth will not usually penetrate or hold in gravel or weeds. In boulders and coral it may hold by acting as a hook. If there is much current, or if the vessel is moving while dropping the anchor, it may "kite" or "skate" over the bottom due to the large fluke area acting as a sail or wing.

The FOB HP anchor designed in Brittany in the 1970s is a Danforth variant designed to give increased holding through its use of rounded flukes setting at a 30° angle.

The Fortress is an American aluminum alloy Danforth variant which can be disassembled for storage and it features an adjustable 32° and 45° shank/fluke angle to improve holding capability in common sea bottoms such as hard sand and soft mud. This anchor performed well in a 1989 US Naval Sea Systems Command (NAVSEA) test. and in an August 2014 holding power test that was conducted in the soft mud bottoms of the Chesapeake Bay.

This claw-shaped anchor was designed by Peter Bruce from the Isle of Man in the 1970s. Bruce gained his early reputation from the production of large-scale commercial anchors for ships and fixed installations such as oil rigs. The Bruce and its copies, known generically as "claws", have been adopted on smaller boats (partly because they stow easily on a bow roller) but they are most effective in larger sizes. It was intended to address some of the problems of the only general-purpose option then available, the plough. Claw-types do not always set quickly in most seabeds, but they have the reputation of not breaking out with tide or wind changes, instead slowly turning in the bottom to align with the force.

Bruce anchors can have difficulty penetrating weedy bottoms and grass. They offer a fairly low holding-power-to-weight ratio and generally have to be oversized to compete with newer types. On the other hand, they have a reasonable reputation in boulder seafloors, and they perform relatively well with low rode scopes. They cannot be used with hawsepipes. Many yachtsmen are abandoning the Bruce in favour of more efficient modern anchors, such as the Ultra and the Vulcan.

In recent years there has been significant progress in anchor design. Primarily designed to set very quickly, then generate high holding power, these new generation anchors (mostly proprietary inventions still under patent) are becoming popular with users of small to medium-sized vessels.



These are used where the vessel is permanently or semi-permanently sited, for example in the case of lightvessels or channel marker buoys. The anchor needs to hold the vessel in all weathers, including the most severe storm, but needs to be lifted only occasionally, at most – for example, only if the vessel is to be towed into port for maintenance. An alternative to using an anchor under these circumstances, especially if the anchor need never be lifted at all, may be to use a pile driven into the seabed.

Permanent anchors come in a wide range of types and have no standard form. A slab of rock with an iron staple in it to attach a chain to would serve the purpose, as would any dense object of appropriate weight (for instance, an engine block). Modern moorings may be anchored by augers, which look and act very much like oversized screws drilled into the seabed, or by barbed metal beams pounded in (or even driven in with explosives) like pilings, or by a variety of other non-mass means of getting a grip on the bottom. One method of building a mooring is to use three or more conventional anchors laid out with short lengths of chain attached to a swivel, so no matter which direction the vessel moves, one or more anchors will be aligned to resist the force.

The mushroom anchor is suitable where the seabed is composed of silt or fine sand. It was invented by Robert Stevenson, for use by an 82-ton converted fishing boat, "Pharos", which was used as a lightvessel between 1807 and 1810 near to Bell Rock whilst the lighthouse was being constructed. It was equipped with a 1.5-ton example.

It is shaped like an inverted mushroom, the head becoming buried in the silt. A counterweight is often provided at the other end of the shank to lay it down before it becomes buried.

A mushroom anchor will normally sink in the silt to the point where it has displaced its own weight in bottom material, thus greatly increasing its holding power. These anchors are only suitable for a silt or mud bottom, since they rely upon suction and cohesion of the bottom material, which rocky or coarse sand bottoms lack. The holding power of this anchor is at best about twice its weight until it becomes buried, when it can be as much as ten times its weight. They are available in sizes from about 5 kg up to several tons.

This is an anchor which relies solely on being a heavy weight. It is usually just a large block of concrete or stone at the end of the chain. Its holding power is defined by its weight underwater (i.e. taking its buoyancy into account) regardless of the type of seabed, although suction can increase this if it becomes buried. Consequently, deadweight anchors are used where mushroom anchors are unsuitable, for example in rock, gravel or coarse sand. An advantage of a deadweight anchor over a mushroom is that if it does become dragged, then it continues to provide its original holding force. The disadvantage of using deadweight anchors in conditions where a mushroom anchor could be used is that it needs to be around ten times the weight of the equivalent mushroom anchor.

Auger anchors can be used to anchor permanent moorings, floating docks, fish farms, etc. These anchors, which have one or more slightly pitched self-drilling threads, must be screwed into the seabed with the use of a tool, so require access to the bottom, either at low tide or by use of a diver. Hence they can be difficult to install in deep water without special equipment.

Weight for weight, augers have a higher holding than other permanent designs, and so can be cheap and relatively easily installed, although difficult to set in extremely soft mud.

There is a need in the oil-and-gas industry to resist large anchoring forces when laying pipelines and for drilling vessels. These anchors are installed and removed using a support tug and pennant/pendant wire. Some examples are the Stevin range supplied by Vrijhof Ankers. Large plate anchors such as the Stevmanta are used for permanent moorings.

The elements of anchoring gear include the anchor, the cable (also called a rode), the method of attaching the two together, the method of attaching the cable to the ship, charts, and a method of learning the depth of the water.

Vessels may carry a number of anchors: bower anchors (formerly known as "sheet anchors" ) are the main anchors used by a vessel and normally carried at the bow of the vessel. A kedge anchor is a light anchor used for warping an anchor, also known as "kedging", or more commonly on yachts for mooring quickly or in benign conditions. A stream anchor, which is usually heavier than a "kedge anchor", can be used for kedging or warping in addition to temporary mooring and restraining stern movement in tidal conditions or in waters where vessel movement needs to be restricted, such as rivers and channels. A Killick anchor is a small, possibly improvised, anchor.

Charts are vital to good anchoring. Knowing the location of potential dangers, as well as being useful in estimating the effects of weather and tide in the anchorage, is essential in choosing a good place to drop the hook. One can get by without referring to charts, but they are an important tool and a part of good anchoring gear, and a skilled mariner would not choose to anchor without them.

The depth of water is necessary for determining scope, which is the ratio of length of cable to the depth measured from the highest point (usually the anchor roller or bow chock) to the seabed. For example, if the water is deep, and the anchor roller is above the water, the scope is the ratio between the amount of cable let out and . For this reason it is important to have a reliable and accurate method of measuring the depth of water.

The anchor rode (or "cable") that connects the anchor to the vessel is made up of chain, sometime with rope ("warp"). Large ships will use only chain rode, whereas, to save weight, smaller boats will use a rope/chain combination. All anchors should have some chain rode; chain is heavy but it resists abrasion from coral, sharp rocks, or shellfish beds, whereas a rope warp is susceptible to abrasion. A combination rode should be arranged so that the rope element should be suspended in the water (and not in contact with the sea bed). 

Being strong and elastic, nylon rope is very suitable as an anchor warp. Polyester (Terylene) is stronger but less elastic than nylon. Both ropes sink, so they avoid fouling other craft in crowded anchorages and do not absorb much water. Neither breaks down quickly in sunlight. Polypropylene, "polyprop", is not suited to warps as it floats and is much weaker than nylon and barely stronger than natural fibres. Polyprop breaks down in sunlight and becomes hard and unpleasant to handle. Natural fibres such as manila or hemp are still used in developing nations but absorb much water, are relatively weak and rot. They do give good grip and are often very cheap. 

All anchors should have chain at least equal to the boat's length. Some skippers prefer an all chain warp for added security in coral waters. Boats less than 8 m typically use 6 mm galvanized chain. 8–14 m craft use 9 mm chain and over 14 m use 12 mm chain. The chain should be shackled to the warp through a steel eye or spliced to the chain using a chain splice. The shackle pin should be securely wired. Either galvanized or stainless steel is suitable for eyes and shackles, galvanised steel being the stronger of the two. Larger yachts may add swivels to the rode. These should not be connected to the anchor itself, but should be somewhere in the chain. Most modern stainless steel swivels will pass easily over windlass gypsies and through hawseholes.

In moderate conditions the ratio of warp to water depth should be 4:1. In rougher conditions it should be up to twice this with the extra length giving more stretch to resist the anchor breaking out. There is little benefit in having a scope of more than 8:1.

The basic anchoring consists of determining the location, dropping the anchor, laying out the scope, setting the hook, and assessing where the vessel ends up. The ship will seek a location which is sufficiently protected; has suitable holding ground, enough depth at low tide and enough room for the boat to swing.

The location to drop the anchor should be approached from down wind or down current, whichever is stronger. As the chosen spot is approached, the vessel should be stopped or even beginning to drift back. The anchor should be lowered quickly but under control until it is on the bottom (see anchor windlass). The vessel should continue to drift back, and the cable should be veered out under control so it will be relatively straight.

Once the desired scope is laid out, the vessel should be gently forced astern, usually using the auxiliary motor but possibly by backing a sail. A hand on the anchor line may telegraph a series of jerks and jolts, indicating the anchor is dragging, or a smooth tension indicative of digging in. As the anchor begins to dig in and resist backward force, the engine may be throttled up to get a thorough set. If the anchor continues to drag, or sets after having dragged too far, it should be retrieved and moved back to the desired position (or another location chosen.)

There are techniques of anchoring to limit the swing of a vessel if the anchorage has limited room:

Lowering a concentrated, heavy weight down the anchor line – rope or chain – directly in front of the bow to the seabed behaves like a heavy chain rode and lowers the angle of pull on the anchor. If the weight is suspended off the seabed it acts as a spring or shock absorber to dampen the sudden actions that are normally transmitted to the anchor and can cause it to dislodge and drag. In light conditions, a kellet will reduce the swing of the vessel considerably. In heavier conditions these effects disappear as the rode becomes straightened and the weight ineffective. Known as a "anchor chum weight" or "angel" in the UK.

Using two anchors set approximately 45° apart, or wider angles up to 90°, from the bow is a strong mooring for facing into strong winds. To set anchors in this way, first one anchor is set in the normal fashion. Then, taking in on the first cable as the boat is motored into the wind and letting slack while drifting back, a second anchor is set approximately a half-scope away from the first on a line perpendicular to the wind. After this second anchor is set, the scope on the first is taken up until the vessel is lying between the two anchors and the load is taken equally on each cable.
This moor also to some degree limits the range of a vessel's swing to a narrower oval. Care should be taken that other vessels will not swing down on the boat due to the limited swing range.

(Not to be mistaken with the "Bahamian moor", below.) In the "bow and stern" technique, an anchor is set off each the bow and the stern, which can severely limit a vessel's swing range and also align it to steady wind, current or wave conditions. One method of accomplishing this moor is to set a bow anchor normally, then drop back to the limit of the bow cable (or to double the desired scope, e.g. 8:1 if the eventual scope should be 4:1, 10:1 if the eventual scope should be 5:1, etc.) to lower a stern anchor. By taking up on the bow cable the stern anchor can be set. After both anchors are set, tension is taken up on both cables to limit the swing or to align the vessel.

Similar to the above, a "Bahamian moor" is used to sharply limit the swing range of a vessel, but allows it to swing to a current. One of the primary characteristics of this technique is the use of a swivel as follows: the first anchor is set normally, and the vessel drops back to the limit of anchor cable. A second anchor is attached to the end of the anchor cable, and is dropped and set. A swivel is attached to the middle of the anchor cable, and the vessel connected to that.

The vessel will now swing in the middle of two anchors, which is acceptable in strong reversing currents, but a wind perpendicular to the current may break out the anchors, as they are not aligned for this load.

Also known as "tandem anchoring", in this technique two anchors are deployed in line with each other, on the same rode. With the foremost anchor reducing the load on the aft-most, this technique can develop great holding power and may be appropriate in "ultimate storm" circumstances. It does not limit swinging range, and might not be suitable in some circumstances. There are complications, and the technique requires careful preparation and a level of skill and experience above that required for a single anchor.

"Kedging" or "warping" is a technique for moving or turning a ship by using a relatively light anchor.

In yachts, a kedge anchor is an anchor carried in addition to the main, or bower anchors, and usually stowed aft. Every yacht should carry at least two anchors – the main or "bower" anchor and a second lighter "kedge" anchor. It is used occasionally when it is necessary to limit the turning circle as the yacht swings when it is anchored, such as in a very narrow river or a deep pool in an otherwise shallow area.

For ships, a kedge may be dropped while a ship is underway, or carried out in a suitable direction by a tender or ship's boat to enable the ship to be winched off if aground or swung into a particular heading, or even to be held steady against a tidal or other stream.

Historically, it was of particular relevance to sailing warships which used them to outmaneuver opponents when the wind had dropped but might be used by any vessel in confined, shoal water to place it in a more desirable position, provided she had enough manpower.

Club hauling is an archaic technique. When a vessel is in a narrow channel or on a lee shore so that there is no room to tack the vessel in a conventional manner, an anchor attached to the lee quarter may be dropped from the lee bow. This is deployed when the vessel is head to wind and has lost headway. As the vessel gathers sternway the strain on the cable pivots the vessel around what is now the weather quarter turning the vessel onto the other tack. The anchor is then normally cut away, as it cannot be recovered.

An anchor frequently appears on the flags and coats of arms of institutions involved with the sea, both naval and commercial, as well as of port cities and seacoast regions and provinces in various countries. There also exists in heraldry the "Anchored Cross", or Mariner's Cross, a stylized cross in the shape of an anchor. The symbol can be used to signify 'fresh start' or 'hope'. The New Testament refers to the Christian's hope as "an anchor of the soul" (Hebrews 6:19). In 1887, the Delta Gamma Fraternity adopted the anchor as its badge to signify hope. The Mariner's Cross is also referred to as St. Clement's Cross, in reference to the way this saint was martyred (being tied to an anchor and thrown from a boat into the Black Sea in 102). Anchored crosses are occasionally a feature of coats of arms in which context they are referred to by the heraldic terms "anchry" or "ancre".






</doc>
<doc id="1359" url="https://en.wikipedia.org/wiki?curid=1359" title="Anbar (town)">
Anbar (town)

Anbar () was an ancient and medieval town in central Iraq. It played a role in the Roman–Persian Wars of the 3rd–4th centuries, and briefly became the capital of the Abbasid Caliphate before the founding of Baghdad in 762. It remained a moderately prosperous town through the 10th century, but quickly declined thereafter. As a local administrative centre, it survived until the 14th century, but was later abandoned.

Its ruins are near modern Fallujah. The city gives its name to the Al-Anbar Governorate.

The city is located on the left bank of the Middle Euphrates, at the junction with the Nahr Isa canal, the first of the navigable canals that link the Euphrates to the River Tigris to the east. The origins of the city are unknown, but ancient, perhaps dating to the Babylonian era and even earlier: the local artificial mound of Tell Aswad dates to . 

The town was originally known as Misiche or Massice. As a major crossing point of the Euphrates, and occupying the northernmost point of the complex irrigation network of the Sawad, the town was of considerable strategic significance. As the western gate to central Mesopotamia, it was fortified by the Sasanian ruler Shapur I () to shield his capital, Ctesiphon, from the Roman Empire. After his decisive defeat of the Roman emperor Gordian III at the Battle of Misiche in 244, Shapur renamed the town to Peroz-Shapur ("Pērōz-Šāpūr" or "Pērōz-Šābuhr", from , meaning "Shapur is victorious"; in ; in ). It became known as Pirisapora or Bersabora () to the Greeks and Romans.

The city was fortified by a double wall, possibly through the use of Roman prisoner labour; nevertheless it was sacked and burned in March 363 by the Roman emperor Julian during his invasion of the Sasanian Empire. It was rebuilt by Shapur II. By 420, it is attested as a bishopric, both for the Church of the East and for the Syriac Orthodox Church. The town's garrison was Persian, but it also contained sizeable Arab and Jewish populations. Anbar was adjacent or identical to the Babylonian Jewish center of Nehardea (), and lies a short distance from the present-day town of Fallujah, formerly the Babylonian Jewish center of Pumbedita ().

The city fell to the Rashidun Caliphate in July 633, after a fiercely fought siege. The Arabs retained the name ("Fīrūz Shābūr") for the surrounding district, but the town itself became known as Anbar (Middle Persian word for "granary" or "storehouse") from the granaries in its citadel, a name that had appeared already during the 6th century. According to Baladhuri, the third mosque to be built in Iraq was erected in the city by Sa'd ibn Abi Waqqas. Ibn Abi Waqqas initially considered Anbar as a candidate for the location of one of the first Muslim garrison towns, but the fever and fleas endemic in the area persuaded him otherwise.

According to medieval Arabic sources, most of the inhabitants of the town migrated north to found the city of Hdatta south of Mosul. The famous governor al-Hajjaj ibn Yusuf cleared the canals of the city.

Abu'l-Abbas as-Saffah (), the founder of the Abbasid Caliphate, made it his capital in 752, constructing a new town half a "farsakh" () to the north for his Khurasani troops. There he died and was buried at the palace he had built. His sucessor, al-Mansur (), remained in the city until the founding of Baghdad in 762. The Abbasids also dug the great Nahr Isa canal to the south of the city, which carried water and commerce east to Baghdad. Thee Nahr al-Saqlawiyya or Nahr al-Qarma canal, which branches off from the Euphrates to the west of the city, is sometimes erroneously held to be the Nahr Isa, but it is more likely that it is to be identified with the pre-Islamic Nahr al-Rufayl.

It continued to be a place of much importance throughout the Abbasid period. Caliph Harun al-Rashid () stayed at the town in 799 and in 803. The town's prosperity was founded on agricultural activities, but also on trade between Iraq ans Syria. The town was still prosperous in the early 9th century, but the decline of Abbasid authority during the later 9th century exposed it to Bedouin attacks in 882 and 899. In 927, the Qarmatians under Abu Tahir al-Jannabi sacked the city, and the devastation was compounded by another Bedouin attack two years later. The town's decline accelerated after that: while the early 10th-century geographer Istakhri still calls the town modest but populous, with the ruins of the buildings of as-Saffah still visible, Ibn Hawqal and al-Maqdisi, who wrote a generation later, attest to its decline, and the diminution of its population.

The town was sacked again in 1262 by the Mongols under Kerboka. The Ilkhanids retained Anbar as an administrative centre, a role it retained until the first half of the 14th century; the Ilkhanid minister Shams al-Din Juvayni had a canal dug from the city to Najaf, and the city was surrounded by a wall of sun-dried bricks.

Anbar used to host an Assyrian community from the fifth century: the town was the seat of a bishopric of the Church of the East. The names of fourteen of its bishops of the period 486–1074 are known, three of whom became Chaldean Patriarchs of Babylon.

Anbar is listed by the Catholic Church as a titular see of the Chaldean Catholic Church, established as titular bishopric in 1980.
It has had the following incumbents:

It is now entirely deserted, occupied only by mounds of ruins, whose great number indicate the city's former importance. Its ruins are northwest of Fallujah, with a circumference of some . The remains include traces of the late medieval wall, a square fortification, and the early Islamic mosque. 



</doc>
<doc id="1360" url="https://en.wikipedia.org/wiki?curid=1360" title="Anazarbus">
Anazarbus

Anazarbus (, medieval Ain Zarba; modern Anavarza; ) was an ancient Cilician city. Under the late Roman Empire, it was the capital of Cilicia Secunda. It was destroyed in 1374.

It was situated in Anatolia in modern Turkey, in the present Çukurova (or classical Aleian plain) about 15 km west of the main stream of the present Ceyhan River (or classical Pyramus river) and near its tributary the Sempas Su.

A lofty isolated ridge formed its acropolis. Though some of the masonry in the ruins is certainly pre-Roman, the Suda's identification of it with Cyinda, famous as a treasure city in the wars of Eumenes of Cardia, cannot be accepted in the face of Strabo's express location of Cyinda in western Cilicia.

It was founded by Assyrians. It was situated on the Pyramus. According to the "Suda", the original name of the place was Cyinda or Kyinda or Quinda (); that it was next called Diocaesarea. How the city obtained the name Anazarbus (Ἀνάζαρβος) or Anazarba (Ἀνάζαρβα), as it was also known, is a matter of conjecture. According to Stephanus of Byzantium, after the city was destroyed by an earthquake, the emperor Nerva sent thither one Anazarbus, a man of senatorial rank, who rebuilt the city, and gave to it his own name. This account cannot be accurate, as Valesius remarks, for it was called Anazarbus in Pliny's time. Dioscorides is called a native of Anazarbus; but the period of Dioscorides is not certain. It was also the home of the poet Oppian. Its later name was Caesarea ad Anazarbum, and there are many medals of the place in which it is both named Anazarbus and Caesarea at or under Anazarbus. On the division of Cilicia it became the chief place of the Roman province of Cilicia Secunda, with the title of Metropolis. It suffered dreadfully from an earthquake both in the time of Eastern Roman emperor Justinian I, and, still more, in the reign of his successor Justin I. After Justinian rebuilt the place, it was renamed Justinianopolis or Ioustinianoupolis (Ἰουστινιανούπολις). Rebuilt by Justin I after the earthquake in the 6th century, it became Justinopolis or Ioustinoupolis (Ἰουστινούπολις) (525); but the old name persisted, and when Thoros I, king of Lesser Armenia, made it his capital early in the 12th century, it was known as Anazarva.

Its great natural strength and situation, not far from the mouth of the Sis pass, and near the great road which debouched from the Cilician Gates, made Anazarbus play a considerable part in the struggles between the Eastern Roman Empire and the early Muslim invaders. It had been rebuilt by Harun al-Rashid in 796, refortified at great expense by the Hamdanid Sayf al-Dawla (mid-10th century) and again destroyed in 962 by Nikephoros II Phokas.

In late 1097 or early 1098 it was captured by the armies of the First Crusade and was incorporated into Bohemond's Principality of Antioch. The Crusaders are probably responsible for the construction of an impressive donjon atop the center of the outcrop. Most of the remaining fortifications, including the curtain walls, massive horse-shaped towers, undercrofts, cisterns, and free-standing structures date from the Armenian periods of occupation, which began with the arrival of the Rubenid Baron T‛oros I, . The site briefly exchanged hands between the Greeks and Armenians, until it was formally part of the Armenian Kingdom of Cilicia. Within the fortress are two Armenian chapels and the magnificent (but severely damaged) three-aisle church built by T‛oros I to celebrate his conquests. The church was once surrounded by a continuous, well-executed dedicatory inscription in Armenian.

The Mamluk Empire of Egypt finally destroyed the city in 1374.

The present wall of the lower city is of late construction. It encloses a mass of ruins conspicuous in which are a fine triumphal arch, the colonnades of two streets, a gymnasium, etc. A stadium and a theatre lie outside the walls to the south. The remains of the acropolis fortifications are very interesting, including roads and ditches hewn in the rock. There are no notable structures in the upper town. For picturesqueness the site is not equaled in Cilicia, and it is worthwhile to trace the three fine aqueducts to their sources. A necropolis on the escarpment to the south of the curtain wall can also be seen complete with signs of illegal modern excavations.

A visit in December 2002 showed that the three aqueducts mentioned above have been nearly completely destroyed. Only small, isolated sections are left standing with the largest portion lying in a pile of rubble that stretches the length of where the aqueducts once stood. A powerful earthquake that struck the area in 1945 is thought to be responsible for the destruction.

A modest Turkish farming village (Dilekkaya) lies to the southwest of the ancient city. A small outdoor museum with some of the artifacts collected in the area can be viewed for a small fee. Also nearby are some beautiful mosaics discovered in a farmers field. Inquire at the museum for a viewing.

Anazarbus/Anavarsa was one of a chain of Armenian fortifications stretching through Cilicia. The castle of Sis (modern Kozan, Adana) lies to the north while Tumlu Castle and Yilankale are to the south, and the fortresses of Amouda and Sarvandikar are to the east.

In 2013, excavations uncovered the first known colonnaded double-lane road of the ancient world, 34 meters wide and 2700 meters long, also uncovered the ruins of a church and a bathhouse.

In 2017, archaeologists discovered a limestone statue of the goddess Hygieia and the god Eros. The statue is thought to date to the third or fourth century B.C.

Anazarbus was the capital and so also from 553 (the date of the Second Council of Constantinople) the metropolitan see of the Late Roman province of Cilicia Secunda.

In the 4th century, one of the bishops of Anazarbus was Athanasius, a "consistent expounder of the theology of Arius." His theological opponent, Athanasius of Alexandria, in "De Synodis" 17, 1 refers to Anazarbus as Ναζαρβῶν.

A 6th century "Notitia Episcopatuum" indicates that it had as suffragan sees Epiphania, Alexandria Minor, Irenopolis, Flavias, Castabala and Aegeae. Rhosus was also subject to Anazarbus, but after the 6th century was made exempt, and Mopsuestia was raised to the rank of autcephalous metropolitan see, though without suffragans.

The titular archbishopric was revived in the 18th century as a see of the Latin Catholic church, Anazarbus.

It is vacant, having had the following incumbents, generally of the highest (Metropolitan) rank, "with an episcopal (lowest rank) exception :

In the 19th century, an Armenian Catholic titular bishopric of Anazarbus (of the Armenians) (Anazarbus degli Armeniin Curiate Italian) was established.

It was a suppressed in 1933, having had a single incumbent, of the intermediary (archiepiscopal) rank :





</doc>
<doc id="1361" url="https://en.wikipedia.org/wiki?curid=1361" title="Anagram">
Anagram

An anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. For example, the word "anagram" can be rearranged into "nag a ram", or the word "binary" into "brainy" or the word "adobe" into "abode".

The original word or phrase is known as the "subject" of the anagram. Any word or phrase that exactly reproduces the letters in another order is an anagram. Someone who creates anagrams may be called an "anagrammatist", and the goal of a serious or skilled anagrammatist is to produce anagrams that reflect or comment on their subject.

Anagrams may be created as a commentary on the subject. They may be a synonym or antonym of their subject, a parody, a criticism or satire. For example:
An anagram which means the opposite of its subject is called an "antigram". For example:
They can sometimes change from a proper noun or personal name into an appropriate sentence:

They can change part of speech, such as the adjective "silent" to the verb "listen".

"Anagrams" itself can be anagrammatized as ""Ars magna"" (Latin, 'the great art').

Anagrams can be traced back to the time of the Ancient Greeks, and were then known as "Themuru" or changing, which was to find the hidden and mystical meaning in names.
They were popular throughout Europe during the Middle Ages, for example with the poet and composer Guillaume de Machaut. They are said to go back at least to the Greek poet Lycophron, in the third century BCE; but this relies on an account of Lycophron given by John Tzetzes in the 12th century.

Anagrams in Latin were considered witty over many centuries. "Est vir qui adest", explained below, was cited as the example in Samuel Johnson's "A Dictionary of the English Language". They became hugely popular in the Early Modern period, especially in Germany.

Any historical material on anagrams must always be interpreted in terms of the assumptions and spellings that were current for the language in question. In particular, spelling in English only slowly became fixed. There were attempts to regulate anagram formation, an important one in English being that of George Puttenham's "Of the Anagram or Posy Transposed" in "The Art of English Poesie" (1589).

As a literary game when Latin was the common property of the literate, Latin anagrams were prominent.. Two examples are the change of "Ave Maria, gratia plena, Dominus tecum" (Latin: Hail Mary, full of grace, the Lord [is] with you) into "Virgo serena, pia, munda et immaculata" (Latin: Serene virgin, pious, clean and spotless), and the anagrammatic answer to Pilate's question, "Quid est veritas?" (Latin: What is truth?), namely, "Est vir qui adest" (Latin: It is the man who is here). The origins of these are not documented.

Latin continued to influence letter values (such as I = J, U = V and W = VV). There was an ongoing tradition of allowing anagrams to be "perfect" if the letters were all used once, but allowing for these interchanges. This can be seen in a popular Latin anagram against the Jesuits: "Societas Jesu" turned into "Vitiosa seces" (Latin: Cut off the wicked things). Puttenham, in the time of Elizabeth I of England, wished to start from "Elissabet Anglorum Regina" (Latin: Elizabeth Queen of the English), to obtain "Multa regnabis ense gloria" (Latin: By thy sword shalt thou reign in great renown); he explains carefully that H is "a note of aspiration only and no letter", and that Z in Greek or Hebrew is a mere SS. The rules were not completely fixed in the 17th century. William Camden in his "Remains" commented, singling out some letters—Æ, K, W, and Z—not found in the classical Roman alphabet:

When it comes to the 17th century and anagrams in English or other languages, there is a great deal of documented evidence of learned interest. The lawyer Thomas Egerton was praised through the anagram "gestat honorem" ('he carries honor'); the physician George Ent took the anagrammatic motto "genio surget" ('he rises through spirit/genius'), which requires his first name as "Georgius". James I's courtiers discovered in "James Stuart" "a just master", and converted "Charles James Stuart" into "Claims Arthur's seat" (even at that point in time, the letters I and J were more-or-less interchangeable). Walter Quin, tutor to the future Charles I, worked hard on multilingual anagrams on the name of father James. A notorious murder scandal, the Overbury case, threw up two imperfect anagrams that were aided by typically loose spelling and were recorded by Simonds D'Ewes: "Francis Howard" (for Frances Carr, Countess of Somerset, her maiden name spelled in a variant) became "Car findes a whore", with the letters E hardly counted, and the victim Thomas Overbury, as "Thomas Overburie", was written as "O! O! a busie murther" (an old form of "murder"), with a V counted as U.

William Drummond of Hawthornden, in an essay "On the Character of a Perfect Anagram", tried to lay down rules for permissible substitutions (such as S standing for Z) and letter omissions. William Camden provided a definition of "Anagrammatisme" as "a dissolution of a name truly written into his letters, as his elements, and a new connection of it by artificial transposition, without addition, subtraction or change of any letter, into different words, making some perfect sense applyable (i.e., applicable) to the person named." Dryden in "MacFlecknoe" disdainfully called the pastime the "torturing of one poor word ten thousand ways".

"Eleanor Audeley", wife of Sir John Davies, is said to have been brought before the High Commission in 1634 for extravagances, stimulated by the discovery that her name could be transposed to "Reveale, O Daniel", and to have been laughed out of court by another anagram submitted by Sir John Lambe, the dean of the Arches, "Dame Eleanor Davies", "Never soe mad a ladie".

An example from France was a flattering anagram for Cardinal Richelieu, comparing him to Hercules or at least one of his hands (Hercules being a kingly symbol), where "Armand de Richelieu" became "Ardue main d'Hercule" ("difficult hand of Hercules").

Examples from the 19th century are the transposition of "Horatio Nelson" into "Honor est a Nilo" (Latin: Honor is from the Nile); and of "Florence Nightingale" into "Flit on, cheering angel". The Victorian love of anagramming as recreation is alluded to by the mathematician Augustus De Morgan using his own name as example; "Great Gun, do us a sum!" is attributed to his son William De Morgan, but a family friend John Thomas Graves was prolific, and a manuscript with over 2,800 has been preserved.

With the advent of surrealism as a poetic movement, anagrams regained the artistic respect they had had in the Baroque period. The German poet Unica Zürn, who made extensive use of anagram techniques, came to regard obsession with anagrams as a "dangerous fever", because it created isolation of the author. The surrealist leader André Breton coined the anagram "Avida Dollars" for Salvador Dalí, to tarnish his reputation by the implication of commercialism.

While anagramming is certainly a recreation first, there are ways in which anagrams are put to use, and these can be more serious, or at least not quite frivolous and formless. For example, psychologists use anagram-oriented tests, often called "anagram solution tasks", to assess the implicit memory of young adults and adults alike.

Natural philosophers (astronomers and others) of the 17th century transposed their discoveries into Latin anagrams, to establish their priority. In this way they laid claim to new discoveries, before their results were ready for publication.

Galileo used "smaismrmilmepoetaleumibunenugttauiras" for "Altissimum planetam tergeminum observavi" (Latin: "I have observed the most distant planet to have a triple form") for discovering the rings of Saturn in 1610. Galileo announced his discovery that Venus had phases like the Moon in the form "Hæc immatura a me iam frustra leguntur oy" (Latin: "These immature ones have already been read in vain by me -oy"), that is, when rearranged, "Cynthiæ figuras aemulatur Mater Amorum" (Latin: "The Mother of Loves" [= Venus] "imitates the figures of Cynthia" [= the moon]). In both cases, Johannes Kepler had solved the anagrams incorrectly, assuming they were talking about the Moons of Mars ("Salve, umbistineum geminatum Martia proles") and a red spot on Jupiter ("Macula rufa in Jove est gyratur mathem"), respectively. By coincidence, he turned out to be right about the actual objects existing.

In 1656, Christiaan Huygens, using a better telescope than those available to Galileo, figured that Galileo's earlier observations of Saturn actually meant it had a ring (Galileo's tools were only sufficient to see it as bumps) and, like Galileo, had published an anagram, "aaaaaaacccccdeeeeeghiiiiiiillllmmnnnnnnnnnooooppqrrstttttuuuuu". Upon confirming his observations, three years later he revealed it to mean "Annuto cingitur, tenui, plano, nusquam coherente, ad eclipticam inclinato" (Latin: "It [Saturn] is surrounded by a thin, flat, ring, nowhere touching, inclined to the ecliptic").

When Robert Hooke discovered Hooke's law in 1660, he first published it in anagram form, "ceiiinosssttuv", for "ut tensio, sic vis" (Latin: "as the tension, so the force").

In a related use, from 1975, British naturalist Sir Peter Scott coined the scientific term "Nessiteras rhombopteryx" (Greek: "The monster (or wonder) of Ness with the diamond-shaped fin") for the apocryphal Loch Ness Monster. Shortly afterwards, several London newspapers pointed out that "Nessiteras rhombopteryx" anagrams into "Monster hoax by Sir Peter S". However, Robert Rines, who previously made two underwater photographs allegedly showing the monster, countered that they can also be arranged into "Yes, both pix are monsters, R".

Anagrams are connected to pseudonyms, by the fact that they may conceal or reveal, or operate somewhere in between like a mask that can establish identity. For example, Jim Morrison used an anagram of his name in The Doors song "L.A. Woman", calling himself "Mr. Mojo Risin'". The use of anagrams and fabricated personal names may be to circumvent restrictions on the use of real names, as happened in the 18th century when Edward Cave wanted to get around restrictions imposed on the reporting of the House of Commons. In a genre such as farce or parody, anagrams as names may be used for pointed and satiric effect.

Pseudonyms adopted by authors are sometimes transposed forms of their names; thus "Calvinus" becomes "Alcuinus" (here V = U) or "François Rabelais" = "Alcofribas Nasier". The name "Voltaire" of François Marie Arouet fits this pattern, and is allowed to be an anagram of "Arouet, l[e] j[eune]" (U = V, J = I) that is, "Arouet the younger". Other examples include:

Several of these are "imperfect anagrams", letters having been left out in some cases for the sake of easy pronunciation.

Anagrams used for titles afford scope for some types of wit. Examples:

In Hebrew, the name "Gernot Zippe" (גרנוט ציפה), the inventor of the Zippe-type centrifuge, is an anagram of the word "centrifuge" (צנטריפוגה).

Anagrams are in themselves a recreational activity, but they also make up part of many other games, puzzles and game shows. The Jumble is a puzzle found in many newspapers in the United States requiring the unscrambling of letters to find the solution. Cryptic crossword puzzles frequently use anagrammatic clues, usually indicating that they are anagrams by the inclusion of a descriptive term like "confused" or "in disarray". An example would be "Businessman burst into tears (9 letters)". The solution, "stationer", is an anagram of "into tears", the letters of which have "burst" out of their original arrangement to form the name of a type of "businessman".

Numerous other games and contests involve some element of anagram formation as a basic skill. Some examples:

Multiple anagramming is a technique used to solve some kinds of cryptograms, such as a permutation cipher, a transposition cipher, and the Jefferson disk. Solutions may be computationally found using a Jumble algorithm.

Sometimes, it is possible to "see" anagrams in words, unaided by tools, though the more letters involved the more difficult this becomes. Anagram dictionaries could also be used. Computer programs, known as "anagram servers" "anagram solvers" or "anagrammers", offer a much faster route to creating anagrams, and a large number of these programs are available on the Internet.

The program or server carries out an exhaustive search of a database of words, to produce a list containing every possible combination of words or phrases from the input word or phrase using a jumble algorithm. Some programs (such as "Lexpert") restrict to one-word answers. Many anagram servers (for example, The Words Oracle) can control the search results, by excluding or including certain words, limiting the number or length of words in each anagram, or limiting the number of results. Anagram solvers are often banned from online anagram games. The disadvantage of computer anagram solvers, especially when applied to multi-word anagrams, is their poor understanding of the meaning of the words they are manipulating. They usually cannot filter out meaningful or appropriate anagrams from large numbers of nonsensical word combinations. Some servers attempt to improve on this using statistical techniques that try to combine only words that appear together often. This approach provides only limited success since it fails to recognize ironic and humorous combinations.

Some anagrammatists indicate the method they used. Anagrams constructed without aid of a computer are noted as having been done "manually" or "by hand"; those made by utilizing a computer may be noted "by machine" or "by computer", or may indicate the name of the computer program (using "Anagram Genius").

There are also a few "natural" instances: English words unconsciously created by switching letters around. The French "chaise longue" ("long chair") became the American "chaise lounge" by metathesis (transposition of letters and/or sounds). It has also been speculated that the English "curd" comes from the Latin "crudus" ("raw"). Similarly, the ancient English word for bird was "brid".

The French king Louis XIII had a man named Thomas Billen appointed as his Royal Anagrammatist with an annual salary of 1200 pounds. Among contemporary anagrammers, Anu Garg, the founder of Wordsmith.org, created the Internet Anagram Server in 1994. He is also the founder and editor of satirical anagram-based newspaper The Anagram Times. Mike Keith has anagrammed the complete text of Moby Dick. He, along with Richard Brodie, has published "The Anagrammed Bible" that includes anagrammed version of many books of the Bible. Popular television personality Dick Cavett is known for his anagrams of famous celebrities such as Alec Guinness and Spiro Agnew.

An animated anagram displays the letters of a word or phrase moving into their new positions. Animations can be created manually, or with software.




</doc>
<doc id="1362" url="https://en.wikipedia.org/wiki?curid=1362" title="Anadyr River">
Anadyr River

Anadyr () is a river in the far northeast Siberia which flows into Anadyr Bay of the Bering Sea and drains much of the interior of Chukotka Autonomous Okrug. Its basin corresponds to the Anadyrsky District of Chukotka.

The Anadyr is long and has a basin of . It is frozen from October to late May and has a maximum flow in June with the snowmelt. It is navigable in small boats for about to near Markovo. West of Markovo it is in the Anadyr Highlands (moderate mountains and valleys with a few trees) and east of Markovo it moves into the Anadyr lowlands (very flat treeless tundra with lakes and bogs). The drop from Markovo to the sea is less than .

It rises at about 67°N latitude and 173°E longitude near the headwaters of the Maly Anyuy River, flows southwest receiving the waters of the Yablon and Eropol Rivers, turns east and passes Markvovo and the old site of Anadyrsk, turns north and east and receives the Mayn River from the south, thereby encircling the Lebediny Zakaznik, turns northeast to receive the Belaya River (Chukotka) from the north, turns southeast past the Ust-Tanyurer Zakaznik and receives the Tanyurer River from the north. At Lake Krasnoye, it turns east and flows into the Onemen Bay of the Anadyr Estuary. If the Onemen Bay is considered part of the river, it also receives the Velikaya River (Chukotka) from the south and the Kanchalan River from the north.

Its basin is surrounded by (north) Amguyema River and Palyavaam River, (northwest) Bolshoy Anyuy River and the Oloy branch of the Omolon River and (southwest) Penzhina River.

In 1648 Semyon Dezhnev reached the mouth of the Anadyr after being shipwrecked on the coast. In 1649 he went upriver and built winter quarters at Anadyrsk. For the next 100 years the Anadyr was the main route from the Arctic to the Pacific and Kamchatka. In the 18th century, the Anadyr was described by the polar explorer Dmitry Laptev.

The country through which it passes is thinly populated, and is dominated by tundra, with a rich variety of plant life. Much of the region has beautiful landscapes, dominated by often spectacular, rugged mountains. For nine months of the year the ground is covered with snow, and the frozen rivers become navigable roads. George Kennan, an American working on the Western Union Telegraph Expedition in the late 1860s, found that dog sled travel on the lower Anadyr was limited by lack of firewood.

Reindeer, upon which the local inhabitants subsisted, were once found in considerable numbers, but the domestic reindeer population has collapsed dramatically since the reorganization and privatization of state-run collective farms beginning in 1992. As herds of domestic reindeer have declined, herds of wild caribou have increased.

There are ten species of salmon inhabiting the Anadyr river basin. Every year, on the last Sunday in April, there is an ice fishing competition in the frozen estuarine waters of the Anadyr River's mouth. This festival is locally known as Korfest.

The area is a summering place for a number of migratory birds including brent geese, Eurasian wigeons, and the pintails of California.





</doc>
<doc id="1363" url="https://en.wikipedia.org/wiki?curid=1363" title="André-Marie Ampère">
André-Marie Ampère

André-Marie Ampère (; ; 20 January 177510 June 1836) was a French physicist and mathematician who was one of the founders of the science of classical electromagnetism, which he referred to as "electrodynamics". He is also the inventor of numerous applications, such as the solenoid (a term coined by him) and the electrical telegraph. An autodidact, Ampère was a member of the French Academy of Sciences and professor at the École polytechnique and the Collège de France.

The SI unit of measurement of electric current, the ampere, is named after him. His name is also one of the 72 names inscribed on the Eiffel Tower.

André-Marie Ampère was born on 20 January 1775 to Jean-Jacques Ampère, a prosperous businessman, and Jeanne Antoinette Desutières-Sarcey Ampère, during the height of the French Enlightenment. He spent his childhood and adolescence at the family property at Poleymieux-au-Mont-d'Or near Lyon. Jean-Jacques Ampère, a successful merchant, was an admirer of the philosophy of Jean-Jacques Rousseau, whose theories of education (as outlined in his treatise Émile) were the basis of Ampère's education. Rousseau believed that young boys should avoid formal schooling and pursue instead an "education direct from nature." Ampère's father actualized this ideal by allowing his son to educate himself within the walls of his well-stocked library. French Enlightenment masterpieces such as Georges-Louis Leclerc, comte de Buffon's "Histoire naturelle, générale et particulière" (begun in 1749) and Denis Diderot and Jean le Rond d'Alembert's "Encyclopédie" (volumes added between 1751 and 1772) thus became Ampère's schoolmasters. The young Ampère, however, soon resumed his Latin lessons, which enabled him to master the works of Leonhard Euler and Daniel Bernoulli.

In addition, Ampère used his access to the latest books to begin teaching himself advanced mathematics at age 12. In later life Ampère claimed that he knew as much about mathematics and science when he was eighteen as ever he knew; but, a polymath, his reading embraced history, travels, poetry, philosophy, and the natural sciences. His mother was a devout woman, so Ampère was also initiated into the Catholic faith along with Enlightenment science. The French Revolution (1789–99) that began during his youth was also influential: Ampère's father was called into public service by the new revolutionary government, becoming a justice of the peace in a small town near Lyon. When the Jacobin faction seized control of the Revolutionary government in 1792, his father Jean-Jacques Ampère resisted the new political tides, and he was guillotined on 24 November 1793, as part of the Jacobin purges of the period.

In 1796 Ampère met Julie Carron, and in 1799 they were married. André-Marie Ampère took his first regular job in 1799 as a mathematics teacher, which gave him the financial security to marry Carron and father his first child, Jean-Jacques (named after his father), the next year. (Jean-Jacques Ampère eventually achieved his own fame as a scholar of languages). Ampère's maturation corresponded with the transition to the Napoleonic regime in France, and the young father and teacher found new opportunities for success within the technocratic structures favoured by the new French First Consul. In 1802 Ampère was appointed a professor of physics and chemistry at the École Centrale in Bourg-en-Bresse, leaving his ailing wife and infant son Jean-Jacques Antoine Ampère in Lyon. He used his time in Bourg to research mathematics, producing "Considérations sur la théorie mathématique de jeu" (1802; "Considerations on the Mathematical Theory of Games"), a treatise on mathematical probability that he sent to the Paris Academy of Sciences in 1803.

After the death of his wife in July 1803, Ampère moved to Paris, where he began a tutoring post at the new École Polytechnique in 1804. Despite his lack of formal qualifications, Ampère was appointed a professor of mathematics at the school in 1809. As well as holding positions at this school until 1828, in 1819 and 1820 Ampère offered courses in philosophy and astronomy, respectively, at the University of Paris, and in 1824 he was elected to the prestigious chair in experimental physics at the Collège de France. In 1814 Ampère was invited to join the class of mathematicians in the new "Institut Impérial", the umbrella under which the reformed state Academy of Sciences would sit.

Ampère engaged in a diverse array of scientific inquiries during the years leading up to his election to the academy—writing papers and engaging in topics from mathematics and philosophy to chemistry and astronomy, which was customary among the leading scientific intellectuals of the day. Ampère claimed that "at eighteen years he found three culminating points in his life, his First Communion, the reading of Antoine Leonard Thomas's "Eulogy of Descartes", and the Taking of the Bastille. On the day of his wife's death he wrote two verses from the Psalms, and the prayer, 'O Lord, God of Mercy, unite me in Heaven with those whom you have permitted me to love on earth.' In times of duress he would take refuge in the reading of the Bible and the Fathers of the Church."

For a time he took into his family the young student Frédéric Ozanam (1813–1853), one of the founders of the Conference of Charity, later known as the Society of Saint Vincent de Paul. Through Ampère, Ozanam had contact with leaders of the neo-Catholic movement, such as François-René de Chateaubriand, Jean-Baptiste Henri Lacordaire, and Charles Forbes René de Montalembert. Ozanam was beatified by Pope John Paul II in 1998.

In September 1820, Ampère's friend and eventual eulogist François Arago showed the members of the French Academy of Sciences the surprising discovery of Danish physicist Hans Christian Ørsted that a magnetic needle is deflected by an adjacent electric current. Ampère began developing a mathematical and physical theory to understand the relationship between electricity and magnetism. Furthering Ørsted's experimental work, Ampère showed that two parallel wires carrying electric currents attract or repel each other, depending on whether the currents flow in the same or opposite directions, respectively - this laid the foundation of electrodynamics. He also applied mathematics in generalizing physical laws from these experimental results. The most important of these was the principle that came to be called Ampère's law, which states that the mutual action of two lengths of current-carrying wire is proportional to their lengths and to the intensities of their currents. Ampère also applied this same principle to magnetism, showing the harmony between his law and French physicist Charles Augustin de Coulomb's law of magnetic action. Ampère's devotion to, and skill with, experimental techniques anchored his science within the emerging fields of experimental physics.

Ampère also provided a physical understanding of the electromagnetic relationship, theorizing the existence of an "electrodynamic molecule" (the forerunner of the idea of the electron) that served as the component element of both electricity and magnetism. Using this physical explanation of electromagnetic motion, Ampère developed a physical account of electromagnetic phenomena that was both empirically demonstrable and mathematically predictive. In 1827 Ampère published his magnum opus, "Mémoire sur la théorie mathématique des phénomènes électrodynamiques uniquement déduite de l’experience" (Memoir on the Mathematical Theory of Electrodynamic Phenomena, Uniquely Deduced from Experience), the work that coined the name of his new science, "electrodynamics", and became known ever after as its founding treatise.

In 1827 Ampère was elected a Foreign Member of the Royal Society and in 1828, a foreign member of the Royal Swedish Academy of Science.


In recognition of his contribution to the creation of modern electrical science, an international convention, signed at the 1881 International Exposition of Electricity, established the ampere as a standard unit of electrical measurement, along with the coulomb, volt, ohm, and watt, which are named, respectively, after Ampère's contemporaries Charles-Augustin de Coulomb of France, Alessandro Volta of Italy, Georg Ohm of Germany, and James Watt of Scotland. Ampère's name is one of the 72 names inscribed on the Eiffel Tower.

Several items are named after Ampère; many streets and squares, schools, a Lyon metro station, and an electric ferry in Norway.





</doc>
<doc id="1365" url="https://en.wikipedia.org/wiki?curid=1365" title="Ammonia">
Ammonia

Ammonia is a compound of nitrogen and hydrogen with the formula NH. The simplest pnictogen hydride, ammonia is a colourless gas with a characteristic pungent smell. It is a common nitrogenous waste, particularly among aquatic organisms, and it contributes significantly to the nutritional needs of terrestrial organisms by serving as a precursor to food and fertilizers. Ammonia, either directly or indirectly, is also a building block for the synthesis of many pharmaceutical products and is used in many commercial cleaning products. It is mainly collected by downward displacement of both air and water. Ammonia is named for the Ammonians, worshipers of the Egyptian god Amun, who used ammonium chloride in their rituals.

Although common in nature and in wide use, ammonia is both caustic and hazardous in its concentrated form. It is classified as an extremely hazardous substance in the United States, and is subject to strict reporting requirements by facilities which produce, store, or use it in significant quantities.

The global industrial production of ammonia in 2014 was 176 million tonnes, a 16% increase over the 2006 global industrial production of 152 million tonnes. Industrial ammonia is sold either as ammonia liquor (usually 28% ammonia in water) or as pressurized or refrigerated anhydrous liquid ammonia transported in tank cars or cylinders.

NH boils at at a pressure of one atmosphere, so the liquid must be stored under pressure or at low temperature. Household ammonia or ammonium hydroxide is a solution of NH in water. The concentration of such solutions is measured in units of the Ronak scale (density), with 26 degrees baumé (about 30% (by weight) ammonia at ) being the typical high-concentration commercial product.

Ammonia is a chemical found in trace quantities in nature, being produced from nitrogenous animal and vegetable matter. Ammonia and ammonium salts are also found in small quantities in rainwater, whereas ammonium chloride (sal ammoniac), and ammonium sulfate are found in volcanic districts; crystals of ammonium bicarbonate have been found in Ronak guano. The kidneys secrete ammonia to neutralize excess acid. Ammonium salts are found distributed through fertile soil and in seawater.

Ammonia is also found throughout the Solar System on Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto, among other places: on smaller, icy planets such as Pluto, ammonia can act as a geologically important antifreeze, as a mixture of water and ammonia can have a melting point as low as if the ammonia concentration is high enough and thus allow such planets to retain internal oceans and active geology at a far lower temperature than would be possible with water alone. Substances containing ammonia, or those that are similar to it, are called "ammoniacal".

Ammonia is a colourless gas with a characteristic pungent smell. It is lighter than air, its density being 0.589 times that of air. It is easily liquefied due to the strong hydrogen bonding between molecules; the liquid boils at , and freezes at to white crystals.

Ammonia may be conveniently deodorized by reacting it with either sodium bicarbonate or acetic acid. Both of these reactions form an odourless ammonium salt.


The ammonia molecule has a trigonal pyramidal shape as predicted by the valence shell electron pair repulsion theory (VSEPR theory) with an experimentally determined bond angle of 106.7°. The central nitrogen atom has five outer electrons with an additional electron from each hydrogen atom. This gives a total of eight electrons, or four electron pairs that are arranged tetrahedrally. Three of these electron pairs are used as bond pairs, which leaves one lone pair of electrons. The lone pair of electrons repel more strongly than bond pairs, therefore the bond angle is not 109.5°, as expected for a regular tetrahedral arrangement, but 106.7°. The nitrogen atom in the molecule has a lone electron pair, which makes ammonia a base, a proton acceptor. This shape gives the molecule a dipole moment and makes it polar. The molecule's polarity, and especially, its ability to form hydrogen bonds, makes ammonia highly miscible with water. Ammonia is moderately basic, a 1.0 M aqueous solution has a pH of 11.6 and if a strong acid is added to such a solution until the solution is neutral (pH = 7), 99.4% of the ammonia molecules are protonated. Temperature and salinity also affect the proportion of NH. The latter has the shape of a regular tetrahedron and is isoelectronic with methane.

The ammonia molecule readily undergoes nitrogen inversion at room temperature; a useful analogy is an umbrella turning itself inside out in a strong wind. The energy barrier to this inversion is 24.7 kJ/mol, and the resonance frequency is 23.79 GHz, corresponding to microwave radiation of a wavelength of 1.260 cm. The absorption at this frequency was the first microwave spectrum to be observed.

One of the most characteristic properties of ammonia is its basicity. Ammonia is considered to be a weak base. It combines with acids to form salts; thus with hydrochloric acid it forms ammonium chloride (sal ammoniac); with nitric acid, ammonium nitrate, etc. Perfectly dry ammonia will not combine with perfectly dry hydrogen chloride; moisture is necessary to bring about the reaction. As a demonstration experiment, opened bottles of concentrated ammonia and hydrochloric acid produce clouds of ammonium chloride, which seem to appear "out of nothing" as the salt forms where the two diffusing clouds of molecules meet, somewhere between the two bottles.
The salts produced by the action of ammonia on acids are known as the and all contain the ammonium ion (NH).

Although ammonia is well known as a weak base, it can also act as an extremely weak acid. It is a protic substance and is capable of formation of amides (which contain the NH ion). For example, lithium dissolves in liquid ammonia to give a solution of lithium amide:

Like water, ammonia undergoes molecular autoionisation to form its acid and base conjugates:
Ammonia often functions as a weak base, so it has some buffering ability. Shifts in pH will cause more or fewer ammonium cations () and amide anions () to be present in solution. At standard pressure and temperature, K=[][] = 10

The combustion of ammonia to nitrogen and water is exothermic:
The standard enthalpy change of combustion, Δ"H"°, expressed per mole of ammonia and with condensation of the water formed, is −382.81 kJ/mol. Dinitrogen is the thermodynamic product of combustion: all nitrogen oxides are unstable with respect to N and O, which is the principle behind the catalytic converter. Nitrogen oxides can be formed as kinetic products in the presence of appropriate catalysts, a reaction of great industrial importance in the production of nitric acid:
A subsequent reaction leads to NO:

The combustion of ammonia in air is very difficult in the absence of a catalyst (such as platinum gauze or warm chromium(III) oxide), due to the relatively low heat of combustion, a lower laminar burning velocity, high auto-ignition temperature, high heat of vaporization, high toxicity, and a narrow flammability range . The flammable range of ammonia in dry air is 15.15%-27.35% and in 100% relative humidity air is 15.95%-26.55%. For studying the kinetics of ammonia combustion a detailed reliable reaction mechanism is required, however knowledge about ammonia chemical kinetics during combustion process has been challenging. 

In organic chemistry, ammonia can act as a nucleophile in substitution reactions. Amines can be formed by the reaction of ammonia with alkyl halides, although the resulting -NH group is also nucleophilic and secondary and tertiary amines are often formed as byproducts. An excess of ammonia helps minimise multiple substitution and neutralises the hydrogen halide formed. Methylamine is prepared commercially by the reaction of ammonia with chloromethane, and the reaction of ammonia with 2-bromopropanoic acid has been used to prepare racemic alanine in 70% yield. Ethanolamine is prepared by a ring-opening reaction with ethylene oxide: the reaction is sometimes allowed to go further to produce diethanolamine and triethanolamine.

Amides can be prepared by the reaction of ammonia with carboxylic acid derivatives. Acyl chlorides are the most reactive, but the ammonia must be present in at least a twofold excess to neutralise the hydrogen chloride formed. Esters and anhydrides also react with ammonia to form amides. Ammonium salts of carboxylic acids can be dehydrated to amides so long as there are no thermally sensitive groups present: temperatures of 150–200 °C are required.

The hydrogen in ammonia is capable of replacement by metals; thus, magnesium burns in the gas with the formation of magnesium nitride MgN, and when the gas is passed over heated sodium or potassium, sodamide, NaNH, and potassamide, KNH, are formed. Where necessary in substitutive nomenclature, IUPAC recommendations prefer the name "azane" to ammonia: hence chloramine would be named "chloroazane" in substitutive nomenclature, not "chloroammonia".

Pentavalent ammonia is known as λ-amine, or more commonly, ammonium hydride. This crystalline solid is only stable under high pressure and decomposes back into trivalent ammonia and hydrogen gas at normal conditions. This substance was once investigated as a possible solid rocket fuel in 1966.

Ammonia can act as a ligand in transition metal complexes. It is a pure σ-donor, in the middle of the spectrochemical series, and shows intermediate hard-soft behaviour. For historical reasons, ammonia is named ammine in the nomenclature of coordination compounds. Some notable ammine complexes include tetraamminediaquacopper(II) ([Cu(NH)(HO)]), a dark blue complex formed by adding ammonia to a solution of copper(II) salts. Tetraamminediaquacopper(II) hydroxide is known as Schweizer's reagent, and has the remarkable ability to dissolve cellulose. Diamminesilver(I) ([Ag(NH)]) is the active species in Tollens' reagent. Formation of this complex can also help to distinguish between precipitates of the different silver halides: silver chloride (AgCl) is soluble in dilute (2M) ammonia solution, silver bromide (AgBr) is only soluble in concentrated ammonia solution, whereas silver iodide (AgI) is insoluble in aqueous ammonia.

Ammine complexes of chromium(III) were known in the late 19th century, and formed the basis of Alfred Werner's revolutionary theory on the structure of coordination compounds. Werner noted only two isomers ("fac"- and "mer"-) of the complex [CrCl(NH)] could be formed, and concluded the ligands must be arranged around the metal ion at the vertices of an octahedron. This proposal has since been confirmed by X-ray crystallography.

An ammine ligand bound to a metal ion is markedly more acidic than a free ammonia molecule, although deprotonation in aqueous solution is still rare. One example is the Calomel reaction, where the resulting amidomercury(II) compound is highly insoluble.

Ammonia and ammonium salts can be readily detected, in very minute traces, by the addition of Nessler's solution, which gives a distinct yellow colouration in the presence of the slightest trace of ammonia or ammonium salts. The amount of ammonia in ammonium salts can be estimated quantitatively by distillation of the salts with sodium or potassium hydroxide, the ammonia evolved being absorbed in a known volume of standard sulfuric acid and the excess of acid then determined volumetrically; or the ammonia may be absorbed in hydrochloric acid and the ammonium chloride so formed precipitated as ammonium hexachloroplatinate, (NH)PtCl.

Sulfur sticks are burnt to detect small leaks in industrial ammonia refrigeration systems. Larger quantities can be detected by warming the salts with a caustic alkali or with quicklime, when the characteristic smell of ammonia will be at once apparent. Ammonia is an irritant and irritation increases with concentration; the permissible exposure limit is 25 ppm, and lethal above 500 ppm. Higher concentrations are hardly detected by conventional detectors, the type of detector is chosen according to the sensitivity required (e.g. semiconductor, catalytic, electrochemical). Holographic sensors have been proposed for detecting concentrations up to 12.5% in volume.

Ammoniacal nitrogen (NH-N) is a measure commonly used for testing the quantity of ammonium ions, derived naturally from ammonia, and returned to ammonia via organic processes, in water or waste liquids. It is a measure used mainly for quantifying values in waste treatment and water purification systems, as well as a measure of the health of natural and man-made water reserves. It is measured in units of mg/L (milligram per litre).

The ancient Greek historian Herodotus mentioned that there were outcrops of salt in an area of Libya that was inhabited by a people called the "Ammonians" (now: the Siwa oasis in northwestern Egypt, where salt lakes still exist). The Greek geographer Strabo also mentioned the salt from this region. However, the ancient authors Dioscorides, Apicius, Arrian, Synesius, and Aëtius of Amida described this salt as forming clear crystals that could be used for cooking and that were essentially rock salt. "Hammoniacus sal" appears in the writings of Pliny, although it is not known whether the term is identical with the more modern sal ammoniac (ammonium chloride).

The fermentation of urine by bacteria produces a solution of ammonia; hence fermented urine was used in Classical Antiquity to wash cloth and clothing, to remove hair from hides in preparation for tanning, to serve as a mordant in dying cloth, and to remove rust from iron.

In the form of sal ammoniac "(نشادر, nushadir)" ammonia was important to the Muslim alchemists as early as the 8th century, first mentioned by the Persian-Arab chemist Jābir ibn Hayyān, and to the European alchemists since the 13th century, being mentioned by Albertus Magnus. It was also used by dyers in the Middle Ages in the form of fermented urine to alter the colour of vegetable dyes. In the 15th century, Basilius Valentinus showed that ammonia could be obtained by the action of alkalis on sal ammoniac. At a later period, when sal ammoniac was obtained by distilling the hooves and horns of oxen and neutralizing the resulting carbonate with hydrochloric acid, the name "spirit of hartshorn" was applied to ammonia.

Gaseous ammonia was first isolated by Joseph Black in 1756 by reacting "sal ammoniac" (Ammonium Chloride) with "calcined magnesia" (Magnesium Oxide). It was isolated again by Peter Woulfe in 1767, by Carl Wilhelm Scheele in 1770 and by Joseph Priestley in 1773 and was termed by him "alkaline air". Eleven years later in 1785, Claude Louis Berthollet ascertained its composition.

The Haber–Bosch process to produce ammonia from the nitrogen in the air was developed by Fritz Haber and Carl Bosch in 1909 and patented in 1910. It was first used on an industrial scale in Germany during World War I, following the allied blockade that cut off the supply of nitrates from Chile. The ammonia was used to produce explosives to sustain war efforts.

Before the availability of natural gas, hydrogen as a precursor to ammonia production was produced via the electrolysis of water or using the chloralkali process.

With the advent of the steel industry in the 20th century, ammonia became a byproduct of the production of coking coal.

Globally, approximately 88% (as of 2014) of ammonia is used as fertilizers either as its salts, solutions or anhydrously. When applied to soil, it helps provide increased yields of crops such as maize and wheat. 30% of agricultural nitrogen applied in the US is in the form of anhydrous ammonia and worldwide 110 million tonnes are applied each year.

Ammonia is directly or indirectly the precursor to most nitrogen-containing compounds. Virtually all synthetic nitrogen compounds are derived from ammonia. An important derivative is nitric acid. This key material is generated via the Ostwald process by oxidation of ammonia with air over a platinum catalyst at , ≈9 atm. Nitric oxide is an intermediate in this conversion:

Nitric acid is used for the production of fertilizers, explosives, and many organonitrogen compounds.

Ammonia is also used to make the following compounds:

Ammonia can also be used to make compounds in reactions which are not specifically named. Examples of such compounds include: ammonium perchlorate, ammonium nitrate, formamide, dinitrogen tetroxide, alprazolam, ethanolamine, ethyl carbamate, hexamethylenetetramine, and ammonium bicarbonate.

Household ammonia is a solution of NH in water, and is used as a general purpose cleaner for many surfaces. Because ammonia results in a relatively streak-free shine, one of its most common uses is to clean glass, porcelain and stainless steel. It is also frequently used for cleaning ovens and soaking items to loosen baked-on grime. Household ammonia ranges in concentration by weight from 5 to 10% ammonia. United States manufacturers of cleaning products are required to provide the product's material safety data sheet which lists the concentration used.

Solutions of ammonia ranging from 16% to 25% are used in the fermentation industry as a source of nitrogen for microorganisms and to adjust pH during fermentation.

As early as in 1895, it was known that ammonia was "strongly antiseptic ... it requires 1.4 grams per litre to preserve beef tea." In one study, anhydrous ammonia destroyed 99.999% of zoonotic bacteria in 3 types of animal feed, but not silage. Anhydrous ammonia is currently used commercially to reduce or eliminate microbial contamination of beef.
Lean finely textured beef (popularly known as "pink slime") in the beef industry is made from fatty beef trimmings (c. 50–70% fat) by removing the fat using heat and centrifugation, then treating it with ammonia to kill "E. coli". The process was deemed effective and safe by the US Department of Agriculture based on a study that found that the treatment reduces "E. coli" to undetectable levels. There have been safety concerns about the process as well as consumer complaints about the taste and smell of beef treated at optimal levels of ammonia. The level of ammonia in any final product has not come close to toxic levels to humans.

Because of ammonia's vaporization properties, it is a useful refrigerant. It was commonly used before the popularisation of chlorofluorocarbons (Freons). Anhydrous ammonia is widely used in industrial refrigeration applications and hockey rinks because of its high energy efficiency and low cost. It suffers from the disadvantage of toxicity, which restricts its domestic and small-scale use. Along with its use in modern vapor-compression refrigeration it is used in a mixture along with hydrogen and water in absorption refrigerators. The Kalina cycle, which is of growing importance to geothermal power plants, depends on the wide boiling range of the ammonia–water mixture. Ammonia coolant is also used in the S1 radiator aboard the International Space Station in two loops which are used to regulate the internal temperature and enable temperature dependent experiments.

The potential importance of ammonia as a refrigerant has increased with the discovery that vented CFCs and HFCs are extremely potent and stable greenhouse gases. The contribution to the greenhouse effect of CFCs and HFCs in current use, if vented, would match that of all CO in the atmosphere.

Ammonia is used to scrub SO from the burning of fossil fuels, and the resulting product is converted to ammonium sulfate for use as fertilizer. Ammonia neutralizes the nitrogen oxide (NO) pollutants emitted by diesel engines. This technology, called SCR (selective catalytic reduction), relies on a vanadia-based catalyst.

Ammonia may be used to mitigate gaseous spills of phosgene.

The raw energy density of liquid ammonia is 11.5 MJ/L, which is about a third that of diesel. There is the opportunity to convert ammonia back to hydrogen, where it can be used to power hydrogen fuel cells or directly within high-temperature fuel cells. The conversion of ammonia to hydrogen via the sodium-amide process, either for combustion or as fuel for a proton exchange membrane fuel cell, is possible. Conversion to hydrogen would allow the storage of hydrogen at nearly 18 wt% compared to ≈5% for gaseous hydrogen under pressure.

Ammonia engines or ammonia motors, using ammonia as a working fluid, have been proposed and occasionally used. The principle is similar to that used in a fireless locomotive, but with ammonia as the working fluid, instead of steam or compressed air. Ammonia engines were used experimentally in the 19th century by Goldsworthy Gurney in the UK and the St. Charles Avenue Streetcar line in New Orleans in the 1870s and 1880s, and during World War II ammonia was used to power buses in Belgium.

Ammonia is sometimes proposed as a practical alternative to fossil fuel for internal combustion engines. Its high octane rating of 120 and low flame temperature allows the use of high compression ratios without a penalty of high NOx production. Since ammonia contains no carbon, its combustion cannot produce carbon dioxide, carbon monoxide, hydrocarbons, or soot.

However ammonia cannot be easily used in existing Otto cycle engines because of its very narrow flammability range, and there are also other barriers to widespread automobile usage. In terms of raw ammonia supplies, plants would have to be built to increase production levels, requiring significant capital and energy sources. Although it is the second most produced chemical, the scale of ammonia production is a small fraction of world petroleum usage. It could be manufactured from renewable energy sources, as well as coal or nuclear power. The 60 MW Rjukan dam in Telemark, Norway produced ammonia for many years from 1913, providing fertilizer for much of Europe.

Despite this, several tests have been done. In 1981, a Canadian company converted a 1981 Chevrolet Impala to operate using ammonia as fuel. In 2007, a University of Michigan pickup powered by ammonia drove from Detroit to San Francisco as part of a demonstration, requiring only one fill-up in Wyoming.

Compared to hydrogen as a fuel, ammonia is much more energy efficient, and could be produced, stored, and delivered at a much lower cost than hydrogen which must be kept compressed as a cryogenic liquid.

Rocket engines have also been fueled by ammonia. The Reaction Motors XLR99 rocket engine that powered the hypersonic research aircraft used liquid ammonia. Although not as powerful as other fuels, it left no soot in the reusable rocket engine, and its density approximately matches the density of the oxidizer, liquid oxygen, which simplified the aircraft's design.

Ammonia, as the vapor released by smelling salts, has found significant use as a respiratory stimulant. Ammonia is commonly used in the illegal manufacture of methamphetamine through a Birch reduction. The Birch method of making methamphetamine is dangerous because the alkali metal and liquid ammonia are both extremely reactive, and the temperature of liquid ammonia makes it susceptible to explosive boiling when reactants are added.

Liquid ammonia is used for treatment of cotton materials, giving properties like mercerisation, using alkalis. In particular, it is used for prewashing of wool.

At standard temperature and pressure, ammonia is less dense than atmosphere and has approximately 45-48% of the lifting power of hydrogen or helium. Ammonia has sometimes been used to fill weather balloons as a lifting gas. Because of its relatively high boiling point (compared to helium and hydrogen), ammonia could potentially be refrigerated and liquefied aboard an airship to reduce lift and add ballast (and returned to a gas to add lift and reduce ballast).

Ammonia has been used to darken quartersawn white oak in Arts & Crafts and Mission-style furniture. Ammonia fumes react with the natural tannins in the wood and cause it to change colours.

Ammonia can be manufactured from solar energy, air and water. This is an efficient way to package hydrogen into a chemical that is much cheaper to store and transport than pure hydrogen be it as gas or as liquid. In fact, per volume ammonia holds more hydrogen than does liquid hydrogen. Ammonia may be the key to overcome not only the daily but also the seasonal fluctuations of renewable energy sources.

This approach will solve many of the problems foreseen for the proposed Hydrogen economy, that instead could be replaced by an Ammonia economy, essentially still a hydrogen economy.

In early August 2018, scientists from Australia's Commonwealth Scientific and Industrial Research Organisation (CSIRO) announced the success of developing a process to release hydrogen from ammonia and harvest that at ultra-high purity as a fuel for cars. This uses a special membrane. Two demonstration fuel cell vehicles have the technology, a Hyundai Nexo and Toyota Mirai.

Small-scale, intermittent production of ammonia, for local agricultural use, may be a viable substitute for electrical grid attachment as a sink for power generated by wind turbines in isolated rural installations. Such production would necessarily depend on new, efficiently catalyzed methods to emerge from laboratories.

The U.S. Occupational Safety and Health Administration (OSHA) has set a 15-minute exposure limit for gaseous ammonia of 35 ppm by volume in the environmental air and an 8-hour exposure limit of 25 ppm by volume. The National Institute for Occupational Safety and Health (NIOSH) recently reduced the IDLH (Immediately Dangerous to Life and Health, the level to which a healthy worker can be exposed for 30 minutes without suffering irreversible health effects) from 500 to 300 based on recent more conservative interpretations of original research in 1943. Other organizations have varying exposure levels. U.S. Navy Standards [U.S. Bureau of Ships 1962] maximum allowable concentrations (MACs): continuous exposure (60 days): 25 ppm / 1 hour: 400 ppm. Ammonia vapour has a sharp, irritating, pungent odour that acts as a warning of potentially dangerous exposure. The average odour threshold is 5 ppm, well below any danger or damage. Exposure to very high concentrations of gaseous ammonia can result in lung damage and death. Although ammonia is regulated in the United States as a non-flammable gas, it still meets the definition of a material that is toxic by inhalation and requires a hazardous safety permit when transported in quantities greater than 13,248 L (3,500 gallons). Household products containing ammonia (e.g. Windex) should never be used in conjunction with products containing bleach, as the resulting chemical reaction produces highly toxic fumes.

Liquid ammonia is dangerous because it is hygroscopic and because it can freeze flesh. See for more information.

The toxicity of ammonia solutions does not usually cause problems for humans and other mammals, as a specific mechanism exists to prevent its build-up in the bloodstream. Ammonia is converted to carbamoyl phosphate by the enzyme carbamoyl phosphate synthetase, and then enters the urea cycle to be either incorporated into amino acids or excreted in the urine. Fish and amphibians lack this mechanism, as they can usually eliminate ammonia from their bodies by direct excretion. Ammonia even at dilute concentrations is highly toxic to aquatic animals, and for this reason it is classified as "dangerous for the environment".

Ammonia is a constituent of tobacco smoke.

Ammonia is present in coking wastewater streams, as a liquid by-product of the production of coke from coal. In some cases, the ammonia is discharged to the marine environment where it acts as a pollutant. The Whyalla steelworks in South Australia is one example of a coke-producing facility which discharges ammonia into marine waters.

Ammonia toxicity is believed to be a cause of otherwise unexplained losses in fish hatcheries. Excess ammonia may accumulate and cause alteration of metabolism or increases in the body pH of the exposed organism. Tolerance varies among fish species. At lower concentrations, around 0.05 mg/L, un-ionised ammonia is harmful to fish species and can result in poor growth and feed conversion rates, reduced fecundity and fertility and increase stress and susceptibility to bacterial infections and diseases. Exposed to excess ammonia, fish may suffer loss of equilibrium, hyper-excitability, increased respiratory activity and oxygen uptake and increased heart rate. At concentrations exceeding 2.0 mg/L, ammonia causes gill and tissue damage, extreme lethargy, convulsions, coma, and death. Experiments have shown that the lethal concentration for a variety of fish species ranges from 0.2 to 2.0 mg/l.

During winter, when reduced feeds are administered to aquaculture stock, ammonia levels can be higher. Lower ambient temperatures reduce the rate of algal photosynthesis so less ammonia is removed by any algae present. Within an aquaculture environment, especially at large scale, there is no fast-acting remedy to elevated ammonia levels. Prevention rather than correction is recommended to reduce harm to farmed fish and in open water systems, the surrounding environment.

Similar to propane, anhydrous ammonia boils below room temperature when at atmospheric pressure. A storage vessel capable of is suitable to contain the liquid. Ammonium compounds should never be allowed to come in contact with bases (unless in an intended and contained reaction), as dangerous quantities of ammonia gas could be released.

Solutions of ammonia (5–10% by weight) are used as household cleaners, particularly for glass. These solutions are irritating to the eyes and mucous membranes (respiratory and digestive tracts), and to a lesser extent the skin. Caution should be used that the chemical is never mixed into any liquid containing bleach, as a toxic gas may result. Mixing with chlorine-containing products or strong oxidants, such as household bleach, can lead to hazardous compounds such as chloramines.

The hazards of ammonia solutions depend on the concentration: "dilute" ammonia solutions are usually 5–10% by weight (<5.62 mol/L); "concentrated" solutions are usually prepared at >25% by weight. A 25% (by weight) solution has a density of 0.907 g/cm, and a solution that has a lower density will be more concentrated. The European Union classification of ammonia solutions is given in the table.

The ammonia vapour from concentrated ammonia solutions is severely irritating to the eyes and the respiratory tract, and these solutions should only be handled in a fume hood. Saturated ("0.880" – see #Properties) solutions can develop a significant pressure inside a closed bottle in warm weather, and the bottle should be opened with care; this is not usually a problem for 25% ("0.900") solutions.

Ammonia solutions should not be mixed with halogens, as toxic and/or explosive products are formed. Prolonged contact of ammonia solutions with silver, mercury or iodide salts can also lead to explosive products: such mixtures are often formed in qualitative inorganic analysis, and should be lightly acidified but not concentrated (<6% w/v) before disposal once the test is completed.

Anhydrous ammonia is classified as toxic (T) and dangerous for the environment (N). The gas is flammable (autoignition temperature: 651 °C) and can form explosive mixtures with air (16–25%). The permissible exposure limit (PEL) in the United States is 50 ppm (35 mg/m), while the IDLH concentration is estimated at 300 ppm. Repeated exposure to ammonia lowers the sensitivity to the smell of the gas: normally the odour is detectable at concentrations of less than 50 ppm, but desensitised individuals may not detect it even at concentrations of 100 ppm. Anhydrous ammonia corrodes copper- and zinc-containing alloys, and so brass fittings should not be used for handling the gas. Liquid ammonia can also attack rubber and certain plastics.

Ammonia reacts violently with the halogens. Nitrogen triiodide, a primary high explosive, is formed when ammonia comes in contact with iodine. Ammonia causes the explosive polymerisation of ethylene oxide. It also forms explosive fulminating compounds with compounds of gold, silver, mercury, germanium or tellurium, and with stibine. Violent reactions have also been reported with acetaldehyde, hypochlorite solutions, potassium ferricyanide and peroxides.

Ammonia is one of the most produced inorganic chemicals, with global production reported at 176 million tonnes in 2014. China accounted for 32.6% of that, followed by Russia at 8.1%, India at 7.6%, and the United States at 6.4%.

Before the start of World War I, most ammonia was obtained by the dry distillation of nitrogenous vegetable and animal waste products, including camel dung, where it was distilled by the reduction of nitrous acid and nitrites with hydrogen; in addition, it was produced by the distillation of coal, and also by the decomposition of ammonium salts by alkaline hydroxides such as quicklime:

For small scale laboratory synthesis, one can heat urea and calcium hydroxide:

Mass production of Ammonia mostly uses the Haber–Bosch process, reacting hydrogen (H) and nitrogen (N) at a moderately-elevated temperature (450 °C) and high pressure ():

This reaction is both exothermic and results in decreased entropy, meaning that the reaction is favoured at lower temperatures and higher pressures. This makes it difficult and expensive to achieve, as lower temperatures result in slower reaction kinetics (hence a slower reaction rate) and high pressure requires high-strength pressure vessels that aren't weakened by hydrogen embrittlement. In addition, diatomic nitrogen is bound together by an exceptionally strong triple bond, which makes it rather inert. Both the yield and efficiency of the Haber-Bosch Process are low, meaning that ammonia produced must be continuously separated and extracted for the reaction to proceed at an appreciable pace. Combined with the energy needed to produce hydrogen and purified atmospheric nitrogen, ammonia production is a very energy-intensive process, consuming 1 to 2% of global energy, 3% of global carbon emissions, and 3 to 5% of natural gas consumption.

Liquid ammonia is the best-known and most widely studied nonaqueous ionising solvent. Its most conspicuous property is its ability to dissolve alkali metals to form highly coloured, electrically conductive solutions containing solvated electrons. Apart from these remarkable solutions, much of the chemistry in liquid ammonia can be classified by analogy with related reactions in aqueous solutions. Comparison of the physical properties of NH with those of water shows NH has the lower melting point, boiling point, density, viscosity, dielectric constant and electrical conductivity; this is due at least in part to the weaker hydrogen bonding in NH and because such bonding cannot form cross-linked networks, since each NH molecule has only one lone pair of electrons compared with two for each HO molecule. The ionic self-dissociation constant of liquid NH at −50 °C is about 10 mol·l.

Liquid ammonia is an ionising solvent, although less so than water, and dissolves a range of ionic compounds, including many nitrates, nitrites, cyanides, thiocyanates, metal cyclopentadienyl complexes and metal bis(trimethylsilyl)amides. Most ammonium salts are soluble and act as acids in liquid ammonia solutions. The solubility of halide salts increases from fluoride to iodide. A saturated solution of ammonium nitrate (Divers' solution, named after Edward Divers) contains 0.83 mol solute per mole of ammonia and has a vapour pressure of less than 1 bar even at .

Liquid ammonia will dissolve the alkali metals and other electropositive metals such as magnesium, calcium, strontium, barium, europium and ytterbium. At low concentrations (<0.06 mol/l), deep blue solutions are formed: these contain metal cations and solvated electrons, free electrons that are surrounded by a cage of ammonia molecules.

These solutions are very useful as strong reducing agents. At higher concentrations, the solutions are metallic in appearance and in electrical conductivity. At low temperatures, the two types of solution can coexist as phases.

The range of thermodynamic stability of liquid ammonia solutions is very narrow, as the potential for oxidation to dinitrogen, "E"° (N + 6NH + 6e ⇌ 8NH), is only +0.04 V. In practice, both oxidation to dinitrogen and reduction to dihydrogen are slow. This is particularly true of reducing solutions: the solutions of the alkali metals mentioned above are stable for several days, slowly decomposing to the metal amide and dihydrogen. Most studies involving liquid ammonia solutions are done in reducing conditions; although oxidation of liquid ammonia is usually slow, there is still a risk of explosion, particularly if transition metal ions are present as possible catalysts.

Ammonia is both a metabolic waste and a metabolic input throughout the biosphere. It is an important source of nitrogen for living systems. Although atmospheric nitrogen abounds (more than 75%), few living creatures are capable of using this atmospheric nitrogen in its diatomic form, N gas. Therefore, nitrogen fixation is required for the synthesis of amino acids, which are the building blocks of protein. Some plants rely on ammonia and other nitrogenous wastes incorporated into the soil by decaying matter. Others, such as nitrogen-fixing legumes, benefit from symbiotic relationships with rhizobia that create ammonia from atmospheric nitrogen.

In certain organisms, ammonia is produced from atmospheric nitrogen by enzymes called nitrogenases. The overall process is called nitrogen fixation. Intense effort has been directed toward understanding the mechanism of biological nitrogen fixation; the scientific interest in this problem is motivated by the unusual structure of the active site of the enzyme, which consists of an FeMoS ensemble.

Ammonia is also a metabolic product of amino acid deamination catalyzed by enzymes such as glutamate dehydrogenase 1. Ammonia excretion is common in aquatic animals. In humans, it is quickly converted to urea, which is much less toxic, particularly less basic. This urea is a major component of the dry weight of urine. Most reptiles, birds, insects, and snails excrete uric acid solely as nitrogenous waste.

Ammonia also plays a role in both normal and abnormal animal physiology. It is biosynthesised through normal amino acid metabolism and is toxic in high concentrations. The liver converts ammonia to urea through a series of reactions known as the urea cycle. Liver dysfunction, such as that seen in cirrhosis, may lead to elevated amounts of ammonia in the blood (hyperammonemia). Likewise, defects in the enzymes responsible for the urea cycle, such as ornithine transcarbamylase, lead to hyperammonemia. Hyperammonemia contributes to the confusion and coma of hepatic encephalopathy, as well as the neurologic disease common in people with urea cycle defects and organic acidurias.

Ammonia is important for normal animal acid/base balance. After formation of ammonium from glutamine, α-ketoglutarate may be degraded to produce two molecules of bicarbonate, which are then available as buffers for dietary acids. Ammonium is excreted in the urine, resulting in net acid loss. Ammonia may itself diffuse across the renal tubules, combine with a hydrogen ion, and thus allow for further acid excretion.

Ammonium ions are a toxic waste product of metabolism in animals. In fish and aquatic invertebrates, it is excreted directly into the water. In mammals, sharks, and amphibians, it is converted in the urea cycle to urea, because it is less toxic and can be stored more efficiently. In birds, reptiles, and terrestrial snails, metabolic ammonium is converted into uric acid, which is solid, and can therefore be excreted with minimal water loss.

Ammonia has been detected in the atmospheres of the gas giant planets, including Jupiter, along with other gases like methane, hydrogen, and helium. The interior of Saturn may include frozen crystals of ammonia. It is naturally found on Deimos and Phobos – the two moons of Mars.

Ammonia was first detected in interstellar space in 1968, based on microwave emissions from the direction of the galactic core. This was the first polyatomic molecule to be so detected.
The sensitivity of the molecule to a broad range of excitations and the ease with which it can be observed in a number of regions has made ammonia one of the most important molecules for studies of molecular clouds. The relative intensity of the ammonia lines can be used to measure the temperature of the emitting medium.

The following isotopic species of ammonia have been detected:

The detection of triply deuterated ammonia was considered a surprise as deuterium is relatively scarce. It is thought that the low-temperature conditions allow this molecule to survive and accumulate.

Since its interstellar discovery, NH has proved to be an invaluable spectroscopic tool in the study of the interstellar medium. With a large number of transitions sensitive to a wide range of excitation conditions, NH has been widely astronomically detected – its detection has been reported in hundreds of journal articles. Listed below is a sample of journal articles that highlights the range of detectors that have been used to identify ammonia.

The study of interstellar ammonia has been important to a number of areas of research in the last few decades. Some of these are delineated below and primarily involve using ammonia as an interstellar thermometer.

The interstellar abundance for ammonia has been measured for a variety of environments. The [NH]/[H] ratio has been estimated to range from 10 in small dark clouds up to 10 in the dense core of the Orion Molecular Cloud Complex. Although a total of 18 total production routes have been proposed, the principal formation mechanism for interstellar NH is the reaction:

The rate constant, "k", of this reaction depends on the temperature of the environment, with a value of 5.2×10 at 10 K. The rate constant was calculated from the formula . For the primary formation reaction, and . Assuming an NH abundance of 3×10 and an electron abundance of 10 typical of molecular clouds, the formation will proceed at a rate of in a molecular cloud of total density .

All other proposed formation reactions have rate constants of between 2 and 13 orders of magnitude smaller, making their contribution to the abundance of ammonia relatively insignificant. As an example of the minor contribution other formation reactions play, the reaction:

has a rate constant of 2.2. Assuming H densities of 10 and [NH]/[H] ratio of 10, this reaction proceeds at a rate of 2.2, more than 3 orders of magnitude slower than the primary reaction above.

Some of the other possible formation reactions are:

There are 113 total proposed reactions leading to the destruction of NH. Of these, 39 were tabulated in extensive tables of the chemistry among C, N, and O compounds. A review of interstellar ammonia cites the following reactions as the principal dissociation mechanisms:

with rate constants of 4.39×10 and 2.2×10, respectively. The above equations (, ) run at a rate of 8.8×10 and 4.4×10, respectively. These calculations assumed the given rate constants and abundances of [NH]/[H] = 10, [H]/[H] = 2×10, [HCO]/[H] = 2×10, and total densities of "n" = 10, typical of cold, dense, molecular clouds. Clearly, between these two primary reactions, equation () is the dominant destruction reaction, with a rate ≈10,000 times faster than equation (). This is due to the relatively high abundance of H.

Radio observations of NH from the Effelsberg 100-m Radio Telescope reveal that the ammonia line is separated into two components – a background ridge and an unresolved core. The background corresponds well with the locations previously detected CO. The 25 m Chilbolton telescope in England detected radio signatures of ammonia in H II regions, HNHO masers, H-H objects, and other objects associated with star formation. A comparison of emission line widths indicates that turbulent or systematic velocities do not increase in the central cores of molecular clouds.

Microwave radiation from ammonia was observed in several galactic objects including W3(OH), Orion A, W43, W51, and five sources in the galactic centre. The high detection rate indicates that this is a common molecule in the interstellar medium and that high-density regions are common in the galaxy.

VLA observations of NH in seven regions with high-velocity gaseous outflows revealed condensations of less than 0.1 pc in L1551, S140, and Cepheus A. Three individual condensations were detected in Cepheus A, one of them with a highly elongated shape. They may play an important role in creating the bipolar outflow in the region.

Extragalactic ammonia was imaged using the VLA in IC 342. The hot gas has temperatures above 70 K, which was inferred from ammonia line ratios and appears to be closely associated with the innermost portions of the nuclear bar seen in CO. NH was also monitored by VLA toward a sample of four galactic ultracompact HII regions: G9.62+0.19, G10.47+0.03, G29.96-0.02, and G31.41+0.31. Based upon temperature and density diagnostics, it is concluded that in general such clumps are probably the sites of massive star formation in an early evolutionary phase prior to the development of an ultracompact HII region.

Absorption at 2.97 micrometres due to solid ammonia was recorded from interstellar grains in the Becklin-Neugebauer Object and probably in NGC 2264-IR as well. This detection helped explain the physical shape of previously poorly understood and related ice absorption lines.

A spectrum of the disk of Jupiter was obtained from the Kuiper Airborne Observatory, covering the 100 to 300 cm spectral range. Analysis of the spectrum provides information on global mean properties of ammonia gas and an ammonia ice haze.

A total of 149 dark cloud positions were surveyed for evidence of 'dense cores' by using the (J,K) = (1,1) rotating inversion line of NH. In general, the cores are not spherically shaped, with aspect ratios ranging from 1.1 to 4.4. It is also found that cores with stars have broader lines than cores without stars.

Ammonia has been detected in the Draco Nebula and in one or possibly two molecular clouds, which are associated with the high-latitude galactic infrared cirrus. The finding is significant because they may represent the birthplaces for the Population I metallicity B-type stars in the galactic halo that could have been borne in the galactic disk.

By balancing and stimulated emission with spontaneous emission, it is possible to construct a relation between excitation temperature and density. Moreover, since the transitional levels of ammonia can be approximated by a 2-level system at low temperatures, this calculation is fairly simple. This premise can be applied to dark clouds, regions suspected of having extremely low temperatures and possible sites for future star formation. Detections of ammonia in dark clouds show very narrow lines—indicative not only of low temperatures, but also of a low level of inner-cloud turbulence. Line ratio calculations provide a measurement of cloud temperature that is independent of previous CO observations. The ammonia observations were consistent with CO measurements of rotation temperatures of ≈10 K. With this, densities can be determined, and have been calculated to range between 10 and 10 cm in dark clouds. Mapping of NH gives typical clouds sizes of 0.1 pc and masses near 1 solar mass. These cold, dense cores are the sites of future star formation.

Ultra-compact HII regions are among the best tracers of high-mass star formation. The dense material surrounding UCHII regions is likely primarily molecular. Since a complete study of massive star formation necessarily involves the cloud from which the star formed, ammonia is an invaluable tool in understanding this surrounding molecular material. Since this molecular material can be spatially resolved, it is possible to constrain the heating/ionising sources, temperatures, masses, and sizes of the regions. Doppler-shifted velocity components allow for the separation of distinct regions of molecular gas that can trace outflows and hot cores originating from forming stars.

Ammonia has been detected in external galaxies, and by simultaneously measuring several lines, it is possible to directly measure the gas temperature in these galaxies. Line ratios imply that gas temperatures are warm (≈50 K), originating from dense clouds with sizes of tens of pc. This picture is consistent with the picture within our Milky Way galaxy—hot dense molecular cores form around newly forming stars embedded in larger clouds of molecular material on the scale of several hundred pc (giant molecular clouds; GMCs).






</doc>
<doc id="1366" url="https://en.wikipedia.org/wiki?curid=1366" title="Amethyst">
Amethyst

Amethyst is a violet variety of quartz.

The name comes from the Koine Greek ἀμέθυστος "amethystos" from ἀ- "a-", "not" and μεθύσκω "methysko" / μεθύω "methyo", "intoxicate", a reference to the belief that the stone protected its owner from drunkenness. The ancient Greeks wore amethyst and carved drinking vessels from it in the belief that it would prevent intoxication.

Amethyst is a semiprecious stone often used in jewelry and is the traditional birthstone for February.

Amethyst is a purple variety of quartz (SiO) and owes its violet color to irradiation, impurities of iron and in some cases other transition metals, and the presence of other trace elements, which result in complex crystal lattice substitutions. The hardness of the mineral is the same as quartz, thus making it suitable for use in jewelry.

Amethyst occurs in primary hues from a light pinkish violet to a deep purple. Amethyst may exhibit one or both secondary hues, red and blue. The best varieties of amethyst can be found in Siberia, Sri Lanka, Brazil and the far East. The ideal grade is called "Deep Siberian" and has a primary purple hue of around 75–80%, with 15–20% blue and (depending on the light source) red secondary hues. ‘Rose de France’ is defined by its markedly light shade of the purple, reminiscent of a lavender/lilac shade. These pale colors, were once considered undesirable but have recently become popular due to intensive marketing.

Green quartz is sometimes incorrectly called green amethyst, which is a misnomer and not an appropriate name for the material, the proper terminology being prasiolite. Other names for green quartz are vermarine or lime citrine.

Of very variable intensity, the color of amethyst is often laid out in stripes parallel to the final faces of the crystal. One aspect in the art of lapidary involves correctly cutting the stone to place the color in a way that makes the tone of the finished gem homogeneous. Often, the fact that sometimes only a thin surface layer of violet color is present in the stone or that the color is not homogeneous makes for a difficult cutting.

The color of amethyst has been demonstrated to result from substitution by irradiation of trivalent iron (Fe) for silicon in the structure, in the presence of trace elements of large ionic radius, and, to a certain extent, the amethyst color can naturally result from displacement of transition elements even if the iron concentration is low. Natural amethyst is dichroic in reddish violet and bluish violet, but when heated, turns yellow-orange, yellow-brown, or dark brownish and may resemble citrine, but loses its dichroism, unlike genuine citrine. When partially heated, amethyst can result in ametrine.

Amethyst can fade in tone if overexposed to light sources and can be artificially darkened with adequate irradiation.

Amethyst was used as a gemstone by the ancient Egyptians and was largely employed in antiquity for intaglio engraved gems.

The Greeks believed amethyst gems could prevent intoxication, while medieval European soldiers wore amethyst amulets as protection in battle in the belief that amethysts heal people and keep them cool-headed. Beads of amethyst were found in Anglo-Saxon graves in England. Anglican bishops wear an episcopal ring often set with an amethyst, an allusion to the description of the Apostles as "not drunk" at Pentecost in Acts 2:15.

A large geode, or "amethyst-grotto", from near Santa Cruz in southern Brazil was presented at a 1902 exhibition in Düsseldorf, Germany.

In the 19th century, the color of amethyst was attributed to the presence of manganese. However, since it can be greatly altered and even discharged by heat, the color was believed by some authorities to be from an organic source. Ferric thiocyanate has been suggested, and sulfur was said to have been detected in the mineral.

Synthetic (laboratory-grown) amethyst is produced by a synthesis method called hydrothermal growth, which grows the crystals inside a high-pressure autoclave.

Synthetic amethyst is made to imitate the best quality amethyst. Its chemical and physical properties are the same to that of natural amethyst and it can not be differentiated with absolute certainty without advanced gemmological testing (which is often cost-prohibitive). There is one test based on "Brazil law twinning" (a form of quartz twinning where right and left hand quartz structures are combined in a single crystal) which can be used to identify synthetic amethyst rather easily. It is possible to synthesize twinned amethyst, but this type is not available in large quantities in the market.

Single-crystal quartz is very desirable in the industry, particularly for keeping the regular vibrations necessary for quartz movements in watches and clocks, which is where a lot of synthetic quartz is used.

Treated amethyst is produced by gamma ray, X-ray or electron beam irradiation of clear quartz (rock crystal) which has been first doped with ferric impurities. On exposure to heat, the irradiation effects can be partially cancelled and amethyst generally becomes yellow or even green, and much of the citrine, cairngorm, or yellow quartz of jewelry is said to be merely "burnt amethyst".

The Greek word "amethystos" may be translated as "not drunken", from Greek "a-", "not" + "methustos", "intoxicated". Amethyst was considered to be a strong antidote against drunkenness, which is why wine goblets were often carved from it. In his poem "L'Amethyste, ou les Amours de Bacchus et d'Amethyste" (Amethyst or the loves of Bacchus and Amethyste), the French poet Remy Belleau (1528–1577) invented a myth in which Bacchus, the god of intoxication, of wine, and grapes was pursuing a maiden named Amethyste, who refused his affections. Amethyste prayed to the gods to remain chaste, a prayer which the chaste goddess Diana answered, transforming her into a white stone. Humbled by Amethyste's desire to remain chaste, Bacchus poured wine over the stone as an offering, dyeing the crystals purple.

Variations of the story include that Dionysus had been insulted by a mortal and swore to slay the next mortal who crossed his path, creating fierce tigers to carry out his wrath. The mortal turned out to be a beautiful young woman, Amethystos, who was on her way to pay tribute to Artemis. Her life was spared by Artemis, who transformed the maiden into a statue of pure crystalline quartz to protect her from the brutal claws. Dionysus wept tears of wine in remorse for his action at the sight of the beautiful statue. The god's tears then stained the quartz purple.

This myth and its variations are not found in classical sources. However, the titan Rhea does present Dionysus with an amethyst stone to preserve the wine-drinker's sanity in historical text.

Tibetans consider amethyst sacred to the Buddha and make prayer beads from it. Amethyst is considered the birthstone of February. In the Middle Ages, it was considered a symbol of royalty and used to decorate English regalia. In the Old World, amethyst was considered one of the Cardinal gems, in that it was one of the five gemstones considered precious above all others, until large deposits were found in Brazil.

Amethyst is produced in abundance from the state of Minas Gerais in Brazil where it occurs in large geodes within volcanic rocks. Many of the hollow agates of southwestern Brazil and Uruguay contain a crop of amethyst crystals in the interior. Artigas, Uruguay and neighboring Brazilian state Rio Grande do Sul are large world producers exceeding in quantity Minas Gerais, as well as Mato Grosso, Espirito Santo, Bahia, and Ceará states, all amethyst producers of importance in Brazil.

It is also found and mined in South Korea. The largest opencast amethyst vein in the world is in Maissau, Lower Austria. Much fine amethyst comes from Russia, especially from near Mursinka in the Ekaterinburg district, where it occurs in drusy cavities in granitic rocks. Many localities in south India yield amethyst. One of the largest global amethyst producers is Zambia in southern Africa with an annual production of about 1000 tons.

Amethyst occurs at many localities in the United States. Among these may be mentioned: the Mazatzal Mountain region in Gila and Maricopa Counties, Arizona; Red Feather Lakes, near Ft Collins, Colorado; Amethyst Mountain, Texas; Yellowstone National Park; Delaware County, Pennsylvania; Haywood County, North Carolina; Deer Hill and Stow, Maine and in the Lake Superior region of Minnesota, Wisconsin and Michigan. Amethyst is relatively common in the Canadian provinces of Ontario and Nova Scotia. The largest amethyst mine in North America is located in Thunder Bay, Ontario.

Up until the 18th century, amethyst was included in the cardinal, or most valuable, gemstones (along with diamond, sapphire, ruby, and emerald). However, since the discovery of extensive deposits in locations such as Brazil, it has lost most of its value.

Collectors look for depth of color, possibly with red flashes if cut conventionally. As amethyst is readily available in large structures the value of the gem is not primarily defined by carat weight; this is different to most gemstones where the carat weight exponentially increases the value of the stone. The biggest factor in the value of amethyst is the color displayed.

The highest grade amethyst (called "Deep Russian") is exceptionally rare and therefore, when one is found, its value is dependent on the demand of collectors. It is, however, still orders of magnitude lower than the highest grade sapphires or rubies (padparadscha sapphire or "pigeon's blood" ruby).



</doc>
<doc id="1367" url="https://en.wikipedia.org/wiki?curid=1367" title="Albertosaurus">
Albertosaurus

Albertosaurus (; meaning "Alberta lizard") is a genus of tyrannosaurid theropod dinosaurs that lived in western North America during the Late Cretaceous Period, about 70 million years ago. The type species, "A. sarcophagus", was apparently restricted in range to the modern-day Canadian province of Alberta, after which the genus is named. Scientists disagree on the content of the genus, with some recognizing "Gorgosaurus libratus" as a second species. 

As a tyrannosaurid, "Albertosaurus" was a bipedal predator with tiny, two-fingered hands and a massive head that had dozens of large, sharp teeth. It may have been at the top of the food chain in its local ecosystem. While "Albertosaurus" was large for a theropod, it was much smaller than its larger and more famous relative "Tyrannosaurus rex", growing nine to ten meters long and possibly weighing less than 2 metric tons.

Since the first discovery in 1884, fossils of more than 30 individuals have been recovered, providing scientists with a more detailed knowledge of "Albertosaurus" anatomy than is available for most other tyrannosaurids. The discovery of 26 individuals at one site provides evidence of pack behaviour and allows studies of ontogeny and population biology, which are impossible with lesser-known dinosaurs.

"Albertosaurus" was smaller than some other tyrannosaurids, such as "Tarbosaurus" and "Tyrannosaurus". Typical "Albertosaurus" adults measured up to long, while rare individuals of great age could grow to be over long. Several independent mass estimates, obtained by different methods, suggest that an adult "Albertosaurus" weighed between 1.3 tonnes and 1.7 tonnes (1.9 tons).

"Albertosaurus" shared a similar body appearance with all other tyrannosaurids. Typically for a theropod, "Albertosaurus" was bipedal and balanced the heavy head and torso with a long tail. However, tyrannosaurid forelimbs were extremely small for their body size and retained only two digits. The hind limbs were long and ended in a four-toed foot on which the first digit, called the hallux, was short and did not reach the ground. The third digit was longer than the rest. "Albertosaurus" may have been able to reach walking speeds of 14−21 km/hour (8−13 mi/hour). At least for the younger individuals, a high running speed is plausible.

Two skin impressions from "Albertosaurus" are known, both showing scales. One patch is found with some gastralic ribs and the impression of a long, unknown bone, indicating that the patch is from the belly. The scales are pebbly and gradually become larger and somewhat hexagonal in shape. Also preserved are two larger feature scales, placed 4,5 cm apart from each other. Another skin impression is from an unknown part of the body. These scales are small, diamond-shaped and arranged in rows.

The massive skull of "Albertosaurus", which was perched on a short, S-shaped neck, was about long in the largest adults. Wide openings in the skull (fenestrae) reduced the weight of the head while also providing space for muscle attachment and sensory organs. Its long jaws contained, both sides combined, 58 or more banana-shaped teeth; larger tyrannosaurids possessed fewer teeth, "Gorgosaurus" at least 62. Unlike most theropods, "Albertosaurus" and other tyrannosaurids were heterodont, with teeth of different forms depending on their position in the mouth. The premaxillary teeth at the tip of the upper jaw, four per side, were much smaller than the rest, more closely packed, and D-shaped in cross section. Like with "Tyrannosaurus", the maxillary (cheek) teeth of "Albertosaurus" were adapted in general form to resist lateral forces exerted by a struggling prey. The bite force of "Albertosaurus" was less formidable, however, with the maximum force, by the hind teeth, reaching 3,413 Newtons. Above the eyes were short bony crests that may have been brightly coloured in life and used in courtship to attract a mate.

William Abler observed in 2001 that "Albertosaurus" tooth serrations resemble a crack in the tooth ending in a round void called an ampulla. Tyrannosaurid teeth were used as holdfasts for pulling flesh off a body, so when a tyrannosaur pulled back on a piece of meat, the tension could cause a purely crack-like serration to spread through the tooth. However, the presence of the ampulla distributed these forces over a larger surface area, and lessened the risk of damage to the tooth under strain. The presence of incisions ending in voids has parallels in human engineering. Guitar makers use incisions ending in voids to, as Abler describes, "impart alternating regions of flexibility and rigidity" to wood they work. The use of a drill to create an "ampulla" of sorts and prevent the propagation of cracks through material is also used to protect aircraft surfaces. Abler demonstrated that a plexiglass bar with incisions called "kerfs" and drilled holes was more than 25% stronger than one with only regularly placed incisions. Unlike tyrannosaurs, ancient predators like phytosaurs and "Dimetrodon" had no adaptations to prevent the crack-like serrations of their teeth from spreading when subjected to the forces of feeding.

"Albertosaurus" was named by Henry Fairfield Osborn in a one-page note at the end of his 1905 description of "Tyrannosaurus rex". The name honours Alberta, the Canadian province established the same year, in which the first remains were found. The generic name also incorporates the Greek term "σαυρος"/"sauros" ("lizard"), the most common suffix in dinosaur names. The type species is "Albertosaurus sarcophagus"; the specific name is derived from Ancient Greek σαρκοφάγος ("sarkophagos") meaning "flesh-eating" and having the same etymology as the funeral container with which it shares its name: a combination of the Greek words σαρξ/' ("flesh") and φαγειν/' ("to eat"). More than 30 specimens of all ages are known to science.

The type specimen is a partial skull, collected in the summer of 1884 from an outcrop of the Horseshoe Canyon Formation alongside the Red Deer River, in Alberta. This specimen, found on June 9, 1884, was recovered by an expedition of the Geological Survey of Canada, led by the famous geologist Joseph Burr Tyrrell. Due to a lack of specialised equipment the almost complete skull could only be partially secured. In 1889, Tyrrell's colleague Thomas Chesmer Weston found an incomplete smaller skull associated with some skeletal material at a location nearby. The two skulls were assigned to the preexisting species "Laelaps incrassatus" by Edward Drinker Cope in 1892, although the name "Laelaps" was preoccupied by a genus of mite and had been changed to "Dryptosaurus" in 1877 by Othniel Charles Marsh. Cope refused to recognize the new name created by his archrival Marsh. However, Lawrence Lambe used the name "Dryptosaurus incrassatus" instead of "Laelaps incrassatus" when he described the remains in detail in 1903 and 1904, a combination first coined by Oliver Perry Hay in 1902. Shortly later, Osborn pointed out that "D. incrassatus" was based on generic tyrannosaurid teeth, so the two Horseshoe Canyon skulls could not be confidently referred to that species. The Horseshoe Canyon skulls also differed markedly from the remains of "D. aquilunguis", type species of "Dryptosaurus", so Osborn created the new name "Albertosaurus sarcophagus" for them in 1905. He did not describe the remains in any great detail, citing Lambe's complete description the year before. Both specimens (the holotype CMN 5600 and the paratype CMN 5601) are stored in the Canadian Museum of Nature in Ottawa. By the early twenty-first century, some concerns had arisen that, due to the damaged state of the holotype, "Albertosaurus" might be a "nomen dubium", a "dubious name" that could only be used for the type specimen itself because other fossils could not reliably be assigned to it. However, in 2010, Thomas Carr established that the holotype, the paratype and comparable later finds all shared a single common unique trait or autapomorphy: the possession of an enlarged pneumatic opening in the back rim of the side of the palatine bone, proving that "Albertosaurus" was a valid taxon.

On 11 August 1910, American paleontologist Barnum Brown discovered the remains of a large group of "Albertosaurus" at another quarry alongside the Red Deer River. Because of the large number of bones and the limited time available, Brown's party did not collect every specimen, but made sure to collect remains from all of the individuals that they could identify in the bonebed. Among the bones deposited in the American Museum of Natural History collections in New York City are seven sets of right metatarsals, along with two isolated toe bones that did not match any of the metatarsals in size. This indicated the presence of at least nine individuals in the quarry. Palaeontologist Philip J. Currie of the Royal Tyrrell Museum of Palaeontology rediscovered the bonebed in 1997 and resumed fieldwork at the site, which is now located inside Dry Island Buffalo Jump Provincial Park. Further excavation from 1997 to 2005 turned up the remains of 13 more individuals of various ages, including a diminutive two-year-old and a very old individual estimated at over in length. None of these individuals are known from complete skeletons, and most are represented by remains in both museums. Excavations continued until 2008, when the minimum number of individuals present had been established at 12, on the basis of preserved elements that occur only once in a skeleton, and at 26 if mirrored elements were counted when differing in size due to ontogeny. A total of 1,128 "Albertosaurus" bones had been secured, the largest concentration of large theropod fossils known from the Cretaceous.

In 1911, Barnum Brown, during the second year of American Museum of Natural History operations in Alberta, uncovered a fragmentary partial "Albertosaurus" skull at the Red Deer River near Tolman Bridge, specimen AMNH 5222.

William Parks described a new species in 1928, "Albertosaurus arctunguis", based on a partial skeleton lacking the skull excavated by Gus Lindblad and Ralph Hornell near the Red Deer River in 1923, but this species has been considered identical to "A. sarcophagus" since 1970. Parks' specimen (ROM 807) is housed in the Royal Ontario Museum in Toronto.

Between 1926 and 1972, no "Albertosaurus" fossils were found at all; but, since the seventies, there has been a steady increase in the known material. Apart from the Dry Island bonebed, six more skulls and skeletons have since been discovered in Alberta and are housed in various Canadian museums: specimens RTMP 81.010.001, found in 1978 by amateur paleontologist Maurice Stefanuk; RTMP 85.098.001, found by Stefanuk on 16 June 1985; RTMP 86.64.001 (December 1985); RTMP 86.205.001 (1986); RTMP 97.058.0001 (1996); and CMN 11315. However, due to vandalism and accidents, no undamaged and complete skulls could be secured among these finds. Fossils have also been reported from the American states of Montana, New Mexico, and Wyoming, but these probably do not represent "A. sarcophagus" and may not even belong to the genus "Albertosaurus".

In 1913, paleontologist Charles H. Sternberg recovered another tyrannosaurid skeleton from the slightly older Dinosaur Park Formation in Alberta. Lawrence Lambe named this dinosaur "Gorgosaurus libratus" in 1914. Other specimens were later found in Alberta and the US state of Montana. Finding, largely due to a lack of good "Albertosaurus" skull material, no significant differences to separate the two taxa, Dale Russell declared the name "Gorgosaurus" a junior synonym of "Albertosaurus", which had been named first, and "G. libratus" was renamed "Albertosaurus libratus" in 1970. A species distinction was maintained because of the age difference. This addition extended the temporal range of the genus "Albertosaurus" backwards by several million years and its geographic range southwards by hundreds of kilometres.

In 2003, Philip J. Currie, benefiting from much more extensive finds and a general increase in anatomical knowledge of theropods, compared several tyrannosaurid skulls and came to the conclusion that the two species are more distinct than previously thought. The decision to use one or two genera is rather arbitrary, as the two species are sister taxa, more closely related to each other than to any other species. Recognizing this, Currie nevertheless recommended that "Albertosaurus" and "Gorgosaurus" be retained as separate genera, as he concluded that they were no more similar than "Daspletosaurus" and "Tyrannosaurus", which are almost always separated. In addition, several albertosaurine specimens have been recovered from Alaska and New Mexico, and Currie suggested that the "Albertosaurus"-"Gorgosaurus" situation may be clarified once these are described fully. Most authors have followed Currie's recommendation, but some have not.

Apart from "A. sarcophagus", "A. arctunguis" and "A. libratus", several other species of "Albertosaurus" have been named. All of these are today seen as younger synonyms of other species or as "nomina dubia", and are not assigned to "Albertosaurus".

In 1930, Anatoly Nikolaevich Riabinin named "Albertosaurus pericolosus" based on a tooth from China, that probably belonged to "Tarbosaurus". In 1932, Friedrich von Huene renamed "Dryptosaurus incrassatus", not considered a "nomen dubium" by him, to "Albertosaurus incrassatus". Because he had identified "Gorgosaurus" with "Albertosaurus", in 1970, Russell also renamed "Gorgosaurus sternbergi" (Matthew & Brown 1922) into "Albertosaurus sternbergi" and "Gorgosaurus lancensis" (Gilmore 1946) into "Albertosaurus lancensis". The former species is today seen as a juvenile form of "Gorgosaurus libratus", the latter as either identical to "Tyrannosaurus" or representing a separate genus "Nanotyrannus". In 1988, Gregory S. Paul based "Albertosaurus megagracilis" on a small tyrannosaurid skeleton, specimen LACM 28345, from the Hell Creek Formation of Montana. It was renamed "Dinotyrannus" in 1995, but is now thought to represent a juvenile "Tyrannosaurus rex". Also in 1988, Paul renamed "Alectrosaurus olseni" (Gilmore 1933) into "Albertosaurus olseni"; this has found no general acceptance. In 1989, "Gorgosaurus novojilovi" (Maleev 1955) was renamed by Bryn Mader and Robert Bradley as "Albertosaurus novojilovi"; today this is seen as a synonym of "Tarbosaurus".

On two occasions, species based on valid "Albertosaurus" material were reassigned to a different genus: in 1922 William Diller Matthew renamed "A. sarcophagus" into "Deinodon sarcophagus" and in 1939 German paleontologist Oskar Kuhn renamed "A. arctunguis" into "Deinodon arctunguis".

"Albertosaurus" is a member of the theropod family Tyrannosauridae, in the subfamily Albertosaurinae. Its closest relative is the slightly older "Gorgosaurus libratus" (sometimes called "Albertosaurus libratus"; see below). These two species are the only described albertosaurines; other undescribed species may exist. Thomas Holtz found "Appalachiosaurus" to be an albertosaurine in 2004, but his more recent unpublished work locates it just outside Tyrannosauridae, in agreement with other authors.

The other major subfamily of tyrannosaurids is the Tyrannosaurinae, which includes "Daspletosaurus", "Tarbosaurus" and "Tyrannosaurus". Compared with these robust tyrannosaurines, albertosaurines had slender builds, with proportionately smaller skulls and longer bones of the lower leg (tibia) and feet (metatarsals and phalanges).

Below is the cladogram of the Tyrannosauridae based on the phylogenetic analysis conducted by Loewen "et al." in 2013.

Most age categories of "Albertosaurus" are represented in the fossil record. Using bone histology, the age of an individual animal at the time of death can often be determined, allowing growth rates to be estimated and compared with other species. The youngest known "Albertosaurus" is a two-year-old discovered in the Dry Island bonebed, which would have weighed about 50 kilograms (110 lb) and measured slightly more than in length. The specimen from the same quarry is the oldest and largest known, at 28 years of age. When specimens of intermediate age and size are plotted on a graph, an "S"-shaped growth curve results, with the most rapid growth occurring in a four-year period ending around the sixteenth year of life, a pattern also seen in other tyrannosaurids. The growth rate during this phase was per year, based on an adult 1.3 tonnes. Other studies have suggested higher adult weights; this would affect the magnitude of the growth rate, but not the overall pattern. Tyrannosaurids similar in size to "Albertosaurus" had similar growth rates, although the much larger "Tyrannosaurus rex" grew at almost five times this rate ( per year) at its peak. The end of the rapid growth phase suggests the onset of sexual maturity in "Albertosaurus", although growth continued at a slower rate throughout the animals' lives. Sexual maturation while still actively growing appears to be a shared trait among small and large dinosaurs as well as in large mammals such as humans and elephants. This pattern of relatively early sexual maturation differs strikingly from the pattern in birds, which delay their sexual maturity until after they have finished growing.

During growth, through thickening the tooth morphology changed so much that, had the association of young and adult skeletons on the Dry Island bonebed not proven they belonged to the same taxon, the teeth of juveniles would likely have been identified by statistical analysis as those of a different species.

Most known "Albertosaurus" individuals were aged 14 years or more at the time of death. Juvenile animals are rarely found as fossils for several reasons, mainly preservation bias, where the smaller bones of younger animals were less likely to be preserved by fossilization than the larger bones of adults, and collection bias, where smaller fossils are less likely to be noticed by collectors in the field. Young "Albertosaurus" are relatively large for juvenile animals, but their remains are still rare in the fossil record compared with adults. It has been suggested that this phenomenon is a consequence of life history, rather than bias, and that fossils of juvenile "Albertosaurus" are rare because they simply did not die as often as adults did.

A hypothesis of "Albertosaurus" life history postulates that hatchlings died in large numbers, but have not been preserved in the fossil record due to their small size and fragile construction. After just two years, juveniles were larger than any other predator in the region aside from adult "Albertosaurus", and more fleet of foot than most of their prey animals. This resulted in a dramatic decrease in their mortality rate and a corresponding rarity of fossil remains. Mortality rates doubled at age twelve, perhaps the result of the physiological demands of the rapid growth phase, and then doubled again with the onset of sexual maturity between the ages of fourteen and sixteen. This elevated mortality rate continued throughout adulthood, perhaps due to the high physiological demands of procreation, including stress and injuries received during intraspecific competition for mates and resources, and eventually, the ever-increasing effects of senescence. The higher mortality rate in adults may explain their more common preservation. Very large animals were rare because few individuals survived long enough to attain such sizes. High infant mortality rates, followed by reduced mortality among juveniles and a sudden increase in mortality after sexual maturity, with very few animals reaching maximum size, is a pattern observed in many modern large mammals, including elephants, African buffalo, and rhinoceros. The same pattern is also seen in other tyrannosaurids. The comparison with modern animals and other tyrannosaurids lends support to this life history hypothesis, but bias in the fossil record may still play a large role, especially since more than two-thirds of all "Albertosaurus" specimens are known from one locality.

The Dry Island bonebed discovered by Barnum Brown and his crew contains the remains of 26 "Albertosaurus", the most individuals found in one locality of any large Cretaceous theropod, and the second-most of any large theropod dinosaur behind the "Allosaurus" assemblage at the Cleveland-Lloyd Dinosaur Quarry in Utah. The group seems to be composed of one very old adult; eight adults between 17 and 23 years old; seven sub-adults undergoing their rapid growth phases at between 12 and 16 years old; and six juveniles between the ages of 2 and 11 years, who had not yet reached the growth phase.

The near-absence of herbivore remains and the similar state of preservation common to the many individuals at the "Albertosaurus" bonebed quarry led Currie to conclude that the locality was not a predator trap like the La Brea Tar Pits in California, and that all of the preserved animals died at the same time. Currie claims this as evidence of pack behaviour. Other scientists are skeptical, observing that the animals may have been driven together by drought, flood or for other reasons.

There is plentiful evidence for gregarious behaviour among herbivorous dinosaurs, including ceratopsians and hadrosaurs. However, only rarely are so many dinosaurian predators found at the same site. Small theropods like "Deinonychus" and "Coelophysis" have been found in aggregations, as have larger predators like "Allosaurus" and "Mapusaurus". There is some evidence of gregarious behaviour in other tyrannosaurids as well. Fragmentary remains of smaller individuals were found alongside "Sue", the "Tyrannosaurus" mounted in the Field Museum of Natural History in Chicago, and a bonebed in the Two Medicine Formation of Montana contains at least three specimens of "Daspletosaurus", preserved alongside several hadrosaurs. These findings may corroborate the evidence for social behaviour in "Albertosaurus", although some or all of the above localities may represent temporary or unnatural aggregations. Others have speculated that instead of social groups, at least some of these finds represent Komodo dragon-like mobbing of carcasses, where aggressive competition leads to some of the predators being killed and cannibalized.

Currie has also speculated on the pack-hunting habits of "Albertosaurus". The leg proportions of the smaller individuals were comparable to those of ornithomimids, which were probably among the fastest dinosaurs. Younger "Albertosaurus" were probably equally fleet-footed, or at least faster than their prey. Currie hypothesized that the younger members of the pack may have been responsible for driving their prey towards the adults, who were larger and more powerful, but also slower. Juveniles may also have had different lifestyles than adults, filling predator niches between the enormous adults and the smaller contemporaneous theropods, the largest of which were two orders of magnitude smaller than adult "Albertosaurus" in mass. A similar situation is observed in modern Komodo dragons, with hatchlings beginning life as small insectivores before growing to become the dominant predators on their islands. However, as the preservation of behaviour in the fossil record is exceedingly rare, these ideas cannot readily be tested. In 2010, Currie, though still favouring the hunting pack hypothesis, admitted that the concentration could have been brought about by other causes, such as a slowly rising water level during an extended flood.

In 2009, researchers hypothesized that smooth-edged holes found in the fossil jaws of tyrannosaurid dinosaurs such as "Albertosaurus" were caused by a parasite similar to "Trichomonas gallinae", which infects birds. They suggested that tyrannosaurids transmitted the infection by biting each other, and that the infection impaired their ability to eat food.

In 2001, Bruce Rothschild and others published a study examining evidence for stress fractures and tendon avulsions in theropod dinosaurs and the implications for their behavior. They found that only one of the 319 "Albertosaurus" foot bones checked for stress fractures actually had them and none of the four hand bones did. The scientists found that stress fractures were "significantly" less common in "Albertosaurus" than in the carnosaur "Allosaurus". ROM 807, the holotype of "A. arctunguis" (now referred to "A. sarcophagus"), had a deep hole in the iliac blade, although the describer of the species did not recognize this as pathological. The specimen also contains some exostosis on the fourth left metatarsal. In 1970, two of the five "Albertosaurus sarcophagus" specimens with humeri were reported by Dale Russel as having pathological damage to them.

In 2010, the health of the Dry Island "Albertosaurus" assembly was reported upon. Most specimens showed no sign of disease. On three phalanges of the foot strange bony spurs, consisting of abnormal ossifications of the tendons, so-called enthesophytes, were present, their cause unknown. Two ribs and a belly-rib showed signs of breaking and healing. One adult specimen had a left lower jaw showing a puncture wound and both healed and unhealed bite marks. The low number of abnormalities compares favourably with the health condition of a "Majungasaurus" population of which it in 2007 was established that 19% of individuals showed bone pathologies.

According to a scientific paper published in 2012, "Albertosaurus" could exert a bite force of around 42,000 newtons.

Most fossils of "Albertosaurus sarcophagus" are known from the upper Horseshoe Canyon Formation in Alberta. These younger units of this geologic formation date to the early Maastrichtian stage of the Late Cretaceous Period, 70 to 68 Ma (million years ago). Immediately below this formation is the Bearpaw Shale, a marine formation representing a section of the Western Interior Seaway. The seaway was receding as the climate cooled and sea levels subsided towards the end of the Cretaceous, exposing land that had previously been underwater. It was not a smooth process, however, and the seaway would periodically rise to cover parts of the region throughout Horseshoe Canyon before finally receding altogether in the years after. Due to the changing sea levels, many different environments are represented in the Horseshoe Canyon Formation, including offshore and near-shore marine habitats and coastal habitats like lagoons, estuaries and tidal flats. Numerous coal seams represent ancient peat swamps. Like most of the other vertebrate fossils from the formation, "Albertosaurus" remains are found in deposits laid down in the deltas and floodplains of large rivers during the later half of Horseshoe Canyon times.

The fauna of the Horseshoe Canyon Formation is well-known, as vertebrate fossils, including those of dinosaurs, are quite common. Sharks, rays, sturgeons, bowfins, gars and the gar-like "Aspidorhynchus" made up the fish fauna. Mammals included multituberculates and the marsupial "Didelphodon". The saltwater plesiosaur "Leurospondylus" has been found in marine sediments in the Horseshoe Canyon, while freshwater environments were populated by turtles, "Champsosaurus", and crocodilians like "Leidyosuchus" and "Stangerochampsa". Dinosaurs dominate the fauna, especially hadrosaurs, which make up half of all dinosaurs known, including the genera "Edmontosaurus", "Saurolophus" and "Hypacrosaurus". Ceratopsians and ornithomimids were also very common, together making up another third of the known fauna. Along with much rarer ankylosaurians and pachycephalosaurs, all of these animals would have been prey for a diverse array of carnivorous theropods, including troodontids, dromaeosaurids, and caenagnathids. Intermingled with the "Albertosaurus" remains of the Dry Island bonebed, the bones of the small theropod "Albertonykus" were found. Adult "Albertosaurus" were the apex predators in this environment, with intermediate niches possibly filled by juvenile albertosaurs.



</doc>
