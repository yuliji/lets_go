<doc id="12343" url="https://en.wikipedia.org/wiki?curid=12343" title="Guadeloupe">
Guadeloupe

Guadeloupe (; ; Antillean Creole: "Gwadloup") is an overseas region of France in the Caribbean. It consists of six inhabited islands, Basse-Terre, Grande-Terre, Marie-Galante, La Désirade, and the Îles des Saintes, as well as many uninhabited islands and outcroppings.

Like the other overseas departments, it is an integral part of France. As a constituent territory of the European Union and the Eurozone, the euro is its official currency and any European Union citizen is free to settle and work there indefinitely. As an overseas department, however, it is not part of the Schengen Area. The official language is French. Antillean Creole is also spoken.

The archipelago was called "Karukera" (or "The Island of Beautiful Waters") by the Arawak people, who settled on there in the year 300.

Christopher Columbus named the island Santa María de Guadalupe in 1493 after the Virgin Mary, venerated in the Spanish town of Guadalupe. Upon becoming a French colony, the Spanish name was retained though altered to French orthography and phonology. The islands are locally known as Gwada.

The islands were first populated by indigenous peoples of the Americas about 5,000 years ago. Arawak people settled in the area, who were in turn replaced by the Kalina or Caribs. 

Christopher Columbus landed on the island in 1493. During the 1600s, the Kalina repelled Spanish settlers. The Compagnie des Îles de l'Amérique settled in Guadeloupe in 1635, took possession of the island, and brought in French farmers to colonise the land. This led to the death of many Caribs by disease and violence.

By 1640, the Compagnie des Îles de l'Amérique had gone bankrupt, and sold the land to Charles Houël du Petit Pré who began plantation agriculture, with the first African slaves arriving in 1650. Ownership of the island then passed to the French West India Company before it was annexed to France in 1674. Institutionalized slavery, enforced by the Code Noir from 1685, led to a booming sugar plantation economy.

During the Seven Years' War the English occupied Guadeloupe from the time of 1759 British Invasion of Guadeloupe until the 1763 Treaty of Paris. During this time Pointe-à-Pitre became a major harbour, and markets in Britain's North American colonies were opened to Guadeloupean sugar which was traded for cheap food and lumber. The economy expanded quickly, growing the wealth of colonists. During this time about 18,000 slaves were brought in. So prosperous was Guadeloupe at the time that under the 1763 Treaty of Paris France forfeited its Canadian colonies in exchange for Guadeloupe. Coffee planting began in 1770, increasing slavery, and by 1775 cocoa had become a major export product. 

The 1789 French Revolution brought chaos to Guadeloupe. Under new revolutionary law free people of color were entitled to equal rights. In the anarchy that followed, the British invaded, to which the French responded by sending soldiers led by Victor Hugues who retook the lands and abolished slavery. In the Reign of Terror that followed more than 1,000 colonists were killed. In 1802 the First French Empire reinstated the prerevolutionary government and slavery. In 1810 the British again seized the island, handing it over to Sweden in 1813. In the Treaty of Paris of 1814, Sweden ceded Guadeloupe to France, giving rise to the Guadeloupe Fund. In 1816 the Treaty of Vienna definitively acknowledged French control of Guadeloupe.

Six years after the final abolition of slavery in 1848, indentured servants from the French colony of Pondicherry in what is now India were brought in. Emancipated slaves had the vote from 1849, but French nationality and the vote was not granted to Indian citizens until 1921. 

In 1946, the colony of Guadeloupe became an overseas department of France.

In January 2009, labour unions and others known as the Liyannaj Kont Pwofitasyon went on strike for more pay. The strike lasted 44 days. Tourism suffered greatly during this time and affected the 2010 tourist season as well. The 2009 French Caribbean general strikes exposed deep ethnic, racial, and class tensions and disparities within Guadeloupe.

Guadeloupe is an archipelago of more than 12 islands, as well as islets and rocks situated where the northeastern Caribbean Sea meets the western Atlantic Ocean. It is in the Leeward Islands, in the northern part of the Lesser Antilles, an island arc, partly a volcanic arc. Montserrat is visible from the north, and Dominica is visible from the south.

Most of the inhabitants live on a pair of islands, Basse-Terre Island and Grande-Terre, which form a butterfly shape, viewed from above, the two wings of which are separated by a narrow sea channel, la Rivière Salée.

More than half of Guadeloupe's land surface is on the 847.8 km Basse-Terre. Basse-Terre is mountainous, including the active volcano La Grande Soufrière, the highest mountain peak in the Lesser Antilles, with an elevation of .

Les Saintes is an archipelago of eight islands of which two, Terre-de-Bas and Terre-de-Haut are inhabited. The landscape is similar to that of Basse-Terre, with volcanic hills and irregular shoreline with deep bays.

Grande-Terre, is mostly flat, with rocky coasts to the north, irregular hills at the centre, mangrove at the southwest, and white sand beaches sheltered by coral reefs along the south shore. This is where the main tourist resorts are found.

La Désirade, an island east of Grande-Terre, is a north-east slanted limestone plateau, the highest point of which is . Nearby is Petite-Terre, which are two islands Terre de Haut and Terre de Bas totalling 2 km.

Marie-Galante and La Désirade are generally low-lying.

Basse-Terre is a volcanic island. The Lesser Antilles are at the outer edge of the Caribbean Plate, and Guadeloupe is part of the outer arc of the Lesser Antilles Volcanic Arc. Many of the islands were formed as a result of the subduction of oceanic crust of the Atlantic Plate under the Caribbean Plate in the Lesser Antilles subduction zone. This process is ongoing and is responsible for volcanic and earthquake activity in the region. Guadeloupe was formed from multiple volcanoes, of which only la Soufriere is not extinct. Its last eruption was in 1976, and led to the evacuation of the southern part of Basse-Terre. 73,600 people were displaced over a course of three and a half months following the eruption.

K–Ar dating indicates that the three northern massifs on Basse-Terre Island are 2.79 million years old. Sections of volcanoes collapsed and eroded within the last 650,000 years, after which the Sans Toucher volcano grew in the collapsed area. Volcanoes in the north of Basse-Terre Island mainly produced andesite and basaltic andesite. There are several beaches of dark or "black" sand.

La Désirade, east of the main islands has a basement from the Mesozoic, overlaid with thick limestones from the Pliocene to Quaternary periods.

Grande-Terre and Marie-Galante have basements probably composed of volcanic units of Eocene to Oligocene, but there are no visible outcrops. On Grande-Terre, the overlying carbonate platform is 120 metres thick.

The islands are part of the Leeward Islands, so called because they are downwind of the prevailing trade winds, which blow out of the northeast. This was significant in the days of sailing ships. Haute-Terre is so named because it is on the eastern, or windward side, exposed to the Atlantic winds. Basse-Terre is so named because it is on the leeward south-west side and sheltered from the winds.

Among storms to make landfall on the islands are: Hurricane Cleo in 1966, Hurricane Hugo in 1989, and Hurricane Maria in 2017.

Guadeloupe has a tropical climate tempered by maritime influences and the Trade Winds. There are two seasons, the dry season called "Lent" from January to June, and the wet season called "winter", from July to December.

With fertile volcanic soils, heavy rainfall and a warm climate, vegetation on Basse-Terre is lush. Most of the islands' forest is on Basse-Terre.

Mangrove swamps line the Salée River.

Guadeloupe recorded a population of 402,119 in the 2013 census.

The population of Guadeloupe is mainly of Afro-Caribbean or mixed descent of Europeans, Indians (Tamil, Telugu, and other South Indians), Lebanese, Syrians, and Chinese.

The population of Guadeloupe has been stable recently, with a net increase of only 335 people between the 2008 and 2013 censuses.

In 2012 the average population density in Guadeloupe was 247.7 inhabitants for every square kilometre, which is very high in comparison to the whole France's 116.5 inhabitants for every square kilometre. One third of the land is devoted to agriculture and all mountains are uninhabitable. This lack of space and shelter makes the population density even higher.

Because Guadeloupe is a wealthy country in comparison to the surrounding Caribbean islands, immigration is popular. People immigrate to Guadeloupe because of its stronger political stability and greater agricultural job opportunities. However, just because foreigners immigrate to Guadeloupe for its opportunities does not mean the country is economically stable; rather, it is stable in comparison to the surrounding regions/islands.

At the 2006 census the population of Basse-Terre Island was 186,661 inhabitants living in 16 communes (municipalities). The population density was 220 inhabitants per square kilometre (570/sq mi). The largest city is the city of Basse-Terre which had 37,455 inhabitants in its urban area at the 2006 census.

Over 80% of the population are Roman Catholic. Guadeloupe is in the diocese of Basse-Terre (et Pointe-à-Pitre).

In 2011, life expectancy at birth was recorded at 77.0 years for males and 83.5 for females.

Medical centers in Guadeloupe include: University Hospital Center (CHU) in Pointe-à-Pitre, Regional Hospital Center (CHR) in Basse-Terre, and four hospitals located in Capesterre-Belle-Eau, Pointe-Noire, Bouillante and Saint-Claude.

The "Institut Pasteur de la Guadeloupe", is located in Pointe-à-Pitre and is responsible for researching environmental hygiene, vaccinations, and the spread of tuberculosis and mycobacteria

Guadeloupe elects one deputy from one of each of the first, second, third, and fourth constituencies to the National Assembly of France. Three senators are chosen for the Senate of France by indirect election. 

Most of the French political parties are active in Guadeloupe. In addition there are regional parties such as the Guadeloupe Communist Party, the Progressive Democratic Party of Guadeloupe, the Guadeloupean Objective, the Pluralist Left, and United Guadaloupe, Socialism and Realities.

The top-level territorial sub-division of France is the region, which contain of departments. Guadeloupe, like a few other places (French Guiana, Martinique, Mayotte, and Réunion) is both a region and a department combined into one entity, the overseas department. Guadeloupe has separate departmental and regional councils.

The Regional Council of Guadeloupe is a body, elected every six years, consisting of a president, currently Ary Chalus, and eight vice-presidents. They were elected in 2015. The regional council oversees higher secondary education, regional transportation, economic development, the environment, and some infrastructure, among other things.

The elected president of the Departmental Council of Guadeloupe is Jacques Gillot. Its main areas of responsibility include the management of a number of social and welfare allowances, of junior high school (collège) buildings and technical staff, and local roads and school and rural buses.

The prefecture (regional capital) of Guadeloupe is Basse-Terre. Local services of the state administration are traditionally organised at departmental level, where the prefect represents the government.

For local government, Guadeloupe is divided into 32 communes. Each commune has a municipal council and a mayor. Revenues for the communes come from transfers from the French government, and local taxes. Administration done at this level includes water management, acts of birth, marriage, etc., and municipal police.

For electoral purposes, Guadeloupe is divided into two arrondissements (Basse-Terre and Pointe-à-Pitre), and 21 cantons.

In 2006, the GDP per capita of Guadeloupe at market exchange rates, not at PPP, was €17,338 (US$21,780).

The economy of Guadeloupe depends on tourism, agriculture, light industry and services. It is dependent upon mainland France for large subsidies and imports. Unemployment is especially high among the youth population.

GDP: real exchange rate - US$9.74 billion (in 2006)

GDP - real growth rate: NA%

GDP - per capita: real exchange rate - US$21,780 (in 2006)

Exports: US$676 million (in 2005)

Exports - commodities: bananas, sugar, rum

Exports - partners: Mainland France 60%, Martinique 18%, US 4% (1997)

Imports: US$3.102 billion (in 2005)

Tourism is a key industry, with 83.3% of tourists visiting from metropolitan France, 10.8% coming from the rest of Europe, 3.4% coming from the United States, 1.5% coming from Canada, 0.4% coming from South America, and 0.6% coming from the rest of the world. An increasingly large number of cruise ships visit Guadeloupe, the cruise terminal of which is in Pointe-à-Pitre.

The traditional sugar cane crop is slowly being replaced by other crops, such as bananas (which now supply about 50% of export earnings), eggplant, guinnep, noni, sapotilla, giraumon squash, yam, gourd, plantain, christophine, cocoa, jackfruit, pomegranate, and many varieties of flowers. Other vegetables and root crops are cultivated for local consumption, although Guadeloupe is dependent upon imported food, mainly from the rest of France.

Light industry features sugar and rum, solar energy, and many industrial products. Most manufactured goods and fuel are imported.

As it is a region of France, Guadeloupe's official language is French, which is spoken by nearly all of the population.
In addition, most of the population can also speak Guadeloupean Creole, a variety of Antillean Creole. Throughout the island's colonial history, Creole was the language of local community, of resistance to European domination, of ethno-racial identity. Consequently, when from the early 1970s to the mid 1980s, Guadeloupe saw the rise and fall of an at-times violent movement for (greater) political independence from France, Creole was claimed as key to local cultural pride and unity. In the 1990s, in the wake of the independence movement's demise, Creole retained its de-stigmatized status as a symbol of local culture, albeit without de jure support from the state and without being practiced with equal competence in all strata and age groups of society. The third millennium, however, brought greater acceptance of Creole on the part of France, such that it was introduced as an elective in public schools. Today, the question as to whether French and Creole are stable in Guadeloupe, i.e. whether both languages are practised widely and competently throughout society, remains a subject of active research.

Saint-John Perse won the 1960 Nobel Prize in Literature. Guadeloupe has always had a rich literary output, continued today by many living writers, poets, novelists, essayists and journalists, among them Maryse Condé and Simone Schwarz-Bart.

Music and dance are also very popular, and the widely accepted interaction of African, French and Indian cultures has given birth to some original new forms specific to the archipelago. Since the 1970s, Guadeloupean music increasingly claimed the local language, Guadeloupean Creole as the preferred language of popular music. Islanders enjoy many local dance styles including zouk, zouk-love, compas, as well as the modern international dances such as hip hop, etc.

Traditional Guadeloupean music includes biguine, kadans, cadence-lypso,and gwo ka. Popular music artists and bands such as Experience 7, Francky Vincent, Kassav' (which included Patrick St-Eloi), and Gilles Floro embody the traditional music style of the island and the new generation of music, while some other musical artists, like Tom Frager (who grew up in Guadeloupe), perform colorful reggae music that defines the Guadeloupe island as paradise-like. Many international festivals take place in Guadeloupe, like the Creole Blues Festival, hosted in Marie-Galante. All the Euro-French forms of art are also ubiquitous. The melting pot is emphasized by other communities (from Brazil, Dominican Republic, Haiti, India, Lebanon, Syria), who live on the island and share their cultures.

Another element of Guadeloupean culture is its dress. A few women (particularly of the older generation) wear a unique style of traditional dress, with many layers of colourful fabric, now only worn on special occasions. On festive occasions they also wore a madras (originally a "kerchief" from South India) head scarf tied in many different symbolic ways, each with a different name. The headdress could be tied in the "bat" style, or the "firefighter" style, as well as the "Guadeloupean woman". Jewelry, mainly gold, is also important in the Guadeloupean lady's dress, a product of European, African and Indian inspiration.

Guadeloupe is one of the safest islands in the Caribbean; nevertheless, it was the most violent overseas French department in 2016. The murder rate is slightly more than that of Paris, at 8.2 per 100,000. The high level of unemployment caused violence and crime to rise especially in 2009 and 2010, the years following a great worldwide recession. Most of this violence is caused by the drug trade or domestic disputes, and the residents of Guadeloupe describe the island as a place without much everyday crime.

Football (soccer) is popular in Guadeloupe, and several notable footballers are of Guadeloupean origin, including Stéphane Auvray, Ronald Zubar and his younger brother Stéphane, Miguel Comminges, Dimitri Foulquier, Bernard Lambourde and Anthony Martial.

The national football team were 2007 CONCACAF Gold Cup semi-finalists, defeated by Mexico.

Basketball is also popular. Best known players are the NBA players Mickaël Piétrus, Johan Petro, Rodrigue Beaubois, and Mickael Gelabale (now playing in Russia), who were born on the island.

Several track and field athletes, such as Marie-José Pérec, Patricia Girard-Léno, Christine Arron, and Wilhem Belocian, are also Guadeloupe natives. Triple Olympic champion Marie-José Pérec, and fourth-fastest runner Christine Arron.

The island has produced many world-class fencers. Yannick Borel, Daniel Jérent, Ysaora Thibus, Anita Blaze, Enzo Lefort and Laura Flessel were all born and raised in Guadeloupe. According to olympic gold medalist and world champion Yannick Borel, there is a good fencing school and a culture of fencing in Guadeloupe.

Even though Guadeloupe is part of France, it has its own sports teams. Rugby union is a small but rapidly growing sport in Guadeloupe. France international and RC Toulon centre Mathieu Bastareaud (cousin of footballer William Gallas) was born in Guadeloupe.

The island is also internationally known for hosting the Karujet Race – Jet Ski World Championship since 1998. This nine-stage, four-day event attracts competitors from around the world (mostly Caribbeans, Americans, and Europeans). The Karujet, generally made up of seven races around the island, has an established reputation as one of the most difficult championships in which to compete.

The Route du Rhum is one of the most prominent nautical French sporting events, occurring every four years.

Bodybuilder Serge Nubret was born in Anse-Bertrand, Grande-Terre, representing the French state in various bodybuilding competitions throughout the 1960s and 1970s including the IFBB's Mr. Olympia contest, taking 3rd place every year from 1972 to 1974, and 2nd place in 1975. Bodybuilder Marie-Laure Mahabir also hails from Guadeloupe.
The country has also a passion for cycling. It hosted the French Cycling Championships in 2009 and continues to host the Tour de Guadeloupe every year.

Guadeloupe also continues to host the Orange Open de Guadeloupe tennis tournament (since 2011).

The Tour of Guadeloupe sailing, which was founded in 1981.

On 9 September 2013 the county government voted in favour of constructing a tramway in Pointe-à-Pitre. The first phase will link northern Abymes to downtown Pointe-à-Pitre by 2019. The second phase, scheduled for completion in 2023, will extend the line to serve the university.



</doc>
<doc id="12345" url="https://en.wikipedia.org/wiki?curid=12345" title="Demographics of Guadeloupe">
Demographics of Guadeloupe

Guadeloupe has a population of 403,977 (2012).

According to INSEE Guadeloupe has an estimated population of 403,977 on January 1, 2012. Life expectancy at birth is 77.0 years for males, and 83.5 for females (figures for 2011).

French is the official language, taught in the school system. Antillean Creole French is spoken by a large part of the population, understood by nearly all, and taught in some schools. A 2007 document issued by the Organisation internationale de la Francophonie estimated the population to be 80.2% "francophone" and 14.9% "partially francophone".

The following vital statistics include Saint Martin and Saint Barthélemy.


Structure of the population (01.01.2010) (Provisional estimates) (Excluding data for Saint Barthélemy and Saint Martin) :


</doc>
<doc id="12349" url="https://en.wikipedia.org/wiki?curid=12349" title="Telecommunications in Guadeloupe">
Telecommunications in Guadeloupe

Telephones - main lines in use:
159,000 (1995)

Telephones - mobile cellular:
814 (1990)

Telephone system:
domestic facilities inadequate
<br>"domestic:"
NA
<br>"international:"
satellite earth station - 1 Intelsat (Atlantic Ocean); microwave radio relay to Antigua and Barbuda, Dominica, and Martinique

Radio broadcast stations:
AM 1, FM 17, shortwave 0 (1998)

Radios:
113,000 (1997)

Television broadcast stations:
5 (plus several low-power repeaters) (1997)

Televisions:
118,000 (1997)

Internet Service Providers (ISPs): France Telecom (Orange)

Country code (Top-level domain): GP



</doc>
<doc id="12350" url="https://en.wikipedia.org/wiki?curid=12350" title="Transport in Guadeloupe">
Transport in Guadeloupe

Transport in Guadeloupe.

<br>"total:"
NA km; privately owned, narrow-gauge plantation lines

<br>"total:"
2,082 km
<br>"paved:"
1,742 km
<br>"unpaved:"
340 km (1985 est.)
<br>"note:"
in 1996 there were a total of 3,200 km of roads

Basse-Terre, Pointe-à-Pitre (on Grande-Terre).

Merchant marine:
<br>"total:"
1 ship (1,000 GT or over) totaling 1,240 GT/
<br>"ships by type:"
passenger 1 (1999 est.)

9 (1999 est.)

<br>"total:"
8
<br>"over 3,047 m:"
1
<br>"914 to 1,523 m:"
2
<br>"under 914 m:"
5 (1999 est.)

<br>"total:"
1
<br>"under 914 m:"
1 (1999 est.)

<br>
Flights Booking Guadeloupe Flight's comparator specific for Guadeloupe Island


</doc>
<doc id="12353" url="https://en.wikipedia.org/wiki?curid=12353" title="Glagolitic script">
Glagolitic script

The Glagolitic script (, "Glagolitsa") is the oldest known Slavic alphabet. It is generally agreed to have been created in the 9th century by Saint Cyril, a Byzantine monk from Thessaloniki. He and his brother, Saint Methodius, were sent by the Byzantine Emperor Michael III in 863 to Great Moravia to spread Christianity among the West Slavs in the area. The brothers decided to translate liturgical books into the Old Slavic language that was understandable to the general population, but as the words of that language could not be easily written by using either the Greek or Latin alphabets, Cyril decided to invent a new script, Glagolitic, which he based on the local dialect of the Slavic tribes from the Byzantine theme of Thessalonica.

After the deaths of Cyril and Methodius, the Glagolitic alphabet ceased to be used in Moravia, but their students continued to propagate it in the First Bulgarian Empire, where it was subsequently also displaced by the Cyrillic alphabet. The Glagolitic alphabet was preserved only by the clergy of Croatia to write Church Slavonic until the early 19th century.

The name was not created until many centuries after the script's creation, and comes from the Old Church Slavonic глаголъ "glagol" "utterance". The verb "glagolati" means "to speak". It has been conjectured that the name "glagolitsa" developed in Croatia around the 14th century and was derived from the word "glagolity", applied to adherents of the liturgy in Slavonic.

The creation of the characters is popularly attributed to Saints Cyril and Methodius, who may have created them to facilitate the introduction of Christianity. It is believed that the original letters were fitted to Macedonian dialects specifically.

The number of letters in the original Glagolitic alphabet is not known, but it may have been close to its presumed Greek model. The 41 letters known today include letters for non-Greek sounds, which may have been added by Saint Cyril, as well as ligatures added in the 12th century under the influence of Cyrillic, as Glagolitic lost its dominance. In later centuries, the number of letters dropped dramatically, to fewer than 30 in modern Croatian and Czech recensions of the Church Slavic language. Twenty-four of the 41 original Glagolitic letters (see table below) probably derive from graphemes of the medieval cursive Greek small alphabet but have been given an ornamental design.

The source of the other consonantal letters is unknown. If they were added by Cyril, it is likely that they were taken from an alphabet used for Christian scripture. It is frequently proposed that the letters "sha" , "tsi" , and "cherv" were taken from the letters "shin" ש and "tsadi" צ of the Hebrew alphabet, and that Ⰶ "zhivete" derives from Coptic "janja" Ϫ. However, Cubberley (1996) suggests that if a single prototype were presumed, the most likely source would be Armenian. Other proposals include the Samaritan alphabet, which Cyril learned during his journey to the Khazars in Cherson.

Glagolitic letters were also used as numbers, similarly to Cyrillic numerals. Unlike Cyrillic numerals, which inherited their numeric value from the corresponding Greek letter (see Greek numerals), Glagolitic letters were assigned values based on their native alphabetic order.

The two monks later canonized as Saints Cyril and Methodius, brothers from Thessaloniki, were sent to Great Moravia in 862 by the Byzantine emperor at the request of Prince Rastislav, who wanted to weaken the dependence of his country on East Frankish priests. The Glagolitic alphabet, however it originated, was used between 863 and 885 for government and religious documents and books and at the Great Moravian Academy ("Veľkomoravské učilište") founded by the missionaries, where their followers were educated. The Kiev Missal, found in the 19th century in Jerusalem, was dated to the 10th century.

In 886 an East Frankish bishop of Nitra named Wiching banned the script and jailed 200 followers of Methodius, mostly students of the original academy. They were then dispersed or, according to some sources, sold as slaves by the Franks. Many of them (including Naum, Clement, Angelarious, Sava and Gorazd), however, reached Bulgaria and were commissioned by Boris I of Bulgaria to teach and instruct the future clergy of the state in the Slavic languages. After the adoption of Christianity in Bulgaria in 865, religious ceremonies and Divine Liturgy were conducted in Greek by clergy sent from the Byzantine Empire, using the Byzantine rite. Fearing growing Byzantine influence and weakening of the state, Boris viewed the introduction of the Slavic alphabet and language into church use as a way to preserve the independence of the Bulgarian Empire from Byzantine Constantinople. As a result of Boris' measures, two academies, one in Ohrid and one in Preslav, were founded.

From there, the students travelled to other places and spread the use of their alphabet. Some went to Croatia (Dalmatia), where the squared variant arose and where Glagolitic remained in use for a long time. In 1248, Pope Innocent IV granted the Croatians of southern Dalmatia the unique privilege of using their own language and this script in the Roman Rite liturgy. Formally granted to bishop Philip of Senj, permission to use the Glagolitic liturgy (the Roman Rite conducted in the Slavic language instead of Latin, not the Byzantine rite), actually extended to all Croatian lands, mostly along the Adriatic coast. The Holy See had several Glagolitic missals published in Rome. Authorization for the use of this language was extended to some other Slavic regions between 1886 and 1935. In missals, the Glagolitic script was eventually replaced with the Latin alphabet, but the use of the Slavic language in the Mass continued, until replaced by modern vernacular languages.

Some students of the Ohrid academy went to Bohemia where the alphabet was used in the 10th and 11th centuries, along with other scripts. It is not clear whether the Glagolitic alphabet was used in the Duchy of Kopnik before the Wendish Crusade, but it was certainly used in Kievan Rus'.

In Croatia, from the 12th century, Glagolitic inscriptions appeared mostly in littoral areas: Istria, Primorje, Kvarner, and Kvarner islands, notably Krk, Cres, and Lošinj; in Dalmatia, on the islands of Zadar, but there were also findings in inner Lika and Krbava, reaching to Kupa river, and even as far as Međimurje and Slovenia.
The "Hrvoje's Missal" () from 1404 was written in Split, and it is considered one of the most beautiful Croatian Glagolitic books. The 1483 "Missale Romanum Glagolitice" was the first printed Croatian Glagolitic book.

It was believed that Glagolitsa in Croatia was present only in those areas. But, in 1992, the discovery of Glagolitic inscriptions in churches along the Orljava river in Slavonia totally changed the picture (churches in Brodski Drenovac, Lovčić, and some others), showing that use of the Glagolitic alphabet was spread from Slavonia also.

At the end of the 9th century, one of these students of Methodius – Naum, who had settled in Preslav, Bulgaria – created the Cyrillic script, which almost entirely replaced Glagolitic during the Middle Ages. The Cyrillic alphabet is derived from the Greek alphabet, with some letters (like ⟨ш⟩, ⟨ц⟩, ⟨ч⟩, ⟨ъ⟩, ⟨ь⟩, ⟨ѣ⟩) peculiar to Slavic languages being derived from the Hebrew alphabet. The decision in favor of Cyrillic created an alphabetical difference between the two literary centres of the Bulgarian state in Pliska and Ohrid. In the western part the Glagolitic alphabet remained dominant at first. However, subsequently in the next two centuries, mostly after the fall of the First Bulgarian Empire to the Byzantines, Glagolitic gradually ceased to be used there at all. Nevertheless, particular passages or words written with the Glagolitic alphabet appeared in Bulgarian Cyrillic manuscripts till the end of the 14th century.

Sporadic instances aside, Glagolitic survived beyond the 12th century as a primary script in Croatia alone, although from there a brief attempt at reintroduction was made in the West Slavic area in the 14th century. The centre of influence appears to have been in the Kvarner Gulf, though the nature and extent of this influence remain subjects of debate. The early development of the Glagolitic minuscule script alongside the increasingly square majuscule is poorly documented, but before the advent of printing, a mutual relationship evolved between the two varieties; the majuscule being used primarily for inscriptions and higher liturgical uses, and the minuscule being applied to both religious and secular documents. Ignoring the problematic early Slavonian inscriptions, the use of the Glagolitic script at its peak before the Croatian-Ottoman wars corresponded roughly to the area that spoke the Chakavian dialect at the time, in addition to, to varying extents, the adjacent Kajkavian regions within the Zagreb bishopric. As a result, vernacular impact on the liturgical language and script largely stems from Chakavian sub-dialects.

The first major threat to Croatian Glagolitic since it attained stability was from the Ottoman excursions, though the extent of cultural damage varied locally depending on the course of war. In the 17th century, though, the first successful direct attack on the script since the 12th century was headed by the Bishop of Zagreb, and after the Magnate conspiracy left the script without secular protectors, its use was limited to the littoral region. In the meantime, printing gradually overtook handwriting for liturgical manuscripts, resulting in a decline of the majuscule script, which was absorbed for titular and sometimes initial use within for minuscule documents. It was not until the late 18th century and the onset of modernity that Glagolitic received significant further threats, and through western influence, especially secular, Glagolitic culture collapsed, so that by the mid 19th century, the script was purely liturgical, relying mostly on printed materials. By the time of the devastating Italianization movements under Fascist Italy in the early 20th century, numerous independent events had already greatly reduced the area of the liturgical use of Glagolitic.

The tradition that the alphabet was designed by Saint Cyril and Saint Methodius has not been universally accepted. A less common belief, contradicting allochthonic Slovene origin, was that the Glagolitic was created or used in the 4th century by St. Jerome (Latin: "Eusebius Sophronius Hieronymus"), hence the alphabet is sometimes named Hieronymian.

It is also acrophonically called azbuki from the names of its first two letters in Bulgaria, on the same model as "alpha" + "beta". The Slavs of Great Moravia (present-day Slovakia and Moravia), Hungary, Slovenia and Slavonia were called "Slověne" at that time, which gives rise to the name Slovenish for the alphabet. Some other, rarer, names for this alphabet are Bukvitsa (from common Slavic word "bukva" meaning "letter", and a suffix "-itsa") and Illyrian.

In the Middle Ages, Glagolitsa was also known as "St. Jerome's script" due to popular mediaeval legend (created by Croatian scribes in the 13th century) ascribing its invention to St. Jerome (342–429). That claim, however, has been resolutely disproven.

The epoch of traditional attribution of the script to Jerome ended probably in 1812. In modern times, only certain marginal authors share this view, usually "re-discovering" one of the already-known mediaeval sources.

A hypothetical pre-Glagolitic writing system is typically referred to as "cherty i rezy" (strokes and incisions) – but no material evidence of the existence of any pre-Glagolitic Slavic writing system has been found, except for a few brief and vague references in old chronicles and "lives of the saints". All artifacts presented as evidence of pre-Glagolitic Slavic inscriptions have later been identified as texts in known scripts and in known non-Slavic languages, or as fakes. The well-known Chernorizets Hrabar's "strokes and incisions" are usually considered to be a reference to a kind of property mark or alternatively fortune-telling signs. Some "Ruthenian letters" found in one version of St. Cyril's life are explainable as misspelled "Syrian letters" (in Slavic, the roots are very similar: "rus-" vs. "sur-" or "syr-"), etc.

The values of many of the letters are thought to have been displaced under Cyrillic influence or to have become confused through the early spread to different dialects so the original values are not always clear. For instance, the letter "yu" Ⱓ is thought to have perhaps originally had the sound /u/ but was displaced by the adoption of an "oѵ" ligature Ⱆ under the influence of later Cyrillic. Other letters were late creations after a Cyrillic model.

The following table lists each letter in its modern order, showing an image of the letter (round variant), the corresponding modern Cyrillic letter, the approximate sound transcribed with the , the name, and suggestions for its origin. Several letters have no modern counterpart.
Note that "yery" () is a digraph of either "yer" () or "yerь" (), followed by either "izhe" () or "i" (Ⰻ).

In older texts, "uk" () and three out of four "yus"es () also can be written as digraphs, in two separate parts.

The order of "izhe" () and "i" () varies from source to source, as does the order of the various forms of "yus" (). Correspondence between Glagolitic "izhe" () and "i" () with Cyrillic "И" and "І" is unknown.

Proto-Slavic language did not have the letter "F", and the letter Fita () was used for transcribing words of Greek origin at first, later for native Slavic words once the phoneme [f] developed.

The Glagolitic alphabet was added to the Unicode Standard in March 2005 with the release of version 4.1.

The Unicode block for Glagolitic is U+2C00–U+2C5F.
The Glagolitic combining letters for Glagolitic Supplement block (U+1E000–U+1E02F) was added to the Unicode Standard in June, 2016 with the release of version 9.0:

Glagolitic script is the writing system used in the world of "The Witcher" video game series. It is also featured, in various uses, in several of the point and click adventure games made by Cateia Games, a Croatian game studio.





</doc>
<doc id="12354" url="https://en.wikipedia.org/wiki?curid=12354" title="Greatest common divisor">
Greatest common divisor

In mathematics, the greatest common divisor (gcd) of two or more integers, which are not all zero, is the largest positive integer that divides each of the integers. For example, the gcd of 8 and 12 is 4.

The greatest common divisor is also known as the greatest common factor (gcf), highest common factor (hcf), greatest common measure (gcm), or highest common divisor.

This notion can be extended to polynomials (see Polynomial greatest common divisor) and other commutative rings (see below).

In this article we will denote the greatest common divisor of two integers "a" and "b" as gcd("a","b"). Some authors use ("a","b").

What is the greatest common divisor of 54 and 24? 

The number 54 can be expressed as a product of two integers in several different ways:

Thus the divisors of 54 are: formula_2

Similarly, the divisors of 24 are: formula_3

The numbers that these two lists share in common are the common divisors of 54 and 24:

The greatest of these is 6. That is, the greatest common divisor of 54 and 24. One writes:

Two numbers are called relatively prime, or coprime, if their greatest common divisor equals 1. For example, 9 and 28 are relatively prime.

For example, a 24-by-60 rectangular area can be divided into a grid of: 1-by-1 squares, 2-by-2 squares, 3-by-3 squares, 4-by-4 squares, 6-by-6 squares or 12-by-12 squares. Therefore, 12 is the greatest common divisor of 24 and 60. A 24-by-60 rectangular area can be divided into a grid of 12-by-12 squares, with two squares along one edge (24/12 = 2) and five squares along the other (60/12 = 5).

The greatest common divisor is useful for reducing fractions to be in lowest terms. For example, gcd(42, 56) = 14, therefore,

The greatest common divisor can be used to find the least common multiple of two numbers when the greatest common divisor is known, using the relation,

Greatest common divisors can in principle be computed by determining the prime factorizations of the two numbers and comparing factors, as in the following example: to compute gcd(18, 84), we find the prime factorizations 18 = 2 · 3 and 84 = 2 · 3 · 7 and notice that the "overlap" of the two expressions is 2 · 3; so gcd(18, 84) = 6. In practice, this method is only feasible for small numbers; computing prime factorizations in general takes far too long.

Here is another concrete example, illustrated by a Venn diagram. Suppose it is desired to find the greatest common divisor of 48 and 180. First, find the prime factorizations of the two numbers:

What they share in common is two "2"s and a "3":

A much more efficient method is the Euclidean algorithm, which uses a division algorithm such as long division in combination with the observation that the gcd of two numbers also divides their difference. To compute gcd(48,18), divide 48 by 18 to get a quotient of 2 and a remainder of 12. Then divide 18 by 12 to get a quotient of 1 and a remainder of 6. Then divide 12 by 6 to get a remainder of 0, which means that 6 is the gcd. Note that we ignored the quotient in each step except to notice when the remainder reached 0, signalling that we had arrived at the answer. Formally the algorithm can be described as:

where
If the arguments are both greater than zero then the algorithm can be written in more elementary terms as follows:

Lehmer's algorithm is based on the observation that the initial quotients produced by Euclid's algorithm can be determined based on only the first few digits; this is useful for numbers that are larger than a computer word. In essence, one extracts initial digits, typically forming one or two computer words, and runs Euclid's algorithms on these smaller numbers, as long as it is guaranteed that the quotients are the same with those that would be obtained with the original numbers. Those quotients are collected into a small 2-by-2 transformation matrix (that is a matrix of single-word integers), for using them all at once for reducing the original numbers. This process is repeated until numbers have a size for which the binary algorithm (see below) is more efficient. 

This algorithm improves speed, because it reduces the number of operations on very large numbers and can use the speed of hardware arithmetic for most operations. In fact, most of the quotients are very small, so a fair number of steps of the Euclidean algorithm can be collected in a 2-by-2 matrix of single-word integers. When Lehmer's algorithm encounters a too large quotient, it must fall back to one iteration of Euclidean algorithm, with a Euclidean division of large numbers.

An alternative method of computing the gcd is the binary GCD algorithm which uses only subtraction and division by 2.
In outline the method is as follows: Let "a" and "b" be the two non negative integers. Also set the integer "d" to 0. There are five possibilities:
As gcd("a", "a") = "a", the desired gcd is "a" × 2 (as "a" and "b" are changed in the other cases, and "d" records the number of times that "a" and "b" have been both divided by 2 in the next step, the gcd of the initial pair is the product of "a" and 2).

In this case 2 is a common divisor. Divide both "a" and "b" by 2, increment "d" by 1 to record the number of times 2 is a common divisor and continue.

In this case 2 is not a common divisor. Divide "a" by 2 and continue.

As in the previous case 2 is not a common divisor. Divide "b" by 2 and continue.

As gcd("a","b") = gcd("b","a") and we have already considered the case "a" = "b", we may assume that "a" > "b". The number "c" = "a" − "b" is smaller than "a" yet still positive. Any number that divides "a" and "b" must also divide "c" so every common divisor of "a" and "b" is also a common divisor of "b" and "c". Similarly, "a" = "b" + "c" and every common divisor of "b" and "c" is also a common divisor of "a" and "b". So the two pairs ("a", "b") and ("b", "c") have the same common divisors, and thus gcd("a","b") = gcd("b","c"). Moreover, as "a" and "b" are both odd, "c" is even, and one may replace "c" by "c"/2 without changing the gcd. Thus the process can be continued with the pair ("a", "b") replaced by the smaller numbers ("c"/2, "b").

Each of the above steps reduces at least one of "a" and "b" towards 0 and so can only be repeated a finite number of times. Thus one must eventually reach the case "a" = "b", which is the only stopping case. Then, as quoted above, the gcd is "a" × 2.

This algorithm can be programmed as follows:

Example: ("a", "b", "d") = (48, 18, 0) → (24, 9, 1) → (12, 9, 1) → (6, 9, 1) → (3, 9, 1) → (3, 6, 1) → (3, 3, 1) ; the original gcd is thus the product 6 of 2 = 2 and "a"= "b"= 3.

The binary GCD algorithm is particularly easy to implement on binary computers. The test for whether a number is divisible by two can be performed by testing the lowest bit in the number. Division by two can be achieved by shifting the input number by one bit. Each step of the algorithm makes at least one such shift. Subtracting two numbers smaller than "a" and "b" costs formula_14 bit operations. Each step makes at most one such subtraction. The total number of steps is at most the sum of the numbers of bits of "a" and "b", hence the computational complexity is

The computational complexity is usually given in terms of the length of the input. Here, this length is formula_16 and the complexity is thus

If "a" and "b" are both nonzero, the greatest common divisor of "a" and "b" can be computed by using least common multiple (lcm) of "a" and "b":

but more commonly the lcm is computed from the gcd.

Using Thomae's function "f",
which generalizes to "a" and "b" rational numbers or commensurable real numbers.

Keith Slavin has shown that for odd "a" ≥ 1:

which is a function that can be evaluated for complex "b". Wolfgang Schramm has shown that

is an entire function in the variable "b" for all positive integers "a" where "c"("k") is Ramanujan's sum. 

The computational complexity of the computation of greatest common divisors has been widely studied. If one uses the Euclidean algorithm and the elementary algorithms for multiplication and division, the computation of the greatest common divisor of two integers of at most bits is formula_22 This means that the computation of greatest common divisor has, up to a constant factor, the same complexity as the multiplication.

However, if a fast multiplication algorithm is used, one may modify the Euclidean algorithm for improving the complexity, but the computation of a greatest common divisor becomes slower than the multiplication. More precisely, if the multiplication of two integers of bits takes a time of , then the fastest known algorithm for greatest common divisor has a complexity formula_23 This implies that the fastest known algorithm has a complexity of formula_24

Previous complexities are valid for the usual models of computation, specifically multitape Turing machines and random-access machines.

The computation of the greatest common divisors belongs thus to the class of problems solvable in quasilinear time. "A fortiori", the corresponding decision problem belongs to the class P of problems solvable in polynomial time. The GCD problem is not known to be in NC, and so there is no known way to parallelize it efficiently; nor is it known to be P-complete, which would imply that it is unlikely to be possible to efficiently parallelize GCD computation. Shallcross et al. showed that a related problem (EUGCD, determining the remainder sequence arising during the Euclidean algorithm) is NC-equivalent to the problem of integer linear programming with two variables; if either problem is in NC or is P-complete, the other is as well. Since NC contains NL, it is also unknown whether a space-efficient algorithm for computing the GCD exists, even for nondeterministic Turing machines.

Although the problem is not known to be in NC, parallel algorithms asymptotically faster than the Euclidean algorithm exist; the fastest known deterministic algorithm is by Chor and Goldreich, which (in the CRCW-PRAM model) can solve the problem in time with processors. Randomized algorithms can solve the problem in time on formula_25 processors (note this is superpolynomial).


In 1972, James E. Nymann showed that "k" integers, chosen independently and uniformly from {"1"...,"n"}, are coprime with probability 1/"ζ"("k") as "n" goes to infinity, where "ζ" refers to the Riemann zeta function. (See coprime for a derivation.) This result was extended in 1987 to show that the probability that "k" random integers have greatest common divisor "d" is "d"/ζ("k").

Using this information, the expected value of the greatest common divisor function can be seen (informally) to not exist when "k" = 2. In this case the probability that the gcd equals "d" is "d"/ζ(2), and since ζ(2) = π/6 we have

This last summation is the harmonic series, which diverges. However, when "k" ≥ 3, the expected value is well-defined, and by the above argument, it is

For "k" = 3, this is approximately equal to 1.3684. For "k" = 4, it is approximately 1.1106.

The notion of greatest common divisor can more generally be defined for elements of an arbitrary commutative ring, although in general there need not exist one for every pair of elements.

If is a commutative ring, and and are in , then an element of is called a "common divisor" of and if it divides both and (that is, if there are elements and in such that "d"·"x" = "a" and "d"·"y" = "b").
If is a common divisor of and , and every common divisor of and divides , then is called a "greatest common divisor" of and "b".

Note that with this definition, two elements and may very well have several greatest common divisors, or none at all. If is an integral domain then any two gcd's of and must be associate elements, since by definition either one must divide the other; indeed if a gcd exists, any one of its associates is a gcd as well. Existence of a gcd is not assured in arbitrary integral domains. However if is a unique factorization domain, then any two elements have a gcd, and more generally this is true in gcd domains.
If is a Euclidean domain in which euclidean division is given algorithmically (as is the case for instance when "R" = "F"["X"] where is a field, or when is the ring of Gaussian integers), then greatest common divisors can be computed using a form of the Euclidean algorithm based on the division procedure.

The following is an example of an integral domain with two elements that do not have a gcd:

The elements 2 and 1 +  are two maximal common divisors (that is, any common divisor which is a multiple of 2 is associated to 2, the same holds for 1 + , but they are not associated, so there is no greatest common divisor of and "b".

Corresponding to the Bézout property we may, in any commutative ring, consider the collection of elements of the form "pa" + "qb", where and range over the ring. This is the ideal generated by and , and is denoted simply ("a", "b"). In a ring all of whose ideals are principal (a principal ideal domain or PID), this ideal will be identical with the set of multiples of some ring element "d"; then this is a greatest common divisor of and "b". But the ideal ("a", "b") can be useful even when there is no greatest common divisor of and "b". (Indeed, Ernst Kummer used this ideal as a replacement for a gcd in his treatment of Fermat's Last Theorem, although he envisioned it as the set of multiples of some hypothetical, or "ideal", ring element , whence the ring-theoretic term.)






</doc>
<doc id="12357" url="https://en.wikipedia.org/wiki?curid=12357" title="Gazpacho">
Gazpacho

Gazpacho (; ) or Andalusian gazpacho is a cold soup made of raw, blended vegetables. A classic of Spanish cuisine, it originated in the southern region of Andalusia. Gazpacho is widely eaten in Spain and Portugal, particularly during the hot summers, as it is refreshing and cool.

There are other recipes called "gazpacho", such as "gazpacho manchego", which is very different from Andalusian gazpacho. There are also a number of dishes that are closely related to Andalusian gazpacho and often considered variants thereof, such as ajoblanco, salmorejo, pipirrana, porra antequerana (closer to a bread soup), cojondongo and Portuguese gaspacho ().

Gazpacho has ancient roots. There are a number of theories of its origin, including as a soup of bread, olive oil, water and garlic that arrived in Spain and Portugal with the Romans and also with the addition of vinegar. Once in Spain, it became a part of Andalusian cuisine, particularly in Córdoba, Seville and Granada, using stale bread, garlic, olive oil, salt, and vinegar, similar to ajoblanco.

During the 19th century, the red gazpacho evolved when tomatoes were added to the ingredients. This version was spread internationally.

There are many modern variations of gazpacho, often in different colors and omitting the tomatoes and bread in favor of avocados, cucumbers, parsley, watermelon, grapes, meat stock, seafood, and other ingredients.

In Andalusia, most gazpacho recipes include stale bread, tomato, cucumber, bell pepper, onion, garlic, olive oil, wine vinegar, water, and salt.

The following is a typical modern method of preparing gazpacho:


Traditionally, gazpacho was made by pounding the vegetables in a mortar with a pestle; this more laborious method is still sometimes used as it helps keep the gazpacho cool and avoids the foam and the completely smooth consistency created by blenders and food processors. A traditional way of preparation is to pound garlic cloves in a mortar, add a little soaked stale bread, then olive oil and salt, to make a paste. Then very ripe tomatoes and vinegar are added. In the days before refrigeration the gazpacho was left in an unglazed earthenware pot to cool by evaporation, and some water added.

Gazpacho may be served with garnishes, served separately, such as hard boiled eggs and chopped ham (in the salmorejo variety from Córdoba), chopped almonds, cumin crushed with mint, orange segments, finely chopped green pepper, onion, tomato or cucumber. In Extremadura, gazpacho with local ham, added to the gazpacho rather than as a garnish, is called "gazpacho extremeño". Andalusian sources say that gazpacho should be slightly chilled, but not iced.

Ingredients, texture, and how thick the gazpacho is made vary regionally and between families.

Similar cold raw soups such as Arjamolho in Portugal, salmorejo, porra antequerana and ajoblanco, are also popular in Andalusia, although not as widespread as gazpacho.

"Gazpacho manchego", despite its name, is a meat stew, served hot, not a variation on the cold vegetable soup.

The original recipe using bread, water, vinegar, oil and salt is traditional in the Iberian Peninsula, perhaps going back to Roman times. Every Andalusian region or comarca has its own variety. The humble gazpacho became a very deeply rooted food for peasants and shepherds in the south of Spain. The basic gazpacho gave rise to many variants, some also called gazpacho, others not; some authors have tried to classify all these variations. Gazpachos may be classified by colour: the most usual red ones (which contain tomato), white ones (which contain no tomato, but include dried fruits), and green ones (which are white but contain some spices that make them green). These variants have their basic ingredients in common, garlic paste which works as an emulsifier, bread, olive oil, vinegar and salt. To the traditional ingredients red fruits such as strawberries, muskmelon, etc., may be added, making the gazpacho a bit sweeter. Gazpacho may be served as a starter, main dish, or tapa.

A popular variation comes from the town of Rota in the province of Cadiz. During times of drought there was not enough water to make gazpacho; arranque has the same ingredients as gazpacho, but uses less water and bread, making it a sort of cream. Some people add more bread until it takes on the consistency of a dip.

In Extremadura, gazpachos are a kind of purée or thick gazpacho known as "cojondongo", or "cojondongo del gañán", made of breadcrumbs, garlic, oil, and vinegar, then topped with chopped onions, tomato and peppers.

Gazpacho manchego, as its name implies, is made in the east region of La Mancha, in Albacete and nearby areas, and is popular in other areas in the center and southwest of the country.

It is a meat stew, whose main ingredients are small game animals or birds such as rabbit, hare, quail, or pigeon and flat bread, and may include garlic, tomatoes, and mushrooms. It is cooked in a cauldron and served hot. Garlic and tomatoes may be added. Another well-known variant in La Mancha is gazpachos de pastor or galianos.

Some other hot meat or fish dishes from other regions are called gazpachos (gazpacho jumillano, gazpacho de Yecla, gazpacho de Requena, etc.)

Gazpacho is often eaten during the very hot and dry summers in Castilla y León. The gazpacho made in La Moraña in the province of Ávila has large pieces of vegetables floating in a watery soup.



</doc>
<doc id="12359" url="https://en.wikipedia.org/wiki?curid=12359" title="Gopher (disambiguation)">
Gopher (disambiguation)

A gopher, also known as a "pocket gopher" (family Geomyidae), is a burrowing rodent native to North America and Central America.

Gopher may also refer to:






</doc>
<doc id="12361" url="https://en.wikipedia.org/wiki?curid=12361" title="Gnome">
Gnome

A gnome is a diminutive spirit in Renaissance magic and alchemy, first introduced by Paracelsus in the 16th century and later adopted by more recent authors including those of modern fantasy literature. Its characteristics have been reinterpreted to suit the needs of various story tellers, but it is typically said to be a small humanoid that lives underground.

The word comes from Renaissance Latin "gnomus", which first appears in the "Ex Libro de Nymphis, Sylvanis, Pygmaeis, Salamandris et Gigantibus, etc" by Paracelsus, published posthumously in Nysa in 1566 (and again in the Johannes Huser edition of 1589–1591 from an autograph by Paracelsus).

The term may be an original invention of Paracelsus, possibly deriving the term from Latin "gēnomos" (itself representing a Greek , literally "earth-dweller"). In this case, the omission of the "ē" is, as the Oxford English Dictionary (OED) calls it, a blunder. Paracelsus uses "Gnomi" as a synonym of "Pygmæi" and classifies them as earth elementals. He describes them as two spans high, very reluctant to interact with humans, and able to move through solid earth as easily as humans move through air.
The chthonic, or earth-dwelling, spirit has precedents in numerous ancient and medieval mythologies, often guarding mines and precious underground treasures, notably in the Germanic dwarfs and the Greek Chalybes, Telchines or Dactyls.

The English word is attested from the early 18th century. Gnomes are used in Alexander Pope's "The Rape of the Lock". The creatures from this mock-epic are small, celestial creatures which were prudish women in their past-lives, and now spend all of eternity looking out for prudish women (in parallel to the guardian angels in Catholic belief). Other uses of the term "gnome" remain obscure until the early 19th century, when it is taken up by authors of Romanticist collections of fairy tales and becomes mostly synonymous with the older word "goblin".

Pope's stated source, the French satire "Comte de Gabalis" (1670), used the term "gnomide" to refer to female gnomes (often "gnomid" in English translations). The author of this work, Nicolas-Pierre-Henri de Montfaucon de Villars, the abbot of Villars, describes gnomes as such:
"The Earth is filled almost to the Center with "Gnomes" or "Pharyes", a People of small Stature, the Guardians of Treasures, of Mines, and of Precious Stones. They are Ingenious, Friends of Men, and easie to be commandded. They furnish the Children of the "Sages" with as much Money, as they have need of; and never ask any other Reward of their Services, than the Glory of being Commanded. The "Gnomides" or Wives of these "Gnomes" or "Pharyes", are Little, but very Handson; and their Habit marvellously Curious."

In 19th-century fiction, the chthonic gnome became a sort of antithesis to the more airy or luminous fairy. Nathaniel Hawthorne in "Twice-Told Tales" (1837) contrasts the two in "Small enough to be king of the fairies, and ugly enough to be king of the gnomes" (cited after OED). Similarly, gnomes are contrasted to elves, as in William Cullen Bryant's "Little People of the Snow" (1877), which has "let us have a tale of elves that ride by night, with jingling reins, or gnomes of the mine" (cited after OED).

One of the first movements in Mussorgsky's 1874 work "Pictures at an Exhibition", named "Gnomus" (Latin for "The Gnome"), is written to sound as if a gnome is moving about, his movements constantly changing in speed.
Franz Hartmann in 1895 satirized materialism in an allegorical tale entitled "Unter den Gnomen im Untersberg". The English translation appeared in 1896 as "Among the Gnomes: An Occult Tale of Adventure in the Untersberg". In this story, the "Gnomes" are still clearly subterranean creatures, guarding treasures of gold within the Untersberg mountain.

As a figure of 19th-century fairy tales, the term gnome became largely synonymous with other terms for "little people" by the 20th century, such as "goblin", "brownie", "kobold", "leprechaun", "Heinzelmännchen" and other instances of the "domestic spirit" type, losing its strict association with earth or the underground world.



After World War II (with early references, in ironic use, from the late 1930s) the diminutive figurines introduced as lawn ornaments during the 19th century came to be known as garden gnomes. The image of the gnome changed further during the 1960s to 1970s, when the first plastic garden gnomes were manufactured. These gnomes followed the style of the 1937 depiction of the seven dwarves in "Snow White and the Seven Dwarfs" by Disney. This "Disneyfied" image of the gnome was built upon by the illustrated children's book classic "The Secret Book of Gnomes" (1976), in the original Dutch "Leven en werken van de Kabouter". Garden gnomes share a resemblance to the Scandinavian tomte and nisse, and the Swedish term "tomte" can be translated as "gnome" in English.

Several gnome themed entertainment parks exist. Notable ones are:

Garden gnome liberationists such as the Gnome Liberation Front were introduced in France in 1997. They claim that Garden Gnomes deserve the same freedom that any other living creature would have. They are noted to have stolen hundreds of gnomes.

Gnome parades are held annually at Atlanta's Inman Park Festival. Numerous one-off gnome parades have been held, including in Savannah, Georgia (April 2012) and Cleveland, Ohio (May 2011).



</doc>
<doc id="12365" url="https://en.wikipedia.org/wiki?curid=12365" title="Googolplex">
Googolplex

A googolplex is the number 10, or equivalently, 10. Written out in ordinary decimal notation, it is 1 followed by 10 zeroes, that is, a 1 followed by a googol zeroes.

In 1920, Edward Kasner's nine-year-old nephew, Milton Sirotta, coined the term "googol", which is 10, then proposed the further term "googolplex" to be "one, followed by writing zeroes until you get tired". Kasner decided to adopt a more formal definition because "different people get tired at different times and it would never do to have Carnera a better mathematician than Dr. Einstein, simply because he had more endurance and could write for longer". It thus became standardized to 10.

A typical book can be printed with 10 zeros (around 400 pages with 50 lines per page and 50 zeros per line). Therefore, it requires 10 such books to print all the zeros of a googolplex (that is, printing a googol zeros). If each book had a mass of 100 grams, all of them would have a total mass of 10 kilograms. In comparison, Earth's mass is 5.972 x 10 kilograms, and the mass of the Milky Way Galaxy is estimated at 2.5 x 10 kilograms.

In pure mathematics, there are several notational methods for representing large numbers by which the magnitude of a googolplex could be represented, such as tetration, hyperoperation, Knuth's up-arrow notation, Steinhaus–Moser notation, or Conway chained arrow notation.

In the PBS science program "", , astronomer and television personality Carl Sagan estimated that writing a googolplex in full decimal form (i.e., "10,000,000,000...") would be physically impossible, since doing so would require more space than is available in the known universe.

One googol is presumed to be greater than the number of atoms in the observable universe, which has been estimated to be approximately 10. Thus, in the physical world, it is difficult to give examples of numbers that compare to the vastly greater googolplex. However, in analyzing quantum states and black holes, physicist Don Page writes that "determining experimentally whether or not information is lost down black holes of solar mass ... would require more than 10 measurements to give a rough determination of the final density matrix after a black hole evaporates". The end of the universe via Big Freeze without proton decay is expected to be around 10 years into the future.

In a separate article, Page shows that the number of states in a black hole with a mass roughly equivalent to the Andromeda Galaxy is in the range of a googolplex.

Writing the number would take an extreme amount of time: if a person can write two digits per second, then writing a googolplex would take about 1.51 years, which is about 1.1 times the accepted age of the universe.

The residues (mod "n") of a googolplex are:




</doc>
<doc id="12366" url="https://en.wikipedia.org/wiki?curid=12366" title="Graphite">
Graphite

Graphite (), archaically referred to as plumbago, is a crystalline form of the element carbon with its atoms arranged in a hexagonal structure. It occurs naturally in this form and is the most stable form of carbon under standard conditions. Under high pressures and temperatures it converts to diamond. Graphite is used in pencils and lubricants. Its high conductivity makes it useful in electronic products such as electrodes, batteries, and solar panels. 

The principal types of natural graphite, each occurring in different types of ore deposits, are


Graphite occurs in metamorphic rocks as a result of the reduction of sedimentary carbon compounds during metamorphism. It also occurs in igneous rocks and in meteorites. Minerals associated with graphite include quartz, calcite, micas and tourmaline. The principal export sources of mined graphite are in order of tonnage: China, Mexico, Canada, Brazil, and Madagascar. 

In meteorites, graphite occurs with troilite and silicate minerals. Small graphitic crystals in meteoritic iron are called cliftonite. Some microscopic grains have distinctive isotopic compositions, indicating that they were formed before the Solar system. They are one of about 12 known types of mineral that predate the Solar System and have also been detected in molecular clouds. These minerals were formed in the ejecta when supernovae exploded or low- to intermediate-sized stars expelled their outer envelopes late in their lives. Graphite may be the second or third oldest mineral in the Universe. 

Solid carbon comes in different forms known as allotropes depending on the type of chemical bond. The two most common are diamond and graphite (less common ones include buckminsterfullerene). In diamond the bonds are sp and the atoms form tetrahedra with each bound to four nearest neighbors. In graphite they are sp orbital hybrids and the atoms form in planes with each bound to three nearest neighbors 120 degrees apart.

The individual layers are called graphene. In each layer, the carbon atoms are arranged in a honeycomb lattice with separation of 0.142 nm, and the distance between planes is 0.335 nm. Atoms in the plane are bonded covalently, with only three of the four potential bonding sites satisfied. The fourth electron is free to migrate in the plane, making graphite electrically conductive. However, it does not conduct in a direction at right angles to the plane. Bonding between layers is via weak van der Waals bonds, which allows layers of graphite to be easily separated, or to slide past each other.

The two known forms of graphite, "alpha" (hexagonal) and "beta" (rhombohedral), have very similar physical properties, except that the graphene layers stack slightly differently. The alpha graphite may be either flat or buckled. The alpha form can be converted to the beta form through mechanical treatment and the beta form reverts to the alpha form when it is heated above 1300 °C.

The equilibrium pressure and temperature conditions for a transition between graphite and diamond is well established theoretically and experimentally. The pressure changes linearly between at and at (the diamond/graphite/liquid triple point).
However, the phases have a wide region about this line where they can coexist. At normal temperature and pressure, and , the stable phase of carbon is graphite, but diamond is metastable and its rate of conversion to graphite is negligible. However, at temperatures above about , diamond rapidly converts to graphite. Rapid conversion of graphite to diamond requires pressures well above the equilibrium line: at , a pressure of is needed.

The acoustic and thermal properties of graphite are highly anisotropic, since phonons propagate quickly along the tightly bound planes, but are slower to travel from one plane to another. Graphite's high thermal stability and electrical and thermal conductivity facilitate its widespread use as electrodes and refractories in high temperature material processing applications. However, in oxygen-containing atmospheres graphite readily oxidizes to form carbon dioxide at temperatures of 700 °C and above.
Graphite is an electrical conductor, hence useful in such applications as arc lamp electrodes. It can conduct electricity due to the vast electron delocalization within the carbon layers (a phenomenon called aromaticity). These valence electrons are free to move, so are able to conduct electricity. However, the electricity is primarily conducted within the plane of the layers. The conductive properties of powdered graphite allow its use as pressure sensor in carbon microphones.

Graphite and graphite powder are valued in industrial applications for their self-lubricating and dry lubricating properties. There is a common belief that graphite's lubricating properties are solely due to the loose interlamellar coupling between sheets in the structure. However, it has been shown that in a vacuum environment (such as in technologies for use in space), graphite degrades as a lubricant, due to the hypoxic conditions. This observation led to the hypothesis that the lubrication is due to the presence of fluids between the layers, such as air and water, which are naturally adsorbed from the environment. This hypothesis has been refuted by studies showing that air and water are not absorbed. Recent studies suggest that an effect called superlubricity can also account for graphite's lubricating properties. The use of graphite is limited by its tendency to facilitate pitting corrosion in some stainless steel, and to promote galvanic corrosion between dissimilar metals (due to its electrical conductivity). It is also corrosive to aluminium in the presence of moisture. For this reason, the US Air Force banned its use as a lubricant in aluminium aircraft, and discouraged its use in aluminium-containing automatic weapons. Even graphite pencil marks on aluminium parts may facilitate corrosion. Another high-temperature lubricant, hexagonal boron nitride, has the same molecular structure as graphite. It is sometimes called "white graphite", due to its similar properties.

When a large number of crystallographic defects bind these planes together, graphite loses its lubrication properties and becomes what is known as pyrolytic graphite. It is also highly anisotropic, and diamagnetic, thus it will float in mid-air above a strong magnet. If it is made in a fluidized bed at 1000–1300 °C then it is isotropic turbostratic, and is used in blood contacting devices like mechanical heart valves and is called pyrolytic carbon, and is not diamagnetic. Pyrolytic graphite and pyrolytic carbon are often confused but are very different materials.

Natural and crystalline graphites are not often used in pure form as structural materials, due to their shear-planes, brittleness, and inconsistent mechanical properties.

In the 4th millennium BC, during the Neolithic Age in southeastern Europe, the Marița culture used graphite in a ceramic paint for decorating pottery.

Some time before 1565 (some sources say as early as 1500), an enormous deposit of graphite was discovered on the approach to Grey Knotts from the hamlet of Seathwaite in Borrowdale parish, Cumbria, England, which the locals found useful for marking sheep. During the reign of Elizabeth I (1558–1603), Borrowdale graphite was used as a refractory material to line moulds for cannonballs, resulting in rounder, smoother balls that could be fired farther, contributing to the strength of the English navy. This particular deposit of graphite was extremely pure and soft, and could easily be cut into sticks. Because of its military importance, this unique mine and its production were strictly controlled by the Crown.

During the 19th century, graphite's uses greatly expanded to include stove polish, lubricants, paints, crucibles, foundry facings, and pencils, a major factor in the expansion of educational tools during the first great rise of education for the masses. The British empire controlled most of the world's production (especially from Ceylon), but production from Austrian, German and American deposits expanded by mid-century. For example, the Dixon Crucible Company of Jersey City, New Jersey, founded by Joseph Dixon and partner Orestes Cleveland in 1845, opened mines in the Lake Ticonderoga district of New York, built a processing plant there, and a factory to manufacture pencils, crucibles and other products in New Jersey, described in the "Engineering & Mining Journal" 21 December 1878. The Dixon pencil is still in production.

The beginnings of the revolutionary froth flotation process are associated with graphite mining. Included in the "E&MJ" article on the Dixon Crucible Company is a sketch of the "floating tanks" used in the age-old process of extracting graphite. Because graphite is so light, the mix of graphite and waste was sent through a final series of water tanks where a cleaner graphite “floated” off, which left waste to drop out. In an 1877 patent, the two brothers Bessel (Adolph and August) of Dresden, Germany, took this "floating" process a step further and added a small amount of oil to the tanks and boiled the mix – an agitation or frothing step – to collect the graphite, the first steps toward the future flotation process. Adolph Bessel received the Wohler Medal for the patented process that upgraded the recovery of graphite to 90% from the German deposit. In 1977, the German Society of Mining Engineers and Metallurgists organized a special symposium dedicated to their discovery and, thus, the 100th anniversary of flotation.

In the United States, in 1885, Hezekiah Bradford of Philadelphia patented a similar process, but it is uncertain if his process was used successfully in the nearby graphite deposits of Chester County, Pennsylvania, a major producer by the 1890s. The Bessel process was limited in use, primarily because of the abundant cleaner deposits found around the globe, which needed not much more than hand-sorting to gather the pure graphite. The state of the art, ca. 1900, is described in the Canadian Department of Mines report on graphite mines and mining, when Canadian deposits began to become important producers of graphite. 

Historically, graphite was called black lead or plumbago. Plumbago was commonly used in its massive mineral form. Both of these names arise from confusion with the similar-appearing lead ores, particularly galena. The Latin word for lead, "plumbum", gave its name to the English term for this grey metallic-sheened mineral and even to the leadworts or plumbagos, plants with flowers that resemble this colour.

The term "black lead" usually refers to a powdered or processed graphite, matte black in color.

Abraham Gottlob Werner coined the name "graphite" ("writing stone") in 1789. He attempted to clear up the confusion between molybdena, plumbago and black lead after Carl Wilhelm Scheele in 1778 proved that there are at least three different minerals. Scheele's analysis showed that the chemical compounds molybdenum sulfide (molybdenite), lead(II) sulfide (galena) and graphite were three different soft black minerals.

Natural graphite is mostly used for refractories, batteries, steelmaking, expanded graphite, brake linings, foundry facings and lubricants. 

The use of graphite as a refractory (heat-resistant) material began before 1900 with the graphite crucible used to hold molten metal; this is now a minor part of refractories. In the mid-1980s, the carbon-magnesite brick became important, and a bit later the alumina-graphite shape. the order of importance is: alumina-graphite shapes, carbon-magnesite brick, monolithics (gunning and ramming mixes), and then crucibles.

Crucibles began using very large flake graphite, and carbon-magnesite brick requiring not quite so large flake graphite; for these and others there is now much more flexibility in the size of flake required, and amorphous graphite is no longer restricted to low-end refractories. Alumina-graphite shapes are used as continuous casting ware, such as nozzles and troughs, to convey the molten steel from ladle to mold, and carbon magnesite bricks line steel converters and electric-arc furnaces to withstand extreme temperatures. Graphite blocks are also used in parts of blast furnace linings where the high thermal conductivity of the graphite is critical. High-purity monolithics are often used as a continuous furnace lining instead of carbon-magnesite bricks.

The US and European refractories industry had a crisis in 2000–2003, with an indifferent market for steel and a declining refractory consumption per tonne of steel underlying firm buyouts and many plant closures. Many of the plant closures resulted from the acquisition of Harbison-Walker Refractories by RHI AG and some plants had their equipment auctioned off. Since much of the lost capacity was for carbon-magnesite brick, graphite consumption within the refractories area moved towards alumina-graphite shapes and monolithics, and away from brick. The major source of carbon-magnesite brick is now imports from China. Almost all of the above refractories are used to make steel and account for 75% of refractory consumption; the rest is used by a variety of industries, such as cement.

According to the USGS, US natural graphite consumption in refractories comprised 12,500 tonnes in 2010.

The use of graphite in batteries has increased in the last 30 years. Natural and synthetic graphite are used to construct electrodes in major battery technologies. The lithium-ion battery utilizes roughly twice the amount of graphite as lithium carbonate.

The demand for batteries, primarily nickel–metal hydride and lithium-ion batteries, caused a growth in demand for graphite in the late 1980s and early 1990s – a growth driven by portable electronics, such as portable CD players and power tools. Laptops, mobile phones, tablets, and smartphone products have increased the demand for batteries. Electric-vehicle batteries are anticipated to increase graphite demand. As an example, a lithium-ion battery in a fully electric Nissan Leaf contains nearly 40 kg of graphite.

Natural graphite in steelmaking mostly goes into raising the carbon content in molten steel, and can also be used to lubricate the dies used to extrude hot steel. Carbon additives are subject to competitive pricing from alternatives such as synthetic graphite powder, petroleum coke, and other forms of carbon. A carbon raiser is added to increase the carbon content of the steel to the specified level. An estimate based on USGS's graphite consumption statistics indicates that 10,500 tonnes were used in this fashion in the US in 2005.

Natural amorphous and fine flake graphite are used in brake linings or brake shoes for heavier (nonautomotive) vehicles, and became important with the need to substitute for asbestos. This use has been important for quite some time, but nonasbestos organic (NAO) compositions are beginning to reduce graphite's market share. A brake-lining industry shake-out with some plant closures has not been beneficial, nor has an indifferent automotive market. According to the USGS, US natural graphite consumption in brake linings was 6,510 tonnes in 2005.

A foundry facing mold wash is a water-based paint of amorphous or fine flake graphite. Painting the inside of a mold with it and letting it dry leaves a fine graphite coat that will ease separation of the object cast after the hot metal has cooled. Graphite lubricants are specialty items for use at very high or very low temperatures, as forging die lubricant, an antiseize agent, a gear lubricant for mining machinery, and to lubricate locks. Having low-grit graphite, or even better, no-grit graphite (ultra high purity), is highly desirable. It can be used as a dry powder, in water or oil, or as colloidal graphite (a permanent suspension in a liquid). An estimate based on USGS graphite consumption statistics indicates that 2,200 tonnes was used in this fashion in 2005. Metal can also be impregnated into graphite to create a self-lubricating alloy for application in extreme conditions, such as bearings for machines exposed to high or low temperatures. 

The ability to leave marks on paper and other objects gave graphite its name, given in 1789 by German mineralogist Abraham Gottlob Werner. It stems from "graphein", meaning "to write" or "draw" in Ancient Greek.

From the 16th century, all pencils were made with leads of English natural graphite, but modern pencil lead is most commonly a mix of powdered graphite and clay; it was invented by Nicolas-Jacques Conté in 1795. It is chemically unrelated to the metal lead, whose ores had a similar appearance, hence the continuation of the name. Plumbago is another older term for natural graphite used for drawing, typically as a lump of the mineral without a wood casing. The term plumbago drawing is normally restricted to 17th and 18th century works, mostly portraits.

Today, pencils are still a small but significant market for natural graphite. Around 7% of the 1.1 million tonnes produced in 2011 was used to make pencils. Low-quality amorphous graphite is used and sourced mainly from China.

Natural graphite has found uses in zinc-carbon batteries, in electric motor brushes, and various specialized applications. Graphite of various hardness or softness results in different qualities and tones when used as an artistic medium. Railroads would often mix powdered graphite with waste oil or linseed oil to create a heat-resistant protective coating for the exposed portions of a steam locomotive's boiler, such as the smokebox or lower part of the firebox.

Expanded graphite is made by immersing natural flake graphite in a bath of chromic acid, then concentrated sulfuric acid, which forces the crystal lattice planes apart, thus expanding the graphite. The expanded graphite can be used to make graphite foil or used directly as "hot top" compound to insulate molten metal in a ladle or red-hot steel ingots and decrease heat loss, or as firestops fitted around a fire door or in sheet metal collars surrounding plastic pipe (during a fire, the graphite expands and chars to resist fire penetration and spread), or to make high-performance gasket material for high-temperature use. After being made into graphite foil, the foil is machined and assembled into the bipolar plates in fuel cells.
The foil is made into heat sinks for laptop computers which keeps them cool while saving weight, and is made into a foil laminate that can be used in valve packings or made into gaskets. Old-style packings are now a minor member of this grouping: fine flake graphite in oils or greases for uses requiring heat resistance. A GAN estimate of current US natural graphite consumption in this end use is 7,500 tonnes.

Graphite forms intercalation compounds with some metals and small molecules. In these compounds, the host molecule or atom gets "sandwiched" between the graphite layers, resulting in a type of compound with variable stoichiometry. A prominent example of an intercalation compound is potassium graphite, denoted by the formula KC. Some graphite intercalation compounds are superconductors. The highest transition temperature (by June 2009) "T" = 11.5 K is achieved in CaC, and it further increases under applied pressure (15.1 K at 8 GPa). Graphite's ability to intercalate lithium ions without significant damage from swelling is what makes it the dominant anode material in lithium-ion batteries.

In 1893, Charles Street of Le Carbone discovered a process for making artificial graphite. Another process to make synthetic graphite was invented accidentally by Edward Goodrich Acheson (1856–1931). In the mid-1890s, Acheson discovered that overheating carborundum (silicon carbide or SiC) produced almost pure graphite. While studying the effects of high temperature on carborundum, he had found that silicon vaporizes at about 4,150 °C (7,500 °F), leaving the carbon behind in graphitic carbon. This graphite was another major discovery for him, and it became extremely valuable and helpful as a lubricant.

In 1896, Acheson received a patent for his method of synthesizing graphite, and in 1897 started commercial production. The Acheson Graphite Co. was formed in 1899. 

Highly oriented pyrolytic graphite (HOPG) is the highest-quality synthetic form of graphite. It is used in scientific research, in particular, as a length standard for scanner calibration of scanning probe microscope.

Graphite electrodes carry the electricity that melts scrap iron and steel, and sometimes direct-reduced iron (DRI), in electric arc furnaces, which are the vast majority of steel furnaces. They are made from petroleum coke after it is mixed with coal tar pitch. They are then extruded and shaped, baked to carbonize the binder (pitch), and finally graphitized by heating it to temperatures approaching 3000 °C, at which the carbon atoms arrange into graphite. They can vary in size up to long and in diameter. An increasing proportion of global steel is made using electric arc furnaces, and the electric arc furnace itself is becoming more efficient, making more steel per tonne of electrode. An estimate based on USGS data indicates that graphite electrode consumption was 197,000 tonnes in 2005.

Electrolytic aluminium smelting also uses graphitic carbon electrodes. On a much smaller scale, synthetic graphite electrodes are used in electrical discharge machining (EDM), commonly to make injection molds for plastics.

The powder is made by heating powdered petroleum coke above the temperature of graphitization, sometimes with minor modifications. The graphite scrap comes from pieces of unusable electrode material (in the manufacturing stage or after use) and lathe turnings, usually after crushing and sizing. Most synthetic graphite powder goes to carbon raising in steel (competing with natural graphite), with some used in batteries and brake linings. According to the USGS, US synthetic graphite powder and scrap production was 95,000 tonnes in 2001 (latest data).

Special grades of synthetic graphite, such as Gilsocarbon, also find use as a matrix and neutron moderator within nuclear reactors. Its low neutron cross-section also recommends it for use in proposed fusion reactors. Care must be taken that reactor-grade graphite is free of neutron absorbing materials such as boron, widely used as the seed electrode in commercial graphite deposition systems – this caused the failure of the Germans' World War II graphite-based nuclear reactors. Since they could not isolate the difficulty they were forced to use far more expensive heavy water moderators. Graphite used for nuclear reactors is often referred to as nuclear graphite.

Graphite (carbon) fiber and carbon nanotubes are also used in carbon fiber reinforced plastics, and in heat-resistant composites such as reinforced carbon-carbon (RCC). Commercial structures made from carbon fiber graphite composites include fishing rods, golf club shafts, bicycle frames, sports car body panels, the fuselage of the Boeing 787 Dreamliner and pool cue sticks and have been successfully employed in reinforced concrete, The mechanical properties of carbon fiber graphite-reinforced plastic composites and grey cast iron are strongly influenced by the role of graphite in these materials. In this context, the term "(100%) graphite" is often loosely used to refer to a pure mixture of carbon reinforcement and resin, while the term "composite" is used for composite materials with additional ingredients.

Modern smokeless powder is coated in graphite to prevent the buildup of static charge.

Graphite has been used in at least three radar absorbent materials. It was mixed with rubber in Sumpf and Schornsteinfeger, which were used on U-boat snorkels to reduce their radar cross section. It was also used in tiles on early F-117 Nighthawk stealth strike fighters.

Graphite composites are used as absorber for high-energy particles (e.g. in the LHC beam dump).

Graphite is mined by both open pit and underground methods. Graphite usually needs beneficiation. This may be carried out by hand-picking the pieces of gangue (rock) and hand-screening the product or by crushing the rock and floating out the graphite. Beneficiation by flotation encounters the difficulty that graphite is very soft and "marks" (coats) the particles of gangue. This makes the "marked" gangue particles float off with the graphite, yielding impure concentrate. There are two ways of obtaining a commercial concentrate or product: repeated regrinding and floating (up to seven times) to purify the concentrate, or by acid leaching (dissolving) the gangue with hydrofluoric acid (for a silicate gangue) or hydrochloric acid (for a carbonate gangue).
In milling, the incoming graphite products and concentrates can be ground before being classified (sized or screened), with the coarser flake size fractions (below 8 mesh, 8–20 mesh, 20–50 mesh) carefully preserved, and then the carbon contents are determined. Some standard blends can be prepared from the different fractions, each with a certain flake size distribution and carbon content. Custom blends can also be made for individual customers who want a certain flake size distribution and carbon content. If flake size is unimportant, the concentrate can be ground more freely. Typical end products include a fine powder for use as a slurry in oil drilling and coatings for foundry molds, carbon raiser in the steel industry (Synthetic graphite powder and powdered petroleum coke can also be used as carbon raiser). Environmental impacts from graphite mills consist of air pollution including fine particulate exposure of workers and also soil contamination from powder spillages leading to heavy metal contamination of soil.
According to the United States Geological Survey (USGS), world production of natural graphite in 2016 was 1,200,000 tonnes, of which the following major exporters are: China (780,000 t), India (170,000 t), Brazil (80,000 t), Turkey (32,000 t) and North Korea (30,000 t). Graphite is not mined in the United States, but U.S. production of synthetic graphite in 2010 was 134,000 t valued at $1.07 billion.

People can be exposed to graphite in the workplace by breathing it in, skin contact, and eye contact.

The Occupational Safety and Health Administration (OSHA) has set the legal limit (permissible exposure limit) for graphite exposure in the workplace as a time weighted average (TWA) of 15 million particles per cubic foot (1.5 mg/m) over an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of TWA 2.5 mg/m respirable dust over an 8-hour workday. At levels of 1250 mg/m, graphite is immediately dangerous to life and health.

The most common way of recycling graphite occurs when synthetic graphite electrodes are either manufactured and pieces are cut off or lathe turnings are discarded, or the electrode (or other) are used all the way down to the electrode holder. A new electrode replaces the old one, but a sizeable piece of the old electrode remains. This is crushed and sized, and the resulting graphite powder is mostly used to raise the carbon content of molten steel. Graphite-containing refractories are sometimes also recycled, but often not because of their graphite: the largest-volume items, such as carbon-magnesite bricks that contain only 15–25% graphite, usually contain too little graphite. However, some recycled carbon–magnesite brick is used as the basis for furnace-repair materials, and also crushed carbon–magnesite brick is used in slag conditioners. While crucibles have a high graphite content, the volume of crucibles used and then recycled is very small.

A high-quality flake graphite product that closely resembles natural flake graphite can be made from steelmaking kish. Kish is a large-volume near-molten waste skimmed from the molten iron feed to a basic oxygen furnace, and consists of a mix of graphite (precipitated out of the supersaturated iron), lime-rich slag, and some iron. The iron is recycled on site, leaving a mixture of graphite and slag. The best recovery process uses hydraulic classification (which utilizes a flow of water to separate minerals by specific gravity: graphite is light and settles nearly last) to get a 70% graphite rough concentrate. Leaching this concentrate with hydrochloric acid gives a 95% graphite product with a flake size ranging from 10 mesh down.




</doc>
<doc id="12367" url="https://en.wikipedia.org/wiki?curid=12367" title="Garry Trudeau">
Garry Trudeau

Garretson Beekman "Garry" Trudeau (born July 21, 1948) is an American cartoonist, best known for creating the "Doonesbury" comic strip. Trudeau is also the creator and executive producer of the Amazon Studios political comedy series "Alpha House".

Trudeau was born in New York City, the son of Jean Douglas (née Moore) and Francis Berger Trudeau Jr. He is the great-grandson of Dr. Edward Livingston Trudeau, who created Adirondack Cottage Sanitarium for the treatment of pulmonary tuberculosis at Saranac Lake, New York. Edward was succeeded by his son Francis and grandson Francis Jr. The latter founded the Trudeau Institute at Saranac Lake, with which his son Garry retains a connection.

His ancestry is French Canadian, English, Dutch, German, and Swedish.

Raised in Saranac Lake, Trudeau attended St. Paul's School, Concord, New Hampshire. He enrolled in Yale University in 1966. As an art major, Trudeau initially focused on painting, but soon discovered a greater interest in the graphic arts. He spent much of his time cartooning and writing for Yale's humor magazine "The Yale Record", eventually serving as the magazine's editor-in-chief. At the same time, Trudeau began contributing to the "Yale Daily News", which eventually led to the creation of "Bull Tales", a comic strip parodying the exploits of Yale quarterback Brian Dowling. This strip was the progenitor of "Doonesbury".

While still an undergraduate at Yale, Trudeau published two collections of "Bull Tales": "Bull Tales" (1969, published by the "Yale Daily News") and "Michael J." (1970, published by "The Yale Record").

As a senior, Trudeau became a member of Scroll and Key. He did postgraduate work at the Yale School of Art, earning a master of fine arts degree in graphic design in 1973. It was there that Trudeau first met photographer David Levinthal, with whom he would later collaborate on "Hitler Moves East", an influential "graphic chronicle" of the German invasion of the Soviet Union.

Soon after "Bull Tales" began running in the Yale student newspaper, the strip caught the attention of the newly formed Universal Press Syndicate. The syndicate's editor, James F. Andrews, recruited Trudeau, changed the strip's name to "Doonesbury", and began distributing it following the cartoonist's graduation in 1970. Today "Doonesbury" is syndicated to 1,000 daily and Sunday newspapers worldwide and is accessible online in association with "The Washington Post".

In 1975, Trudeau became the first comic strip artist to win a Pulitzer, traditionally awarded to editorial-page cartoonists. He was also a Pulitzer finalist in 1990, 2004, and 2005. Other awards include the National Cartoonist Society Newspaper Comic Strip Award in 1994, and the Reuben Award in 1995. In 1993, Trudeau was made a fellow of the American Academy of Arts and Sciences. Wiley Miller, fellow comic-strip artist responsible for "Non Sequitur", called him "far and away the most influential editorial cartoonist in the last 25 years". A regular graduation speaker, Trudeau has received 35 honorary degrees.

In addition to his creating his strip, Trudeau has worked in both theater and television. He was nominated for an Oscar in 1977 in the category of Animated Short Film for "A Doonesbury Special", created for NBC in collaboration with John and Faith Hubley. The film went on to win the Cannes Film Festival Jury Special Prize in 1978. In 1984, with composer Elizabeth Swados, he wrote the book and lyrics for the Broadway musical "Doonesbury", for which he was nominated for two Drama Desk Awards. A cast album of the show, recorded for MCA, received a Grammy nomination. Trudeau again collaborated with Swados in 1984, this time on "Rap Master Ronnie", a satirical review about the Reagan Administration that opened off-Broadway at the Village Gate. A filmed version, featuring Jon Cryer, the Smothers Brothers, and Carol Kane, was broadcast on Cinemax in 1988.

Also in 1988, Trudeau wrote and co-produced with director Robert Altman HBO's critically acclaimed "Tanner '88", a satiric look at that year's presidential election campaign. The show won the gold medal for Best Television Series at the Cannes Television Festival, the British Academy Television Award for Best Foreign Program, and Best Imported Program from the British Broadcasting Press Guild. It earned an Emmy Award, as well as four ACE Award nominations. In 2004, Trudeau reunited with Altman to write and co-produce a sequel mini-series, "Tanner on Tanner", for the Sundance Channel.

In 1996, "Newsweek" and the "Washington Post" speculated that Trudeau had written the novel "Primary Colors", which was later revealed to have been written by Joe Klein. In February 2000, Trudeau, working with Dotcomix, launched "Duke2000", a web-based presidential campaign featuring a real-time, 3-D, streaming-animation version of Duke. Nearly 30 campaign videos were created for the site, and Ambassador Duke was interviewed live by satellite on the "Today Show, Larry King Live, The Charlie Rose Show", and dozens of local TV and radio news shows.

In 2013, Trudeau created, wrote and co-produced "Alpha House", a political sitcom starring John Goodman that revolves around four Republican U.S. Senators who live together in a townhouse on Capitol Hill. Trudeau was inspired to write the show's pilot after reading a 2007 "New York Times" article about a real D.C. townhouse shared by New York Senator Chuck Schumer, Illinois Senator Dick Durbin of Illinois, and California Representative George Miller, all Democrats. The pilot for "Alpha House" was produced by Amazon Studios and aired in early 2013. Due to positive response, Amazon picked up the show to develop into a full series, streaming eleven episodes for its first season. On March 31, 2014, Amazon announced that "Alpha House" had been renewed. Production began in July 2014, and the entire second season became available for streaming on October 24, 2014.

While writing "Alpha House", Trudeau put the daily Doonesbury into rerun mode. On March 3, 2014 the "Classic Doonesbury" series began, featuring approximately four weeks of daily strips from each year of the strip's run. He continues to produce new strips for Sundays. Although "Alpha House" has not been in production since the end of 2014, Trudeau has not returned to creating daily "Doonesbury" strips; new material remains a Sunday-only event.

Trudeau has contributed to such publications as "Harper's", "Rolling Stone", "The New Republic", "The New Yorker", "New York", and "The Washington Post". From 1990-94, he wrote and drew an occasional column for "The New York Times" op-ed page, and was a contributing essayist for "Time" magazine from 1996 to 2001.

Beginning with the Gulf War in 1991, Trudeau has written about military issues extensively. In recognition for his work on wounded warriors, he has been presented with the Commander's Award for Public Service by the Department of the Army, the Commander's Award from Disabled American Veterans, the President's Award for Excellence in the Arts from Vietnam Veterans of America, the Distinguished Public Service Award from the American Academy of Physical Medicine and Rehabilitation, the Mental Health Research Advocacy Award from the Yale School of Medicine, and a special citation from the Vet Centers.

He received several unit commendations from the field during the Gulf War, and traveled with the USO to visit troops in Iraq and Afghanistan. From 2005 to 2014, his website hosted "The Sandbox", a milblog posting over 800 essays by deployed soldiers, returned vets, caregivers, and spouses. For most of the strip's run, Trudeau has eschewed merchandising, but starting in 1998 he teamed up with Starbucks to create "Doonesbury" products to raise funds for local literacy programs. The items were offered for sale in Starbucks stores for nearly two years and raised over $1 million. Also for charity, Trudeau licensed the strip to Ben & Jerry's, which created a best-selling sorbet flavor called "Doonesberry".

Garry Trudeau's son Ross, a digital media producer, is also a crossword constructor who has been published in the New York Times. As part of the ongoing celebrity partnership series, Ross and Garry collaborated on a crossword puzzle that was published on Tues. May 15, 2018 in the NYT. This is the 6th NYT puzzle for Ross and the 1st for Garry.

Trudeau married Jane Pauley in 1980; they have three children. He maintains a low personal profile. A rare early appearance on television was as a guest on "To Tell the Truth" in 1971, where only one of the three panelists guessed his identity. In 1990, Trudeau appeared on the cover of "Newsweek" for "Inside Doonesbury's Brain", a story written by Jonathan Alter. This was the first interview Trudeau had given in seventeen years.

Trudeau cooperated extensively with "Wired" magazine for a 2000 profile, "The Revolution Will be Satirized". He later spoke with the writer of that article, Edward Cone, for a 2004 newspaper column in the Greensboro, North Carolina "News & Record", about the war wounds suffered by the Doonesbury character "B.D.", and in 2006 did a Q&A at Cone's personal blog about The Sandbox. Trudeau granted an interview to "Rolling Stone" in 2004 in which he discussed his time at Yale University, which he attended two years behind George W. Bush. He granted another "Rolling Stone" interview in 2010. In 2006, "The Washington Post" printed an extensive profile of Trudeau by writer Gene Weingarten. He appeared on the "Charlie Rose" television program, and at signings for "The Long Road Home: One Step at a Time", his "Doonesbury" book about B.D.'s struggle with injuries received during the second Gulf War.

On August 1, 2016, Trudeau appeared on MSNBC on "The Rachel Maddow Show". He was brought on to discuss his ability to predict and accurately write about Donald Trump's plans to run for president almost three decades earlier. Maddow presented cartoon strips from as far back as 1987. Trudeau was on her show to promote his new book "Yuge", which covers 30 years of Trump appearing in "Doonesbury". On November 7, 2016, Trudeau appeared on "Fresh Air" with Terry Gross to discuss "Yuge". On the CBS program Sunday Morning of December 2nd 2018 he was featured and was interviewed by his wife, Jane Pauley.

Trudeau has attracted criticism both for the comic strip and for his own opinions. The "Saturday Review" once voted Trudeau one of the "Most Overrated People in American Arts and Letters", stating that after his hiatus, his comic strip was "predictable, mean-spirited, and not as funny as before."

Eric Alterman, writing in "The Nation", called "Doonesbury" "one of the great intellectual/artistic accomplishments of the past half-century, irrespective of category".

Trudeau's acceptance speech on the occasion of receiving a Polk Award in 2015 for lifetime achievement stirred controversy. In the speech, Trudeau criticized the cartoonists of "Charlie Hebdo"—after a number of "Charlie Hebdo" writers, editors and cartoonists had been murdered execution style in their own Paris offices by Muslim terrorists—for "punching downward..., attacking a powerless, disenfranchised minority with crude, vulgar drawings closer to graffiti than cartoons", and thereby wandering "into the realm of hate speech" with cartoons of Muhammad. Writing in "The Atlantic", in which Trudeau had published his speech, political commentator David Frum criticized what he called Trudeau's "moral theory" that calls for identifying "the bearer of privilege", then holding "the privilege-bearer responsible". Trudeau was labelled a "terror apologist" by the editors of "The New York Post" for his comments, with his choice of the venue in which to make them "adding to the insult".




</doc>
<doc id="12369" url="https://en.wikipedia.org/wiki?curid=12369" title="Guild">
Guild

A guild is an association of artisans or merchants who oversee the practice of their craft/trade in a particular area. The earliest types of guild formed as a confraternities of tradesmen, normally operating in a single city and covering a single trade. They were organized in a manner something between a professional association, a trade union, a cartel, and a secret society. They sometimes depended on grants of letters patent from a monarch or other ruler to enforce the flow of trade to their self-employed members, and to retain ownership of tools and the supply of materials, but were generally regulated by the city government. A lasting legacy of traditional guilds are the guildhalls constructed and used as guild meeting-places. Guild members found guilty of cheating on the public would be fined or banned from the guild. 

Typically the key "privilege" was that only guild members were allowed to sell their goods or practice their skill within the city. There might be controls on minimum or maximum prices, hours of trading, numbers of apprentices, and many other things. As well as reducing free competition, but sometimes maintaining a good quality of work, often these rules made it difficult or impossible for women, immigrants to the city, and non-Christians to run businesses working in the trade. 

An important result of the guild framework was the emergence of universities at Bologna (established in 1088), Oxford (at least since 1096) and Paris (c. 1150); they originated as guilds of students (as at Bologna) or of masters (as at Paris).

A type of guild was known in Roman times. Known as "collegium", "collegia" or "corpus", these were organised groups of merchants who specialised in a particular craft and whose membership of the group was voluntary. One such example is the "corpus naviculariorum", the college of long-distance shippers based at Rome's La Ostia port. The Roman guilds failed to survive the collapse of the Roman Empire. 

In medieval cities, craftsmen tended to form associations based on their trades, confraternities of textile workers, masons, carpenters, carvers, glass workers, each of whom controlled secrets of traditionally imparted technology, the "arts" or "mysteries" of their crafts. Usually the founders were free independent master craftsmen who hired apprentices.

There were several types of guilds, including the two main categories of merchant guilds and craft guilds but also the frith guild and religious guild. Guilds arose beginning in the High Middle Ages as craftsmen united to protect their common interests. In the German city of Augsburg craft guilds are mentioned in the Towncharter of 1156.

The continental system of guilds and merchants arrived in England after the Norman Conquest, with incorporated societies of merchants in each town or city holding exclusive rights of doing business there. In many cases they became the governing body of a town. For example, London's Guildhall became the seat of the Court of Common Council of the City of London Corporation, the world’s oldest continuously elected local government, whose members to this day must be Freemen of the City. The Freedom of the City, effective from the Middle Ages until 1835, gave the right to trade, and was only bestowed upon members of a Guild or Livery.

Early egalitarian communities called "guilds" were denounced by Catholic clergy for their "conjurations" — the binding oaths sworn among the members to support one another in adversity, kill specific enemies, and back one another in feuds or in business ventures. The occasion for these oaths were drunken banquets held on December 26, the pagan feast of Jul (Yule)—in 858, West Francian Bishop Hincmar sought vainly to Christianise the guilds.

In the Early Middle Ages, most of the Roman craft organisations, originally formed as religious confraternities, had disappeared, with the apparent exceptions of stonecutters and perhaps glassmakers, mostly the people that had local skills. Gregory of Tours tells a miraculous tale of a builder whose art and techniques suddenly left him, but were restored by an apparition of the Virgin Mary in a dream. Michel Rouche remarks that the story speaks for the importance of practically transmitted journeymanship.

In France, guilds were called "corps de métiers". According to Viktor Ivanovich Rutenburg, "Within the guild itself there was very little division of labour, which tended to operate rather between the guilds. Thus, according to Étienne Boileau's Book of Handicrafts, by the mid-13th century there were no less than 100 guilds in Paris, a figure which by the 14th century had risen to 350." There were different guilds of metal-workers: the farriers, knife-makers, locksmiths, chain-forgers, nail-makers, often formed separate and distinct corporations; the armourers were divided into helmet-makers, escutcheon-makers, harness-makers, harness-polishers, etc. In Catalan towns, specially at Barcelona, guilds or "gremis" were a basic agent in the society: a shoemakers' guild is recorded in 1208.

In England, specifically in the City of London Corporation, more than 110 guilds, referred to as livery companies, survive today, with the oldest more than a thousand years old. Other groups, such as the Worshipful Company of Tax Advisers, have been formed far more recently. Membership in a livery company is expected for individuals participating in the governance of "The City", as the Lord Mayor and the Remembrancer.

The guild system reached a mature state in Germany circa 1300 and held on in German cities into the 19th century, with some special privileges for certain occupations remaining today. In the 15th century, Hamburg had 100 guilds, Cologne 80, and Lübeck 70. The latest guilds to develop in Western Europe were the "" of Spain: e.g., Valencia (1332) or Toledo (1426).

Not all city economies were controlled by guilds; some cities were "free." Where guilds were in control, they shaped labor, production and trade; they had strong controls over instructional capital, and the modern concepts of a lifetime progression of apprentice to craftsman, and then from journeyman eventually to widely recognized master and grandmaster began to emerge. In order to become a master, a journeyman would have to go on a three-year voyage called journeyman years. The practice of the journeyman years still exists in Germany and France.

As production became more specialized, trade guilds were divided and subdivided, eliciting the squabbles over jurisdiction that produced the paperwork by which economic historians trace their development: The metalworking guilds of Nuremberg were divided among dozens of independent trades in the boom economy of the 13th century, and there were 101 trades in Paris by 1260. In Ghent, as in Florence, the woolen textile industry developed as a congeries of specialized guilds. The appearance of the European guilds was tied to the emergent money economy, and to urbanization. Before this time it was not possible to run a money-driven organization, as commodity money was the normal way of doing business.
The guild was at the center of European handicraft organization into the 16th century. In France, a resurgence of the guilds in the second half of the 17th century is symptomatic of the monarchy's concerns to impose unity, control production and reap the benefits of transparent structure in the shape of more efficient taxation.

The guilds were identified with organizations enjoying certain privileges (letters patent), usually issued by the king or state and overseen by local town business authorities (some kind of chamber of commerce). These were the predecessors of the modern patent and trademark system. The guilds also maintained funds in order to support infirm or elderly members, as well as widows and orphans of guild members, funeral benefits, and a 'tramping' allowance for those needing to travel to find work. As the guild system of the City of London declined during the 17th century, the Livery Companies transformed into mutual assistance fraternities along such lines.

European guilds imposed long standardized periods of apprenticeship, and made it difficult for those lacking the capital to set up for themselves or without the approval of their peers to gain access to materials or knowledge, or to sell into certain markets, an area that equally dominated the guilds' concerns. These are defining characteristics of mercantilism in economics, which dominated most European thinking about political economy until the rise of classical economics.

The guild system survived the emergence of early capitalists, which began to divide guild members into "haves" and dependent "have-nots". The civil struggles that characterize the 14th-century towns and cities were struggles in part between the greater guilds and the lesser artisanal guilds, which depended on piecework. "In Florence, they were openly distinguished: the "Arti maggiori" and the "Arti minori"—already there was a "popolo grasso" and a "popolo magro"". Fiercer struggles were those between essentially conservative guilds and the merchant class, which increasingly came to control the means of production and the capital that could be ventured in expansive schemes, often under the rules of guilds of their own. German social historians trace the "Zunftrevolution", the urban revolution of guildmembers against a controlling urban patriciate, sometimes reading into them, however, perceived foretastes of the class struggles of the 19th century.
In the countryside, where guild rules did not operate, there was freedom for the entrepreneur with capital to organize cottage industry, a network of cottagers who spun and wove in their own premises on his account, provided with their raw materials, perhaps even their looms, by the capitalist who took a share of the profits. Such a dispersed system could not so easily be controlled where there was a vigorous local market for the raw materials: wool was easily available in sheep-rearing regions, whereas silk was not.

In Florence, Italy, there were seven to twelve "greater guilds" and fourteen "lesser guilds" the most important of the greater guilds was that for judges and notaries, who handled the legal business of all the other guilds and often served as an arbitrator of disputes. Other greater guilds include the wool, silk, and the money changers' guilds. They prided themselves on a reputation for very high-quality work, which was rewarded with premium prices. The guilds fined members who deviated from standards. Other greater guilds included those of doctors, druggists, and furriers. Among the lesser guilds, were those for bakers, saddle makers, ironworkers and other artisans. They had a sizable membership, but lacked the political and social standing necessary to influence city affairs.

The guild was made up by experienced and confirmed experts in their field of handicraft. They were called master craftsmen. Before a new employee could rise to the level of mastery, he had to go through a schooling period during which he was first called an apprentice. After this period he could rise to the level of journeyman. Apprentices would typically not learn more than the most basic techniques until they were trusted by their peers to keep the guild's or company's secrets.

Like "journey", the distance that could be travelled in a day, the title 'journeyman' derives from the French words for 'day' ("jour" and "journée") from which came the middle English word "journei". Journeymen were able to work for other masters, unlike apprentices, and generally paid by the day and were thus day labourers. After being employed by a master for several years, and after producing a qualifying piece of work, the apprentice was granted the rank of journeyman and was given documents (letters or certificates from his master and/or the guild itself) which certified him as a journeyman and entitled him to travel to other towns and countries to learn the art from other masters. These journeys could span large parts of Europe and were an unofficial way of communicating new methods and techniques, though by no means all journeymen made such travels — they were most common in Germany and Italy, and in other countries journeymen from small cities would often visit the capital.
After this journey and several years of experience, a journeyman could be received as master craftsman, though in some guilds this step could be made straight from apprentice. This would typically require the approval of all masters of a guild, a donation of money and other goods (often omitted for sons of existing members), and the production of a so-called "masterpiece,' which would illustrate the abilities of the aspiring master craftsman; this was often retained by the guild.

The medieval guild was established by charters or letters patent or similar authority by the city or the ruler and normally held a monopoly on trade in its craft within the city in which it operated: handicraft workers were forbidden by law to run any business if they were not members of a guild, and only masters were allowed to be members of a guild. Before these privileges were legislated, these groups of handicraft workers were simply called 'handicraft associations'.

The town authorities might be represented in the guild meetings and thus had a means of controlling the handicraft activities. This was important since towns very often depended on a good reputation for export of a narrow range of products, on which not only the guild's, but the town's, reputation depended. Controls on the association of physical locations to well-known exported products, e.g. wine from the Champagne and Bordeaux regions of France, tin-glazed earthenwares from certain cities in Holland, lace from Chantilly, etc., helped to establish a town's place in global commerce — this led to modern trademarks.

In many German and Italian cities, the more powerful guilds often had considerable political influence, and sometimes attempted to control the city authorities. In the 14th century, this led to numerous bloody uprisings, during which the guilds dissolved town councils and detained patricians in an attempt to increase their influence. In fourteenth-century north-east Germany, people of Wendish, i.e. Slavic, origin were not allowed to join some guilds. According to Wilhelm Raabe, ""down into the eighteenth century no German guild accepted a Wend.""

Ogilvie (2004) argues that guilds negatively affected quality, skills, and innovation. Through what economists now call "rent-seeking" they imposed deadweight losses on the economy. Ogilvie argues they generated limited positive externalities and notes that industry began to flourish only after the guilds faded away. Guilds persisted over the centuries because they redistributed resources to politically powerful merchants. On the other hand, Ogilvie agrees, guilds created "social capital" of shared norms, common information, mutual sanctions, and collective political action. This social capital benefited guild members, even as it arguably hurt outsiders.

The guild system became a target of much criticism towards the end of the 18th century and the beginning of the 19th century. Critics argued that they hindered free trade and technological innovation, technology transfer and business development. According to several accounts of this time, guilds became increasingly involved in simple territorial struggles against each other and against free practitioners of their arts.

Two of the most outspoken critics of the guild system were Jean-Jacques Rousseau and Adam Smith, and all over Europe a tendency to oppose government control over trades in favour of laissez-faire free market systems grew rapidly and made its way into the political and legal systems. Many people who participated in the French Revolution saw guilds as a last remnant of feudalism. The Le Chapelier Law of 1791 abolished the guilds in France. Smith wrote in "The Wealth of Nations" (Book I, Chapter X, paragraph 72):

Karl Marx in his "Communist Manifesto" also criticized the guild system for its rigid gradation of social rank and the relation of oppressor/oppressed entailed by this system. It was the 18th and 19th centuries that saw the beginning of the low regard in which some people hold the guilds to this day. In part due to their own inability to control unruly corporate behavior, the tide of public opinion turned against the guilds.

Because of industrialization and modernization of the trade and industry, and the rise of powerful nation-states that could directly issue patent and copyright protections — often revealing the trade secrets — the guilds' power faded. After the French Revolution they gradually fell in most European nations over the course of the 19th century, as the guild system was disbanded and replaced by laws that promoted free trade. As a consequence of the decline of guilds, many former handicraft workers were forced to seek employment in the emerging manufacturing industries, using not closely guarded techniques formerly protected by guilds, but rather the standardized methods controlled by corporations.
Interest in the medieval guild system was revived during the late 19th century, among far right circles. Fascism in Italy (among other countries) implemented corporatism, operating at the national rather than city level, to try to imitate the corporatism of the Middle Ages.

Guilds are sometimes said to be the precursors of modern trade unions. Guilds, however, can also be seen as a set of self-employed skilled craftsmen with ownership and control over the materials and tools they needed to produce their goods. Some argue that guilds operated more like cartels than they were like trade unions (Olson 1982). However, the journeymen organizations, which were at the time illegal, may have been influential.

The exclusive privilege of a guild to produce certain goods or provide certain services was similar in spirit and character with the original patent systems that surfaced in England in 1624. These systems played a role in ending the guilds' dominance, as trade secret methods were superseded by modern firms directly revealing their techniques, and counting on the state to enforce their legal monopoly.

Some guild traditions still remain in a few handicrafts, in Europe especially among shoemakers and barbers. Some ritual traditions of the guilds were preserved in order organisations such as the Freemasons, allegedly deriving from the Masons Guild, and the Oddfellows, allegedly derived from various smaller guilds. These are, however, not very important economically except as reminders of the responsibilities of some trades toward the public.

Modern antitrust law could be said to derive in some ways from the original statutes by which the guilds were abolished in Europe.

The economic consequences of guilds have led to heated debates among economic historians. On the one side, scholars say that since merchant guilds persisted over long periods they must have been efficient institutions (since inefficient institutions die out). Others say they persisted not because they benefited the entire economy but because they benefited the owners, who used political power to protect them. Ogilvie (2011) says they regulated trade for their own benefit, were monopolies, distorted markets, fixed prices, and restricted entrance into the guild. Ogilvie (2008) argues that their long apprenticeships were unnecessary to acquire skills, and their conservatism reduced the rate of innovation and made the society poorer. She says their main goal was rent seeking, that is, to shift money to the membership at the expense of the entire economy.

Epstein and Prak's book (2008) rejects Ogilvie's conclusions. Specifically, Epstein argues that guilds were cost-sharing rather than rent-seeking institutions. They located and matched masters and likely apprentices through monitored learning. Whereas the acquisition of craft skills required experience-based learning, he argues that this process necessitated many years in apprenticeship.

The extent to which guilds were able to monopolize markets is also debated.

For the most part, medieval guilds limited women's participation, and usually only the widows and daughters of known masters were allowed in. Even if a woman entered a guild, she was excluded from guild offices. It's important to note that while this was the overarching practice, there were guilds and professions that did allow women's participation, and that the Medieval era was an ever-changing, mutable society—especially considering that it spanned hundreds of years and many different cultures. There were multiple accounts of women's participation in guilds in England and the Continent. In a study of London silkwomen of the 15th century by Marian K. Dale, she notes that medieval women could inherit property, belong to guilds, manage estates, and run the family business if widowed. The "Livre des métiers de Paris (Book of Trades of Paris)" was compiled by Étienne Boileau, the Grand Provost of Paris under King Louis IX. It documents that 5 out of 110 Parisian guilds were female monopolies, and that only a few guilds systematically excluded women. Boileau notes that some professions were also open to women: surgeons, glass-blowers, chain-mail forgers. Entertainment guilds also had a significant number of women members. John, Duke of Berry documents payments to female musicians from Le Puy, Lyons, and Paris.

Women did have problems with entering healers' guilds, as opposed to their relative freedom in trade or craft guilds. Their status in healers' guilds were often challenged. The idea that medicine should only be practice by men was supported by the Catholic Church, royal heads, and secular authorities at the time. It is believed that the Inquisition and witch hunts throughout the ages contributed to the lack of women in medical guilds.

Scholars from the history of ideas have noticed that consultants play a part similar to that of the journeymen of the guild systems: they often travel a lot, work at many companies and spread new practices and knowledge between companies and corporations.

Professional organizations replicate guild structure and operation.
Professions such as architecture, engineering, geology, and land surveying require varying lengths of apprenticeships before one can gain a "professional" certification. These certifications hold great legal weight: most states make them a prerequisite to practicing there.

Thomas W. Malone champions a modern variant of the guild structure for modern "e-lancers", professionals who do mostly telework for multiple employers. Insurance including any professional liability, intellectual capital protections, an ethical code perhaps enforced by peer pressure and software, and other benefits of a strong association of producers of knowledge, benefit from economies of scale, and may prevent cut-throat competition that leads to inferior services undercutting prices. And, as with historical guilds, such a structure will resist foreign competition. The free software community has from time to time explored a guild-like structure to unite against competition from Microsoft, e.g. Advogato assigns journeyer and master ranks to those committing to work only or mostly on free software.

In many European countries guilds have experienced a revival as local organizations for craftsmen, primarily in traditional skills. They may function as forums for developing competence and are often the local units of a national employer's organisation.

In the City of London, the ancient guilds survive as livery companies, all of which play a ceremonial role in the City's many customs. The City of London livery companies maintain strong links with their respective trade, craft or profession, some still retain regulatory, inspection or enforcement roles. The senior members of the City of London Livery Companies (known as liverymen) elect the sheriffs and approve the candidates for the office of Lord Mayor of London. Guilds also survive in many other towns and cities the UK including in Preston, Lancashire, as the Preston Guild Merchant where among other celebrations descendants of burgesses are still admitted into membership. With the City of London livery companies, the UK has over 300 extant guilds and growing.

In 1878 the London livery companies established the City and Guilds of London Institute the forerunner of the engineering school (still called City and Guilds College) at Imperial College London. The aim of the City and Guilds of London Institute was the advancement of technical education. "City and Guilds" operates as an examining and accreditation body for vocational, managerial and engineering qualifications from entry-level craft and trade skills up to post-doctoral achievement. A separate organisation, the City and Guilds of London Art School has also close ties with the London livery companies and is involved in the training of master craftworkers in stone and wood carving, as well as fine artists.

In Germany there are no longer any "Zünfte" (or "Gilden" – the terms used were rather different from town to town), nor any restriction of a craft to a privileged corporation. However, under one other of their old names albeit a less frequent one, "Innungen", guilds continue to exist as private member clubs with membership limited to practitioners of particular trades or activities. These clubs are corporations under public law, albeit the membership is voluntary; the president normally comes from the ranks of master-craftsmen and is called "Obermeister" ("master-in-chief"). Journeymen elect their own representative bodies, with their president having the traditional title of "Altgesell" (senior journeyman).

There are also "craft chambers" ("Handwerkskammern"), which have less resemblance to ancient guilds in that they are organized for all crafts in a certain region, not just one. In them membership is mandatory, and they serve to establish self-governance of the crafts.

In the United States guilds exist in several fields.

In the film and television industry, guild membership is generally a prerequisite for working on major productions in certain capacities. The Screen Actors Guild, Directors Guild of America, Writers Guild of America, East, Writers Guild of America, West and other profession-specific guilds have the ability to exercise strong control in the cinema of the United States as a result of a rigid system of intellectual-property rights and a history of power-brokers also holding guild membership (e.g., DreamWorks founder Steven Spielberg was, and is, a DGA member). These guilds maintain their own contracts with production companies to ensure a certain number of their members are hired for roles in each film or television production, and that their members are paid a minimum of guild "scale," along with other labor protections. These guilds set high standards for membership, and exclude professional actors, writers, etc. who do not abide by the strict rules for competing within the film and television industry in America.

The Newspaper Guild is a labor union for journalists and other newspaper workers, with over 30,000 members in North America.

Real-estate brokerage offers an example of a modern American guild system. Signs of guild behavior in real-estate brokerage include: standard pricing (6% of the home price), strong affiliation among all practitioners, self-regulation (see National Association of Realtors), strong cultural identity (see realtor), little price variation with quality differences, and traditional methods in use by all practitioners. In September 2005 the U.S. Department of Justice filed an antitrust lawsuit against the National Association of Realtors, challenging NAR practices that (the DOJ asserted) prevent competition from practitioners who use different methods. The DOJ and the Federal Trade Commission in 2005 advocated against state laws, supported by NAR, that disadvantage new kinds of brokers. "U.S. v. National Assoc. of Realtors", Civil Action No. 05C-5140 (N.D. Ill. Sept. 7, 2005).

The practice of law in the United States also exemplifies modern guilds at work. Every state maintains its own bar association, supervised by that state's highest court. The court decides the criteria for entering and staying in the legal profession. In most states, every attorney must become a member of that state's bar association in order to practice law. State laws forbid any person from engaging in the unauthorized practice of law and practicing attorneys are subject to rules of professional conduct that are enforced by the state's high court.

Medical associations comparable to guilds include the state Medical Boards, the American Medical Association, and the American Dental Association. Medical licensing in most states requires specific training, tests and years of low-paid apprenticeship (internship and residency) under harsh working conditions. Even qualified international or out-of-state doctors may not practice without acceptance by the local medical guild (Medical board). Similarly, nurses and physicians' practitioners have their own guilds. A doctor cannot work as a physician's assistant unless (s)he separately trains, tests and apprentices as one.

Australia is home to several guilds including the Australian Butcher's Guild (a fraternity of independent butchers) which provides links to resources like Australian meat standards and a guide to different beef cuts. Another guild is The Pharmacy Guild of Australia, created in 1928 as the Federated Pharmaceutical Services Guild of Australia, which serves "5700 community pharmacies," while also providing training and standards for the country's pharmacists. Australia's craft guilds include, among others, the Australian Director's Guild, representing the country's directors, documentary makers and animators, the Australian Writer's Guild, and The Artists Guild, a craft guild focusing on female artists.






</doc>
<doc id="12372" url="https://en.wikipedia.org/wiki?curid=12372" title="Gradius (video game)">
Gradius (video game)

The arcade version of "Gradius" was released internationally outside Japan under the title of Nemesis, although subsequent home releases have the original title. Home versions were released for various platforms, such as the NES, the MSX home computer, and the PC Engine.

The player controls the trans-dimensional spaceship Vic Viper, and must battle waves of enemies through various environments. The game became synonymous with the phrase, "Destroy the core!", as the standard of boss battles in the "Gradius" series involved combat with a giant craft, in the center of which would be situated one to several blue colored spheres. These bosses would be designed in such a way that there would be a straight passage from the exterior of the giant craft which leads directly to one of these cores. The player must fire shots into this passage while avoiding attack patterns from weapon emplacements on the body of the boss. However, small but destructible walls are situated in this passage, impeding the bullet shots from damaging the core, and must be whittled away by repeated well-placed shots. In a way, these tiny walls represent the boss' shielding gauge until its core is finally vulnerable to attack. Some bosses have the ability to regenerate these walls. When the core has sustained enough hits, it usually changes color from blue to red, indicating that it is in critical condition and its destruction is imminent. Upon the destruction of a core, a piece of the boss may be put out of commission, seeing that it is no longer powered by a core, or if all of the cores are destroyed, the entire boss is defeated and explodes satisfyingly. Note that these cores are not present on the more organic bosses of "Gradius". Such bosses have weak spots in places such as a mouth, head or eye.

When gameplay begins, the Vic Viper is relatively slow and has only a weak gun. This level of capability is generally insufficient for engaging enemies, but the Vic Viper can gain greater capabilities by collecting and using power-up items. While most arcade games utilize distinct power up-items that each correspond to a specific effect on the player character, "Gradius" has a single power-up item. The effect of this power-up item is to advance the currently selected item in a power-up menu that appears at the bottom of the screen. When the desired power-up is highlighted, the player can obtain it by pressing the power-up button, returning the menu to its initial state in which no power-up is highlighted.
Development of "Gradius" began when series creator Hiroyasu Machiguchi was given a team to work with and asked them what kind of game they wanted to develop. The response was a shoot 'em up, with the intent of surpassing Namco's "Xevious". They made it a horizontal shooting game because they wanted to reuse material from "Scramble" as much as possible, originally naming the game "Scramble 2". The development lasted for a year after refining and experimenting with the gameplay. The team originally tried twenty different movement patterns for the Options and used a process of elimination when something did not work. For the story, Hiroyasu's team was inspired by science fiction movies, with the popular sci-fi films at the time being "Star Wars" and the anime adaptations of "Lensman". The team saw "Lensman" together and it influenced the game's story. Its plasma laser impressed them and is why "Gradius" features a laser weapon. The Moai were included to add a mysterious element to the game like "Xevious" and its Nazca Lines.

"Gradius" was first released in Japan for Konami's Bubble System, an arcade board which allows operators to change the software through the used of a proprietary magnetic-based media called "Bubble Software". The game was distributed as a standard printed circuit board in North America and Europe under the title of "Nemesis". The North American version of "Nemesis" features a considerably increased difficulty compared to the Japanese and European version. To balance this, the game spawns a fleet of orange enemies when the player loses a life in order to provide as many power-up capsules as possible in order to recover as many upgrades as possible. The title screen was also updated, showing an in-game reproduction of the promotional artwork behind the logo.

The first home conversion of "Gradius" was released for Nintendo's Famicom console on April 25, 1986 in Japan. Due to the hardware limitations of the Famicom, many of the level designs were simplified (the Moai stage, for example, lacks the vertical scrolling present in the arcade game) and the maximum amount of options that the player can upgrade to was reduced from four to two. This version added a cheat code that can be entered while the game is paused that grants the player's ship almost all the power-ups. This code would appear again in many later Konami on the NES and other consoles (such as "Contra" and "Life Force"), becoming known as the Konami Code.

The NES version of "Gradius" was released in North America on December 1986. It is the first NES game to have been released by Konami in the region and unlike the original arcade game, the title was kept unchanged between regions. The NES version was produced for the arcades on the Nintendo Vs. System board (under the title of "VS. Gradius"), as well on the PlayChoice 10 cabinet.

The MSX version of "Gradius" was released on July 25, 1986 in Japan, a few months after the Famicom version. It was also released in Europe under the "Nemesis" title. This version underwent changes similar to the Famicom version, but adds its slew of exclusive content to make up for the downgrade. A new stage, the bone planet was added between the Inverted Volcano stage and the Antennoid stage, featuring exclusive enemy types. There also four hidden warp zones and the ability to play as the titular ship from "TwinBee" if the MSX version of that game is played alongside "Nemesis".

The PC Engine version of "Gradius" was released on November 15, 1991 exclusively in Japan. Released on a 2-Megabit HuCard, it had relatively few omissions compared to the NES and MSX versions and added a Desert Planet stage similar to the Bone Planet stage from the MSX version. Because of the lower resolution of the PC Engine compared to the original arcade hardware, the PC Engine features some slight vertical-scrolling.

In addition to the MSX, "Gradius" was also ported to other microcomputers shortly after its release, such as the ZX Spectrum, Amstrad CPC and Commodore 64 in Europe (as "Nemesis: The Final Challenge"), as well as the NEC PC-8801 and Sharp X1 in Japan. A port for the X68000 computer was also included in the early models of the computer. The original "Gradius" is also included in collection such as "Gradius Deluxe Pack" for the PlayStation and Sega Saturn and "Gradius Collection" for the PlayStation Portable. The arcade
version was digitally released on the PlayStation 4 as part of the Arcade Archives series, with the option to play all four regional variants of the game.


The game went to number 2 in the UK sales charts, behind "Feud". The Western cover art for the NES version claimed that it had sold one million copies in Japan. 

"GameSpot" stated that "Gradius" was one of the toughest side-scrolling shooter games available on the NES, second only to "Contra". "IGN" has given the game a rating 7 out of 10 for its re-release on the Wii Virtual Console and has hailed it as one of the greatest classic side-scrolling shooter games.

"Gradius" spawned several sequels, the first of which was 1986's "Salamander". The series has continued into the seventh generation with "Gradius ReBirth".

It was also re-released on Windows Store on December 20, 2013, GameNow in May 2014 and for PlayStation 4's Arcade Archives on January 25 in Japan. An NES port was re-released for the Nintendo Switch Online on September 19, 2018 in Worldwide and Update release as on November 14, 2018 in Worldwide.




</doc>
<doc id="12373" url="https://en.wikipedia.org/wiki?curid=12373" title="Gamemaster">
Gamemaster

A gamemaster (GM; also known as game master, game manager, game moderator or referee) is a person who acts as an organizer, officiant for regarding rules, arbitrator, and moderator for a multiplayer role-playing game. They are more common in co-operative games in which players work together than in competitive games in which players oppose each other. The act performed by a gamemaster is sometimes referred to as "Gamemastering" or simply "GM-ing".

The role of a gamemaster in a traditional table-top role-playing game (pencil-and-paper role-playing game) is to weave the other participants' player-character stories together, control the non-player aspects of the game, create environments in which the players can interact, and solve any player disputes. The basic role of the gamemaster is the same in almost all traditional role-playing games, although differing rule sets make the specific duties of the gamemaster unique to that system.

The role of a gamemaster in an online game is to enforce the game's rules and provide general customer service. Also, unlike gamemasters in traditional role-playing games, gamemasters for online games in some cases are paid employees.

The term "gamemaster" and the role associated with it could be found in the postal gaming hobby. In typical play-by-mail games, players control armies or civilizations and mail their chosen actions to the GM. The GM then mails the updated game state to all players on a regular basis. Usage in a wargaming context includes Guidon Games 1973 ruleset, "Ironclad". 

In a role-playing game context, it was first used by Dave Arneson while developing his game "Blackmoor" in 1971, although the first usage in print may have been "Chivalry & Sorcery". 

Each gaming system has its own name for the role of the gamemaster, such as "judge", "narrator", "referee", "director", or "storyteller", and these terms not only describe the role of the gamemaster in general but also help define how the game is intended to be run. For example, the Storyteller System used in White Wolf Game Studio's storytelling games calls its GM the "storyteller", while the rules- and setting-focused "Marvel Super Heroes" role-playing game calls its GM the "judge". The cartoon inspired role-playing game "Toon" calls its GM the "animator". A few games apply system- or setting-specific flavorful names to the GM, such as the Keeper of Arcane Lore (in "Call of Cthulhu"); the Hollyhock God ("Nobilis", in which the hollyhock represents vanity), or the most famous of such terms, "Dungeon Master" (or "DM") in "Dungeons & Dragons".

The gamemaster prepares the game session for the players and the characters they play (known as player characters or PCs), describes the events taking place and decides on the outcomes of players' decisions. The gamemaster also keeps track of non-player characters (NPCs) and random encounters, as well as of the general state of the game world. The game session (or "adventure") can be metaphorically described as a play, in which the players are the lead actors, and the GM provides the stage, the scenery, the basic plot on which the improvisational script is built, as well as all the bit parts and supporting characters. Gamemasters can also be in charge of RPG board games making the events and setting challenges.

GMs may choose to run a game based on a published game world, with the maps and history already in place; such game worlds often have pre-written adventures. Alternatively, the GM may build their own world and script their own adventures.

A good gamemaster draws the players into the adventure, making it enjoyable for everyone. Good gamemasters have quick minds, sharp wits, and rich imaginations. Gamemasters must also maintain game balance: hideously overpowered monsters "or" players are no fun. It was noted, in 1997, that those who favor their left-brain such as skilled code writers usually do not make it in the ethereal gamemaster world of storytelling and verse.


In early virtual worlds gamemasters served as a moderator or administrator; in MUD game masters were called "wizards". Gamemastering in the form found in traditional role-playing games has also been used in a semi-automatic virtual worlds. However, human moderation was sometimes considered unfair or out of context in an otherwise automated world.
As online games expanded, gamemaster duties expanded to include being a customer service representative for an online community. A gamemaster in such a game is either an experienced volunteer player or an employee of the game's publisher. They enforce the game's rules by banishing spammers, player killers, cheaters, and hackers and by solving players' problems by providing general customer service. For their tasks they use special tools and characters that allow them to do things like teleport to players, summon items, and browse logs that record players' activities. Often, players who feel dissatisfied with the game will blame the GMs directly for any errors or glitches. However, this blame is misdirected as most GMs are not developers and cannot resolve those types of problems.

The now defunct America Online Online Gaming Forum used to use volunteers selected by applications from its user base. These people were simply referred to as OGFs by other members, and their screennames were indicative of their position (i.e., OGF Moose, etc.). While membership in the Online Gaming Forum had only one real requirement (that is, be a member of AOL), OGFs were given powers quite similar to AOL "Guides" and could use them at will to discipline users as they saw appropriate.

"World of Warcraft" has employees of Blizzard Entertainment that serve as gamemasters to help users with various problems in gameplay, chat, and other things like account and billing issues. A gamemaster in this game will communicate with players through chat that has blue text and they will also have a special "GM" tag and Blizzard logo in front of their names.

"RuneScape" has more than 500 moderators employed by Jagex to assist players and perform administrative duties in-game and on the site forums. These "Jagex Moderators", as they are called, usually have the word "Mod" and a gold crown preceding their account names which ordinary players are not permitted to use. The game also has "Player Moderators" and "Forum Moderators" who are player volunteers helping with moderation, having the ability to mute (block from chatting) other players who violate rules.

"Battleground Europe", a medium-sized MMOFPS has a team of "Game Moderators", anonymous volunteers who moderate the game.

"Miniconomy", a smaller text-based MMO has a team of "Federals", experienced players that help moderate the game and interactions.

"Transformice", an MMORPG, has a team of volunteer moderators called "Mods" who are experienced players that help moderate the game and interactions.

Note that a few games, notably "Neverwinter Nights" and "", are video game adaptations of tabletop role-playing games that are played online with one player acting as a traditional gamemaster.

Gamemastering, sometimes referred to as Orchestration is used in pervasive games to guide players along a trajectory desired by the game author. To ensure proper gamemastering can take place, four components are needed: some kind of sensory system to the game allowing the game masters to know current events, providing dynamic game information; dynamic and static game information lets game masters make informed decisions; decisions need to be actuated into the game, either through the game system or through manual intervention; and finally a communication structure is needed for both diegetic or non-diegetic communication.
Effective gamemastering can require specialized user interfaces that are highly game specific.

Sometimes, tabletop GMs simply can not find players interested in either the same setting, product line, or play style in their local neighborhood. The advent of the networked personal computer provided a solution in the form of online chat programs. Appropriately equipped gamemasters can find players online and a group can meet via chat rooms, forums, or other electronic means.

In contrast to standard tabletop procedure (and to games "designed" to be played online), this online chat format significantly changed the balance of duties for a prospective gamemaster. Descriptive text required more preparation, if only via cut-and-paste; acting and voice skills could not be utilized to get the personality of NPCs and monsters across, increasing the value of background music ('assigned' in advance or individually chosen) as a playing aid. The GM was likely to need copies of player-character records, being unable to glance at the originals as in normal face-to-face procedure. The format also forced the issue (particularly when participants were not personally acquainted) of whether to leave all rolling of dice to the GM (making one's own rolls is a privilege not readily surrendered by some players), or to trust all players to honestly report the results of their rolls (the honor system may be strained when it is in a player's best interest to roll well).

However, workarounds to these challenges have only increased over time. The use of Wiki software helps GMs and players alike keep track of all manner of game data, sometimes evolving into a home-made gaming supplement. Scripting software allows unwieldy mechanics (e.g. a complicated formula or repetitive die-rolling) to be resolved at the push of a button. Teleconferencing enhances group communication through voice, video, and a shared whiteboard. The use of technology to enable online play is growing, as reflected in products like the D&D Insider.



</doc>
<doc id="12383" url="https://en.wikipedia.org/wiki?curid=12383" title="Genetic engineering">
Genetic engineering

Genetic engineering, also called genetic modification or genetic manipulation, is the direct manipulation of an organism's genes using biotechnology. It is a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms. New DNA is obtained by either isolating and copying the genetic material of interest using recombinant DNA methods or by artificially synthesising the DNA. A construct is usually created and used to insert this DNA into the host organism. The first recombinant DNA molecule was made by Paul Berg in 1972 by combining DNA from the monkey virus SV40 with the lambda virus. As well as inserting genes, the process can be used to remove, or "knock out", genes. The new DNA can be inserted randomly, or targeted to a specific part of the genome.

An organism that is generated through genetic engineering is considered to be genetically modified (GM) and the resulting entity is a genetically modified organism (GMO). The first GMO was a bacterium generated by Herbert Boyer and Stanley Cohen in 1973. Rudolf Jaenisch created the first GM animal when he inserted foreign DNA into a mouse in 1974. The first company to focus on genetic engineering, Genentech, was founded in 1976 and started the production of human proteins. Genetically engineered human insulin was produced in 1978 and insulin-producing bacteria were commercialised in 1982. Genetically modified food has been sold since 1994, with the release of the Flavr Savr tomato. The Flavr Savr was engineered to have a longer shelf life, but most current GM crops are modified to increase resistance to insects and herbicides. GloFish, the first GMO designed as a pet, was sold in the United States in December 2003. In 2016 salmon modified with a growth hormone were sold.

Genetic engineering has been applied in numerous fields including research, medicine, industrial biotechnology and agriculture. In research GMOs are used to study gene function and expression through loss of function, gain of function, tracking and expression experiments. By knocking out genes responsible for certain conditions it is possible to create animal model organisms of human diseases. As well as producing hormones, vaccines and other drugs genetic engineering has the potential to cure genetic diseases through gene therapy. The same techniques that are used to produce drugs can also have industrial applications such as producing enzymes for laundry detergent, cheeses and other products.

The rise of commercialised genetically modified crops has provided economic benefit to farmers in many different countries, but has also been the source of most of the controversy surrounding the technology. This has been present since its early use; the first field trials were destroyed by anti-GM activists. Although there is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, GM food safety is a leading concern with critics. Gene flow, impact on non-target organisms, control of the food supply and intellectual property rights have also been raised as potential issues. These concerns have led to the development of a regulatory framework, which started in 1975. It has led to an international treaty, the Cartagena Protocol on Biosafety, that was adopted in 2000. Individual countries have developed their own regulatory systems regarding GMOs, with the most marked differences occurring between the US and Europe.

Genetic engineering is a process that alters the genetic structure of an organism by either removing or introducing DNA. Unlike traditional animal and plant breeding, which involves doing multiple crosses and then selecting for the organism with the desired phenotype, genetic engineering takes the gene directly from one organism and inserts it in the other. This is much faster, can be used to insert any genes from any organism (even ones from different domains) and prevents other undesirable genes from also being added.

Genetic engineering could potentially fix severe genetic disorders in humans by replacing the defective gene with a functioning one. It is an important tool in research that allows the function of specific genes to be studied. Drugs, vaccines and other products have been harvested from organisms engineered to produce them. Crops have been developed that aid food security by increasing yield, nutritional value and tolerance to environmental stresses.

The DNA can be introduced directly into the host organism or into a cell that is then fused or hybridised with the host. This relies on recombinant nucleic acid techniques to form new combinations of heritable genetic material followed by the incorporation of that material either indirectly through a vector system or directly through micro-injection, macro-injection or micro-encapsulation.

Genetic engineering does not normally include traditional breeding, in vitro fertilisation, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process. However, some broad definitions of genetic engineering include selective breeding. Cloning and stem cell research, although not considered genetic engineering, are closely related and genetic engineering can be used within them. Synthetic biology is an emerging discipline that takes genetic engineering a step further by introducing artificially synthesised material into an organism.

Plants, animals or micro organisms that have been changed through genetic engineering are termed genetically modified organisms or GMOs. If genetic material from another species is added to the host, the resulting organism is called transgenic. If genetic material from the same species or a species that can naturally breed with the host is used the resulting organism is called cisgenic. If genetic engineering is used to remove genetic material from the target organism the resulting organism is termed a knockout organism. In Europe genetic modification is synonymous with genetic engineering while within the United States of America and Canada genetic modification can also be used to refer to more conventional breeding methods.

Humans have altered the genomes of species for thousands of years through selective breeding, or artificial selection as contrasted with natural selection. More recently, mutation breeding has used exposure to chemicals or radiation to produce a high frequency of random mutations, for selective breeding purposes. Genetic engineering as the direct manipulation of DNA by humans outside breeding and mutations has only existed since the 1970s. The term "genetic engineering" was first coined by Jack Williamson in his science fiction novel "Dragon's Island", published in 1951 – one year before DNA's role in heredity was confirmed by Alfred Hershey and Martha Chase, and two years before James Watson and Francis Crick showed that the DNA molecule has a double-helix structure – though the general concept of direct genetic manipulation was explored in rudimentary form in Stanley G. Weinbaum's 1936 science fiction story "Proteus Island".

In 1972, Paul Berg created the first recombinant DNA molecules by combining DNA from the monkey virus SV40 with that of the lambda virus. In 1973 Herbert Boyer and Stanley Cohen created the first transgenic organism by inserting antibiotic resistance genes into the plasmid of an "Escherichia coli" bacterium. A year later Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world’s first transgenic animal These achievements led to concerns in the scientific community about potential risks from genetic engineering, which were first discussed in depth at the Asilomar Conference in 1975. One of the main recommendations from this meeting was that government oversight of recombinant DNA research should be established until the technology was deemed safe.

In 1976 Genentech, the first genetic engineering company, was founded by Herbert Boyer and Robert Swanson and a year later the company produced a human protein (somatostatin) in "E.coli". Genentech announced the production of genetically engineered human insulin in 1978. In 1980, the U.S. Supreme Court in the "Diamond v. Chakrabarty" case ruled that genetically altered life could be patented. The insulin produced by bacteria was approved for release by the Food and Drug Administration (FDA) in 1982.

In 1983, a biotech company, Advanced Genetic Sciences (AGS) applied for U.S. government authorisation to perform field tests with the ice-minus strain of "Pseudomonas syringae" to protect crops from frost, but environmental groups and protestors delayed the field tests for four years with legal challenges. In 1987, the ice-minus strain of "P. syringae" became the first genetically modified organism (GMO) to be released into the environment when a strawberry field and a potato field in California were sprayed with it. Both test fields were attacked by activist groups the night before the tests occurred: "The world's first trial site attracted the world's first field trasher".

The first field trials of genetically engineered plants occurred in France and the US in 1986, tobacco plants were engineered to be resistant to herbicides. The People’s Republic of China was the first country to commercialise transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the first genetically modified food, the Flavr Savr, a tomato engineered to have a longer shelf life. In 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialised in Europe. In 1995, Bt Potato was approved safe by the Environmental Protection Agency, after having been approved by the FDA, making it the first pesticide producing crop to be approved in the US. In 2009 11 transgenic crops were grown commercially in 25 countries, the largest of which by area grown were the US, Brazil, Argentina, India, Canada, China, Paraguay and South Africa.

In 2010, scientists at the J. Craig Venter Institute created the first synthetic genome and inserted it into an empty bacterial cell. The resulting bacterium, named Mycoplasma laboratorium, could replicate and produce proteins. Four years later this was taken a step further when a bacterium was developed that replicated a plasmid containing a unique base pair, creating the first organism engineered to use an expanded genetic alphabet. In 2012, Jennifer Doudna and Emmanuelle Charpentier collaborated to develop the CRISPR/Cas9 system, a technique which can be used to easily and specifically alter the genome of almost any organism.

Creating a GMO is a multi-step process. Genetic engineers must first choose what gene they wish to insert into the organism. This is driven by what the aim is for the resultant organism and is built on earlier research. Genetic screens can be carried out to determine potential genes and further tests then used to identify the best candidates. The development of microarrays, transcriptomics and genome sequencing has made it much easier to find suitable genes. Luck also plays its part; the round-up ready gene was discovered after scientists noticed a bacterium thriving in the presence of the herbicide.

The next step is to isolate the candidate gene. The cell containing the gene is opened and the DNA is purified. The gene is separated by using restriction enzymes to cut the DNA into fragments or polymerase chain reaction (PCR) to amplify up the gene segment. These segments can then be extracted through gel electrophoresis. If the chosen gene or the donor organism's genome has been well studied it may already be accessible from a genetic library. If the DNA sequence is known, but no copies of the gene are available, it can also be artificially synthesised. Once isolated the gene is ligated into a plasmid that is then inserted into a bacterium. The plasmid is replicated when the bacteria divide, ensuring unlimited copies of the gene are available.

Before the gene is inserted into the target organism it must be combined with other genetic elements. These include a promoter and terminator region, which initiate and end transcription. A selectable marker gene is added, which in most cases confers antibiotic resistance, so researchers can easily determine which cells have been successfully transformed. The gene can also be modified at this stage for better expression or effectiveness. These manipulations are carried out using recombinant DNA techniques, such as restriction digests, ligations and molecular cloning.

There are a number of techniques used to insert genetic material into the host genome. Some bacteria can naturally take up foreign DNA. This ability can be induced in other bacteria via stress (e.g. thermal or electric shock), which increases the cell membrane's permeability to DNA; up-taken DNA can either integrate with the genome or exist as extrachromosomal DNA. DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell's nuclear envelope directly into the nucleus, or through the use of viral vectors.

In plants the DNA is often inserted using "Agrobacterium"-mediated recombination, taking advantage of the "Agrobacterium"s T-DNA sequence that allows natural insertion of genetic material into plant cells. Other methods include biolistics, where particles of gold or tungsten are coated with DNA and then shot into young plant cells, and electroporation, which involves using an electric shock to make the cell membrane permeable to plasmid DNA. Due to the damage caused to the cells and DNA the transformation efficiency of biolistics and electroporation is lower than agrobacterial transformation and microinjection.

As only a single cell is transformed with genetic material, the organism must be regenerated from that single cell. In plants this is accomplished through the use of tissue culture. In animals it is necessary to ensure that the inserted DNA is present in the embryonic stem cells. Bacteria consist of a single cell and reproduce clonally so regeneration is not necessary. Selectable markers are used to easily differentiate transformed from untransformed cells. These markers are usually present in the transgenic organism, although a number of strategies have been developed that can remove the selectable marker from the mature transgenic plant.

Further testing using PCR, Southern hybridization, and DNA sequencing is conducted to confirm that an organism contains the new gene. These tests can also confirm the chromosomal location and copy number of the inserted gene. The presence of the gene does not guarantee it will be expressed at appropriate levels in the target tissue so methods that look for and measure the gene products (RNA and protein) are also used. These include northern hybridisation, quantitative RT-PCR, Western blot, immunofluorescence, ELISA and phenotypic analysis.

The new genetic material can be inserted randomly within the host genome or targeted to a specific location. The technique of gene targeting uses homologous recombination to make desired changes to a specific endogenous gene. This tends to occur at a relatively low frequency in plants and animals and generally requires the use of selectable markers. The frequency of gene targeting can be greatly enhanced through genome editing. Genome editing uses artificially engineered nucleases that create specific double-stranded breaks at desired locations in the genome, and use the cell’s endogenous mechanisms to repair the induced break by the natural processes of homologous recombination and nonhomologous end-joining. There are four families of engineered nucleases: meganucleases, zinc finger nucleases, transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from CRISPR). TALEN and CRISPR are the two most commonly used and each has its own advantages. TALENs have greater target specificity, while CRISPR is easier to design and more efficient. In addition to enhancing gene targeting, engineered nucleases can be used to introduce mutations at endogenous genes that generate a gene knockout.

Genetic engineering has applications in medicine, research, industry and agriculture and can be used on a wide range of plants, animals and micro organisms. Bacteria, the first organisms to be genetically modified, can have plasmid DNA inserted containing new genes that code for medicines or enzymes that process food and other substrates. Plants have been modified for insect protection, herbicide resistance, virus resistance, enhanced nutrition, tolerance to environmental pressures and the production of edible vaccines. Most commercialised GMOs are insect resistant or herbicide tolerant crop plants. Genetically modified animals have been used for research, model animals and the production of agricultural or pharmaceutical products. The genetically modified animals include animals with genes knocked out, increased susceptibility to disease, hormones for extra growth and the ability to express proteins in their milk.

Genetic engineering has many applications to medicine that include the manufacturing of drugs, creation of model animals that mimic human conditions and gene therapy. One of the earliest uses of genetic engineering was to mass-produce human insulin in bacteria. This application has now been applied to, human growth hormones, follicle stimulating hormones (for treating infertility), human albumin, monoclonal antibodies, antihemophilic factors, vaccines and many other drugs. Mouse hybridomas, cells fused together to create monoclonal antibodies, have been adapted through genetic engineering to create human monoclonal antibodies. In 2017, genetic engineering of chimeric antigen receptors on a patient's own T-cells was approved by the U.S. FDA as a treatment for the cancer acute lymphoblastic leukemia. Genetically engineered viruses are being developed that can still confer immunity, but lack the infectious sequences.

Genetic engineering is also used to create animal models of human diseases. Genetically modified mice are the most common genetically engineered animal model. They have been used to study and model cancer (the oncomouse), obesity, heart disease, diabetes, arthritis, substance abuse, anxiety, aging and Parkinson disease. Potential cures can be tested against these mouse models. Also genetically modified pigs have been bred with the aim of increasing the success of pig to human organ transplantation.

Gene therapy is the genetic engineering of humans, generally by replacing defective genes with effective ones. Clinical research using somatic gene therapy has been conducted with several diseases, including X-linked SCID, chronic lymphocytic leukemia (CLL), and Parkinson's disease. In 2012, Alipogene tiparvovec became the first gene therapy treatment to be approved for clinical use. In 2015 a virus was used to insert a healthy gene into the skin cells of a boy suffering from a rare skin disease, epidermolysis bullosa, in order to grow, and then graft healthy skin onto 80 percent of the boy's body which was affected by the illness.

Germline gene therapy would result in any change being inheritable, which has raised concerns within the scientific community. In 2015, CRISPR was used to edit the DNA of non-viable human embryos, leading scientists of major world academies to call for a moratorium on inheritable human genome edits. There are also concerns that the technology could be used not just for treatment, but for enhancement, modification or alteration of a human beings' appearance, adaptability, intelligence, character or behavior. The distinction between cure and enhancement can also be difficult to establish. In November 2018, He Jiankui announced that he had edited the genomes of two human embryos, to attempt to disable the "CCR5" gene, which codes for a receptor that HIV uses to enter cells. He said that twin girls, Lulu and Nana, had been born a few weeks earlier. He said that the girls still carried functional copies of CCR5 along with disabled CCR5 (mosaicism) and were still vulnerable to HIV. The work was widely condemned as unethical, dangerous, and premature.

Researchers are altering the genome of pigs to induce the growth of human organs to be used in transplants. Scientists are creating "gene drives", changing the genomes of mosquitoes to make them immune to malaria, and then looking to spread the genetically altered mosquitoes throughout the mosquito population in the hopes of eliminating the disease.

Genetic engineering is an important tool for natural scientists, with the creation of transgenic organisms one of the most important tools for analysis of gene function. Genes and other genetic information from a wide range of organisms can be inserted into bacteria for storage and modification, creating genetically modified bacteria in the process. Bacteria are cheap, easy to grow, clonal, multiply quickly, relatively easy to transform and can be stored at -80 °C almost indefinitely. Once a gene is isolated it can be stored inside the bacteria providing an unlimited supply for research.
Organisms are genetically engineered to discover the functions of certain genes. This could be the effect on the phenotype of the organism, where the gene is expressed or what other genes it interacts with. These experiments generally involve loss of function, gain of function, tracking and expression.


Organisms can have their cells transformed with a gene coding for a useful protein, such as an enzyme, so that they will overexpress the desired protein. Mass quantities of the protein can then be manufactured by growing the transformed organism in bioreactor equipment using industrial fermentation, and then purifying the protein. Some genes do not work well in bacteria, so yeast, insect cells or mammalians cells can also be used. These techniques are used to produce medicines such as insulin, human growth hormone, and vaccines, supplements such as tryptophan, aid in the production of food (chymosin in cheese making) and fuels. Other applications with genetically engineered bacteria could involve making them perform tasks outside their natural cycle, such as making biofuels, cleaning up oil spills, carbon and other toxic waste and detecting arsenic in drinking water. Certain genetically modified microbes can also be used in biomining and bioremediation, due to their ability to extract heavy metals from their environment and incorporate them into compounds that are more easily recoverable.

In materials science, a genetically modified virus has been used in a research laboratory as a scaffold for assembling a more environmentally friendly lithium-ion battery. Bacteria have also been engineered to function as sensors by expressing a fluorescent protein under certain environmental conditions.

One of the best-known and controversial applications of genetic engineering is the creation and use of genetically modified crops or genetically modified livestock to produce genetically modified food. Crops have been developed to increase production, increase tolerance to abiotic stresses, alter the composition of the food, or to produce novel products.

The first crops to be released commercially on a large scale provided protection from insect pests or tolerance to herbicides. Fungal and virus resistant crops have also been developed or are in development. This makes the insect and weed management of crops easier and can indirectly increase crop yield. GM crops that directly improve yield by accelerating growth or making the plant more hardy (by improving salt, cold or drought tolerance) are also under development. In 2016 Salmon have been genetically modified with growth hormones to reach normal adult size much faster.

GMOs have been developed that modify the quality of produce by increasing the nutritional value or providing more industrially useful qualities or quantities. The Amflora potato produces a more industrially useful blend of starches. Soybeans and canola have been genetically modified to produce more healthy oils. The first commercialised GM food was a tomato that had delayed ripening, increasing its shelf life.

Plants and animals have been engineered to produce materials they do not normally make. Pharming uses crops and animals as bioreactors to produce vaccines, drug intermediates, or the drugs themselves; the useful product is purified from the harvest and then used in the standard pharmaceutical production process. Cows and goats have been engineered to express drugs and other proteins in their milk, and in 2009 the FDA approved a drug produced in goat milk.

Genetic engineering has potential applications in conservation and natural area management. Gene transfer through viral vectors has been proposed as a means of controlling invasive species as well as vaccinating threatened fauna from disease. Transgenic trees have been suggested as a way to confer resistance to pathogens in wild populations. With the increasing risks of maladaptation in organisms as a result of climate change and other perturbations, facilitated adaptation through gene tweaking could be one solution to reducing extinction risks. Applications of genetic engineering in conservation are thus far mostly theoretical and have yet to be put into practice.

Genetic engineering is also being used to create microbial art. Some bacteria have been genetically engineered to create black and white photographs. Novelty items such as lavender-colored carnations, blue roses, and glowing fish have also been produced through genetic engineering.

The regulation of genetic engineering concerns the approaches taken by governments to assess and manage the risks associated with the development and release of GMOs. The development of a regulatory framework began in 1975, at Asilomar, California. The Asilomar meeting recommended a set of voluntary guidelines regarding the use of recombinant technology. As the technology improved the US established a committee at the Office of Science and Technology, which assigned regulatory approval of GM food to the USDA, FDA and EPA. The Cartagena Protocol on Biosafety, an international treaty that governs the transfer, handling, and use of GMOs, was adopted on 29 January 2000. One hundred and fifty-seven countries are members of the Protocol and many use it as a reference point for their own regulations.

The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation. Some countries allow the import of GM food with authorisation, but either do not allow its cultivation (Russia, Norway, Israel) or have provisions for cultivation even though no GM products are yet produced (Japan, South Korea). Most countries that do not allow GMO cultivation do permit research. Some of the most marked differences occurring between the US and Europe. The US policy focuses on the product (not the process), only looks at verifiable scientific risks and uses the concept of substantial equivalence. The European Union by contrast has possibly the most stringent GMO regulations in the world. All GMOs, along with irradiated food, are considered "new food" and subject to extensive, case-by-case, science-based food evaluation by the European Food Safety Authority. The criteria for authorisation fall in four broad categories: "safety," "freedom of choice," "labelling," and "traceability." The level of regulation in other countries that cultivate GMOs lie in between Europe and the United States.
One of the key issues concerning regulators is whether GM products should be labeled. The European Commission says that mandatory labeling and traceability are needed to allow for informed choice, avoid potential false advertising and facilitate the withdrawal of products if adverse effects on health or the environment are discovered. The American Medical Association and the American Association for the Advancement of Science say that absent scientific evidence of harm even voluntary labeling is misleading and will falsely alarm consumers. Labeling of GMO products in the marketplace is required in 64 countries. Labeling can be mandatory up to a threshold GM content level (which varies between countries) or voluntary. In Canada and the US labeling of GM food is voluntary, while in Europe all food (including processed food) or feed which contains greater than 0.9% of approved GMOs must be labelled.

Critics have objected to the use of genetic engineering on several grounds, including ethical, ecological and economic concerns. Many of these concerns involve GM crops and whether food produced from them is safe and what impact growing them will have on the environment. These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries.

Accusations that scientists are "playing God" and other religious issues have been ascribed to the technology from the beginning. Other ethical issues raised include the patenting of life, the use of intellectual property rights, the level of labeling on products, control of the food supply and the objectivity of the regulatory process. Although doubts have been raised, economically most studies have found growing GM crops to be beneficial to farmers.

Gene flow between GM crops and compatible plants, along with increased use of selective herbicides, can increase the risk of "superweeds" developing. Other environmental concerns involve potential impacts on non-target organisms, including soil microbes, and an increase in secondary and resistant insect pests. Many of the environmental impacts regarding GM crops may take many years to be understood and are also evident in conventional agriculture practices. With the commercialisation of genetically modified fish there are concerns over what the environmental consequences will be if they escape.

There are three main concerns over the safety of genetically modified food: whether they may provoke an allergic reaction; whether the genes could transfer from the food into human cells; and whether the genes not approved for human consumption could outcross to other crops. There is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe.

Genetic engineering features in many science fiction stories. Frank Herbert's novel "The White Plague" described the deliberate use of genetic engineering to create a pathogen which specifically killed women. Another of Herbert's creations, the "Dune" series of novels, uses genetic engineering to create the powerful but despised Tleilaxu. Films such as "The Island" and "Blade Runner" bring the engineered creature to confront the person who created it or the being it was cloned from. Few films have informed audiences about genetic engineering, with the exception of the 1978 "The Boys from Brazil" and the 1993 "Jurassic Park", both of which made use of a lesson, a demonstration, and a clip of scientific film. Genetic engineering methods are weakly represented in film; Michael Clark, writing for The Wellcome Trust, calls the portrayal of genetic engineering and biotechnology "seriously distorted" in films such as "The 6th Day". In Clark's view, the biotechnology is typically "given fantastic but visually arresting forms" while the science is either relegated to the background or fictionalised to suit a young audience.





</doc>
<doc id="12384" url="https://en.wikipedia.org/wiki?curid=12384" title="Gettysburg Address">
Gettysburg Address

The Gettysburg Address is a speech that U.S. President Abraham Lincoln delivered during the American Civil War at the dedication of the Soldiers' National Cemetery in Gettysburg, Pennsylvania, on the afternoon of Thursday, November 19, 1863, four and a half months after the Union armies defeated those of the Confederacy at the Battle of Gettysburg. It is one of the best-known speeches in American history.

Although not the day's primary speech, Lincoln's carefully crafted address came to be seen as one of the greatest and most influential statements of American national purpose. In just 271 words, beginning with the now iconic phrase "Four score and seven years ago,"‍ referring to the signing of the Declaration of Independence eighty-seven years earlier‍, Lincoln described the USA as a nation "conceived in Liberty, and dedicated to the proposition that all men are created equal," and represented the Civil War as a test that would decide whether such a nation, the Union sundered by the secession crisis, could endure. He extolled the sacrifices of those who died at Gettysburg in defense of those principles, and exhorted his listeners to resolve

Despite the speech's prominent place in the history and popular culture of the United States, its exact wording is disputed. The five known manuscripts of the Gettysburg Address in Lincoln's hand differ in a number of details, and also differ from contemporary newspaper reprints of the speech. Neither is it clear just where stood the platform from which Lincoln delivered the address. Modern scholarship locates the speakers' platform 40 yards (or more) away from the traditional site in Soldiers' National Cemetery at the Soldiers' National Monument, which means that it stood entirely within the private, adjacent Evergreen Cemetery.

Following the Battle of Gettysburg on July 1–3, 1863, the removal of the fallen Union soldiers from the Gettysburg Battlefield graves and their reburial in graves at the National Cemetery at Gettysburg began on October 17. In inviting President Lincoln to the ceremonies, David Wills, of the committee for the November 19 Consecration of the National Cemetery at Gettysburg, wrote, "It is the desire that, after the Oration, you, as Chief Executive of the nation, formally set apart these grounds to their sacred use by a few appropriate remarks."

On the train trip from Washington, D.C., to Gettysburg on November 18, Lincoln was accompanied by three members of his Cabinet, William Seward, John Usher and Montgomery Blair, several foreign officials, his secretary John Nicolay, and his assistant secretary, John Hay. During the trip Lincoln remarked to Hay that he felt weak; on the morning of November 19, Lincoln mentioned to Nicolay that he was dizzy. Hay noted that during the speech Lincoln's face had "a ghastly color" and that he was "sad, mournful, almost haggard." After the speech, when Lincoln boarded the 6:30 pm train for Washington, D.C., he was feverish and weak, with a severe headache. A protracted illness followed, which included a vesicular rash; it was diagnosed as a mild case of smallpox. It thus seems highly likely that Lincoln was in the prodromal period of smallpox when he delivered the Gettysburg address.

The program organized for that day by Wills and his committee included:

While it is Lincoln's short speech that has gone down in history as one of the finest examples of English public oratory, it was Everett's two-hour oration that was slated to be the "Gettysburg address" that day. His now seldom-read 13,607-word oration began:

Standing beneath this serene sky, overlooking these broad fields now reposing from the labors of the waning year, the mighty Alleghenies dimly towering before us, the graves of our brethren beneath our feet, it is with hesitation that I raise my poor voice to break the eloquent silence of God and Nature. But the duty to which you have called me must be performed;—grant me, I pray you, your indulgence and your sympathy.

And ended two hours later with:

But they, I am sure, will join us in saying, as we bid farewell to the dust of these martyr-heroes, that wheresoever throughout the civilized world the accounts of this great warfare are read, and down to the latest period of recorded time, in the glorious annals of our common country, there will be no brighter page than that which relates the Battles of Gettysburg.

Lengthy dedication addresses like Everett's were common at cemeteries in this era. The tradition began in 1831 when Justice Joseph Story delivered the dedication address at Mount Auburn Cemetery in Cambridge, Massachusetts. Those addresses often linked cemeteries to the mission of Union.

Lincoln's address followed the oration by Edward Everett, who subsequently included a copy of the Gettysburg Address in his 1864 book about the event ("Address of the Hon. Edward Everett At the Consecration of the National Cemetery At Gettysburg, 19th November 1863, with the Dedicatory Speech of President Lincoln, and the Other Exercises of the Occasion; Accompanied by An Account of the Origin of the Undertaking and of the Arrangement of the Cemetery Grounds, and by a Map of the Battle-field and a Plan of the Cemetery").

Shortly after Everett's well-received remarks, Lincoln spoke for only a few minutes. With a "few appropriate remarks", he was able to summarize his view of the war in just ten sentences.

Despite the historical significance of Lincoln's speech, modern scholars disagree as to its exact wording, and contemporary transcriptions published in newspaper accounts of the event and even handwritten copies by Lincoln himself differ in their wording, punctuation, and structure. Of these versions, the Bliss version, written well after the speech as a favor for a friend, is viewed by many as the standard text. Its text differs, however, from the written versions prepared by Lincoln before and after his speech. It is the only version to which Lincoln affixed his signature, and the last he is known to have written.

In "Lincoln at Gettysburg", Garry Wills notes the parallels between Lincoln's speech and Pericles's Funeral Oration during the Peloponnesian War as described by Thucydides. (James McPherson notes this connection in his review of Wills's book. Gore Vidal also draws attention to this link in a BBC documentary about oration.) Pericles' speech, like Lincoln's:
In contrast, writer Adam Gopnik, in "The New Yorker", notes that while Everett's Oration was explicitly neoclassical, referring directly to Marathon and Pericles, "Lincoln's rhetoric is, instead, deliberately Biblical. (It is difficult to find a single obviously classical reference in any of his speeches.) Lincoln had mastered the sound of the King James Bible so completely that he could recast abstract issues of constitutional law in Biblical terms, making the proposition that Texas and New Hampshire should be forever bound by a single post office sound like something right out of Genesis."

Several theories have been advanced by Lincoln scholars to explain the provenance of Lincoln's famous phrase "government of the people, by the people, for the people". Despite many claims, there is no evidence a similar phrase appears in the Prologue to John Wycliffe's 1384 English translation of the Bible.

In a discussion "A more probable origin of a famous Lincoln phrase", in "The American Monthly Review of Reviews", Albert Shaw credits a correspondent with pointing out the writings of William Herndon, Lincoln's law partner, who wrote in the 1888 work "Abraham Lincoln: The True Story of A Great Life" that he had brought to Lincoln some of the sermons of abolitionist minister Theodore Parker, of Massachusetts, and that Lincoln was moved by Parker's use of this idea:

Craig R. Smith, in "Criticism of Political Rhetoric and Disciplinary Integrity", suggested Lincoln's view of the government as expressed in the Gettysburg Address was influenced by the noted speech of Massachusetts Senator Daniel Webster, the "Second Reply to Hayne", in which Webster famously thundered "Liberty and Union, now and forever, one and inseparable!" Specifically, in this speech on January 26, 1830, before the United States Senate, Webster described the federal government as: "made for the people, made by the people, and answerable to the people", foreshadowing Lincoln's "government of the people, by the people, for the people". Webster also noted, "This government, Sir, is the independent offspring of the popular will. It is not the creature of State legislatures; nay, more, if the whole truth must be told, the people brought it into existence, established it, and have hitherto supported it, for the very purpose, amongst others, of imposing certain salutary restraints on State sovereignties."

A source predating these others with which Lincoln was certainly familiar was Chief Justice John Marshall's opinion in "McCulloch v. Maryland" (1819), a case upholding federal authority to create a national bank and to be free from the State's powers to tax. In asserting the superiority of federal power over the states, Chief Justice Marshall stated: "The government of the Union, then (whatever may be the influence of this fact on the case), is, emphatically and truly, a government of the people. In form, and in substance, it emanates from them. Its powers are granted by them, and are to be exercised directly on them, and for their benefit." Lincoln, a lawyer and President engaged in the greatest struggle of federalism, was (more eloquently) echoing the preeminent case that had solidified federal power over the States.

Wills observed Lincoln's usage of the imagery of birth, life, and death in reference to a nation "brought forth", "conceived", and that shall not "perish". Others, including Allen C. Guelzo, the director of Civil War Era studies at Gettysburg College in Pennsylvania, suggested that Lincoln's formulation "four score and seven" was an allusion to the King James Version of the Bible's , in which man's lifespan is given as "threescore years and ten; and if by reason of strength they be fourscore years".

Lincoln was probably influenced by Lajos Kossuth - the formerly governor of Hungary - who gave a speech before the Ohio State Legislature on February 1852: "The spirit of our age is Democracy. All for the people, and all by the people. Nothing about the people without the people - That is Democracy! […]"

Each of the five known manuscript copies of the Gettysburg Address is named for the person who received it from Lincoln. Lincoln gave copies to his private secretaries, John Nicolay and John Hay. Both of these drafts were written around the time of his November 19 address, while the other three copies of the address, the Everett, Bancroft, and Bliss copies, were written by Lincoln for charitable purposes well after November 19. In part because Lincoln provided a title and signed and dated the Bliss copy, it has become the standard text of Lincoln's Gettysburg Address.

Nicolay and Hay were appointed custodians of Lincoln's papers by Lincoln's son Robert Todd Lincoln in 1874. After appearing in facsimile in an article written by John Nicolay in 1894, the Nicolay copy was presumably among the papers passed to Hay by Nicolay's daughter Helen upon Nicolay's death in 1901. Robert Lincoln began a search for the original copy in 1908, which resulted in the discovery of a handwritten copy of the Gettysburg Address among the bound papers of John Hay—a copy now known as the "Hay copy" or "Hay draft".

The Hay draft differed from the version of the Gettysburg Address published by John Nicolay in 1894 in a number of significant ways: it was written on a different type of paper, had a different number of words per line and number of lines, and contained editorial revisions in Lincoln's hand.

Both the Hay and Nicolay copies of the Address are within the Library of Congress, encased in specially designed, temperature-controlled, sealed containers with argon gas in order to protect the documents from oxidation and continued deterioration.

The Nicolay copy is often called the "first draft" because it is believed to be the earliest copy that exists. Scholars disagree over whether the Nicolay copy was actually the reading copy Lincoln held at Gettysburg on November 19. In an 1894 article that included a facsimile of this copy, Nicolay, who had become the custodian of Lincoln's papers, wrote that Lincoln had brought to Gettysburg the first part of the speech written in ink on Executive Mansion stationery, and that he had written the second page in pencil on lined paper before the dedication on November 19. Matching folds are still evident on the two pages, suggesting it could be the copy that eyewitnesses say Lincoln took from his coat pocket and read at the ceremony. Others believe that the delivery text has been lost, because some of the words and phrases of the Nicolay copy do not match contemporary transcriptions of Lincoln's original speech. The words "under God", for example, are missing in this copy from the phrase "that this nation shall have a new birth of freedom  ..." In order for the Nicolay draft to have been the reading copy, either the contemporary transcriptions were inaccurate, or Lincoln would have had to depart from his written text in several instances. This copy of the Gettysburg Address apparently remained in John Nicolay's possession until his death in 1901, when it passed to his friend and colleague John Hay. It used to be on display as part of the American Treasures exhibition of the Library of Congress in Washington, D.C.

The existence of the Hay copy was first announced to the public in 1906, after the search for the "original manuscript" of the Address among the papers of John Hay brought it to light. Significantly, it differs somewhat from the manuscript of the Address described by John Nicolay in his article, and contains numerous omissions and inserts in Lincoln's own hand, including omissions critical to the basic meaning of the sentence, not simply words that would be added by Lincoln to strengthen or clarify their meaning. In this copy, as in the Nicolay copy, the words "under God" are not present.

This version has been described as "the most inexplicable" of the drafts and is sometimes referred to as the "second draft". The "Hay copy" was made either on the morning of the delivery of the Address, or shortly after Lincoln's return to Washington. Those who believe that it was completed on the morning of his address point to the fact that it contains certain phrases that are not in the first draft but are in the reports of the address as delivered and in subsequent copies made by Lincoln. It is probable, they conclude, that, as stated in the explanatory note accompanying the original copies of the first and second drafts in the Library of Congress, Lincoln held this second draft when he delivered the address. Lincoln eventually gave this copy to Hay, whose descendants donated both it and the Nicolay copy to the Library of Congress in 1916.

The Everett copy, also known as the "Everett-Keyes copy", was sent by President Lincoln to Edward Everett in early 1864, at Everett's request. Everett was collecting the speeches at the Gettysburg dedication into one bound volume to sell for the benefit of stricken soldiers at New York's Sanitary Commission Fair. The draft Lincoln sent became the third autograph copy, and is now in the possession of the Illinois State Historical Library in Springfield, Illinois, where it is displayed in the Treasures Gallery of the Abraham Lincoln Presidential Library and Museum.

The Bancroft copy of the Gettysburg Address was written out by President Lincoln in February 1864 at the request of George Bancroft, the famed historian and former Secretary of the Navy, whose comprehensive ten-volume "History of the United States" later led him to be known as the "father of American History". Bancroft planned to include this copy in "Autograph Leaves of Our Country's Authors", which he planned to sell at a Soldiers' and Sailors' Sanitary Fair in Baltimore. As this fourth copy was written on both sides of the paper, it proved unusable for this purpose, and Bancroft was allowed to keep it. This manuscript is the only one accompanied both by a letter from Lincoln transmitting the manuscript and by the original envelope addressed and franked by Lincoln. This copy remained in the Bancroft family for many years, was sold to various dealers and purchased by Nicholas and Marguerite Lilly Noyes, who donated the manuscript to Cornell in 1949. It is now held by the Division of Rare and Manuscript Collections in the Carl A. Kroch Library at Cornell University. It is the only one of the five copies to be privately owned.

Discovering that his fourth written copy could not be used, Lincoln then wrote a fifth draft, which was accepted for the purpose requested. The Bliss copy, named for Colonel Alexander Bliss, Bancroft's stepson and publisher of "Autograph Leaves", is the only draft to which Lincoln affixed his signature. Lincoln is not known to have made any further copies of the Gettysburg Address. Because of the apparent care in its preparation, and in part, because Lincoln provided a title and signed and dated this copy, it has become the standard version of the address and the source for most facsimile reproductions of Lincoln's Gettysburg Address. It is the version that is inscribed on the South wall of the Lincoln Memorial.

This draft is now displayed in the Lincoln Room of the White House, a gift of Oscar B. Cintas, former Cuban Ambassador to the United States. Cintas, a wealthy collector of art and manuscripts, purchased the Bliss copy at a public auction in 1949 for $54,000 ($ as of 2019), at that time the highest price ever paid for a document at public auction. Cintas' properties were claimed by the Castro government after the Cuban Revolution in 1959, but Cintas, who died in 1957, willed the Gettysburg Address to the American people, provided it would be kept at the White House, where it was transferred in 1959.

Garry Wills concluded the Bliss copy "is stylistically preferable to others in one significant way: Lincoln removed 'here' from 'that cause for which they (here) gave  ... ' The seventh 'here' is in all other versions of the speech." Wills noted the fact that Lincoln "was still making such improvements", suggesting Lincoln was more concerned with a perfected text than with an 'original' one.

From November 21, 2008, to January 1, 2009, the Albert H. Small Documents Gallery at the Smithsonian Institution National Museum of American History hosted a limited public viewing of the Bliss copy, with the support of then-First Lady Laura Bush. The Museum also launched an online exhibition and interactive gallery to enable visitors to look more closely at the document.

Another contemporary source of the text is the Associated Press dispatch, transcribed from the shorthand notes taken by reporter Joseph L. Gilbert. It also differs from the drafted text in a number of minor ways.

Eyewitness reports vary as to their view of Lincoln's performance. In 1931, the printed recollections of 87-year-old Mrs. Sarah A. Cooke Myers, who was 19 when she attended the ceremony, suggest a dignified silence followed Lincoln's speech: "I was close to the President and heard all of the Address, but it seemed short. Then there was an impressive silence like our Menallen Friends Meeting. There was no applause when he stopped speaking." According to historian Shelby Foote, after Lincoln's presentation, the applause was delayed, scattered, and "barely polite". In contrast, Pennsylvania Governor Andrew Gregg Curtin maintained, "He pronounced that speech in a voice that all the multitude heard. The crowd was hushed into silence because the President stood before them  ... It was so Impressive! It was the common remark of everybody. Such a speech, as they said it was!" Reinterment of soldiers' remains from field graves into the cemetery, which had begun within months of the battle, was less than half complete on the day of the ceremony.

In an oft-repeated legend, Lincoln is said to have turned to his bodyguard Ward Hill Lamon and remarked that his speech, like a bad plow, "won't scour". According to Garry Wills, this statement has no basis in fact and largely originates from the unreliable recollections of Lamon. In Garry Wills's view, " had done what he wanted to do ".

In a letter to Lincoln written the following day, Everett praised the President for his eloquent and concise speech, saying, "I should be glad if I could flatter myself that I came as near to the central idea of the occasion, in two hours, as you did in two minutes." Lincoln replied that he was glad to know the speech was not a "total failure".

Other public reaction to the speech was divided along partisan lines. The Democratic-leaning "Chicago Times" observed, "The cheek of every American must tingle with shame as he reads the silly, flat and dishwatery utterances of the man who has to be pointed out to intelligent foreigners as the President of the United States." In contrast, the Republican-leaning "The New York Times" was complimentary and printed the speech. In Massachusetts, the "Springfield Republican" also printed the entire speech, calling it "a perfect gem" that was "deep in feeling, compact in thought and expression, and tasteful and elegant in every word and comma". The "Republican" predicted that Lincoln's brief remarks would "repay further study as the model speech". On the sesquicentennial of the address, "The Patriot-News" of Harrisburg, Pennsylvania, formerly the "Patriot & Union", retracted its original reaction ("silly remarks" deserving "the veil of oblivion") stating: "Seven score and ten years ago, the forefathers of this media institution brought forth to its audience a judgment so flawed, so tainted by hubris, so lacking in the perspective history would bring, that it cannot remain unaddressed in our archives.  ... the "Patriot & Union" failed to recognize [the speech's] momentous importance, timeless eloquence, and lasting significance. The "Patriot-News" regrets the error."

Foreign newspapers also criticized Lincoln's remarks. "The Times" of London commented: "The ceremony [at Gettysburg] was rendered ludicrous by some of the luckless sallies of that poor President Lincoln."

Congressman Joseph A. Goulden, then an eighteen-year-old school teacher, was present and heard the speech. He served in the United States Marine Corps during the war, and later had a successful career in insurance in Pennsylvania and New York City before entering Congress as a Democrat. In his later life, Goulden was often asked about the speech, since the passage of time made him one of a dwindling number of individuals who had been present for it. He commented on the event and Lincoln's speech in favorable terms, naming Lincoln's address as one of the inspirations for him to enter military service. Goulden's recollections included remarks to the House of Representatives in 1914.

William R. Rathvon is the only known eyewitness of both Lincoln's arrival at Gettysburg and the address itself to have left an audio recording of his recollections which can be found here . One year before his death in 1939, Rathvon's reminiscences were recorded on February 12, 1938, at the Boston studios of radio station WRUL, including his reading the address, itself, and a 78 RPM record was pressed. The title of the 78 record was "I Heard Lincoln That Day – William R. Rathvon, TR Productions". A copy wound up at National Public Radio (NPR) during a "Quest for Sound" project in 1999. This link depicts the story but it can no longer play it. 

Like most people who came to Gettysburg, the Rathvon family was aware that Lincoln was going to make some remarks. The family went to the town square where the procession was to form to go out to the cemetery that had not been completed yet. At the head of the procession rode Lincoln on a gray horse preceded by a military band that was the first the young boy had ever seen. Rathvon describes Lincoln as so tall and with such long legs that they went almost to the ground; he also mentions the long eloquent speech given by Edward Everett of Massachusetts whom Rathvon accurately described as the "most finished orator of the day". Rathvon then goes on to describe how Lincoln stepped forward and "with a manner serious almost to sadness, gave his brief address". During the delivery, along with some other boys, young Rathvon wiggled his way forward through the crowd until he stood within 15 feet of Mr. Lincoln and looked up into what he described as Lincoln's "serious face". Rathvon recalls candidly that, although he listened "intently to every word the president uttered and heard it clearly", he explains, "boylike, I could not recall any of it afterwards". But he explains that if anyone said anything disparaging about "honest Abe", there would have been a "junior battle of Gettysburg". In the recording Rathvon speaks of Lincoln's speech allegorically "echoing through the hills".

The only known and confirmed photograph of Lincoln at Gettysburg, taken by photographer David Bachrach was identified in the Mathew Brady collection of photographic plates in the National Archives and Records Administration in 1952. While Lincoln's speech was short and may have precluded multiple pictures of him while speaking, he and the other dignitaries sat for hours during the rest of the program. Given the length of Everett's speech and the length of time it took for 19th-century photographers to get "set up" before taking a picture, it is quite plausible that the photographers were ill-prepared for the brevity of Lincoln's remarks.

The words "under God" do not appear in the Nicolay and Hay drafts but are included in the three later copies (Everett, Bancroft, and Bliss). Accordingly, some skeptics maintain that Lincoln did not utter the words "under God" at Gettysburg. However, at least three reporters telegraphed the text of Lincoln's speech on the day the Address was given with the words "under God" included. Historian William E. Barton argues that:

The reporters present included Joseph Gilbert, from the Associated Press; Charles Hale, from the "Boston Advertiser"; John R. Young (who later became the Librarian of Congress), from the "Philadelphia Press"; and reporters from the "Cincinnati Commercial", "New York Tribune", and "The New York Times". Charles Hale "had notebook and pencil in hand, [and] took down the slow-spoken words of the President". "He took down what he declared was the exact language of Lincoln's address, and his declaration was as good as the oath of a court stenographer. His associates confirmed his testimony, which was received, as it deserved to be, at its face value." One explanation is that Lincoln deviated from his prepared text and inserted the phrase when he spoke. Ronald C. White, visiting professor of history at the University of California – Los Angeles and professor of American religious history emeritus at the San Francisco Theological Seminary, wrote in this context of Lincoln's insertion and usage of "under God":

It was an uncharacteristically spontaneous revision for a speaker who did not trust extemporaneous speech. Lincoln had added impromptu words in several earlier speeches, but always offered a subsequent apology for the change. In this instance, he did not. And Lincoln included "under God" in all three copies of the address he prepared at later dates. "Under God" pointed backward and forward: back to "this nation", which drew its breath from both political and religious sources, but also forward to a "new birth". Lincoln had come to see the Civil War as a ritual of purification. The old Union had to die. The old man had to die. Death became a transition to a new Union and a new humanity.

The phrase "under God" was used frequently in works published before 1860, usually with the meaning "with God's help".

Outside the Cemetery and within sight of the crosswalk, a historical marker reads:

Nearby, Nov. 19, 1863, in dedicating the National Cemetery, Abraham Lincoln gave the address which he had written in Washington and revised after his arrival at Gettysburg the evening of November 18.

Directly inside the Taneytown Road entrance are located the Rostrum and the "Lincoln Address Memorial." Neither of these is located within 300 yards of any of the five (or more) claimed locations for the dedicatory platform.

Colonel W. Yates Selleck was a marshal in the parade on Consecration Day and was seated on the platform when Lincoln made the address. Selleck marked a map with the position of the platform and described it as "350 feet almost due north of Soldiers' National Monument, 40 feet from a point in the outer circle of lots where [the] Michigan and New York [burial sections] are separated by a path". A location which approximates this description is 39°49.243′N, 77°13.869′W.

As pointed out in 1973 by retired park historian Frederick Tilberg, the "Selleck Site" is 25 feet lower than the crest of Cemetery Hill, and only the crest presents a panoramic view of the battlefield. A spectacular view from the location of the speech was noted by many eyewitnesses, is consistent with the "Traditional Site" at the Soldiers' National Monument (and other sites on the crest) but is inconsistent with the "Selleck Site."

The "Kentucky Memorial", erected in 1975, is directly adjacent to the Soldiers' National Monument, and states, "Kentucky honors her son, Abraham Lincoln, who delivered his immortal address at the site now marked by the soldiers' monument." With its position at the center of the concentric rings of soldiers' graves and the continuing endorsement of Lincoln's native state the Soldiers' National Monument persists as a credible location for the speech.

Writing a physical description of the layout for the Gettysburg National Cemetery under construction in November 1863, the correspondent from the "Cincinnati Daily Commercial" described the dividing lines between the state grave plots as "the radii of a common center, where a flag pole is now raised, but where it is proposed to erect a national monument". With the inclusion of this quotation Tilberg inadvertently verifies a central principle of future photographic analyses—a flagpole, rather than the speakers' platform, occupied the central point of the soldiers' graves. In fact, the precision of the photo-analyses relies upon the coincidence of position between this temporary flag pole and the future monument.

Confusing to today's tourist, the "Kentucky Memorial" is contradicted by a newer marker which was erected nearby by the Gettysburg National Military Park and locates the speakers' platform inside Evergreen Cemetery. Similarly, outdated National Park Service documents which pinpoint the location at the Soldiers' National Monument have not been systematically revised since the placement of the newer marker. Miscellaneous web pages perpetuate the "Traditional Site."

Based upon photographic analysis, the Gettysburg National Military Park (G.N.M.P.) placed a marker (near ) which states, "The speakers' platform was located in Evergreen Cemetery to your left." The observer of this marker stands facing the fence which separates the two cemeteries (one public and one private).

In 1982, Senior Park Historian Kathleen Georg Harrison first analyzed photographs and proposed a location in Evergreen Cemetery but has not published her analysis. Speaking for Harrison without revealing details, two sources characterize her proposed location as "on or near [the] Brown family vault" in Evergreen Cemetery.

William A. Frassanito, a former military intelligence analyst, documented a comprehensive photographic analysis in 1995, and it associates the location of the platform with the position of specific modern headstones in Evergreen Cemetery. According to Frassanito, the extant graves of Israel Yount (died 1892)(), John Koch (died 1913)(), and George E. Kitzmiller (died 1874)() are among those which occupy the location of the 1863 speaker's stand.

The GNMP marker, Wills' interpretation of Harrison's analysis, and the Frassanito analysis concur that the platform was located in private Evergreen Cemetery, rather than public Soldiers' National Cemetery. The National Park Service's "National Cemetery Walking Tour" brochure is one NPS document which agrees:
The Soldiers' National Monument, long misidentified as the spot from which Lincoln spoke, honors the fallen soldiers. [The location of the speech] was actually on the crown of this hill, a short distance on the other side of the iron fence and inside the Evergreen Cemetery, where President Lincoln delivered the Gettysburg Address to a crowd of some 15,000 people.

While the GNMP marker is unspecific, providing only "to your left", the locations determined by the Harrison/Wills analysis and the Frassanito analysis differ by 40 yards. Frassanito has documented 1) his own conclusion, 2) his own
methods and 3) a refutation of the Harrison site, but neither the GNMP nor Harrison has provided any documentation. Each of the three points to a location in Evergreen Cemetery, as do modern NPS publications.

Although Lincoln dedicated the Gettysburg National Cemetery, the monument at the Cemetery's center actually has nothing to do with Lincoln or his famous speech. Intended to symbolize Columbia paying tribute to her fallen sons, its appreciation has been commandeered by the thirst for a tidy home for the speech. Freeing the Cemetery and Monument to serve their original purpose, honoring of Union departed, is as unlikely as a resolution to the location controversy and the erection of a public monument to the speech in the exclusively private Evergreen Cemetery.

The importance of the Gettysburg Address in the history of the United States is underscored by its enduring presence in American culture. In addition to its prominent place carved into a stone cella on the south wall of the Lincoln Memorial in Washington, D.C., the Gettysburg Address is frequently referred to in works of popular culture, with the implicit expectation that contemporary audiences will be familiar with Lincoln's words.

In the many generations that have passed since the Address, it has remained among the most famous speeches in American history, and is often taught in classes about history or civics. Lincoln's Gettysburg Address is itself referenced in another of those famed orations, Martin Luther King Jr.'s "I Have a Dream" speech. Standing on the steps of the Lincoln Memorial in August 1963, King began with a reference, by the style of his opening phrase, to President Lincoln and his enduring words: "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice."

Phrases from the Address are often used or referenced in other works. The current Constitution of France states that the principle of the French Republic is ""gouvernement du peuple, par le peuple et pour le peuple" ("government of the people, by the people, and for the people"), a literal translation of Lincoln's words. Sun Yat-Sen's "Three Principles of the People" as well as the preamble for the 1947 Constitution of Japan were also inspired from that phrase. The aircraft carrier has as its ship's motto the phrase "shall not perish".

U.S. Senator Charles Sumner of Massachusetts wrote of the address and its enduring presence in American culture after Lincoln's assassination in April 1865: "That speech, uttered at the field of Gettysburg  ... and now sanctified by the martyrdom of its author, is a monumental act. In the modesty of his nature he said 'the world will little note, nor long remember what we say here; but it can never forget what they did here.' He was mistaken. The world at once noted what he said, and will never cease to remember it."

U.S. President John F. Kennedy stated in July 1963 about the battle and Lincoln's speech: "Five score years ago the ground on which we here stand shuddered under the clash of arms and was consecrated for all time by the blood of American manhood. Abraham Lincoln, in dedicating this great battlefield, has expressed, in words too eloquent for paraphrase or summary, why this sacrifice was necessary." Kennedy was himself assassinated three days after the Gettysburg Address centennial.

In 2015, the Abraham Lincoln Presidential Library Foundation compiled "Gettysburg Replies: The World Responds to Abraham Lincoln's Gettysburg Address". The work challenges leaders to craft 272 word responses to celebrate Lincoln, the Gettysburg Address, or a related topic.
One of the replies was by astrophysicist Neil deGrasse Tyson in which he made the point that one of Lincoln's greatest legacies was establishing, in the same year of the Gettysburg Address, the National Academy of Sciences, which had the longterm effect of "setting our Nation on a course of scientifically enlightened governance, without which we all may perish from this Earth".

A common American myth about the Gettysburg Address is that Lincoln quickly wrote the speech on the back of an envelope. This widely held misunderstanding may have originated with a popular book, "The Perfect Tribute", by Mary Raymond Shipman Andrews (1906), which was assigned reading for generations of schoolchildren, sold 600,000 copies when published as a standalone volume, and was twice adapted for film.

Other lesser-known claims include Harriet Beecher Stowe's assertion that Lincoln had composed the address "in only a few moments," and that of industrialist Andrew Carnegie, who claimed to have personally supplied Lincoln with a pen.





</doc>
<doc id="12385" url="https://en.wikipedia.org/wiki?curid=12385" title="Genetic code">
Genetic code

The genetic code is the set of rules used by living cells to translate information encoded within genetic material (DNA or mRNA sequences) into proteins. Translation is accomplished by the ribosome, which links amino acids in an order specified by messenger RNA (mRNA), using transfer RNA (tRNA) molecules to carry amino acids and to read the mRNA three nucleotides at a time. The genetic code is highly similar among all organisms and can be expressed in a simple table with 64 entries.

The code defines how sequences of nucleotide triplets, called "codons", specify which amino acid will be added next during protein synthesis. With some exceptions, a three-nucleotide codon in a nucleic acid sequence specifies a single amino acid. The vast majority of genes are encoded with a single scheme (see the RNA codon table). That scheme is often referred to as the canonical or standard genetic code, or simply "the" genetic code, though variant codes (such as in human mitochondria) exist.

While the "genetic code" determines a protein's amino acid sequence, other genomic regions determine when and where these proteins are produced according to various "gene regulatory codes".

Efforts to understand how proteins are encoded began after DNA's structure was discovered in 1953. George Gamow postulated that sets of three bases must be employed to encode the 20 standard amino acids used by living cells to build proteins, which would allow a maximum of 64 amino acids.

The Crick, Brenner, Barnett and Watts-Tobin experiment first demonstrated that codons consist of three DNA bases. Marshall Nirenberg and Heinrich J. Matthaei were the first to reveal the nature of a codon in 1961.

They used a cell-free system to translate a poly-uracil RNA sequence (i.e., UUUUU...) and discovered that the polypeptide that they had synthesized consisted of only the amino acid phenylalanine. They thereby deduced that the codon UUU specified the amino acid phenylalanine.

This was followed by experiments in Severo Ochoa's laboratory that demonstrated that the poly-adenine RNA sequence (AAAAA...) coded for the polypeptide poly-lysine and that the poly-cytosine RNA sequence (CCCCC...) coded for the polypeptide poly-proline. Therefore, the codon AAA specified the amino acid lysine, and the codon CCC specified the amino acid proline. Using various copolymers most of the remaining codons were then determined.

Subsequent work by Har Gobind Khorana identified the rest of the genetic code. Shortly thereafter, Robert W. Holley determined the structure of transfer RNA (tRNA), the adapter molecule that facilitates the process of translating RNA into protein. This work was based upon Ochoa's earlier studies, yielding the latter the Nobel Prize in Physiology or Medicine in 1959 for work on the enzymology of RNA synthesis.

Extending this work, Nirenberg and Philip Leder revealed the code's triplet nature and deciphered its codons. In these experiments, various combinations of mRNA were passed through a filter that contained ribosomes, the components of cells that translate RNA into protein. Unique triplets promoted the binding of specific tRNAs to the ribosome. Leder and Nirenberg were able to determine the sequences of 54 out of 64 codons in their experiments. Khorana, Holley and Nirenberg received the 1968 Nobel for their work.

The three stop codons were named by discoverers Richard Epstein and Charles Steinberg. "Amber" was named after their friend Harris Bernstein, whose last name means "amber" in German. The other two stop codons were named "ochre" and "opal" in order to keep the "color names" theme.

In a broad academic audience, the concept of the evolution of the genetic code from the original and ambiguous genetic code to a well-defined ("frozen") code with the repertoire of 20 (+2) canonical amino acids is widely accepted.
However, there are different opinions, concepts, approaches and ideas, which is the best way to change it experimentally. Even models are proposed that predict "entry points" for synthetic amino acid invasion of the genetic code.

Since 2001, 40 non-natural amino acids have been added into protein by creating a unique codon (recoding) and a corresponding transfer-RNA:aminoacyl – tRNA-synthetase pair to encode it with diverse physicochemical and biological properties in order to be used as a tool to exploring protein structure and function or to create novel or enhanced proteins.
H. Murakami and M. Sisido extended some codons to have four and five bases. Steven A. Benner constructed a functional 65th ("in vivo") codon.

In 2015 N. Budisa, D. Söll and co-workers reported the full substitution of all 20,899 tryptophan residues (UGG codons) with unnatural thienopyrrole-alanine in the genetic code of the bacterium "Escherichia coli".

In 2016 the first stable semisynthetic organism was created. It was a (single cell) bacterium with two synthetic bases (called X and Y). The bases survived cell division.

In 2017, researchers in South Korea reported that they had engineered a mouse with an extended genetic code that can produce proteins with unnatural amino acids.

In May 2019, researchers, in a milestone effort, reported the creation of a new synthetic (possibly artificial) form of viable life, a variant of the bacteria "Escherichia coli", by reducing the natural number of 64 codons in the bacterial genome to 59 codons instead, in order to encode 20 amino acids.

A reading frame is defined by the initial triplet of nucleotides from which translation starts. It sets the frame for a run of successive, non-overlapping codons, which is known as an "open reading frame" (ORF). For example, the string 5'-AAATGAACG-3' (see figure), if read from the first position, contains the codons AAA, TGA, and ACG ; if read from the second position, it contains the codons AAT and GAA ; and if read from the third position, it contains the codons ATG and AAC. Every sequence can, thus, be read in its 5' → 3' direction in three reading frames, each producing a possibly distinct amino acid sequence: in the given example, Lys (K)-Trp (W)-Thr (T), Asn (N)-Glu (E), or Met (M)-Asn (N), respectively (when translating with the vertebrate mitochondrial code). When DNA is double-stranded, six possible reading frames are defined, three in the forward orientation on one strand and three reverse on the opposite strand. Protein-coding frames are defined by a start codon, usually the first AUG (ATG) codon in the RNA (DNA) sequence.

In eukaryotes, ORFs in exons are often interrupted by introns.

Translation starts with a chain-initiation codon or start codon. The start codon alone is not sufficient to begin the process. Nearby sequences such as the Shine-Dalgarno sequence in "E. coli" and initiation factors are also required to start translation. The most common start codon is AUG, which is read as methionine or, in bacteria, as formylmethionine. Alternative start codons depending on the organism include "GUG" or "UUG"; these codons normally represent valine and leucine, respectively, but as start codons they are translated as methionine or formylmethionine.

The three stop codons have names: UAG is "amber", UGA is "opal" (sometimes also called "umber"), and UAA is "ochre". Stop codons are also called "termination" or "nonsense" codons. They signal release of the nascent polypeptide from the ribosome because no cognate tRNA has anticodons complementary to these stop signals, allowing a release factor to bind to the ribosome instead.

During the process of DNA replication, errors occasionally occur in the polymerization of the second strand. These errors, mutations, can affect an organism's phenotype, especially if they occur within the protein coding sequence of a gene. Error rates are typically 1 error in every 10–100 million bases—due to the "proofreading" ability of DNA polymerases.

Missense mutations and nonsense mutations are examples of point mutations that can cause genetic diseases such as sickle-cell disease and thalassemia respectively. Clinically important missense mutations generally change the properties of the coded amino acid residue among basic, acidic, polar or non-polar states, whereas nonsense mutations result in a stop codon.

Mutations that disrupt the reading frame sequence by indels (insertions or deletions) of a non-multiple of 3 nucleotide bases are known as frameshift mutations. These mutations usually result in a completely different translation from the original, and likely cause a stop codon to be read, which truncates the protein. These mutations may impair the protein's function and are thus rare in "in vivo" protein-coding sequences. One reason inheritance of frameshift mutations is rare is that, if the protein being translated is essential for growth under the selective pressures the organism faces, absence of a functional protein may cause death before the organism becomes viable. Frameshift mutations may result in severe genetic diseases such as Tay–Sachs disease.

Although most mutations that change protein sequences are harmful or neutral, some mutations have benefits. These mutations may enable the mutant organism to withstand particular environmental stresses better than wild type organisms, or reproduce more quickly. In these cases a mutation will tend to become more common in a population through natural selection. Viruses that use RNA as their genetic material have rapid mutation rates, which can be an advantage, since these viruses thereby evolve rapidly, and thus evade the immune system defensive responses. In large populations of asexually reproducing organisms, for example, "E. coli", multiple beneficial mutations may co-occur. This phenomenon is called clonal interference and causes competition among the mutations.

Degeneracy is the redundancy of the genetic code. This term was given by Bernfield and Nirenberg. The genetic code has redundancy but no ambiguity (see the codon tables below for the full correlation). For example, although codons GAA and GAG both specify glutamic acid (redundancy), neither specifies another amino acid (no ambiguity). The codons encoding one amino acid may differ in any of their three positions. For example, the amino acid leucine is specified by YUR or CUN (UUA, UUG, CUU, CUC, CUA, or CUG) codons (difference in the first or third position indicated using IUPAC notation), while the amino acid serine is specified by UCN or AGY (UCA, UCG, UCC, UCU, AGU, or AGC) codons (difference in the first, second, or third position). A practical consequence of redundancy is that errors in the third position of the triplet codon cause only a silent mutation or an error that would not affect the protein because the hydrophilicity or hydrophobicity is maintained by equivalent substitution of amino acids; for example, a codon of NUN (where N = any nucleotide) tends to code for hydrophobic amino acids. NCN yields amino acid residues that are small in size and moderate in hydropathy; NAN encodes average size hydrophilic residues. The genetic code is so well-structured for hydropathy that a mathematical analysis (Singular Value Decomposition) of 12 variables (4 nucleotides x 3 positions) yields a remarkable correlation (C = 0.95) for predicting the hydropathy of the encoded amino acid directly from the triplet nucleotide sequence, "without translation." Note in the table, below, eight amino acids are not affected at all by mutations at the third position of the codon, whereas in the figure above, a mutation at the second position is likely to cause a radical change in the physicochemical properties of the encoded amino acid.
Nevertheless, changes in the first position of the codons are more important than changes in the second position on a global scale. The reason may be that charge reversal (from a positive to a negative charge or vice versa) can only occur upon mutations in the first position, but never upon changes in the second position of a codon. Such charge reversal may have dramatic consequences for the structure or function of a protein. This aspect may have been largely underestimated by previous studies. 
The frequency of codons, also known as codon usage bias, can vary from species to species with functional implications for the control of translation. The following codon usage table is for the human genome.

The DNA codon table is essentially identical to that for RNA, but with U replaced by T.

In some proteins, non-standard amino acids are substituted for standard stop codons, depending on associated signal sequences in the messenger RNA. For example, UGA can code for selenocysteine and UAG can code for pyrrolysine. Selenocysteine became to be seen as the 21st amino acid, and pyrrolysine as the 22nd. Unlike selenocysteine, pyrrolysine-encoded UAG is translated with the participation of a dedicated aminoacyl-tRNA synthetase. Both selenocysteine and pyrrolysine may be present in the same organism. Although the genetic code is normally fixed in an organism, the achaeal prokaryote "Acetohalobium arabaticum" can expand its genetic code from 20 to 21 amino acids (by including pyrrolysine) under different conditions of growth.

Variations on the standard code were predicted in the 1970s. The first was discovered in 1979, by researchers studying human mitochondrial genes. Many slight variants were discovered thereafter, including various alternative mitochondrial codes. These minor variants for example involve translation of the codon UGA as tryptophan in "Mycoplasma" species, and translation of CUG as a serine rather than leucine in yeasts of the "CTG clade" (such as "Candida albicans"). Because viruses must use the same genetic code as their hosts, modifications to the standard genetic code could interfere with viral protein synthesis or functioning. However, viruses such as totiviruses have adapted to the host's genetic code modification. In bacteria and archaea, GUG and UUG are common start codons. In rare cases, certain proteins may use alternative start codons.
Surprisingly, variations in the interpretation of the genetic code exist also in human nuclear-encoded genes: In 2016, researchers studying the translation of malate dehydrogenase found that in about 4% of the mRNAs encoding this enzyme the stop codon is naturally used to encode the amino acids tryptophan and arginine. This type of recoding is induced by a high-readthrough stop codon context and it is referred to as "functional translational readthrough".

Variant genetic codes used by an organism can be inferred by identifying highly conserved genes encoded in that genome, and comparing its codon usage to the amino acids in homologous proteins of other organisms. For example, the program FACIL infers a genetic code by searching which amino acids in homologous protein domains are most often aligned to every codon. The resulting amino acid probabilities for each codon are displayed in a genetic code logo, that also shows the support for a stop codon.

Despite these differences, all known naturally occurring codes are very similar. The coding mechanism is the same for all organisms: three-base codons, tRNA, ribosomes, single direction reading and translating single codons into single amino acids.

The genetic code is a key part of the story of life, according to which self-replicating RNA molecules preceded life as we know it. The main hypothesis for life's origin is the RNA world hypothesis. Any model for the emergence of genetic code is intimately related to a model of the transfer from ribozymes (RNA enzymes) to proteins as the principal enzymes in cells. In line with the RNA world hypothesis, transfer RNA molecules appear to have evolved before modern aminoacyl-tRNA synthetases, so the latter cannot be part of the explanation of its patterns.

A hypothetical randomly evolved genetic code further motivates a biochemical or evolutionary model for its origin. If amino acids were randomly assigned to triplet codons, there would be 1.5 × 10 possible genetic codes. This number is found by calculating the number of ways that 21 items (20 amino acids plus one stop) can be placed in 64 bins, wherein each item is used at least once. However, the distribution of codon assignments in the genetic code is nonrandom. In particular, the genetic code clusters certain amino acid assignments.

Amino acids that share the same biosynthetic pathway tend to have the same first base in their codons. This could be an evolutionary relic of an early, simpler genetic code with fewer amino acids that later evolved to code a larger set of amino acids. It could also reflect steric and chemical properties that had another effect on the codon during its evolution. Amino acids with similar physical properties also tend to have similar codons, reducing the problems caused by point mutations and mistranslations.

Given the non-random genetic triplet coding scheme, a tenable hypothesis for the origin of genetic code could address multiple aspects of the codon table, such as absence of codons for D-amino acids, secondary codon patterns for some amino acids, confinement of synonymous positions to third position, the small set of only 20 amino acids (instead of a number approaching 64), and the relation of stop codon patterns to amino acid coding patterns.

Three main hypotheses address the origin of the genetic code. Many models belong to one of them or to a hybrid:


Hypotheses have addressed a variety of scenarios:




</doc>
<doc id="12386" url="https://en.wikipedia.org/wiki?curid=12386" title="Golden ratio">
Golden ratio

In mathematics, two quantities are in the golden ratio if their ratio is the same as the ratio of their sum to the larger of the two quantities. The figure on the right illustrates the geometric relationship. Expressed algebraically, for quantities "a" and "b" with "a" > "b" > 0,

where the Greek letter phi (formula_2 or formula_3) represents the golden ratio.{2}</math>. The sum of the two solutions is one, and the product of the two solutions is negative one.}} It is an irrational number that is a solution to the quadratic equation formula_4, with a value of:

The golden ratio is also called the golden mean or golden section (Latin: "sectio aurea"). Other names include extreme and mean ratio, medial section, divine proportion, divine section (Latin: "sectio divina"), golden proportion, golden cut, and golden number.

Mathematicians since Euclid have studied the properties of the golden ratio, including its appearance in the dimensions of a regular pentagon and in a golden rectangle, which may be cut into a square and a smaller rectangle with the same aspect ratio. The golden ratio has also been used to analyze the proportions of natural objects as well as man-made systems such as financial markets, in some cases based on dubious fits to data. The golden ratio appears in some patterns in nature, including the spiral arrangement of leaves and other plant parts.

Some twentieth-century artists and architects, including Le Corbusier and Salvador Dalí, have proportioned their works to approximate the golden ratio—especially in the form of the golden rectangle, in which the ratio of the longer side to the shorter is the golden ratio—believing this proportion to be aesthetically pleasing.

Two quantities "a" and "b" are said to be in the "golden ratio" if

One method for finding the value of is to start with the left fraction. Through simplifying the fraction and substituting in b/a = 1/,

Therefore,

Multiplying by gives

which can be rearranged to

Using the quadratic formula, two solutions are obtained:

Because is the ratio between positive quantities, is necessarily positive:

The golden ratio has been claimed to have held a special fascination for at least 2,400 years, although without reliable evidence. According to Mario Livio:

Ancient Greek mathematicians first studied what we now call the golden ratio because of its frequent appearance in geometry; the division of a line into "extreme and mean ratio" (the golden section) is important in the geometry of regular pentagrams and pentagons. According to one story, 5th-century BC mathematician Hippasus discovered that the golden ratio was neither a whole number nor a fraction (an irrational number), surprising Pythagoreans. Euclid's "Elements" () provides several propositions and their proofs employing the golden ratio and contains the first known definition:

The golden ratio was studied peripherally over the next millennium. Abu Kamil (c. 850–930) employed it in his geometric calculations of pentagons and decagons; his writings influenced that of Fibonacci (Leonardo of Pisa) (c. 1170–1250), who used the ratio in related geometry problems, though never connected it to the series of numbers named after him. Luca Pacioli named his book "Divina proportione" (1509) after the ratio and explored its properties including its appearance in some of the Platonic solids. Leonardo da Vinci, who illustrated the aforementioned book, called the ratio the "sectio aurea" ('golden section'). 16th-century mathematicians such as Rafael Bombelli solved geometric problems using the ratio.

German mathematician Simon Jacob (d. 1564) noted that consecutive Fibonacci numbers converge to the golden ratio; this was rediscovered by Johannes Kepler in 1608. The first known decimal approximation of the (inverse) golden ratio was stated as "about 0.6180340" in 1597 by Michael Maestlin of the University of Tübingen in a letter to Kepler, his former student. The same year, Kepler wrote to Maestlin of the Kepler triangle, which combines the golden ratio with the Pythagorean theorem. Kepler said of these:

18th-century mathematicians Abraham de Moivre, Daniel Bernoulli, and Leonhard Euler used a golden ratio-based formula which finds the value of a Fibonacci number based on its placement in the sequence; in 1843 this was rediscovered by Jacques Philippe Marie Binet, for whom it was named "Binet's formula". Martin Ohm first used the German term "goldener Schnitt" ('golden section') to describe the ratio in 1835. James Sully used the equivalent English term in 1875.

By 1910, mathematician Mark Barr began using the Greek letter Phi (φ) as a symbol for the golden ratio. It has also been represented by tau (τ), the first letter of the ancient Greek τομή ('cut' or 'section').

In 1974, Roger Penrose discovered the Penrose tiling, a pattern that is related to the golden ratio both in the ratio of areas of its two rhombic tiles and in their relative frequency within the pattern. This led to Dan Shechtman's early 1980s discovery of quasicrystals, some of which exhibit icosahedral symmetry.

A 2004 geometrical analysis of earlier research into the Great Mosque of Kairouan (670) reveals a consistent application of the golden ratio throughout the design. They found ratios close to the golden ratio in the overall layout and in the dimensions of the prayer space, the court, and the minaret. However, the areas with ratios close to the golden ratio were not part of the original plan, and were likely added in a reconstruction.

It has been speculated that the golden ratio was used by the designers of the Naqsh-e Jahan Square (1629) and the adjacent Lotfollah Mosque.

The Swiss architect Le Corbusier, famous for his contributions to the modern international style, centered his design philosophy on systems of harmony and proportion. Le Corbusier's faith in the mathematical order of the universe was closely bound to the golden ratio and the Fibonacci series, which he described as "rhythms apparent to the eye and clear in their relations with one another. And these rhythms are at the very root of human activities. They resound in man by an organic inevitability, the same fine inevitability which causes the tracing out of the Golden Section by children, old men, savages and the learned."

Le Corbusier explicitly used the golden ratio in his Modulor system for the scale of architectural proportion. He saw this system as a continuation of the long tradition of Vitruvius, Leonardo da Vinci's "Vitruvian Man", the work of Leon Battista Alberti, and others who used the proportions of the human body to improve the appearance and function of architecture. In addition to the golden ratio, Le Corbusier based the system on human measurements, Fibonacci numbers, and the double unit. He took suggestion of the golden ratio in human proportions to an extreme: he sectioned his model human body's height at the navel with the two sections in golden ratio, then subdivided those sections in golden ratio at the knees and throat; he used these golden ratio proportions in the Modulor system. Le Corbusier's 1927 Villa Stein in Garches exemplified the Modulor system's application. The villa's rectangular ground plan, elevation, and inner structure closely approximate golden rectangles.

Another Swiss architect, Mario Botta, bases many of his designs on geometric figures. Several private houses he designed in Switzerland are composed of squares and circles, cubes and cylinders. In a house he designed in Origlio, the golden ratio is the proportion between the central section and the side sections of the house.

"Divina proportione" ("Divine proportion"), a three-volume work by Luca Pacioli, was published in 1509. Pacioli, a Franciscan friar, was known mostly as a mathematician, but he was also trained and keenly interested in art. "Divina proportione" explored the mathematics of the golden ratio. Though it is often said that Pacioli advocated the golden ratio's application to yield pleasing, harmonious proportions, Livio points out that the interpretation has been traced to an error in 1799, and that Pacioli actually advocated the Vitruvian system of rational proportions. Pacioli also saw Catholic religious significance in the ratio, which led to his work's title.

Leonardo da Vinci's illustrations of polyhedra in "Divina proportione" have led some to speculate that he incorporated the golden ratio in his paintings. But the suggestion that his "Mona Lisa", for example, employs golden ratio proportions, is not supported by Leonardo's own writings. Similarly, although the "Vitruvian Man" is often shown in connection with the golden ratio, the proportions of the figure do not actually match it, and the text only mentions whole number ratios.

Salvador Dalí, influenced by the works of Matila Ghyka, explicitly used the golden ratio in his masterpiece, "The Sacrament of the Last Supper". The dimensions of the canvas are a golden rectangle. A huge dodecahedron, in perspective so that edges appear in golden ratio to one another, is suspended above and behind Jesus and dominates the composition.

A statistical study on 565 works of art of different great painters, performed in 1999, found that these artists had not used the golden ratio in the size of their canvases. The study concluded that the average ratio of the two sides of the paintings studied is 1.34, with averages for individual artists ranging from 1.04 (Goya) to 1.46 (Bellini). On the other hand, Pablo Tosto listed over 350 works by well-known artists, including more than 100 which have canvasses with golden rectangle and root-5 proportions, and others with proportions like root-2, 3, 4, and 6.
According to Jan Tschichold,

There was a time when deviations from the truly beautiful page proportions 2:3, 1:√3, and the Golden Section were rare. Many books produced between 1550 and 1770 show these proportions exactly, to within half a millimeter.

According to some sources, the golden ratio is used in everyday design, for example in the proportions of playing cards, postcards, posters, light switch plates, and widescreen televisions.

Ernő Lendvai analyzes Béla Bartók's works as being based on two opposing systems, that of the golden ratio and the acoustic scale, though other music scholars reject that analysis. French composer Erik Satie used the golden ratio in several of his pieces, including "Sonneries de la Rose+Croix". The golden ratio is also apparent in the organization of the sections in the music of Debussy's "Reflets dans l'eau (Reflections in Water)", from "Images" (1st series, 1905), in which "the sequence of keys is marked out by the intervals 34, 21, 13 and 8, and the main climax sits at the phi position".

The musicologist Roy Howat has observed that the formal boundaries of Debussy's "La Mer" correspond exactly to the golden section. Trezise finds the intrinsic evidence "remarkable", but cautions that no written or reported evidence suggests that Debussy consciously sought such proportions.

Pearl Drums positions the air vents on its Masters Premium models based on the golden ratio. The company claims that this arrangement improves bass response and has applied for a patent on this innovation.

Though Heinz Bohlen proposed the non-octave-repeating 833 cents scale based on combination tones, the tuning features relations based on the golden ratio. As a musical interval the ratio 1.618... is 833.090... cents ().

Johannes Kepler wrote that "the image of man and woman stems from the divine proportion. In my opinion, the propagation of plants and the progenitive acts of animals are in the same ratio".

Adolf Zeising, whose main interests were mathematics and philosophy, found the golden ratio expressed in the arrangement of parts such as leaves and branches along the stems of plants and of veins in leaves. He extended his research to the skeletons of animals and the branchings of their veins and nerves, to the proportions of chemical compounds and the geometry of crystals, even to the use of proportion in artistic endeavors. In these patterns in nature he saw the golden ratio operating as a universal law. In connection with his scheme for golden-ratio-based human body proportions, Zeising wrote in 1854 of a universal law "in which is contained the ground-principle of all formative striving for beauty and completeness in the realms of both nature and art, and which permeates, as a paramount spiritual ideal, all structures, forms and proportions, whether cosmic or individual, organic or inorganic, acoustic or optical; which finds its fullest realization, however, in the human form."

In 2010, the journal "Science" reported that the golden ratio is present at the atomic scale in the magnetic resonance of spins in cobalt niobate crystals.

However, some have argued that many apparent manifestations of the golden ratio in nature, especially in regard to animal dimensions, are fictitious.

The golden ratio is key to the golden-section search.

The golden ratio is an irrational number. Below are two short proofs of irrationality:

Recall that:

If we call the whole "n" and the longer part "m", then the second statement above becomes

or, algebraically

To say that the golden ratio is rational means that is a fraction "n"/"m" where "n" and "m" are integers. We may take "n"/"m" to be in lowest terms and "n" and "m" to be positive. But if "n"/"m" is in lowest terms, then the identity labeled (*) above says "m"/("n" − "m") is in still lower terms. That is a contradiction that follows from the assumption that is rational.

Another short proof—perhaps more commonly known—of the irrationality of the golden ratio makes use of the closure of rational numbers under addition and multiplication. If formula_15 is rational, then formula_16 is also rational, which is a contradiction if it is already known that the square root of a non-square natural number is irrational.

The golden ratio is also an algebraic number and even an algebraic integer. It has minimal polynomial

Having degree 2, this polynomial actually has two roots, the other being the golden ratio conjugate.

The conjugate root to the minimal polynomial x − x − 1 is

The absolute value of this quantity (≈ 0.618) corresponds to the length ratio taken in reverse order (shorter segment length over longer segment length, "b/a"), and is sometimes referred to as the "golden ratio conjugate". It is denoted here by the capital Phi (formula_19):

Alternatively, formula_19 can be expressed as

This illustrates the unique property of the golden ratio among positive numbers, that

or its inverse:

This means 0.61803...:1 = 1:1.61803...

The formula = 1 + 1/ can be expanded recursively to obtain a continued fraction for the golden ratio:

and its reciprocal:

The convergents of these continued fractions (1/1, 2/1, 3/2, 5/3, 8/5, 13/8, ..., or 1/1, 1/2, 2/3, 3/5, 5/8, 8/13, ...) are ratios of successive Fibonacci numbers.

The equation = 1 + likewise produces the continued square root, or infinite surd, form:

An infinite series can be derived to express "φ":

Also:

These correspond to the fact that the length of the diagonal of a regular pentagon is times the length of its side, and similar relations in a pentagram.

The number turns up frequently in geometry, particularly in figures with pentagonal symmetry.
The length of a regular pentagon's diagonal is times its side.
The vertices of a regular icosahedron are those of three mutually orthogonal golden rectangles.

There is no known general algorithm to arrange a given number of nodes evenly on a sphere, for any of several definitions of even distribution (see, for example, "Thomson problem"). However, a useful approximation results from dividing the sphere into parallel bands of equal surface area and placing one node in each band at longitudes spaced by a golden section of the circle, i.e. 360°/ ≅ 222.5°. This method was used to arrange the 1500 mirrors of the student-participatory satellite Starshine-3.

Application examples you can see in the articles Pentagon with a given side length, Decagon with given circumcircle and Decagon with a given side length.

Both the above displayed different algorithms produce geometric constructions that determine two aligned line segments where the ratio of the longer to the shorter one is the golden ratio.
The golden triangle can be characterized as an isosceles triangle ABC with the property that bisecting the angle C produces a new triangle CXB which is a similar triangle to the original.

If angle BCX = α, then XCA = α because of the bisection, and CAB = α because of the similar triangles; ABC = 2α from the original isosceles symmetry, and BXC = 2α by similarity. The angles in a triangle add up to 180°, so 5α = 180, giving α = 36°. So the angles of the golden triangle are thus 36°-72°-72°. The angles of the remaining obtuse isosceles triangle AXC (sometimes called the golden gnomon) are 36°-36°-108°.

Suppose XB has length 1, and we call BC length . Because of the isosceles triangles XC=XA and BC=XC, so these are also length φ. Length AC = AB, therefore equals  + 1. But triangle ABC is similar to triangle CXB, so AC/BC = BC/BX, AC/ = φ/1, and so AC also equals . Thus = φ + 1, confirming that is indeed the golden ratio.

Similarly, the ratio of the area of the larger triangle AXC to the smaller CXB is equal to , while the inverse ratio is φ − 1.

In a regular pentagon the ratio of a diagonal to a side is the golden ratio, while intersecting diagonals section each other in the golden ratio.

George Odom has given a remarkably simple construction for involving an equilateral triangle: if an equilateral triangle is inscribed in a circle and the line segment joining the midpoints of two sides is produced to intersect the circle in either of two points, then these three points are in golden proportion. This result is a straightforward consequence of the intersecting chords theorem and can be used to construct a regular pentagon, a construction that attracted the attention of the noted Canadian geometer H. S. M. Coxeter who published it in Odom's name as a diagram in the "American Mathematical Monthly" accompanied by the single word "Behold!" 

The golden ratio plays an important role in the geometry of pentagrams. Each intersection of edges sections other edges in the golden ratio. Also, the ratio of the length of the shorter segment to the segment bounded by the two intersecting edges (a side of the pentagon in the pentagram's center) is , as the four-color illustration shows.

The pentagram includes ten isosceles triangles: five acute and five obtuse isosceles triangles. In all of them, the ratio of the longer side to the shorter side is . The acute triangles are golden triangles. The obtuse isosceles triangles are golden gnomons.

The golden ratio properties of a regular pentagon can be confirmed by applying Ptolemy's theorem to the quadrilateral formed by removing one of its vertices. If the quadrilateral's long edge and diagonals are "b", and short edges are "a", then Ptolemy's theorem gives "b" = "a" + "ab" which yields

Consider a triangle with sides of lengths "a", "b", and "c" in decreasing order. Define the "scalenity" of the triangle to be the smaller of the two ratios "a"/"b" and "b"/"c". The scalenity is always less than and can be made as close as desired to .

If the side lengths of a triangle form a geometric progression and are in the ratio 1 : "r" : "r", where "r" is the common ratio, then "r" must lie in the range −1 < "r" < , which is a consequence of the triangle inequality (the sum of any two sides of a triangle must be strictly bigger than the length of the third side). If "r" = then the shorter two sides are 1 and but their sum is , thus "r" < . A similar calculation shows that "r" > −1. A triangle whose sides are in the ratio 1 : : is a right triangle (because 1 + = ) known as a Kepler triangle.

A golden rhombus is a rhombus whose diagonals are in the golden ratio. The rhombic triacontahedron is a convex polytope that has a very special property: all of its faces are golden rhombi. In the rhombic triacontahedron the dihedral angle between any two adjacent rhombi is 144°, which is twice the isosceles angle of a golden triangle and four times its most acute angle.

The mathematics of the golden ratio and of the Fibonacci sequence are intimately interconnected. The Fibonacci sequence is:

A closed-form expression for the Fibonacci sequence involves the golden ratio:

The golden ratio is the limit of the ratios of successive terms of the Fibonacci sequence (or any Fibonacci-like sequence), as shown by Kepler:

In other words, if a Fibonacci number is divided by its immediate predecessor in the sequence, the quotient approximates ; e.g., 987/610  1.6180327868852. These approximations are alternately lower and higher than , and converge to as the Fibonacci numbers increase, and:

More generally:

where above, the ratios of consecutive terms of the Fibonacci sequence, is a case when formula_38

Furthermore, the successive powers of obey the Fibonacci recurrence:

This identity allows any polynomial in to be reduced to a linear expression. For example:

The reduction to a linear expression can be accomplished in one step by using the relationship
where formula_42 is the "k"th Fibonacci number.

However, this is no special property of , because polynomials in any solution "x" to a quadratic equation can be reduced in an analogous manner, by applying:
for given coefficients "a", "b" such that "x" satisfies the equation. Even more generally, any rational function (with rational coefficients) of the root of an irreducible "n"th-degree polynomial over the rationals can be reduced to a polynomial of degree Phrased in terms of field theory, if α is a root of an irreducible "n"th-degree polynomial, then formula_44 has degree "n" over formula_45, with basis formula_46

The golden ratio and inverse golden ratio formula_47 have a set of symmetries that preserve and interrelate them. They are both preserved by the fractional linear transformations formula_48 – this fact corresponds to the identity and the definition quadratic equation.
Further, they are interchanged by the three maps formula_49 – they are reciprocals, symmetric about formula_50, and (projectively) symmetric about 2.

More deeply, these maps form a subgroup of the modular group formula_51 isomorphic to the symmetric group on 3 letters, formula_52 corresponding to the stabilizer of the set formula_53 of 3 standard points on the projective line, and the symmetries correspond to the quotient map formula_54 – the subgroup formula_55 consisting of the 3-cycles and the identity formula_56 fixes the two numbers, while the 2-cycles interchange these, thus realizing the map.

The golden ratio has the simplest expression (and slowest convergence) as a continued fraction expansion of any irrational number (see "Alternate forms" above). It is, for that reason, one of the worst cases of Lagrange's approximation theorem and it is an extremal case of the Hurwitz inequality for Diophantine approximations. This may be why angles close to the golden ratio often show up in phyllotaxis (the growth of plants).

The defining quadratic polynomial and the conjugate relationship lead to decimal values that have their fractional part in common with :

The sequence of powers of contains these values 0.618..., 1.0, 1.618..., 2.618...; more generally,
any power of is equal to the sum of the two immediately preceding powers:

As a result, one can easily decompose any power of into a multiple of and a constant. The multiple and the constant are always adjacent Fibonacci numbers. This leads to another property of the positive powers of :

If formula_60, then:

When the golden ratio is used as the base of a numeral system (see Golden ratio base, sometimes dubbed "phinary" or "-nary"), every integer has a terminating representation, despite being irrational, but every fraction has a non-terminating representation.

The golden ratio is a fundamental unit of the algebraic number field formula_63 and is a Pisot–Vijayaraghavan number. In the field formula_63 we have formula_65, where formula_66 is the formula_67-th Lucas number.

The golden ratio also appears in hyperbolic geometry, as the maximum distance from a point on one side of an ideal triangle to the closer of the other two sides: this distance, the side length of the equilateral triangle formed by the points of tangency of a circle inscribed within the ideal triangle, is formula_68.

The golden ratio's decimal expansion can be calculated directly from the expression

with ≈ 2.2360679774997896964 . The square root of 5 can be calculated with the Babylonian method, starting with an initial estimate such as "x" = 2 and iterating

for "n" = 1, 2, 3, ..., until the difference between "x" and "x" becomes zero, to the desired number of digits.

The Babylonian algorithm for is equivalent to Newton's method for solving the equation "x" − 5 = 0. In its more general form, Newton's method can be applied directly to any algebraic equation, including the equation "x" − x − 1 = 0 that defines the golden ratio. This gives an iteration that converges to the golden ratio itself,

for an appropriate initial estimate "x" such as "x" = 1. A slightly faster method is to rewrite the equation as "x" − 1 − 1/"x" = 0, in which case the Newton iteration becomes

These iterations all converge quadratically; that is, each step roughly doubles the number of correct digits. The golden ratio is therefore relatively easy to compute with arbitrary precision. The time needed to compute "n" digits of the golden ratio is proportional to the time needed to divide two "n"-digit numbers. This is considerably faster than known algorithms for the transcendental numbers and .

An easily programmed alternative using only integer arithmetic is to calculate two large consecutive Fibonacci numbers and divide them. The ratio of Fibonacci numbers "F" and "F" , each over 5000 digits, yields over 10,000 significant digits of the golden ratio.

The decimal expansion of the golden ratio has been calculated to an accuracy of two trillion ( = 2,000,000,000,000) digits.

Both Egyptian pyramids and the regular square pyramids that resemble them can be analyzed with respect to the golden ratio and other ratios.

A pyramid in which the apothem (slant height along the bisector of a face) is equal to times the semi-base (half the base width) is sometimes called a "golden pyramid". The isosceles triangle that is the face of such a pyramid can be constructed from the two halves of a diagonally split golden rectangle (of size semi-base by apothem), joining the medium-length edges to make the apothem. The height of this pyramid is formula_73 times the semi-base (that is, the slope of the face is formula_73); the square of the height is equal to the area of a face, times the square of the semi-base.

The medial right triangle of this "golden" pyramid (see diagram), with sides formula_75 is interesting in its own right, demonstrating via the Pythagorean theorem the relationship formula_76 or formula_77. This Kepler triangle
is the only right triangle proportion with edge lengths in geometric progression, just as the 3–4–5 triangle is the only right triangle proportion with edge lengths in arithmetic progression. The angle with tangent formula_73 corresponds to the angle that the side of the pyramid makes with respect to the ground, 51.827... degrees (51° 49' 38").

A nearly similar pyramid shape, but with rational proportions, is described in the Rhind Mathematical Papyrus (the source of a large part of modern knowledge of ancient Egyptian mathematics), based on the 3:4:5 triangle; the face slope corresponding to the angle with tangent 4/3 is, to two decimal places, 53.13 degrees (53 degrees and 8 minutes). The slant height or apothem is 5/3 or 1.666... times the semi-base. The Rhind papyrus has another pyramid problem as well, again with rational slope (expressed as run over rise). Egyptian mathematics did not include the notion of irrational numbers, and the rational inverse slope (run/rise, multiplied by a factor of 7 to convert to their conventional units of palms per cubit) was used in the building of pyramids.

Another mathematical pyramid with proportions almost identical to the "golden" one is the one with perimeter equal to 2 times the height, or h:b = 4:. This triangle has a face angle of 51.854° (51°51'), very close to the 51.827° of the Kepler triangle. This pyramid relationship corresponds to the coincidental relationship formula_79.

Egyptian pyramids very close in proportion to these mathematical pyramids are known.

One Egyptian pyramid that is close to a "golden pyramid" is the Great Pyramid of Giza (also known as the Pyramid of Cheops or Khufu). Its slope of 51° 52' is close to the "golden" pyramid inclination of 51° 50' – and even closer to the -based pyramid inclination of 51° 51'. However, several other mathematical theories of the shape of the great pyramid, based on rational slopes, have been found to be both more accurate and more plausible explanations for the 51° 52' slope.

In the mid-nineteenth century, Friedrich Röber studied various Egyptian pyramids including those of Khafre, Menkaure, and some of the Giza, Saqqara, and Abusir groups. He did not apply the golden ratio to the Great Pyramid of Giza, but instead agreed with John Shae Perring that its side-to-height ratio is 8:5. For all the other pyramids he applied measurements related to the Kepler triangle, and claimed that either their whole or half-side lengths are related to their heights by the golden ratio.

In 1859, the pyramidologist John Taylor misinterpreted Herodotus () as indicating that the Great Pyramid's height squared equals the area of one of its face triangles. This led Taylor to claim that, in the Great Pyramid, the golden ratio is represented by the ratio of the length of the face (the slope height, inclined at an angle θ to the ground) to half the length of the side of the square base (equivalent to the secant of the angle θ). The above two lengths are about and , respectively. The ratio of these lengths is the golden ratio, accurate to more digits than either of the original measurements. Similarly, Howard Vyse reported the great pyramid height , and half-base , yielding 1.6189 for the ratio of slant height to half-base, again more accurate than the data variability.

Eric Temple Bell, mathematician and historian, claimed in 1950 that Egyptian mathematics would not have supported the ability to calculate the slant height of the pyramids, or the ratio to the height, except in the case of the 3:4:5 pyramid, since the 3:4:5 triangle was the only right triangle known to the Egyptians and they did not know the Pythagorean theorem, nor any way to reason about irrationals such as or . Example geometric problems of pyramid design in the Rhind papyrus correspond to various rational slopes.

Michael Rice asserts that principal authorities on the history of Egyptian architecture have argued that the Egyptians were well acquainted with the golden ratio and that it is part of the mathematics of the pyramids, citing Giedon (1957). Historians of science have long debated whether the Egyptians had any such knowledge, contending that its appearance in the Great Pyramid is the result of chance.

Examples of disputed observations of the golden ratio include the following:


The Parthenon's façade (c. 432 BC) as well as elements of its façade and elsewhere are said by some to be circumscribed by golden rectangles. Other scholars deny that the Greeks had any aesthetic association with golden ratio. For example, Keith Devlin says, "Certainly, the oft repeated assertion that the Parthenon in Athens is based on the golden ratio is not supported by actual measurements. In fact, the entire story about the Greeks and golden ratio seems to be without foundation." Midhat J. Gazalé affirms that "It was not until Euclid ... that the golden ratio's mathematical properties were studied."

From measurements of 15 temples, 18 monumental tombs, 8 sarcophagi, and 58 grave stelae from the fifth century BC to the second century AD, one researcher concluded that the golden ratio was totally absent from Greek architecture of the classical fifth century BC, and almost absent during the following six centuries.
Later sources like Vitruvius (first century BC) exclusively discuss proportions that can be expressed in whole numbers, i.e. commensurate as opposed to irrational proportions.

The Section d'Or ('Golden Section') was a collective of painters, sculptors, poets and critics associated with Cubism and Orphism. Active from 1911 to around 1914, they adopted the name both to highlight that Cubism represented the continuation of a grand tradition, rather than being an isolated movement, and in homage to the mathematical harmony associated with Georges Seurat. The Cubists observed in its harmonies, geometric structuring of motion and form, the primacy of idea over nature, an absolute scientific clarity of conception. However, despite this general interest in mathematical harmony, whether the paintings featured in the celebrated 1912 "Salon de la Section d'Or" exhibition used the golden ratio in any compositions is more difficult to determine. Livio, for example, claims that they did not, and Marcel Duchamp said as much in an interview. On the other hand, an analysis suggests that Juan Gris made use of the golden ratio in composing works that were likely, but not definitively, shown at the exhibition. Art historian Daniel Robbins has argued that in addition to referencing the mathematical term, the exhibition's name also refers to the earlier "Bandeaux d'Or" group, with which Albert Gleizes and other former members of the Abbaye de Créteil had been involved.

Piet Mondrian has been said to have used the golden section extensively in his geometrical paintings, though other experts (including critic Yve-Alain Bois) have discredited these claims.

Footnotes
Citations



</doc>
<doc id="12388" url="https://en.wikipedia.org/wiki?curid=12388" title="Genome">
Genome

In the fields of molecular biology and genetics, a genome is the genetic material of an organism. It consists of DNA (or RNA in RNA viruses). The genome includes both the genes (the coding regions) and the noncoding DNA, as well as mitochondrial DNA and chloroplast DNA. The study of the genome is called genomics.

The term "genome" was created in 1920 by Hans Winkler, professor of botany at the University of Hamburg, Germany. The Oxford Dictionary suggests the name is a blend of the words "gene" and "chromosome". However, see omics for a more thorough discussion. A few related "-ome" words already existed, such as "biome" and "rhizome", forming a vocabulary into which "genome" fits systematically.

A genome sequence is the complete list of the nucleotides (A, C, G, and T for DNA genomes) that make up all the chromosomes of an individual or a species. Within a species, the vast majority of nucleotides are identical between individuals, but sequencing multiple individuals is necessary to understand the genetic diversity. 
In 1976, Walter Fiers at the University of Ghent (Belgium) was the first to establish the complete nucleotide sequence of a viral RNA-genome (Bacteriophage MS2). The next year, Fred Sanger completed the first DNA-genome sequence: Phage Φ-X174, of 5386 base pairs. The first complete genome sequences among all three domains of life were released within a short period during the mid-1990s: The first bacterial genome to be sequenced was that of Haemophilus influenzae, completed by a team at The Institute for Genomic Research in 1995. A few months later, the first eukaryotic genome was completed, with sequences of the 16 chromosomes of budding yeast "Saccharomyces cerevisiae" published as the result of a European-led effort begun in the mid-1980s. The first genome sequence for an archaeon, "Methanococcus jannaschii", was completed in 1996, again by The Institute for Genomic Research.

The development of new technologies has made genome sequencing dramatically cheaper and easier, and the number of complete genome sequences is growing rapidly. The US National Institutes of Health maintains one of several comprehensive databases of genomic information. Among the thousands of completed genome sequencing projects include those for rice, a mouse, the plant "Arabidopsis thaliana", the puffer fish, and the bacteria E. coli. In December 2013, scientists first sequenced the entire "genome" of a Neanderthal, an extinct species of humans. The genome was extracted from the toe bone of a 130,000-year-old Neanderthal found in a Siberian cave.

New sequencing technologies, such as massive parallel sequencing have also opened up the prospect of personal genome sequencing as a diagnostic tool, as pioneered by Manteia Predictive Medicine. A major step toward that goal was the completion in 2007 of the full genome of James D. Watson, one of the co-discoverers of the structure of DNA.

Whereas a genome sequence lists the order of every DNA base in a genome, a genome map identifies the landmarks. A genome map is less detailed than a genome sequence and aids in navigating around the genome. The Human Genome Project was organized to map and to sequence the human genome. A fundamental step in the project was the release of a detailed genomic map by Jean Weissenbach and his team at the Genoscope in Paris.

Reference genome sequences and maps continue to be updated, removing errors and clarifying regions of high allelic complexity. The decreasing cost of genomic mapping has permitted genealogical sites to offer it as a service, to the extent that one may submit one's genome to crowdsourced scientific endeavours such as DNA.LAND at the New York Genome Center, an example both of the economies of scale and of citizen science.

Viral genomes can be composed of either RNA or DNA. The genomes of RNA viruses can be either single-stranded or double-stranded RNA, and may contain one or more separate RNA molecules. DNA viruses can have either single-stranded or double-stranded genomes. Most DNA virus genomes are composed of a single, linear molecule of DNA, but some are made up of a circular DNA molecule.

Prokaryotes and eukaryotes have DNA genomes. Archaea have a single circular chromosome. Most bacteria also have a single circular chromosome; however, some bacterial species have linear chromosomes or multiple chromosomes. If the DNA is replicated faster than the bacterial cells divide, multiple copies of the chromosome can be present in a single cell, and if the cells divide faster than the DNA can be replicated, multiple replication of the chromosome is initiated before the division occurs, allowing daughter cells to inherit complete genomes and already partially replicated chromosomes. Most prokaryotes have very little repetitive DNA in their genomes. However, some symbiotic bacteria (e.g. "Serratia symbiotica") have reduced genomes and a high fraction of pseudogenes: only ~40% of their DNA encodes proteins.

Some bacteria have auxiliary genetic material, also part of their genome, which is carried in plasmids. For this, the word "genome" should not be used as a synonym of "chromosome".

Eukaryotic genomes are composed of one or more linear DNA chromosomes. The number of chromosomes varies widely from Jack jumper ants and an asexual nemotode, which each have only one pair, to a fern species that has 720 pairs. A typical human cell has two copies of each of 22 autosomes, one inherited from each parent, plus two sex chromosomes, making it diploid. Gametes, such as ova, sperm, spores, and pollen, are haploid, meaning they carry only one copy of each chromosome.

In addition to the chromosomes in the nucleus, organelles such as the chloroplasts and mitochondria have their own DNA. Mitochondria are sometimes said to have their own genome often referred to as the "mitochondrial genome". The DNA found within the chloroplast may be referred to as the "plastome". Like the bacteria they originated from, mitochondria and chloroplasts have a circular chromosome.

Unlike prokaryotes, eukaryotes have exon-intron organization of protein coding genes and variable amounts of repetitive DNA. In mammals and plants, the majority of the genome is composed of repetitive DNA.

DNA sequences that carry the instructions to make proteins are coding sequences. The proportion of the genome occupied by coding sequences varies widely. A larger genome does not necessarily contain more genes, and the proportion of non-repetitive DNA decreases along with increasing genome size in complex eukaryotes.

Simple eukaryotes such as "C. elegans" and fruit fly, have more non-repetitive DNA than repetitive DNA, while the genomes of more complex eukaryotes tend to be composed largely of repetitive DNA. In some plants and amphibians, the proportion of repetitive DNA is more than 80%. Similarly, only 2% of the human genome codes for proteins. 
Noncoding sequences include introns, sequences for non-coding RNAs, regulatory regions, and repetitive DNA. Noncoding sequences make up 98% of the human genome. There are two categories of repetitive DNA in the genome: tandem repeats and interspersed repeats.

Short, non-coding sequences that are repeated head-to-tail are called tandem repeats. Microsatellites consisting of 2-5 basepair repeats, while minisatellite repeats are 30-35 bp. Tandem repeats make up about 4% of the human genome and 9% of the fruit fly genome. Tandom repeats can be functional. For example, telomeres are composed of the tandem repeat TTAGGG in mammals, and they play an important role in protecting the ends of the chromosome.

In other cases, expansions in the number of tandem repeats in exons or introns can cause disease. For example, the human gene huntingtin typically contains 6–29 tandem repeats of the nucleotides CAG (encoding a polyglutamine tract). An expansion to over 36 repeats results in Huntington's disease, a neurodegenerative disease. Twenty human disorders are known to result from similar tandem repeat expansions in various genes. The mechanism by which proteins with expanded polygulatamine tracts cause death of neurons is not fully understood. One possibility is that the proteins fail to fold properly and avoid degradation, instead accumulating in aggregates that also sequester important transcription factors, thereby altering gene expression.

Tandem repeats are usually caused by slippage during replication, unequal crossing-over and gene conversion.

Transposable elements (TEs) are sequences of DNA with a defined structure that are able to change their location in the genome. TEs are categorized as either class I TEs, which replicate by a copy-and-paste mechanism, or class II TEs, which can be excised from the genome and inserted at a new location.

The movement of TEs is a driving force of genome evolution in eukaryotes because their insertion can disrupt gene functions, homologous recombination between TEs can produce duplications, and TE can shuffle exons and regulatory sequences to new locations.

Retrotransposons can be transcribed into RNA, which are then duplicated at another site into the genome. Retrotransposons can be divided into Long terminal repeats (LTRs) and Non-Long Terminal Repeats (Non-LTR).

Long terminal repeats (LTRs) are derived from ancient retroviral infections, so they encode proteins related to retroviral proteins including gag (structural proteins of the virus), pol (reverse transcriptase and integrase), pro (protease), and in some cases env (envelope) genes. These genes are flanked by long repeats at both 5' and 3' ends. It has been reported that LTRs consist of the largest fraction in most plant genome and might account for the huge variation in genome size.

Non-long terminal repeats (Non-LTRs) are classified as long interspersed elements (LINEs), short interspersed elements (SINEs), and Penelope-like elements. In "Dictyostelium discoideum", there is another DIRS-like elements belong to Non-LTRs. Non-LTRs are widely spread in eukaryotic genomes.

Long interspersed elements (LINEs) encode genes for reverse transcriptase and endonuclease, making them autonomous transposable elements. The human genome has around 500,000 LINEs, taking around 17% of the genome.

Short interspersed elements (SINEs) are usually less than 500 base pairs and are non-autonomous, so they rely on the proteins encoded by LINEs for transposition. The Alu element is the most common SINE found in primates. It is about 350 base pairs and occupies about 11% of the human genome with around 1,500,000 copies.

DNA transposons encode a transposase enzyme between inverted terminal repeats. When expressed, the transposase recognizes the terminal inverted repeats that flank the transposon and catalyzes its excision and reinsertion in a new site. This cut-and-paste mechanism typically reinserts transposons near their original location (within 100kb). DNA transposons are found in bacteria and make up 3% of the human genome and 12% of the genome of the roundworm "C. elegans".

Genome size is the total number of DNA base pairs in one copy of a haploid genome. In humans, the nuclear genome comprises approximately 3.2 billion nucleotides of DNA, divided into 24 linear molecules, the shortest 50 000 000 nucleotides in length and the longest 260 000 000 nucleotides, each contained in a different chromosome. The genome size is positively correlated with the morphological complexity among prokaryotes and lower eukaryotes; however, after mollusks and all the other higher eukaryotes above, this correlation is no longer effective. This phenomenon also indicates the mighty influence coming from repetitive DNA on the genomes.

Since genomes are very complex, one research strategy is to reduce the number of genes in a genome to the bare minimum and still have the organism in question survive. There is experimental work being done on minimal genomes for single cell organisms as well as minimal genomes for multi-cellular organisms (see Developmental biology). The work is both "in vivo" and "in silico".

Here is a table of some significant or representative genomes. See #See also for lists of sequenced genomes.

All the cells of an organism originate from a single cell, so they are expected to have identical genomes; however, in some cases, differences arise. Both the process of copying DNA during cell division and exposure to environmental mutagens can result in mutations in somatic cells. In some cases, such mutations lead to cancer because they cause cells to divide more quickly and invade surrounding tissues. In certain lymphocytes in the human immune system, V(D)J recombination generates different genomic sequences such that each cell produces a unique antibody or T cell receptors.

During meiosis, diploid cells divide twice to produce haploid germ cells. During this process, recombination results in a reshuffling of the genetic material from homologous chromosomes so each gamete has a unique genome.

Genome-wide reprogramming in mouse primordial germ cells involves epigenetic imprint erasure leading to totipotency. Reprogramming is facilitated by active DNA demethylation, a process that entails the DNA base excision repair pathway. This pathway is employed in the erasure of CpG methylation (5mC) in primordial germ cells. The erasure of 5mC occurs via its conversion to 5-hydroxymethylcytosine (5hmC) driven by high levels of the ten-eleven dioxygenase enzymes TET1 and TET2.

Genomes are more than the sum of an organism's genes and have traits that may be measured and studied without reference to the details of any particular genes and their products. Researchers compare traits such as karyotype (chromosome number), genome size, gene order, codon usage bias, and GC-content to determine what mechanisms could have produced the great variety of genomes that exist today (for recent overviews, see Brown 2002; Saccone and Pesole 2003; Benfey and Protopapas 2004; Gibson and Muse 2004; Reese 2004; Gregory 2005).

Duplications play a major role in shaping the genome. Duplication may range from extension of short tandem repeats, to duplication of a cluster of genes, and all the way to duplication of entire chromosomes or even entire genomes. Such duplications are probably fundamental to the creation of genetic novelty.

Horizontal gene transfer is invoked to explain how there is often an extreme similarity between small portions of the genomes of two organisms that are otherwise very distantly related. Horizontal gene transfer seems to be common among many microbes. Also, eukaryotic cells seem to have experienced a transfer of some genetic material from their chloroplast and mitochondrial genomes to their nuclear chromosomes. Recent empirical data suggest an important role of viruses and sub-viral RNA-networks to represent a main driving role to generate genetic novelty and natural genome editing.

Works of science fiction illustrate concerns about the availability of genome sequences.

Michael Crichton's 1990 novel "Jurassic Park" and the subsequent film tell the story of a billionaire who creates a theme park of cloned dinosaurs on a remote island, with disastrous outcomes. A geneticist extracts dinosaur DNA from the blood of ancient mosquitoes and fills in the gaps with DNA from modern species to create several species of dinosaurs. A chaos theorist is asked to give his expert opinion on the safety of engineering an ecosystem with the dinosaurs, and he repeatedly warns that the outcomes of the project will be unpredictable and ultimately uncontrollable. These warnings about the perils of using genomic information are a major theme of the book.

The 1997 film "Gattaca" is set in a futurist society where genomes of children are engineered to contain the most ideal combination of their parents' traits, and metrics such as risk of heart disease and predicted life expectancy are documented for each person based on their genome. People conceived outside of the eugenics program, known as "In-Valids" suffer discrimination and are relegated to menial occupations. The protagonist of the film is an In-Valid who works to defy the supposed genetic odds and achieve his dream of working as a space navigator. The film warns against a future where genomic information fuels prejudice and extreme class differences between those who can and can't afford genetically engineered children.




</doc>
<doc id="12393" url="https://en.wikipedia.org/wiki?curid=12393" title="Gaia philosophy">
Gaia philosophy

Gaia philosophy (named after Gaia, Greek goddess of the Earth) is a broadly inclusive term for related concepts that living organisms on a planet will affect the nature of their environment in order to make the environment more suitable for life. This set of theories holds that all organisms on a life-giving planet regulate the biosphere in such a way as to promote its habitability. Gaia concept draws a connection between the survivability of a species (hence its evolutionary course) and its usefulness to the survival of other species.

While there were a number of precursors to Gaia theory, the first scientific form of this idea was proposed as the Gaia hypothesis by James Lovelock, a UK chemist, in 1970. The Gaia hypothesis deals with the concept of biological homeostasis, and claims the resident life forms of a host planet coupled with their environment have acted and act like a single, self-regulating system. This system includes the near-surface rocks, the soil, and the atmosphere. Today many scientists consider such ideas to be unsupported by, or at odds with, the available evidence (see Gaia hypothesis criticism). These theories are however significant in green politics.

There are some mystical, scientific and religious predecessors to the Gaia philosophy, which had a Gaia-like conceptual basis. Many religious mythologies had a view of Earth as being a whole that is greater than the sum of its parts (e.g. some Native American religions and various forms of shamanism).

Lewis Thomas believed that Earth should be viewed as a single cell; he derived this view from Johannes Kepler's view of Earth as a single round organism.

Isaac Newton wrote of the earth, "Thus this Earth resembles a great animall or rather inanimate vegetable, draws in æthereall breath for its dayly refreshment & vitall ferment & transpires again with gross exhalations, And according to the condition of all other things living ought to have its times of beginning youth old age & perishing."

Pierre Teilhard de Chardin, a paleontologist and geologist, believed that evolution unfolded from cell to organism to planet to solar system and ultimately the whole universe, as we humans see it from our limited perspective. Teilhard later influenced Thomas Berry and many Catholic humanist thinkers of the 20th century.

Buckminster Fuller is generally credited with making the idea respectable in Western scientific circles in the 20th century. Building to some degree on his observations and artifacts, e.g. the Dymaxion map of the Earth he created, others began to ask if there was a way to make the Gaia theory scientifically sound.

Oberon Zell-Ravenheart in 1970 in an article in "Green Egg" Magazine, independently articulated the Gaia Thesis.

None of these ideas are considered scientific hypotheses; by definition a scientific hypothesis must make testable predictions. As the above claims are not testable, they are outside the bounds of current science.

These are conjectures and perhaps can only be considered as social and maybe political philosophy; they may have implications for theology, or "thealogy" as Zell-Ravenheart and Isaac Bonewits put it.

According to James Kirchner there is a spectrum of Gaia hypotheses, ranging from the undeniable to radical. At one end is the undeniable statement that the organisms on the Earth have radically altered its composition. A stronger position is that the Earth's biosphere effectively acts as if it is a self-organizing system which works in such a way as to keep its systems in some kind of equilibrium that is conducive to life. Today many scientists consider that such a view (and any stronger views) are unlikely to be correct. An even stronger claim is that all lifeforms are part of a single planetary being, called Gaia. In this view, the atmosphere, the seas, the terrestrial crust would be the result of interventions carried out by Gaia, through the coevolving diversity of living organisms.

The most extreme form of Gaia theory is that the entire Earth is a single unified organism with a highly intelligent mind that arose as an emergent property of the whole biosphere. In this view, the Earth's biosphere is "consciously" manipulating the climate in order to make conditions more conducive to life. Scientists contend that there is no evidence at all to support this last point of view, and it has come about because many people do not understand the concept of homeostasis. Many non-scientists instinctively and incorrectly see homeostasis as a process that requires conscious control 

The more speculative versions of Gaia, including versions in which it is believed that the Earth is actually conscious, sentient, and highly intelligent, are usually considered outside the bounds of what is usually considered science.

Buckminster Fuller has been credited as the first to incorporate scientific ideas into a Gaia theory, which he did with his Dymaxion map of the Earth.

The first scientifically rigorous theory was the Gaia hypothesis by James Lovelock, a UK chemist.

A variant of this hypothesis was developed by Lynn Margulis, a microbiologist, in 1979.
Her version is sometimes called the "Gaia Theory" (note uppercase-T). Her model is more limited in scope than the one that Lovelock proposed.

Whether this sort of system is present on Earth is still open to debate. Some relatively simple homeostatic mechanisms are generally accepted. For example, when atmospheric carbon dioxide levels rise, plants are able to grow better and thus remove more carbon dioxide from the atmosphere. Other biological effects and feedbacks exist, but the extent to which these mechanisms have stabilized and modified the Earth's overall climate is largely not known.

The Gaia hypothesis is sometimes viewed from significantly different philosophical perspectives. Some environmentalists view it as an almost conscious process, in which the Earth's ecosystem is literally viewed as a single unified organism. Some evolutionary biologists, on the other hand, view it as an undirected emergent property of the ecosystem: as each individual species pursues its own self-interest, their combined actions tend to have counterbalancing effects on environmental change. Proponents of this view sometimes point to examples of life's actions in the past that have resulted in dramatic change rather than stable equilibrium, such as the conversion of the Earth's atmosphere from a reducing environment to an oxygen-rich one.

Depending on how strongly the case is stated, the hypothesis conflicts with mainstream neo-Darwinism. Most biologists would accept Daisyworld-style homeostasis as possible, but would certainly not accept the idea that this equates to the whole biosphere acting as one organism.

A very small number of scientists, and a much larger number of environmental activists, claim that Earth's biosphere is "consciously" manipulating the climate in order to make conditions more conducive to life. Scientists contend that there is no evidence to support this belief.

A social science view of Gaia theory is the role of humans as a keystone species who may be able to accomplish global homeostasis. Whilst a few social scientists who draw inspiration from 'organic' views of society have embraced Gaia philosophy as a way to explain the human-nature interconnections, most professional social scientists are more involved in reflecting upon the way Gaia philosophy is used and engaged with within sub-sections of society. Alan Marshall, in the Department of Social Sciences at Mahidol University, for example, reflects upon the way Gaia philosophy has been used and advocated by environmentalists, spiritualists, managers, economists, and scientists and engineers (see The Unity of Nature, 2002, Imperial College Press: London and Singapore). Social Scientists themselves in the 1960s gave up on systems ideas of society since they were interpreted as supporting conservatism and traditionalism.

Some radical political environmentalists who accept some form of the Gaia theory call themselves Gaians. They actively seek to restore the Earth's homeostasis — whenever they see it out of balance, e.g. to prevent manmade climate change, primate extinction, or rainforest loss. In effect, they seek to cooperate to become the "system consciously manipulating to make conditions more conducive to life". Such activity defines the homeostasis, but for leverage it relies on deep investigation of the homeorhetic balances, if only to find places to intervene in a system which is changing in undesirable ways.

Tony Bondhus brings up the point in his book, "Society of Conceivia", that if Gaia is alive, then societies are living things as well. This suggests that our understanding of Gaia can be used to create a better society and to design a better political system.

Other intellectuals in the environmental movement, like Edward Goldsmith, have used Gaia in the completely opposite way; to stake a claim about how Gaia's focus on natural balance and resistance and resilience, should be emulated to design a conservative political system (as explored in Alan Marshall's 2002 book "The Unity of Nature", (Imperial College Press: London).

Gaians do not passively ask "what is going on", but rather, "what to do next", e.g. in terraforming or climate engineering or even on a small scale, such as gardening. Changes can be planned, agreed upon by many people, being very deliberate, as in urban ecology and especially industrial ecology. "See arcology for more on this 'active' view."

Gaians argue that it is a human duty to act as such - committing themselves in particular to the Precautionary Principle. Such views began to influence the Green Parties, Greenpeace, and a few more radical wings of the environmental movement such as the Gaia Liberation Front and the Earth Liberation Front. These views dominate some such groups, e.g. the Bioneers. Some refer to this political activity as a separate and radical branch of the ecology movement, one that takes the axioms of the science of ecology in general, and Gaia theory in particular, and raises them to a kind of theory of personal conduct or moral code.

The ecologist and theologian Anne Primavesi is the author of two books dealing with the Gaia hypothesis and theology.

Rosemary Radford Ruether, the American feminist scholar and theologian, wrote a book called "Gaia and God: An Ecofeminist Theology of Earth Healing".

A book edited by Allan Hunt Badiner called Dharma Gaia explores the ground where Buddhism and ecology meet through writings by the Dalai Lama, Gary Snyder, Thich Nhat Hanh, Allen Ginsberg, Joanna Macy, Robert Aitken, and 25 other Buddhists and ecologists.

Many new age authors have written books which mix New Age teachings with Gaia philosophy. This is known as New Age Gaian. Often referred to as Gaianism, or the Gaian Religion, this spiritual aspect of the philosophy is very broad and inclusive, making it adaptable to other religions: Taoism, Neo-Paganism, Pantheism, Judeo-Christian Religions, and many others.

The question of "what is an organism", and at what scale is it rational to speak about organisms vs. biospheres, gives rise to a semantic debate. We are all ecologies in the sense that our (human) bodies contain gut bacteria, parasite species, etc., and to them our body is not organism but rather more of a microclimate or biome. Applying that thinking to whole planets:

The argument is that these symbiotic organisms, being unable to survive apart from each other and their climate and local conditions, form an organism in their own right, under a wider conception of the term organism than is conventionally used. It is a matter for often heated debate whether this is a valid usage of the term, but ultimately it appears to be a semantic dispute. In this sense of the word organism, it is argued under the theory that the entire biomass of the Earth is a single organism (as Johannes Kepler thought).

Unfortunately, many supporters of the various Gaia theories do not state exactly where they sit on this spectrum; this makes discussion and criticism difficult.

Much effort on behalf of those analyzing the theory currently is an attempt to clarify what these different hypotheses are, and whether they are proposals to 'test' or 'manipulate' outcomes. Both Lovelock's and Margulis's understanding of Gaia are considered scientific hypotheses, and like all scientific theories are constantly put to the test.

More speculative versions of Gaia, including all versions in which it is held that the Earth is actually conscious, are currently held to be outside the bounds of science, and are not supported by either Lovelock or Margulis.

One of the most problematic issues with referring to Gaia as an organism is its apparent failure to meet the biological criterion of being able to reproduce. Richard Dawkins has asserted that the planet is not the offspring of any parents and is unable to reproduce.





</doc>
<doc id="12395" url="https://en.wikipedia.org/wiki?curid=12395" title="Greenhouse effect">
Greenhouse effect

The greenhouse effect is the process by which radiation from a planet's atmosphere warms the planet's surface to a temperature above what it would be without its atmosphere.

Radiatively active gases (i.e., greenhouse gases) in a planet's atmosphere radiate energy in all directions. Part of this radiation is directed towards the surface, warming it.
The intensity of the downward radiation – that is, the strength of the greenhouse effect – will depend on the atmosphere's temperature and on the amount of greenhouse gases that the atmosphere contains.

Earth’s natural greenhouse effect is critical to supporting life. Human activities, mainly the burning of fossil fuels and clearing of forests, have strengthened the greenhouse effect and caused global warming.

The term "greenhouse effect" keeps being used in science despite being a known misnomer. While both an atmosphere and a greenhouse retain heat, they do it in fundamentally different ways: an atmosphere reduces radiative loss from the surface to space, a greenhouse blocks convective loss.

The existence of the greenhouse effect was argued for by Joseph Fourier in 1824. The argument and the evidence were further strengthened by Claude Pouillet in 1827 and 1838 and reasoned from experimental observations by Eunice Newton Foote in 1856. John Tyndall expanded her work in 1859 by measuring radiative properties of a wider spectrum of greenhouse gases. The effect was more fully quantified by Svante Arrhenius in 1896, who made the first quantitative prediction of global warming due to a hypothetical doubling of atmospheric carbon dioxide. However, the term "greenhouse" was not used to refer to this effect by any of these scientists; the term was first used in this way by Nils Gustaf Ekholm in 1901.

Earth receives energy from the Sun in the form of ultraviolet, visible, and near-infrared radiation. About 26% of the incoming solar energy is reflected to space by the atmosphere and clouds, and 19% is absorbed by the atmosphere and clouds. Most of the remaining energy is absorbed at the surface of Earth. Because the Earth's surface is colder than the Sun, it radiates at wavelengths that are much longer than the wavelengths that were absorbed. Most of this thermal radiation is absorbed by the atmosphere and warms it. The atmosphere also gains heat by sensible and latent heat fluxes from the surface. The atmosphere radiates energy both upwards and downwards; the part radiated downwards is absorbed by the surface of Earth. This leads to a higher equilibrium temperature than if the atmosphere did not radiate.

An ideal thermally conductive blackbody at the same distance from the Sun as Earth would have a temperature of about . However, because Earth reflects about 30% of the incoming sunlight, this idealized planet's effective temperature (the temperature of a blackbody that would emit the same amount of radiation) would be about . The surface temperature of this hypothetical planet is below Earth's actual surface temperature of approximately .. The greenhouse effect is the contribution of greenhouse gases to this difference. 
The basic mechanism can be qualified in a number of ways, none of which affect the fundamental process. The atmosphere near the surface is largely opaque to thermal radiation (with important exceptions for "window" bands), and most heat loss from the surface is by sensible heat and latent heat transport. Radiative energy losses become increasingly important higher in the atmosphere, largely because of the decreasing concentration of water vapor, an important greenhouse gas. It is more realistic to think of the greenhouse effect as applying to a layer in the mid-troposphere, which is effectively coupled to the surface by a lapse rate. The simple picture also assumes a steady state, but in the real world, the diurnal cycle as well as the seasonal cycle and weather disturbances complicate matters. Solar heating applies only during daytime. During the night, the atmosphere cools somewhat, but not greatly, because its emissivity is low. Diurnal temperature changes decrease with height in the atmosphere.

Within the region where radiative effects are important, the description given by the idealized greenhouse model becomes realistic. Earth's surface, warmed to a temperature around 255 K, radiates long-wavelength, infrared heat in the range of 4–100 μm. At these wavelengths, greenhouse gases that were largely transparent to incoming solar radiation are more absorbent. Each layer of atmosphere with greenhouses gases absorbs some of the heat being radiated upwards from lower layers. It reradiates in all directions, both upwards and downwards; in equilibrium (by definition) the same amount as it has absorbed. This results in more warmth below. Increasing the concentration of the gases increases the amount of absorption and reradiation, and thereby further warms the layers and ultimately the surface below.

Greenhouse gases—including most diatomic gases with two different atoms (such as carbon monoxide, CO) and all gases with three or more atoms—are able to absorb and emit infrared radiation. Though more than 99% of the dry atmosphere is IR transparent (because the main constituents—, , and Ar—are not able to directly absorb or emit infrared radiation), intermolecular collisions cause the energy absorbed and emitted by the greenhouse gases to be shared with the other, non-IR-active, gases. 

By their percentage contribution to the greenhouse effect on Earth the four major gases are:


It is not possible to assign a specific percentage to each gas because the absorption and emission bands of the gases overlap (hence the ranges given above). Clouds also absorb and emit infrared radiation and thus affect the radiative properties of the atmosphere.

Strengthening of the greenhouse effect through human activities is known as the enhanced (or anthropogenic) greenhouse effect. This increase in radiative forcing from human activity is attributable mainly to increased atmospheric carbon dioxide levels. According to the latest Assessment Report from the Intergovernmental Panel on Climate Change, ""atmospheric concentrations of carbon dioxide, methane and nitrous oxide are unprecedented in at least the last 800,000 years. Their effects, together with those of other anthropogenic drivers, have been detected throughout the climate system and are extremely likely to have been the dominant cause of the observed warming since the mid-20th century"".

Over the past 800,000 years, ice core data shows that carbon dioxide has varied from values as low as 180 ppm to the pre-industrial level of 270 ppm. Paleoclimatologists consider variations in carbon dioxide concentration to be a fundamental factor influencing climate variations over this time scale.

The "greenhouse effect" of the atmosphere is named by analogy to greenhouses which become warmer in sunlight. However, a greenhouse is not primarily warmed by the "greenhouse effect".
"Greenhouse effect" is actually a misnomer since heating in the usual greenhouse is due to the reduction of convection, while the "greenhouse effect" works by preventing absorbed heat from leaving the structure through radiative transfer.

A greenhouse is built of any material that passes sunlight: usually glass or plastic. The sun warms the ground and contents inside just like the outside, and these then warm the air. Outside, the warm air near the surface rises and mixes with cooler air aloft, keeping the temperature lower than inside, where the air continues to heat up because it is confined within the greenhouse. This can be demonstrated by opening a small window near the roof of a greenhouse: the temperature will drop considerably. It was demonstrated experimentally (R. W. Wood, 1909) that a (not heated) "greenhouse" with a cover of rock salt (which is transparent to infrared) heats up an enclosure similarly to one with a glass cover. Thus greenhouses work primarily by preventing convective cooling.

Heated greenhouses are yet another matter: as they have an internal source of heating, it is desirable to minimise the amount of heat leaking out by radiative cooling. This can be done through the use of adequate glazing.

The anti-greenhouse effect is a mechanism similar and symmetrical to the greenhouse effect: in the greenhouse effect, the atmosphere lets radiation in while not letting thermal radiation out, thus warming the body surface; in the anti-greenhouse effect, the atmosphere keeps radiation out while letting thermal radiation out, which lowers the equilibrium surface temperature. Such an effect has been proposed for Saturn's moon Titan.

A runaway greenhouse effect occurs if positive feedbacks lead to the evaporation of all greenhouse gases into the atmosphere. A runaway greenhouse effect involving carbon dioxide and water vapor has long ago been hypothesized to have occurred on Venus, .

The greenhouse effect on Venus is particularly large because its dense atmosphere consists mainly of carbon dioxide.
"Venus experienced a runaway greenhouse in the past, and we expect that Earth will in about 2 billion years as solar luminosity increases".

Titan has an anti-greenhouse effect, in that its atmosphere absorbs solar radiation but is relatively transparent to outgoing infrared radiation.

Pluto is also colder than would be expected because evaporation of nitrogen cools it.




</doc>
<doc id="12396" url="https://en.wikipedia.org/wiki?curid=12396" title="Group homomorphism">
Group homomorphism

In mathematics, given two groups, ("G", ∗) and ("H", ·), a group homomorphism from ("G", ∗) to ("H", ·) is a function "h" : "G" → "H" such that for all "u" and "v" in "G" it holds that

where the group operation on the left hand side of the equation is that of "G" and on the right hand side that of "H".

From this property, one can deduce that "h" maps the identity element "e" of "G" to the identity element "e" of "H",

and it also maps inverses to inverses in the sense that 

Hence one can say that "h" "is compatible with the group structure".

Older notations for the homomorphism "h"("x") may be "x" or "x", though this may be confused as an index or a general subscript. A more recent trend is to write group homomorphisms on the right of their arguments, omitting brackets, so that "h"("x") becomes simply "x h". This approach is especially prevalent in areas of group theory where automata play a role, since it accords better with the convention that automata read words from left to right.

In areas of mathematics where one considers groups endowed with additional structure, a "homomorphism" sometimes means a map which respects not only the group structure (as above) but also the extra structure. For example, a homomorphism of topological groups is often required to be continuous.

The purpose of defining a group homomorphism is to create functions that preserve the algebraic structure. An equivalent definition of group homomorphism is: The function "h" : "G" → "H" is a group homomorphism if whenever 

"a" ∗ "b" = "c"   we have   "h"("a") ⋅ "h"("b") = "h"("c"). 

In other words, the group "H" in some sense has a similar algebraic structure as "G" and the homomorphism "h" preserves that.


We define the "kernel of h" to be the set of elements in "G" which are mapped to the identity in "H"

and the "image of h" to be

The kernel and image of a homomorphism can be interpreted as measuring how close it is to being an isomorphism. The first isomorphism theorem states that the image of a group homomorphism, "h"("G") is isomorphic to the quotient group "G"/ker "h".

The kernel of h is a normal subgroup of "G" and the image of h is a subgroup of "H":

If and only if }, the homomorphism, "h", is a "group monomorphism"; i.e., "h" is injective (one-to-one). Injection directly gives that there is a unique element in the kernel, and a unique element in the kernel gives injection:



If and are group homomorphisms, then so is . This shows that the class of all groups, together with group homomorphisms as morphisms, forms a category.

If "G" and "H" are abelian (i.e., commutative) groups, then the set of all group homomorphisms from "G" to "H" is itself an abelian group: the sum of two homomorphisms is defined by
The commutativity of "H" is needed to prove that is again a group homomorphism.

The addition of homomorphisms is compatible with the composition of homomorphisms in the following sense: if "f" is in , "h", "k" are elements of , and "g" is in , then 
Since the composition is associative, this shows that the set End("G") of all endomorphisms of an abelian group forms a ring, the "endomorphism ring" of "G". For example, the endomorphism ring of the abelian group consisting of the direct sum of "m" copies of Z/"nZ is isomorphic to the ring of "m"-by-"m" matrices with entries in Z/"nZ. The above compatibility also shows that the category of all abelian groups with group homomorphisms forms a preadditive category; the existence of direct sums and well-behaved kernels makes this category the prototypical example of an abelian category.




</doc>
<doc id="12397" url="https://en.wikipedia.org/wiki?curid=12397" title="Group isomorphism">
Group isomorphism

In abstract algebra, a group isomorphism is a function between two groups that sets up a one-to-one correspondence between the elements of the groups in a way that respects the given group operations. If there exists an isomorphism between two groups, then the groups are called isomorphic. From the standpoint of group theory, isomorphic groups have the same properties and need not be distinguished.

Given two groups (G, ∗) and (H, formula_1), a "group isomorphism" from (G, ∗) to (H, formula_1) is a bijective group homomorphism from G to H. Spelled out, this means that a group isomorphism is a bijective function formula_3 such that for all u and v in G it holds that

The two groups (G, ∗) and (H, formula_1) are isomorphic if there exists an isomorphism from one to the other. This is written:

Often shorter and simpler notations can be used. When the relevant group operations are unambiguous they are omitted and one writes:

Sometimes one can even simply write G = H. Whether such a notation is possible without confusion or ambiguity depends on context. For example, the equals sign is not very suitable when the groups are both subgroups of the same group. See also the examples.

Conversely, given a group (G, ∗), a set H, and a bijection formula_3, we can make H a group (H, formula_1) by defining

If H = G and formula_1 = ∗ then the bijection is an automorphism ("q.v.").

Intuitively, group theorists view two isomorphic groups as follows: For every element "g" of a group "G", there exists an element "h" of "H" such that "h" 'behaves in the same way' as "g" (operates with other elements of the group in the same way as "g"). For instance, if "g" generates "G", then so does "h". This implies in particular that "G" and "H" are in bijective correspondence. Thus, the definition of an isomorphism is quite natural.

An isomorphism of groups may equivalently be defined as an invertible morphism in the category of groups, where invertible here means has a two-sided inverse.

In this section some notable examples of isomorphic groups are listed.

Some groups can be proven to be isomorphic, relying on the axiom of choice, but the proof does not indicate how to construct a concrete isomorphism. Examples:

The kernel of an isomorphism from ("G", ∗) to ("H", formula_1), is always {e} where e is the identity of the group ("G", ∗)

If ("G", ∗) is isomorphic to ("H",formula_1), and if "G" is abelian then so is "H".

If ("G", ∗) is a group that is isomorphic to ("H", formula_1) [where "f" is the isomorphism], then if "a" belongs to "G" and has order "n", then so does "f(a)".

If ("G", ∗) is a locally finite group that is isomorphic to ("H", formula_1), then ("H", formula_1) is also locally finite. 

The number of distinct groups (when isomorphic groups are considered equal) of order formula_31 is given by sequence A000001 in OEIS. The first few numbers are 0, 1, 1, 1 and 2 meaning that 4 is the lowest order with more than one group.

All cyclic groups of a given order are isomorphic to formula_32.

Let "G" be a cyclic group and "n" be the order of "G". "G" is then the group generated by formula_33. 
We will show that

Define 
Then

From the definition, it follows that any isomorphism formula_3 will map the identity element of G to the identity element of H, 
that it will map inverses to inverses,
and more generally, "n"th powers to "n"th powers,
for all u in G,
and that the inverse map formula_44 is also a group isomorphism.

The relation "being isomorphic" satisfies all the axioms of an equivalence relation. If f is an isomorphism between two groups G and H, then everything that is true about G that is only related to the group structure can be translated via f into a true ditto statement about H, and vice versa.

An isomorphism from a group (G, ∗) to itself is called an automorphism of this group. Thus it is a bijection formula_45 such that

An automorphism always maps the identity to itself. The image under an automorphism of a conjugacy class is always a conjugacy class (the same or another). The image of an element has the same order as that element.

The composition of two automorphisms is again an automorphism, and with this operation the set of all automorphisms of a group G, denoted by Aut(G), forms itself a group, the "automorphism group" of G.

For all abelian groups there is at least the automorphism that replaces the group elements by their inverses. However, in groups where all elements are equal to their inverse this is the trivial automorphism, e.g. in the Klein four-group. For that group all permutations of the three non-identity elements are automorphisms, so the automorphism group is isomorphic to S and Dih.

In Z for a prime number p, one non-identity element can be replaced by any other, with corresponding changes in the other elements. The automorphism group is isomorphic to . For example, for , multiplying all elements of Z by 3, modulo 7, is an automorphism of order 6 in the automorphism group, because , while lower powers do not give 1. Thus this automorphism generates Z. There is one more automorphism with this property: multiplying all elements of Z by 5, modulo 7. Therefore, these two correspond to the elements 1 and 5 of Z, in that order or conversely.

The automorphism group of Z is isomorphic to Z, because only each of the two elements 1 and 5 generate Z, so apart from the identity we can only interchange these.

The automorphism group of has order 168, as can be found as follows. All 7 non-identity elements play the same role, so we can choose which plays the role of (1,0,0). Any of the remaining 6 can be chosen to play the role of (0,1,0). This determines which corresponds to (1,1,0). For (0,0,1) we can choose from 4, which determines the rest. Thus we have automorphisms. They correspond to those of the Fano plane, of which the 7 points correspond to the 7 non-identity elements. The lines connecting three points correspond to the group operation: "a", "b", and "c" on one line means , , and . See also general linear group over finite fields.

For abelian groups all automorphisms except the trivial one are called outer automorphisms.

Non-abelian groups have a non-trivial inner automorphism group, and possibly also outer automorphisms.




</doc>
<doc id="12398" url="https://en.wikipedia.org/wiki?curid=12398" title="Geographic information system">
Geographic information system

A geographic information system (GIS) is a system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data. GIS applications are tools that allow users to create interactive queries (user-created searches), analyze spatial information, edit data in maps, and present the results of all these operations. GIS (more commonly GIScience) sometimes refers to geographic information science (GIScience), the science underlying geographic concepts, applications, and systems.

GIS can refer to a number of different technologies, processes, techniques and methods. It is attached to many operations and has many applications related to engineering, planning, management, transport/logistics, insurance, telecommunications, and business. For that reason, GIS and location intelligence applications can be the foundation for many location-enabled services that rely on analysis and visualization.

GIS can relate unrelated information by using location as the key index variable. Locations or extents in the Earth space–time may be recorded as dates/times of occurrence, and x, y, and z coordinates representing, longitude, latitude, and elevation, respectively. All Earth-based spatial–temporal location and extent references should be relatable to one another and ultimately to a "real" physical location or extent. This key characteristic of GIS has begun to open new avenues of scientific inquiry.

The first known use of the term "geographic information system" was by Roger Tomlinson in the year 1968 in his paper "A Geographic Information System for Regional Planning". Tomlinson is also acknowledged as the "father of GIS".
Previously, one of the first applications of spatial analysis in epidemiology is the 1832 ""Rapport sur la marche et les effets du choléra dans Paris et le département de la Seine"". The French geographer Charles Picquet represented the 48 districts of the city of Paris by halftone color gradient according to the number of deaths by cholera per 1,000 inhabitants. In 1854 John Snow determined the source of a cholera outbreak in London by marking points on a map depicting where the cholera victims lived, and connecting the cluster that he found with a nearby water source. This was one of the earliest successful uses of a geographic methodology in epidemiology. While the basic elements of topography and theme existed previously in cartography, the John Snow map was unique, using cartographic methods not only to depict but also to analyze clusters of geographically dependent phenomena.

The early 20th century saw the development of photozincography, which allowed maps to be split into layers, for example one layer for vegetation and another for water. This was particularly used for printing contours – drawing these was a labour-intensive task but having them on a separate layer meant they could be worked on without the other layers to confuse the draughtsman. This work was originally drawn on glass plates but later plastic film was introduced, with the advantages of being lighter, using less storage space and being less brittle, among others. When all the layers were finished, they were combined into one image using a large process camera. Once color printing came in, the layers idea was also used for creating separate printing plates for each color. While the use of layers much later became one of the main typical features of a contemporary GIS, the photographic process just described is not considered to be a GIS in itself – as the maps were just images with no database to link them to.

Two additional developments are notable in the early days of GIS: Ian McHarg's publication ""Design with Nature"" and its map overlay method and the introduction of a street network into the U.S. Census Bureau's DIME (Dual Independent Map Encoding) system. 

Computer hardware development spurred by nuclear weapon research led to general-purpose computer "mapping" applications by the early 1960s.

The year 1960 saw the development of the world's first true operational GIS in Ottawa, Ontario, Canada, by the federal Department of Forestry and Rural Development. Developed by Dr. Roger Tomlinson, it was called the Canada Geographic Information System (CGIS) and was used to store, analyze, and manipulate data collected for the Canada Land Inventory – an effort to determine the land capability for rural Canada by mapping information about soils, agriculture, recreation, wildlife, waterfowl, forestry and land use at a scale of 1:50,000. A rating classification factor was also added to permit analysis.

CGIS was an improvement over "computer mapping" applications as it provided capabilities for overlay, measurement, and digitizing/scanning. It supported a national coordinate system that spanned the continent, coded lines as arcs having a true embedded topology and it stored the attribute and locational information in separate files. As a result of this, Tomlinson has become known as the "father of GIS", particularly for his use of overlays in promoting the spatial analysis of convergent geographic data.

CGIS lasted into the 1990s and built a large digital land resource database in Canada. It was developed as a mainframe-based system in support of federal and provincial resource planning and management. Its strength was continent-wide analysis of complex datasets. The CGIS was never available commercially.

In 1964 Howard T. Fisher formed the Laboratory for Computer Graphics and Spatial Analysis at the Harvard Graduate School of Design (LCGSA 1965–1991), where a number of important theoretical concepts in spatial data handling were developed, and which by the 1970s had distributed seminal software code and systems, such as SYMAP, GRID, and ODYSSEY – that served as sources for subsequent commercial development—to universities, research centers and corporations worldwide.

By the late 1970s two public domain GIS systems (MOSS and GRASS GIS) were in development, and by the early 1980s, M&S Computing (later Intergraph) along with Bentley Systems Incorporated for the CAD platform, Environmental Systems Research Institute (ESRI), CARIS (Computer Aided Resource Information System), MapInfo Corporation and ERDAS (Earth Resource Data Analysis System) emerged as commercial vendors of GIS software, successfully incorporating many of the CGIS features, combining the first generation approach to separation of spatial and attribute information with a second generation approach to organizing attribute data into database structures.

In 1986, Mapping Display and Analysis System (MIDAS), the first desktop GIS product was released for the DOS operating system. This was renamed in 1990 to MapInfo for Windows when it was ported to the Microsoft Windows platform. This began the process of moving GIS from the research department into the business environment.

By the end of the 20th century, the rapid growth in various systems had been consolidated and standardized on relatively few platforms and users were beginning to explore viewing GIS data over the Internet, requiring data format and transfer standards. More recently, a growing number of free, open-source GIS packages run on a range of operating systems and can be customized to perform specific tasks. Increasingly geospatial data and mapping applications are being made available via the World Wide Web (see ).

Several articles on the history of GIS have been published.

Modern GIS technologies use digital information, for which various digitized data creation methods are used. The most common method of data creation is digitization, where a hard copy map or survey plan is transferred into a digital medium through the use of a CAD program, and geo-referencing capabilities. With the wide availability of ortho-rectified imagery (from satellites, aircraft, Helikites and UAVs), heads-up digitizing is becoming the main avenue through which geographic data is extracted. Heads-up digitizing involves the tracing of geographic data directly on top of the aerial imagery instead of by the traditional method of tracing the geographic form on a separate digitizing tablet (heads-down digitizing).

GIS uses spatio-temporal (space-time) location as the key index variable for all other information. Just as a relational database containing text or numbers can relate many different tables using common key index variables, GIS can relate otherwise unrelated information by using location as the key index variable. The key is the location and/or extent in space-time.

Any variable that can be located spatially, and increasingly also temporally, can be referenced using a GIS. Locations or extents in Earth space–time may be recorded as dates/times of occurrence, and x, y, and z coordinates representing, longitude, latitude, and elevation, respectively. These GIS coordinates may represent other quantified systems of temporo-spatial reference (for example, film frame number, stream gage station, highway mile-marker, surveyor benchmark, building address, street intersection, entrance gate, water depth sounding, POS or CAD drawing origin/units). Units applied to recorded temporal-spatial data can vary widely (even when using exactly the same data, see map projections), but all Earth-based spatial–temporal location and extent references should, ideally, be relatable to one another and ultimately to a "real" physical location or extent in space–time.

Related by accurate spatial information, an incredible variety of real-world and projected past or future data can be analyzed, interpreted and represented. This key characteristic of GIS has begun to open new avenues of scientific inquiry into behaviors and patterns of real-world information that previously had not been systematically correlated.

GIS accuracy depends upon source data, and how it is encoded to be data referenced. Land surveyors have been able to provide a high level of positional accuracy utilizing the GPS-derived positions. High-resolution digital terrain and aerial imagery, powerful computers and Web technology are changing the quality, utility, and expectations of GIS to serve society on a grand scale, but nevertheless there are other source data that affect overall GIS accuracy like paper maps, though these may be of limited use in achieving the desired accuracy.

In developing a digital topographic database for a GIS, topographical maps are the main source, and aerial photography and satellite imagery are extra sources for collecting data and identifying attributes which can be mapped in layers over a location facsimile of scale. The scale of a map and geographical rendering area representation type are very important aspects since the information content depends mainly on the scale set and resulting locatability of the map's representations. In order to digitize a map, the map has to be checked within theoretical dimensions, then scanned into a raster format, and resulting raster data has to be given a theoretical dimension by a rubber sheeting/warping technology process.

A quantitative analysis of maps brings accuracy issues into focus. The electronic and other equipment used to make measurements for GIS is far more precise than the machines of conventional map analysis. All geographical data are inherently inaccurate, and these inaccuracies will propagate through GIS operations in ways that are difficult to predict.

GIS data represents real objects (such as roads, land use, elevation, trees, waterways, etc.) with digital data determining the mix. Real objects can be divided into two abstractions: discrete objects (e.g., a house) and continuous fields (such as rainfall amount, or elevations). Traditionally, there are two broad methods used to store data in a GIS for both kinds of abstractions mapping references: raster images and vector. Points, lines, and polygons are the stuff of mapped location attribute references. A new hybrid method of storing data is that of identifying point clouds, which combine three-dimensional points with RGB information at each point, returning a "3D color image". GIS thematic maps then are becoming more and more realistically visually descriptive of what they set out to show or determine.

For a list of popular GIS file formats, such as shapefiles, see .

Data capture—entering information into the system—consumes much of the time of GIS practitioners. There are a variety of methods used to enter data into a GIS where it is stored in a digital format.

Existing data printed on paper or PET film maps can be digitized or scanned to produce digital data. A digitizer produces vector data as an operator traces points, lines, and polygon boundaries from a map. Scanning a map results in raster data that could be further processed to produce vector data.

Survey data can be directly entered into a GIS from digital data collection systems on survey instruments using a technique called coordinate geometry (COGO). Positions from a global navigation satellite system (GNSS) like Global Positioning System can also be collected and then imported into a GIS. A current trend in data collection gives users the ability to utilize field computers with the ability to edit live data using wireless connections or disconnected editing sessions. This has been enhanced by the availability of low-cost mapping-grade GPS units with decimeter accuracy in real time. This eliminates the need to post process, import, and update the data in the office after fieldwork has been collected. This includes the ability to incorporate positions collected using a laser rangefinder. New technologies also allow users to create maps as well as analysis directly in the field, making projects more efficient and mapping more accurate.

Remotely sensed data also plays an important role in data collection and consist of sensors attached to a platform. Sensors include cameras, digital scanners and lidar, while platforms usually consist of aircraft and satellites. In England in the mid 1990s, hybrid kite/balloons called helikites first pioneered the use of compact airborne digital cameras as airborne geo-information systems. Aircraft measurement software, accurate to 0.4 mm was used to link the photographs and measure the ground. Helikites are inexpensive and gather more accurate data than aircraft. Helikites can be used over roads, railways and towns where unmanned aerial vehicles (UAVs) are banned.

Recently aerial data collection is becoming possible with miniature UAVs. For example, the Aeryon Scout was used to map a 50-acre area with a ground sample distance of in only 12 minutes.

The majority of digital data currently comes from photo interpretation of aerial photographs. Soft-copy workstations are used to digitize features directly from stereo pairs of digital photographs. These systems allow data to be captured in two and three dimensions, with elevations measured directly from a stereo pair using principles of photogrammetry. Analog aerial photos must be scanned before being entered into a soft-copy system, for high-quality digital cameras this step is skipped.

Satellite remote sensing provides another important source of spatial data. Here satellites use different sensor packages to passively measure the reflectance from parts of the electromagnetic spectrum or radio waves that were sent out from an active sensor such as radar. Remote sensing collects raster data that can be further processed using different bands to identify objects and classes of interest, such as land cover.

When data is captured, the user should consider if the data should be captured with either a relative accuracy or absolute accuracy, since this could not only influence how information will be interpreted but also the cost of data capture.

After entering data into a GIS, the data usually requires editing, to remove errors, or further processing. For vector data it must be made "topologically correct" before it can be used for some advanced analysis. For example, in a road network, lines must connect with nodes at an intersection. Errors such as undershoots and overshoots must also be removed. For scanned maps, blemishes on the source map may need to be removed from the resulting raster. For example, a fleck of dirt might connect two lines that should not be connected.

Data restructuring can be performed by a GIS to convert data into different formats. For example, a GIS may be used to convert a satellite image map to a vector structure by generating lines around all cells with the same classification, while determining the cell spatial relationships, such as adjacency or inclusion.

More advanced data processing can occur with image processing, a technique developed in the late 1960s by NASA and the private sector to provide contrast enhancement, false color rendering and a variety of other techniques including use of two dimensional Fourier transforms. Since digital data is collected and stored in various ways, the two data sources may not be entirely compatible. So a GIS must be able to convert geographic data from one structure to another. In so doing, the implicit assumptions behind different ontologies and classifications require analysis. Object ontologies have gained increasing prominence as a consequence of object-oriented programming and sustained work by Barry Smith and co-workers.

The earth can be represented by various models, each of which may provide a different set of coordinates (e.g., latitude, longitude, elevation) for any given point on the Earth's surface. The simplest model is to assume the earth is a perfect sphere. As more measurements of the earth have accumulated, the models of the earth have become more sophisticated and more accurate. In fact, there are models called datums that apply to different areas of the earth to provide increased accuracy, like NAD83 for U.S. measurements, and the World Geodetic System for worldwide measurements.

GIS spatial analysis is a rapidly changing field, and GIS packages are increasingly including analytical tools as standard built-in facilities, as optional toolsets, as add-ins or 'analysts'. In many instances these are provided by the original software suppliers (commercial vendors or collaborative non commercial development teams), while in other cases facilities have been developed and are provided by third parties. Furthermore, many products offer software development kits (SDKs), programming languages and language support, scripting facilities and/or special interfaces for developing one's own analytical tools or variants. The increased availability has created a new dimension to business intelligence termed "spatial intelligence" which, when openly delivered via intranet, democratizes access to geographic and social network data. Geospatial intelligence, based on GIS spatial analysis, has also become a key element for security. GIS as a whole can be described as conversion to a vectorial representation or to any other digitisation process.

Slope can be defined as the steepness or gradient of a unit of terrain, usually measured as an angle in degrees or as a percentage. Aspect can be defined as the direction in which a unit of terrain faces. Aspect is usually expressed in degrees from north. Slope, aspect, and surface curvature in terrain analysis are all derived from neighborhood operations using elevation values of a cell's adjacent neighbours. Slope is a function of resolution, and the spatial resolution used to calculate slope and aspect should always be specified. Various authors have compared techniques for calculating slope and aspect.

The following method can be used to derive slope and aspect:

The elevation at a point or unit of terrain will have perpendicular tangents (slope) passing through the point, in an east-west and north-south direction. These two tangents give two components, ∂z/∂x and ∂z/∂y, which then be used to determine the overall direction of slope, and the aspect of the slope. The gradient is defined as a vector quantity with components equal to the partial derivatives of the surface in the x and y directions.

The calculation of the overall 3x3 grid slope "S" and aspect "A" for methods that determine east-west and north-south component use the following formulas respectively:

formula_1

formula_2

Zhou and Liu describe another formula for calculating aspect, as follows:

formula_3

It is difficult to relate wetlands maps to rainfall amounts recorded at different points such as airports, television stations, and schools. A GIS, however, can be used to depict two- and three-dimensional characteristics of the Earth's surface, subsurface, and atmosphere from information points. For example, a GIS can quickly generate a map with isopleth or contour lines that indicate differing amounts of rainfall. Such a map can be thought of as a rainfall contour map. Many sophisticated methods can estimate the characteristics of surfaces from a limited number of point measurements. A two-dimensional contour map created from the surface modeling of rainfall point measurements may be overlaid and analyzed with any other map in a GIS covering the same area. This GIS derived map can then provide additional information - such as the viability of water power potential as a renewable energy source. Similarly, GIS can be used to compare other renewable energy resources to find the best geographic potential for a region.

Additionally, from a series of three-dimensional points, or digital elevation model, isopleth lines representing elevation contours can be generated, along with slope analysis, shaded relief, and other elevation products. Watersheds can be easily defined for any given reach, by computing all of the areas contiguous and uphill from any given point of interest. Similarly, an expected thalweg of where surface water would want to travel in intermittent and permanent streams can be computed from elevation data in the GIS.

A GIS can recognize and analyze the spatial relationships that exist within digitally stored spatial data. These topological relationships allow complex spatial modelling and analysis to be performed. Topological relationships between geometric entities traditionally include adjacency (what adjoins what), containment (what encloses what), and proximity (how close something is to something else).

Geometric networks are linear networks of objects that can be used to represent interconnected features, and to perform special spatial analysis on them. A geometric network is composed of edges, which are connected at junction points, similar to graphs in mathematics and computer science. Just like graphs, networks can have weight and flow assigned to its edges, which can be used to represent various interconnected features more accurately. Geometric networks are often used to model road networks and public utility networks, such as electric, gas, and water networks. Network modeling is also commonly employed in transportation planning, hydrology modeling, and infrastructure modeling.

GIS hydrological models can provide a spatial element that other hydrological models lack, with the analysis of variables such as slope, aspect and watershed or catchment area. Terrain analysis is fundamental to hydrology, since water always flows down a slope. As basic terrain analysis of a digital elevation model (DEM) involves calculation of slope and aspect, DEMs are very useful for hydrological analysis. Slope and aspect can then be used to determine direction of surface runoff, and hence flow accumulation for the formation of streams, rivers and lakes. Areas of divergent flow can also give a clear indication of the boundaries of a catchment. Once a flow direction and accumulation matrix has been created, queries can be performed that show contributing or dispersal areas at a certain point. More detail can be added to the model, such as terrain roughness, vegetation types and soil types, which can influence infiltration and evapotranspiration rates, and hence influencing surface flow. One of the main uses of hydrological modeling is in environmental contamination research. Other applications of hydrological modeling include groundwater and surface water mapping, as well as flood risk maps.

Dana Tomlin probably coined the term "cartographic modeling" in his PhD dissertation (1983); he later used it in the title of his book, "Geographic Information Systems and Cartographic Modeling" (1990).
Cartographic modeling refers to a process where several thematic layers of the same area are produced, processed, and analyzed. Tomlin used raster layers, but the overlay method (see below) can be used more generally. Operations on map layers can be combined into algorithms, and eventually into simulation or optimization models.

The combination of several spatial datasets (points, lines, or polygons) creates a new output vector dataset, visually similar to stacking several maps of the same region. These overlays are similar to mathematical Venn diagram overlays. A union overlay combines the geographic features and attribute tables of both inputs into a single new output. An intersect overlay defines the area where both inputs overlap and retains a set of attribute fields for each. A symmetric difference overlay defines an output area that includes the total area of both inputs except for the overlapping area.

Data extraction is a GIS process similar to vector overlay, though it can be used in either vector or raster data analysis. Rather than combining the properties and features of both datasets, data extraction involves using a "clip" or "mask" to extract the features of one data set that fall within the spatial extent of another dataset.

In raster data analysis, the overlay of datasets is accomplished through a process known as "local operation on multiple rasters" or "map algebra", through a function that combines the values of each raster's matrix. This function may weigh some inputs more than others through use of an "index model" that reflects the influence of various factors upon a geographic phenomenon.

Geostatistics is a branch of statistics that deals with field data, spatial data with a continuous index. It provides methods to model spatial correlation, and predict values at arbitrary locations (interpolation).

When phenomena are measured, the observation methods dictate the accuracy of any subsequent analysis. Due to the nature of the data (e.g. traffic patterns in an urban environment; weather patterns over the Pacific Ocean), a constant or dynamic degree of precision is always lost in the measurement. This loss of precision is determined from the scale and distribution of the data collection.

To determine the statistical relevance of the analysis, an average is determined so that points (gradients) outside of any immediate measurement can be included to determine their predicted behavior. This is due to the limitations of the applied statistic and data collection methods, and interpolation is required to predict the behavior of particles, points, and locations that are not directly measurable.

Interpolation is the process by which a surface is created, usually a raster dataset, through the input of data collected at a number of sample points. There are several forms of interpolation, each which treats the data differently, depending on the properties of the data set. In comparing interpolation methods, the first consideration should be whether or not the source data will change (exact or approximate). Next is whether the method is subjective, a human interpretation, or objective. Then there is the nature of transitions between points: are they abrupt or gradual. Finally, there is whether a method is global (it uses the entire data set to form the model), or local where an algorithm is repeated for a small section of terrain.

Interpolation is a justified measurement because of a spatial autocorrelation principle that recognizes that data collected at any position will have a great similarity to, or influence of those locations within its immediate vicinity.

Digital elevation models, triangulated irregular networks, edge-finding algorithms, Thiessen polygons, Fourier analysis, (weighted) moving averages, inverse distance weighting, kriging, spline, and trend surface analysis are all mathematical methods to produce interpolative data.

Geocoding is interpolating spatial locations (X,Y coordinates) from street addresses or any other spatially referenced data such as ZIP Codes, parcel lots and address locations. A reference theme is required to geocode individual addresses, such as a road centerline file with address ranges. The individual address locations have historically been interpolated, or estimated, by examining address ranges along a road segment. These are usually provided in the form of a table or database. The software will then place a dot approximately where that address belongs along the segment of centerline. For example, an address point of 500 will be at the midpoint of a line segment that starts with address 1 and ends with address 1,000. Geocoding can also be applied against actual parcel data, typically from municipal tax maps. In this case, the result of the geocoding will be an actually positioned space as opposed to an interpolated point. This approach is being increasingly used to provide more precise location information.

Reverse geocoding is the process of returning an estimated street address number as it relates to a given coordinate. For example, a user can click on a road centerline theme (thus providing a coordinate) and have information returned that reflects the estimated house number. This house number is interpolated from a range assigned to that road segment. If the user clicks at the midpoint of a segment that starts with address 1 and ends with 100, the returned value will be somewhere near 50. Note that reverse geocoding does not return actual addresses, only estimates of what should be there based on the predetermined range.

Coupled with GIS, multi-criteria decision analysis methods support decision-makers in analysing a set of alternative spatial solutions, such as the most likely ecological habitat for restoration, against multiple criteria, such as vegetation cover or roads. MCDA uses decision rules to aggregate the criteria, which allows the alternative solutions to be ranked or prioritised. GIS MCDA may reduce costs and time involved in identifying potential restoration sites.

Cartography is the design and production of maps, or visual representations of spatial data. The vast majority of modern cartography is done with the help of computers, usually using GIS but production of quality cartography is also achieved by importing layers into a design program to refine it. Most GIS software gives the user substantial control over the appearance of the data.

Cartographic work serves two major functions:

First, it produces graphics on the screen or on paper that convey the results of analysis to the people who make decisions about resources. Wall maps and other graphics can be generated, allowing the viewer to visualize and thereby understand the results of analyses or simulations of potential events. Web Map Servers facilitate distribution of generated maps through web browsers using various implementations of web-based application programming interfaces (AJAX, Java, Flash, etc.).

Second, other database information can be generated for further analysis or use. An example would be a list of all addresses within one mile (1.6 km) of a toxic spill.

Traditional maps are abstractions of the real world, a sampling of important elements portrayed on a sheet of paper with symbols to represent physical objects. People who use maps must interpret these symbols. Topographic maps show the shape of land surface with contour lines or with shaded relief.

Today, graphic display techniques such as shading based on altitude in a GIS can make relationships among map elements visible, heightening one's ability to extract and analyze information. For example, two types of data were combined in a GIS to produce a perspective view of a portion of San Mateo County, California.

A GIS was used to register and combine the two images to render the three-dimensional perspective view looking down the San Andreas Fault, using the Thematic Mapper image pixels, but shaded using the elevation of the landforms. The GIS display depends on the viewing point of the observer and time of day of the display, to properly render the shadows created by the sun's rays at that latitude, longitude, and time of day.

An archeochrome is a new way of displaying spatial data. It is a thematic on a 3D map that is applied to a specific building or a part of a building. It is suited to the visual display of heat-loss data.

Spatial ETL tools provide the data processing functionality of traditional extract, transform, load (ETL) software, but with a primary focus on the ability to manage spatial data. They provide GIS users with the ability to translate data between different standards and proprietary formats, whilst geometrically transforming the data en route. These tools can come in the form of add-ins to existing wider-purpose software such as spreadsheets.

GIS or spatial data mining is the application of data mining methods to spatial data. Data mining, which is the partially automated search for hidden patterns in large databases, offers great potential benefits for applied GIS-based decision making. Typical applications include environmental monitoring. A characteristic of such applications is that spatial correlation between data measurements require the use of specialized algorithms for more efficient data analysis.

The implementation of a GIS is often driven by jurisdictional (such as a city), purpose, or application requirements. Generally, a GIS implementation may be custom-designed for an organization. Hence, a GIS deployment developed for an application, jurisdiction, enterprise, or purpose may not be necessarily interoperable or compatible with a GIS that has been developed for some other application, jurisdiction, enterprise, or purpose.

GIS provides, for every kind of location-based organization, a platform to update geographical data without wasting time to visit the field and update a database manually. GIS when integrated with other powerful enterprise solutions like SAP and the Wolfram Language helps creating powerful decision support system at enterprise level.
Many disciplines can benefit from GIS technology. An active GIS market has resulted in lower costs and continual improvements in the hardware and software components of GIS, and usage in the fields of science, government, business, and industry, with applications including real estate, public health, crime mapping, national defense, sustainable development, natural resources, climatology, landscape architecture, archaeology, regional and community planning, transportation and logistics. GIS is also diverging into location-based services, which allows GPS-enabled mobile devices to display their location in relation to fixed objects (nearest restaurant, gas station, fire hydrant) or mobile objects (friends, children, police car), or to relay their position back to a central server for display or other processing.

The Open Geospatial Consortium (OGC) is an international industry consortium of 384 companies, government agencies, universities, and individuals participating in a consensus process to develop publicly available geoprocessing specifications. Open interfaces and protocols defined by OpenGIS Specifications support interoperable solutions that "geo-enable" the Web, wireless and location-based services, and mainstream IT, and empower technology developers to make complex spatial information and services accessible and useful with all kinds of applications. Open Geospatial Consortium protocols include Web Map Service, and Web Feature Service.

GIS products are broken down by the OGC into two categories, based on how completely and accurately the software follows the OGC specifications.
"Compliant Products" are software products that comply to OGC's OpenGIS Specifications. When a product has been tested and certified as compliant through the OGC Testing Program, the product is automatically registered as "compliant" on this site.

"Implementing Products" are software products that implement OpenGIS Specifications but have not yet passed a compliance test. Compliance tests are not available for all specifications. Developers can register their products as implementing draft or approved specifications, though OGC reserves the right to review and verify each entry.

In recent years there has been a proliferation of free-to-use and easily accessible mapping software such as the proprietary web applications Google Maps and Bing Maps, as well as the free and open-source alternative OpenStreetMap. These services give the public access to huge amounts of geographic data; perceived by many users to be as trustworthy and usable as professional information.

Some of them, like Google Maps and OpenLayers, expose an application programming interface (API) that enable users to create custom applications. These toolkits commonly offer street maps, aerial/satellite imagery, geocoding, searches, and routing functionality. Web mapping has also uncovered the potential of crowdsourcing geodata in projects like OpenStreetMap, which is a collaborative project to create a free editable map of the world. These mashup projects have been proven to provide a high level of value and benefit to end users outside that possible through traditional geographic information.

The condition of the Earth's surface, atmosphere, and subsurface can be examined by feeding satellite data into a GIS. GIS technology gives researchers the ability to examine the variations in Earth processes over days, months, and years. As an example, the changes in vegetation vigor through a growing season can be animated to determine when drought was most extensive in a particular region. The resulting graphic represents a rough measure of plant health. Working with two variables over time would then allow researchers to detect regional differences in the lag between a decline in rainfall and its effect on vegetation.

GIS technology and the availability of digital data on regional and global scales enable such analyses. The satellite sensor output used to generate a vegetation graphic is produced for example by the advanced very-high-resolution radiometer (AVHRR). This sensor system detects the amounts of energy reflected from the Earth's surface across various bands of the spectrum for surface areas of about 1 square kilometer. The satellite sensor produces images of a particular location on the Earth twice a day. AVHRR and more recently the moderate-resolution imaging spectroradiometer (MODIS) are only two of many sensor systems used for Earth surface analysis.

In addition to the integration of time in environmental studies, GIS is also being explored for its ability to track and model the progress of humans throughout their daily routines. A concrete example of progress in this area is the recent release of time-specific population data by the U.S. Census. In this data set, the populations of cities are shown for daytime and evening hours highlighting the pattern of concentration and dispersion generated by North American commuting patterns. The manipulation and generation of data required to produce this data would not have been possible without GIS.

Using models to project the data held by a GIS forward in time have enabled planners to test policy decisions using spatial decision support systems.

Tools and technologies emerging from the World Wide Web Consortium's Semantic Web are proving useful for data integration problems in information systems. Correspondingly, such technologies have been proposed as a means to facilitate interoperability and data reuse among GIS applications. and also to enable new analysis mechanisms.

Ontologies are a key component of this semantic approach as they allow a formal, machine-readable specification of the concepts and relationships in a given domain. This in turn allows a GIS to focus on the intended meaning of data rather than its syntax or structure. For example, reasoning that a land cover type classified as "deciduous needleleaf trees" in one dataset is a specialization or subset of land cover type "forest" in another more roughly classified dataset can help a GIS automatically merge the two datasets under the more general land cover classification. Tentative ontologies have been developed in areas related to GIS applications, for example the hydrology ontology developed by the Ordnance Survey in the United Kingdom and the SWEET ontologies developed by NASA's Jet Propulsion Laboratory. Also, simpler ontologies and semantic metadata standards are being proposed by the W3C Geo Incubator Group to represent geospatial data on the web. GeoSPARQL is a standard developed by the Ordnance Survey, United States Geological Survey, Natural Resources Canada, Australia's Commonwealth Scientific and Industrial Research Organisation and others to support ontology creation and reasoning using well-understood OGC literals (GML, WKT), topological relationships (Simple Features, RCC8, DE-9IM), RDF and the SPARQL database query protocols.

Recent research results in this area can be seen in the International Conference on Geospatial Semantics and the Terra Cognita – Directions to the Geospatial Semantic Web workshop at the International Semantic Web Conference.

With the popularization of GIS in decision making, scholars have begun to scrutinize the social and political implications of GIS. GIS can also be misused to distort reality for individual and political gain. It has been argued that the production, distribution, utilization, and representation of geographic information are largely related with the social context and has the potential to increase citizen trust in government. Other related topics include discussion on copyright, privacy, and censorship. A more optimistic social approach to GIS adoption is to use it as a tool for public participation.

At the end of the 20th century, GIS began to be recognized as tools that could be used in the classroom. The benefits of GIS in education seem focused on developing spatial thinking, but there is not enough bibliography or statistical data to show the concrete scope of the use of GIS in education around the world, although the expansion has been faster in those countries where the curriculum mentions them.

GIS seem to provide many advantages in teaching geography because they allow for analyses based on real geographic data and also help raise many research questions from teachers and students in classrooms, as well as they contribute to improvement in learning by developing spatial and geographical thinking and, in many cases, student motivation.

GIS is proven as an organization-wide, enterprise and enduring technology that continues to change how local government operates. Government agencies have adopted GIS technology as a method to better manage the following areas of government organization:
The Open Data initiative is pushing local government to take advantage of technology such as GIS technology, as it encompasses the requirements to fit the Open Data/Open Government model of transparency. With Open Data, local government organizations can implement Citizen Engagement applications and online portals, allowing citizens to see land information, report potholes and signage issues, view and sort parks by assets, view real-time crime rates and utility repairs, and much more. The push for open data within government organizations is driving the growth in local government GIS technology spending, and database management.




</doc>
<doc id="12401" url="https://en.wikipedia.org/wiki?curid=12401" title="Graph theory">
Graph theory

In mathematics, graph theory is the study of "graphs", which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of "vertices" (also called "nodes" or "points") which are connected by "edges" (also called "links" or "lines"). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically; see Graph (discrete mathematics) for more detailed definitions and for other variations in the types of graph that are commonly considered. Graphs are one of the prime objects of study in discrete mathematics.

Refer to the glossary of graph theory for basic definitions in graph theory.

Definitions in graph theory vary. The following are some of the more basic ways of defining graphs and related mathematical structures.

In one restricted but very common sense of the term, a graph is an ordered pair comprising:


</doc>
<doc id="12405" url="https://en.wikipedia.org/wiki?curid=12405" title="Gumby">
Gumby

Gumby is an American clay animation franchise, centered on a green clay humanoid character created and modeled by Art Clokey. The character has been the subject of two television series, a feature-length film and other media. Since the original series aired, Gumby has become a famous example of stop-motion clay animation and an influential cultural icon, spawning tributes, parodies and merchandising.

"Gumby" follows the titular character on his adventures through different environments and times in history. Gumby's primary sidekick is Pokey, a talking orange pony. His nemeses are the G and J Blockheads, a pair of antagonistic red humanoid figures with cube-shaped heads, one with the letter G on the block, the other with the letter J. The blockheads were inspired by the trouble-making Katzenjammer Kids. Other characters include Prickle, a yellow dinosaur who sometimes styles himself as a detective with pipe and deerstalker hat like Sherlock Holmes; Goo, a flying blue mermaid who spits blue goo balls and can change shape at will; Gumbo and Gumba, Gumby's parents; and Nopey, Gumby's dog whose entire vocabulary is the word "nope". The 1988 syndicated series added Gumby's sister Minga, mastodon friend Denali and chicken friend Tilly.

Gumby was created by Art Clokey in the early 1950s after he finished film school at the University of Southern California (USC).

Clokey's first animated film was a 1953 three-minute student film called "Gumbasia", a surreal montage of moving and expanding lumps of clay set to music in a parody of Disney's "Fantasia". "Gumbasia" was created in the "kinesthetic" style taught by Clokey's USC professor Slavko Vorkapić, described as "massaging of the eye cells." Much of Gumby's look and feel was inspired by this technique of camera movements and editing.

In 1955, Clokey showed "Gumbasia" to movie producer Sam Engel, who encouraged him to develop his technique by animating figures into children's stories. Clokey moved forward, producing a pilot episode featuring the character Gumby.

The name "Gumby" came from the muddy clay found at Clokey's grandparents' farm that his family called "gumbo". Gumby's appearance was inspired by a suggestion from his wife, Ruth (née Parkander), that Gumby be based on the Gingerbread Man. The color green was then chosen because Clokey saw it as both racially neutral and a symbol of life. Gumby's legs and feet were made wide for pragmatic reasons; they ensured that the character would stand up during stop-motion filming. Gumby's famous slanted head was based on the hairstyle of Clokey's father, Charles Farrington, in an old photograph.

Clokey's pilot episode was seen by NBC executive Thomas Warren Sarnoff, who asked Clokey to make another one. The second episode, "Gumby on the Moon", became a huge hit on "Howdy Doody", leading Sarnoff to order a series in 1955 entitled "The Gumby Show". In 1955 and 1956, 25 eleven-minute episodes aired on NBC. In early episodes, Gumby's voice was provided by Ruth Eggleston, wife of the show's art director Al Eggleston, until Dallas McKennon assumed her role in 1957. Gumby's best friend, an orange pony named Pokey, was introduced during the earliest episodes. Because of its variety-type format, "The Gumby Show" featured not only Clokey's puppet films, but also interviews and games. During this time, the show went through a succession of two hosts, Robert Nicholson and Pinky Lee.

In 1959, "The Gumby Show" entered syndication, and more episodes were produced in the 1960s. Production started in Hollywood and in 1960 moved to a larger studio in Glendora, California, where it remained until production ended in 1969. During this time, Gumby was primarily voiced by Norma MacMillan, and occasionally by Ginny Tyler. The cartoon shorts introduced new characters including a blue mermaid named Goo and a yellow dinosaur named Prickle.

Beginning in 1982, Gumby was parodied by Eddie Murphy on "Saturday Night Live". According to Murphy’s parody, when the television cameras were turned off, the sweet Gumby reverted to his true self: an irascible, cigar-chomping celebrity who was highly demanding of the production executives. Whenever the executives refused to give in to his demands, Gumby would assert his star status by saying “I’m "Gumby", dammit!"

In 1987, the original Gumby shorts enjoyed a revival on home video. The following year, Gumby appeared in "The Puppetoon Movie".

This renewed interest led to a reincarnation of the series consisting of 99 new seven-minute episodes produced for television syndication in association with Lorimar-Telepictures in 1987. Dallas McKennon returned to voice Gumby in the new adventures, in which Gumby and his pals traveled beyond their toyland-type setting and established themselves as a musical band. The show also included new characters, such as Gumby's little sister Minga, a mastodon named Denali and a chicken named Tilly.

In addition to the new episodes, the 1950s and 1960s shorts were included in the series, but with new audio. The voices were re-recorded and the original music was replaced by Jerry Gerber's synthesizer score from the 1987 series. Legal issues prevented Clokey from renewing rights to the original Capitol Records production tracks.

Starting in 1992, TV channels such as Nickelodeon and Cartoon Network aired reruns of "Gumby" episodes. In 1995, Clokey's production company produced an independently released theatrical film, "", marking the character's first feature-length adventure. In it, the villainous Blockheads replace Gumby and his band with robots and kidnap their dog, Lowbelly. The movie featured in-joke homages to science-fiction films such as "Star Wars", "The Terminator" and "", Red Heat. In 1998, the "Gumby" episode "Robot Rumpus" was featured on "Mystery Science Theater 3000".

On March 16, 2007, YouTube announced that all Gumby episodes would appear in their full-length form on its site, digitally remastered and with their original soundtracks. This deal also extended to other video sites, including AOL. In March 2007, KQED-TV broadcast an hour-long documentary "Gumby Dharma" as part of its "Truly CA" series.

In 2012, Me-TV began airing "Gumby" on weekend morning, in its weekend morning animation block. The show remained part of the channel's programming until the end of the year.

On April 8, 2015, it was announced that a new "Gumby" series was in the works, co-produced by the Jim Henson Company.


In 1993, "TV Guide" named "Gumby" the best cartoon series of the 1950s in its issue celebrating 40 years of television.

Beginning in 1994, the Library of Congress used Gumby as a "spokescharacter" for "Adventures into Books: Gumby's World", a traveling exhibition that promoted the Center for the Book's national reading campaign from 1997 to 2000. By the end of the 1990s, Gumby and Pokey had also appeared in various commercials for Cheerios cereal, most notably Frosted Cheerios.

In 2005, "Gumby" made a cameo in a couch gag from the 358th episode of the animated sitcom "The Simpsons".

On August 4, 2006, the Center for Puppetry Arts in Atlanta opened "Art Clokey's Gumby: The First Fifty Years". This exhibition featured many of the original puppets and sets, along with screening of Art Clokey's films. This event was conceived by David Scheve of T.D.A. Animation and Joe Clokey of Premavision, and was one of several exhibits that opened around the country, celebrating the 50th anniversary of "The Gumby Show". The children's book "Gumby Goes to the Sun" was also published that year to commemorate the anniversary. The book was originally created in the 1980s by Clokey's daughter, Holly Harman.

In 2007, the "Gumby" comic book series was nominated for two Eisner Awards, Best New Series and Best Publication for a Young Audience, and won the latter.

On October 12, 2011, Google paid tribute to Art Clokey’s 90th birthday with a doodle featuring clay balls transforming into characters from the show. The doodle was composed of a toy block with a "G" and five clay balls in the Google colors. Clicking each of the balls revealed the Blockheads, Prickle, Goo, Gumby and Pokey.

In a 2014 episode of Disney XD's "Gravity Falls" called "Little Gift Shop of Horrors", the character of Soos Ramirez appears in the "Clay Day" segment resembling Gumby.

Various Gumby merchandise has been produced over the years, the most prominent item being bendable figures by Lakeside Toys, headquartered in Minneapolis, Minnesota. Several single packs and multi-figure sets by Jesco (later Trendmasters), as well as a 50th anniversary collection, have been made of the Gumby characters. Also included in the Gumby merchandise catalog are plush dolls, keychains, mugs, a 1988 Colorforms set, a 1995 Trendmasters playset and a Kubricks set by Medicom. A tribute album, "Gumby: The Green Album", produced by Shepard Stern, was released in 1989 through Buena Vista Records.

In August 2005, the first video game featuring Gumby, "Gumby vs. the Astrobots", was released by Namco for the Game Boy Advance. In it, Gumby must rescue Pokey, Prickle and Goo after they are captured by the Blockheads and their cohorts, the Astrobots.

The Gumby images and toys are registered trademarks of Prema Toy Company. Premavision owned the distribution rights to the "Gumby" cartoons, having been reverted from previous distributor Warner Bros. Television in 2003, and had licensed the rights to Classic Media until September 30, 2012. At this time, Classic Media was officially acquired by DreamWorks Animation and branded as DreamWorks Classics, which became a subsidiary of NBCUniversal in 2016. As of April 2015, NCircle Entertainment owns home video and digital distribution rights to the cartoons.




</doc>
<doc id="12406" url="https://en.wikipedia.org/wiki?curid=12406" title="Gioachino Rossini">
Gioachino Rossini

Gioachino Antonio Rossini (; 29 February 1792 – 13 November 1868) was an Italian composer who gained fame for his 39 operas, although he also wrote many songs, some chamber music and piano pieces, and some sacred music. He set new standards for both comic and serious opera before retiring from large-scale composition while still in his thirties, at the height of his popularity.

Born in Pesaro to parents who were both musicians (his father a trumpeter, his mother a singer), Rossini began to compose by the age of 12 and was educated at music school in Bologna. His first opera was performed in Venice in 1810 when he was 18 years old. In 1815 he was engaged to write operas and manage theatres in Naples. In the period 1810–1823 he wrote 34 operas for the Italian stage that were performed in Venice, Milan, Ferrara, Naples and elsewhere; this productivity necessitated an almost formulaic approach for some components (such as overtures) and a certain amount of self-borrowing. During this period he produced his most popular works including the comic operas "L'italiana in Algeri", "Il barbiere di Siviglia" (known in English as "The Barber of Seville") and "La Cenerentola", which brought to a peak the "opera buffa" tradition he inherited from masters such as Domenico Cimarosa. He also composed "opera seria" works such as "Otello", "Tancredi" and "Semiramide". All of these attracted admiration for their innovation in melody, harmonic and instrumental colour, and dramatic form. In 1824 he was contracted by the Opéra in Paris, for which he produced an opera to celebrate the coronation of Charles X, "Il viaggio a Reims" (later cannibalised for his first opera in French, "Le comte Ory"), revisions of two of his Italian operas, "Le siège de Corinthe" and "Moïse", and in 1829 his last opera, "Guillaume Tell".

Rossini's withdrawal from opera for the last 40 years of his life has never been fully explained; contributary factors may have been ill-health, the wealth his success had brought him, and the rise of spectacular Grand Opera under composers such as Giacomo Meyerbeer. From the early 1830s to 1855, when he left Paris and was based in Bologna, Rossini wrote relatively little. On his return to Paris in 1855 he became renowned for his musical salons on Saturdays, regularly attended by musicians and the artistic and fashionable circles of Paris, for which he wrote the entertaining pieces "Péchés de vieillesse." Guests included Franz Liszt, Anton Rubinstein, Giuseppe Verdi, Meyerbeer and Joseph Joachim. Rossini's last major composition was his "Petite messe solennelle" (1863). He died in Paris in 1868.

Rossini was born in 1792 in Pesaro, a town on the Adriatic coast of Italy that was then part of the Papal States. He was the only child of Giuseppe Rossini, a trumpeter and horn player, and his wife Anna, "née" Guidarini, a seamstress by trade, daughter of a baker. Giuseppe Rossini was charming but impetuous and feckless; the burden of supporting the family and raising the child fell mainly on Anna, with some help from her mother and mother-in-law. Stendhal, who published a colourful biography of Rossini in 1824, wrote:

Giuseppe was imprisoned at least twice: first in 1790 for insubordination to local authorities in a dispute about his employment as town trumpeter; and in 1799 and 1800 for republican activism and support of the troops of Napoleon against the Pope's Austrian backers. In 1798, when Rossini was aged six, his mother began a career as a professional singer in comic opera, and for a little over a decade was a considerable success in cities including Trieste and Bologna, before her untrained voice began to fail.

In 1802 the family moved to Lugo, near Ravenna, where Rossini received a good basic education in Italian, Latin and arithmetic as well as music. He studied the horn with his father and other music with a priest, Giuseppe Malerbe, whose extensive library contained works by Haydn and Mozart, both little known in Italy at the time, but inspirational to the young Rossini. He was a quick learner, and by the age of twelve he had composed a set of six sonatas for four stringed instruments, which were performed under the aegis of a rich patron in 1804. Two years later he was admitted to the recently-opened Liceo Musicale, Bologna, initially studying singing, cello and piano, and joining the composition class soon afterwards. He wrote some substantial works while a student, including a mass and a cantata, and after two years he was invited to continue his studies. He declined the offer: the strict academic regime of the Liceo had given him a solid compositional technique, but as his biographer Richard Osborne puts it, "his instinct to continue his education in the real world finally asserted itself".

While still at the Liceo, Rossini had performed in public as a singer and worked in theatres as a répétiteur and keyboard soloist. In 1810 at the request of the popular tenor Domenico Mombelli he wrote his first operatic score, a two-act operatic "dramma serio", "Demetrio e Polibio", to a libretto by Mombelli's wife. It was publicly staged in 1812, after the composer's first successes. Rossini and his parents concluded that his future lay in composing operas. The main operatic centre in north eastern Italy was Venice; under the tutelage of the composer Giovanni Morandi, a family friend, Rossini moved there in late 1810, when he was eighteen.

Rossini's first opera to be staged was "La cambiale di matrimonio", a one-act comedy, given at the small Teatro San Moisè in November 1810. The piece was a great success, and Rossini received what then seemed to him a considerable sum: "forty "scudi" – an amount I had never seen brought together". He later described the San Moisè as an ideal theatre for a young composer learning his craft – "everything tended to facilitate the début of a novice composer": it had no chorus, and a small company of principals; its main repertoire consisted of one-act comic operas ("farse"), staged with modest scenery and minimal rehearsal. Rossini followed the success of his first piece with three more "farse" for the house: "L'inganno felice" (1812), "La scala di seta" (1812), and "Il signor Bruschino" (1813).

Rossini maintained his links with Bologna, where in 1811 he had a success directing Haydn's "The Seasons", and a failure with his first full-length opera, "L'equivoco stravagante". He also worked for opera houses in Ferrara and Rome. In mid-1812 he received a commission from La Scala, Milan, where his two-act comedy "La pietra del paragone" ran for fifty-three performances, a considerable run for the time, which brought him not only financial benefits, but exemption from military service and the title of "maestro di cartello" – a composer whose name on advertising posters guaranteed a full house. The following year his first "opera seria", "Tancredi", did well at La Fenice in Venice, and even better at Ferrara, with a rewritten, tragic ending. The success of "Tancredi" made Rossini's name known internationally; productions of the opera followed in London (1820) and New York (1825). Within weeks of "Tancredi", Rossini had another box-office success with his comedy "L'italiana in Algeri", composed in great haste and premiered in May 1813.

1814 was a less remarkable year for the rising composer, neither "Il turco in Italia" or "Sigismondo" pleasing the Milanese or Venetian public, respectively. 1815 marked an important stage in Rossini's career. In May he moved to Naples, to take up the post of director of music for the royal theatres. These included the Teatro di San Carlo, the city's leading opera house; its manager Domenico Barbaia was to be an important influence on the composer's career there.

The musical establishment of Naples was not immediately welcoming to Rossini, who was seen as an intruder into its cherished operatic traditions. The city had once been the operatic capital of Europe; the memory of Cimarosa was revered and Paisiello was still living, but there were no local composers of any stature to follow them, and Rossini quickly won the public and critics round. Rossini's first work for the San Carlo, "Elisabetta, regina d'Inghilterra" was a dramma per musica in two acts, in which he reused substantial sections of his earlier works, unfamiliar to the local public. The Rossini scholars Philip Gossett and Patricia Brauner write, "It is as if Rossini wished to present himself to the Neapolitan public by offering a selection of the best music from operas unlikely to be revived in Naples." The new opera was received with tremendous enthusiasm, as was the Neapolitan premiere of "L'italiana in Algeri", and Rossini's position in Naples was assured.

For the first time, Rossini was able to write regularly for a resident company of first-rate singers and a fine orchestra, with adequate rehearsals, and schedules that made it unnecessary to compose in a rush to meet deadlines. Between 1815 and 1822 he composed eighteen more operas: nine for Naples and nine for opera houses in other cities. In 1816, for the Teatro Argentina in Rome, he composed the opera that was to become his best-known: "Il barbiere di Siviglia" ("The Barber of Seville"). There was already a popular opera of that title by Paisiello, and Rossini's version was originally given the same title as its hero, "Almaviva". Despite an unsuccessful opening night, with mishaps on stage and many pro-Paisiello and anti-Rossini audience members, the opera quickly became a success, and by the time of its first revival, in Bologna a few months later, it was billed by its present Italian title, and rapidly eclipsed Paisiello's setting.

Rossini's operas for the Teatro San Carlo were substantial, mainly serious pieces. His "Otello" (1816) provoked Lord Byron to write, "They have been crucifying "Othello" into an opera: music good, but lugubrious – but as for the words!" Nonetheless the piece proved generally popular, and held the stage in frequent revivals until it was overshadowed by Verdi's version, seven decades later. Among his other works for the house were "Mosè in Egitto", based on the biblical story of Moses and the Exodus from Egypt (1818), and "La donna del lago", from Sir Walter Scott's poem "The Lady of the Lake" (1819). For La Scala he wrote the opera semiseria "La gazza ladra" (1817), and for Rome his version of the Cinderella story, "La Cenerentola" (1817). In 1817 came the first performance of one of his operas ("L'Italiana") at the Theâtre-Italien in Paris; its success led to others of his operas being staged there, and eventually to his contract in Paris from 1824 to 1830.

Rossini kept his personal life as private as possible, but he was known for his susceptibility to singers in the companies he worked with. Among his lovers in his early years were Ester Mombelli (Domenico's daughter) and Maria Marcolini of the Bologna company. By far the most important of these relationships – both personal and professional – was with Isabella Colbran, prima donna of the Teatro San Carlo (and former mistress of Barbaia). Rossini had heard her sing in Bologna in 1807, and when he moved to Naples he wrote a succession of important roles for her in "opere serie".

By the early 1820s Rossini was beginning to tire of Naples. The failure of his operatic tragedy "Ermione" the previous year convinced him that he and the Neapolitan audiences had had enough of each other. An insurrection in Naples against the monarchy, though quickly crushed, unsettled Rossini; when Barbaia signed a contract to take the company to Vienna, Rossini was glad to join them, but did not reveal to Barbaia that he had no intention of returning to Naples afterwards. He travelled with Colbran, in March 1822, breaking their journey at Bologna, where they were married in the presence of his parents in a small church in Castenaso a few miles from the city. The bride was thirty-seven, the groom thirty.

In Vienna, Rossini received a hero's welcome; his biographers describe it as "unprecedentedly feverish enthusiasm", "Rossini fever", and "near hysteria". The authoritarian chancellor of the Austrian Empire, Metternich, liked Rossini's music, and thought it free of all potential revolutionary or republican associations. He was therefore happy to permit the San Carlo company to perform the composer's operas. In a three-month season they played six of them, to audiences so enthusiastic that Beethoven's assistant, Anton Schindler, described it as "an idolatrous orgy".

While in Vienna Rossini heard Beethoven's "Eroica" symphony, and was so moved that he determined to meet the reclusive composer. He finally managed to do so, and later described the encounter to many people, including Eduard Hanslick and Richard Wagner. He recalled that although conversation was hampered by Beethoven's deafness and Rossini's ignorance of German, Beethoven made it plain that he thought Rossini's talents were not for serious opera, and that "above all" he should "do more "Barbiere"" "(Barbers)".

After the Vienna season Rossini returned to Castenaso to work with his librettist, Gaetano Rossi, on "Semiramide", commissioned by La Fenice. It was premiered in February 1823, his last work for the Italian theatre. Colbran starred, but it was clear to everyone that her voice was in serious decline, and "Semiramide" ended her career in Italy. The work survived that one major disadvantage, and entered the international operatic repertory, remaining popular throughout the 19th century; in Richard Osborne's words, it brought "[Rossini's] Italian career to a spectacular close."

In November 1823 Rossini and Colbran set off for London, where a lucrative contract had been offered. They stopped for four weeks "en route" in Paris. Although he was not as feverishly acclaimed by the Parisians as he had been in Vienna, he nevertheless had an exceptionally welcoming reception from the musical establishment and the public. When he attended a performance of "Il barbiere" at the Théâtre-Italien he was applauded, dragged onto the stage, and serenaded by the musicians. A banquet was given for him and his wife, attended by leading French composers and artists, and he found the cultural climate of Paris congenial.

Once in England, Rossini was received and made much of by the king, George IV, although the composer was by now unimpressed by royalty and aristocracy. Rossini and Colbran had signed contracts for an opera season at the in the Haymarket. Her vocal shortcomings were a serious liability, and she reluctantly retired from performing. Public opinion was not improved by Rossini's failure to provide a new opera, as promised. The impresario, Vincenzo Benelli, defaulted on his contract with the composer, but this was not known to the London press and public, who blamed Rossini.

In a 2003 biography of the composer, Gaia Servadio comments that Rossini and England were not made for each other. He was prostrated by the Channel crossing, and was unlikely to be enthused by the English weather or English cooking. Although his stay in London was financially rewarding – the British press reported disapprovingly that he had earned over £30,000 – he was happy to sign a contract at the French embassy in London to return to Paris, where he had felt much more at home.

Rossini's new, and highly remunerative, contract with the French government was negotiated under Louis XVIII, who died in September 1824, soon after Rossini's arrival in Paris. It had been agreed that the composer would produce one grand opera for the Académie Royale de Musique and either an "opera buffa" or an "opera semiseria" for the Théâtre-Italien. He was also to help run the latter theatre and revise one of his earlier works for revival there. The death of the king and the accession of Charles X changed Rossini's plans, and his first new work for Paris was "Il viaggio a Reims", an operatic entertainment given in June 1825 to celebrate Charles's coronation. It was Rossini's last opera with an Italian libretto. He permitted only four performances of the piece, intending to reuse the best of the music in a less ephemeral opera. About half the score of "Le comte Ory" (1828) is from the earlier work.

Colbran's enforced retirement put a strain on the Rossinis' marriage, leaving her unoccupied while he continued to be the centre of musical attention and constantly in demand. She consoled herself with what Servadio describes as "a new pleasure in shopping"; for Rossini, Paris offered continual gourmet delights, as his increasingly rotund shape began to reflect.

The first of the four operas Rossini wrote to French librettos were "Le siège de Corinthe" (1826) and "Moïse et Pharaon" (1827). Both were substantial reworkings of pieces written for Naples: "Maometto II" and "Mosè in Egitto". Rossini took great care before beginning work on the first, learning to speak French and familiarising himself with traditional French operatic ways of declaiming the language. As well as dropping some of the original music that was in an ornate style unfashionable in Paris, Rossini accommodated local preferences by adding dances, hymn-like numbers and a greater role for the chorus.

Rossini's mother, Anna, died in 1827; he had been devoted to her, and he felt her loss deeply. She and Colbran had never got on well, and Servadio suggests that after Anna died Rossini came to resent the surviving woman in his life.

In 1828 Rossini wrote "Le comte Ory", his only French-language comic opera. His determination to reuse music from "Il viaggio a Reims" caused problems for his librettists, who had to adapt their original plot and write French words to fit existing Italian numbers, but the opera was a success, and was seen in London within six months of the Paris premiere, and in New York in 1831. The following year Rossini wrote his long-awaited French grand opera, "Guillaume Tell", based on Friedrich Schiller's 1804 play which drew on the William Tell legend.

"Guillaume Tell" was well received. The orchestra and singers gathered outside Rossini's house after the premiere and performed the rousing finale to the second act in his honour. The newspaper "Le Globe" commented that a new era of music had begun. Gaetano Donizetti remarked that the first and last acts of the opera were written by Rossini, but the middle act was written by God. The work was an undoubted success, without being a smash hit; the public took some time in getting to grips with it, and some singers found it too demanding. It nonetheless was produced abroad within months of the premiere, and there was no suspicion that it would be the composer's last opera.
Jointly with "Semiramide", "Guillaume Tell" is Rossini's longest opera, at three hours and forty-five minutes, and the effort of composing it left him exhausted. Although within a year he was planning an operatic treatment of the Faust story, events and ill health overtook him. After the opening of "Guillaume Tell" the Rossinis had left Paris and were staying in Castenaso. Within a year events in Paris had Rossini hurrying back. Charles X was overthrown in a revolution in July 1830, and the new administration, headed by Louis Philippe I, announced radical cutbacks in government spending. Among the cuts was Rossini's lifetime annuity, won after hard negotiation with the previous regime. Attempting to restore the annuity was one of Rossini's reasons for returning. The other was to be with his new mistress, Olympe Pélissier. He left Colbran in Castenaso; she never returned to Paris and they never lived together again.

The reasons for Rossini's withdrawal from opera have been continually discussed during and since his lifetime. Some have supposed that aged thirty-seven and in variable health, having negotiated a sizeable annuity from the French government, and having written thirty-nine operas, he simply planned to retire and kept to that plan. In a 1934 study of the composer, the critic Francis Toye coined the phrase "The Great Renunciation", and called Rossini's retirement a "phenomenon unique in the history of music and difficult to parallel in the whole history of art":

The poet Heine compared Rossini's retirement with Shakespeare's withdrawal from writing: two geniuses recognising when they had accomplished the unsurpassable and not seeking to follow it. Others, then and later, suggested that Rossini had retired because of pique at the successes of Giacomo Meyerbeer and Fromental Halévy in the genre of grand opéra. Modern Rossini scholarship has generally discounted such theories, maintaining that Rossini had no intention of renouncing operatic composition, and that circumstances rather than personal choice made "Guillaume Tell" his last opera. Gossett and Richard Osborne suggest that illness may have been a major factor in Rossini's retirement. From about this time, Rossini had intermittent bad health, both physical and mental. He had contracted gonorrhoea in earlier years, which later led to painful side-effects, from urethritis to arthritis; he suffered from bouts of debilitating depression, which commentators have linked to several possible causes: cyclothymia, or bipolar disorder, or reaction to his mother's death.

For the next twenty-five years following "Guillaume Tell" Rossini composed little, although Gossett comments that his comparatively few compositions from the 1830s and 1840s show no falling-off in musical inspiration. They include the "Soirées musicales" (1830–1835: a set of twelve songs for solo or duet voices and piano) and his Stabat Mater (begun in 1831 and completed in 1841). After winning his fight with the government over his annuity in 1835 Rossini left Paris and settled in Bologna. His return to Paris in 1843 for medical treatment by Jean Civiale sparked hopes that he might produce a new grand opera – it was rumoured that Eugène Scribe was preparing a libretto for him about Joan of Arc. The Opéra was moved to present a French version of "Otello" in 1844 which also included material from some of the composer's earlier operas. It is unclear to what extent – if at all – Rossini was involved with this production, which was in the event poorly received. More controversial was the "pasticcio" opera of "Robert Bruce" (1846), in which Rossini, by then returned to Bologna, closely cooperated by selecting music from his past operas which had not yet been performed in Paris, notably "La donna del lago." The Opéra sought to present "Robert" as a new Rossini opera. But although "Othello" could at least claim to be genuine, canonic, Rossini, the historian Mark Everist notes that detractors argued that "Robert" was simply "fake goods, and from a bygone era at that"; he cites Théophile Gautier regretting that "the lack of unity could have been masked by a superior performance; unfortunately the tradition of Rossini's music was lost at the Opéra a long time ago."

The period after 1835 saw Rossini's formal separation from his wife, who remained at Castenaso (1837), and the death of his father at the age of eighty (1839). In 1845 Colbran became seriously ill, and in September Rossini travelled to visit her; a month later she died. The following year Rossini and Pélissier were married in Bologna. The events of the Year of Revolution in 1848 led Rossini to move away from the Bologna area, where he felt threatened by insurrection, and to make Florence his base, which it remained until 1855.

By the early 1850s Rossini's mental and physical health had deteriorated to the point where his wife and friends feared for his sanity or his life. By the middle of the decade it was clear that he needed to return to Paris for the most advanced medical care then available. In April 1855 the Rossinis set off for their final journey from Italy to France. Rossini returned to Paris aged sixty-three and made it his home for the rest of his life.

Gossett observes that although an account of Rossini's life between 1830 and 1855 makes depressing reading, it is "no exaggeration to say that, in Paris, Rossini returned to life". He recovered his health and "joie de vivre". Once settled in Paris he maintained two homes: a flat in the rue de la Chaussée-d'Antin, a smart central area, and a neo-classical villa built for him in Passy, a commune now absorbed into the city, but then semi-rural. He and his wife established a salon that became internationally famous. The first of their Saturday evening gatherings – the "samedi soirs" – was held in December 1858, and the last, two months before he died in 1868.

Rossini began composing again. His music from his final decade was not generally intended for public performance, and he did not usually put dates of composition on the manuscripts. Consequently, musicologists have found it difficult to give definite dates for his late works, but the first, or among the first, was the song cycle "Musique anodine", dedicated to his wife and presented to her in April 1857. For their weekly salons he produced more than 150 pieces, including songs, solo piano pieces, and chamber works for many different combinations of instruments. He referred to them as his "Péchés de vieillesse" – "sins of old age". The salons were held both at Beau Séjour – the Passy villa – and, in the winter, at the Paris flat. Such gatherings were a regular feature of Parisian life – the writer James Penrose has observed that the well-connected could easily attend different salons almost every night of the week – but the Rossinis' "samedi soirs" quickly became the most sought after: "an invitation was the city's highest social prize." The music, carefully chosen by Rossini, was not only his own, but included works by Pergolesi, Haydn and Mozart and modern pieces by some of his guests. Among the composers who attended the salons, and sometimes performed, were Auber, Gounod, Liszt, Rubinstein, Meyerbeer and Verdi. Rossini liked to call himself a fourth-class pianist, but the many famous pianists who attended the "samedi soirs" were dazzled by his playing. Violinists such as Pablo Sarasate and Joseph Joachim, and the leading singers of the day were regular guests. In 1860, Wagner visited Rossini via an introduction from Rossini's friend Edmond Michotte who some forty-five years later wrote his account of the genial conversation between the two composers.

One of Rossini's few late works intended to be given in public was his "Petite messe solennelle", first performed in 1864. In the same year Rossini was made a grand officer of the Legion of Honour by Napoleon III.

After a short illness, and an unsuccessful operation to treat colorectal cancer, Rossini died at Passy on 13 November 1868 at the age of seventy-six. He left Olympe a life interest in his estate, which after her death, ten years later, passed to the Commune of Pesaro for the establishment of a Liceo Musicale, and funded a home for retired opera singers in Paris. After a funeral service attended by more than four thousand people at the church of Sainte-Trinité, Paris, Rossini's body was interred at the Père Lachaise Cemetery. In 1887 his remains were moved to the church of Santa Croce, Florence.

The writer Julian Budden, noting the formulas adopted early on by Rossini in his career and consistently followed by him thereafter as regards overtures, arias, structures and ensembles, has called them "the Code Rossini" in a reference to the Code Napoléon, the legal system established by the French Emperor. Rossini's overall style may indeed have been influenced more directly by the French: the historian John Rosselli suggests that French rule in Italy at the start of the 19th century meant that "music had taken on new military qualities of attack, noise and speed – to be heard in Rossini." Rossini's approach to opera was inevitably tempered by changing tastes and audience demands. The formal "classicist" libretti of Metastasio which had underpinned late 18th century "opera seria" were replaced by subjects more to the taste of the age of Romanticism, with stories demanding stronger characterisation and quicker action; a jobbing composer needed to meet these demands or fail. Rossini's strategies met this reality. A formulaic approach was logistically indispensable for Rossini's career, at least at the start: in the seven years 1812–1819, he wrote 27 operas, often at extremely short notice. For "La Cenerentola" (1817), for example, he had just over three weeks to write the music before the première.

Such pressures led to a further significant element of Rossini's compositional procedures, not included in Budden's "Code", namely, recycling. The composer often transferred a successful overture to subsequent operas: thus the overture to "La pietra del paragone" was later used for the "opera seria" "Tancredi" (1813), and (in the other direction) the overture to "Aureliano in Palmira" (1813) ended as (and is today known as) the overture to the comedy "Il barbiere di Siviglia (The Barber of Seville)". He also liberally re-employed arias and other sequences in later works. Spike Hughes notes that of the twenty-six numbers of "Eduardo e Cristina", produced in Venice in 1817, nineteen were lifted from previous works. "The audience ... were remarkably good-humoured  ... and asked slyly why the libretto had been changed since the last performance". Rossini expressed his disgust when the publisher Giovanni Ricordi issued a complete edition of his works in the 1850s: "The same pieces will be found several times, for I thought I had the right to remove from my fiascos those pieces which seemed best, to rescue them from shipwreck ... A fiasco seemed to be good and dead, and now look they've resuscitated them all!"

Philip Gossett notes that Rossini "was from the outset a consummate composer of overtures." His basic formula for these remained constant throughout his career: Gossett characterises them as "sonata movements without development sections, usually preceded by a slow introduction" with "clear melodies, exuberant rhythms [and] simple harmonic structure" and a "crescendo" climax. Richard Taruskin also notes that the second theme is always announced in a woodwind solo, whose "catchiness" "etch[es] a distinct profile in the aural memory", and that the richness and inventiveness of his handling of the orchestra, even in these early works, marks the start of "[t]he great nineteenth-century flowering of orchestration."

Rossini's handling of arias (and duets) in "cavatina" style marked a development from the eighteenth-century commonplace of recitative and aria. In the words of Rosselli, in Rossini's hands "the aria became an engine for releasing emotion". Rossini's typical aria structure involved a lyrical introduction (""cantabile"") and a more intensive, brilliant, conclusion (""cabaletta""). This model could be adapted in various ways so as to forward the plot (as opposed to the typical eighteenth-century handling which resulted in the action coming to a halt as the requisite repeats of the "da capo aria" were undertaken). For example, they could be punctuated by comments from other characters (a convention known as ""pertichini""), or the chorus could intervene between the "cantabile" and the "cabaletta" so as to fire up the soloist. If such developments were not necessarily Rossini's own invention, he nevertheless made them his own by his expert handling of them. A landmark in this context is the "cavatina" ""Di tanti palpiti"" from "Tancredi", which both Taruskin and Gossett (amongst others) single out as transformative, "the most famous aria Rossini ever wrote", with a "melody that seems to capture the melodic beauty and innocence characteristic of Italian opera." Both writers point out the typical Rossinian touch of avoiding an "expected" cadence in the aria by a sudden shift from the home key of F to that of A flat (see example); Taruskin notes the implicit pun, as the words talk of returning, but the music moves in a new direction. The influence was lasting; Gossett notes how the Rossinian "cabaletta" style continued to inform Italian opera as late as Giuseppe Verdi's "Aida" (1871).

Such structural integration of the forms of vocal music with the dramatic development of the opera meant a sea-change from the Metastasian primacy of the aria; in Rossini's works, solo arias progressively take up a smaller proportion of the operas, in favour of duets (also typically in "cantabile-caballetta" format) and ensembles.

During the late 18th-century, creators of "opera buffa" had increasingly developed dramatic integration of the finales of each act. Finales began to "spread backwards", taking an ever larger proportion of the act, taking the structure of a musically continuous chain, accompanied throughout by orchestra, of a series of sections, each with its own characteristics of speed and style, mounting to a clamorous and vigorous final scene. In his comic operas Rossini brought this technique to its peak, and extended its range far beyond his predecessors. Of the finale to the first act of "L'italiana in Algeri", Taruskin writes that "[r]unning through almost a hundred pages of vocal score in record time, it is the most concentrated single dose of Rossini that there is."

Of greater consequence for the history of opera was Rossini's ability to progress this technique in the genre of "opera seria". Gossett in a very detailed analysis of the first-act finale of "Tancredi" identifies several the elements in Rossini's practice. These include the contrast of "kinetic" action sequences, often characterised by orchestral motifs, with "static" expressions of emotion, the final "static" section in the form of a caballetta, with all the characters joining in the final cadences. Gossett claims that it is "from the time of "Tancredi" that the caballetta ... becomes the obligatory closing section of each musical unit in the operas of Rossini and his contemporaries."

With extremely few exceptions, all Rossini's compositions before the "Péchés de vieillesse" of his retirement involve the human voice. His very first surviving work (apart from a single song) is however a set of string sonatas for two violins, cello and double-bass, written at the age of 12, when he had barely begun instruction in composition. Tuneful and engaging, they indicate how remote the talented child was from the influence of the advances in musical form evolved by Mozart, Haydn and Beethoven; the accent is on cantabile melody, colour, variation and virtuosity rather than transformational development. These qualities are also evident in Rossini's early operas, especially his "farse" (one-act farces), rather than his more formal "opere serie". Gossett notes that these early works were written at a time when "[t]he deposited mantles of Cimarosa and Paisiello were unfilled" – these were Rossini's first, and increasingly appreciated, steps in trying them on. The Teatro San Moisè in Venice, where his "farse" were first performed, and the La Scala Theatre of Milan which premiered his two-act opera "La pietra del paragone" (1812), were seeking works in that tradition; Gossett notes that in these operas "Rossini's musical personality began to take shape ... many elements emerge that remain throughout his career" including "[a] love of sheer sound, of sharp and effective rhythms". The unusual effect employed in the overture of "Il signor Bruschino", (1813) deploying violin bows tapping rhythms on music stands, is an example of such witty originality.

The great success in Venice of the premieres of both "Tancredi" and the comic opera "L'italiana in Algeri" within a few weeks of each other (6 February 1813 and 22 May 1813 respectively) set the seal on Rossini's reputation as the rising opera composer of his generation. From the end of 1813 to mid-1814 he was in Milan creating two new operas for La Scala, "Aureliano in Palmira" and "Il Turco in Italia". Arsace in "Aureliano" was sung by the "castrato" Giambattista Velluti; this was the last opera role Rossini wrote for a "castrato" singer as the norm became to use contralto voices – another sign of change in operatic taste. Rumour had it that Rossini was displeased by Velluti's ornamentation of his music; but in fact throughout his Italian period, up to "Semiramide" (1823), Rossini's written vocal lines become increasingly florid, and this is more appropriately credited to the composer's own changing style.

Rossini's work in Naples contributed to this stylistic development. The city, which was the cradle of the operas of Cimarosa and Paisiello, had been slow to acknowledge the composer from Pesaro, but Domenico Barbaia invited him in 1815 on a seven-year contract to manage his theatres and compose operas. For the first time, Rossini was able to work over a long period with a company of musicians and singers, including amongst the latter Isabella Colbran, Andrea Nozzari, Giovanni David and others, who as Gossett notes "all specialized in florid singing" and "whose vocal talents left an indelible and not wholly positive mark on Rossini's style". Rossini's first operas for Naples, "Elisabetta, regina d'Inghilterra" and "La gazzetta" were both largely recycled from earlier works, but "Otello" (1816) is marked not only by its virtuoso vocal lines but by its masterfully integrated last act, with its drama underlined by melody, orchestration and tonal colour; here, in Gossett's opinion "Rossini came of age as a dramatic artist." He further comments:
By now, Rossini's career was arousing interest across Europe. Others came to Italy to study the revival of Italian opera and used its lessons to advance themselves; amongst these was the Berlin-born Giacomo Meyerbeer who arrived in Italy in 1816, a year after Rossini's establishment at Naples, and lived and worked there until following him to Paris in 1825; he used one of Rossini's librettists, Gaetano Rossi, for five of his seven Italian operas, which were produced at Turin, Venice and Milan. In a letter to his brother of September 1818, he includes a detailed critique of "Otello" from the point of view of a non-Italian informed observer. He is scathing about the self-borrowings in the first two acts, but concedes that the third act "so firmly established Rossini's reputation in Venice that even a thousand follies could not rob him of it. But this act is divinely beautiful, and what is so strange is that [its] beauties ... are blatantly un-Rossinian: outstanding, even passionate recitatives, mysterious accompaniments, lots of local colour."

Rossini's contract did not prevent him from undertaking other commissions, and before "Otello, Il barbiere di Siviglia", a grand culmination of the "opera buffa" tradition, had been premiered in Rome (February 1816). Richard Osborne catalogues its excellencies:Beyond the physical impact of ... Figaro's ""Largo al factotum"", there is Rossini's ear for vocal and instrumental timbres of a peculiar astringency and brilliance, his quick-witted word-setting, and his mastery of large musical forms with their often brilliant and explosive internal variations. Add to that what Verdi called the opera's "abundance of true musical ideas", and the reasons for the work's longer-term emergence as Rossini's most popular "opera buffa" are not hard to find.

Apart from "La Cenerentola" (Rome, 1817), and the "pen-and-ink sketch" "farsa" "Adina" (1818, not performed until 1826), Rossini's other works during his contract with Naples were all in the "opera seria" tradition. Amongst the most notable of these, all containing virtuoso singing roles, were "Mosè in Egitto" (1818), "La donna del lago" (1819), "Maometto II" (1820) all staged in Naples, and "Semiramide", his last opera written for Italy, staged at La Fenice in Venice in 1823. Both "Mosè" and "Maometto II" were later to undergo significant reconstruction in Paris (see below).

 Already in 1818, Meyerbeer had heard rumours that Rossini was seeking a lucrative appointment at the Paris Opéra – "Should [his proposals] be accepted, he will go to the French capital, and we will perhaps experience curious things." Some six years were to pass before this prophecy came true.

In 1824 Rossini, under a contract with the French government, became director of the Théâtre-Italien in Paris, where he introduced Meyerbeer's opera "Il crociato in Egitto", and for which he wrote "Il viaggio a Reims" to celebrate the coronation of Charles X (1825). This was his last opera to an Italian libretto, and was later cannibalised to create his first French opera, "Le comte Ory" (1828). A new contract in 1826 meant he could concentrate on productions at the Opéra and to this end he substantially revised "Maometta II" as "Le siège de Corinthe" (1826) and "Mosé" as "Moïse et Pharaon" (1827). Meeting French taste, the works are extended (each by one act), the vocal lines in the revisions are less florid and the dramatic structure is enhanced, with the proportion of arias reduced. One of the most striking additions was the chorus at the end of Act III of "Moïse", with a crescendo repetition of a diatonic ascending bass line, rising first by a minor third, then by a major third, at each appearance, and a descending chromatic top line, which roused the excitement of audiences.

Rossini's government contract required him to create at least one new ""grand opėra"", and Rossini settled on the story of William Tell, working closely with the librettist Étienne de Jouy. The story in particular enabled him to indulge "an underlying interest in the related genres of folk music, pastoral and the picturesque". This becomes clear from the overture, which is explicitly programmatic in describing weather, scenery and action, and presents a version of the "ranz des vaches", the Swiss cowherd's call, which "undergoes a number of transformations during the opera" and gives it in Richard Osborne's opinion "something of the character of a leitmotif". In the opinion of the music historian Benjamin Walton, Rossini "saturate[s] the work with local colour to such a degree that there is room for little else." Thus, the role of the soloists is significantly reduced compared to other Rossini operas, the hero not even having an aria of his own, whilst the chorus of the Swiss people is consistently in the musical and dramatic foregrounds.

"Guillaume Tell" premiered in August 1829. Rossini also provided for the Opéra a shorter, three-act version, which incorporated the "pas redoublé" (quick march) final section of the overture in its finale; it was first performed in 1831 and became the basis of the Opéra's future productions. "Tell" was very successful from the start and was frequently revived – in 1868 the composer was present at its 500th performance at the Opéra. The "Globe" had reported enthusiastically at its opening that "a new epoch has opened not only for French opera, but for dramatic music elsewhere." This was an era, it transpired, in which Rossini was not to participate.

Rossini's contract required him to provide five new works for the Opéra over 10 years. After the première of "Tell" he was already considering some opera subjects, including Goethe's "Faust", but the only significant works he completed before abandoning Paris in 1836 were the Stabat Mater, written for a private commission in 1831 (later completed and published in 1841), and the collection of salon vocal music "Soirées musicales" published in 1835. Living in Bologna, he occupied himself teaching singing at the Liceo Musicale, and also created a "pasticcio" of "Tell", "Rodolfo di Sterlinga", for the benefit of the singer Nikolay Ivanov, for which Giuseppe Verdi provided some new arias. Continuing demand in Paris resulted in the productions of a "new" French version of "Otello" in 1844 (with which Rossini was not involved) and a "new" opera "Robert Bruce" for which Rossini cooperated with Louis Niedermeyer and others to recast music for "La donna del lago" and others of his works which were little-known in Paris to fit a new libretto. The success of both of these was qualified, to say the least.

Not until Rossini returned to Paris in 1855 were there signs of a revival of his musical spirits. A stream of pieces, for voices, choir, piano, and chamber ensembles, written for his soirées, the "Péchés de vieillesse (Sins of old age)" were issued in thirteen volumes from 1857 to 1868; of these volumes 4 to 8 comprise "56 semi-comical piano pieces ... dedicated to pianists of the fourth class, to which I have the honour of belonging." These include a mock funeral march, "Marche et reminiscences pour mon dernier voyage (March and reminiscences for my last journey)." Gossett writes of the "Péchés" "Their historical position remains to be assessed but it seems likely that their effect, direct or indirect, on composers like Camille Saint-Saëns and Erik Satie was significant."

The most substantial work of Rossini's last decade, the "Petite messe solennelle" (1863), was written for small forces (originally voices, two pianos and harmonium), and therefore unsuited to concert hall performance; and as it included women's voices it was unacceptable for church performances at the time. For these reasons, Richard Osborne suggests, the piece has been somewhat overlooked among Rossini's compositions. It is neither especially "petite" (little) nor entirely "solennelle" (solemn), but is notable for its grace, counterpoint and melody. At the end of the manuscript, the composer wrote Dear God, here it is finished, this poor little Mass. Is it sacred music I have written, or damned music? I was born for opera buffa, as you know well. A little technique, a little heart, that's all. Be blessed then, and grant me Paradise.

The popularity of Rossini's melodies led many contemporary virtuosi to create piano transcriptions or fantasies based on them. Examples include Sigismond Thalberg's fantasy on themes from "Moïse", the sets of variations on "Non più mesta" from "La Cenerentola" by Henri Herz, Frédéric Chopin, Franz Hünten, Anton Diabelli and Friedrich Burgmüller, and Liszt's transcriptions of the "William Tell" overture (1838) and the "Soirées musicales".

The continuing popularity of his comic operas (and the decline in staging his "opere serie"), the overthrow of the singing and staging styles of his period, and the emerging concept of the composer as "creative artist" rather than craftsman, diminished and distorted Rossini's place in music history even though the forms of Italian opera continued up to the period of verismo to be indebted to his innovations. Rossini's status amongst his contemporary Italian composers is indicated by the "Messa per Rossini", a project initiated by Verdi within a few days of Rossini's death, which he and a dozen other composers created in collaboration.

If Rossini's principal legacy to Italian opera was in vocal forms and dramatic structure for serious opera, his legacy to French opera was to provide a bridge from opera buffa to the development of "opéra comique" (and thence, via Jacques Offenbach's "opéras bouffes" to the genre of operetta). "Opéras comiques" showing a debt to Rossini's style include François-Adrien Boieldieu's "La dame blanche" (1825) and Daniel Auber's "Fra Diavolo" (1830), as well as works by Ferdinand Hérold, Adolphe Adam and Fromental Halévy. Critical of Rossini's style was Hector Berlioz, who wrote of his "melodic cynicism, his contempt for dramatic and good sense, his endless repetition of a single form of cadence, his eternal puerile crescendo and his brutal bass drum".

It was perhaps inevitable that the formidable reputation which Rossini had built in his lifetime would fade thereafter. In 1886, less than twenty years after the composer's death, Bernard Shaw wrote: "The once universal Rossini, whose "Semiramide" appeared to our greener grandfathers a Ninevesque wonder, came at last to be no longer looked upon as a serious musician." In an 1877 review of "Il barbiere", he noted that Adelina Patti sang as an encore in the lesson scene "Home, Sweet Home" but that "the opera proved so intolerably wearisome that some of her audience had already displayed their appreciation of the sentiment of the ballad in the most practical way."

In the early 20th century Rossini received tributes from both Ottorino Respighi, who had orchestrated excerpts from the "Péchés de viellesse" both in his ballet "la boutique fantasque" (1918) and in his 1925 suite "Rossiniana", and from Benjamin Britten, who adapted music by Rossini for two suites, "Soirées musicales" (Op. 9) in 1936 and "Matinées musicales" (Op. 24) in 1941. Richard Osborne singles out the three-volume biography of Rossini by Giuseppe Radiciotti (1927–1929) as an important turning-point towards positive appreciation, which may also have been assisted by the trend of neoclassicism in music. A firm re-evaluation of Rossini's significance began only later in the 20th century in the light of study, and the creation of critical editions, of his works. A prime mover in these developments was the "Fondazione G. Rossini" which was created by the city of Pesaro in 1940 using the funds which had been left to the city by the composer. Since 1980 the "Fondazione" has supported the annual Rossini Opera Festival in Pesaro.

In the 21st century, the Rossini repertoire of opera houses around the world remains dominated by "Il barbiere", "La Cenerentola" being the second most popular. Several other operas are regularly produced, including "Le comte Ory", "La donna del lago", "La gazza ladra", "Guillaume Tell", "L'italiana in Algeri", "La scala di seta", "Il turco in Italia" and "Il viaggio a Reims". Other Rossini pieces in the current international repertory, given from time to time, include "Adina", "Armida", "Elisabetta regina d'Inghilterra", "Ermione", "Mosé in Egitto" and "Tancredi". The Rossini in Wildbad festival specialises in producing the rarer works. The Operabase performance-listing website records 2,319 performances of 532 productions of Rossini operas in 255 venues across the world in the three years 2017–2019. All of Rossini's operas have been recorded.






</doc>
<doc id="12407" url="https://en.wikipedia.org/wiki?curid=12407" title="Gibberish">
Gibberish

Gibberish, alternatively jibber, jabber, jibber-jabber, or gobbledygook, is speech that is (or appears to be) nonsense. It may include speech sounds that are not actual words, or language games and specialized jargon that seems nonsensical to outsiders. 

"Gibberish" is also used as an imprecation to denigrate or tar ideas or opinions the user disagrees with or finds irksome, a rough equivalent of "nonsense", "falderal", or "claptrap". The implication is that the criticized expression or proposition lacks substance or congruence, as opposed to simply being a differing view.

The word "gibberish" is more commonly applied to informal speech, while "gobbledygook" (sometimes "gobbledegook", "gobbledigook" or "gobbledegoo") is more often applied to writing or language that is meaningless or is made unintelligible by excessive use of abstruse technical terms. "Officialese", "legalese", or "bureaucratese" are forms of gobbledygook. The related word "jibber-jabber" refers to rapid talk that is difficult to understand.

The etymology of "gibberish" is uncertain. The term was first seen in English in the early 16th century. It is generally thought to be an onomatopoeia imitative of speech, similar to the words "jabber" (to talk rapidly) and "gibber" (to speak inarticulately).

It may originate from the word "jib", which is the Angloromani variant of the Romani language word meaning "language" or "tongue". To non-speakers, the Anglo-Romany dialect could sound like English mixed with nonsense words, and if those seemingly-nonsensical words are referred to as "jib" then the term "gibberish" (pronounced "jibberish") could be derived as a descriptor for nonsensical speech. Another theory is that "gibberish" came from the name of a famous 8th century Arabian alchemist, Jābir ibn Hayyān, whose name was Latinized as "Geber". Thus, "gibberish" was a reference to the incomprehensible technical jargon and allegorical coded language used by Jabir and other alchemists.

A discredited alternative theory asserts that it is derived from the Irish word "gob" or "gab" ("mouth") or from the Irish phrase "Geab ar ais" ("back talk, backward chat"). The latter Irish etymology was suggested by Daniel Cassidy, whose work has been criticised by linguists and scholars. The terms "geab" and "geabaire" are certainly Irish words, but the phrase "geab ar ais" does not exist, and the word "gibberish" exists as a loan-word in Irish as "gibiris".

The term "gobbledygook" was coined by Maury Maverick, a former congressman from Texas and former mayor of San Antonio. When Maverick was chairman of the Smaller War Plants Corporation during World War II, he sent a memorandum that said: "Be short and use plain English. ... Stay off gobbledygook language." Maverick defined "gobbledygook" as "talk or writing which is long, pompous, vague, involved, usually with Latinized words." The allusion was to a turkey, "always gobbledygobbling and strutting with ridiculous pomposity."

The term "gobbledygook" has a long history of usage in politics. Nixon's Oval Office tape from June 14, 1971, showed H. R. Haldeman describing a situation to Nixon as "... a bunch of gobbledygook. But out of the gobbledygook comes a very clear thing: You can't trust the government; you can't believe what they say." President Ronald Reagan explained tax law revisions in an address to the nation with the word, May 28, 1985, saying that "most didn’t improve the system; they made it more like Washington itself: Complicated, unfair, cluttered with gobbledygook and loopholes designed for those with the power and influence to hire high-priced legal and tax advisers." In 2017, US Supreme Court justice John Roberts dismissed quantitative sociological reasoning as "gobbledygook" in arguing against any numerical test for gerrymandering.

Michael Shanks, former chairman to the National Consumer Council of Great Britain, characterizes professional gobbledygook as sloppy jargon intended to confuse nonspecialists: "'Gobbledygook' may indicate a failure to think clearly, a contempt for one's clients, or more probably a mixture of both. A system that can't or won't communicate is not a safe basis for a democracy."

Using gibberish whilst acting can be used as an exercise in performance art education. Another usage of gibberish is as part of Osho's "Gibberish meditation" which has been derived from an old Sufi practice.

The terms "officialese" or "bureaucratese" refer to language used by officials or authorities. "Legalese" is a closely related concept, referring to language used by lawyers, legislators, and others involved with the law. The language used in these fields may contain complex sentences and specialized jargon or buzzwords, making it difficult for those outside the field to understand. Speakers or writers of officialese or legalese may recognize that it is confusing or even meaningless to outsiders, but view its use as appropriate within their organization or group.

Bafflegab is a synonym, a slang term referring to confusing or a generally unintelligible use of jargon.



</doc>
<doc id="12408" url="https://en.wikipedia.org/wiki?curid=12408" title="Gnaeus Julius Agricola">
Gnaeus Julius Agricola

Gnaeus Julius Agricola (; 13 June 40 – 23 August 93) was a Gallo-Roman general responsible for much of the Roman conquest of Britain. Written by his son-in-law Tacitus, the "De vita et moribus Iulii Agricolae" is the primary source for most of what is known about him, along with detailed archaeological evidence from northern Britain.

Agricola began his military career in Britain, serving under governor Gaius Suetonius Paulinus. His subsequent career saw him serve in a variety of positions; he was appointed quaestor in Asia province in 64, then Plebeian Tribune in 66, and praetor in 68. He supported Vespasian during the Year of the Four Emperors (69), and was given a military command in Britain when the latter became emperor. When his command ended in 73, he was made patrician in Rome and appointed governor of Gallia Aquitania. He was made consul and governor of Britannia in 77. While there, he completed the conquest of what is now Wales and northern England, and led his army to the far north of Scotland, establishing forts across much of the Lowlands. He was recalled from Britain in 85 after an unusually lengthy service, and thereafter retired from military and public life.

Agricola was born in the "colonia" of Forum Julii, Gallia Narbonensis (now Fréjus, France). Agricola's parents were from noted Gallo-Roman political families of senatorial rank, and his ancestors were Romanised Gauls of local origin. Both of his grandfathers served as imperial governors. His father, Lucius Julius Graecinus, was a "praetor" and had become a member of the Roman Senate in the year of his birth. Graecinus had become distinguished by his interest in philosophy. Between August 40 and January 41, the Emperor Caligula ordered his death because he refused to prosecute the Emperor's second cousin Marcus Junius Silanus.

His mother was Julia Procilla. The Roman historian Tacitus describes her as "a lady of singular virtue". Tacitus states that Procilla had a fond affection for her son. Agricola was educated in Massilia (Marseille), and showed what was considered an unhealthy interest in philosophy.

He began his career in Roman public life as a military tribune, serving in Britain under Gaius Suetonius Paulinus from 58 to 62. He was probably attached to the "Legio II Augusta", but was chosen to serve on Suetonius's staff and thus almost certainly participated in the suppression of Boudica's uprising in 61.

Returning from Britain to Rome in 62, he married Domitia Decidiana, a woman of noble birth. Their first child was a son. Agricola was appointed as "quaestor" for 64, which he served in the province of Asia under the corrupt proconsul Lucius Salvius Otho Titianus. While he was there, his daughter, Julia Agricola, was born, but his son died shortly afterwards. He was tribune of the plebs in 66 and "praetor" in June 68, during which time he was ordered by the Governor of Spain Galba to take an inventory of the temple treasures.

During that same, the emperor Nero was declared a public enemy by the Senate and committed suicide, and the period of civil war known as the Year of the Four Emperors began. Galba succeeded Nero, but was murdered in early 69 by Otho, who took the throne. Agricola's mother was murdered on her estate in Liguria by Otho's marauding fleet. Hearing of Vespasian's bid for the empire, Agricola immediately gave him his support. Otho meanwhile committed suicide after being defeated by Vitellius.

After Vespasian had established himself as emperor, Agricola was appointed to the command of the "Legio XX Valeria Victrix", stationed in Britain, in place of Marcus Roscius Coelius, who had stirred up a mutiny against the governor, Marcus Vettius Bolanus. Britain had revolted during the year of civil war, and Bolanus was a mild governor. Agricola reimposed discipline on the legion and helped to consolidate Roman rule. In 71, Bolanus was replaced by a more aggressive governor, Quintus Petillius Cerialis, and Agricola was able to display his talents as a commander in campaigns against the Brigantes in northern England.

When his command ended in 73, Agricola was enrolled as a patrician and appointed to govern Gallia Aquitania. There he stayed for almost three years. In 76 or 77, he was recalled to Rome and appointed suffect consul, and betrothed his daughter to Tacitus. The following year, Tacitus and Julia married; Agricola was appointed to the College of Pontiffs, and returned to Britain for a third time, as its governor ("Legatus Augusti pro praetore").

Arriving in midsummer of 77, Agricola discovered that the Ordovices of north Wales had virtually destroyed the Roman cavalry stationed in their territory. He immediately moved against them and defeated them. He then moved north to the island of Mona (Anglesey), which Suetonius Paulinus had failed to subjugate in 60 because of the outbreak of the Boudican rebellion, and forced its inhabitants to sue for peace. He established a good reputation as an administrator, as well as a commander, by reforming the widely corrupt corn levy. He introduced Romanising measures, encouraging communities to build towns on the Roman model and educating the sons of the native nobility in the Roman manner.

Agricola also expanded Roman rule north into Caledonia (modern Scotland). In the summer of 79, he pushed his armies to the estuary of the river Taus, usually interpreted as the Firth of Tay, virtually unchallenged, and established some forts. Though their location is left unspecified, the close dating of the fort at Elginhaugh in Midlothian makes it a possible candidate.

In 81, Agricola "crossed in the first ship" and defeated peoples unknown to the Romans until then. Tacitus, in Chapter 24 of "Agricola", does not tell us what body of water he crossed, although most scholars believe it was the Clyde or Forth, and some translators even add the name of their preferred river to the text; however, the rest of the chapter exclusively concerns Ireland, so southwest Scotland is perhaps to be preferred. The text of the "Agricola" has been amended here to record the Romans "crossing into trackless wastes", referring to the wilds of the Galloway peninsula. Agricola fortified the coast facing Ireland, and Tacitus recalls that his father-in-law often claimed the island could be conquered with a single legion and auxiliaries. He had given refuge to an exiled Irish king whom he hoped he might use as the excuse for conquest. This conquest never happened, but some historians believe the crossing referred to was in fact a small-scale exploratory or punitive expedition to Ireland, though no Roman camps have been identified to confirm such a suggestion.

Irish legend provides a striking parallel. Tuathal Teachtmhar, a legendary High King, is said to have been exiled from Ireland as a boy, and to have returned from Britain at the head of an army to claim the throne. The traditional date of his return is 76–80, and archaeology has found Roman or Romano-British artefacts in several sites associated with Tuathal.

The following year, Agricola raised a fleet and encircled the tribes beyond the Forth, and the Caledonians rose in great numbers against him. They attacked the camp of the "Legio IX Hispana" at night, but Agricola sent in his cavalry and they were put to flight. The Romans responded by pushing further north. Another son was born to Agricola this year, but died before his first birthday.

In the summer of 83, Agricola faced the massed armies of the Caledonians, led by Calgacus, at the Battle of Mons Graupius. Tacitus estimates their numbers at more than 30,000. Agricola put his auxiliaries in the front line, keeping the legions in reserve, and relied on close-quarters fighting to make the Caledonians' unpointed slashing swords useless as they were unable to swing them properly or utilise thrusting attacks. Even though the Caledonians were put to rout and therefore lost this battle, two thirds of their army managed to escape and hide in the Highlands or the "trackless wilds" as Tacitus calls them. Battle casualties were estimated by Tacitus to be about 10,000 on the Caledonian side and 360 on the Roman side.

A number of authors have reckoned the battle to have occurred in the Grampian Mounth within sight of the North Sea. In particular, Roy, Surenne, Watt, Hogan and others have advanced notions that the site of the battle may have been Kempstone Hill, Megray Hill or other knolls near the Raedykes Roman camp; these points of high ground are proximate to the Elsick Mounth, an ancient trackway used by Romans and Caledonians for military manoeuvres. However, following the discovery of the Roman camp at Durno in 1975, most scholars now believe that the battle took place on the ground around Bennachie in Aberdeenshire.

Satisfied with his victory, Agricola extracted hostages from the Caledonian tribes. He may have marched his army to the northern coast of Britain, as evidenced by the probable discovery of a Roman fort at Cawdor (near Inverness).

He also instructed the prefect of the fleet to sail around the north coast, confirming (allegedly for the first time) that Britain was in fact an island.

Agricola was recalled from Britain in 85, after an unusually long tenure as governor. Tacitus claims Domitian ordered his recall because Agricola's successes outshone the Emperor's own modest victories in Germany. He re-entered Rome unobtrusively, reporting as ordered to the palace at night. The relationship between Agricola and the Emperor is unclear; on the one hand, Agricola was awarded triumphal decorations and a statue (the highest military honours apart from an actual triumph); on the other, Agricola never again held a civil or military post, in spite of his experience and renown. He was offered the governorship of the province of Africa, but declined it, whether due to ill health or (as Tacitus claims) the machinations of Domitian.
In 93, Agricola died on his family estates in Gallia Narbonensis aged fifty-three. Rumours circulated attributing the death to a poison administered by the Emperor Domitian, but no positive evidence for this was ever produced.




 


</doc>
<doc id="12417" url="https://en.wikipedia.org/wiki?curid=12417" title="Guanosine">
Guanosine

Guanosine is a purine nucleoside comprising guanine attached to a ribose (ribofuranose) ring via a β-N-glycosidic bond. Guanosine can be phosphorylated to become guanosine monophosphate (GMP), cyclic guanosine monophosphate (cGMP), guanosine diphosphate (GDP), and guanosine triphosphate (GTP). These forms play important roles in various biochemical processes such as synthesis of nucleic acids and proteins, photosynthesis, muscle contraction, and intracellular signal transduction (cGMP). When guanine is attached by its N9 nitrogen to the C1 carbon of a deoxyribose ring it is known as deoxyguanosine.

Guanosine is a white, crystalline powder with no odor and mild saline taste.
It is very soluble in acetic acid, slightly soluble in water, insoluble in ethanol, diethyl ether, benzene and chloroform.

Guanosine is required for an RNA splicing reaction in mRNA, when a "self-splicing" intron removes itself from the mRNA message by cutting at both ends, re-ligating, and leaving just the exons on either side to be translated into protein.
The antiviral drug acyclovir, often used in herpes treatment, and the anti-HIV drug abacavir, are structurally similar to guanosine. Guanosine was also used to make regadenoson.

Guanosine can be found in pancreas, clover, coffee plant, and pollen of pines.


</doc>
<doc id="12420" url="https://en.wikipedia.org/wiki?curid=12420" title="Gödel's ontological proof">
Gödel's ontological proof

Gödel's ontological proof is a formal argument by the mathematician Kurt Gödel (1906–1978) for the existence of God. The argument is in a line of development that goes back to Anselm of Canterbury (1033–1109). St. Anselm's ontological argument, in its most succinct form, is as follows: "God, by definition, is that for which no greater can be conceived. God exists in the understanding. If God exists in the understanding, we could imagine Him to be greater by existing in reality. Therefore, God must exist." A more elaborate version was given by Gottfried Leibniz (1646–1716); this is the version that Gödel studied and attempted to clarify with his ontological argument.

Gödel left a fourteen-point outline of his philosophical beliefs in his papers. Points relevant to the ontological proof include

The first version of the ontological proof in Gödel's papers is dated "around 1941". Gödel is not known to have told anyone about his work on the proof until 1970, when he thought he was dying. In February, he allowed Dana Scott to copy out a version of the proof, which circulated privately. In August 1970, Gödel told Oskar Morgenstern that he was "satisfied" with the proof, but Morgenstern recorded in his diary entry for 29 August 1970, that Gödel would not publish because he was afraid that others might think "that he actually believes in God, whereas he is only engaged in a logical investigation (that is, in showing that such a proof with classical assumptions (completeness, etc.) correspondingly axiomatized, is possible)." Gödel died January 14, 1978. Another version, slightly different from Scott's, was found in his papers. It was finally published, together with Scott's version, in 1987.

Morgenstern's diary is an important and usually reliable source for Gödel's later years, but the implication of the August 1970 diary entry—that Gödel did not believe in God—is not consistent with the other evidence. In letters to his mother, who was not a churchgoer and had raised Kurt and his brother as freethinkers, Gödel argued at length for a belief in an afterlife. He did the same in an interview with a skeptical Hao Wang, who said: "I expressed my doubts as G spoke [...] Gödel smiled as he replied to my questions, obviously aware that his answers were not convincing me." Wang reports that Gödel's wife, Adele, two days after Gödel's death, told Wang that "Gödel, although he did not go to church, was religious and read the Bible in bed every Sunday morning." In an unmailed answer to a questionnaire, Gödel described his religion as "baptized Lutheran (but not member of any religious congregation). My belief is "theistic", not pantheistic, following Leibniz rather than Spinoza."

The proof uses modal logic, which distinguishes between "necessary" truths and "contingent" truths. In the most common semantics for modal logic, many "possible worlds" are considered. A truth is "necessary" if it is true in all possible worlds. By contrast, a truth is "contingent" if it just happens to be the case. For instance, "more than half of this planet is covered by water" is a contingent truth, that relies upon which planet "this planet" is. If a statement happens to be true in our world, but is false in another world, then it is a contingent truth. A statement that is true in some world (not necessarily our own) is called a "possible" truth.

Furthermore, the proof uses higher-order (modal) logic because the definition of God employs an explicit quantification over properties.

First, Gödel axiomatizes the notion of a "positive property": for each property "φ", either "φ" or its negation ¬"φ" must be positive, but not both (axiom 2). If a positive property "φ" implies a property "ψ" in each possible world, then "ψ" is positive, too (axiom 1). Gödel then argues that each positive property is "possibly exemplified", i.e. applies at least to some object in some world (theorem 1). Defining an object to be Godlike if it has all positive properties (definition 1), and requiring that property to be positive itself (axiom 3), Gödel shows that in "some" possible world a Godlike object exists (theorem 2), called "God" in the following. Gödel proceeds to prove that a Godlike object exists in "every" possible world.

To this end, he defines "essences": if "x" is an object in some world, then a property "φ" is said to be an essence of "x" if "φ"("x") is true in that world and if "φ" necessarily entails all other properties that "x" has in that world (definition 2). Requiring positive properties being positive in every possible world (axiom 4), Gödel can show that Godlikeness is an essence of a Godlike object (theorem 3). Now, "x" is said to "exist necessarily" if, for every essence "φ" of "x", there is an element "y" with property "φ" in every possible world (definition 3). Axiom 5 requires necessary existence to be a positive property.

Hence, it must follow from Godlikeness. Moreover, Godlikeness is an essence of God, since it entails all positive properties, and any non-positive property is the negation of some positive property, so God cannot have any non-positive properties. Since necessary existence is also a positive property (axiom 5), it must be a property of every Godlike object, as every Godlike object has all the positive properties (definition 1). Since any Godlike object is necessarily existent, it follows that any Godlike object in one world is a Godlike object in all worlds, by the definition of necessary existence. Given the existence of a Godlike object in one world, proven above, we may conclude that there is a Godlike object in every possible world, as required (theorem 4). Besides axiom 1-5 and definition 1-3, a few other axioms from modal logic were tacitly used in the proof.

From these hypotheses, it is also possible to prove that there is only one God in each world by Leibniz's law, the identity of indiscernibles: two or more objects are identical (the same) if they have all their properties in common, and so, there would only be one object in each world that possesses property G. Gödel did not attempt to do so however, as he purposely limited his proof to the issue of existence, rather than uniqueness.

formula_1

Most criticism of Gödel's proof is aimed at its axioms: As with any proof in any logical system, if the axioms the proof depends on are doubted, then the conclusions can be doubted. This is particularly applicable to Gödel's proof – because it rests on five axioms, some of which are questionable. A proof does not necessitate that the conclusion be correct, but rather that by accepting the axioms, the conclusion follows logically.

Many philosophers have called the axioms into question. The first layer of criticism is simply that there are no arguments presented that give reasons why the axioms are true. A second layer is that these particular axioms lead to unwelcome conclusions. This line of thought was argued by Jordan Howard Sobel, showing that if the axioms are accepted, they lead to a "modal collapse" where every statement that is true is necessarily true, i.e. the sets of necessary, of contingent, and of possible truths all coincide (provided there are accessible worlds at all). According to Robert Koons, Sobel suggested that Gödel might have welcomed modal collapse.

There are suggested amendments to the proof, presented by C. Anthony Anderson, but argued to be refutable by Anderson and Michael Gettings. Sobel's proof of modal collapse has been questioned by Koons, but a counter-defence by Sobel has been given.

Gödel's proof has also been questioned by Graham Oppy, asking whether lots of other almost-gods would also be "proven" by Gödel's axioms. This counter-argument has been questioned by Gettings, who agrees that the axioms might be questioned, but disagrees that Oppy's particular counter-example can be shown from Gödel's axioms.

Religious scholar Fr. Robert J. Spitzer accepted Gödel's proof, calling it "an improvement over the Anselmian Ontological Argument (which does not work)."

There are, however, many more criticisms, most focusing on the philosophically interesting question of whether these axioms "must" be rejected to avoid odd conclusions. The broader criticism is that even if the axioms cannot be shown to be false, that does not mean that they are true. Hilbert's famous remark about interchangeability of the primitives' names applies to those in Gödel's ontological axioms ("positive", "god-like", "essence") as well as to those in Hilbert's geometry axioms ("point", "line", "plane"). According to André Fuhrmann (2005) it remains to show that the dazzling notion prescribed by traditions and often believed to be essentially mysterious satisfies Gödel's axioms. This is not a mathematical, but merely a theological task. It is this task which decides which religion's god has been proven to exist.

Christoph Benzmüller and Bruno Woltzenlogel-Paleo formalized Gödel's proof to a level that is suitable for automated theorem proving or at least computer verification via proof assistants. The effort made headlines in German newspapers. According to the authors of this effort, they were inspired by Melvin Fitting's book.

In 2014, they computer-verified Gödel's proof (in the above version).
They also proved that this version's axioms are consistent,
but imply modal collapse, thus confirming Sobel's 1987 argument.

In the same paper, they suspected Gödel's original version of the axioms to be inconsistent, as they failed to prove their consistency.
In 2016, they gave a computer proof that this version implies formula_2, i.e. is inconsistent in every modal logic with a reflexive or symmetric accessibility relation.
Moreover, they gave an argument that this version is inconsistent in every logic at all, but failed to duplicate it by automated provers. In the same paper they suggested that modal collapse is not necessarily a flaw.

A humorous variant of Gödel's ontological proof is mentioned in Quentin Canterel's novel "The Jolly Coroner".
The proof is also mentioned in the TV series "Hand of God".





</doc>
<doc id="12422" url="https://en.wikipedia.org/wiki?curid=12422" title="List of gymnasts">
List of gymnasts

Gymnasts are people who participate in the sport of gymnastics. This sport contains disciplines that include, but are not limited to:

This list is of those who are considered to be notable in their chosen discipline.

See gymnasium (ancient Greece) for the origin of the word "gymnast" from gymnastikos.




</doc>
<doc id="12424" url="https://en.wikipedia.org/wiki?curid=12424" title="Genetic programming">
Genetic programming

In artificial intelligence, genetic programming (GP) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs. It is essentially a heuristic search technique often described as 'hill climbing', i.e. searching for an optimal or at least suitable program among the space of all programs.

The operations are: selection of the fittest programs for reproduction (crossover) and mutation according to a predefined fitness measure, usually proficiency at the desired task. The crossover operation involves swapping random parts of selected pairs (parents) to produce new and different offspring that become part of the new generation of programs. Mutation involves substitution of some random part of a program with some other random part of a program. - Some programs not selected for reproduction are copied from the current generation to the new generation. Then the selection and other operations are recursively applied to the new generation of programs.

Typically, members of each new generation are on average more fit than the members of the previous generation, and the best-of-generation program is often better than the best-of-generation programs from previous generations. Termination of the recursion is when some individual program reaches a predefined proficiency or fitness level.

It may and often does happen that a particular run of the algorithm results in premature convergence to some local maximum which
is not a globally optimal or even good solution. Multiple runs (dozens to hundreds) are usually necessary to produce a very good result. It may also be necessary to increase the starting population size and variability of the individuals to avoid pathologies.

The technique, embodied in a system called the 'invention machine' was patented by Stanford University computer scientist John Koza in 1988.

The first record of the proposal to evolve programs is probably that of Alan Turing in 1950. There was a gap of 25 years before the publication of John Holland's 'Adaptation in Natural and Artificial Systems' laid out the theoretical and empirical foundations of the science. In 1981, Richard Forsyth demonstrated the successful evolution of small programs, represented as trees, to perform classification of crime scene evidence for the UK Home Office. 

Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Holland’s students, it was not until they organised the first Genetic Algorithms conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages. In 1988 John Koza (also a PhD student of John Holland) patented his invention of a GA for program evolution. This was followed by publication in the International Joint Conference on Artificial Intelligence IJCAI-89.

Koza followed this with 205 publications on “Genetic Programming” (GP), name coined by David Goldberg, also a PhD student of John Holland. However, it is the series of 4 books by Koza, starting in 1992 with accompanying videos, that really established GP. Subsequently, there was an enormous expansion of the number of publications with the Genetic Programming Bibliography, surpassing 10,000 entries. In 2010, Koza listed 77 results where Genetic Programming was human competitive.

In 1996 Koza started the annual Genetic Programming conference which was followed in 1998 by the annual EuroGP conference, and the first book in a GP series edited by Koza. 1998 also saw the first GP textbook. GP continued to flourish, leading to the first specialist GP journal and three years later (2003) the annual Genetic Programming Theory and Practice (GPTP) workshop was established by Rick Riolo. Genetic Programming papers continue to be published at a diversity of conferences and associated journals. Today there are nineteen GP books including several for students.

Early work that set the stage for current genetic programming research topics and applications is diverse, and includes software synthesis and repair, predictive modeling, data mining, financial modeling, soft sensors, design, and image processing. Applications in some areas, such as design, often make use of intermediate representations, such as Fred Gruau’s cellular encoding. Industrial uptake has been significant in several areas including finance, the chemical industry, bioinformatics and the steel industry.

GP evolves computer programs, traditionally represented in memory as tree structures. Trees can be easily evaluated in a recursive manner. Every tree node has an operator function and every terminal node has an operand, making mathematical expressions easy to evolve and evaluate. Thus traditionally GP favors the use of programming languages that naturally embody tree structures (for example, Lisp; other functional programming languages are also suitable).

Non-tree representations have been suggested and successfully implemented, such as linear genetic programming which suits the more traditional imperative languages [see, for example, Banzhaf "et al." (1998)]. The commercial GP software "Discipulus" uses automatic induction of binary machine code ("AIM") to achieve better performance. "µGP" uses directed multigraphs to generate programs that fully exploit the syntax of a given assembly language. Other program representations on which significant research and development have been conducted include programs for stack-based virtual machines, and sequences of integers that are mapped to arbitrary programming languages via grammars. Cartesian genetic programming is another form of GP, which uses a graph representation instead of the usual tree based representation to encode computer programs.

Most representations have structurally noneffective code (introns). Such non-coding genes may seem to be useless, because they have no effect on the performance of any one individual. However, they alter the probabilities of generating different offspring under the variation operators, and thus alter the individual's variational properties.
Experiments seem to show faster convergence when using program representations that allow such non-coding genes, compared to program representations that do not have any non-coding genes.

Selection is a process whereby certain individuals are selected from the current generation that would serve as parents for the next generation. The individuals are selected probabilistically such that the better performing individuals have a higher chance of getting selected. The most commonly used selection method in GP is tournament selection, although other methods such as fitness proportionate selection, lexicase selection, and others have been demonstrated to perform better for many GP problems.

Elitism, which involves seeding the next generation with the best individual (or best "n" individuals) from the current generation, is a technique sometimes employed to avoid regression.

Various genetic operators (i.e., crossover and mutation) are applied to the individuals selected in the selection step described above to breed new individuals. The rate at which these operators are applied determine the diversity in the population.

GP has been successfully used as an automatic programming tool, a machine learning tool and an automatic problem-solving engine. GP is especially useful in the domains where the exact form of the 
solution is not known in advance or an approximates solution is acceptable (possibly because finding the exact solution is very difficult). Some of the applications of GP are curve fitting, data modeling, Symbolic regression, feature selection, classification, etc. John R. Koza mentions 76
instances where Genetic Programming has been able to produce results that are competitive with human-produced results (called Human-competitive results). Since 2004, the annual Genetic and Evolutionary Computation Conference (GECCO) holds Human Competitive Awards (called Humies) competition, where cash awards are presented to human-competitive results produced by any form of genetic and evolutionary computation. GP has won many awards in this competition over the years.

Meta-genetic programming is the proposed meta learning technique of evolving a genetic programming system using genetic programming itself. It suggests that chromosomes, crossover, and mutation were themselves evolved, therefore like their real life counterparts should be allowed to change on their own rather than being determined by a human programmer. Meta-GP was formally proposed by Jürgen Schmidhuber in 1987. Doug Lenat's Eurisko is an earlier effort that may be the same technique. It is a recursive but terminating algorithm, allowing it to avoid infinite recursion. In the "autoconstructive evolution" approach to meta-genetic programming, the methods for the production and variation of offspring are encoded within the evolving programs themselves, and programs are executed to produce new programs to be added to the population.

Critics of this idea often say this approach is overly broad in scope. However, it might be possible to constrain the fitness criterion onto a general class of results, and so obtain an evolved GP that would more efficiently produce results for sub-classes. This might take the form of a meta evolved GP for producing human walking algorithms which is then used to evolve human running, jumping, etc. The fitness criterion applied to the meta GP would simply be one of efficiency.




</doc>
<doc id="12425" url="https://en.wikipedia.org/wiki?curid=12425" title="Gustav Klimt">
Gustav Klimt

Gustav Klimt (July 14, 1862 – February 6, 1918) was an Austrian symbolist painter and one of the most prominent members of the Vienna Secession movement. Klimt is noted for his paintings, murals, sketches, and other objets d'art. Klimt's primary subject was the female body, and his works are marked by a frank eroticism. In addition to his figurative works, which include allegories and portraits, he painted landscapes. Among the artists of the Vienna Secession, Klimt was the most influenced by Japanese art and its methods.

Early in his artistic career, he was a successful painter of architectural decorations in a conventional manner. As he developed a more personal style, his work was the subject of controversy that culminated when the paintings he completed around 1900 for the ceiling of the Great Hall of the University of Vienna were criticized as pornographic. He subsequently accepted no more public commissions, but achieved a new success with the paintings of his "golden phase", many of which include gold leaf. Klimt's work was an important influence on his younger contemporary Egon Schiele.

Gustav Klimt was born in Baumgarten, near Vienna in Austria-Hungary, the second of seven children—three boys and four girls. His mother, Anna Klimt ("née" Finster), had an unrealized ambition to be a musical performer. His father, Ernst Klimt the Elder, formerly from Bohemia, was a gold engraver. All three of their sons displayed artistic talent early on. Klimt's younger brothers were Ernst Klimt and Georg Klimt.

Klimt lived in poverty while attending the Vienna Kunstgewerbeschule, a school of applied arts and crafts, now the University of Applied Arts Vienna, where he studied architectural painting from 1876 until 1883. He revered Vienna's foremost history painter of the time, Hans Makart. Klimt readily accepted the principles of a conservative training; his early work may be classified as academic. In 1877 his brother, Ernst, who, like his father, would become an engraver, also enrolled in the school. The two brothers and their friend, Franz Matsch, began working together and by 1880 they had received numerous commissions as a team that they called the "Company of Artists". They also helped their teacher in painting murals in the Kunsthistorisches Museum in Vienna. Klimt began his professional career painting interior murals and ceilings in large public buildings on the Ringstraße, including a successful series of "Allegories and Emblems".

In 1888 Klimt received the Golden Order of Merit from Emperor Franz Josef I of Austria for his contributions to murals painted in the Burgtheater in Vienna. He also became an honorary member of the University of Munich and the University of Vienna. In 1892 Klimt's father and brother Ernst both died, and he had to assume financial responsibility for his father's and brother's families. The tragedies also affected his artistic vision and soon he would move towards a new personal style. 
Characteristic of his style at the end of the 19th century is the inclusion of "Nuda Veritas" ("naked truth") as a symbolic figure in some of his works, including "Ancient Greece and Egypt" (1891), "Pallas Athene" (1898) and "Nuda Veritas" (1899). Historians believe that Klimt with the "nuda veritas" denounced both the policy of the Habsburgs and Austrian society, which ignored all political and social problems of that time. 
In the early 1890s Klimt met Austrian fashion designer Emilie Louise Flöge (a sibling of his sister-in-law) who was to be his companion until the end of his life. His painting, "The Kiss" (1907–08), is thought to be an image of them as lovers. He designed many costumes that she produced and modeled in his works.

During this period Klimt fathered at least fourteen children.

Klimt became one of the founding members and president of the "Wiener Sezession" (Vienna Secession) in 1897 and of the group's periodical, "Ver Sacrum" ("Sacred Spring"). He remained with the Secession until 1908. The goals of the group were to provide exhibitions for unconventional young artists, to bring the works of the best foreign artists to Vienna, and to publish its own magazine to showcase the work of members. The group declared no manifesto and did not set out to encourage any particular style—Naturalists, Realists, and Symbolists all coexisted. The government supported their efforts and gave them a lease on public land to erect an exhibition hall. The group's symbol was Pallas Athena, the Greek goddess of just causes, wisdom, and the arts—of whom Klimt painted his radical version in 1898.

In 1894, Klimt was commissioned to create three paintings to decorate the ceiling of the Great Hall of the University of Vienna. Not completed until the turn of the century, his three paintings, "Philosophy", "Medicine", and "Jurisprudence" were criticized for their radical themes and material, and were called "pornographic". Klimt had transformed traditional allegory and symbolism into a new language that was more overtly sexual and hence more disturbing to some. The public outcry came from all quarters—political, aesthetic and religious. As a result, the paintings "(seen in gallery below)" were not displayed on the ceiling of the Great Hall. This would be the last public commission accepted by the artist.

All three paintings were destroyed when retreating German forces burned Schloss Immendorf in May 1945.

His "Nuda Veritas" (1899) defined his bid to further "shake up" the establishment. The starkly naked red-headed woman holds the mirror of truth, while above her is a quotation by Friedrich Schiller in stylized lettering: "If you cannot please everyone with your deeds and your art, please only a few. To please many is bad."

In 1902, Klimt finished the "Beethoven Frieze" for the Fourteenth Vienna Secessionist exhibition, which was intended to be a celebration of the composer and featured a monumental polychrome sculpture by Max Klinger. Intended for the exhibition only, the frieze was painted directly on the walls with light materials. After the exhibition the painting was preserved, although it was not displayed again until 1986. The face on the Beethoven portrait resembled the composer and Vienna Court Opera director Gustav Mahler.

During this period Klimt did not confine himself to public commissions. Beginning in the late 1890s he took annual summer holidays with the Flöge family on the shores of Attersee and painted many of his landscapes there. These landscapes constitute the only genre aside from figure painting that seriously interested Klimt. In recognition of his intensity, the locals called him Waldschrat ("forest demon").

Klimt's Attersee paintings are of sufficient number and quality as to merit separate appreciation. Formally, the landscapes are characterized by the same refinement of design and emphatic patterning as the figural pieces. Deep space in the Attersee works is flattened so efficiently to a single plane that it is believed that Klimt painted them by using a telescope.

Klimt's 'Golden Phase' was marked by positive critical reaction and financial success. Many of his paintings from this period included gold leaf. Klimt had previously used gold in his "Pallas Athene" (1898) and "Judith I" (1901), although the works most popularly associated with this period are the "Portrait of Adele Bloch-Bauer I" (1907) and "The Kiss" (1907–08).

Klimt travelled little, but trips to Venice and Ravenna, both famous for their beautiful mosaics, most likely inspired his gold technique and his Byzantine imagery. In 1904, he collaborated with other artists on the lavish Palais Stoclet, the home of a wealthy Belgian industrialist that was one of the grandest monuments of the Art Nouveau age. Klimt's contributions to the dining room, including both "Fulfillment" and "Expectation", were some of his finest decorative works, and as he publicly stated, "probably the ultimate stage of my development of ornament."

In 1905, Klimt created a painted portrait of Margarete Wittgenstein, Ludwig Wittgenstein's sister, on the occasion of her marriage. Then, between 1907 and 1909, Klimt painted five canvases of society women wrapped in fur. His apparent love of costume is expressed in the many photographs of Flöge modeling clothing he had designed.

As he worked and relaxed in his home, Klimt normally wore sandals and a long robe with no undergarments. His simple life was somewhat cloistered, devoted to his art, family, and little else except the Secessionist Movement. He avoided café society and seldom socialized with other artists. Klimt's fame usually brought patrons to his door and he could afford to be highly selective. His painting method was very deliberate and painstaking at times and he required lengthy sittings by his subjects. Although very active sexually, he kept his affairs discreet and he avoided personal scandal.

Klimt wrote little about his vision or his methods. He wrote mostly postcards to Flöge and kept no diary. In a rare writing called "Commentary on a non-existent self-portrait", he states "I have never painted a self-portrait. I am less interested in myself as a subject for a painting than I am in other people, above all women... There is nothing special about me. I am a painter who paints day after day from morning to night ... Who ever wants to know something about me ... ought to look carefully at my pictures."

In 1901 Hermann Bahr wrote, in his "Speech on Klimt": "Just as only a lover can reveal to a man what life means to him and develop its innermost significance, I feel the same about these paintings."

In 1911 his painting "Death and Life" received first prize in the world exhibitions in Rome. In 1915 Anna, his mother, died. Klimt died three years later in Vienna on February 6, 1918, having suffered a stroke and pneumonia due to the worldwide influenza epidemic of that year. He was buried at the Hietzinger Cemetery in Hietzing, Vienna. Numerous paintings by him were left unfinished.

Klimt's paintings have brought some of the highest prices recorded for individual works of art. In November 2003, Klimt's "Landhaus am Attersee" sold for $29,128,000, but that sale was soon eclipsed by prices paid for Willem de Kooning's "Woman III" and later Klimt's own "Adele Bloch-Bauer II", the latter of which sold for $150 million in 2016. More frequently than paintings, however, the artist's works on paper can be found on the art market. The art market database Artprice lists 67 auction entries for paintings, but 1564 for drawings and watercolors. The most expensive drawing sold so far was "Reclining Female Nude Facing Left", which was made between 1914 and 1915 and sold in London in 2008 for . However, the majority of the art trade traditionally takes place privately through galleries such as Wienerroither & Kohlbacher, which specialize in the trade with original works by Gustav Klimt and Egon Schiele and regularly present these at monographic exhibitions and international art fairs.

In 2006, the 1907 portrait, "Adele Bloch-Bauer I", was purchased for the Neue Galerie New York by Ronald Lauder reportedly for US $135 million, surpassing Picasso's 1905 "Boy With a Pipe" (sold May 5, 2004 for $104 million), as the highest reported price ever paid for a painting up to that point.

On August 7, 2006, Christie's auction house announced it was handling the sale of the remaining four works by Klimt that were recovered by Maria Altmann and her co-heirs after their long legal battle against Austria (see "Republic of Austria v. Altmann"). Maria Altmann's fight to regain her family's paintings has been the subject of a number of documentary films, including "Adele's Wish". Her struggle also became the subject of the dramatic film the "Woman in Gold", a movie inspired by "Stealing Klimt", the documentary featuring Maria Altmann herself. The portrait of "Adele Bloch-Bauer II" was sold at auction in November 2006 for $88 million, the third-highest priced piece of art at auction at the time. "The Apple Tree I" (c. 1912) sold for $33 million, "Birch Forest" (1903) sold for $40.3 million, and "Houses in Unterach on Lake Atter" (1916) sold for $31 million. Collectively, the five restituted paintings netted more than $327 million. The painting "Litzlberg am Attersee" was auctioned for $40.4 million at Sotheby's in November 2011.

The city of Vienna, Austria had many special exhibitions commemorating the 150th anniversary of Klimt's birth in 2012.

The only folio set produced in Klimt's lifetime, "Das Werk Gustav Klimts", was published initially by H. O. Miethke (of Gallerie Miethke, Klimt's exclusive gallery in Vienna) from 1908 to 1914 in an edition of 300, supervised personally by the artist. The first thirty-five editions (I-XXXV) each included an original drawing by Klimt, and the next thirty-five editions (XXXVI-LXX) each with a facsimile signature on the title page. Fifty images depicting Klimt's most important paintings (1893–1913) were reproduced using collotype lithography and mounted on a heavy, cream-colored wove paper with deckled edges. Thirty-one of the images (ten of which are multicolored) are printed on "Chine-collé". The remaining nineteen are high quality halftones prints. Each piece was marked with a unique signet—designed by Klimt—which was impressed into the wove paper in gold metallic ink. The prints were issued in groups of ten to subscribers, in unbound black paper folders embossed with Klimt's name. Because of the delicate nature of collotype lithography, as well as the necessity for multicolored prints (a feat difficult to reproduce with collotypes), and Klimt's own desire for perfection, the series that was published in mid-1908 was not completed until 1914.

Each of the fifty prints was categorized among five themes:

The monochrome collotypes as well as the halftone works were printed with a variety of colored inks ranging from sepia to blue and green. Emperor Franz Joseph I of Austria was the first to purchase a folio set of "Das Werk Gustav Klimts" in 1908.

"Fünfundzwanzig Handzeichnungen" ("Twenty-five Drawings") was released the year after Klimt's death. Many of the drawings in the collection were erotic in nature and just as polarizing as his painted works. Published in Vienna in 1919 by Gilhofer & Ranschburg, the edition of 500 features twenty-five monochrome and two-color collotype reproductions, nearly indistinguishable from the original works. While the set was released a year after Klimt's death, some art historians suspect he was involved with production planning due to the meticulous nature of the printing (Klimt had overseen the production of the plates for "Das Werk Gustav Klimts", making sure each one was to his exact specifications, a level of quality carried through similarly in "Fünfundzwanzig Handzeichnungen"). The first ten editions also each contained an original Klimt drawing.

Many of the works contained in this volume depict erotic scenes of nude women, some of whom are masturbating alone or are coupled in sapphic embraces. When a number of the original drawings were exhibited to the public, at Gallerie Miethke in 1910 and the International Exhibition of Prints and Drawings in Vienna in 1913, they were met by critics and viewers who were hostile towards Klimt's contemporary perspective. There was an audience for Klimt's erotic drawings, however, and fifteen of his drawings were selected by Viennese poet Franz Blei for his translation of Hellenistic satirist Lucian's "Dialogues of the Courteseans". The book, limited to 450 copies, provided Klimt the opportunity to show these more lurid depictions of women and avoided censorship thanks to an audience composed of a small group of (mostly male) affluent patrons.

Composed in 1931 by editor Max Eisler and printed by the Austrian State Printing Office, "Gustav Klimt An Aftermath" was intended to complete the lifetime folio "Das Werk Gustav Klimts". The folio contains thirty colored collotypes (fourteen of which are multicolored) and follows a similar format found in "Das Werk Gustav Klimts", replacing the unique Klimt-designed signets with gold-debossed plate numbers. One hundred and fifty sets were produced in English, with twenty of them (Nos. I–XX) presented as a "gala edition" bound in gilt leather. The set contains detailed images from previously released works (Hygeia from the University Mural "Medicine", 1901; a section of the third University Mural "Jurisprudence", 1903), as well as the unfinished paintings ("Adam and Eve", "Bridal Progress").

In 1963, the Albertina Museum in Vienna began researching the drawings of Gustav Klimt. The research project "Gustav Klimt. Die Zeichnungen", has since been associated with intensive exhibition and publication activities.

Between 1980 and 1984 Alice Strobl published the three-volume catalogue raisonné, which records and describes all drawings by Gustav Klimt known at the time in chronological order. An additional supplementary volume was published in 1989. In the following year Alice Strobl transferred her work to the art historian and curator Marian Bisanz-Prakken, who had assisted her since 1975 in the determination and classification of the works and who continues the research project to this day. Since 1990, Marian Bisanz-Prakken has redefined, documented, and scientifically processed around 400 further drawings.

This makes the Albertina Vienna the only institution in the world that has been examining and scientifically classifying the artist's works for half a century. The research project now includes information on over 4300 works by Gustav Klimt.

According to the writer Frank Whitford: "Klimt of course, is an important artist—he's a very "popular" artist—but in terms of the history of art, he's a very unimportant artist. Although he sums up so much in his work, about the society in which he found himself—in art historical terms his effect was negligible. So he's an artist really in a cul-de-sac." Klimt's work had a strong influence on the paintings of Egon Schiele, with whom he would collaborate to found the "Kunsthalle" (Hall of Art) in 1917, to try to keep local artists from going abroad. Artists who reinterpreted Klimt's work include Slovak artist Rudolf Fila.

Several of Klimt's most famous works from his golden period inspired the title sequence for the animated adaptation of the manga series, "Elfen Lied", in which the art is recreated to fit with the series' own characters and is arranged as a montage with the song "Lilium". The opening to the anime "Sound of the Sky" also is largely inspired by Klimt's works, which was also directed by the same director as "Elfen Lied". The design of the land of Centopia on the TV series "Mia and Me" is inspired by Klimt's works. The art of the video game "Transistor" also uses patterns and embellishments inspired by Klimt.

Couturier John Galliano found inspiration for the Christian Dior Spring-Summer 2008 haute couture collection in Klimt's work.

Gustav Klimt and his work have been the subjects of many collector coins and medals, such as the 100 Euro Painting Gold Coin, issued on November 5, 2003, by the Austrian Mint. The obverse depicts Klimt in his studio with two unfinished paintings on easels.

In addition to the permanent exhibitions on display, the city of Vienna, Austria celebrated the 150th anniversary of the birth of Klimt with special exhibitions throughout the city. Guided walking tours through the city allowed people to see some of the buildings where Klimt worked.

Google commemorated Gustav Klimt with a Google doodle celebrating Klimt's painting "The Kiss" on his 150th birthday, 14 July 2012.

In 2012, the Austrian Mint began a five-coin gold series to coincide with the 150th anniversary of Klimt's birth. The first 50 Euro gold coin was issued on January 25, 2012 and featured a portrait of Klimt on the obverse and a portion of his painting of Adele Bloch-Bauer.

In 2013, the Gustav Klimt Foundation was set up by Ursula Ucicky, widow of Klimt's illegitimate son Gustav Ucicky, with a mission to "preserve and disseminate Gustav Klimt's legacy." The managing director of the Leopold Museum, Peter Weinhäupl, was appointed as Chairman of the foundation. As a reaction, the museum's director Tobias G. Natter resigned in protest, citing Ucicky's past as a Nazi propaganda film-maker.





</doc>
<doc id="12426" url="https://en.wikipedia.org/wiki?curid=12426" title="Groucho Marx">
Groucho Marx

Julius Henry "Groucho" Marx (; October 2, 1890 – August 19, 1977) was an American comedian, writer, stage, film, radio, and television star. A master of quick wit, he is widely considered one of America's greatest comedians.

He made 13 feature films with his siblings the Marx Brothers, of whom he was the third-born. He also had a successful solo career, most notably as the host of the radio and television game show "You Bet Your Life".

His distinctive appearance, carried over from his days in vaudeville, included quirks such as an exaggerated stooped posture, spectacles, cigar, and a thick greasepaint mustache and eyebrows. These exaggerated features resulted in the creation of one of the most recognizable and ubiquitous novelty disguises, known as Groucho glasses: a one-piece mask consisting of horn-rimmed glasses, a large plastic nose, bushy eyebrows and mustache.

Julius Marx was born on October 2, 1890, in Manhattan, New York. Marx stated that he was born in a room above a butcher's shop on East 78th Street, "Between Lexington & 3rd", as he told Dick Cavett in a 1969 television interview. The Marx children grew up on East 93rd Street off Lexington Avenue in a neighborhood now known as Carnegie Hill on the Upper East Side of the borough of Manhattan. The turn-of-the-century building that his brother Harpo in his memoir "Harpo Speaks" called "the first real home they ever knew", was populated with European immigrants, mostly artisans. Just across the street were the oldest brownstones in the area, owned by people such as the well-connected Loew Brothers and William Orth. The Marx family lived there "for about 14 years", Groucho also told Cavett.
Marx's family was Jewish. Groucho's mother was Miene "Minnie" Schoenberg, whose family came from Dornum in northern Germany when she was 16 years old. His father was Simon "Sam" Marx, who changed his name from Marrix, and was called "Frenchie" by his sons throughout his life, because he and his family came from Alsace in France. Minnie's brother was Al Schoenberg, who shortened his name to Al Shean when he went into show business as half of Gallagher and Shean, a noted vaudeville act of the early 20th century. According to Groucho, when Shean visited, he would throw the local waifs a few coins so that when he knocked at the door he would be surrounded by adoring fans. Marx and his brothers respected his opinions and asked him on several occasions to write some material for them.

Minnie Marx did not have an entertainment industry career but had intense ambition for her sons to go on the stage like their uncle. While pushing her eldest son Leonard (Chico Marx) in piano lessons, she found that Julius had a pleasant soprano voice and the ability to remain on key. Julius's early career goal was to become a doctor, but the family's need for income forced him out of school at the age of twelve. By that time, young Julius had become a voracious reader, particularly fond of Horatio Alger. Marx would continue to overcome his lack of formal education by becoming well-read.

After a few stabs at entry-level office work and jobs suitable for adolescents, Julius took to the stage as a boy singer with the Gene Leroy Trio, debuting at the Ramona Theatre in Grand Rapids, MI, on July 16, 1905. Marx reputedly claimed that he was "hopelessly average" as a vaudevillian, but this was typical Marx, wisecracking in his true form. By 1909, Minnie Marx had assembled her sons into an undistinguished vaudeville singing group billed as "The Four Nightingales". The brothers Julius, Milton (Gummo Marx) and Arthur (originally Adolph, but Harpo Marx from 1911) and another boy singer, Lou Levy, traveled the U.S. vaudeville circuits to little fanfare. After exhausting their prospects in the East, the family moved to La Grange, Illinois, to play the Midwest.
After a particularly dispiriting performance in Nacogdoches, Texas, Julius, Milton, and Arthur began cracking jokes onstage for their own amusement. Much to their surprise, the audience liked them better as comedians than as singers. They modified the then-popular Gus Edwards comedy skit "School Days" and renamed it "Fun In Hi Skule". The Marx Brothers would perform variations on this routine for the next seven years.

For a time in vaudeville, all the brothers performed using ethnic accents. Leonard, the oldest, developed the Italian accent he used as Chico Marx to convince some roving bullies that he was Italian, not Jewish. Arthur, the next oldest, donned a curly red wig and became "Patsy Brannigan", a stereotypical Irish character. His discomfort when speaking on stage led to his uncle Al Shean's suggestion that he stop speaking altogether and play the role in mime. Julius Marx's character from "Fun In Hi Skule" was an ethnic German, so Julius played him with a German accent. After the sinking of the in 1915, public anti-German sentiment was widespread, and Marx's German character was booed, so he quickly dropped the accent and developed the fast-talking wise-guy character that became his trademark.

The Marx Brothers became the biggest comedic stars of the Palace Theatre in New York, which billed itself as the "Valhalla of Vaudeville". Brother Chico's deal-making skills resulted in three hit plays on Broadway. No other comedy routine had ever so infected the Broadway circuit. All of this stage work predated their Hollywood career. By the time the Marxes made their first movie, they were already major stars with sharply honed skills; and by the time Groucho was relaunched to stardom on "You Bet Your Life", he had been performing successfully for half a century.

Groucho Marx started his career in vaudeville in 1905 when he joined up with an act called The Leroy Trio. He was asked by a man named Robin Leroy to join the group as a singer, along with fellow vaudeville actor Johnny Morris. Through this act, Groucho got his first taste of life as a vaudeville performer. In 1909, Groucho and his brothers had become a group act, at first called The Three Nightingales and later The Four Nightingales. The brothers' mother, Minnie Marx, was the group's manager, putting them together and booking their shows. The group had a rocky start, performing in less than adequate venues and rarely, if ever, being paid for their performances. Eventually one of the brothers would leave to serve in World War I and was replaced by Herbert (Zeppo), and the group became known as the Marx Brothers. Their first successful show was "Fun In Hi Skule" (1910).

Groucho Marx made 26 movies, 13 of them with his brothers Chico and Harpo. Marx developed a routine as a wisecracking hustler with a distinctive chicken-walking lope, an exaggerated greasepaint mustache and eyebrows, and an ever-present cigar, improvising insults to stuffy dowagers (usually played by Margaret Dumont) and anyone else who stood in his way. As the Marx Brothers, he and his brothers starred in a series of popular stage shows and movies.

Their first movie was a silent film made in 1921 that was never released, and is believed to have been destroyed at the time. A decade later, the team made two of their Broadway hits—"The Cocoanuts" and "Animal Crackers"—into movies. Other successful films were "Monkey Business", "Horse Feathers", "Duck Soup", and "A Night at the Opera". One quip from Marx concerned his response to Sam Wood, the director of "A Night at the Opera". Furious with the Marx Brothers' ad-libs and antics on the set, Wood yelled in disgust: "You can't make an actor out of clay." Groucho responded, "Nor a director out of Wood."

Marx also worked as a radio comedian and show host. One of his earliest stints was a short-lived series in 1932, "Flywheel, Shyster, and Flywheel," costarring Chico. Though most of the scripts and discs were thought to have been destroyed, all but one of the scripts were found in 1988 in the Library of Congress.
In 1947, Marx was asked to host a radio quiz program "You Bet Your Life." It was broadcast by ABC and then CBS before moving to NBC. It moved from radio to television on October 5, 1950, and ran for eleven years. Filmed before an audience, the show consisted of Marx bantering with the contestants and ad-libbing jokes before briefly quizzing them. The show was responsible for popularizing the phrases "Say the secret word and the duck will come down and give you fifty dollars," "Who's buried in Grant's Tomb?" and "What color is the White House?" (asked to reward a losing contestant a consolation prize).

Throughout his career, Marx introduced a number of memorable songs in films, including "Hooray for Captain Spaulding" and "Hello, I Must Be Going", in "Animal Crackers", "Whatever It Is, I'm Against It", "Everyone Says I Love You" and "Lydia the Tattooed Lady". Frank Sinatra, who once quipped that the only thing he could do better than Marx was sing, made a film with Marx and Jane Russell in 1951 entitled "Double Dynamite".

In public and off-camera, Harpo and Chico were hard to recognize, without their wigs and costumes, and it was almost impossible for fans to recognize Groucho without his trademark eyeglasses, fake eyebrows, and mustache.
The greasepaint mustache and eyebrows originated spontaneously prior to a vaudeville performance in the early 1920s when he did not have time to apply the pasted-on mustache he had been using (or, according to his autobiography, simply did not enjoy the removal of the mustache because of the effects of tearing an adhesive bandage off the same patch of skin every night). After applying the greasepaint mustache, a quick glance in the mirror revealed his natural hair eyebrows were too undertoned and did not match the rest of his face, so Marx added the greasepaint to his eyebrows and headed for the stage. The absurdity of the greasepaint was never discussed on-screen, but in a famous scene in "Duck Soup," where both Chicolini (Chico) and Pinky (Harpo) disguise themselves as Groucho, they are briefly seen applying the greasepaint, implicitly answering any question a viewer might have had about where he got his mustache and eyebrows.

Marx was asked to apply the greasepaint mustache once more for "You Bet Your Life" when it came to television, but he refused, opting instead to grow a real one, which he wore for the rest of his life. By this time, his eyesight had weakened enough for him actually to need corrective lenses; before then, his eyeglasses had merely been a stage prop. He debuted this new, and now much-older, appearance in "Love Happy," the Marx Brothers's last film as a comedy team.

He did paint the old character mustache over his real one on a few rare performing occasions, including a TV sketch with Jackie Gleason on the latter's variety show in the 1960s (in which they performed a variation on the song "Mister Gallagher and Mister Shean," co-written by Marx's uncle Al Shean) and the 1968 Otto Preminger film "Skidoo". In his late 70s at the time, Marx remarked on his appearance: "I looked like I was embalmed." He played a mob boss called "God" and, according to Marx, "both my performance and the film were God-awful!"

The exaggerated walk, with one hand on the small of his back and his torso bent almost 90 degrees at the waist was a parody of a fad from the 1880s and 1890s. Fashionable young men of the upper classes would affect a walk with their right hand held fast to the base of their spines, and with a slight lean forward at the waist and a very slight twist toward the right with the left shoulder, allowing the left hand to swing free with the gait. (Edmund Morris, in his biography "The Rise of Theodore Roosevelt", describes a young Roosevelt, newly elected to the State Assembly, walking into the House Chamber for the first time in this trendy, affected gait, somewhat to the amusement of the older and more rural members.) Groucho exaggerated this fad to a marked degree, and the comedy effect was enhanced by how out of date the fashion was by the 1940s and 1950s.

Groucho's three marriages ended in divorce. His first wife was chorus girl Ruth Johnson. He was 29 and she 19 at the time of their wedding. The couple had two children, Arthur Marx and Miriam Marx. His second wife was Kay Marvis (m. 1945–51), Catherine Dittig, former wife of Leo Gorcey. Groucho was 54 and Kay 21 at the time of their marriage. They had a daughter, Melinda Marx. His third wife was actress Eden Hartford.

During the early 1950s, Groucho described his perfect woman: "Someone who looks like Marilyn Monroe and talks like George S. Kaufman."

Groucho was denied membership in an informal symphonietta of friends (including Harpo) organized by Ben Hecht, because he could play only the mandolin. When the group began its first rehearsal at Hecht's home, Groucho rushed in and demanded silence from the "lousy amateurs". The musicians discovered him conducting the Los Angeles Symphony Orchestra in a performance of the overture to "Tannhäuser" in Hecht's living room. Groucho was allowed to join the symphonietta.

Later in life, Groucho would sometimes note to talk show hosts, not entirely jokingly, that he was unable to actually insult anyone, because the target of his comment would assume that it was a Groucho-esque joke, and would laugh.
Despite his lack of formal education, he wrote many books, including his autobiography, "Groucho and Me" (1959) and "Memoirs of a Mangy Lover" (1963). He was a friend of such literary figures as Booth Tarkington, T. S. Eliot and Carl Sandburg. Much of his personal correspondence with those and other figures is featured in the book "The Groucho Letters" (1967) with an introduction and commentary on the letters written by Groucho, who donated his letters to the Library of Congress. His daughter Miriam published a collection of his letters to her in 1992 titled "Love, Groucho."

Groucho made serious efforts to learn to play the guitar. In the 1932 film "Horse Feathers", Groucho performs the film's love theme "Everyone Says I Love You" for costar Thelma Todd on a Gibson L-5.

In July 1937, an America vs England pro-celebrity tennis doubles match was organized, featuring Marx and Ellsworth Vines playing against Charlie Chaplin and Fred Perry, to open the new clubhouse at the Beverly Hills Tennis Club. Marx appeared on court with 12 rackets and a suitcase, leaving Chaplin – who took tennis seriously – bemused, before he asked what was in it. Marx asked Chaplin what was in his, with Chaplin responding he didn’t have one. Marx replied, "What kind of tennis player are you?" After playing only a few games, Marx sat on the court and unpacked a picnic lunch from his suitcase.

Irving Berlin quipped, "The world would not be in such a snarl, had Marx been Groucho instead of Karl". In his book "The Groucho Phile", Marx says "I've been a liberal Democrat all my life", and "I frankly find Democrats a better, more sympathetic crowd... I'll continue to believe that Democrats have a greater regard for the common man than Republicans do". However, just like some of the other Democrats of the time, Marx also said in a television interview that he disliked the women's liberation movement. On the July 7, 1967, "Firing Line" TV show, Groucho said, "The whole political left is the Garden of Eden of incompetence."

"Marx & Lennon: The Parallel Sayings" was published in 2005; the book records similar sayings between Groucho Marx and John Lennon.

Groucho's radio career was not as successful as his work on stage and in film, though historians such as Gerald Nachman and Michael Barson suggest that, in the case of the single-season "Flywheel, Shyster, and Flywheel" (1932), the failure may have been a combination of a poor time slot and the Marx Brothers' returning to Hollywood to make another film.
In the mid-1940s, during a depressing lull in his career (his radio show "Blue Ribbon Town" had failed, he failed to sell his proposed sitcom "The Flotsam Family" only to see it become a huge hit as "The Life of Riley" with William Bendix in the title role, and the Marx Brothers as film performers were well past their prime), Groucho was scheduled to appear on a radio show with Bob Hope. Annoyed that he was made to wait in the green room for 40 minutes, Groucho went on the air in a foul mood.

Hope started by saying "Why, Groucho Marx! Groucho, what are you doing out here in the desert?" Groucho retorted, "Huh, desert, I've been sitting in the dressing room for forty minutes! Some desert alright..." Groucho continued to ignore the script, ad-libbing at length to take the scene well beyond its allotted time slot.

Listening in on the show was producer John Guedel, who had a brainstorm. He approached Groucho about doing a quiz show, to which Groucho derisively retorted, "A quiz show? Only actors who are completely washed up resort to a quiz show!" Undeterred, Guedel proposed that the quiz would be only a backdrop for Groucho's interviews of people, and the storm of ad-libbing that they would elicit. Groucho replied, "Well, I've had no success in radio, and I can't hold on to a sponsor. At this point, I'll try anything!"

"You Bet Your Life" debuted in October 1947 on ABC radio (which aired it from 1947 to 1949), sponsored by costume jewelry manufacturer Allen Gellman; and then on CBS (1949–50), and finally NBC. The show was on radio only from 1947 to 1950; on both radio and television from 1950 to 1960; and on television only, from 1960 to 1961. The show proved a huge hit, being one of the most popular on television by the mid-1950s. With George Fenneman as his announcer and straight man, Groucho entertained his audiences with improvised conversation with his guests. Since "You Bet Your Life" was mostly ad-libbed and unscripted—although writers did pre-interview the guests and feed Groucho ready-made lines in advance—the producers insisted that the network prerecord it instead of it being broadcast live. There were two reasons for this: prerecording provided Groucho with time to fish around for funny exchanges and any intervening dead spots to be edited out; and secondly to protect the network, since Groucho was a notorious loose cannon and known to say almost anything. The television show ran for 11 seasons until it was canceled in 1961. Automobile "marque" DeSoto was a longtime major sponsor. For the DeSoto ads, Marx would sometimes say: "Tell 'em Groucho sent you", or "Try a DeSoto before you decide".

The program's theme music was an instrumental version of "Hooray for Captain Spaulding", which became increasingly identified as Groucho's personal theme song. A recording of the song with Groucho and the Ken Lane singers with an orchestra directed by Victor Young was released in 1952. Another recording made by Groucho during this period was "The Funniest Song in the World", released on the Young People's Records label in 1949. It was a series of five original children's songs with a connecting narrative about a monkey and his fellow zoo creatures.

An apocryphal story relates Groucho interviewing Charlotte Story, who had borne 20 children. When Marx asked why she had chosen to raise such a large family, Mrs. Story is said to have replied, "I love my husband"; to which Marx responded, "I love my cigar, but I take it out of my mouth once in a while." The remark was judged too risqué to be aired, according to the anecdote, and was edited out before broadcast. Charlotte Story and her husband Marion, indeed parents of 20 children, were real people who appeared on the program in 1950. Audio recordings of the interview exist, and a reference to cigars is made ("With each new kid, do you go around passing out cigars?"), but there is no evidence of the claimed remark. Marx and Fenneman both denied that the incident took place. "I get credit all the time for things I never said," Marx told Roger Ebert in 1972. "You know that line in "You Bet Your Life"? The guy says he has seventeen kids and I say, 'I smoke a cigar, but I take it out of my mouth occasionally'? I never said that." Marx's 1976 memoir recounts the episode as fact, but co-writer Hector Arce relied mostly on sources other than Groucho himself—who was by then in his mid eighties, in ill health and mentally compromised—and was probably unaware that Groucho had specifically denied making the observation.

By the time "You Bet Your Life" debuted on TV on October 5, 1950, Groucho had grown a real mustache (which he had already sported earlier in the films "Copacabana" and "Love Happy").

During a tour of Germany in 1958, accompanied by then-wife Eden, daughter Melinda, Robert Dwan and Dwan's daughter Judith, he climbed a pile of rubble that marked the site of Adolf Hitler's bunker, the site of Hitler's death, and performed a two-minute Charleston. He later remarked to Richard J. Anobile in "The Marx Brothers Scrapbook," "Not much satisfaction after he killed six million Jews!"
In 1960, Groucho, a lifelong devotee of the comic operas of Gilbert and Sullivan, appeared as Ko-Ko, the Lord High Executioner, in a televised production of "The Mikado" on NBC's "Bell Telephone Hour". A clip of this is in rotation on Classic Arts Showcase.

Another TV show, "Tell It To Groucho", premiered January 11, 1962, on CBS, but only lasted five months. On October 1, 1962, Groucho, after acting as occasional guest host of "The Tonight Show" during the six-month interval between Jack Paar and Johnny Carson, introduced Carson as the new host.

In 1964, Marx starred in the "Time for Elizabeth" episode of "Bob Hope Presents the Chrysler Theatre", a truncated version of a play that Groucho Marx and Norman Krasna wrote in 1948.

In 1965, Groucho starred in a weekly show for British TV titled "Groucho", broadcast on ITV. The program was along similar lines to "You Bet Your Life", with Keith Fordyce taking on the Fenneman role. However, it was poorly received and lasted only 11 weeks.

Groucho appeared as a gangster named God in the movie "Skidoo" (1968), directed by Otto Preminger, and costarring Jackie Gleason and Carol Channing. It was released by the studio where the Marx Brothers began their film career, Paramount Pictures. The film received almost universally negative reviews. As a side note, writer Paul Krassner published a story in the February 1981 issue of "High Times", relating how Groucho prepared for the LSD-themed movie by taking a dose of the drug in Krassner's company, and had a moving, largely pleasant experience.

Groucho developed friendships with rock star Alice Cooper—the two were photographed together for "Rolling Stone" magazine—and television host Dick Cavett, becoming a frequent guest on Cavett's late-night talk show, even appearing in a one-man, 90-minute interview. He befriended Elton John when the British singer was staying in California in 1972, insisting on calling him "John Elton." According to writer Philip Norman, when Groucho jokingly pointed his index fingers as if holding a pair of six-shooters, Elton John put up his hands and said, "Don't shoot me, I'm only the piano player," thereby naming the album he had just completed. A film poster for the Marx Bros. movie "Go West" is visible on the album cover photograph as an homage to Groucho. Elton John accompanied Groucho to a performance of "Jesus Christ Superstar". As the lights went down, Groucho called out, "Does it have a happy ending?" And during the Crucifixion scene, he declared, "This is sure to offend the Jews."

Groucho's previous work regained popularity; new books of transcribed conversations were published by Richard J. Anobile and Charlotte Chandler. In a BBC interview in 1975, Groucho called his greatest achievement having a book selected for cultural preservation in the Library of Congress. In a Cavett interview in 1971, Groucho said being published in The New Yorker under his own name, Julius Henry Marx, meant more than all the plays he appeared in. As a man who never had formal schooling, to have his writings declared culturally important was a point of great satisfaction. As he passed his 81st birthday in 1971, however, Groucho became increasingly frail, physically and mentally, as a result of a succession of minor strokes.

In 1972, largely at the behest of his companion Erin Fleming, Groucho staged a live one-man show at Carnegie Hall that was later released as a double album, "An Evening with Groucho", on A&M Records. He also made an appearance in 1973 on a short-lived variety show hosted by Bill Cosby. Fleming's influence on Marx was controversial. Some close to Marx believed that she did much to revive his popularity, and the relationship with a younger woman boosted his ego and vitality. Others described her as a Svengali, exploiting an increasingly senile Marx in pursuit of her own stardom. Marx's children, particularly Arthur, felt strongly that Fleming was pushing their weak father beyond his physical and mental limits. Writer Mark Evanier concurred.

On the 1974 Academy Awards telecast, Marx's final major public appearance, Jack Lemmon presented him with an honorary Academy Award to a standing ovation. The award honored his brothers as well: "in recognition of his brilliant creativity and for the unequalled achievements of the Marx Brothers in the art of motion picture comedy." Noticeably frail, Groucho took a bow for his deceased brothers. "I wish that Harpo and Chico could be here to share with me this great honor," he said, naming the two deceased brothers. He also praised the late Margaret Dumont as a great straight woman who never understood any of his jokes. Groucho's final appearance was a brief sketch with George Burns in the Bob Hope television special "Joys" (a parody of the 1975 movie "Jaws") in March 1976. His health continued to decline the following year; when his younger brother Gummo died at age 84 on April 21, 1977, Groucho was never told for fear of eliciting still further deterioration of his health.

Groucho maintained his irrepressible sense of humor to the very end, however. George Fenneman, his radio and TV announcer, good-natured foil, and lifelong friend, often related a story of one of his final visits to Groucho's home: When the time came to end the visit, Fenneman lifted Groucho from his wheelchair, put his arms around his torso, and began to "walk" the frail comedian backwards across the room towards his bed. As he did, he heard a weak voice in his ear: "Fenneman," whispered Groucho, "you always were a lousy dancer." When a nurse approached him with a thermometer during his final hospitalization, explaining that she wanted to see if he had a temperature, he responded, "Don't be silly — everybody has a temperature." Actor Elliott Gould recalled a similar incident: "I recall the last time I saw Groucho, he was in the hospital, and he had tubes in his nose and what have you," he said. "And when he saw me, he was weak, but he was there; and he put his fingers on the tubes and played them like it was a clarinet. Groucho played the tubes for me, which brings me to tears."

Marx was hospitalized at Cedars-Sinai Medical Center with pneumonia on June 22, 1977, and died there nearly two months later at the age of 86 on August 19, four months after Gummo's death.

Groucho was cremated and the ashes are interred in the Eden Memorial Park Cemetery in Los Angeles. He was survived by his three children and younger brother Zeppo, who outlived him by two years. His gravestone bears no epitaph, but in one of his last interviews he suggested one: "Excuse me, I can't stand up."

Litigation over his estate lasted into the 1980s. Eventually, Arthur Marx and his sisters were awarded the bulk of the estate, and Erin Fleming was ordered to repay $472,000.

Groucho Marx was, and remains, the most recognizable and well-known of the Marx Brothers. Groucho-like characters and references have appeared in popular culture both during and after his life, some aimed at audiences who may never have seen a Marx Brothers movie. Groucho's trademark eyeglasses, nose, mustache, and cigar have become icons of comedy—glasses with fake noses and mustaches (referred to as "Groucho glasses", "nose-glasses," and other names) are sold by novelty and costume shops around the world.

Nat Perrin, close friend of Groucho Marx and writer of several Marx Brothers films, inspired John Astin's portrayal of Gomez Addams on the 1960s TV series "The Addams Family" with similarly thick mustache, eyebrows, sardonic remarks, backward logic, and ever-present cigar (pulled from his breast pocket already lit).
A meeting with Elton John led to a press photo of Groucho pointing both of his index fingers and thumbs at Elton like revolvers. John's spontaneous response of holding up his hands and replying, "Don't shoot me! I'm only the piano player!" was so amusing that Elton John reused it as the title of a 1973 album. An added Marx homage was that a poster for the Marx Brothers' movie "Go West" was included on the cover art.

Two albums by British rock band Queen, "A Night at the Opera" (1975) and "A Day at the Races" (1976), are named after Marx Brothers films. In March 1977, Groucho invited Queen to visit him in his Los Angeles home; there they performed "'39" a cappella.

A long-running ad campaign for Vlasic Pickles features an animated stork that imitates Groucho's mannerisms and voice. On the famous Hollywood Sign in California, one of the "O"s is dedicated to Groucho. Alice Cooper contributed over $27,000 to remodel the sign, in memory of his friend.

Actor Frank Ferrante has performed as Groucho Marx on stage for more than two decades. He continues to tour under rights granted by the Marx family in a show entitled "An Evening with Groucho" in theaters throughout the United States and Canada with supporting actors and piano accompanist Jim Furmston. In the late 1980s, Ferrante starred as Groucho in the off-Broadway and London show "" penned by Groucho's son Arthur. Ferrante portrayed the comedian from age 15 to 85. The show was later filmed for PBS in 2001. In 1982, Gabe Kaplan filmed a version of the same show, entitled "Groucho".

Woody Allen's 1996 musical "Everyone Says I Love You", in addition to being named for one of Groucho's signature songs, ends with a Groucho-themed New Year's Eve party in Paris, which some of the stars, including Allen and Goldie Hawn, attend in full Groucho costume. The highlight of the scene is an ensemble song-and-dance performance of "Hooray for Captain Spaulding"—done entirely in French.

On June 25, 2019, "The New York Times Magazine" listed Groucho Marx among hundreds of artists whose material was reportedly destroyed in the 2008 Universal fire.







</doc>
<doc id="12430" url="https://en.wikipedia.org/wiki?curid=12430" title="Game Boy Advance">
Game Boy Advance

The (commonly abbreviated as GBA) is a 32-bit handheld video game console developed, manufactured and marketed by Nintendo as the successor to the Game Boy Color. It was released in Japan on March 21, 2001, in North America on June 11, 2001, in Australia and Europe on June 22, 2001, and in mainland China on June 8, 2004 as iQue Game Boy Advance. The GBA was part of the sixth generation. The original model did not have an illuminated screen; Nintendo addressed that with the release of a redesigned model with a frontlit screen, the Game Boy Advance SP, in 2003. Another redesign, the Game Boy Micro, was released in 2005.

As of June 30, 2010, the Game Boy Advance series has sold 81.51 million units worldwide. Its successor, the Nintendo DS, was released in November 2004 and is also compatible with Game Boy Advance software.

Contrary to the previous Game Boy models, which were all following the "portrait" form factor of the original Game Boy (designed by Gunpei Yokoi), the Game Boy Advance was designed in a "landscape" form factor, putting the buttons to the sides of the device instead of below the screen. The Game Boy Advance was designed by the French designer Gwénaël Nicolas and his Tokyo-based design studio Curiosity Inc.

Word of a successor to the Game Boy Color (GBC) first emerged at the Nintendo Space World trade show in late August 1999, where it was reported that two new handheld systems were in the works: one of which being an improved version of the GBC with wireless online connectivity, codenamed the Advanced Game Boy (AGB), and a brand-new 32-bit system, which wasn’t set for release until the following year. On September 1, 1999, Nintendo officially announced the Game Boy Advance, revealing details about the system's specifications including online connectivity through a cellular device and an improved model of the Game Boy Camera. Nintendo teased that the handheld would first be released in Japan in August 2000, with the North American and European launch dates slated for the end of the same year. Simultaneously, Nintendo announced a partnership with Konami to form Mobile 21, a development studio that would focus on creating technology for the GBA to interact with the Dolphin, Nintendo's home console which was also in development at the time. On August 21, 2000, IGN showed off images of a GBA development kit running a demonstrational port of "Yoshi Story", and on August 22, pre-production images of the GBA were revealed in an issue of "Famitsu" magazine in Japan. On August 24, Nintendo officially revealed the console to the public in a presentation, revealing the Japanese and North American launch dates, in addition to revealing that 10 games would be available as launch titles for the system. The GBA was then featured at Nintendo Space World 2000 from August 24–26 alongside several peripherals for the system, including the GBA Link cable, the GameCube - Game Boy Advance link cable, a rechargable battery pack for the system, and an infrared communications adaptor which would allow systems to exchange data with each other. In March 2001, Nintendo revealed details about the system's North American launch, including the suggested price of $99.99 and the 15 launch games. Nintendo estimated that around 60 games would be made available for the system by the end of 2001.

In 1996, magazines including "Electronic Gaming Monthly", "Next Generation", issues 53 and 54 of "Total!" and the July 1996 issue of "Game Informer" featured reports of a new Game Boy, codenamed Project Atlantis. Although Nintendo's expectations of releasing the system in at least one territory by the end of 1996 would make that machine seem to be the Game Boy Color, it was described as having a 32-bit RISC processor, a 3-by-2-inch color LCD screen, and a link port—a description that more closely matches the Game Boy Advance. It also may have referred to the unnamed, unreleased Game Boy Color successor prototype that was revealed at 2009's Game Developers Conference. It was announced that Nintendo of Japan was working on a game for the system called "Mario's Castle". Nintendo tabled the project in 1997, since the original Game Boy was still too popular (holding 80% of the handheld market) to merit the release of a successor.

The technical specifications of the original Game Boy Advance are, as provided by Nintendo:
Backward compatibility for Game Boy and Game Boy Color games is provided by a custom 4.194/8.388 MHz Z80-based coprocessor (Game Boy Advance software can use the audio tone generators to supplement the primary sound system), while a link port at the top of the unit allows it to be connected to other devices using a Game Link cable or GameCube link cable. When playing Game Boy or Game Boy Color games on the Game Boy Advance, the L and R buttons can be used to toggle between a stretched widescreen format and the original screen ratio of the Game Boy . Game Boy games can be played using the same selectable color palettes as on the Game Boy Color.
Every Nintendo handheld system following the release of the Game Boy Advance SP has included a built-in light and rechargeable battery.

The Game Boy Advance and Nintendo DS 2D graphics hardware have scaling and rotation for traditional tiled backgrounds in its modes 1 and 2 and scaling and rotation for bitmaps in modes 3 through 5 (used less often on the GBA because of technical limitations). On each machine supporting this effect, it is possible to change the scaling and rotation values during the horizontal blanking period of each scanline to draw a flat plane in a perspective projection. More complex effects such as fuzz are possible by using other equations for the position, scaling, and rotation of each line. The "character mode" supports up to 4 tile map background layers per frame, with each tile being 8x8 pixels in size and having 16 or 256 colors. The "character mode" also supports up to 128 hardware sprites per frame, with any sprite size from 8x8 to 64x64 pixels and with 16 or 256 colors per sprite.

With hardware comparable to the Super NES, the Game Boy Advance represents progress for sprite-based technology. The Game Boy Advance has platformers, SNES-style role-playing video games, and classic games ported from various 8-bit and 16-bit systems of the previous generations. This includes the "Super Mario Advance" series, as well as the system's backward compatibility with all earlier Game Boy titles. All titles were GBA-exclusive and none of these were backwards compatible with older Game Boy systems. It featured a warning message that was refuse to play on classic Game Boy.

"Final Fantasy VI Advance" was the final licensed Japanese GBA game release. Released November 2006, it was the final Nintendo-published game for the system. "2 Games in 1: Columns Crown & ChuChu Rocket!" was the final European GBA game, released November 2008. "Samurai Deeper Kyo" was the final North American GBA game, released in February 2008. The last Nintendo-developed game released for the system was the Japan-only rhythm game "Rhythm Tengoku", which later went on to form the popular "Rhythm Heaven" series.

An accessory for the GameCube, known as the Game Boy Player, was released in 2003 as the successor to the Super Game Boy peripheral for the Super Nintendo Entertainment System. The accessory allows Game Boy Advance games, as well as Game Boy and Game Boy Color games, to be played on the GameCube. However, some games may have compatibility issues due to certain features (for example, games with built-in motion sensors would require players to manipulate the console itself).

Game Boy Advance games are compatible with the Nintendo DS and Nintendo DS Lite handheld consoles, which feature a cartridge slot at the bottom. They are not, however, compatible with the Nintendo DSi, as it does not feature a cartridge slot.

As part of an Ambassador Program for early adopters of the Nintendo 3DS system, ten Game Boy Advance games were made available free for players who bought a system before August 2011. Unlike other Virtual Console games for the system, players were not able to use features such as the Home menu or save states (since the games are not actually emulated and are running natively). 3DS systems that have custom firmware installed can also install the ten available games available to Ambassador Program members. Many other Game Boy Advance games can also be played via custom firmware by injecting a difference game into one of the officially released Game Boy Advance games, including Game Boy Advance games not available on the Wii U Virtual console. Satoru Iwata stated Game Boy Advance games will be available on the Wii U Virtual Console sometime during April 2014. On April 3, 2014, the first of the announced GBA games ("Advance Wars", "Metroid Fusion" and "") were released for the Wii U Virtual Console. A full Virtual Console service for Game Boy Advance games was launched for the Wii U console. All of the Virtual Console releases are single player only, as they do not emulate multiplayer features enabled by Game Link cables.

Nintendo released many addons for the Game Boy Advance. These include:

Other accessories for the Game Boy Advance are:

In early 2003, Nintendo introduced a new form-factor for the handheld, known as the Game Boy Advance SP (model AGS-001). The redesigned unit resembles a pocket-size laptop computer, including a folding case approximately one-half the size of the original unit. It also supports a rechargeable lithium ion battery, a significantly brighter LCD screen, and an internal front-light that can be toggled on and off. The redesign was intended to address some common complaints about the original Game Boy Advance, which had been criticized for being somewhat uncomfortable to use, especially due to an overly dark screen.

Around the same time as the release of the Game Boy Micro, Nintendo released a new backlit version of the SP (model AGS-101) in North America (commonly referred to as the "GBA SP+", SPII, or SP2). The switch that controls the light now toggles between "normal" (which itself is already brighter than the original Game Boy Advance SP's screen), and "bright", an intense brightness level similar to an LCD television set.

In September 2005, Nintendo released a second redesign of the Game Boy Advance. This model, dubbed the Game Boy Micro, is similar in style to the original Game Boy Advance's horizontal orientation, but is much smaller and sleeker. The Game Boy Micro also allows the user to switch between several colored faceplates to allow customization, a feature which Nintendo advertised heavily around the Game Boy Micro's launch. Nintendo also hoped that this "fashion" feature would help target audiences outside of typical video game players. Unlike the previous Game Boy Advance models, Game Boy Micro is unable to support Game Boy and Game Boy Color titles. The Game Boy Micro did not make much of an impact in the video game market as it was overshadowed by Nintendo's other portable, the Nintendo DS, which also played Game Boy Advance cartridges.

The Game Boy Advance, SP, and Micro had numerous colors and limited editions.

The Game Boy Advance was initially available in Arctic, Black, Orange, Fuchsia, Glacier (translucent blue/purple) and Indigo. Later in the system's availability, additional colours and special editions were released. These editions include: Red, Clear Orange/Black, Platinum, White, Gold, Hello Kitty edition (pink with Hello Kitty and logo on bezel), King of Fighters edition (black with images on bezel and buttons), Chobits edition (translucent light blue, with images on bezel and buttons), Battle Network Rockman EXE 2 (light blue with images on bezel), Mario Bros. edition (Glacier with Mario and Luigi on bezel) and Yumiuri Giant edition (Glacier with images on bezel).

A number of Pokémon-themed limited-edition systems were made available in Pokémon Center stores in Japan. These editions include: Gold Pokémon edition (Gold with Pikachu and Pichu on bezel), Suicune edition (blue/grey with greyscale Pikachu and Pichu on bezel, and a Pokémon Center sticker on the back), Celebi edition (olive green with Celebi images on bezel), and Latias/Latios edition (pink/red and purple, with images of Latias and Latios on bezel).


Upon its North American release, IGN praised the Game Boy Advance's graphical capabilities and battery life, but criticized the system's shoulder button placement and noted the system's high price tag which "may be a tad bit too high to swallow," ultimately scoring the system with in "8.0" out of 10. They also pointed out the system's lack of a backlight which occasionally got in the way of playing games.
ABC News praised the Game Boy Advance's graphics, grip and larger screen, stating that "You've never had as much fun playing old games."

Reviewing for CNET, Darren Gladstone scored the system with a 7.0 out of 10, praising its graphical performance and backwards compatibility but being considerably critical of the system's lack of a backlit screen, noting that it makes it "nearly impossible" to play in normal lighting conditions. Gladstone ultimately suggested the sleeker and backlit Game Boy Advance SP over the system despite noting that its cheaper price may "appeal to gamers on a lower budget."

Nintendo hoped to sell 1.1 million Game Boy Advance units by the end of March with the system's Japanese debut, and anticipated sales of 24 million units before the end of 2001; many marketing analysts believed for this to be a realistic goal due to the company's lack of major competition in the handheld video game market. Within the first week of its North American launch in June, the Game Boy Advance sold 500,000 units, making it the fastest-selling video game console in the United States at the time. In response to strong sales, Nintendo ordered 100,000 units to ship to retail stores, hoping to ship another half million of them by the end of June. The Game Boy Advance also became the fastest-selling system in the United Kingdom, selling 81,000 units in its first week of release and beating the PlayStation 2's previous record of 20,000 units. In 2004, the system's sales in the United Kingdom surpassed one million units.

On December 1, 2006, Nintendo of America released launch-to-date information indicating that the company had sold 33.6 million units of the Game Boy Advance series in the United States. In a Kotaku article published on January 18, 2008, Nintendo revealed that the Game Boy Advance series has sold 36.2 million units in the United States, as of January 1, 2008. As of December 31, 2009, the Game Boy Advance series has sold 81.51 million units worldwide, 43.57 million of which are Game Boy Advance SP units and 2.42 million of which are Game Boy Micro units.

After the Game Boy Advance's support lessened, the most popular software became mostly games oriented to younger gamers.



</doc>
<doc id="12431" url="https://en.wikipedia.org/wiki?curid=12431" title="Google Search">
Google Search

Google Search, also referred to as Google Web Search or simply Google, is a web search engine developed by Google LLC. It is the most used search engine on the World Wide Web across all platforms, with 92.74% market share as of October 2018, handling more than 3.5 billion searches each day.

The order of search results returned by Google is based, in part, on a priority rank system called "PageRank". Google Search also provides many different options for customized search, using symbols to include, exclude, specify or require certain search behavior, and offers specialized interactive experiences, such as flight status and package tracking, weather forecasts, currency, unit and time conversions, word definitions, and more.

The main purpose of Google Search is to hunt for text in publicly accessible documents offered by web servers, as opposed to other data, such as images or data contained in databases. It was originally developed by Larry Page and Sergey Brin in 1997. In June 2011, Google introduced "Google Voice Search" to search for spoken, rather than typed, words. In May 2012, Google introduced a Knowledge Graph semantic search feature in the U.S.

Analysis of the frequency of search terms may indicate economic, social and health trends. Data about the frequency of use of search terms on Google can be openly inquired via Google Trends and have been shown to correlate with flu outbreaks and unemployment levels, and provide the information faster than traditional reporting methods and surveys. As of mid-2016, Google's search engine has begun to rely on deep neural networks.

Competitors of Google include Baidu and Soso.com in China; Naver.com and Daum.net in South Korea; Yandex in Russia; Seznam.cz in the Czech Republic; Yahoo in Japan, Taiwan and the US, as well as Bing and DuckDuckGo. Some smaller search engines offer facilities not available with Google, e.g. not storing any private or tracking information.

Within the US, as of July 2018, Microsoft Sites handled 24.2 percent of all search queries in the United States. During the same period of time, Oath (formerly known as Yahoo) had a search market share of 11.5 percent. Market leader Google generated 63.2 percent of all core search queries in the United States.

Google indexes hundreds of terabytes of information from web pages. For websites that are currently down or otherwise not available, Google provides links to cached versions of the site, formed by the search engine's latest indexing of that page. Additionally, Google indexes some file types, being able to show users PDFs, Word documents, Excel spreadsheets, PowerPoint presentations, certain Flash multimedia content, and plain text files. Users can also activate "SafeSearch", a filtering technology aimed at preventing explicit and pornographic content from appearing in search results.

Despite Google search's immense index, sources generally assume that Google is only indexing less than 5% of the total Internet, with the rest belonging to the deep web, inaccessible through its search tools.

In 2012, Google changed its search indexing tools to demote sites that had been accused of piracy. In October 2016, Gary Illyes, a webmaster trends analyst with Google, announced that the search engine would be making a separate, primary web index dedicated for mobile devices, with a secondary, less up-to-date index for desktop use. The change was a response to the continued growth in mobile usage, and a push for web developers to adopt a mobile-friendly version of their websites. In December 2017, Google began rolling out the change, having already done so for multiple websites.

In August 2009, Google invited web developers to test a new search architecture, codenamed "Caffeine", and give their feedback. The new architecture provided no visual differences in the user interface, but added significant speed improvements and a new "under-the-hood" indexing infrastructure. The move was interpreted in some quarters as a response to Microsoft's recent release of an upgraded version of its own search service, renamed Bing, as well as the launch of Wolfram Alpha, a new search engine based on "computational knowledge". Google announced completion of "Caffeine" on June 8, 2010, claiming 50% fresher results due to continuous updating of its index.

With "Caffeine", Google moved its back-end indexing system away from MapReduce and onto Bigtable, the company's distributed database platform.

In August 2018, Danny Sullivan from Google announced a broad core algorithm update. As per current analysis done by the industry leaders Search Engine Watch and Search Engine Land, the update was to drop down the medical and health related websites that were not user friendly and were not providing good user experience. This is why, the industry experts named it "Medic".

Google reserves very high standards for YMYL (Your Money or Your Life) pages. This is because misinformation can affect users financially, physically or emotionally. Therefore, the update targeted particularly those YMYL pages that have low-quality content and misinformation. This resulted in the algorithm targeting health and medical related websites more than others. However, many other websites from other industries were also negatively affected.

Google Search consists of a series of localized websites. The largest of those, the google.com site, is the top most-visited website in the world. Some of its features include a definition link for most searches including dictionary words, the number of results you got on your search, links to other searches (e.g. for words that Google believes to be misspelled, it provides a link to the search results using its proposed spelling), and many more.

Google search accepts queries as normal text, as well as individual keywords. It automatically corrects misspelled words, and yields the same results regardless of capitalization. For more customized results, one can use a wide variety of operators, including, but not limited to:


Google applies query expansion to submitted search queries, using techniques to deliver results that it considers "smarter" than the query users actually submitted. This technique involves several steps, including:

In 2008, Google started to give users autocompleted search suggestions in a list below the search bar while typing.

Google's homepage includes a button labeled "I'm Feeling Lucky". This feature originally allowed users to type in their search query, click the button and be taken directly to the first result, bypassing the search results page. With the 2010 announcement of Google Instant, an automatic feature that immediately displays relevant results as users are typing in their query, the "I'm Feeling Lucky" button disappears, requiring that users opt-out of Instant results through search settings in order to keep using the "I'm Feeling Lucky" functionality. In 2012, "I'm Feeling Lucky" was changed to serve as an advertisement for Google services; users hover their computer mouse over the button, it spins and shows an emotion ("I'm Feeling Puzzled" or "I'm Feeling Trendy", for instance), and, when clicked, takes users to a Google service related to that emotion.

Tom Chavez of "Rapt", a firm helping to determine a website's advertising worth, estimated in 2007 that Google lost $110 million in revenue per year due to use of the button, which bypasses the advertisements found on the search results page.

Besides the main text-based search-engine features of Google search, it also offers multiple quick, interactive experiences. These include, but are not limited to:


During Google's developer conference in May 2013, the company announced that, on Google Chrome and Chrome OS, users would be able to say "OK Google", with the browser initiating an audio-based search, with no button presses required. After having the answer presented, users can follow up with additional, contextual questions; an example include initially asking "OK Google, will it be sunny in Santa Cruz this weekend?", hearing a spoken answer, and reply with "how far is it from here?" An update to the Chrome browser with voice-search functionality rolled out a week later, though it required a button press on a microphone icon rather than "OK Google" voice activation. Google released a browser extension for the Chrome browser, named with a "beta" tag for unfinished development, shortly thereafter. In May 2014, the company officially added "OK Google" into the browser itself, though the company removed it in October 2015, citing low usage, though the microphone icon for activation remained available. In May 2016, 20% of search queries on mobile devices were done through voice.

"Universal search" was launched by Google on May 16, 2007 as an idea that merged the results from different kinds of search types into one. Prior to Universal search, a standard Google search would consist of links only to websites. Universal search, however, incorporates a wide variety of sources, including websites, news, pictures, maps, blogs, videos, and more, all shown on the same search results page. Marissa Mayer, then-vice president of search products and user experience, described the goal of Universal search as "we're attempting to break down the walls that traditionally separated our various search properties and integrate the vast amounts of information available into one simple set of search results.

In June 2017, Google expanded its search results to cover available job listings. The data is aggregated from various major job boards and collected by analyzing company homepages. Initially only available in English, the feature aims to simplify finding jobs suitable for each user.

In May 2009, Google announced that they would be parsing website microformats in order to populate search result pages with "Rich snippets". Such snippets include additional details about results, such as displaying reviews for restaurants and social media accounts for individuals.

In May 2016, Google expanded on the "Rich snippets" format to offer "Rich cards", which, similarly to snippets, display more information about results, but shows them at the top of the mobile website in a swipeable carousel-like format. Originally limited to movie and recipe websites in the United States only, the feature expanded to all countries globally in 2017.

The Knowledge Graph is a knowledge base used by Google to enhance its search engine's results with information gathered from a variety of sources. This information is presented to users in a box to the right of search results. Knowledge Graph boxes were added to Google's search engine in May 2012, starting in the United States, with international expansion by the end of the year. The information covered by the Knowledge Graph grew significantly after launch, tripling its original size within seven months, and being able to answer "roughly one-third" of the 100 billion monthly searches Google processed in May 2016. The information is often used as a spoken answer in Google Assistant and Google Home searches. The Knowledge Graph has been criticized for providing answers without source attribution.

In May 2017, Google enabled a new "Personal" tab in Google Search, letting users search for content in their Google accounts' various services, including email messages from Gmail and photos from Google Photos.

The Google feed is a personalized stream of articles, videos, and other news-related content. The feed contains a "mix of cards" which show topics of interest based on users' interactions with Google, or topics they choose to follow directly. Cards include, "links to news stories, YouTube videos, sports scores, recipes, and other content based on what [Google] determined you're most likely to be interested in at that particular moment." Users can also tell Google they're not interested in certain topics to avoid seeing future updates.

The Google feed launched in December 2016 and received a major update in July 2017. As of May 2018, the Google feed can be found on the Google app and by swiping left on the home screen of certain Android devices.

Google's rise was largely due to a patented algorithm called PageRank which helps rank web pages that match a given search string. When Google was a Stanford research project, it was nicknamed BackRub because the technology checks backlinks to determine a site's importance. Other keyword-based methods to rank search results, used by many search engines that were once more popular than Google, would check how often the search terms occurred in a page, or how strongly associated the search terms were within each resulting page. The PageRank algorithm instead analyzes human-generated links assuming that web pages linked from many important pages are also important. The algorithm computes a recursive score for pages, based on the weighted sum of other pages linking to them. PageRank is thought to correlate well with human concepts of importance. In addition to PageRank, Google, over the years, has added many other secret criteria for determining the ranking of resulting pages. This is reported to comprise over 250 different indicators, the specifics of which are kept secret to avoid difficulties created by scammers and help Google maintain an edge over its competitors globally.

PageRank was influenced by a similar page-ranking and site-scoring algorithm earlier used for RankDex, developed by Robin Li in 1996. Larry Page's patent for PageRank filed in 1998 includes a citation to Li's earlier patent. Li later went on to create the Chinese search engine Baidu in 2000.

In a potential hint of Google's future direction of their Search algorithm, Google's then chief executive Eric Schmidt, said in a 2007 interview with the "Financial Times": "The goal is to enable Google users to be able to ask the question such as 'What shall I do tomorrow?' and 'What job shall I take?'". Schmidt reaffirmed this during a 2010 interview with the Wall Street Journal: "I actually think most people don't want Google to answer their questions, they want Google to tell them what they should be doing next."

In 2013 the European Commission found that Google Search favored Google's own products, instead of the best result for consumers' needs. In February 2015 Google announced a major change to its mobile search algorithm which would favor mobile friendly over other websites. Nearly 60% of Google searches come from mobile phones. Google says it wants users to have access to premium quality websites. Those websites which lack a mobile friendly interface would be ranked lower and it is expected that this update will cause a shake-up of ranks. Businesses who fail to update their websites accordingly could see a dip in their regular websites traffic.

Because Google is the most popular search engine, many webmasters attempt to influence their website's Google rankings. An industry of consultants has arisen to help websites increase their rankings on Google and on other search engines. This field, called search engine optimization, attempts to discern patterns in search engine listings, and then develop a methodology for improving rankings to draw more searchers to their clients' sites. Search engine optimization encompasses both "on page" factors (like body copy, title elements, H1 heading elements and image alt attribute values) and Off Page Optimization factors (like anchor text and PageRank). The general idea is to affect Google's relevance algorithm by incorporating the keywords being targeted in various places "on page", in particular the title element and the body copy (note: the higher up in the page, presumably the better its keyword prominence and thus the ranking). Too many occurrences of the keyword, however, cause the page to look suspect to Google's spam checking algorithms. Google has published guidelines for website owners who would like to raise their rankings when using legitimate optimization consultants. It has been hypothesized, and, allegedly, is the opinion of the owner of one business about which there have been numerous complaints, that negative publicity, for example, numerous consumer complaints, may serve as well to elevate page rank on Google Search as favorable comments. The particular problem addressed in "The New York Times" article, which involved DecorMyEyes, was addressed shortly thereafter by an undisclosed fix in the Google algorithm. According to Google, it was not the frequently published consumer complaints about DecorMyEyes which resulted in the high ranking but mentions on news websites of events which affected the firm such as legal actions against it. Google Search Console helps to check for websites that use duplicate or copyright content.

In 2013, Google significantly upgraded its search algorithm with "Hummingbird". Its name was derived from the speed and accuracy of the hummingbird. The change was announced on September 26, 2013, having already been in use for a month. "Hummingbird" places greater emphasis on natural language queries, considering context and meaning over individual keywords. It also looks deeper at content on individual pages of a website, with improved ability to lead users directly to the most appropriate page rather than just a website's homepage. The upgrade marked the most significant change to Google search in years, with more "human" search interactions and a much heavier focus on conversation and meaning. Thus, web developers and writers were encouraged to optimize their sites with natural writing rather than forced keywords, and make effective use of technical web development for on-site navigation.

On certain occasions, the logo on Google's webpage will change to a special version, known as a "Google Doodle". This is a picture, drawing, animation or interactive game that includes the logo. It is usually done for a special event or day although not all of them are well known. Clicking on the Doodle links to a string of Google search results about the topic. The first was a reference to the Burning Man Festival in 1998, and others have been produced for the birthdays of notable people like Albert Einstein, historical events like the interlocking Lego block's 50th anniversary and holidays like Valentine's Day. Some Google Doodles have interactivity beyond a simple search, such as the famous "Google Pacman" version that appeared on May 21, 2010.

Google offers a "Google Search" mobile app for Android and iOS devices. The mobile apps exclusively feature a "feed", a news feed-style page of continually-updated developments on news and topics of interest to individual users. Android devices were introduced to a preview of the feed in December 2016, while it was made official on both Android and iOS in July 2017.

In April 2016, Google updated its Search app on Android to feature "Trends"; search queries gaining popularity appeared in the autocomplete box along with normal query autocompletion. The update received significant backlash, due to encouraging search queries unrelated to users' interests or intentions, prompting the company to issue an update with an opt-out option. In September 2017, the Google Search app on iOS was updated to feature the same functionality.

Until May 2013, Google Search had offered a feature to translate search queries into other languages. A Google spokesperson told "Search Engine Land" that "Removing features is always tough, but we do think very hard about each decision and its implications for our users. Unfortunately, this feature never saw much pick up".
Instant search was announced in September 2010 as a feature that displayed suggested results while the user typed in their search query. The primary advantage of the new system was its ability to save time, with Marissa Mayer, then-vice president of search products and user experience, proclaiming that the feature would save 2–5 seconds per search, elaborating that "That may not seem like a lot at first, but it adds up. With Google Instant, we estimate that we'll save our users 11 hours with each passing second!" Matt Van Wagner of "Search Engine Land" wrote that "Personally, I kind of like Google Instant and I think it represents a natural evolution in the way search works", and also praised Google's efforts in public relations, writing that "With just a press conference and a few well-placed interviews, Google has parlayed this relatively minor speed improvement into an attention-grabbing front-page news story". The upgrade also became notable for the company switching Google Search's underlying technology from HTML to AJAX.

Instant Search could be disabled via Google's "preferences" menu for those who didn't want its functionality.

The publication "" compiled a list of words that Google Instant did not show suggested results for, with a Google spokesperson giving the following statement to "Mashable":

"PC Magazine" discussed the inconsistency in how some forms of the same topic are allowed; for instance, "lesbian" was blocked, while "gay" was not, and "cocaine" was blocked, while "crack" and "heroin" were not. The report further stated that seemingly normal words were also blocked due to pornographic innuendos, most notably "scat", likely due to having two completely separate contextual meanings, one for music and one for a sexual practice.

In July 2017, Google removed Instant results, due to a growing number of searches on mobile devices, where interaction with search, as well as screen sizes, differ significantly from a computer.

Various search engines provide encrypted Web search facilities. In May 2010 Google rolled out SSL-encrypted web search. The encrypted search can be accessed at codice_12 However, the web search is encrypted via Transport Layer Security (TLS) by default today, thus every search request should be automatically encrypted if TLS is supported by the web browser. On its support website, Google announced that the address codice_12 will be turned off in April 30 of 2018, stating that all Google products and most new browsers use HTTPS connections as the reason for the discontinuation.

Google Real-Time Search was a feature of Google Search in which search results also sometimes included real-time information from sources such as Twitter, Facebook, blogs, and news websites. The feature was introduced on December 7, 2009 and went off-line on July 2, 2011 after the deal with Twitter expired. Real-Time Search included Facebook status updates beginning on February 24, 2010. A feature similar to Real-Time Search was already available on Microsoft's Bing search engine, which showed results from Twitter and Facebook. The interface for the engine showed a live, descending "river" of posts in the main region (which could be paused or resumed), while a bar chart metric of the frequency of posts containing a certain search term or hashtag was located on the right hand corner of the page above a list of most frequently reposted posts and outgoing links. Hashtag search links were also supported, as were "promoted" tweets hosted by Twitter (located persistently on top of the river) and thumbnails of retweeted image or video links.

In January 2011, geolocation links of posts were made available alongside results in Real-Time Search. In addition, posts containing syndicated or attached shortened links were made searchable by the "link:" query option. In July 2011 Real-Time Search became inaccessible, with the Real-Time link in the Google sidebar disappearing and a custom 404 error page generated by Google returned at its former URL. Google originally suggested that the interruption was temporary and related to the launch of Google+; they subsequently announced that it was due to the expiry of a commercial arrangement with Twitter to provide access to tweets.

Searches made by search engines, including Google, leave traces. This raises concerns about privacy. In principle, if details of a user's searches are found, those with access to the information—principally state agencies responsible for law enforcement and similar matters—can make deductions about the user's activities. This has been used for the detection and prosecution of lawbreakers; for example a murderer was found and convicted after searching for terms such as "tips with killing with a baseball bat".

A search may leave traces both on a computer used to make the search, and in records kept by the search provider. When using a search engine through a browser program on a computer, search terms and other information may be stored on the computer by default, unless the browser is set not to do this, or they are erased. Saved terms may be discovered on forensic analysis of the computer. An Internet Service Provider (ISP) or search engine provider (e.g., Google) may store records which relate search terms to an IP address and a time. Whether such logs are kept, and access to them by law enforcement agencies, is subject to legislation in different jurisdictions and working practices; the law may mandate, prohibit, or say nothing about logging of various types of information. Some search engines, located in jurisdictions where it is not illegal, make a feature of not storing user search information.

The keywords suggested by the Autocomplete feature show a population of users' research which is made possible by an identity management system. Volumes of personal data are collected via Eddystone web and proximity beacons.

Google has been criticized for placing long-term cookies on users' machines to store these preferences, a tactic which also enables them to track a user's search terms and retain the data for more than a year.

Since 2012, Google Inc. has globally introduced encrypted connections for most of its clients, in order to bypass governative blockings of the commercial and IT services.

In late June 2011, Google introduced a new look to the Google home page in order to boost the use of the Google+ social tools.

One of the major changes was replacing the classic navigation bar with a black one. Google's digital creative director Chris Wiggins explains: "We're working on a project to bring you a new and improved Google experience, and over the next few months, you'll continue to see more updates to our look and feel." The new navigation bar has been negatively received by a vocal minority.

In November 2013, Google started testing yellow labels for advertisements displayed in search results, to improve user experience. The new labels, highlighted in yellow color, and aligned to the left of each sponsored link help users clearly differentiate between organic and sponsored results.

On December 15, 2016, Google rolled out a new desktop search interface that mimics their modular mobile user interface. The mobile design consists of a tabular design that highlights search features in boxes. and works by imitating the desktop Knowledge Graph real estate, which appears in the right-hand rail of the search engine result page, these featured elements frequently feature Twitter carousels, People Also Search For, and Top Stories (vertical and horizontal design) modules. The Local Pack and Answer Box were two of the original features of the Google SERP that were primarily showcased in this manner, but this new layout creates a previously unseen level of design consistency for Google results.

In addition to its tool for searching webpages, Google also provides services for searching images, Usenet newsgroups, news websites, videos, searching by locality, maps, and items for sale online. In 2012, Google has indexed over 30 trillion web pages, and received 100 billion queries per month. It also caches much of the content that it indexes. Google operates other tools and services including Google News, Google Shopping, Google Maps, Google Custom Search, Google Earth, Google Docs, Picasa, Panoramio, YouTube, Google Translate, Google Blog Search and Google Desktop Search.

There are also products available from Google that are not directly search-related. Gmail, for example, is a webmail application, but still includes search features; Google Browser Sync does not offer any search facilities, although it aims to organize your browsing time.

Also Google starts many new beta products, like Google Social Search or Google Image Swirl.

In 2009, Google claimed that a search query requires altogether about 1 kJ or 0.0003 kW·h, which is enough to raise the temperature of one liter of water by 0.24 °C. According to green search engine Ecosia, the industry standard for search engines is estimated to be about 0.2 grams of CO emission per search. Google's 40,000 searches per second translate to 8 kg CO per second or over 252 million kilos of CO per year.

In 2003, "The New York Times" complained about Google's indexing, claiming that Google's caching of content on its site infringed its copyright for the content. In both "Field v. Google" and "Parker v. Google", the United States District Court of Nevada ruled in favor of Google.

Google flags search results with the message "This site may harm your computer" if the site is known to install malicious software in the background or otherwise surreptitiously. Google does this to protect users against visiting sites that could harm their computers. For approximately 40 minutes on January 31, 2009, all search results were mistakenly classified as malware and could therefore not be clicked; instead a warning message was displayed and the user was required to enter the requested URL manually. The bug was caused by human error. The URL of "/" (which expands to all URLs) was mistakenly added to the malware patterns file.

In 2007, a group of researchers observed a tendency for users to rely on Google Search exclusively for finding information, writing that "With the Google interface the user gets the impression that the search results imply a kind of totality. ... In fact, one only sees a small part of what one could see if one also integrates other research tools."

In 2011, Google Search query results have been shown to be tailored to users by Internet activist Eli Pariser, effectively isolating users in what he defined as a filter bubble. Pariser holds algorithms used in search engines such as Google Search responsible for catering "a personal ecosystem of information". Although contrasting views have mitigated the potential threat of "informational dystopia" and questioned the scientific nature of Pariser's claims, filter bubbles have been mentioned to account for the surprising results of the U.S. presidential election in 2016 alongside fake news and echo chambers, suggesting that Facebook and Google have designed personalized online realities in which "we only see and hear what we like".

In 2012, the US Federal Trade Commission fined Google US$22.5 million for violating their agreement not to violate the privacy of users of the Apple's Safari web browser. The FTC was also continuing to investigate if Google's favoring of their own services in their search results violated antitrust regulations.

As people talk about "googling" rather than searching, the company has taken some steps to defend its trademark, in an effort to prevent if from becoming a generic trademark. This has led to lawsuits, threats of lawsuits, and the use of euphemisms, such as calling Google Search a famous web search engine.





</doc>
<doc id="12432" url="https://en.wikipedia.org/wiki?curid=12432" title="Genius">
Genius

A genius is a person who displays exceptional intellectual ability, creative productivity, universality in genres or originality, typically to a degree that is associated with the achievement of new advances in a domain of knowledge. Despite the presence of scholars in many subjects throughout history, many geniuses have shown high achievements in only a single kind of activity.

There is no scientifically precise definition of a genius, and the question of whether the notion itself has any real meaning has long been a subject of debate, although psychologists are converging on a definition that emphasizes creativity and eminent achievement. Usually, genius is associated with talent, but many authors (for example Cesare Lombroso) systematically distinguish these terms.

In ancient Rome, the "genius" (plural in Latin "genii") was the guiding spirit or tutelary deity of a person, family "(gens)", or place "(genius loci)". The noun is related to the Latin verb "genui, genitus", "to bring into being, create, produce". Because the achievements of exceptional individuals seemed to indicate the presence of a particularly powerful "genius", by the time of Augustus, the word began to acquire its secondary meaning of "inspiration, talent". The term "genius" acquired its modern sense in the eighteenth century, and is a conflation of two Latin terms: "genius", as above, and "Ingenium", a related noun referring to our innate dispositions, talents, and inborn nature. Beginning to blend the concepts of the divine and the talented, the "Encyclopédie" article on genius (génie) describes such a person as "he whose soul is more expansive and struck by the feelings of all others; interested by all that is in nature never to receive an idea unless it evokes a feeling; everything excites him and on which nothing is lost."

The assessment of intelligence was initiated by Francis Galton (1822–1911) and James McKeen Cattell. They had advocated the analysis of reaction time and sensory acuity as measures of "neurophysiological efficiency" and the analysis of sensory acuity as a measure of intelligence.

Galton is regarded as the founder of psychometry. He studied the work of his older half-cousin Charles Darwin about biological evolution. Hypothesizing that eminence is inherited from ancestors, Galton did a study of families of eminent people in Britain, publishing it in 1869 as "Hereditary Genius". Galton's ideas were elaborated from the work of two early 19th-century pioneers in statistics: Carl Friedrich Gauss and Adolphe Quetelet. Gauss discovered the normal distribution (bell-shaped curve): given a large number of measurements of the same variable under the same conditions, they vary at random from a most frequent value, the "average", to two least frequent values at maximum differences greater and lower than the most frequent value. Quetelet discovered that the bell-shaped curve applied to social statistics gathered by the French government in the course of its normal processes on large numbers of people passing through the courts and the military. His initial work in criminology led him to observe "the greater the number of individuals observed the more do peculiarities become effaced...". This ideal from which the peculiarities were effaced became "the average man".

Galton was inspired by Quetelet to define the average man as "an entire normal scheme"; that is, if one combines the normal curves of every measurable human characteristic, one will, in theory, perceive a syndrome straddled by "the average man" and flanked by persons that are different. In contrast to Quetelet, Galton's average man was not statistical but was theoretical only. There was no measure of general averageness, only a large number of very specific averages. Setting out to discover a general measure of the average, Galton looked at educational statistics and found bell-curves in test results of all sorts; initially in mathematics grades for the final honors examination and in entrance examination scores for Sandhurst.

Galton's method in "Hereditary Genius" was to count and assess the eminent relatives of eminent men. He found that the number of eminent relatives was greater with a closer degree of kinship. This work is considered the first example of historiometry, an analytical study of historical human progress. The work is controversial and has been criticized for several reasons. Galton then departed from Gauss in a way that became crucial to the history of the 20th century AD. The bell-shaped curve was not random, he concluded. The differences between the average and the upper end were due to a non-random factor, "natural ability", which he defined as "those qualities of intellect and disposition, which urge and qualify men to perform acts that lead to reputation…a nature which, when left to itself, will, urged by an inherent stimulus, climb the path that leads to eminence." The apparent randomness of the scores was due to the randomness of this natural ability in the population as a whole, in theory.

Criticisms include that Galton's study fails to account for the impact of social status and the associated availability of resources in the form of economic inheritance, meaning that inherited "eminence" or "genius" can be gained through the enriched environment provided by wealthy families. Galton went on to develop the field of eugenics.

Genius is expressed in a variety of forms (e.g., mathematical, literary, musical performance). Persons with genius tend to have strong intuitions about their domains, and they build on these insights with tremendous energy. Carl Rogers, a founder of the Humanistic Approach to Psychology, expands on the idea of a genius trusting his or her intuition in a given field, writing: "El Greco, for example, must have realized as he looked at some of his early work, that 'good artists do not paint like that.' But somehow he trusted his own experiencing of life, the process of himself, sufficiently that he could go on expressing his own unique perceptions. It was as though he could say, 'Good artists don't paint like this, but "I" paint like this.' Or to move to another field, Ernest Hemingway was surely aware that 'good writers do not write like this.' But fortunately he moved toward being Hemingway, being himself, rather than toward someone else's conception of a good writer."

A number of people commonly regarded as geniuses have been or were diagnosed with mental disorders, for example Vincent van Gogh, Virginia Woolf, John Forbes Nash Jr., and Ernest Hemingway.

It has been suggested that there exists a connection between mental illness, in particular schizophrenia and bipolar disorder, and genius. Individuals with bipolar disorder and schizotypal personality disorder, the latter of which being more common amongst relatives of schizophrenics, tend to show elevated creativity.

Galton was a pioneer in investigating both eminent human achievement and mental testing. In his book "Hereditary Genius", written before the development of IQ testing, he proposed that hereditary influences on eminent achievement are strong, and that eminence is rare in the general population. Lewis Terman chose "'near' genius or genius" as the classification label for the highest classification on his 1916 version of the Stanford-Binet test. By 1926, Terman began publishing about a longitudinal study of California schoolchildren who were referred for IQ testing by their schoolteachers, called Genetic Studies of Genius, which he conducted for the rest of his life. Catherine M. Cox, a colleague of Terman's, wrote a whole book, "The Early Mental Traits of 300 Geniuses", published as volume 2 of The Genetic Studies of Genius book series, in which she analyzed biographical data about historic geniuses. Although her estimates of childhood IQ scores of historical figures who never took IQ tests have been criticized on methodological grounds, Cox's study was thorough in finding out what else matters besides IQ in becoming a genius. By the 1937 second revision of the Stanford-Binet test, Terman no longer used the term "genius" as an IQ classification, nor has any subsequent IQ test. In 1939, David Wechsler specifically commented that "we are rather hesitant about calling a person a genius on the basis of a single intelligence test score".

The Terman longitudinal study in California eventually provided historical evidence regarding how genius is related to IQ scores. Many California pupils were recommended for the study by schoolteachers. Two pupils who were tested but rejected for inclusion in the study (because their IQ scores were too low) grew up to be Nobel Prize winners in physics, William Shockley, and Luis Walter Alvarez. Based on the historical findings of the Terman study and on biographical examples such as Richard Feynman, who had an IQ of 125 and went on to win the Nobel Prize in physics and become widely known as a genius, the current view of psychologists and other scholars of genius is that a minimum level of IQ (approximately 125) is necessary for genius but not sufficient, and must be combined with personality characteristics such as drive and persistence, plus the necessary opportunities for talent development.

Some high IQ individuals join a High IQ society. The most famous is Mensa International but others exist including The International High IQ Society, the Prometheus Society, the Triple Nine Society, and Magnus. 

Various philosophers have proposed definitions of what genius is and what that implies in the context of their philosophical theories.
In the philosophy of David Hume, the way society perceives genius is similar to the way society perceives the ignorant. Hume states that a person with the characteristics of a genius is looked at as a person disconnected from society, as well as a person who works remotely, at a distance, away from the rest of the world. On the other hand, the mere ignorant is still more despised; nor is any thing deemed a surer sign of an illiberal genius in an age and nation where the sciences flourish, than to be entirely destitute of all relish for those noble entertainments. The most perfect character is supposed to lie between those extremes; retaining an equal ability and taste for books, company, and business; preserving in conversation that discernment and delicacy which arise from polite letters; and in business, that probity and accuracy which are the natural result of a just philosophy.

In the philosophy of Immanuel Kant, genius is the ability to independently arrive at and understand concepts that would normally have to be taught by another person. For Kant, originality was the essential character of genius. This genius is a talent for producing ideas which can be described as non-imitative. Kant's discussion of the characteristics of genius is largely contained within the "Critique of Judgment" and was well received by the Romantics of the early 19th century. In addition, much of Schopenhauer's theory of genius, particularly regarding talent and freedom from constraint, is directly derived from paragraphs of Part I of Kant's "Critique of Judgment".

In the philosophy of Arthur Schopenhauer, a genius is someone in whom intellect predominates over "will" much more than within the average person. In Schopenhauer's aesthetics, this predominance of the intellect over the will allows the genius to create artistic or academic works that are objects of pure, disinterested contemplation, the chief criterion of the aesthetic experience for Schopenhauer. Their remoteness from mundane concerns means that Schopenhauer's geniuses often display maladaptive traits in more mundane concerns; in Schopenhauer's words, they fall into the mire while gazing at the stars, an allusion to Plato's dialogue "Theætetus", in which Socrates tells of Thales (the first philosopher) being ridiculed for falling in such circumstances. As he says in Volume 2 of "The World as Will and Representation":

In the philosophy of Bertrand Russell, genius entails that an individual possesses unique qualities and talents that make the genius especially valuable to the society in which he or she operates, once given the chance to contribute to society. Russell's philosophy further maintains, however, that it is possible for such geniuses to be crushed in their youth and lost forever when the environment around them is unsympathetic to their potential maladaptive traits. Russell rejected the notion he believed was popular during his lifetime that, "genius will out".


Sources listed in chronological order of publication within each category.




</doc>
<doc id="12434" url="https://en.wikipedia.org/wiki?curid=12434" title="Grain (disambiguation)">
Grain (disambiguation)

Grains are the seeds of arable crops or the crops bearing them. 

Grain or grains may also refer to:







</doc>
<doc id="12435" url="https://en.wikipedia.org/wiki?curid=12435" title="Grass (disambiguation)">
Grass (disambiguation)

Grass refers to the many species of plants in the family Poaceae.

Grass may also refer to:













</doc>
<doc id="12436" url="https://en.wikipedia.org/wiki?curid=12436" title="Grape">
Grape

A grape is a fruit, botanically a berry, of the deciduous woody vines of the flowering plant genus "Vitis".

Grapes can be eaten fresh as table grapes or they can be used for making wine, jam, juice, jelly, grape seed extract, raisins, vinegar, and grape seed oil. Grapes are a non-climacteric type of fruit, generally occurring in clusters.

The cultivation of the domesticated grape began 6,000–8,000 years ago in the Near East. Yeast, one of the earliest domesticated microorganisms, occurs naturally on the skins of grapes, leading to the discovery of alcoholic drinks such as wine. The earliest archeological evidence for a dominant position of wine-making in human culture dates from 8,000 years ago in Georgia. 

The oldest known winery was found in Armenia, dating to around 4000 BC. By the 9th century AD the city of Shiraz was known to produce some of the finest wines in the Middle East. Thus it has been proposed that Syrah red wine is named after Shiraz, a city in Persia where the grape was used to make Shirazi wine. 

Ancient Egyptian hieroglyphics record the cultivation of purple grapes, and history attests to the ancient Greeks, Phoenicians, and Romans growing purple grapes for both eating and wine production. The growing of grapes would later spread to other regions in Europe, as well as North Africa, and eventually in North America.

In North America, native grapes belonging to various species of the genus "Vitis" proliferate in the wild across the continent, and were a part of the diet of many Native Americans, but were considered by early European colonists to be unsuitable for wine. In the 19th century, Ephraim Bull of Concord, Massachusetts, cultivated seeds from wild "Vitis labrusca" vines to create the Concord grape which would become an important agricultural crop in the United States.

Grapes are a type of fruit that grow in clusters of 15 to 300, and can be crimson, black, dark blue, yellow, green, orange, and pink. "White" grapes are actually green in color, and are evolutionarily derived from the purple grape. Mutations in two regulatory genes of white grapes turn off production of anthocyanins, which are responsible for the color of purple grapes. Anthocyanins and other pigment chemicals of the larger family of polyphenols in purple grapes are responsible for the varying shades of purple in red wines. Grapes are typically an ellipsoid shape resembling a prolate spheroid.

Most grapes come from cultivars of "Vitis vinifera", the European grapevine native to the Mediterranean and Central Asia. Minor amounts of fruit and wine come from American and Asian species such as:


According to the Food and Agriculture Organization (FAO), 75,866 square kilometers of the world are dedicated to grapes. Approximately 71% of world grape production is used for wine, 27% as fresh fruit, and 2% as dried fruit. A portion of grape production goes to producing grape juice to be reconstituted for fruits canned "with no added sugar" and "100% natural". The area dedicated to vineyards is increasing by about 2% per year.

There are no reliable statistics that break down grape production by variety. It is believed that the most widely planted variety is Sultana, also known as Thompson Seedless, with at least 3,600 km (880,000 acres) dedicated to it. The second most common variety is Airén. Other popular varieties include Cabernet Sauvignon, Sauvignon blanc, Cabernet Franc, Merlot, Grenache, Tempranillo, Riesling, and Chardonnay.

Commercially cultivated grapes can usually be classified as either table or wine grapes, based on their intended method of consumption: eaten raw (table grapes) or used to make wine (wine grapes). While almost all of them belong to the same species, "Vitis vinifera", table and wine grapes have significant differences, brought about through selective breeding. Table grape cultivars tend to have large, seedless fruit (see below) with relatively thin skin. Wine grapes are smaller, usually seeded, and have relatively thick skins (a desirable characteristic in winemaking, since much of the aroma in wine comes from the skin). Wine grapes also tend to be very sweet: they are harvested at the time when their juice is approximately 24% sugar by weight. By comparison, commercially produced "100% grape juice", made from table grapes, is usually around 15% sugar by weight.

Seedless cultivars now make up the overwhelming majority of table grape plantings. Because grapevines are vegetatively propagated by cuttings, the lack of seeds does not present a problem for reproduction. It is an issue for breeders, who must either use a seeded variety as the female parent or rescue embryos early in development using tissue culture techniques.

There are several sources of the seedlessness trait, and essentially all commercial cultivators get it from one of three sources: Thompson Seedless, Russian Seedless, and Black Monukka, all being cultivars of "Vitis vinifera". There are currently more than a dozen varieties of seedless grapes. Several, such as Einset Seedless, Benjamin Gunnels's Prime seedless grapes, Reliance, and Venus, have been specifically cultivated for hardiness and quality in the relatively cold climates of northeastern United States and southern Ontario.

An offset to the improved eating quality of seedlessness is the loss of potential health benefits provided by the enriched phytochemical content of grape seeds (see Health claims, below).

In most of Europe and North America, dried grapes are referred to as "raisins" or the local equivalent. In the UK, three different varieties are recognized, forcing the EU to use the term "dried vine fruit" in official documents.

A "raisin" is any dried grape. While "raisin" is a French loanword, the word in French refers to the fresh fruit; "grappe" (from which the English "grape" is derived) refers to the bunch (as in "une grappe de raisins").

A "currant" is a dried Zante Black Corinth grape, the name being a corruption of the French "raisin de Corinthe" (Corinth grape). "Currant" has also come to refer to the blackcurrant and redcurrant, two berries unrelated to grapes.

A "sultana" was originally a raisin made from Sultana grapes of Turkish origin (known as Thompson Seedless in the United States), but the word is now applied to raisins made from either white grapes or red grapes that are bleached to resemble the traditional sultana.

Grape juice is obtained from crushing and blending grapes into a liquid. The juice is often sold in stores or fermented and made into wine, brandy, or vinegar. Grape juice that has been pasteurized, removing any naturally occurring yeast, will not ferment if kept sterile, and thus contains no alcohol. In the wine industry, grape juice that contains 7–23% of pulp, skins, stems and seeds is often referred to as "must". In North America, the most common grape juice is purple and made from Concord grapes, while white grape juice is commonly made from Niagara grapes, both of which are varieties of grapes, a different species from European wine grapes. In California, Sultana (known there as Thompson Seedless) grapes are sometimes diverted from the raisin or table market to produce white juice.

Comparing diets among Western countries, researchers have discovered that although the French tend to eat higher levels of animal fat, the incidence of heart disease remains low in France. This phenomenon has been termed the French paradox, and is thought to occur from protective benefits of regularly consuming red wine. Apart from potential benefits of alcohol itself, including reduced platelet aggregation and vasodilation, polyphenols (e.g., resveratrol) mainly in the grape skin provide other suspected health benefits, such as:


Although adoption of wine consumption is not recommended by some health authorities, a significant volume of research indicates moderate consumption, such as one glass of red wine a day for women and two for men, may confer health benefits. Emerging evidence is that wine polyphenols such as resveratrol provide physiological benefit, whereas alcohol itself may have protective effects on the cardiovascular system. More may be seen in the article Long-term effects of alcohol.

Resveratrol is found in widely varying amounts among grape varieties, primarily in their skins and seeds, which, in muscadine grapes, have about one hundred times higher concentration than pulp. Fresh grape skin contains about 50 to 100 micrograms of resveratrol per gram.

Anthocyanins tend to be the main polyphenolics in purple grapes whereas flavan-3-ols (i.e. catechins) are the more abundant phenolic in white varieties. Total phenolic content, a laboratory index of antioxidant strength, is higher in purple varieties due almost entirely to anthocyanin density in purple grape skin compared to absence of anthocyanins in white grape skin. It is these anthocyanins that are attracting the efforts of scientists to define their properties for human health. Phenolic content of grape skin varies with cultivar, soil composition, climate, geographic origin, and cultivation practices or exposure to diseases, such as fungal infections.

Red wine may offer health benefits more so than white because potentially beneficial compounds are present in grape skin, and only red wine is fermented with skins. The amount of fermentation time a wine spends in contact with grape skins is an important determinant of its resveratrol content. Ordinary non-muscadine red wine contains between 0.2 and 5.8 mg/L, depending on the grape variety, because it is fermented with the skins, allowing the wine to absorb the resveratrol. By contrast, a white wine contains lower phenolic contents because it is fermented after removal of skins.

Wines produced from muscadine grapes may contain more than 40 mg/L, an exceptional phenolic content. In muscadine skins, ellagic acid, myricetin, quercetin, kaempferol, and trans-resveratrol are major phenolics. Contrary to previous results, ellagic acid and not resveratrol is the major phenolic in muscadine grapes.

The flavonols syringetin, syringetin 3-O-galactoside, laricitrin and laricitrin 3-O-galactoside are also found in purple grape but absent in white grape.

Biochemical and preliminary clinical studies have demonstrated potential biological properties of grape seed oligomeric procyanidins. For example, laboratory tests indicated a potential anticancer effect from grape seed extract. According to the American Cancer Society, "there is very little reliable scientific evidence available at this time that drinking red wine, eating grapes, or following the grape diet can prevent or treat cancer in people".

Grape seed oil from crushed seeds is used in cosmeceuticals and skincare products for perceived health benefits. Grape seed oil contains tocopherols (vitamin E) and high contents of phytosterols and polyunsaturated fatty acids such as linoleic acid, oleic acid, and alpha-linolenic acid.

The consumption of grapes and raisins presents a potential health threat to dogs. Their toxicity to dogs can cause the animal to develop acute renal failure (the sudden development of kidney failure) with anuria (a lack of urine production) and may be fatal.

Grape therapy, also known as ampelotherapy (), is a form of naturopathic medicine or alternative medicine that involves heavy consumption of grapes, including seeds, and parts of the vine, including leaves. Although there is some limited evidence of positive benefits from the consumption of grapes for health purposes, extreme claims, such as its ability to cure cancer, have been widely derided as "quackery".

In the Bible, grapes are first mentioned when Noah grows them on his farm. Instructions concerning wine are given in the book of Proverbs and in the book of Isaiah. Deuteronomy tells of the use of wine during Jewish feasts. Grapes were also significant to both the Greeks and Romans, and their god of agriculture, Dionysus, was linked to grapes and wine, being frequently portrayed with grape leaves on his head. Grapes are especially significant for Christians, who since the Early Church have used wine in their celebration of the Eucharist. Views on the significance of the wine vary between denominations. In Christian art, grapes often represent the blood of Christ, such as the grape leaves in Caravaggio's "John the Baptist".

Christians have traditionally used wine during worship services as a means of remembering the blood of Jesus Christ which was shed for the remission of sins. Christians who oppose the partaking of alcoholic beverages sometimes use grape juice or water as the "cup" or "wine" in the Lord's Supper.

The Catholic Church continues to use wine in the celebration of the Eucharist because it is part of the tradition passed down through the ages starting with Jesus Christ at the Last Supper, where Catholics believe the consecrated bread and wine "literally" become the body and blood of Jesus Christ, a dogma known as transubstantiation. Wine is used (not grape juice) both due to its strong Scriptural roots, and also to follow the tradition set by the early Christian Church. The Code of Canon Law of the Catholic Church (1983), Canon 924 says that the wine used must be natural, made from grapes of the vine, and not corrupt. In some circumstances, a priest may obtain special permission to use grape juice for the consecration; however, this is extremely rare and typically requires sufficient impetus to warrant such a dispensation, such as personal health of the priest.

Although alcohol is permitted in Judaism, grape juice is sometimes used as an alternative for kiddush on Shabbat and Jewish holidays, and has the same blessing as wine. Many authorities maintain that grape juice must be capable of turning into wine naturally in order to be used for kiddush. Common practice, however, is to use any kosher grape juice for kiddush.




</doc>
<doc id="12437" url="https://en.wikipedia.org/wiki?curid=12437" title="Genetic disorder">
Genetic disorder

A 'genetic disorder' is a problem caused by one or more abnormalities formed in the genome. Most genetic disorders are quite rare and affect one person in every several thousands or millions. The earliest known genetic condition in a hominid was in the fossil species "Paranthropus robustus," with over a third of individuals displaying Amelogenesis imperfecta.

Genetic disorders may be hereditary or non-hereditary, meaning that they are passed down from the parents' genes. However, in some genetic disorders, defects may be caused by new mutations or changes to the DNA. In such cases, the defect will only be passed down if it occurs in the germline. Genetic disorders can be monogenic, multifactoral, or chromosomal. 

Some types of recessive gene disorders confer an advantage in certain environments when only one copy of the gene is present.

A single-gene (or monogenic) disorder is the result of a single mutated gene. Over 6000 human diseases are caused by single-gene defects. Single-gene disorders can be passed on to subsequent generations in several ways. Genomic imprinting and uniparental disomy, however, may affect inheritance patterns. The divisions between recessive and dominant types are not "hard and fast", although the divisions between autosomal and X-linked types are (since the latter types are distinguished purely based on the chromosomal location of the gene). For example, achondroplasia is typically considered as a dominant disorder, but children with two genes for achondroplasia have a severe skeletal disorder of which achondroplasics could be viewed as carriers. Sickle-cell anemia is also considered as a recessive condition, but heterozygous carriers have increased resistance to malaria in early childhood, which could be described as a related dominant condition. When a couple where one partner or both are sufferers or carriers of a single-gene disorder wish to have a child, they can do so through "in vitro" fertilization, which enables preimplantation genetic diagnosis to occur.

Most congenital metabolic disorders known as inborn errors of metabolism result from single-gene defects.

Only one mutated copy of the gene will be necessary for a person to be affected by an autosomal dominant disorder. Each affected person usually has one affected parent. The chance a child will inherit the mutated gene is 50%. Autosomal dominant conditions sometimes have reduced penetrance, which means although only one mutated copy is needed, not all individuals who inherit that mutation go on to develop the disease. Examples of this type of disorder are Huntington's disease, neurofibromatosis type 1, neurofibromatosis type 2, Marfan syndrome, hereditary nonpolyposis colorectal cancer, hereditary multiple exostoses (a highly penetrant autosomal dominant disorder), Tuberous sclerosis, Von Willebrand disease, and acute intermittent porphyria. Birth defects are also called congenital anomalies.

Two copies of the gene must be mutated for a person to be affected by an autosomal recessive disorder. An affected person usually has unaffected parents who each carry a single copy of the mutated gene and are referred to as "carriers". Each parent with a defective gene normally do not have symptoms. Two unaffected people who each carry one copy of the mutated gene have a 25% risk with each pregnancy of having a child affected by the disorder. Examples of this type of disorder are Albinism, Medium-chain acyl-CoA dehydrogenase deficiency, cystic fibrosis, sickle-cell disease, Tay–Sachs disease, Niemann-Pick disease, spinal muscular atrophy, and Roberts syndrome. Certain other phenotypes, such as wet versus dry earwax, are also determined in an autosomal recessive fashion.

X-linked dominant disorders are caused by mutations in genes on the X chromosome. Only a few disorders have this inheritance pattern, with a prime example being X-linked hypophosphatemic rickets. Males and females are both affected in these disorders, with males typically being more severely affected than females. Some X-linked dominant conditions, such as Rett syndrome, incontinentia pigmenti type 2, and Aicardi syndrome, are usually fatal in males either "in utero" or shortly after birth, and are therefore predominantly seen in females. Exceptions to this finding are extremely rare cases in which boys with Klinefelter syndrome (47,XXY) also inherit an X-linked dominant condition and exhibit symptoms more similar to those of a female in terms of disease severity. The chance of passing on an X-linked dominant disorder differs between men and women. The sons of a man with an X-linked dominant disorder will all be unaffected (since they receive their father's Y chromosome), and his daughters will all inherit the condition. A woman with an X-linked dominant disorder has a 50% chance of having an affected fetus with each pregnancy, although in cases such as incontinentia pigmenti, only female offspring are generally viable.

X-linked recessive conditions are also caused by mutations in genes on the X chromosome. Males are more frequently affected than females, and the chance of passing on the disorder differs between men and women. The sons of a man with an X-linked recessive disorder will not be affected, and his daughters will carry one copy of the mutated gene. A woman who is a carrier of an X-linked recessive disorder (XX) has a 50% chance of having sons who are affected and a 50% chance of having daughters who carry one copy of the mutated gene and are therefore carriers. X-linked recessive conditions include the serious diseases hemophilia A, Duchenne muscular dystrophy, and Lesch-Nyhan syndrome, as well as common and less serious conditions such as male pattern baldness and red-green color blindness. X-linked recessive conditions can sometimes manifest in females due to skewed X-inactivation or monosomy X (Turner syndrome).

Y-linked disorders are caused by mutations on the Y chromosome. These conditions may only be transmitted from the heterogametic sex (e.g. male humans) to offspring of the same sex. More simply, this means that Y-linked disorders in humans can only be passed from men to their sons; females can never be affected because they do not possess Y-allosomes.

Y-linked disorders are exceedingly rare but the most well-known examples typically cause infertility. Reproduction in such conditions is only possible through the circumvention of infertility by medical intervention.

This type of inheritance, also known as maternal inheritance, applies to genes encoded by mitochondrial DNA. Because only egg cells contribute mitochondria to the developing embryo, only mothers can pass on mitochondrial DNA conditions to their children. An example of this type of disorder is Leber's hereditary optic neuropathy. It is important to stress that the vast majority of mitochondrial disease (particularly when symptoms develop in early life) is actually caused by an underlying nuclear gene defect, and most often follows autosomal recessive inheritance.

Genetic disorders may also be complex, multifactorial, or polygenic, meaning they are likely associated with the effects of multiple genes in combination with lifestyles and environmental factors. Multifactorial disorders include heart disease and diabetes. Although complex disorders often cluster in families, they do not have a clear-cut pattern of inheritance. This makes it difficult to determine a person’s risk of inheriting or passing on these disorders. Complex disorders are also difficult to study and treat, because the specific factors that cause most of these disorders have not yet been identified. Studies which aim to identify the cause of complex disorders can use several methodological approaches to determine genotype-phenotype associations. One method, the genotype-first approach, starts by identifying genetic variants within patients and then determining the associated clinical manifestations. This is opposed to the more traditional phenotype-first approach, and may identify causal factors that have previously been obscured by clinical heterogeneity, penetrance, and expressivity.

On a pedigree, polygenic diseases do tend to "run in families", but the inheritance does not fit simple patterns as with Mendelian diseases. But this does not mean that the genes cannot eventually be located and studied. There is also a strong environmental component to many of them (e.g., blood pressure).


A chromosomal disorder is a missing, extra, or irregular portional of chromosomal DNA. It can be from an atypical number of chromosome or a structural abnormality in one or more chromosome. An example of these disorder is Trisomy 21 (Down's syndrome), in which there is an extra copy of chromosome 21.

Due to the wide range of genetic disorders that are known, diagnosis is widely varied and dependent of the disorder. Most genetic disorders are diagnosed at birth or during early childhood however some, such as Huntington's disease, can escape detection until the patient is well into adulthood.

The basic aspects of a genetic disorder rests on the inheritance of genetic material. With an in depth family history, it is possible to anticipate possible disorders in children which direct medical professionals to specific tests depending on the disorder and allow parents the chance to prepare for potential lifestyle changes, anticipate the possibility of stillbirth, or contemplate termination. Prenatal diagnosis can detect the presence of characteristic abnormalities in fetal development through ultrasound, or detect the presence of characteristic substances via invasive procedures which involve inserting probes or needles into the uterus such as in amniocentesis.

Not all genetic disorders directly result in death; however, there are no known cures for genetic disorders. Many genetic disorders affect stages of development, such as Down syndrome, while others result in purely physical symptoms such as muscular dystrophy. Other disorders, such as Huntington's disease, show no signs until adulthood. During the active time of a genetic disorder, patients mostly rely on maintaining or slowing the degradation of quality of life and maintain patient autonomy. This includes physical therapy, pain management, and may include a selection of alternative medicine programs.

The treatment of genetic disorders is an ongoing battle with over 1800 gene therapy clinical trials having been completed, are ongoing, or have been approved worldwide. Despite this, most treatment options revolve around treating the symptoms of the disorders in an attempt to improve patient quality of life.

Gene therapy refers to a form of treatment where a healthy gene is introduced to a patient. This should alleviate the defect caused by a faulty gene or slow the progression of disease. A major obstacle has been the delivery of genes to the appropriate cell, tissue, and organ affected by the disorder. How does one introduce a gene into the potentially trillions of cells which carry the defective copy? This question has been the roadblock between understanding the genetic disorder and correcting the genetic disorder.




</doc>
<doc id="12439" url="https://en.wikipedia.org/wiki?curid=12439" title="Guanine">
Guanine

Guanine (; or G, Gua) is one of the four main nucleobases found in the nucleic acids DNA and RNA, the others being adenine, cytosine, and thymine (uracil in RNA). In DNA, guanine is paired with cytosine. The guanine nucleoside is called guanosine.

With the formula CHNO, guanine is a derivative of purine, consisting of a fused pyrimidine-imidazole ring system with conjugated double bonds. Being unsaturated, the bicyclic molecule is planar.

Guanine, along with adenine and cytosine, is present in both DNA and RNA, whereas thymine is usually seen only in DNA, and uracil only in RNA. Guanine has two tautomeric forms, the major keto form (see figures) and rare enol form.

It binds to cytosine through three hydrogen bonds. In cytosine, the amino group acts as the hydrogen bond donor and the C-2 carbonyl and the N-3 amine as the hydrogen-bond acceptors. Guanine has the C-6 carbonyl group that acts as the hydrogen bond acceptor, while a group at N-1 and the amino group at C-2 act as the hydrogen bond donors.
Guanine can be hydrolyzed with strong acid to glycine, ammonia, carbon dioxide, and carbon monoxide. First, guanine gets deaminated to become xanthine. Guanine oxidizes more readily than adenine, the other purine-derivative base in DNA. Its high melting point of 350 °C reflects the intermolecular hydrogen bonding between the oxo and amino groups in the molecules in the crystal. Because of this intermolecular bonding, guanine is relatively insoluble in water, but it is soluble in dilute acids and bases.

The first isolation of guanine was reported in 1844 by the German chemist Julius Bodo Unger (1819–1885), who obtained it as a mineral formed from the excreta of sea birds, which is known as guano and which was used as a source of fertilizer; guanine was named in 1846. Between 1882 and 1906, Fischer determined the structure and also showed that uric acid can be converted to guanine.

Trace amounts of guanine form by the polymerization of ammonium cyanide (). Two experiments conducted by Levy et al. showed that heating 10 mol·L at 80 °C for 24 hours gave a yield of 0.0007%, while using 0.1 mol·L frozen at −20 °C for 25 years gave a 0.0035% yield. These results indicate guanine could arise in frozen regions of the primitive earth. In 1984, Yuasa reported a 0.00017% yield of guanine after the electrical discharge of , , , and 50 mL of water, followed by a subsequent acid hydrolysis. However, it is unknown whether the presence of guanine was not simply a resultant contaminant of the reaction.

A Fischer-Tropsch synthesis can also be used to form guanine, along with adenine, uracil, and thymine. Heating an equimolar gas mixture of CO, H, and NH to 700 °C for 15 to 24 minutes, followed by quick cooling and then sustained reheating to 100 to 200 °C for 16 to 44 hours with an alumina catalyst, yielded guanine and uracil:

Another possible abiotic route was explored by quenching a 90% N–10%CO–HO gas mixture high-temperature plasma.

Traube's synthesis involves heating 2,4,5-triamino-1,6-dihydro-6-oxypyrimidine (as the sulfate) with formic acid for several hours.
The word guanine derives from the Spanish loanword "guano" ("bird/bat droppings"), which itself is from the Quechua word "wanu", meaning "dung". As the Oxford English Dictionary notes, guanine is "A white amorphous substance obtained abundantly from guano, forming a constituent of the excrement of birds".

In 1656 in Paris, a Mr. Jaquin extracted from the scales of the fish "Alburnus alburnus" so-called "pearl essence", which is crystalline guanine. In the cosmetics industry, crystalline guanine is used as an additive to various products (e.g., shampoos), where it provides a pearly iridescent effect. It is also used in metallic paints and simulated pearls and plastics. It provides shimmering luster to eye shadow and nail polish. Facial treatments using the droppings, or guano, from Japanese nightingales have been used in Japan and elsewhere, reportedly because the guanine in the droppings produces a clear, "bright" skin tone that users desire. Guanine crystals are rhombic platelets composed of multiple transparent layers, but they have a high index of refraction that partially reflects and transmits light from layer to layer, thus producing a pearly luster. It can be applied by spray, painting, or dipping. It may irritate the eyes. Its alternatives are mica, faux pearl (from ground shells), and aluminium and bronze particles.

Guanine has a very wide variety of biological uses that include a range of functions ranging in both complexity and versatility. These include camouflage, display, and vision among other purposes.

Spiders, scorpions, and some amphibians convert ammonia, as a product of protein metabolism in the cells, to guanine, as it can be excreted with minimal water loss.

Guanine is also found in specialized skin cells of fish called iridocytes (e.g., the sturgeon), as well as being present in the reflective deposits of the eyes of deep-sea fish and some reptiles, such as crocodiles.

On 8 August 2011, a report, based on NASA studies with meteorites found on Earth, was published suggesting building blocks of DNA and RNA (guanine, adenine and related organic molecules) may have been formed extra-terrestrially in outer space.




</doc>
<doc id="12441" url="https://en.wikipedia.org/wiki?curid=12441" title="Genocide">
Genocide

Genocide is intentional action to destroy a group of people (usually defined as an ethnic, national, racial, or religious group) in whole or in part. The hybrid word "genocide" is a combination of the Greek word "γένος" ("race, people") and the Latin suffix "-caedo" ("act of killing"). The term genocide was coined by Raphael Lemkin in his 1944 book "Axis Rule in Occupied Europe";

The United Nations Genocide Convention, which was established in 1948, defines genocide as "acts committed with intent to destroy, in whole or in part, a national, ethnic, racial or religious group", including the systematic harm or killing of its members, deliberately imposing living conditions that seek to "bring about its physical destruction in whole or in part", preventing births, or forcibly transferring children out of the group to another group.

The term has been applied to the Holocaust, and many other mass killings including the genocide of indigenous peoples in the Americas, the Armenian Genocide, the Greek genocide, the Assyrian genocide, the Serbian genocide, the Holodomor, the Indonesian genocide, the Guatemalan genocide, the 1971 Bangladesh genocide, the Cambodian genocide, and after 1980 the Bosnian genocide, the Anfal genocide, the Darfur genocide, and the Rwandan genocide. Others are listed in Genocides in history and List of genocides by death toll.

The Political Instability Task Force estimated that, between 1956 and 2016, a total of 43 genocides took place, causing the death of about 50 million people. The UNHCR estimated that a further 50 million had been displaced by such episodes of violence up to 2008.

Before 1944, various terms, including "massacre", "crimes against humanity", and "extermination" were used to describe intentional, systematic killings. In 1941, Winston Churchill, when describing the German invasion of the Soviet Union, spoke of "a crime without a name".

In 1944, Raphael Lemkin created the term "genocide" in his book "Axis Rule in Occupied Europe". The book describes the implementation of Nazi policies in occupied Europe, and cites earlier mass killings. The term described the systematic destruction of a nation or people, and the word was quickly adopted by many in the international community. The word "genocide" is the combination of the Greek prefix "geno-" (γένος, meaning 'race' or 'people') and "caedere" (the Latin word for "to kill"). The word "genocide" was used in indictments at the Nuremberg trials, held from 1945, but solely as a descriptive term, not yet as a formal legal term.

According to Lemkin, genocide was "a coordinated strategy to destroy a group of people, a process that could be accomplished through total annihilation as well as strategies that eliminate key elements of the group's basic existence, including language, culture, and economic infrastructure".
Lemkin defined genocide as follows:
The preamble to the 1948 Genocide Convention (CPPCG) notes that instances of genocide have taken place throughout history. But it was not until Lemkin coined the term and the prosecution of perpetrators of the Holocaust at the Nuremberg trials that the United Nations defined the crime of genocide under international law in the Genocide Convention.

Lemkin's lifelong interest in the mass murder of populations in the 20th century was initially in response to the killing of Armenians in 1915 and later to the mass murders in Nazi-controlled Europe. He referred to the Albigensian Crusade as "one of the most conclusive cases of genocide in religious history". He dedicated his life to mobilizing the international community, to work together to prevent the occurrence of such events. In a 1949 interview, Lemkin said "I became interested in genocide because it happened so many times. It happened to the Armenians, then after the Armenians, Hitler took action."

After the Holocaust, which had been perpetrated by Nazi Germany and its allies prior to and during World War II, Lemkin successfully campaigned for the universal acceptance of international laws defining and forbidding genocides. In 1946, the first session of the United Nations General Assembly adopted a resolution that "affirmed" that genocide was a crime under international law and enumerated examples of such events (but did not provide a full legal definition of the crime). In 1948, the UN General Assembly adopted the "Convention on the Prevention and Punishment of the Crime of Genocide" (CPPCG) which defined the crime of genocide for the first time.

The "CPPCG" was adopted by the UN General Assembly on 9 December 1948 and came into effect on 12 January 1951 (Resolution 260 (III)). It contains an internationally recognized definition of genocide which has been incorporated into the national criminal legislation of many countries, and was also adopted by the Rome Statute of the International Criminal Court, which established the International Criminal Court (ICC). Article II of the Convention defines genocide as:

The first draft of the Convention included political killings, but these provisions were removed in a political and diplomatic compromise following objections from some countries, including the USSR, a permanent security council member. The USSR argued that the Convention's definition should follow the etymology of the term, and may have feared greater international scrutiny of its own mass killings. Other nations feared that including political groups in the definition would invite international intervention in domestic politics. However leading genocide scholar William Schabas states: "Rigorous examination of the travaux fails to confirm a popular impression in the literature that the opposition to inclusion of political genocide was some Soviet machination. The Soviet views were also shared by a number of other States for whom it is difficult to establish any geographic or social common denominator: Lebanon, Sweden, Brazil, Peru, Venezuela, the Philippines, the Dominican Republic, Iran, Egypt, Belgium, and Uruguay. The exclusion of political groups was in fact originally promoted by a non-governmental organization, the World Jewish Congress, and it corresponded to Raphael Lemkin's vision of the nature of the crime of genocide."

The convention's purpose and scope was later described by the United Nations Security Council as follows:

In 2007, the European Court of Human Rights (ECHR) noted in its judgement on "Jorgic v. Germany" case that, in 1992, the majority of legal scholars took the narrow view that "intent to destroy" in the CPPCG meant the intended physical-biological destruction of the protected group, and that this was still the majority opinion. But the ECHR also noted that a minority took a broader view, and did not consider biological-physical destruction to be necessary, as the intent to destroy a national, racial, religious or ethnic group was enough to qualify as genocide.

In the same judgement, the ECHR reviewed the judgements of several international and municipal courts. It noted that the International Criminal Tribunal for the Former Yugoslavia and the International Court of Justice had agreed with the narrow interpretation (that biological-physical destruction was necessary for an act to qualify as genocide). The ECHR also noted that at the time of its judgement, apart from courts in Germany (which had taken a broad view), that there had been few cases of genocide under other Convention states' municipal laws, and that "There are no reported cases in which the courts of these States have defined the type of group destruction the perpetrator must have intended in order to be found guilty of genocide."

In the case of "Onesphore Rwabukombe", the German Supreme Court adhered to its previous judgement, and did not follow the narrow interpretation of the ICTY and the ICJ.

The phrase "in whole or in part" has been subject to much discussion by scholars of international humanitarian law. The International Criminal Tribunal for the Former Yugoslavia found in "Prosecutor v. Radislav Krstic – Trial Chamber I – Judgment – IT-98-33 (2001) ICTY8 (2 August 2001)" that Genocide had been committed. In "Prosecutor v. Radislav Krstic – Appeals Chamber – Judgment – IT-98-33 (2004) ICTY 7 (19 April 2004)" paragraphs 8, 9, 10, and 11 addressed the issue of "in part" and found that "the part must be a substantial part of that group. The aim of the Genocide Convention is to prevent the intentional destruction of entire human groups, and the part targeted must be significant enough to have an impact on the group as a whole." The Appeals Chamber goes into details of other cases and the opinions of respected commentators on the Genocide Convention to explain how they came to this conclusion.

The judges continue in paragraph 12, "The determination of when the targeted part is substantial enough to meet this requirement may involve a number of considerations. The numeric size of the targeted part of the group is the necessary and important starting point, though not in all cases the ending point of the inquiry. The number of individuals targeted should be evaluated not only in absolute terms, but also in relation to the overall size of the entire group. In addition to the numeric size of the targeted portion, its prominence within the group can be a useful consideration. If a specific part of the group is emblematic of the overall group, or is essential to its survival, that may support a finding that the part qualifies as substantial within the meaning of Article 4 [of the Tribunal's Statute]."

In paragraph 13 the judges raise the issue of the perpetrators' access to the victims: "The historical examples of genocide also suggest that the area of the perpetrators' activity and control, as well as the possible extent of their reach, should be considered. [...] The intent to destroy formed by a perpetrator of genocide will always be limited by the opportunity presented to him. While this factor alone will not indicate whether the targeted group is substantial, it can—in combination with other factors—inform the analysis."

The Convention came into force as international law on 12 January 1951 after the minimum 20 countries became parties. At that time however, only two of the five permanent members of the UN Security Council were parties to the treaty: France and the Republic of China. The Soviet Union ratified in 1954, the United Kingdom in 1970, the People's Republic of China in 1983 (having replaced the Taiwan-based Republic of China on the UNSC in 1971), and the United States in 1988. This long delay in support for the Convention by the world's most powerful nations caused the Convention to languish for over four decades. Only in the 1990s did the international law on the crime of genocide begin to be enforced.

UN Security Council Resolution 1674, adopted by the United Nations Security Council on 28 April 2006, "reaffirms the provisions of paragraphs 138 and 139 of the 2005 World Summit Outcome Document regarding the responsibility to protect populations from genocide, war crimes, ethnic cleansing and crimes against humanity". The resolution committed the Council to action to protect civilians in armed conflict.

In 2008 the UN Security Council adopted resolution 1820, which noted that "rape and other forms of sexual violence can constitute war crimes, crimes against humanity or a constitutive act with respect to genocide".

Since the Convention came into effect in January 1951 about 80 United Nations member states have passed legislation that incorporates the provisions of CPPCG into their municipal law.

William Schabas has suggested that a permanent body as recommended by the Whitaker Report to monitor the implementation of the Genocide Convention, and require States to issue reports on their compliance with the convention (such as were incorporated into the United Nations Optional Protocol to the Convention against Torture), would make the convention more effective.

Writing in 1998 Kurt Jonassohn and Karin Björnson stated that the CPPCG was a legal instrument resulting from a diplomatic compromise. As such the wording of the treaty is not intended to be a definition suitable as a research tool, and although it is used for this purpose, as it has an international legal credibility that others lack, other definitions have also been postulated. Jonassohn and Björnson go on to say that none of these alternative definitions have gained widespread support for various reasons.

Jonassohn and Björnson postulate that the major reason why no single generally accepted genocide definition has emerged is because academics have adjusted their focus to emphasise different periods and have found it expedient to use slightly different definitions to help them interpret events. For example, Frank Chalk and Kurt Jonassohn studied the whole of human history, while Leo Kuper and R. J. Rummel in their more recent works concentrated on the 20th century, and Helen Fein, Barbara Harff and Ted Gurr have looked at post World War II events. Jonassohn and Björnson are critical of some of these studies, arguing that they are too expansive, and conclude that the academic discipline of genocide studies is too young to have a canon of work on which to build an academic paradigm.

The exclusion of social and political groups as targets of genocide in the CPPCG legal definition has been criticized by some historians and sociologists, for example M. Hassan Kakar in his book "The Soviet Invasion and the Afghan Response, 1979–1982" argues that the international definition of genocide is too restricted, and that it should include political groups or any group so defined by the perpetrator and quotes Chalk and Jonassohn: "Genocide is a form of one-sided mass killing in which a state or other authority intends to destroy a group, as that group and membership in it are defined by the perpetrator." In turn some states such as Ethiopia, France, and Spain include political groups as legitimate genocide victims in their anti-genocide laws.

Barbara Harff and Ted Gurr defined genocide as "the promotion and execution of policies by a state or its agents which result in the deaths of a substantial portion of a group ... [when] the victimized groups are defined primarily in terms of their communal characteristics, i.e., ethnicity, religion or nationality". Harff and Gurr also differentiate between genocides and politicides by the characteristics by which members of a group are identified by the state. In genocides, the victimized groups are defined primarily in terms of their communal characteristics, i.e., ethnicity, religion or nationality. In politicides the victim groups are defined primarily in terms of their hierarchical position or political opposition to the regime and dominant groups. Daniel D. Polsby and Don B. Kates, Jr. state that "we follow Harff's distinction between genocides and 'pogroms', which she describes as 'short-lived outbursts by mobs, which, although often condoned by authorities, rarely persist'. If the violence persists for long enough, however, Harff argues, the distinction between condonation and complicity collapses."

According to R. J. Rummel, genocide has 3 different meanings. The ordinary meaning is murder by government of people due to their national, ethnic, racial, or religious group membership. The legal meaning of genocide refers to the international treaty, the "Convention on the Prevention and Punishment of the Crime of Genocide" (CPPCG). This also includes non-killings that in the end eliminate the group, such as preventing births or forcibly transferring children out of the group to another group. A generalized meaning of genocide is similar to the ordinary meaning but also includes government killings of political opponents or otherwise intentional murder. It is to avoid confusion regarding what meaning is intended that Rummel created the term democide for the third meaning.

Highlighting the potential for state and non-state actors to commit genocide in the 21st century, for example, in failed states or as non-state actors acquire weapons of mass destruction, Adrian Gallagher defined genocide as 'When a source of collective power (usually a state) intentionally uses its power base to implement a process of destruction in order to destroy a group (as defined by the perpetrator), in whole or in substantial part, dependent upon relative group size'. The definition upholds the centrality of intent, the multidimensional understanding of destroy, broadens the definition of group identity beyond that of the 1948 definition yet argues that a substantial part of a group has to be destroyed before it can be classified as genocide.

All signatories to the CPPCG are required to prevent and punish acts of genocide, both in peace and wartime, though some barriers make this enforcement difficult. In particular, some of the signatories—namely, Bahrain, Bangladesh, India, Malaysia, the Philippines, Singapore, the United States, Vietnam, Yemen, and former Yugoslavia—signed with the proviso that no claim of genocide could be brought against them at the International Court of Justice without their consent. Despite official protests from other signatories (notably Cyprus and Norway) on the ethics and legal standing of these reservations, the immunity from prosecution they grant has been invoked from time to time, as when the United States refused to allow a charge of genocide brought against it by former Yugoslavia following the 1999 Kosovo War.

It is commonly accepted that, at least since World War II, genocide has been illegal under customary international law as a peremptory norm, as well as under conventional international law. Acts of genocide are generally difficult to establish for prosecution, because a chain of accountability must be established. International criminal courts and tribunals function primarily because the states involved are incapable or unwilling to prosecute crimes of this magnitude themselves.

The Nazi leaders who were prosecuted shortly after World War II for taking part in the Holocaust, and other mass murders, were charged under existing international laws, such as crimes against humanity, as the crime of "genocide' was not formally defined until the 1948 "Convention on the Prevention and Punishment of the Crime of Genocide" (CPPCG). Nevertheless, the recently coined term appeared in the indictment of the Nazi leaders, Count 3, which stated that those charged had "conducted deliberate and systematic genocide—namely, the extermination of racial and national groups—against the civilian populations of certain occupied territories in order to destroy particular races and classes of people, and national, racial or religious groups, particularly Jews, Poles, Gypsies and others."

The term "Bosnian genocide" is used to refer either to the killings committed by Serb forces in Srebrenica in 1995, or to ethnic cleansing that took place elsewhere during the 1992–1995 Bosnian War.

In 2001, the International Criminal Tribunal for the Former Yugoslavia (ICTY) judged that the 1995 Srebrenica massacre was an act of genocide. On 26 February 2007, the International Court of Justice (ICJ), in the "Bosnian Genocide Case" upheld the ICTY's earlier finding that the massacre in Srebrenica and Zepa constituted genocide, but found that the Serbian government had not participated in a wider genocide on the territory of Bosnia and Herzegovina during the war, as the Bosnian government had claimed.

On 12 July 2007, European Court of Human Rights when dismissing the appeal by Nikola Jorgić against his conviction for genocide by a German court (Jorgic v. Germany) noted that the German courts wider interpretation of genocide has since been rejected by international courts considering similar cases. The ECHR also noted that in the 21st century "Amongst scholars, the majority have taken the view that ethnic cleansing, in the way in which it was carried out by the Serb forces in Bosnia and Herzegovina in order to expel Muslims and Croats from their homes, did not constitute genocide. However, there are also a considerable number of scholars who have suggested that these acts did amount to genocide, and the ICTY has found in the Momcilo Krajisnik case that the actus reus of genocide was met in Prijedor "With regard to the charge of genocide, the Chamber found that in spite of evidence of acts perpetrated in the municipalities which constituted the actus reus of genocide".

About 30 people have been indicted for participating in genocide or complicity in genocide during the early 1990s in Bosnia. To date, after several plea bargains and some convictions that were successfully challenged on appeal two men, Vujadin Popović and Ljubiša Beara, have been found guilty of committing genocide, Zdravko Tolimir has been found guilty of committing genocide and conspiracy to commit genocide, and two others, Radislav Krstić and Drago Nikolić, have been found guilty of aiding and abetting genocide. Three others have been found guilty of participating in genocides in Bosnia by German courts, one of whom Nikola Jorgić lost an appeal against his conviction in the European Court of Human Rights. A further eight men, former members of the Bosnian Serb security forces were found guilty of genocide by the State Court of Bosnia and Herzegovina (See List of Bosnian genocide prosecutions).

Slobodan Milošević, as the former President of Serbia and of Yugoslavia, was the most senior political figure to stand trial at the ICTY. He died on 11 March 2006 during his trial where he was accused of genocide or complicity in genocide in territories within Bosnia and Herzegovina, so no verdict was returned. In 1995, the ICTY issued a warrant for the arrest of Bosnian Serbs Radovan Karadžić and Ratko Mladić on several charges including genocide. On 21 July 2008, Karadžić was arrested in Belgrade, and later tried in The Hague accused of genocide among other crimes. On 24 March 2016, Karadžić was found guilty of genocide in Srebrenica, war crimes and crimes against humanity, 10 of the 11 charges in total, and sentenced to 40 years' imprisonment. Mladić was arrested on 26 May 2011 in Lazarevo, Serbia, and was tried in The Hague. The verdict, delivered on 22 November 2017 found Mladić guilty of 10 of the 11 charges, including genocide and he was sentenced to life imprisonment.

The International Criminal Tribunal for Rwanda (ICTR) is a court under the auspices of the United Nations for the prosecution of offenses committed in Rwanda during the genocide which occurred there during April 1994, commencing on 6 April. The ICTR was created on 8 November 1994 by the Security Council of the United Nations in order to judge those people responsible for the acts of genocide and other serious violations of the international law performed in the territory of Rwanda, or by Rwandan citizens in nearby states, between 1 January and 31 December 1994.

So far, the ICTR has finished nineteen trials and convicted twenty seven accused persons. On 14 December 2009 two more men were accused and convicted for their crimes. Another twenty five persons are still on trial. Twenty-one are awaiting trial in detention, two more added on 14 December 2009. Ten are still at large. The first trial, of Jean-Paul Akayesu, began in 1997. In October 1998, Akayesu was sentenced to life imprisonment. Jean Kambanda, interim Prime Minister, pleaded guilty.

The Khmer Rouge, led by Pol Pot, Ta Mok and other leaders, organized the mass killing of ideologically suspect groups. The total number of victims is estimated at approximately 1.7 million Cambodians between 1975–1979, including deaths from slave labour.

On 6 June 2003 the Cambodian government and the United Nations reached an agreement to set up the Extraordinary Chambers in the Courts of Cambodia (ECCC) which would focus exclusively on crimes committed by the most senior Khmer Rouge officials during the period of Khmer Rouge rule of 1975–1979. The judges were sworn in early July 2006.

The genocide charges related to killings of Cambodia's Vietnamese and Cham minorities, which is estimated to make up tens of thousand killings and possibly more

The investigating judges were presented with the names of five possible suspects by the prosecution on 18 July 2007.

There has been disagreement between some of the international jurists and the Cambodian government over whether any other people should be tried by the Tribunal.

Since 2002, the International Criminal Court can exercise its jurisdiction if national courts are unwilling or unable to investigate or prosecute genocide, thus being a "court of last resort," leaving the primary responsibility to exercise jurisdiction over alleged criminals to individual states. Due to the United States concerns over the ICC, the United States prefers to continue to use specially convened international tribunals for such investigations and potential prosecutions.

There has been much debate over categorizing the situation in Darfur as genocide. The ongoing conflict in Darfur, Sudan, which started in 2003, was declared a "genocide" by United States Secretary of State Colin Powell on 9 September 2004 in testimony before the Senate Foreign Relations Committee. Since that time however, no other permanent member of the UN Security Council has done so. In fact, in January 2005, an International Commission of Inquiry on Darfur, authorized by UN Security Council Resolution 1564 of 2004, issued a report to the Secretary-General stating that "the Government of the Sudan has not pursued a policy of genocide." Nevertheless, the Commission cautioned that "The conclusion that no genocidal policy has been pursued and implemented in Darfur by the Government authorities, directly or through the militias under their control, should not be taken in any way as detracting from the gravity of the crimes perpetrated in that region. International offences such as the crimes against humanity and war crimes that have been committed in Darfur may be no less serious and heinous than genocide."

In March 2005, the Security Council formally referred the situation in Darfur to the Prosecutor of the International Criminal Court, taking into account the Commission report but without mentioning any specific crimes. Two permanent members of the Security Council, the United States and China, abstained from the vote on the referral resolution. As of his fourth report to the Security Council, the Prosecutor has found "reasonable grounds to believe that the individuals identified [in the UN Security Council Resolution 1593] have committed crimes against humanity and war crimes," but did not find sufficient evidence to prosecute for genocide.

In April 2007, the Judges of the ICC issued arrest warrants against the former Minister of State for the Interior, Ahmad Harun, and a Militia
Janjaweed leader, Ali Kushayb, for crimes against humanity and war crimes.

On 14 July 2008, prosecutors at the International Criminal Court (ICC), filed ten charges of war crimes against Sudan's President Omar al-Bashir: three counts of genocide, five of crimes against humanity and two of murder. The ICC's prosecutors claimed that al-Bashir "masterminded and implemented a plan to destroy in substantial part" three tribal groups in Darfur because of their ethnicity.

On 4 March 2009, the ICC issued a warrant of arrest for Omar Al Bashir, President of Sudan as the ICC Pre-Trial Chamber I concluded that his position as head of state does not grant him immunity against prosecution before the ICC. The warrant was for war crimes and crimes against humanity. It did not include the crime of genocide because the majority of the Chamber did not find that the prosecutors had provided enough evidence to include such a charge. Later the decision was changed by the Appeals Panel and after issuing the second decision, charges against Omar al-Bashir include three counts of genocide.

The concept of genocide can be applied to historical events of the past. The preamble to the CPPCG states that "at all periods of history genocide has inflicted great losses on humanity."

Revisionist attempts to challenge or affirm claims of genocide are illegal in some countries. For example, several European countries ban the denial of the Holocaust or the Armenian Genocide, while in Turkey referring to the mass killings of Armenians, Greeks, Assyrians and Maronites as genocides may be prosecuted under Article 301.

William Rubinstein argues that the origin of 20th century genocides can be traced back to the collapse of the elite structure and normal modes of government in parts of Europe following the First World War:

In 1996 Gregory Stanton, the president of Genocide Watch, presented a briefing paper called "The 8 Stages of Genocide" at the United States Department of State. In it he suggested that genocide develops in eight stages that are "predictable but not inexorable".

The Stanton paper was presented to the State Department, shortly after the Rwandan Genocide and much of its analysis is based on why that genocide occurred. The preventative measures suggested, given the briefing paper's original target audience, were those that the United States could implement directly or indirectly by using its influence on other governments.

In April 2012, it was reported that Stanton would soon be officially adding two new stages, Discrimination and Persecution, to his original theory, which would make for a 10-stage theory of genocide.

In a paper for the Social Science Research Council Dirk Moses criticises the Stanton approach, concluding:

Other authors have focused on the structural conditions leading up to genocide and the psychological and social processes that create an evolution toward genocide. Ervin Staub showed that economic deterioration and political confusion and disorganization were starting points of increasing discrimination and violence in many instances of genocides and mass killing. They lead to scapegoating a group and ideologies that identified that group as an enemy. A history of devaluation of the group that becomes the victim, past violence against the group that becomes the perpetrator leading to psychological wounds, authoritarian cultures and political systems, and the passivity of internal and external witnesses (bystanders) all contribute to the probability that the violence develops into genocide. Intense conflict between groups that is unresolved, becomes intractable and violent can also lead to genocide. The conditions that lead to genocide provide guidance to early prevention, such as humanizing a devalued group, creating ideologies that embrace all groups, and activating bystander responses. There is substantial research to indicate how this can be done, but information is only slowly transformed into action.

Kjell Anderson uses a dichotomistic classification of genocides: "hot genocides, motivated by hate and the victims' threatening nature, with low-intensity cold genocides, rooted in victims' supposed inferiority."


Articles

Books

Documents

Research institutes, advocacy groups, and other organizations


</doc>
<doc id="12442" url="https://en.wikipedia.org/wiki?curid=12442" title="George Clinton">
George Clinton

George Clinton may refer to:






</doc>
<doc id="12446" url="https://en.wikipedia.org/wiki?curid=12446" title="Germanic peoples">
Germanic peoples

The Germanic peoples (also called Teutons, Suebian, or Gothic in older literature) were an indigenous ethnolinguistic group of Northern European origin identified by Roman-era authors as distinct from neighbouring Celtic peoples, and identified in modern scholarship as speakers, at least for the most part, of early Germanic languages.

A Proto-Germanic population is believed to have emerged during the Nordic Bronze Age, which developed out of the Battle Axe culture in southern Scandinavia. During the Iron Age various Germanic tribes began a southward expansion at the expense of Celtic peoples, which led to centuries of sporadic violent conflict with ancient Rome. It is from Roman authors that the term "Germanic" originated. The decisive victory of Arminius at the Battle of the Teutoburg Forest in 9 CE is believed to have prevented the eventual Romanization of the Germanic peoples, and has therefore been considered a turning point in world history. Germanic tribes settled the entire Roman frontier along the Rhine and the Danube, and some established close relations with the Romans, often serving as royal tutors and mercenaries, sometimes even rising to the highest offices in the Roman military. Meanwhile, Germanic tribes expanded into Eastern Europe, where the Goths subdued the local Iranian nomads and came to dominate the Pontic Steppe, simultaneously launching sea expeditions into the Balkans and Anatolia as far as Cyprus.

The westward expansion of the Huns into Europe in the late 4th century CE pushed many Germanic tribes into the Western Roman Empire. Their vacated lands were filled by Slavs. Much of these territories were reclaimed in following centuries. Other tribes settled Great Britain and became known as the Anglo-Saxons. With the collapse of the Western Roman Empire, a series of Germanic kingdoms emerged, of which, Francia gained a dominant position. This kingdom formed the Holy Roman Empire under the leadership of Charlemagne, who was officially recognized by Pope Leo III in 800 CE. Meanwhile, North Germanic seafarers, commonly referred to as Vikings, embarked on a massive expansion which led to the establishment of the Duchy of Normandy, Kievan Rus' and their settlement of the British Isles and the North Atlantic Ocean as far as North America. With the North Germanic abandonment of their native religion in the 11th century, nearly all Germanic peoples had been converted to Christianity.

In about 222 BCE, the first use of the Latin term ""Germani"" appears in the "Fasti Capitolini" inscription "de Galleis Insvbribvs et Germ(aneis)". This may simply be referring to Gaul or related people; but this may be an inaccurate date since the inscription was erected in about 18 BCE despite referencing an earlier date. The term "Germani" shows up again, allegedly written by Poseidonios (from 80 BCE), but is merely a quotation inserted by the author Athenaios who wrote much later (around 190 CE). Somewhat later, the first surviving detailed discussions of Germani and Germania are those of Julius Caesar, whose memoirs are based on first-hand experience.

From Caesar's perspective, "Germania" was a geographical area of land on the east bank of the Rhine opposite Gaul, which Caesar left outside direct Roman control. This word provides the etymological origin of the modern concept of "Germanic" languages and Germany as a geographical abstraction. For some classical authors Germania also included regions of Sarmatia, as well as an area under Roman control on the west bank of the Rhine. Additionally, in the south there were Celtic peoples still living east of the Rhine and north of the Alps. Caesar, Tacitus and others noted differences of culture which could be found on the east of the Rhine. But the theme of all these cultural references was that this was a wild and dangerous region, less civilized than Gaul, a place that required additional military vigilance.

Caesar also used the term "Germani" for a very specific tribal grouping in northeastern Belgic Gaul, west of the Rhine, the largest part of whom were the Eburones. He made clear that he was using the name in the local sense. These are the so-called "Germani Cisrhenani", whom Caesar believed to be closely related to the peoples east of the Rhine, and descended from immigrants into Gaul. Tacitus suggests that this was the original meaning of the word ""Germani"" – as the name of a single tribal nation west of the Rhine, ancestral to the Tungri (who lived in the same area as the earlier "Germani" reported by Caesar), and not the name of a whole race ("gens") as it came to mean. He also suggested that two large Belgic tribes neighbouring Caesar's "Germani", the Nervii and the Treveri, liked to call themselves Germanic in his time, in order not to be associated with Gaulish indolence. Caesar described this group of tribes both as Belgic Gauls and as "Germani". Gauls are associated with Celtic languages, and the term "Germani" is associated with Germanic languages, but Caesar did not discuss languages in detail (though he did say that Belgic Gaul was different from Celtic Gaul in language). The geographer Ptolemy described the place where these people lived as "Germania", which according to his accounts was bordered by the Rhine, Vistula and Danube Rivers, but he also circumscribed into Greater "Germania" an area which included Jutland (Cimbrian peninsula) and an enormous island known as "Scandia" (the Scandinavian peninsula).

While saying that the Germani had ancestry across the Rhine, Caesar did not describe these tribes as recent immigrants, saying that they had defended themselves some generations earlier from the invading Cimbri and Teutones. (He thereby distinguished them from the neighbouring Aduatuci, whom he did not call "Germani", but who were descended from those Cimbri and Teutones.) It has been claimed, for example by Maurits Gysseling, that the place names of this region show evidence of an early presence of Germanic languages, as early as the 2nd century BCE. The Celtic culture and language were however clearly influential also, as can be seen in the tribal name of the Eburones, their kings' names, Ambiorix and Cativolcus, and also the material culture of the region.

The etymology of the word "Germani" is uncertain. The likeliest theory so far proposed is that it comes from a Gaulish compound of *"ger" "near" + *"mani" "men", comparable to Welsh "ger" "near" (prep.), Old Irish "gair" "neighbor", Irish "gar-" (prefix) "near", "garach" "neighborly". Another Celtic possibility is that the name meant "noisy"; cf. Breton/Cornish "garm" "shout", Irish "gairm" "call". However, here the vowel does not match, nor does the vowel length (contrast with inscriptional "Garmangabi" (UK) and "Garma" Alise, G-257)). Others have proposed a Germanic etymology *"gēr"-"manni", "spear men", cf. Middle Dutch "ghere", Old High German "Ger", Old Norse "geirr". However, the form "gēr" (from PGmc *"gaizaz") seems far too advanced phonetically for the 1st century, has a long vowel where a short one is expected, and the Latin form has a simplex -"n"-, not a geminate.

The term "Germani", therefore, probably applied to a small group of tribes in northeastern Gaul who may or may not have spoken a Germanic language, and whose links to "Germania" are unclear. It appears that the Germanic tribes did not have a word to describe themselves, although the word "Suebi", used by Caesar to broadly classify Germanic speakers, was likely Germanic in origin. They did however use the term "walhaz" to describe outsiders (mainly Celts, Romans and Greeks). Roman authors frequently employed the term "barbarian" from the Latin derivative "barbarus" (inherited from the Greek "barbaros" which means "foreign") when describing Germanic peoples. Such a term presupposed a distinctive Roman intellectual and cultural superiority and their ethnographic treatises on the various barbarian tribes ascribed specific attributes of barbarism to each one so as to delineate the dichotomy between barbarism and civilization. The more the Romans increased their presence along the periphery of their Empire, the more trade and employment for the barbarians became available, resulting in an economic boom along the corridors of the Danube River, which subsequently increased the Roman focus upon the Germanic peoples. Use of the modern term German or Germanic is the result of 18th and 19th century classical philology which "envisioned the Germanic language group as occupying a central branch of the Indo-European language tree."

Latin scholars of the 10th century used the adjective "teutonicus" (a derivative of Teutones) when referencing East Francia, which in their vernacular was connoted ""Regnum Teutonicum"", for that area and all of its subsequent inhabitants. Modern speakers of English still use the word "Teutons" to describe Germanic peoples. Historically, the Teutones were only one specific tribe, and may not even have spoken a Germanic language. For example, some scholars postulate that the original Teutonic language may have been a form of Celtic. The source of this confusion, whereby Teutons are lumped into the same category as German-speaking tribes, comes from their contact with the Romans in the 2nd century BCE, when they, along with the Cimbri and the Ambrones, led a frightening attack against the Romans. Teuton was the byword the Romans applied to the barbarians from the north and which they used to describe subsequent Germanic peoples. Under the leadership of Gaius Marius, who built his career on barbarian antagonists (like many who followed), the Teutones became one of the archetypal enemies of the Roman Empire.

By the 1st century CE, the writings of Pomponius Mela, Pliny the Elder, and Tacitus indicate a division of Germanic-speaking peoples into large groupings who shared ancestry and culture. This division has been appropriated in modern terminology describing the divisions of Germanic languages.

Tacitus, in his "Germania", wrote that:
Tacitus also specifies that the Suevi are a very large grouping, with many tribes within it, with their own names. The largest, he says, is the Semnones, the Langobardi are fewer, but living surrounded by warlike peoples, and in remoter and better defended areas live the Reudigni, Aviones, Anglii, Varini, Eudoses, the Suardones, and Nuithones.

Pliny the Elder, on the other hand, names five races of Germans in his "Historia Naturalis", not three, by distinguishing the two more easterly blocks of Germans, the Vandals and further east the Bastarnae, who were the first to reach the Black Sea and come into contact with Greek civilization. He is also slightly more specific about the position of the Istvaeones, though he also does not name any examples of them:

The remote Varini are listed by Tacitus as being in the Suebic or Hermionic group by Tacitus, above, but by Pliny in the eastern Vandalic or Gothic group, so the two accounts do not match perfectly.

These accounts and others from the period often emphasise that the Suebi and their Hermione kin formed an especially large and mobile nation, which at the time were living mainly near the Elbe, both east and west of it, but they were also moving westwards into the lands near the Roman frontier. Pomponius Mela in his slightly earlier "Description of the World," places "the farthest people of Germania, the Hermiones" somewhere to the east of the Cimbri and the Teutones, and further from Rome, apparently on the Baltic. Strabo however describes the Suebi as going through a period where they were pushed back east by the Romans, in the direction from which they had come:

By the end of the 5th century the term "Gothic" was used more generally in the historical sources for Pliny's "Vandals" to the east of the Elbe, including not only the Goths and Vandals, but also "the Gepids along the Tisza and the Danube, the Rugians, Sciri and Burgundians, even the Iranian Alans."

Linguists postulate that an early proto-Germanic language existed and was distinguishable from the other Indo-European languages as far back as 500 BCE. The earliest known Germanic inscription was found at Negau (in what is now southern Austria) on a bronze helmet dating back to the first century BCE. Some of the other earliest known physical records of the Germanic language appear on stone and wood carvings in Runic script from around 200 CE. Runic writing likely disappeared due to the concerted opposition of the Christian Church, which regarded runic text as heathen symbols which supposedly contained inherent magical properties that they associated with the Germanic peoples' pagan past. Unfortunately, this primitive view ignores the abundance of "pious runic writing found on church-related objects" (ranging from inscriptions in the doorways of churches, on church bells and even those found on baptismal fonts) when Christianity was introduced into the Germanic North. An important linguistic step was made by the Christian convert Ulfilas, who became a bishop to the Visigoths in CE 341; he subsequently invented an alphabet and translated the scriptures from Greek into Gothic, creating the earliest known translation of the Bible into a Germanic language.

From what is known, the early Germanic tribes may have spoken "mutually intelligible dialects" derived from a common parent language but there are no written records to verify this fact. Despite their common linguistic framework, by the 5th century CE, the Germanic people were linguistically differentiated and could no longer easily comprehend one another. Nonetheless, the line between Germanic languages and Romance speakers in central Europe remained at the western mouth of the Rhine river and while Gaul fell under German domination and was firmly settled by the Franks, the linguistic patterns did not move much. Further west and south in Europe-proper, the linguistic presence of the Germanic languages is almost negligible. Despite the fact that the Visigoths ruled what is now Spain for upwards of 250 years, there are almost no recognizable Gothic words borrowed into Spanish.

The Germanic tribes moved and interacted over the next centuries, and separate dialects among Germanic languages developed down to the present day. Some groups, such as the Suebians, have a continuous recorded existence, and so there is a reasonable confidence that their modern dialects can be traced back to those in classical times. By extension, but sometimes controversially, the names of the sons of Mannus, Istvaeones, Irminones, and Ingvaeones, are also sometimes used to divide up the medieval and modern West Germanic languages. The more easterly groups such as the Vandals are thought to have been united in the use of East Germanic languages, the most famous of which is Gothic. The dialect of the Germanic people who remained in Scandinavia is not generally called Ingvaeonic, but is classified as North Germanic, which developed into Old Norse. Within the West Germanic group, linguists associate the Suebian or Hermionic group with an "Elbe Germanic" which developed into Upper German, including modern German.

More speculatively, given the lack of any such clear explanation in any classical source, modern linguists sometimes designate the Frankish language (and its descendant Dutch) as Istvaeonic, although the geographical term "Weser-Rhine Germanic" is often preferred. However, the classical ""Germani"" near the Rhine, to whom the term was originally applied by Caesar, may not have even spoken Germanic languages, let alone a language recognizably ancestral to modern Dutch. The close relatives of Dutch, Low German, Anglo-Saxon and Frisian, are in fact sometimes designated as Ingvaeonic, or alternatively, "North-Sea Germanic". Frankish, (and later Dutch, Luxembourgish and the Frankish dialects of German in Germany) has continuously been intelligible to some extent with both "Ingvaeonic" Low German, and some "Suebian" High German dialects, with which they form a spectrum of continental dialects. All these dialects or languages appear to have formed by the mixing of migrating peoples after the time of Caesar. So it is not clear if these medieval dialect divisions correspond to any mentioned by Tacitus and Pliny. Indeed, in Tacitus (Tac. Ger. 40) and in Claudius Ptolemy's "Geography", the Anglii, ancestors of the Anglo-Saxons, are designated as being a Suebic tribe.

By 500 CE, the West Germanic speakers had apparently developed a distinct language continuum with extensive loaning from Latin (due to their ongoing contact with the Romans), whereas the East Germanic languages were dying out. West Germanic languages include: German, Yiddish, Dutch, Afrikaans, Luxemburgish, Frisian, and English. Combined, these languages are today spoken as a native tongue by more than 450 million people worldwide. North Germanic languages are Swedish, Danish, Norwegian, Faroese and Icelandic. Roughly 20 million people currently speak the North Germanic languages as their native tongue. Later manifestations of the West Germanic languages and their pursuant typological characteristics are due in part to the activities of the Hanseatic League where trade necessitated a "lingua franca" from the mainland of Scandinavia all along the navigable shores of the North Sea, and within the Baltic Sea.

Archaeological and linguistic evidence from a period known as the Nordic Bronze Age indicates that a common material culture existed between the Germanic tribes that inherited the southern regions of Scandinavia, along with the Schleswig-Holstein area and the area of what is now Hamburg, Germany. Additional archaeological remnants from the Iron Age society that once existed in nearby Wessenstedt also show traces of this culture. Exactly how these cultures interacted remains a mystery but the migrations of early proto-Germanic peoples are discernible from the remaining evidence of prehistoric cultures in Hügelgräber, Urnfield, and La Tene. Climatic change between 850 BCE to 760 BCE in Scandinavia and "a later and more rapid one around 650 BCE might have triggered migrations to the coast of eastern Germany and further toward the Vistula.

The cultural phase of the late Bronze Age and early Iron Age in Europe (c. 1200–600 BCE in temperate continental areas), known in contemporary terms as the Hallstatt culture expanded from the south into this area and brought the early Germanic peoples under the influence of early Celtic (or pre Celtic) culture between 1200 BCE to 600 BCE, whereupon they began extracting bog iron from the available ore in peat bogs. This ushered in the Pre-Roman Iron Age. Stretching from central France all the way to western Hungary and then from the Alps to central Poland, the Hallstatt culture also constructed sophisticated structures and the archaeological remains across parts of France, Germany and Hungary suggest their trade networks along the North Atlantic, Baltic Sea and up and down central Europe's river valleys were fairly elaborate as well.

The earliest sites at which Germanic peoples "per se" have been documented are in Northern Europe, in what now constitutes the plains of Denmark and southern Sweden. However, in even this region, the population had been, according to Waldman & Mason, "remarkably stable" – as far back as the Neolithic Age, when humans first began controlling their environment through the use of agriculture and the domestication of animals. Given this stability, the population of the region necessarily preceded the arrival in Europe of the precursors of the Germanic languages – which most likely began with the Corded Ware culture.

During the 2nd millennium BCE, the so-called Nordic Bronze Age culture expanded eastward into the adjacent regions between the estuaries of the Elbe and Oder rivers.

As early as 750 BCE, archeological evidence gives the impression that the proto-Germanic population was becoming more uniform in its culture. The Germanic peoples at the time inhabited southern Scandinavia and the Northern Sea and Baltic coasts from modern-day Netherlands to the Vistula. As this population grew, it migrated south-west, into coastal floodplains due to the exhaustion of the soil in its original settlements.

By approximately 250 BCE, additional expansion further southwards into central Europe had begun to take place and five general groups of Germanic people emerged, each employing distinct linguistic dialects but sharing similar language innovations — they are distinguished from one another as: "North Germanic" in southern Scandinavia; "North Sea Germanic" in the regions along the North Sea and in the Jutland peninsula NW Europe, which forms the mainland of Denmark together with the north German state of Schleswig-Holstein; "Rhine-Weser Germanic" along the middle Rhine and Weser river (which empties into the North Sea near Bremerhaven); "Elbe Germanic" spoken by the people living directly along the middle Elbe river; and "East Germanic" between the middle of the Oder and the Vistula rivers.

Concomitantly, during the 2nd century BCE the advent of the Celtic culture of Hallstatt and La Tene arose in nearby territories further west but the interactions between the early Germanic people and the Celts is thought to have been minimal based on the linguistic evidence. Despite the absence of the Celtic influence further eastwards, there are a number of Celtic loanwords in Proto-Germanic, which at the very least indicates contact between the people of Gaul and the early Germanic cultures that resided along the Rhine river. Nonetheless, material objects such as metal ornaments and pottery found near the areas east of the lower Rhine are connoted as Jastorf in nomenclature and are characteristically distinguishable from the Celtic objects found further west.

It is not clear if the first occurrence of the term "Germani" in Roman ethnography is either a reference to Germanic or Celtic according to modern linguists, but it is probable that the clear geographic demarcation appearing between the two peoples may have been made for the sake of political convenience by Caesar. Caesar described some tribes more distinctly than others but generally considered most of them as being from Germanic stock. However, the archaeological evidence in some of the regions creates an ethnographic problem in clearly delineating the indigenous people based strictly on Roman classification. Nonetheless, there are scholars who assert that there was an eventual linguistic "Germanization" that occurred during the 1st century BCE through something they call the "elite-dominance" model. Archaeologists are unable to make definitive judgments which accord the observations of the Roman writer Tacitus. Enough cultural absorption between the various Germanic people occurred that geographically defining the extent of pre-Roman Germanic territory is nearly impossible from a classification standpoint.

Some recognizable trends in the archaeological records exist, as it is known that, generally, West Germanic people while still migratory, were more geographically settled, whereas the East Germanic peoples remained transitory for a longer period. Three settlement patterns and solutions come to the fore, the first of which is the establishment of an agricultural base in a region which allowed them to support larger populations; second, the Germanic peoples periodically cleared forests to extend the range of their pasturage; thirdly (and the most frequent occurrence), they often emigrated to other areas as they exhausted the immediately available resources. War and conquest followed as the Germanic people migrated bringing them into direct conflict with the Celts who were forced to either Germanize or migrate elsewhere as a result. Evidence suggest that these were Germanized rather than displaced. West Germanic peoples eventually settled in central Europe and became more accustomed to agriculture and it is those people that are described by Caesar and Tacitus. Meanwhile, the East Germanic people continued their migratory habits. Roman writers characteristically organized and classified people and it may very well have been deliberate on their part to recognize the tribal distinctions of the various Germanic people so as to pick out known leaders and exploit these differences for their benefit. For the most part however, these early Germanic people shared a basic culture, operated similarly from an economic perspective, and were not nearly as differentiated as the Romans implied. In fact, the Germanic tribes are hard to distinguish from the Celts on many accounts simply based on archaeological records.

One of the earliest known written records of the Germanic world in classical times was in the lost work of Pytheas. Pytheas traveled to northern Europe, some time in the late 4th century BCE, and his observations about the geographical environment, traditions and culture of the northern European populations became a central source of information for later historians – often the only source. Authors such as Strabo, Pliny and Diodorus cite Pytheas in disbelief, although Pytheas' observations appear to have been accurate. Though Pytheas was not the first Mediterranean to explore those lands (note for example Himilco (5th century BCE), and possibly Phoenicians and Tartessians (), his became the first substantial surviving description of these populations. Much of the Germanic peoples' early history enters into view through Pytheas, particularly since he was also possibly the first to distinguish the "Germanoi" people of northern and central Europe as distinct from the "Keltoi" people further west. Along with the records of a couple of other classical writers (namely Polybius (2nd century BCE) and Posidonius (c. 135 BCE – c. 51 BCE), the work of Pytheas on the Celts and early Germans influenced scores of future geographers, historians and ethnographers.

An early Germanic people known as the Bastarnae were identified by Roman authors and were allegedly the first to reach the Graeco-Roman world, living in the area north of the Danube's mouth in the Black Sea. They resided primarily in the territory east of the Carpathian Mountains between the Dniester River valley and the delta of the Danube in what is now the Ukraine, Moldova and Romania and are considered the easternmost of the Germanic tribes. The Bastarnae are mentioned in historical sources going back as far as the 3rd century BCE all the way through the 4th century CE. In 201–202 BCE, the Macedonians under the leadership of King Philip V, conscripted the Bastarnae as soldiers to fight against the Romans in the Second Macedonian War. They remained a presence in that area until late in the Roman empire while some settled on Peuce Island at the mouth of the Danube on the Black Sea which is why the name Peucini is also associated with the Bastarnae. King Perseus enlisted the service of the Bastarnae in 171–168 BCE to fight the Third Macedonian War. By 29 BCE, they were subdued by the Romans and those that remained began merging with various tribes of Goths into the second century CE.

Sometime in CE 250, the Gothic king Kniva employed the assistance of the Bastarnae, Carpi, various Goths, and the Taifali when he eventually laid siege to Philippopolis; he followed this victory up with another on the marshy terrain at Abrittus, a battle which cost the life of a Roman emperor and inaugurated a series of consecutive barbarian invasions of the northern Balkans and Asia Minor. Historian Thomas Burns references the Bastarnae but only as an aside from the Latin poet Claudian, claiming that they were among "the oldest of the various Scythian people". Burns further elaborates in stating that there are no "specific references" to the Bastarnae and that remarks about them by Claudian and later third century writers "must give us pause" for the mention of such people might merely have been a "convenient poetic device." Historian Peter Heather disagrees with this position and identifies the Bastarnae as one of the Germanic tribes and asserts that they once "dominated substantial tracts of territory at the mouth of the Danube." Along similar lines, the late classical scholar, Theodor Mommsen, recognized the Bastarnae and placed them in the geographic regions of Moldavia and Bessarabia during the reign of Tiberius. This is the same region where Tacitus placed them. Another historian of antiquity, J. B. Bury, counted the Bastarnae along with the Goths, Vandals, Gepids, Burgundians, Lombards, Rugians, Heruls and Sciri among the East Germanic peoples. Sometime during the 4th or 5th century CE, the Bastarnae were defeated by the Huns, ending their regional domination.

Late in the 2nd century BCE, Roman sources recount the migrating Germanic people of Gaul, Italy and Hispania who invaded areas considered part of Imperial Rome. Unsurprisingly, this cultural confrontation resulted in war between the Roman Republic and the Germanic tribes; particularly those of the Roman Consul under Gaius Marius. The Cimbri crossed into Noricum (Austria) in 113 BCE looking for food and usable land when they confronted and defeated a Roman army. A combined force of Cimbri and Teutoni squared off against additional armies from Rome in 109 and 105 BCE, vanquishing them in the process. Their further incursions into Roman Italy were thrust back in 101 BCE at Vercellae by the Roman army. These earlier invasions were written up by Caesar and others as presaging of a Northern danger for the Roman Republic, a danger that should be controlled.

Julius Caesar describes the "Germani" and their customs in his "Commentarii de Bello Gallico", though it is still a matter of debate if he refers to Northern Celtic tribes or clearly identified Germanic tribes.

[The Germani] have neither Druids to preside over sacred offices, nor do they pay great regard to sacrifices. They rank in the number of the gods those alone whom they behold, and by whose instrumentality they are obviously benefited, namely, the sun, fire, and the moon; they have not heard of the other deities even by report. Their whole life is occupied in hunting and in the pursuits of the military art; from childhood they devote themselves to fatigue and hardships. Those who have remained chaste for the longest time, receive the greatest commendation among their people; they think that by this the growth is promoted, by this the physical powers are increased and the sinews are strengthened. And to have had knowledge of a woman before the twentieth year they reckon among the most disgraceful acts; of which matter there is no concealment, because they bathe promiscuously in the rivers and [only] use skins or small cloaks of deer's hides, a large portion of the body being in consequence naked.

They do not pay much attention to agriculture, and a large portion of their food consists in milk, cheese, and flesh; nor has any one a fixed quantity of land or his own individual limits; but the magistrates and the leading men each year apportion to the tribes and families, who have united together, as much land as, and in the place in which, they think proper, and the year after compel them to remove elsewhere. For this enactment they advance many reasons-lest seduced by long-continued custom, they may exchange their ardor in the waging of war for agriculture; lest they may be anxious to acquire extensive estates, and the more powerful drive the weaker from their possessions; lest they construct their houses with too great a desire to avoid cold and heat; lest the desire of wealth spring up, from which cause divisions and discords arise; and that they may keep the common people in a contented state of mind, when each sees his own means placed on an equality with [those of] the most powerful.

Tacitus described the Germanic people as ethnically uniform or "unmixed" with "a distinct character" and he even generalized them by claiming that "a family likeness pervades the whole." He also reported that their eyes were "stern and blue" and they had "ruddy hair" with "large bodies" that rendered them capable of "powerful exertions." This image portrayed them as a fearsome people deserving Rome's attention. Caesar was wary of these barbaric people of "Germania" and invoked the threat of expansions such as that by Ariovistus' Suebi as justification for his brutal campaigns to annex Gaul to Rome in 58–51 BCE.

An intense Roman militarization, greater than ever before, was begun under Caesar to deal with the barbarian tribes along the frontier — particularly since he feared that the Celtic Gauls between Rome and the Germanic people would not be able to defend themselves. One major Celtic people who were forced from their homeland in modern southwest Germany and Bohemia were the Boii, a migration which had major impacts on Rome and many other peoples. Later, Caesar's attention in 58 BCE was drawn to the movements of the Boii's old neighbours the Helvetii, another population group forced into Gaul from the direction of modern southwest Germany and western Switzerland. When the Gaulish Arverni and Sequani elicited assistance from the Germanic Suebi (who came to them from east of the Rhine into Gaul) against their Aedui enemies in 71 BCE, the Suebi essentially remained "in situ" and were able to expand further into the territory along the periphery of the Roman frontier. Meanwhile, Celtic culture and influence in Gaul began to wane during the first century BCE as a result.

Roman expansion along the Rhine and Danube rivers resulted in the incorporation of many indigenous Celtic societies into the Roman Empire. Lands to the north and east of the Rhine emerge in the Roman records under the name "Germania". Population groups from this area had a complex relationship with Rome; sometimes the peoples of "Germania" were at war with Rome, but at times they established trade relations, symbiotic military alliances, and cultural exchanges with one another. Nevertheless, the Romans made concerted efforts to divide the Germanic tribes when the opportunity presented itself, encouraging intertribal rivalry so as to diminish the threat of an otherwise formidable enemy. Over the following centuries, the Romans sometimes intervened, but often took advantage as their neighbors slaughtered one another using Roman-influenced techniques of war. More instances of "Germani" fighting "Germani" appear in the works of Tacitus than between Romans and "Germani". But it was Caesar's wars against the Germanic people that helped establish and solidify the use of the term "Germania". The initial purpose of the Roman military campaigns was to protect Trans-Alpine Gaul from further incursions of the Germanic tribes by controlling the area between the Rhine and the Elbe.

In the Augustean period there was—as a result of Roman activity as far as the Elbe River—a first definition of the "Germania magna" from the Rhine and Danube rivers in the West and South to the Vistula and the Baltic Sea in the East and North. In 9 CE, a revolt of their Germanic subjects headed by Arminius resulted in a decisive defeat of Publius Quinctilius Varus and the destruction of three Roman legions in a surprise attack at the Battle of the Teutoburg Forest), which caused withdrawal of the Roman frontier to the Rhine. Occupying Germany had proven costly and Arminius' attack helped bring about the end of 28 years of Roman campaigning across the North European plains. Both Arminius and another contemporary Germanic warrior king named Maroboduus, attempted to rule these warrior-based peoples in autocratic fashion but were deposed or outright killed through the treachery of other warrior-nobles, who strove for their own glory. At the end of the 1st century, two provinces west of the Rhine called Germania inferior and Germania superior were established by the Emperor Domitian, having previously been military districts, "so as to separate this more militarized zone from the civilian populations farther west and south". Important medieval cities like Aachen, Cologne, Trier, Mainz, Worms and Speyer were part of these two "militarized" Roman provinces.

The "Germania" by Gaius Cornelius Tacitus, an ethnographic work on the diverse group of Germanic tribes outside of the Roman Empire, is our most important source on the Germanic peoples of the 1st century. Germanic expansions during early Roman times are known only generally, but it is clear that the forebears of the Goths were settled on the southern Baltic shore by 100 CE. According to historian Thomas Burns, major hostilities between the external Germanic peoples of the north and Rome did not commence in "earnest" until the reign of Trajan (CE 98—117), who used the "full weight of Roman might" to attack the Dacians.

In the absence of large-scale political unification, such as that imposed forcibly by the Romans upon the peoples of Italy, the various tribes remained free, led by their own hereditary or chosen leaders. Once Rome faced significant threats on its borders, some of the Germanic tribes who once guarded its periphery chose solace within the Roman empire itself, implying that enough assimilation and cross-cultural pollination had occurred for their societies not only to cooperate, but to live together in some cases. The 4th century Gothic Tervingi are most famous among scholars of classical Rome and pre-modern Europe because the majority of them sought asylum inside the heart of the Roman Empire in 376 CE.

By the middle to late second century CE, migrating Germanic tribes like the Marcomanni and Quadi pushed their way to the Roman frontier along the Danube corridor, movements of people which resulted in conflicts known as the Marcomannic Wars; these conflicts ended in approximately CE 180. Not long thereafter, larger confederations of Germanic people appeared, groups led by tribal leaders acting as would-be kings. The first of these conglomerations mentioned in the historical sources were the Alamanni (a term meaning "all men") who appear in Roman texts sometime in the 3rd century CE. This change indicated that the tribalism of the Germanic people was being abandoned for consolidated rule. Meanwhile, Rome adapted itself due to the arrival of the Germanic tribes. Emperor Severus Alexander was killed by his own soldiers in CE 235 for example (for negotiating peace with the tribes of "Germania" through diplomacy and bribery against the wishes of his men) and the general Maximin elected in his place. Maximin was himself not Roman but was ethnically the child of a Germanic Alan and a Goth. Military expediency trumped aristocratic privilege when it came to securing the Empire and a series of professional military emperors followed as a result.

Around CE 238, the Goths make their first clear impact on Roman history, having moved from the Baltic sea to the area of the modern Ukraine. And sometime in CE 251, they defeated a Roman army in the Balkans, killing the emperor Decius in the process. Close to the same time that the Goths were fighting the Romans in the Baltics, there is also the first mention of the Franks around CE 250. Perennial internal conflicts among several successive emperors of both the eastern and western Empire during the 4th century CE resulted in civil wars and damaged the overall quality of the Roman army; the fighting also depleted the elite from within their officer corps. To compensate for their losses the Romans recruited inferior untried Roman civilians and sought replacements from across the frontier region by militarily proficient barbarian troops, a development which further strengthened the position of the Germanic peoples. Attempting to control the periphery of the Roman empire meant finding innovative ways of dealing with the Germanic people, so the Romans enlisted them as "foederati" (federates) and by the late fourth century, the majority of the Roman military was made up of Germanic warriors. Federating whole tribes of Germanic people into the Empire marked a whole new phase of encroachment and facilitated the fragmentation of Rome from within its own borders.

Among the Romans, the Germanic presence in the military was so extensive for example, that the word "barbarus" became a synonym for "soldier" and the imperial budget of the military was known as the "ficus barbarus". Barbarians (Germanics) composed the mobile army of emperor Constantine with many of them, particularly the more organized ones like the Franks and Alamanni, reaching levels of high command. An example of such prominence shows in the fact that in CE 350 the Frankish general Silvanus was the high military commander of Gaul. Warriors and leaders among the Germanic peoples had an advantage over their Roman counterparts as they knew and could dexterously traverse both worlds, whereas the Romans despised barbarian culture and customs and were unable to secure trust amid the Germanic soldiers on their payrolls. In this way, the ethnic and regional ties within the evolving bureaucratic Roman-Germanic world began to favor the barbarians.

Roman Britannia was contemporaneously under constant threat during the 3rd and 4th centuries CE by northern Picts as well as the Germanic Saxons who sailed from north of Gaul to the eastern coast of the British Isles. Late in CE 367, the Roman garrisons in Britannia collapsed as the Germanic barbarians poured into the region from all directions. Attempting to permanently reestablish control on Britannia, the emperor Valentinian sent an experienced Roman commander who was able to beat the invaders back after a year-long war and gain control of Londonium, but it was a Pyrrhic victory, for the Germanic invaders had burned down standing settlements, ravaged cities on the isles, interrupted trade and annihilated entire Roman garrisons. By the middle of the 5th century, the Picts, Scots and Anglo-Saxons began to dominate the once Roman Britannia.

During the fourth and fifth centuries CE Roman emperors did their best to stave off the advance of the Germanic tribes. While the rulers in the Eastern Empire were able to endure the frequent clashes without serious consequences to their territorial dominion, this was not the case in the Western Empire. For upwards of two centuries, the Roman emperors fought and confined the Germanic tribes to Rhine-Danube frontier and in far-away Britain, but all that changed in CE 378 when the Visigoths destroyed as much as two-thirds of the Roman army of the East under emperor Valens. Roman historian Ammianus Marcellinus referred to the damage inflicted by the Germanic tribes at Adrianople as an "irreparable disaster" and ended his account of Roman history with this battle. Subsequent historians like Sir Edward Gibbon (among others) ascribe a similar significance to this event and call the Battle of Adrianople a watershed moment between the ancient world and the medieval one that followed; for not only did this battle reveal Rome's weakness to the Germanic tribes and inspire them accordingly, never again were they to leave Roman soil. Evidence of the trauma suffered at the hands of the ransacking Visigoths shows up in the writings of the former bishop of Milan, Ambrose, who wrote about melting down golden church plates early in his episcopate so as to help the victims of the calamity at Adrianople.

Before considering the later migration of various Germanic peoples in the 5th century, it is worth noting that the first recorded great migration of a Germanic tribe occurred sometime at the end of the 2nd century when the Goths left the lower Vistula for the shores of the Black Sea. For the next couple hundred years, the restless Goths were a menace to the Roman Empire. Between the 2nd and 4th centuries the Goths slowly filtered deeper into the south and eastwards, making their way to what is now Kiev in Ukraine and pressuring Rome in the process. The arrival of the nomadic Huns along the Black Sea corridor in CE 375 further accelerated the Goth's exodus across the Roman border. Germanic people from the northern coasts of Europe had been making their way into Britain for several centuries before the larger-scale incursions took place.

By the 5th century CE, the Western Roman Empire was losing military strength and political cohesion; numerous Germanic peoples, under pressure from population growth and invading Asian groups, began migrating en masse in far and diverse directions, taking them to Great Britain and far south through present day Continental Europe to the Mediterranean and northern Africa. Over time, this wandering meant intrusions into other tribal territories, and the ensuing wars for land escalated with the dwindling amount of unoccupied territory. Roaming tribes of Germanic people then began staking out permanent homes as a means of protection. Much of this resulted in fixed settlements from which many, under a powerful leader, expanded outwards. Ostrogoths, Visigoths, and Lombards made their way into Italy; Vandals, Burgundians, Franks, and Visigoths conquered much of Gaul; Vandals and Visigoths also pushed into Spain; Vandals additionally made it into North Africa; the Alamanni established a strong presence in the middle Rhine and Alps. In Denmark the Jutes merged with the Danes, in Sweden the Geats and Gutes merged with the Swedes. In England, the Angles merged with the Saxons and other groups (notably the Jutes), as well as absorbing some natives, to form the Anglo-Saxons (later known as the English). Essentially Roman civilization was overrun by these variants of Germanic peoples during the 5th century.

A direct result of the Roman retreat was the disappearance of imported products like ceramics and coins, and a return to virtually unchanged local Iron Age production methods. According to recent views this has caused confusion for decades, and theories assuming the total abandonment of the coastal regions to account for an archaeological time gap that never existed have been renounced. Instead, it has been confirmed that the Frisian graves had been used without interruption between the 4th and 9th centuries and that inhabited areas show continuity with the Roman period in revealing coins, jewellery and ceramics of the 5th century. Also, people continued to live in the same three-aisled farmhouse, while to the east completely new types of buildings arose. More to the south in Belgium, archaeological evidence from this period indicates immigration from the north.

Some of the Germanic tribes are frequently credited in popular depictions of the decline of the Roman Empire in the 5th century. Many historians and archaeologists have since the 1950s shifted their interpretations in such a way that the Germanic peoples are no longer seen as "invading" a decaying empire but as being "co-opted" into helping defend territory the central government could no longer adequately administer. Germanic tribes nonetheless fought against Roman dominance when necessary. When the Roman Empire refused to allow the Visigoths to settle in Noricum for instance, they responded by sacking Rome in CE 410 under the leadership of Alaric I. Oddly enough, Alaric I did not see his imposition in Rome as an attack against the Roman Empire per se but as an attempt to gain a favorable position within its borders, particularly since the Visigoths held the Empire in high regard.

Alaric certainly had no intentions to destroy the great city which was symbolic of Roman power, but he needed to pay his army and the spoils of the city not only afforded the ability to do that, its wealth made him "the richest general in the empire." For the next year, Alaric extracted vast sums from the city; this included 5,000 pounds of gold, 30,000 pounds of silver, 5,000 pounds of oriental pepper, gilded statues from the Forum, and even the one-ton solid silver dome which Constantine once placed over the baptismal basin next to the Lateran basilica. Not only was Alaric able to bleed Rome, he also established a Gothic confederation consisting of Theruingian and Greuthungic peoples, and he played the eastern and western Roman Empires off against one another for his benefit.

At about the same time Alaric was sacking the Empire's capital, there was a Roman exodus from the British Isles, a departure which provided the Germanic Angles and Saxons the opportunity to occupy and control the eastern coastlands of Britain, the southern regions of Sussex, and move into the valley of the Thames. While Germanic tribes overran the once western Roman provinces, they also continued to strive for regional ascendancy closer to Rome's center; meanwhile the threat along the periphery from the Huns created additional difficulties for the Empire.

Individuals and small groups from Germanic tribes had long been recruited from the territories beyond the "limes" (i.e., the regions just outside the Roman Empire), and some of them had risen high in the command structure of the army. The Rhine and Danube provided the bulk of geographic separation for the Roman "limes". On one side of the "limes" stood 'Latin' Europe, law, Roman order, prosperous trading markets, towns and everything that constituted modern civilization for that era; while on the other side stood barbarism, technical backwardness, illiteracy and a tribal society of fierce warriors. Then the Empire recruited entire tribal groups under their native leaders as military officers. Historian Evangelos Chrysos argues the implications concerning the recruitment of the barbarians into the Roman army during the migration period were enormous and relates that:it offered them experience of how the imperial army was organized, how the government arranged the military and functional logistics of their involvement as soldiers or officers and how it administered their practical life, how the professional expertise and the social values of the individual soldier were cultivated in the camp and on the battlefield, how the ideas about the state and its objectives were to be implemented by men in uniform, how the Empire was composed and how it functioned at an administrative level. This knowledge of and experience with the Romans opened to individual members of the "gentes" a path which, once taken, would lead them to more or less substantial affiliation or even solidarity with the Roman world. To take an example from the economic sphere: The service in the Roman army introduced the individual or corporate members into the monetary system of the Empire since quite a substantial part of their salary was paid to them in cash. With money in their hands the "guests" were by necessity exposed to the possibility of taking part in the economic system, of becoming accustomed to the rules of the wide market, of absorbing the messages of or reacting to the imperial propaganda passed to the citizens through the legends on the coins. In addition the goods offered in the markets influenced and transformed the newcomers' food and aesthetic tastes and their cultural horizon. Furthermore Roman "civilitas" was an attractive goal for every individual wishing to succeed in his social advancement. Assisting with defense eventually shifted into administration and then outright rule, as Roman government passed into the hands of Germanic leaders. Odoacer (who commanded the German mercenaries in Italy) deposed Romulus Augustulus, the last emperor of the West in CE 476. Odoacer ruled from Rome and Ravenna, restored the Colosseum and assigned seats to senatorial dignitaries as part of the process of consolidating his rule. The presence of successor states controlled by a nobility from one of the Germanic tribes is evident in the 6th century – even in Italy, the former heart of the Empire, where Odoacer was followed by Theodoric the Great, king of the Ostrogoths, who was regarded by Roman citizens and Gothic settlers alike as legitimate successor to the rule of Rome and Italy. Theodoric ruled from CE 493–526, twice as long as his predecessor, and his rule is evidenced by an abundance of documents. Under the Ostrogoths a considerable degree of Roman and Germanic cultural and political fusion was achieved. Germanic kings worked in-tandem with Roman administrators to the extent possible to help ensure a smooth transition and to facilitate the profitable administration of once Roman lands. Slowly but surely, the distinction between Germanic rulers and Roman subjects faded, followed by varying degrees of "cultural assimilation" which included the adoption of the Gothic language by some of the indigenous people of the former Roman Empire but this was certainly not ubiquitous as Gothic identity still remained distinctive. Theodoric may have tried too hard to accommodate the various people under his dominion; indulging "Romans and Goths, Catholics and Arians, Latin and barbarian culture" resulted in the eventual failure of the Ostrogothic reign and the subsequent "end of Italy as the heartland of late antiquity."

According to noted historian Herwig Wolfram, the Germanic peoples did not and could not "conquer the more advanced Roman world" nor were they able to "restore it as a political and economic entity"; instead, he asserts that the empire's "universalism" was replaced by "tribal particularism" which gave way to "regional patriotism". Nonetheless, the entry of the Germanic tribes deep into the heart of Europe and the subsequent collapse of the western Roman Empire resulted in a "massive disruption" to long established communication networks, a system that had in many ways "bound much of the continent together for centuries." Trade networks and routes shifted accordingly, Germanic kingdoms and peoples established boundaries and it was not until the appearance of the Arabs in Iberia and into Anatolia that Europeans began reestablishing their networks to deal with a new threat.

The transition of the Migration period to the Middle Ages proper took place over the course of the second half of the 1st millennium. It was marked by the Christianization of the Germanic peoples and the formation of stable kingdoms replacing the mostly tribal structures of the Migration period. Some of this stability is discernible in the fact that the Pope recognized Theodoric's reign when the Germanic conqueror entered Rome in CE 500, despite that Theodoric was a known practitioner of Arianism, a faith which the Council of Nicaea condemned in CE 325. Theodoric's Germanic subjects and administrators from the Roman Catholic Church cooperated in serving him, helping establish a codified system of laws and ordinances which facilitated the integration of the Gothic peoples into a burgeoning empire, solidifying their place as they appropriated a Roman identity of sorts. The foundations laid by the Empire enabled the successor Germanic kingdoms to maintain a familiar structure and their success can be seen as part of the lasting triumph of Rome.
In continental Europe, this Germanic evolution saw the rise of Francia in the Merovingian period under the rule of Clovis I who had deposed the last emperor of Gaul, eclipsing lesser kingdoms such as Alemannia. The Merovingians controlled most of Gaul under Clovis, who, through conversion to Christianity, allied himself with the Gallo-Romans. While the Merovingians were checked by the armies of the Ostrogoth Theodoric, they remained the most powerful kingdom in Western Europe and the intermixing of their people with the Romans through marriage rendered the Frankish people less a Germanic tribe and more a "European people" in a manner of speaking. Most of Gaul was under Merovingian control as was part of Italy and their overlordship extended into Germany where they reigned over the Thuringians, Alamans, and Bavarians. Evidence also exists that they may have even had suzerainty over south-east England. Frankish historian Gregory of Tours relates that Clovis converted to Christianity partly as a result of his wife's urging and even more so due to having won a desperate battle after calling out to Christ. According to Gregory, this conversion was sincere but it also proved politically expedient as Clovis used his new faith as a means to consolidate his political power by Christianizing his army. Against Germanic tradition, each of the four sons of Clovis attempted to secure power in different cities but their inability to prove themselves on the battlefield and intrigue against one another led the Visigoths back to electing their leadership.

When Merovingian rule eventually weakened, they were supplanted by another powerful Frankish family, the Carolingians, a dynastic order which produced Charles Martel, and Charlemagne. The coronation of Charlemagne as emperor by Pope Leo III in Rome on Christmas Day, CE 800 represented a shift in the power structure from the south to the north. Frankish power ultimately laid the foundations for the modern nations of Germany and France. For historians, Charlemagne's appearance in the historical chronicle of Europe also marks a transition where the voice of the north appears in its own vernacular thanks to the spread of Christianity, after which the northerners began writing in Latin, Germanic, and Celtic; whereas before, the Germanic people were only known through Roman or Greek sources.

In England, the Germanic Anglo-Saxon tribes reigned over the south of Great Britain from approximately 519 to the tenth century until the Wessex hegemony became the nucleus for the unification of England. Scandinavia was in the Vendel period and eventually entered the Viking Age, with expansion to Britain, Ireland and Iceland in the west and as far as Russia and Greece in the east. By CE 900 the Vikings secured for themselves a foothold on Frankish soil along the Lower Seine River valley in what is now France that became known as Normandy. Hence they became the Normans. They established the Duchy of Normandy, a territorial acquisition which provided them the opportunity to expand beyond Normandy into Anglo-Saxon England. The subsequent Norman Conquest which followed in CE 1066 wrought immense changes to life in England as their new Scandinavian masters altered their government, lordship, public holdings, culture and DNA pool permanently.

The various Germanic tribal cultures began their transformation into the larger nations of later history, English, Norse and German, and in the case of Burgundy, Lombardy and Normandy blending into a Romano-Germanic culture. Many of these later nation states started originally as "client buffer states" for the Roman Empire so as to protect it from its enemies further away. Eventually they carved out their own unique historical paths.

The interactions of the migrating Germanic peoples and the deteriorating Roman empire formed the basis of the history and society of most of Western Europe from the Early Middle Ages and up to the present day. By the middle ages, Germanic tribes were no longer seen as a single ethnic grouping, and instead we can only speak of peoples who speak Germanic languages, though these are no longer mutually intelligible.

The territory of modern Germany was divided between Germanic- and Celtic-speaking groups in the last centuries BCE. The parts south of the Germanic "limes" came under Latin influence in the early centuries CE but were swiftly conquered by Germanic groups such as the Alemanni after the fall of the Western Roman Empire. The Germanic tribes of the Migration period had settled down by the Early Middle Ages, the latest series of movements out of Scandinavia taking place during the Viking Age.

The Goths and Vandals were linguistically assimilated to their Latin (Romance) substrate populations. Evidence exists that for 2nd- and 3rd-century Goths as well as for 4th- and 5th-century Lombards that significant population displacement throughout Roman-occupied Europe occurred. This quite likely contributed to their linguistic assimilation. An exception to this pattern was the Crimean Goths, who preserved their dialect into the 18th century). Burgundians and Lombards were assimilated into both Latin (French and Italian) and Germanic (German-speaking Swiss) populations.

The Viking Age Norse people split into an Old East Norse and an Old West Norse group, which further separated into Icelanders, Faroese and Norwegians on one hand and Swedes and Danes on the other. In Scandinavia, there is a long history of assimilation of and by the Sami people and Finnic peoples, namely Finns and Karelians. In today's usage, the term "Nordic peoples" refers to the ethnic groups in all of the Nordic countries. In Great Britain, Germanic people coalesced into the Anglo-Saxon (or English) people between the 8th and 10th centuries.

The various Germanic peoples of the Migrations period eventually spread out over a vast expanse stretching from contemporary European Russia to Iceland and from Norway to North Africa. The migrants had varying impacts in different regions. In many cases, the newcomers set themselves up as overlords of the pre-existing population. Over time, such groups underwent ethnogenesis, resulting in the creation of new cultural and ethnic identities (e.g., the Franks and Gallo-Romans becoming the French). Thus, many of the descendants of the ancient Germanic peoples do not speak Germanic languages, as they were to a greater or lesser degree assimilated into the cosmopolitan, literate culture of the Roman world. Even where the descendants of Germanic peoples maintained greater continuity with their common ancestors, significant cultural and linguistic differences arose over time, as is strikingly illustrated by the different identities of Christianized Saxon subjects of the Carolingian Empire and pagan Scandinavian Vikings.

More broadly, early Medieval Germanic peoples were often assimilated into the "walha" substrate cultures of their subject populations. Thus, the Burgundians of Burgundy, the Vandals of Northern Africa, and the Visigoths of France and Iberia, lost some Germanic identity and became part of Romano-Germanic Europe. For the Germanic Visigoths in particular, they had intimate contact with Rome for two centuries before their domination of the Iberian Peninsula and were accordingly permeated by Roman culture. Likewise, the Franks of Western Francia form part of the ancestry of the French people.

The Anglo-Saxon settlement of Britain resulted in Anglo-Saxon (or English) displacement and cultural assimilation of the indigenous culture, the Brythonic-speaking British culture, causing the foundation of a new kingdom, England. As in what became England, indigenous Brythonic Celtic culture in some of the south-eastern parts of what became Scotland (approximately the Lothian and Borders region) and areas of what became the Northwest of England (the kingdoms of Rheged, Elmet, etc.) succumbed to Germanic influence c.600—800, due to the extension of overlordship and settlement from the Anglo-Saxon areas to the south. Cultural and linguistic assimilation occurred less frequently between the Germanic Anglo-Saxons and the indigenous people who resided in the Roman dominated areas of England, particularly in the regions that remained previously unconquered. Anglo-Saxons occupied Somerset, the Severn valley, and Lancaster by c. 700 where they remained dominant. Over time, the Anglo-Saxons, with their distinct culture and language, displaced much of the extant Roman influence of old.
On the European continent, East Francia developed into the Kingdom of Germany, which became the most important part of the Holy Roman Empire proclaimed by Otto I in 962 AD.

Perhaps the final incursions by Germanic people which altered in some ways the ethnographic map of Europe was made by the Vikings. Between the 8th and 11th centuries, these Scandinavian/Norse traders and pirates ravaged most of north and central Europe as well as the British Isles, spreading eastwards as far as Russia and into Byzantium. While their initial exploits were generally raids for plunder, they later settled and mixed with the indigenous people of Europe, which resulted in both conquest and colonization. Other examples of assimilation during the Viking Age include the Norse, who settled in Normandy along the French Atlantic coast, and the societal elite in medieval Russia; among whom, many were the descendants of Slavified Norsemen (a theory contested by some Slavic scholars in the former Soviet Union, who named it the "Normanist theory"). Known for their unique ships, there is evidence of the Viking presence all over mainland Europe, as no lands with navigable waters or coastlines escaped their pillaging. Vast territories in eastern England were overrun and occupied by the Vikings and the Danish King, Canute, eventually succeeded to the English crown. Archeological remains on North America even exist which give evidence to the dynamism and territorial ambitions of these Germanic warriors.

Common elements of Germanic society can be deduced both from Roman historiography and comparative evidence from the Early Medieval period. A main element uniting Germanic societies was kingship, in origin a sacral institution combining the functions of military leader, high priest, lawmaker and judge. Germanic monarchy was elective; the king was elected by the free men from among eligible candidates of a family (OE "cynn") tracing their ancestry to the tribe's divine or semi-divine founder.

To a large degree, many of the extant legal records from the Germanic tribes seem to revolve around property transactions. In early Germanic society, the free men of property each ruled their own estate and were subject to the king directly, without any intermediate hierarchy as in later feudalism. Free men without landed property could swear fealty to a man of property who as their lord would then be responsible for their upkeep, including generous feasts and gifts. This system of sworn retainers was central to early Germanic society, and the loyalty of the retainer to his lord generally replaced his family ties.

Early Germanic law reflects a hierarchy of worth within the society of free men, reflected in the differences in weregild. Among the Anglo-Saxons, a regular free man (a "ceorl") had a weregild of 200 shillings (i.e. solidi or gold pieces), classified as a "twyhyndeman" "200-man" for this reason, while a nobleman commanded a fee of six times that amount ("twelfhyndeman" "1200-man"). Similarly, among the Alamanni the basic weregild for a free man was 200 shillings, and the amount could be doubled or tripled according to the man's rank. Unfree serfs did not command a weregild, and the recompense paid in the event of their death was merely for material damage, 15 shillings in the case of the Alamanni, increased to 40 or 50 if the victim had been a skilled artisan.

The social hierarchy is not only reflected in the weregild due in the case of the violent or accidental death of a man, but also in differences in fines for lesser crimes. Thus the fines for insults, injury, burglary or damage to property differ depending on the rank of the injured party. They do not usually depend on the rank of the guilty party, although there are some exceptions associated with royal privilege.

Free women did not have a political station of their own but inherited the rank of their father if unmarried, or their husband if married. The weregild or recompense due for the killing or injuring of a woman is notably set at twice that of a man of the same rank in Alemannic law.

All freemen had the right to participate in general assemblies or "things", where disputes between freemen were addressed according to customary law. The king was bound to uphold ancestral law, but was at the same time the source for new laws for cases not addressed in previous tradition. This aspect was the reason for the creation of the various Germanic law codes by the kings following their conversion to Christianity: besides recording inherited tribal law, these codes have the purpose of settling the position of the church and Christian clergy within society, usually setting the weregilds of the members of the clerical hierarchy parallel to that of the existing hierarchy of nobility, with the position of an archbishop mirroring that of the king.

In the case of a suspected crime, the accused could avoid punishment by presenting a fixed number of free men (their number depending on the severity of the crime) prepared to swear an oath on his innocence. Failing this, he could prove his innocence in a trial by combat. Corporal or capital punishment for free men does not figure in the Germanic law codes, and banishment appears to be the most severe penalty issued officially. This reflects that Germanic tribal law did not have the scope of exacting revenge, which was left to the judgement of the family of the victim, but to settle damages as fairly as possible once an involved party decided to bring a dispute before the assembly. A fascinating component of early Germanic laws were the varying distinctions concerning the physical body, as each body part had a personal injury value and corresponding legal claims for personal injury viewed matters like gender, rank and status as a secondary interest when deliberating cases.

Generally speaking, Roman legal codes eventually provided the model for many Germanic laws and they were fixed in writing along with Germanic legal customs. Traditional Germanic society was gradually replaced by the system of estates and feudalism characteristic of the High Middle Ages in both the Holy Roman Empire and Anglo-Norman England in the 11th to 12th centuries, to some extent under the influence of Roman law as an indirect result of Christianisation, but also because political structures had grown too large for the flat hierarchy of a tribal society. The same effect of political centralization took hold in Scandinavia slightly later, in the 12th to 13th century (Age of the Sturlungs, Consolidation of Sweden, Civil war era in Norway), by the end of the 14th century culminating in the giant Kalmar Union. Elements of tribal law, notably the wager of battle, nevertheless remained in effect throughout the Middle Ages, in the case of the Holy Roman Empire until the establishment of the Imperial Chamber Court in the early German Renaissance. In the federalist organization of Switzerland, where cantonal structures remained comparatively local, the Germanic thing survived into the 21st century in the form of the "Landsgemeinde", albeit subject to federal law.

Historical records of the Germanic tribes in Germania east of the Rhine and west of the Danube do not begin until quite late in the ancient period, so only the period after 100 BCE can be examined. What is clear is that the Germanic idea of warfare was quite different from the pitched battles fought by Rome and Greece. Instead the Germanic tribes focused on raids. Warfare of varying size however was a distinctive feature of barbarian culture.

The purpose of these was generally not to gain territory, but rather to capture resources and secure prestige. These raids were conducted by irregular troops, often formed along family or village lines, in groups of 10 to about 1,000. Leaders of unusual personal magnetism could gather more soldiers for longer periods, but there was no systematic method of gathering and training men, so the death of a charismatic leader could mean the destruction of an army. Armies also often consisted of more than 50 percent noncombatants, as displaced people would travel with large groups of soldiers, the elderly, women, and children. War leaders who were able to secure ample booty for their retainers were able to grow accordingly by attracting warrior bands from nearby villages.

Large bodies of troops, while figuring prominently in the history books, were the exception rather than the rule of ancient warfare. Thus a typical Germanic force might consist of 100 men with the sole goal of raiding a nearby Germanic or foreign village. Thus, most warfare was at their barbarian neighbors. According to Roman sources, when the Germanic Tribes did fight pitched battles, the infantry often adopted wedge formations, each wedge being led by a clan head. Legitimacy for leaders among the Germans resided in their ability to successfully lead armies to victory. Defeat on the battlefield at the hands of the Romans or other barbarians often meant the end of a ruler and in some cases, being absorbed by "another, victorious confederation."

Though often defeated by the Romans, the Germanic tribes were remembered in Roman records as fierce combatants, whose main downfall was that they failed to join together into a collective fighting force under a unified command, which allowed the Roman Empire to employ a "divide and conquer" strategy against them. On occasions when the Germanic tribes worked together, the results were impressive. Three Roman legions were ambushed and destroyed by an alliance of Germanic tribes headed by Arminius at the Battle of the Teutoburg Forest in 9 CE, the Roman Empire made no further concentrated attempts at conquering Germania beyond the Rhine.

During the 4th and 5th centuries CE, Visigoths and Vandals militarily organized themselves to sufficiently challenge and sack Rome in CE 410 and again in CE 455. Then in CE 476, the last Roman emperor was deposed by a German chieftain, an event which effectively ended Roman predominance in western Europe. Germanic tribes eventually overwhelmed and conquered the ancient world. That military transition was additionally spurred by the arrival of the Vikings from the 8th to 10th centuries, giving rise to modern Europe and medieval warfare.

For an analysis of Germanic tactics versus the Roman empire see: Roman infantry versus Gallic and the Germanic tribes

Weapons used by the Germanic tribes varied. Some of them used axes, throwing javelins, spears, bows and arrows along with swords. Most of the swords used by the Germanic warriors were those captured from Roman soldiers until the 4th century when German blacksmiths began making the best steel in Europe. Body armor was rarely worn and when it was, it was light by comparison to what the Romans employed; only war leaders wore helmets on the battlefield. Commandeering of Roman weaponry was widespread and the acquisition of the superior Roman armaments allowed the Germanic leaders to exert their power in ways not previously available. It also meant fierce inter-Germanic rivalry which constituted the larger power blocks of the Germanic world. Much like their predecessors, the Vikings too used axes, swords, long knives, spears, oblong shields, leather or metal helmets and mail or leather coats for protection; the latter being luxuries most could not afford.

To the greatest extent, Germanic fighting units consisted of infantry who would emerge from cover and attack, but they also utilized skilled cavalrymen at times, something the Visigoths used decisively to aid in their victory at Adrianople. Cavalry warfare was limited in northern Europe due to the lack of suitably large horses for mounted troops. Caesar provided his Germanic armies with Roman mounts to enable them greater mobility and to enhance their fighting efficiency. Unlike their western Celtic neighbors, the use of chariots was not picked up by the early Germans. Notwithstanding the use of an occasional fortified position, the Germanic warriors preferred to fight in the open and normally assumed the offensive rather than fight defensively. Emboldening themselves for fierce attacks, the Germanic warriors would rouse themselves to a high-pitched level of excitement and charge headlong against their enemies, which while effective for ambush operations, lacked in terms of the organizational skill needed for prolonged siege warfare. The berserker mentality employed by the Germanic tribes against Rome was still in effect during the Viking era of the 8th and 9th centuries as they too believed that by summoning their gods and working themselves up, they would possess superhuman strength and be protected during battle. Such resolution led them to believe that dying in such a manner was heroic and would transport the fallen fighter straight into Valhalla where they would be embraced by the warrior maidens known as the Valkyries. The later military development of armored knights and fortified castles was a response in part to the relentless plundering and raiding by the Vikings, which meant that the Germanic tribes who had settled mainland Europe and the British Isles had to adapt themselves so as to combat another Germanic tribe of interlopers.

Traces of the earliest pastoralism of the Germanic peoples appear in central Europe in the form of elaborate cattle burials along the Elbe and Vistula Rivers from around 4000–3000 BCE. These archaeological remnants were left by the Globular Amphora culture who cleared forests for herding cattle and sometime after 3000 BCE began using wheeled carts and plows to cultivate their lands. Central to survival for their assistance in tilling the soil and supplying food, cattle became an economic resource to these early people. Germanic settlements were typically small, rarely containing much more than ten households, often less, and were usually located by clearings in the woods. Settlements remained of a fairly constant size throughout the period. The buildings in these villages varied in form, but normally consisted of farmhouses surrounded by smaller buildings such as granaries and other storage rooms. The universal building material was timber. Cattle and humans usually lived together in the same house.

Although the Germans practiced both agriculture and husbandry, the latter was extremely important both as a source of dairy products and as a basis for wealth and social status, which was measured by the size of an individual's herd. The diet consisted mainly of the products of farming and husbandry and was supplied by hunting to a very modest extent. Barley and wheat were the most common agricultural products and were used for baking a certain flat type of bread as well as brewing beer. Evidence from a Saxon village known as Feddersen Wierde near Cuxhaven, Germany (which existed between BCE 50 to CE 450) shows that the Germanic people cultivated oats and rye, used manure as fertilizer, and that they practiced crop rotation.

The fields were tilled with a light-weight wooden ard, although heavier models also existed in some areas. Common clothing styles are known from the remarkably well-preserved corpses that have been found in former marshes on several locations in Denmark, and included woolen garments and brooches for women and trousers and leather caps for men. Other important small-scale industries were weaving, the manual production of basic pottery and, more rarely, the fabrication of iron tools, especially weapons. The Corded Ware culture and the Funnelbeaker culture (circa. 2900–2300 BCE) of these north and central European peoples coincide one another and provide evidence of how they lived, traded and buried their dead.

After 1300 BCE the societies of Jutland and Northern Germany along with the Celtic people experienced a major revolution in technology during the Late Bronze Age, shaping tools, containers and weapons through the improved techniques of working bronze. Both the sword and the bow and arrow as well as other weaponry proliferate and an arms race of sorts between the tribes ensued as they tried to outpace one another. Trade was taking place to a greater degree and simple gems and amber from the Mediterranean indicate that long-distance exchange of goods was occurring. When the Iron Age (1500—1200 BCE) arrived, the Germanic people showed greater mastery of ironworks than their Celtic contemporaries but they did not have the extensive trade networks during this period that their southern neighbors enjoyed with the Greco-Roman world.

Widening trade between the Germanic tribes and Rome started later following the Empire's wars of conquest when they looked to the Germanic people to supply them with slaves, leather and quality iron. One of the reasons the Romans may have drawn borders along the Rhine, besides the sizable population of Germanic warriors on one side of it, was that the Germanic economy was not robust enough for them to extract much booty nor were they convinced they could acquire sufficient tax revenue from any additional efforts of conquest. Drawing a distinctive line between themselves and Germanic people also incentivized alliances and trade as the Germanic people sought a share of the imperial wealth. Roman coinage was coveted by the Germanic people who preferred silver to gold coins, mostly likely indications that a market economy was developing. Tacitus does mention the presence of a bartering system being observable among the Germanic people, but this was not exclusive, as he also writes of their use of "gold and silver for the purpose of commerce", adding rather sardonically in his text, that what they exchanged was nothing more than "petty merchandise. Such observations from Tacitus aside, fine metalwork, iron and glassware was soon being traded by the Germanic peoples along the coast of the North Sea of Denmark and the Netherlands.

The writings of Tacitus allude to the Germanic peoples being aware of a shared ethnicity, in that, they either knew or believed that they shared a common biological ancestor with one another. Just how pervasive this awareness may have been is certainly debatable, but other factors like language, clothing, ornamentation, hair styles, weapon types, religious practices and shared oral history were likely just as significant in tribal identity for the Germanics. Members of a Germanic tribe told tales about the exploits of heroic founding figures who were more or less mythologized. Village life consisted of free men assembled under a chieftain, all of whom shared common cultural and political traditions. Status among the early Germanic tribes was often gauged by the size of a man's cattle herd or by one's martial prowess.

Before their conversion to Christianity, the Germanic peoples of Europe were made up of several tribes, each functioning as an economic and military unit and sometimes united by a common religious cult. Kinship, especially close kinship, was very important to life within a tribe but generally was not the source of a tribe's identity. In fact, several elements of ancient Germanic life tended to weaken the role of kinship: the importance of the retinues surrounding military chieftains, the ability of strong leaders to unite people who were not closely related, and feuds and other conflicts within a tribe that might lead to permanent divisions. The retinue (often called "comitatus" by scholars, following the practice of ancient Roman writers) consisted of the followers of a chieftain, who depended on the retinue for military and other services and who in return provided for the retinue's needs and divided with them the spoils of battle. This relationship between a chieftain and his followers became the basis for the more complicated feudal system that developed in medieval Europe. A chieftain's retinue might include close relatives, but it was not limited to them. Eventually the rising power of individual chieftains and kings from among the military leadership of Germanic tribes and confederations curtailed and in many ways replaced the power once enjoyed by tribal assemblies. A code of ethics in battle prevailed among the Germanic kin. According to Tacitus, the "greatest disgrace that can befall" a warrior of a clan among the Germanic tribes was the abandonment of their shield during combat, as this almost certainly resulted in social isolation. Within tribal Germanic society, their social hierarchy was linked intrinsically to war and this warrior code maintained the fidelity between chiefs and their young warriors.

Feuds were the standard means for resolving conflicts and regulating behavior. Peace within the tribe was about controlling violence with codes identifying exactly how certain types of feuds were to be settled. Those closely related to a person who had been injured or killed were supposed to exact revenge on or monetary payment from the offender. This duty helped reaffirm the bonds between extended family members. Yet such feuds weakened the tribe as a whole, sometimes leading to the creation of a new tribe as one group separated from the rest. Clans of Germanic people consisted of groupings of about 50 households in total with societal rules for each specific clan. Recent scholarship suggests that, despite the obligation to take part in feuds and other customs involving kinship ties, extended families did not form independent units among the early Germanic peoples. Though most members of a tribe would have been more or less distantly related, common descent was not the main source of a tribe's identity, and extended families were not the main social units within a tribe. Traditional theories have emphasized the supposedly central role in Germanic culture of clans or large groups with common ancestry. But there is little evidence that such clans existed, and they were certainly not an important element of social organization. As historian Alexander C. Murray concludes, "kinship was a crucial factor in all aspects of barbarian activity, but its uses and groupings were fluid, and probably on the whole not long lasting." Internal competition within the factions of a tribe occasionally resulted in internecine warfare which weakened and sometime destroyed a group, as appears to have been the case for the Cherusci tribe during Rome's earlier period.

The most important family relationships among the early Germanic peoples were within the individual household, a fact based on the archaeological evidence from their settlements where the long-houses appeared to be central in their existence. Within the household unit, an individual was equally bound to both the mother and the father's side of the family. Fathers were the main figures of authority, but wives also played an important and respected role. Some Germanic tribes even believed that women possessed magical powers and were feared accordingly. Tacitus describes how, during battles, Germanic warriors were encouraged and cared for by their wives and mothers. He also notes that during times of peace, women did most of the work of managing the household. Along with the children, they apparently did most of the household chores as well. Children were valued, and according to Tacitus, limiting or destroying one's offspring was considered shameful. Mothers apparently breast-fed their own children rather than using nurses. Besides parents and children, a household might include slaves, but slavery was uncommon, and according to Tacitus, slaves normally had households of their own. Their slaves (usually prisoners of war) were most often employed as domestic servants. Polygamy and concubinage were rare but existed, at least among the upper classes. When a certain number of families resided on the same territory, this constituted a village ("Dorf" in German). The overall territory occupied by people from the same tribe was designated in the writings of Tacitus as a "civitas", with each of the individual "civitas" divided into "pagi" (or cantons), which were made up of several "vici". In cases where the tribes were grouped into larger confederations or a group of kingdoms, the term "pagus" was applied ("Gau" in German). Extensive contact with Rome altered the egalitarian structure of tribal Germanic society. As individuals rose to prominence, a distinction between commoner and nobility developed and with it the previous constructs of folkright shared equally across the tribe was replaced in some cases by privilege. As a result, Germanic society became more stratified. Elites within the Germanic tribes who learned the Roman system and emulated the way they established dominion were able to gain advantages and exploit them accordingly.

Important changes began taking place by the 4th century CE as Germanic peoples, while still cognizant of their unique clan identities, started forming larger confederations of a similar culture. Gathering around the dominant tribes among them and hearkening to the most charismatic leaders brought the various barbarians tribes closer together. On the surface this change appeared to the Romans as welcome since they preferred to deal with a few strong chiefs to control the populations that they feared across the Rhine and Danube, but it eventually made these Germanic rulers of confederated peoples more and more powerful. While strong, they were still not federated to one another since they possessed no sense of "pan-Germanic solidarity", but this started to change noticeably by the 5th century CE at Rome's expense.

Based on the writings of Tacitus, most of the barbarians were content with one wife, which indicates a general trend towards monogamy. For those higher within their social hierarchy however, polygamy was sometimes "solicited on account of their rank". Of note, Tacitus observed that "the wife does not bring a dowry to her husband, but receives one from him" and wedding gifts related to a marriage consisted of things like oxen, saddles and various armaments. Revealing the warlike nature of their society, Tacitus also reported that wives came to their husbands "as a partner in toils and dangers; to suffer and to dare equally with him, in peace and in war."

The age at first marriage among ancient Germanic tribes, according to Tacitus, was late for women compared to Roman women:
The youths partake late of the pleasures of love, and hence pass the age of puberty unexhausted: nor are the virgins hurried into marriage; the same maturity, the same full growth is required: the sexes unite equally matched and robust; and the children inherit the vigor of their parents.
For Germanic women of later antiquity, marriage obviously had its appeal since it offered greater security and better placement in their social hierarchy. Where Aristotle had set the prime of life at 37 years for men and 18 for women, the Visigothic Code of law in the 7th century placed the prime of life at twenty years for both men and women, after which both presumably married. Thus it can be presumed that ancient Germanic brides were on average about twenty and were roughly the same age as their husbands.
Tacitus, however, had never visited the German-speaking lands and most of his information on Germania comes from secondary sources. In addition, Anglo-Saxon women, like those of other Germanic tribes, are marked as women from the age of twelve onward, based on archaeological finds, implying that the age of marriage coincided with puberty. Generally, there were two forms of marriage among the Germanic peoples, one involving the participation of the parents and the other, those that did not. Known as "Friedelehe", the latter form consisted of marriage between a free man and a free woman, since marriage between free persons and slaves was forbidden by law. Evidence of Germanic patriarchy is evident later in the 7th century CE Edict of Rothari of the Lombards, which stated that women were not allowed to live of their own freewill and that they had to be subject to a man and if no one else, they were to be "under the power of the king".

For Germanic kings, warrior chieftains, senators and Roman nobility, a certain degree of intermarriage was undertaken to strengthen their ties to one another and to the Empire, making marriage or "connubium" as the Romans connoted the bond, an instrument of politics. Earlier treaty terms in the late 4th century CE had forbidden "foreign" Goths to intermarry with Romans. Some of the marriage attempts of the 6th century CE were deliberately planned for the sake of royal succession. Imperial policy had to be carefully charted between the Roman-Germanic claimants to kingship and the maintenance of Roman imperial administration, as the federated Germanic kings attempted to put their stamp on Roman rule and replace Roman armies with their own warriors. Roman leaders were not oblivious to the clever tactics (intermarriage and offspring) employed by Germanic chieftains and adopted creative treaties to either appease them or temper their ambitions.

Prior to the Middle Ages, Germanic peoples followed what is now referred to as Germanic paganism: "a system of interlocking and closely interrelated religious worldviews and practices rather than as one indivisible religion" and as such consisted of "individual worshippers, family traditions and regional cults within a broadly consistent framework". It was polytheistic in nature, with some underlying similarities to other Indo-Germanic traditions. Despite the unique practices of some tribes, there was a degree of cultural uniformity among the Germanic people concerning religion. Germanic ideology and religious practices were pervaded and colored to a large degree by war, particularly the notion of a heroic death on the battlefield, as this brought the god(s) a "blood sacrifice."

Archaeological findings suggest that the Germanic barbarians practiced some of the same 'spiritual' rituals as the Celts, including human sacrifice, divination, and the belief in spiritual connection with the natural environment around them. Germanic priestesses were feared by the Romans, as these tall women with glaring eyes, wearing flowing white gowns often wielded a knife for sacrificial offerings. Captives might have their throats cut and be bled into giant cauldrons or have their intestines opened up and the entrails thrown to the ground for prophetic readings. Spiritual rituals frequently occurred in consecrated groves or upon islands on lakes where perpetual fires burned.

Many of the deities found in Germanic paganism appeared under similar names across the Germanic peoples, most notably the god known to the Germans as Wodan or Wotan, to the Anglo-Saxons as Woden, and to the Norse as Óðinn, as well as the god Thor – known to the Germans as Donar, to the Anglo-Saxons as Þunor and to the Norse as Þórr. Pagan beliefs amid the Germanic tribes were reported by some of the earlier Roman historians and in the 6th century CE another instance of this appears when the Byzantine historian and poet, Agathias, remarked that the Alamannic religion was "solidly and unsophisticatedly pagan." Christianity had no relevance for the pagan barbarians until their contact and integration with Rome.

While the Germanic peoples were slowly converted to Christianity by varying means, many elements of the pre-Christian culture and indigenous beliefs remained firmly in place after the conversion process, particularly in the more rural and distant regions. Of particular note is the survival of the pagan fascination with the forest in the retention of Christmas tree even today. Many of the Germanic tribes actually revered forests as sacred places and left them unmolested. Conversion to Christianity broke this pagan obsession with protecting the forest in some locations and allowed once migrant tribes to settle in places where they previously refused to cultivate the soil or chop down trees based on religious belief. To that end, the Christianisation of Germanic peoples facilitated the clearing of forests and therewith provided "a broad and stable basis for the medieval economy of Central Europe" by leveraging the vast forest resources available to them. The Ostrogoths, Visigoths, and Vandals were christianized while they were still outside the bounds of the Empire; however, they converted to Arianism rather than Catholicism, and were soon regarded as heretics by Catholics. The one great written remnant of the Gothic language is a translation of the Bible made by Wulfila, the Arian missionary who converted them. Goths, Vandals, and other Germanic peoples often offered political resistance prior to their conversion to Christianity. The Lombards were not converted until after their entrance into the Empire, but received Christianity from Arian Germanic tribes sometime during the 5th century.

Paganism and Christianity were still being practiced across the empire when Constantine died in CE 337, despite his conversion; he did however ban pagan rituals at select religious temples. Sometime between CE 391–392, the barbarian king Theodosius I made an official proclamation which outlawed pagan religions in his region of influence with various successors like Justinian doing likewise. The Franks were converted directly from paganism to Catholicism under the leadership of Clovis in about CE 496 without an intervening time as Arians. Eventually the Gothic tribes turned away from their Arian faith and in CE 589 converted to Catholicism. Several centuries later, Anglo-Saxon and Frankish missionaries and warriors undertook the conversion of their Saxon neighbors. A key event was the felling of Thor's Oak near Fritzlar by Boniface, apostle of the Germans, in CE 723. When Thor failed to strike Boniface dead after the oak hit the ground, the Franks were amazed and began their conversion to the Christian faith.

Eventually for many Germanic tribes, the conversion to Christianity was achieved by armed force, successfully completed by Charlemagne, in a series of campaigns (the Saxon Wars), that also brought Saxon lands into the Frankish empire. Massacres, such as the Bloody Verdict of Verden, where as many as 4,500 people were beheaded according to one of Charlemagne's chroniclers, were a direct result of this policy.

In Scandinavia, Germanic paganism continued to dominate until the 11th century in the form of Norse paganism, when it was gradually replaced by Christianity.

It is suggested by geneticists that the movements of Germanic peoples has had a strong influence upon the modern distribution of the male lineage represented by the Y-DNA haplogroup I1, which is believed to have originated with one man, who lived approximately 4,000 to 6,000 years ago somewhere in Northern Europe, possibly modern Denmark (see Most Recent Common Ancestor for more information). There is evidence of this man's descendants settling in all of the areas that Germanic tribes are recorded as having subsequently invaded or migrated to. Haplogroup I1 is older than Germanic languages, but may have been present among early Germanic speakers. Other male lines likely to have been present during the development and dispersal of Germanic language populations include R1a1a, R1b-P312 and R1b-U106, a genetic combination of the haplogroups found to be strongly-represented among current Germanic speaking peoples. Peaking in northern Europe, the R1b-U106 marker seems particular interesting in distribution and provides some helpful genetic clues regarding the historical trek made by the Germanic people.

Haplogroup I1 accounts for approximately 40% of Icelandic males, 40%–50% of Swedish males, 40% of Norwegian males, and 40% of Danish Human Y-chromosome DNA haplogroups. Haplogroup I1 peaks in certain areas of Northern Germany and Eastern England at more than 30%.

The Renaissance revived interest in pre-Christian Classical Antiquity and only in a second phase in pre-Christian Northern Europe. The Germanic peoples of the Roman era are often lumped with the other agents of the barbarian invasions, the Alans and the Huns, as opposed to the civilized "Roman" identity of the Holy Roman Empire.

Early modern publications dealing with Old Norse culture appeared in the 16th century, e.g. "Historia de gentibus septentrionalibus" (Olaus Magnus, 1555) and the first edition of the 13th century "Gesta Danorum" (Saxo Grammaticus), in 1514. Authors of the German Renaissance such as Johannes Aventinus discovered the "Germanii" of Tacitus as the "Old Germans", whose virtue and unspoiled manhood, as it appears in the Roman accounts of noble savagery, they contrast with the decadence of their own day.

The pace of publication increased during the 17th century with Latin translations of the Edda (notably Peder Resen's "Edda Islandorum" of 1665). The Viking revival of 18th century Romanticism created a fascination with anything "Nordic" in disposition. The beginning of Germanic philology proper begins in the early 19th century, with Rasmus Rask's "Icelandic Lexicon " of 1814, and was in full bloom by the 1830s, with Jacob Grimm's "Deutsche Mythologie" giving an extensive account of reconstructed Germanic mythology and composing a German dictionary ("Deutsches Wörterbuch") of Germanic etymology. Jacob Grimm also coauthored with his brother Wilhelm, the famous Grimm's Fairy Tales. Apart from linguistic studies, the subject of what became of the Roman era Germanic tribes, and how they influenced the Middle Ages and the development of modern Western culture was a subject discussed during the Enlightenment by such as writers as Montesquieu and Giambattista Vico.

Later still, the development of Germanic studies as an academic discipline in the 19th century ran parallel to the rise of nationalism in Europe and the search for national histories for the nascent nation states developing after the end of the Napoleonic Wars. A "Germanic" national ethnicity offered itself for the unification of Germany, contrasting the emerging German Empire with its neighboring rivals of differing ancestry. The nascent belief in a German ethnicity was subsequently founded upon national myths of Germanic antiquity. These tendencies culminated in a later Pan-Germanism, "" which had as its aim, the political unity of all of German-speaking Europe (all "Volksdeutsche") into a Teutonic nation state.

Contemporary Romantic nationalism in Scandinavia placed more weight on the Viking Age, resulting in the movement known as Scandinavism. The theories of race developed in the same period, which used Darwinian evolutionary ideals and pseudo-scientific methods in the identification of Germanic peoples (members of a Nordic race), as being superior to other ethnicities. Scientific racism flourished in the late 19th century and into the mid-20th century, where it became the basis for specious racial comparisons and justification for eugenic efforts; it also contributed to compulsory sterilization, anti-miscegenation laws, and was used to sanction immigration restrictions in both Europe and the United States.




</doc>
<doc id="12448" url="https://en.wikipedia.org/wiki?curid=12448" title="Ganges">
Ganges

The Ganges ( ), or Ganga (), is a trans-boundary river of Asia which flows through India and Bangladesh. The river rises in the western Himalayas in the Indian state of Uttarakhand, and flows south and east through the Gangetic Plain of India and Bangladesh, eventually emptying into the Bay of Bengal. 

The Ganges is a lifeline to millions who live along its course. It is a most sacred river to Hindus, and worshiped as the goddess "Ganga" in Hinduism. It has been important historically: many former provincial or imperial capitals (such as Patliputra, Kannauj, Kara, Kashi, Allahabad, Murshidabad, Munger, Baharampur, Kampilya and Kolkata) have been located on its banks.

The Ganges is threatened by pollution, not only to humans, but also to animals, among which are more than 140 fish species, 90 amphibian species, reptiles such as the gharial, and mammals such as the Ganges river dolphin, the last-mentioned two included in the IUCN's critically endangered list. The levels of fecal coliform bacteria from human waste in the river near Varanasi are more than a hundred times the Indian government's official limit. The Ganga Action Plan, an environmental initiative to clean up the river, is considered a failure, which is variously attributed to corruption, a lack of will in the government, poor technical expertise and environmental planning, and a lack of support from religious authorities..

The main stream of Ganga begins at the confluence of the Bhagirathi and Alaknanda rivers in the town of Devprayag in the Garhwal division of the Indian state of Uttarakhand. The Bhagirathi is considered to be the source in Hindu culture and mythology, although the Alaknanda is longer, and, therefore, hydrologically the source stream. The headwaters of the Alakananda are formed by snowmelt from peaks such as Nanda Devi, Trisul, and Kamet. The Bhagirathi rises at the foot of Gangotri Glacier, at Gomukh, at an elevation of , being mythologically referred to as, residing in the matted locks of Shiva, symbolically Tapovan, being a meadow of ethereal beauty at the feet of Mount Shivling, just away.

Although many small streams comprise the headwaters of Ganga, the six longest and their five confluences are considered sacred. The six headstreams are the Alaknanda, Dhauliganga, Nandakini, Pindar, Mandakini, and Bhagirathi rivers. The five confluences, known as the Panch Prayag, are all along the Alaknanda. They are, in downstream order, Vishnuprayag, where the Dhauliganga joins the Alaknanda; Nandprayag, where the Nandakini joins; Karnaprayag, where the Pindar joins, Rudraprayag, where the Mandakini joins; and finally, Devprayag, where the Bhagirathi joins the Alaknanda to form The Ganges.

After flowing 250 km (155.343 mi) through its narrow Himalayan valley, Ganga emerges from the mountains at Rishikesh, then debouches onto the Gangetic Plain at the pilgrimage town of Haridwar. At Haridwar, a dam diverts some of its waters into the Ganga Canal, which irrigates the "Doab" region of Uttar Pradesh, whereas the river, whose course has been roughly southwest until this point, now begins to flow southeast through the plains of northern India.

The Ganga follows an arching course passing through the cities of Kannauj, Farukhabad, and Kanpur. Along the way it is joined by the Ramganga, which contributes an average annual flow of about . Ganga joins the river Yamuna at the Triveni Sangam at Prayagraj, a holy confluence in Hinduism. At their confluence the Yamuna is larger than the Ganga, contributing about , or about 58.5% of the combined flow.

Now flowing east, the river meets the Tamsa River (also called "Tons"), which flows north from the Kaimur Range and contributes an average flow of about . After the Tamsa the Gomti River joins, flowing south from the Himalayas. The Gomti contributes an average annual flow of about . Then the Ghaghara River (Karnali River), also flowing south from the Himalayas of Nepal, joins. The Ghaghara (Karnali), with its average annual flow of about , is the largest tributary of the Ganges. After the Ghaghara (Karnali) confluence the Ganga is joined from the south by the Son River, contributing about . The Gandaki River, then the Kosi River, join from the north flowing from Nepal, contributing about and , respectively. The Kosi is the third largest tributary of the Ganga, after the Ghaghara (Karnali) and Yamuna.The Kosi merges into the Ganga near Kursela in Bihar.

Along the way between Allahabad and Malda, West Bengal, the Ganga passes the towns of Chunar, Mirzapur, Varanasi, Ghazipur, Patna, Hajipur, Chapra, Bhagalpur, Ballia, Buxar, Simaria, Sultanganj, and Saidpur. At Bhagalpur, the river begins to flow south-southeast and at Pakur, it begins its attrition with the branching away of its first distributary, the Bhāgirathi-Hooghly, which goes on to become the Hooghly River. Just before the border with Bangladesh the Farakka Barrage controls the flow of Ganga, diverting some of the water into a feeder canal linked to the Hooghly for the purpose of keeping it relatively silt-free. The Hooghly River is formed by the confluence of the Bhagirathi River and Jalangi River at Nabadwip, and Hooghly has a number of tributaries of its own. The largest is the Damodar River, which is long, with a drainage basin of . The Hooghly River empties into the Bay of Bengal near Sagar Island. Between Malda and the Bay of Bengal, the Hooghly river passes the towns and cities of Murshidabad, Nabadwip, Kolkata and Howrah.

After entering Bangladesh, the main branch of Ganga is known as the Padma. The Padma is joined by the Jamuna River, the largest distributary of the Brahmaputra. Further downstream, the Padma joins the Meghna River, the second largest distributary of the Brahmaputra, and takes on the Meghna's name as it enters the Meghna Estuary, which empties into the Bay of Bengal. Here it forms the Bengal Fan, the world's largest submarine fan, which alone accounts for 10–20% of the global burial of organic carbon.

The Ganga Delta, formed mainly by the large, sediment-laden flows of the Ganga and Brahmaputra rivers, is the world's largest delta, at about . It stretches along the Bay of Bengal.

Only the Amazon and Congo rivers have a greater average discharge than the combined flow of the Ganga, the Brahmaputra, and the Surma-Meghna river system. In full flood only the Amazon is larger.

The Indian subcontinent lies atop the Indian tectonic plate, a minor plate within the Indo-Australian Plate. Its defining geological processes commenced seventy-five million years ago, when, as a part of the southern supercontinent Gondwana, it began a northeastwards drift—lasting fifty million years—across the then unformed Indian Ocean. The subcontinent's subsequent collision with the Eurasian Plate and subduction under it, gave rise to the Himalayas, the planet's highest mountain ranges. In the former seabed immediately south of the emerging Himalayas, plate movement created a vast trough, which, having gradually been filled with sediment borne by the Indus and its tributaries and the Ganges and its tributaries, now forms the Indo-Gangetic Plain.

The Indo-Gangetic Plain is geologically known as a foredeep or foreland basin.

Major left-bank tributaries include Gomti River, Ghaghara River, Gandaki river, and Kosi river; major right-bank tributaries include Yamuna river, Son river, Punpun and Damodar.
The hydrology of the Ganges River is very complicated, especially in the Ganges Delta region. One result is different ways to determine the river's length, its discharge, and the size of its drainage basin.

The name "Ganga" is used for the river between the confluence of the Bhagirathi and Alaknanda rivers, in the Himalayas, and the India-Bangladesh border, near the Farakka Barrage and the first bifurcation of the river. The length of the Ganges is frequently said to be slightly over long, about , to , or perhaps . In these cases the river's source is usually assumed to be the source of the Bhagirathi River, Gangotri Glacier at Gomukh, and its mouth being the mouth of the Meghna River on the Bay of Bengal. Sometimes the source of the Ganges is considered to be at Haridwar, where its Himalayan headwater streams debouch onto the Gangetic Plain.

In some cases, the length of the Ganges is given for its Hooghly River distributary, which is longer than its main outlet via the Meghna River, resulting in a total length of about , from the source of the Bhagirathi, or , from Haridwar to the Hooghly's mouth. In other cases the length is said to be about , from the source of the Bhagirathi to the Bangladesh border, where its name changes to "Padma".

For similar reasons, sources differ over the size of the river's drainage basin. The basin covers parts of four countries, India, Nepal, China, and Bangladesh; eleven Indian states, Himachal Pradesh, Uttarakhand, Uttar Pradesh, Madhya Pradesh, Chhattisgarh, Bihar, Jharkhand, Punjab, Haryana, Rajasthan, West Bengal, and the Union Territory of Delhi. The Ganges basin, including the delta but not the Brahmaputra or Meghna basins, is about , of which are in India (about 80%), in Nepal (13%), in Bangladesh (4%), and in China (3%). Sometimes the Ganges and Brahmaputra–Meghna drainage basins are combined for a total of about , or . The combined Ganges-Brahmaputra-Meghna basin (abbreviated GBM or GMB) drainage basin is spread across Bangladesh, Bhutan, India, Nepal, and China.

The Ganges basin ranges from the Himalaya and the Transhimalaya in the north, to the northern slopes of the Vindhya range in the south, from the eastern slopes of the Aravalli in the west to the Chota Nagpur plateau and the Sunderbans delta in the east. A significant portion of the discharge from the Ganges comes from the Himalayan mountain system. Within the Himalaya, the Ganges basin spreads almost 1,200 km from the Yamuna-Satluj divide along the Simla ridge forming the boundary with the Indus basin in the west to the Singalila Ridge along the Nepal-Sikkim border forming the boundary with the Brahmaputra basin in the east. This section of the Himalaya contains 9 of the 14 highest peaks in the world over 8,000m in height, including Mount Everest which is the high point of the Ganges basin. The other peaks over 8,000m in the basin are Kangchenjunga, Lhotse, Makalu, Cho Oyu, Dhaulagiri, Manaslu, Annapurna and Shishapangma. The Himalayan portion of the basin includes the south-eastern portion of the state of Himachal Pradesh, the entire state of Uttarakhand, the entire country of Nepal and the extreme north-western portion of the state of West Bengal.

The discharge of the Ganges also differs by source. Frequently, discharge is described for the mouth of the Meghna River, thus combining the Ganges with the Brahmaputra and Meghna. This results in a total average annual discharge of about , or . In other cases the average annual discharges of the Ganges, Brahmaputra, and Meghna are given separately, at about for the Ganges, about for the Brahmaputra, and about for the Meghna.
The maximum peak discharge of the Ganges, as recorded at Hardinge Bridge in Bangladesh, exceeded . The minimum recorded at the same place was about , in 1997.

The hydrologic cycle in the Ganges basin is governed by the Southwest Monsoon. About 84% of the total rainfall occurs in the monsoon from June to September. Consequently, streamflow in the Ganges is highly seasonal. The average dry season to monsoon discharge ratio is about 1:6, as measured at Hardinge Bridge. This strong seasonal variation underlies many problems of land and water resource development in the region. The seasonality of flow is so acute it can cause both drought and floods. Bangladesh, in particular, frequently experiences drought during the dry season and regularly suffers extreme floods during the monsoon.

In the Ganges Delta many large rivers come together, both merging and bifurcating in a complicated network of channels. The two largest rivers, the Ganges and Brahmaputra, both split into distributary channels, the largest of which merge with other large rivers before themselves joining. This current channel pattern was not always the case. Over time the rivers in Ganges Delta have changed course, sometimes altering the network of channels in significant ways.

Before the late 12th century the Bhagirathi-Hooghly distributary was the main channel of the Ganges and the Padma was only a minor spill-channel. The main flow of the river reached the sea not via the modern Hooghly River but rather by the Adi Ganga. Between the 12th and 16th centuries the Bhagirathi-Hooghly and Padma channels were more or less equally significant. After the 16th century the Padma grew to become the main channel of the Ganges. It is thought that the Bhagirathi-Hooghly became increasingly choked with silt, causing the main flow of the Ganges to shift to the southeast and the Padma River. By the end of the 18th century the Padma had become the main distributary of the Ganges. One result of this shift to the Padma was that the Ganges joined the Meghna and Brahmaputra rivers before emptying into the Bay of Bengal, together instead of separately. The present confluence of the Ganges and Meghna formed about 150 years ago.

Also near the end of the 18th century, the course of the lower Brahmaputra changed dramatically, altering its relationship with the Ganges. In 1787 there was a great flood on the Teesta River, which at the time was a tributary of the Ganges-Padma River. The flood of 1787 caused the Teesta to undergo a sudden change course (an avulsion), shifting east to join the Brahmaputra and causing the Brahmaputra to shift its course south, cutting a new channel. This new main channel of the Brahmaputra is called the Jamuna River. It flows south to join the Ganges-Padma. Since ancient times the main flow of the Brahmaputra was more easterly, passing by the city of Mymensingh and joining the Meghna River. Today this channel is a small distributary but retains the name Brahmaputra, sometimes Old Brahmaputra. The site of the old Brahmaputra-Meghna confluence, in the locality of Langalbandh, is still considered sacred by Hindus. Near the confluence is a major early historic site called Wari-Bateshwar.

The Late Harappan period, about 1900–1300 BCE, saw the spread of Harappan settlement eastward from the Indus River basin to the Ganges-Yamuna doab, although none crossed the Ganges to settle its eastern bank. The disintegration of the Harappan civilisation, in the early 2nd millennium BC, marks the point when the centre of Indian civilisation shifted from the Indus basin to the Ganges basin. There may be links between the Late Harappan settlement of the Ganges basin and the archaeological culture known as "Cemetery H", the Indo-Aryan people, and the Vedic period.

This river is the longest in India. During the early Vedic Age of the "Rigveda", the Indus and the Sarasvati River were the major sacred rivers, not the Ganges. But the later three Vedas gave much more importance to the Ganges. The Gangetic Plain became the centre of successive powerful states, from the Maurya Empire to the Mughal Empire.

The first European traveller to mention the Ganges was Megasthenes (ca. 350–290 BCE). He did so several times in his work Indica: "India, again, possesses many rivers both large and navigable, which, having their sources in the mountains which stretch along the northern frontier, traverse the level country, and not a few of these, after uniting with each other, fall into the river called the Ganges. Now this river, which at its source is 30 stadia broad, flows from north to south, and empties its waters into the ocean forming the eastern boundary of the Gangaridai, a nation which possesses a vast force of the largest-sized elephants." (Diodorus II.37)
In the rainy season of 1809, the lower channel of the Bhagirathi, leading to Kolkata, had been entirely shut; but in the following year it opened again, and was nearly of the same size with the upper channel; both however suffered a considerable diminution, owing probably to the new communication opened below the Jalanggi on the upper channel.

In 1951 a water sharing dispute arose between India and East Pakistan (now Bangladesh), after India declared its intention to build the Farakka Barrage. The original purpose of the barrage, which was completed in 1975, was to divert up to of water from the Ganges to the Bhagirathi-Hooghly distributary in order to restore navigability at the Port of Kolkata. It was assumed that during the worst dry season the Ganges flow would be around , thus leaving for the then East Pakistan. East Pakistan objected and a protracted dispute ensued. In 1996 a 30-year treaty was signed with Bangladesh. The terms of the agreement are complicated, but in essence they state that if the Ganges flow at Farakka was less than then India and Bangladesh would each receive 50% of the water, with each receiving at least for alternating ten-day periods. However, within a year the flow at Farakka fell to levels far below the historic average, making it impossible to implement the guaranteed sharing of water. In March 1997, flow of the Ganges in Bangladesh dropped to its lowest ever, . Dry season flows returned to normal levels in the years following, but efforts were made to address the problem. One plan is for another barrage to be built in Bangladesh at Pangsha, west of Dhaka. This barrage would help Bangladesh better utilise its share of the waters of the Ganges.

In Greco-Roman mythology Ganges was a river god. His daughter Limaee was the Naiad of a lake in India. She had a son named Athis.

The Ganges is a sacred river to Hindus along every fragment of its length. All along its course, Hindus bathe in its waters, paying homage to their ancestors and to their gods by cupping the water in their hands, lifting it and letting it fall back into the river; they offer flowers and rose petals and float shallow clay dishes filled with oil and lit with wicks (diyas). On the journey back home from the Ganges, they carry small quantities of river water with them for use in rituals (Ganga jal, literally water of the Ganges).

The Ganges is the embodiment of all sacred waters in Hindu mythology. Local rivers are said to be "like" the Ganges, and are sometimes called the local Ganges. The Kaveri river of Karnataka and Tamil Nadu in Southern India is called the Ganges of the South; the Godavari, is the Ganges that was led by the sage Gautama to flow through Central India. The Ganges is invoked whenever water is used in Hindu ritual, and is therefore present in all sacred waters. In spite of this, nothing is more stirring for a Hindu than a dip in the actual river, which is thought to remit sins, especially at one of the famous tirthas such as Gangotri, Haridwar, Prayag, or Varanasi. The symbolic and religious importance of the Ganges is one of the few things that Hindu India, even its skeptics, are agreed upon. Jawaharlal Nehru, a religious iconoclast himself, asked for a handful of his ashes to be thrown into the Ganges. "The Ganga," he wrote in his will, "is the river of India, beloved of her people, round which are intertwined her racial memories, her hopes and fears, her songs of triumph, her victories and her defeats. She has been a symbol of India's age-long culture and civilization, ever-changing, ever-flowing, and yet ever the same Ganga."

In late May or early June every year, Hindus celebrate the "karunasiri" and rise of the Ganges from earth to heaven. The day of the celebration, "Ganga Dashahara", the "dashami" (tenth day) of the waxing moon of the Hindu calendar month Jyestha, brings throngs of bathers to the banks of the river. A dip in the Ganges on this day is said to rid the bather of ten sins (dasha = Sanskrit "ten"; hara = to destroy) or alternatively, ten lifetimes of sins. Those who cannot journey to the river, however, can achieve the same results by bathing in any nearby body of water, which, for the true believer, in the Hindu tradition, takes on all the attributes of the Ganges.

The "karunasiri" is an old theme in Hinduism with a number of different versions of the story. In the Vedic version, Indra, the Lord of Svarga (Heaven) slays the celestial serpent, Vritra, releasing the celestial liquid, the "soma", or the nectar of the gods which then plunges to the earth and waters it with sustenance.

In the Vaishnava version of the myth, the heavenly waters are now a river called "Vishnupadi" ("padi": Skt. "from the foot of"). As Lord Vishnu completes his celebrated three strides—of earth, sky, and heaven—Vishnu as Vamana stubs his toe on the vault of heaven, punches open a hole, and releases the "Vishnupadi", which until now had been circling around the cosmic egg within. Flowing out of the vault, she plummets down to Indra's heaven, where she is received by Dhruva, the once steadfast worshipper of Vishnu, now fixed in the sky as the polestar. Next, she streams across the sky forming the Milky Way and arrives on the moon. She then flows down earthwards to Brahma's realm, a divine lotus atop Mount Meru, whose petals form the earthly continents. There, the divine waters break up, with one stream, the Alaknanda, flowing down one petal into Bharatvarsha (India) as the Ganges.

It is Shiva, however, among the major deities of the Hindu pantheon, who appears in the most widely known version of the "avatarana" story. Told and retold in the Ramayana, the Mahabharata and several Puranas, the story begins with a sage, Kapila, whose intense meditation has been disturbed by the sixty thousand sons of King Sagara. Livid at being disturbed, Kapila sears them with his angry gaze, reduces them to ashes, and dispatches them to the netherworld. Only the waters of the Ganges, then in heaven, can bring the dead sons their salvation. A descendant of these sons, King Bhagiratha, anxious to restore his ancestors, undertakes rigorous penance and is eventually granted the prize of Ganga's descent from heaven. However, since her turbulent force would also shatter the earth, Bhagiratha persuades Shiva in his abode on Mount Kailash to receive Ganga in the coils of his tangled hair and break her fall. Ganga descends, is tamed in Shiva's locks, and arrives in the Himalayas. She is then led by the waiting Bhagiratha down into the plains at Haridwar, across the plains first to the confluence with the Yamuna at Prayag and then to Varanasi, and eventually to Ganga Sagar, where she meets the ocean, sinks to the netherworld, and saves the sons of Sagara. In honour of Bhagirath's pivotal role in the "avatarana", the source stream of the Ganges in the Himalayas is named Bhagirathi, (Sanskrit, "of Bhagiratha").

Since Ganga had descended from heaven to earth, she is also the vehicle of "ascent", from earth to heaven. As the "Triloka-patha-gamini", (Skt. "triloka"= "three worlds", "patha" = "road", "gamini" = "one who travels") of the Hindu tradition, she flows in heaven, earth, and the netherworld, and, consequently, is a "tirtha," or crossing point of all beings, the living as well as the dead. It is for this reason that the story of the "avatarana" is told at "Shraddha" ceremonies for the deceased in Hinduism, and Ganges water is used in Vedic rituals after death. Among all hymns devoted to the Ganges, there are none more popular than the ones expressing the worshipers wish to breathe his last surrounded by her waters. The "Gangashtakam" expresses this longing fervently: O Mother! ... Necklace adorning the worlds! <br> Banner rising to heaven! <br> I ask that I may leave of this body on your banks,<br> Drinking your water, rolling in your waves, <br> Remembering your name, bestowing my gaze upon you.
No place along her banks is more longed for at the moment of death by Hindus than Varanasi, the Great Cremation Ground, or "Mahashmshana". Those who are lucky enough to die in Varanasi, are cremated on the banks of the Ganges, and are granted instant salvation. If the death has occurred elsewhere, salvation can be achieved by immersing the ashes in the Ganges. If the ashes have been immersed in another body of water, a relative can still gain salvation for the deceased by journeying to the Ganges, if possible during the lunar "fortnight of the ancestors" in the Hindu calendar month of Ashwin (September or October), and performing the "Shraddha" rites.

Hindus also perform "pinda pradana", a rite for the dead, in which balls of rice and sesame seed are offered to the Ganges while the names of the deceased relatives are recited. Every sesame seed in every ball thus offered, according to one story, assures a thousand years of heavenly salvation for the each relative. Indeed, the Ganges is so important in the rituals after death that the "Mahabharata", in one of its popular "ślokas", says, "If only (one) bone of a (deceased) person should touch the water of the Ganges, that person shall dwell honoured in heaven." As if to illustrate this truism, the "Kashi Khanda" (Varanasi Chapter) of the Skanda Purana recounts the remarkable story of "Vahika", a profligate and unrepentant sinner, who is killed by a tiger in the forest. His soul arrives before Yama, the Lord of Death, to be judged for the hereafter. Having no compensating virtue, Vahika's soul is at once dispatched to hell. While this is happening, his body on earth, however, is being picked at by vultures, one of whom flies away with a foot bone. Another bird comes after the vulture, and in fighting him off, the vulture accidentally drops the bone into the Ganges below. Blessed by this happenstance, Vahika, on his way to hell, is rescued by a celestial chariot which takes him instead to heaven.

Hindus consider the waters of the Ganges to be both pure and purifying. Nothing reclaims order from disorder more than the waters of the Ganges. Moving water, as in a river, is considered purifying in Hindu culture because it is thought to both absorb impurities and take them away. The swiftly moving Ganges, especially in its upper reaches, where a bather has to grasp an anchored chain in order to not be carried away, is considered especially purifying. What the Ganges removes, however, is not necessarily physical dirt, but symbolic dirt; it wipes away the sins of the bather, not just of the present, but of a lifetime.

A popular paean to the Ganges is the "Ganga Lahiri" composed by a seventeenth century poet Jagannatha who, legend has it, was turned out of his Hindu Brahmin caste for carrying on an affair with a Muslim woman. Having attempted futilely to be rehabilitated within the Hindu fold, the poet finally appeals to Ganga, the hope of the hopeless, and the comforter of last resort. Along with his beloved, Jagannatha sits at the top of the flight of steps leading to the water at the famous "Panchganga" Ghat in Varanasi. As he recites each verse of the poem, the water of the Ganges rises up one step, until in the end it envelops the lovers and carry them away. "I come to you as a child to his mother," begins the "Ganga Lahiri". I come as an orphan to you, moist with love. <br> I come without refuge to you, giver of sacred rest. <br> I come a fallen man to you, uplifter of all. <br> I come undone by disease to you, the perfect physician. <br> I come, my heart dry with thirst, to you, ocean of sweet wine. <br> Do with me whatever you will.

Ganga is a consort to all three major male deities of Hinduism. As Brahma's partner she always travels with him in the form of water in his kamandalu (water-pot). She is also Vishnu's consort. Not only does she emanate from his foot as "Vishnupadi" in the "avatarana" story, but is also, with Sarasvati and Lakshmi, one of his co-wives. In one popular story, envious of being outdone by each other, the co-wives begin to quarrel. While Lakshmi attempts to mediate the quarrel, Ganga and Sarasvati, heap misfortune on each other. They curse each other to become rivers, and to carry within them, by washing, the sins of their human worshippers. Soon their husband, Vishnu, arrives and decides to calm the situation by separating the goddesses. He orders Sarasvati to become the wife of Brahma, Ganga to become the wife of Shiva, and Lakshmi, as the blameless conciliator, to remain as his own wife. Ganga and Sarasvati, however, are so distraught at this dispensation, and wail so loudly, that Vishnu is forced to take back his words. Consequently, in their lives as rivers they are still thought to be with him.
It is Shiva's relationship with Ganga, that is the best-known in Ganges mythology. Her descent, the "avatarana" is not a one time event, but a continuously occurring one in which she is forever falling from heaven into his locks and being forever tamed. Shiva, is depicted in Hindu iconography as "Gangadhara", the "Bearer of the Ganges", with Ganga, shown as spout of water, rising from his hair. The Shiva-Ganga relationship is both perpetual and intimate. Shiva is sometimes called "Uma-Ganga-Patiswara" ("Husband and Lord of Uma (Parvati) and Ganga"), and Ganga often arouses the jealousy of Shiva's better-known consort Parvati.

Ganga is the "shakti" or the moving, restless, rolling energy in the form of which the otherwise recluse and unapproachable Shiva appears on earth. As water, this moving energy can be felt, tasted, and absorbed. The war-god Skanda addresses the sage Agastya in the "Kashi Khand" of the "Skanda Purana" in these words: One should not be amazed ... that this Ganges is really Power, for is she not the Supreme Shakti of the Eternal Shiva, taken in the form of water?<br> This Ganges, filled with the sweet wine of compassion, was sent out for the salvation of the world by Shiva, the Lord of the Lords. <br> Good people should not think this Triple-Pathed River to be like the thousand other earthly rivers, filled with water. 

The Ganges is also the mother, the "Ganga Mata" ("mata"="mother") of Hindu worship and culture, accepting all and forgiving all. Unlike other goddesses, she has no destructive or fearsome aspect, destructive though she might be as a river in nature. She is also a mother to other gods. She accepts Shiva's incandescent seed from the fire-god Agni, which is too hot for this world, and cools it in her waters. This union produces Skanda, or Kartikeya, the god of war. In the "Mahabharata", she is the wife of Shantanu, and the mother of heroic warrior-patriarch, Bhishma. When Bhishma is mortally wounded in battle, Ganga comes out of the water in human form and weeps uncontrollably over his body.

The Ganges is the distilled lifeblood of the Hindu tradition, of its divinities, holy books, and enlightenment. As such, her worship does not require the usual rites of invocation ("avahana") at the beginning and dismissal ("visarjana") at the end, required in the worship of other gods. Her divinity is immediate and everlasting.

Early in ancient Indian culture, the river Ganges was associated with fecundity, its redeeming waters and its rich silt providing sustenance to all who lived along its banks. A counterpoise to the dazzling heat of the Indian summer, the Ganges came to be imbued with magical qualities and to be revered in anthropomorphic form. By the 5th century CE, an elaborate mythology surrounded the Ganges, now a goddess in her own right, and a symbol for all rivers of India. Hindu temples all over India had statues and reliefs of the goddess carved at their entrances, symbolically washing the sins of arriving worshippers and guarding the gods within. As protector of the sanctum sanctorum, the goddess soon came to depicted with several characteristic accessories: the "makara" (a crocodile-like undersea monster, often shown with an elephant-like trunk), the "kumbha" (an overfull vase), various overhead parasol-like coverings, and a gradually increasing retinue of humans.

Central to the goddess's visual identification is the "makara", which is also her "vahana", or mount. An ancient symbol in India, it pre-dates all appearances of the goddess Ganga in art. The "makara" has a dual symbolism. On the one hand, it represents the life-affirming waters and plants of its environment; on the other, it represents fear, both fear of the unknown it elicits by lurking in those waters and real fear it instils by appearing in sight. The earliest extant unambiguous pairing of the "makara" with Ganga is at Udayagiri Caves in Central India (circa 400 CE). Here, in Cave V, flanking the main figure of Vishnu shown in his boar incarnation, two river goddesses, Ganga and Yamuna appear atop their respective mounts, "makara" and "kurma" (a turtle or tortoise).

The "makara" is often accompanied by a "gana", a small boy or child, near its mouth, as, for example, shown in the Gupta period relief from Besnagar, Central India, in the left-most frame above. The "gana" represents both posterity and development ("udbhava"). The pairing of the fearsome, life-destroying "makara" with the youthful, life-affirming "gana" speaks to two aspects of the Ganges herself. Although she has provided sustenance to millions, she has also brought hardship, injury, and death by causing major floods along her banks. The goddess Ganga is also accompanied by a dwarf attendant, who carries a cosmetic bag, and on whom she sometimes leans, as if for support. (See, for example, frames 1, 2, and 4 above.)

The "purna kumbha" or full pot of water is the second most discernible element of the Ganga iconography. Appearing first also in the relief in Udayagiri Caves (5th century), it gradually appeared more frequently as the theme of the goddess matured. By the seventh century it had become an established feature, as seen, for example, the Dashavatara temple, Deogarh, Uttar Pradesh (seventh century), the Trimurti temple, Badoli, Chittorgarh, Rajasthan, and at the Lakshmaneshwar temple, Kharod, Bilaspur, Chhattisgarh, (ninth or tenth century), and seen very clearly in frame 3 above and less clearly in the remaining frames. Worshipped even today, the full pot is emblematic of the formless Brahman, as well as of woman, of the womb, and of birth. Furthermore, The river goddesses Ganga and Saraswati were both born from Brahma's pot, containing the celestial waters.

In her earliest depictions at temple entrances, the goddess Ganga appeared standing beneath the overhanging branch of a tree, as seen as well in the Udayagiri caves. However, soon the tree cover had evolved into a "chatra" or parasol held by an attendant, for example, in the seventh-century Dasavatara temple at Deogarh. (The parasol can be clearly seen in frame 3 above; its stem can be seen in frame 4, but the rest has broken off.) The cover undergoes another transformation in the temple at Kharod, Bilaspur (ninth or tenth century), where the parasol is lotus-shaped, and yet another at the Trimurti temple at Badoli where the parasol has been replaced entirely by a lotus.

As the iconography evolved, sculptors in the central India especially were producing animated scenes of the goddess, replete with an entourage and suggestive of a queen en route to a river to bathe. A relief similar to the depiction in frame 4 above, is described in as follows: A typical relief of about the ninth century that once stood at the entrance of a temple, the river goddess Ganga is shown as a voluptuously endowed lady with a retinue. Following the iconographic prescription, she stands gracefully on her composite "makara" mount and holds a water pot. The dwarf attendant carries her cosmetic bag, and a ... female holds the stem of a giant lotus leaf that serves as her mistress's parasol. The fourth figure is a male guardian. Often in such reliefs the "makara"'s tail is extended with great flourish into a scrolling design symbolizing both vegetation and water.

Kumbh Mela is a mass Hindu pilgrimage in which Hindus gather at the Ganges River. The normal Kumbh Mela is celebrated every 3 years, the "Ardh" (half) Kumbh is celebrated every six years at Haridwar and Prayag, the "Purna" (complete) Kumbh takes place every twelve years at four places (Prayag (Allahabad), Haridwar, Ujjain, and Nashik). The "Maha" (great) Kumbh Mela which comes after 12 'Purna Kumbh Melas', or 144 years, is held at Prayag (Allahabad).

The major event of the festival is ritual bathing at the banks of the river. Other activities include religious discussions, devotional singing, mass feeding of holy men and women and the poor, and religious assemblies where doctrines are debated and standardized. Kumbh Mela is the most sacred of all the pilgrimages. Thousands of holy men and women attend, and the auspiciousness of the festival is in part attributable to this. The sadhus are seen clad in saffron sheets with ashes and powder dabbed on their skin per the requirements of ancient traditions. Some, called "naga sanyasis", may not wear any clothes.

The Ganges and its all tributaries, especially the Yamuna, have been used for irrigation since ancient times. Dams and canals were common in gangetic plain by fourth century BCE. The Ganges-Brahmaputra-Meghna basin has a huge hydroelectric potential, on the order of 200,000 to 250,000 megawatts, nearly half of which could be easily harnessed. As of 1999, India tapped about 12% of the hydroelectric potential of the Ganges and just 1% of the vast potential of the Brahmaputra.

Megasthenes, a Greek ethnographer who visited India during third century BCE when Mauryans ruled India described the existence of canals in the gangetic plain. Kautilya (also known as Chanakya), an advisor to Chandragupta Maurya, the founder of Maurya Empire, included the destruction of dams and levees as a strategy during war. Firuz Shah Tughlaq had many canals built, the longest of which, , was built in 1356 on the Yamuna River. Now known as the Western Yamuna Canal, it has fallen into disrepair and been restored several times. The Mughal emperor Shah Jahan built an irrigation canal on the Yamuna River in the early 17th century. It fell into disuse until 1830, when it was reopened as the Eastern Yamuna Canal, under British control. The reopened canal became a model for the Upper Ganges Canal and all following canal projects.

The first British canal in India—with no Indian antecedents—was the Ganges Canal built between 1842 and 1854.
Contemplated first by Col. John Russell Colvin in 1836, it did not at first elicit much enthusiasm from its eventual architect Sir Proby Thomas Cautley, who balked at idea of cutting a canal through extensive low-lying land in order to reach the drier upland destination. However, after the Agra famine of 1837–38, during which the East India Company's administration spent Rs. 2,300,000 on famine relief, the idea of a canal became more attractive to the Company's budget-conscious Court of Directors. In 1839, the Governor General of India, Lord Auckland, with the Court's assent, granted funds to Cautley for a full survey of the swath of land that underlay and fringed the projected course of the canal. The Court of Directors, moreover, considerably enlarged the scope of the projected canal, which, in consequence of the severity and geographical extent of the famine, they now deemed to be the entire Doab region.

The enthusiasm, however, proved to be short lived. Auckland's successor as Governor General, Lord Ellenborough, appeared less receptive to large-scale public works, and for the duration of his tenure, withheld major funds for the project. Only in 1844, when a new Governor-General, Lord Hardinge, was appointed, did official enthusiasm and funds return to the Ganges canal project. Although the intervening impasse had seemingly affected Cautley's health and required him to return to Britain in 1845 for recuperation, his European sojourn gave him an opportunity to study contemporary hydraulic works in the United Kingdom and Italy. By the time of his return to India even more supportive men were at the helm, both in the North-Western Provinces, with James Thomason as Lt. Governor, and in British India with Lord Dalhousie as Governor-General. Canal construction, under Cautley's supervision, now went into full swing. A long canal, with another of branch lines, eventually stretched between the headworks in Haridwar, splitting into two branches below Aligarh, and its two confluences with the Yamuna (Jumna in map) mainstem in Etawah and the Ganges in Kanpur (Cawnpore in map). The Ganges Canal, which required a total capital outlay of £2.15 million, was officially opened in 1854 by Lord Dalhousie. According to historian Ian Stone: It was the largest canal ever attempted in the world, five times greater in its length than all the main irrigation lines of Lombardy and Egypt put together, and longer by a third than even the largest USA navigation canal, the Pennsylvania Canal.

A major barrage at Farakka was opened on 21 April 1975, It is located close to the point where the main flow of the river enters Bangladesh, and the tributary Hooghly (also known as Bhagirathi) continues in West Bengal past
Kolkata. This barrage, which feeds the Hooghly branch of the river by a long feeder canal, and its water flow management has been a long-lingering source of dispute with Bangladesh. Indo-Bangladesh Ganges Water Treaty signed in December 1996 addressed some of the water sharing issues between India and Bangladesh. There is Lav Khush Barrage across the river Ganges in Kanpur.

Tehri Dam was constructed on Bhagirathi River, tributary of the Ganges. It is located 1.5 km downstream of Ganesh Prayag, the place where Bhilangana meets Bhagirathi. Bhagirathi is called Ganges after Devprayag. Construction of the dam in an earthquake prone area was controversial.

Bansagar Dam was built on the Son River, a tributary of the Ganges for both irrigation and hydroelectric power generation. Ganges flood waters along with Brahmaputra waters can be supplied to most of its right side basin area along with central and south India by constructing a coastal reservoir to store water on the Bay of Bengal sea area.

The Ganges Basin with its fertile soil is instrumental to the agricultural economies of India and Bangladesh. The Ganges and its tributaries provide a perennial source of irrigation to a large area. Chief crops cultivated in the area include rice, sugarcane, lentils, oil seeds, potatoes, and wheat. Along the banks of the river, the presence of swamps and lakes provides a rich growing area for crops such as legumes, chillies, mustard, sesame, sugarcane, and jute. There are also many fishing opportunities along the river, though it remains highly polluted. Also the major industrial towns of Unnao and Kanpur, situated on the banks of the river with the predominance of tanning industries add to the pollution.Kanpur is the largest city on Ganges.

Tourism is another related activity. Three towns holy to Hinduism—Haridwar, Prayag (Allahabad), and Varanasi—attract thousands of pilgrims to its waters to take a dip in the Ganges, which is believed to cleanse oneself of sins and help attain salvation. The rapids of the Ganges also are popular for river rafting, attracting adventure seekers in the summer months. Also, several cities such as Kanpur, Kolkata and Patna have developed riverfront walkways along the banks to attract tourists.

Human development, mostly agriculture, has replaced nearly all of the original natural vegetation of the Ganges basin. More than 95% of the upper Gangetic Plain has been degraded or converted to agriculture or urban areas. Only one large block of relatively intact habitat remains, running along the Himalayan foothills and including Rajaji National Park, Jim Corbett National Park, and Dudhwa National Park. As recently as the 16th and 17th centuries the upper Gangetic Plain harboured impressive populations of wild Asian elephants ("Elephas maximus"), Bengal tigers ("Panthera t. tigris"), Indian rhinoceros ("Rhinoceros unicornis"), gaurs ("Bos gaurus"), barasinghas ("Rucervus duvaucelii"), sloth bears ("Melursus ursinus") and Indian lions ("Panthera leo persica"). In the 21st century there are few large wild animals, mostly deer, wild boars, wildcats, and small numbers of Indian wolves, golden jackals, and red and Bengal foxes. Bengal tigers survive only in the Sundarbans area of the Ganges Delta. The Sundarbands freshwater swamp ecoregion, however, is nearly extinct. Threatened mammals in the upper Gangetic Plain include the tiger, elephant, sloth bear, and four-horned antelope ("Tetracerus quadricornis").

Many types of birds are found throughout the basin, such as myna, "Psittacula" parakeets, crows, kites, partridges, and fowls. Ducks and snipes migrate across the Himalayas during the winter, attracted in large numbers to wetland areas. There are no endemic birds in the upper Gangetic Plain. The great Indian bustard ("Ardeotis nigriceps") and lesser florican ("Sypheotides indicus") are considered globally threatened.

The natural forest of the upper Gangetic Plain has been so thoroughly eliminated it is difficult to assign a natural vegetation type with certainty. There are a few small patches of forest left, and they suggest that much of the upper plains may have supported a tropical moist deciduous forest with sal ("Shorea robusta") as a climax species.

A similar situation is found in the lower Gangetic Plain, which includes the lower Brahmaputra River. The lower plains contain more open forests, which tend to be dominated by "Bombax ceiba" in association with "Albizzia procera", "Duabanga grandiflora", and "Sterculia vilosa". There are early seral forest communities that would eventually become dominated by the climax species sal ("Shorea robusta"), if forest succession was allowed to proceed. In most places forests fail to reach climax conditions due to human causes. The forests of the lower Gangetic Plain, despite thousands of years of human settlement, remained largely intact until the early 20th century. Today only about 3% of the ecoregion is under natural forest and only one large block, south of Varanasi, remains. There are over forty protected areas in the ecoregion, but over half of these are less than . The fauna of the lower Gangetic Plain is similar to the upper plains, with the addition of a number of other species such as the smooth-coated otter ("Lutrogale perspicillata") and the large Indian civet ("Viverra zibetha").

It has been estimated that about 350 fish species live in the entire Ganges drainage, including several endemics. In a major 2007–2009 study of fish in the Ganges basin (including the river itself and its tributaries, but excluding the Brahmaputra and Meghna basins), a total of 143 fish species were recorded, including 10 non-native introduced species. The most diverse orders are Cypriniformes (barbs and allies), Siluriformes (catfish) and Perciformes (perciform fish), each comprising about 50%, 23% and 14% of the total fish species in the drainage.

There are distinct differences between the different sections of the river basin, but Cyprinidae is the most diverse throughout. In the upper section (roughly equalling the basin parts in Uttarakhand) more than 50 species have been recorded and Cyprinidae alone accounts for almost 80% those, followed by Balitoridae (about 15.6%) and Sisoridae (about 12.2%). Sections of the Ganges basin at altitudes above above sea level are generally without fish. Typical genera approaching this altitude are "Schizothorax", "Tor", "Barilius", "Nemacheilus" and "Glyptothorax". About 100 species have been recorded from the middle section of the basin (roughly equalling the sections in Uttar Pradesh and parts of Bihar) and more than 55% of these are in family Cyprinidae, followed by Schilbeidae (about 10.6%) and Clupeidae (about 8.6%). The lower section (roughly equalling the basin in parts of Bihar and West Bengal) includes major floodplains and is home to almost 100 species. About 46% of these are in the family Cyprinidae, followed by Schilbeidae (about 11.4%) and Bagridae (about 9%).

The Ganges basin supports major fisheries, but these have declined in recent decades. In the Allahabad region in the middle section of the basin, catches of carp fell from 424.91 metric tons in 1961–1968 to 38.58 metric tons in 2001–2006, and catches of catfish fell from 201.35 metric tons in 1961–1968 to 40.56 metric tons in 2001–2006. In the Patna region in the lower section of the basin, catches of carp fell from 383.2 metric tons to 118, and catfish from 373.8 metric tons to 194.48. Some of the fish commonly caught in fisheries include catla ("Catla catla"), golden mahseer ("Tor putitora"), tor mahseer ("Tor tor"), rohu ("Labeo rohita"), walking catfish ("Clarias batrachus"), pangas catfish ("Pangasius pangasius"), goonch catfish ("Bagarius"), snakeheads ("Channa"), bronze featherback ("Notopterus notopterus") and milkfish ("Chanos chanos").

The Ganges basin is home to about 30 fish species that are listed as threatened with the primary issues being overfishing (sometimes illegal), pollution, water abstraction, siltation and invasive species. Among the threatened species is the critically endangered Ganges shark ("Glyphis gangeticus"). Several fish species migrate between different sections of the river, but these movements may be prevented by the building of dams.

The main sections of the Ganges River are home to the gharial ("Gavialis gangeticus") and mugger crocodile ("Crocodylus palustris"), and the delta is home to the saltwater crocodile ("C. porosus"). Among the numerous aquatic and semi-aquatic turtles in the Ganges basin are the northern river terrapin ("Batagur baska"; only in the lowermost section of the basin), three-striped roofed turtle ("B. dhongoka"), red-crowned roofed turtle ("B. kachuga"), black pond turtle ("Geoclemys hamiltonii"), Brahminy river turtle ("Hardella thurjii"), Indian black turtle ("Melanochelys trijuga"), Indian eyed turtle ("Morenia petersi"), brown roofed turtle ("Pangshura smithii"), Indian roofed turtle ("Pangshura tecta"), Indian tent turtle ("Pangshura tentoria"), Indian flapshell turtle ("Lissemys punctata"), Indian narrow-headed softshell turtle ("Chitra indica"), Indian softshell turtle ("Nilssonia gangetica"), Indian peacock softshell turtle ("N. hurum") and Cantor's giant softshell turtle ("Pelochelys cantorii"; only in the lowermost section of Ganges basin). Most of these are seriously threatened.

The river's most famed faunal member is the freshwater Ganges river dolphin ("Platanista gangetica gangetica"), which has been declared India's national aquatic animal.

This dolphin used to exist in large schools near to urban centres in both the Ganges and Brahmaputra rivers, but is now seriously threatened by pollution and dam construction. Their numbers have now dwindled to a quarter of their numbers of fifteen years before, and they have become extinct in the Ganges' main tributaries. A recent survey by the World Wildlife Fund found only 3,000 left in the water catchment of both river systems.

The Ganges river dolphin is one of only five true freshwater dolphins in the world. The other four are the baiji ("Lipotes vexillifer") of the Yangtze River in China, now likely extinct; the Indus river dolphin of the Indus River in Pakistan; the Amazon river dolphin of the Amazon River in South America; and the Araguaian river dolphin (not considered a separate species until 2014) of the Araguaia–Tocantins basin in Brazil. There are several marine dolphins whose ranges include some freshwater habitats, but these five are the only dolphins who live only in freshwater rivers and lakes.

The Tibetan Plateau contains the world's third-largest store of ice. Qin Dahe, the former head of the China Meteorological Administration, said that the recent fast pace of melting and warmer temperatures will be good for agriculture and tourism in the short term; but issued a strong warning:

In 2007, the Intergovernmental Panel on Climate Change (IPCC), in its Fourth Report, stated that the Himalayan glaciers which feed the river, were at risk of melting by 2035. The IPCC has now withdrawn that prediction, as the original source admitted that it was speculative and the cited source was not a peer reviewed finding. In its statement, the IPCC stands by its general findings relating to the Himalayan glaciers being at risk from global warming (with consequent risks to water flow into the Gangetic basin). Many studies have suggested that the climate change will affect the water resources in the Ganges river basin including increased summer (monsoon) flow, and peak runoff could result in an increased risk of flooding.

The Ganges suffers from extreme pollution levels, caused by the 400 million people who live close to the river. Sewage from many cities along the river's course, industrial waste and religious offerings wrapped in non-degradable plastics add large amounts of pollutants to the river as it flows through densely populated areas. The problem is exacerbated by the fact that many poorer people rely on the river on a daily basis for bathing, washing, and cooking. The World Bank estimates that the health costs of water pollution in India equal three percent of India's GDP. It has also been suggested that eighty percent of all illnesses in India and one-third of deaths can be attributed to water-borne diseases.

Varanasi, a city of one million people that many pilgrims visit to take a "holy dip" in the Ganges, releases around 200 million litres of untreated human sewage into the river each day, leading to large concentrations of faecal coliform bacteria. According to official standards, water safe for bathing should not contain more than 500 faecal coliforms per 100ml, yet upstream of Varanasi's ghats the river water already contains 120 times as much, 60,000 faecal coliform bacteria per 100 ml.

After the cremation of the deceased at Varanasi's ghats the bones and ashes are thrown into the Ganges. However, in the past thousands of uncremated bodies were thrown into the Ganges during cholera epidemics, spreading the disease. Even today, holy men, pregnant women, people with leprosy/chicken pox, people who have been bitten by snakes, people who have committed suicide, the poor, and children under 5 are not cremated at the ghats but are left to float free, in order to decompose in the waters. In addition, those who cannot afford the large amount of wood needed to incinerate the entire body, leave behind a lot of half burned body parts.

After passing through Varanasi, and receiving 32 streams of raw sewage from the city, the concentration of fecal coliforms in the river's waters rises from 60,000 to 1.5 million, with observed peak values of 100 million per 100 ml. Drinking and bathing in its waters therefore carries a high risk of infection.

Between 1985 and 2000, Rs. 10 billion, around US$226 million, or less than 4 cents per person per year, were spent on the Ganga Action Plan, an environmental initiative that was "the largest single attempt to clean up a polluted river anywhere in the world." The Ganga Action Plan has been described variously as a "failure", a "major failure".

According to one study, 
The Ganga Action Plan, which was taken on priority and with much enthusiasm, was delayed for two years. The expenditure was almost doubled. But the result was not very appreciable. Much expenditure was done over the political propaganda. The concerning governments and the related agencies were not very prompt to make it a success. The public of the areas was not taken into consideration. The releasing of urban and industrial wastes in the river was not controlled fully. The flowing of dirty water through drains and sewers were not adequately diverted. The continuing customs of burning dead bodies, throwing carcasses, washing of dirty clothes by washermen, and immersion of idols and cattle wallowing were not checked. Very little provision of public latrines was made and the open defecation of lakhs of people continued along the riverside. All these made the Action Plan a failure.

The failure of the Ganga Action Plan, has also been variously attributed to "environmental planning without proper understanding of the human–environment interactions," Indian "traditions and beliefs," "corruption and a lack of technical knowledge" and "lack of support from religious authorities."

In December 2009 the World Bank agreed to loan India US$1 billion over the next five years to help save the river. According to 2010 Planning Commission estimates, an investment of almost Rs. 70 billion (Rs. 70 billion, approximately US$1.5 billion) is needed to clean up the river.

In November 2008, the Ganges, alone among India's rivers, was declared a "National River", facilitating the formation of a National Ganga River Basin Authority that would have greater powers to plan, implement and monitor measures aimed at protecting the river.

In July 2014, the Government of India announced an integrated Ganges-development project titled "Namami Ganga" and allocated 2,037 crore for this purpose.

In March 2017 the High Court of Uttarakhand declared the Ganges River a legal "person", in a move that according to one newspaper, "could help in efforts to clean the pollution-choked rivers." , the ruling has been commented on in Indian newspapers to be hard to enforce, that experts do not anticipate immediate benefits, that the ruling is "hardly game changing," that experts believe "any follow-up action is unlikely," and that the "judgment is deficient to the extent it acted without hearing others (in states outside Uttarakhand) who have stakes in the matter."

The incidence of water-borne and enteric diseases—such as gastrointestinal disease, cholera, dysentery, hepatitis A and typhoid—among people who use the river's waters for bathing, washing dishes and brushing teeth is high, at an estimated 66% per year.

Recent studies by Indian Council of Medical Research (ICMR) say that the river is so full of killer pollutants that those living along its banks in Uttar Pradesh, Bihar and Bengal are more prone to cancer than anywhere else in the country. Conducted by the National Cancer Registry Programme under the ICMR, the study throws up shocking findings indicating that the river is thick with heavy metals and lethal chemicals that cause cancer. According to Deputy Director General of NCRP A. Nandkumar, the incidence of cancer was highest in the country in areas drained by the Ganges and stated that the problem would be studied deeply and with the findings presented in a report to the health ministry.

Apart from that, many NGOs have came forward to rejuvenate river Ganga. Vikrant Tongad, an Environmental specialist from SAFE Green filed a petition against Simbhaoli Sugar Mill (Hapur UP) to NGT. NGT slapped a fine of Rs. 5 crore to Sugar Mill also, a fine of 25 Lakhs to Gopaljee Dairy for discharging untreated effluents into the Simbhaoli drain.

Along with ever-increasing pollution, water shortages are getting noticeably worse. Some sections of the river are already completely dry. Around Varanasi, the river once had an average depth of , but in some places, it is now only .

Illegal mining in the Ganges river bed for stones and sand for construction work has long been a problem in Haridwar district, Uttarakhand, where it touches the plains for the first time. This is despite the fact that quarrying has been banned in Kumbh Mela area zone covering 140 km area in Haridwar.






</doc>
<doc id="12449" url="https://en.wikipedia.org/wiki?curid=12449" title="Mobile Suit Gundam Wing">
Mobile Suit Gundam Wing

Mobile Suit Gundam Wing, also known in Japan as , is a 1995 Japanese mecha anime series directed by Masashi Ikeda and written by Katsuyuki Sumizawa. It is the sixth installment in the "Gundam" franchise, taking place in the "After Colony" timeline. As with the original series, the plot of "Gundam Wing" centers on a war in the future (specifically the 2220s) between Earth and its orbital colonies in the Earth-Moon system.

The series aired in Japan on the terrestrial TV Asahi network. It ran for 49 episodes; beginning on April 7, 1995 and ending on March 29, 1996. It received multiple manga adaptations, as well as video games. Four original video animation (OVA) episodes were produced including a retelling of the series, "Operation Meteor", and a direct sequel, "". In 2010, Sumizawa started writing the novel "", another sequel to the series. While the series fared modestly well in Japan, it found greater success in the United States and popularized the "Gundam" franchise in the West.

In the distant future, Mankind has colonized space, with clusters of space colonies at each of the five Earth-Moon Lagrange points. Down on the Earth, the nations have come together to form the United Earth Sphere Alliance. This Alliance oppresses the colonies with its vast military might. The colonies wishing to be free, join together in a movement headed by the pacifist Heero Yuy. In the year After Colony 175, Yuy is shot dead by an assassin, forcing the colonies to search for other paths to peace. The assassination prompts five disaffected scientists from the Organization of the Zodiac, more commonly referred to as OZ, to turn rogue upon the completion of the mobile suit prototype Tallgeese.

The story of "Gundam Wing" begins in the year After Colony 195, with the start of "Operation Meteor": the scientists' plan for revenge against OZ. The operation involves five teenage boys, who have each been chosen and trained by each of the five scientists, then sent to Earth independently in extremely advanced mobile suits (one designed by each of the scientists) known as "Gundams" (called such because they are constructed from a rare and astonishingly durable material called Gundanium alloy, which can only be created in outer space). Each Gundam is sent from a different colony, and the pilots are initially unaware of each other's existence.

The series focuses primarily on the five Gundam pilots: Heero Yuy (an alias, not to be confused with the martyred pacifist), Duo Maxwell, Trowa Barton, Quatre Raberba Winner and Chang Wufei. Their mission is to use their Gundams to attack OZ directly, in order to rid the Alliance of its weapons and free the colonies from its oppressive rule. The series also focuses on Relena Peacecraft, heir to the pacifist Sanc Kingdom, who starts off as a seemingly ordinary girl until she gets caught up in the conflict between OZ and the Gundams; becoming an important political ally to the Gundam pilots (particularly Heero) in the process.

The making of "Gundam Wing" was influenced by "Mobile Fighter G Gundam" with the idea of having five main characters. Originally, the series was meant to be titled "Gundam Meteor" after "Operation Meteor." Bandai suggested having a Gundam with the ability of transforming into a plane-like form. The writers worked together for one week conceptualizing the characters, mobile suits and first 40 episodes. Director Masashi Ikeda reacted to their work comparing it to the first "Gundam" series, "Zeta" and "G" all at once. The series was more focused on drama than mecha, which the staff credits as one of the reasons for the show's popularity within the female demographic.

Writer Katsuyuki Sumizawa expressed difficulties in the making of the story as opposed to his work in novels due to the fact he relayed duties to other members. However, the handling of the five characters was made easy due to the setting. Early sketches of the protagonists by Ikeda were handled by character designer Shuko Murase. He was cast due to his work with Ikeda in "Samurai Troopers". The director wanted the designs to appeal to the female demographic. Originally, Duo Maxwell was set as the protagonist but was replaced by Heero Yuy. The staff members noted Heero was too different from previous Gundam protagonists and were afraid he would be unpopular. The voice casting was more difficult to do than the ones from previous series due to the different atmosphere.

Following the series' ending, the staff members were asked by the studio to make a sequel due to its popularity. Neither Ikeda nor executive producer Hideyuki Tomioka intended to make a sequel for "Gundam Wing". However, Sumizawa was bothered by the finale as he felt the series ended abruptly. Tomioka asked Sumizawa if he could write a continuation which he agreed.

"Gundam Wing" was not the first series in the "Gundam" franchise to be dubbed and distributed in the U.S. (the compilation movie version of the original "Mobile Suit Gundam", as well as the OVAs "" and "", preceded it by about two years), but it is well known as the first "Gundam" series to be aired on American television. This dub was produced by Bandai Entertainment and the voice work was done by Ocean Productions. The series aired on Cartoon Network's weekday afternoon after-school programming block Toonami; premiering on March 6, 2000. In the first extended promo leading up to the series' premiere, voice actor Peter Cullen narrated the back story, evoking memories of "Voltron's" opening credits. The promo was said to be so riveting that Bandai decided to use it as the official promo for the series.

It was broadcast in two formats; an edited version shown in the daytime on Toonami and an uncut version shown past midnight as part of Toonami's "Midnight Run." Examples of the edits included the removal of blood, profanity, atheism, and the word "kill" being replaced with the word "destroy" (this was extended to Duo's nickname, "The God of Death," changed to "The Great Destroyer," forcing the alteration of two episode titles), though the word "death" was mostly left intact. All "Gundam Wing" episodes have been released to VHS and DVD in the U.S. Differences between the two video systems is that the VHS episodes contain the edited version while the DVD episodes contain the uncut version.

Due to the closure of Bandai Entertainment, the series was out-of-print for sometime. On October 11, 2014 at their 2014 New York Comic-Con panel, Sunrise announced they will be releasing all of the Gundam franchise, including "Gundam Wing" in North America though distribution from Right Stuf Inc., beginning in Spring 2015. Right Stuf released the series on Blu-ray and DVD in two sets in November 2017. In addition, a collector's edition set containing the complete series, "Endless Waltz", "Operation Meteor" and the "Frozen Teardrop" picture drama was released in December 2017.

After the series ended, four original video animation (OVA) episodes, compiling various scenes from the series along with a few minutes of new footage, were released in 1996 as "Gundam Wing: Operation Meteor" I and II. 

A three-part OVA titled "" was produced in 1997 as a sequel to the TV series; plot-wise, it brought the "After Colony" timeline to a close. The OVA was also notable for its massive redesigns of all the Gundams by Hajime Katoki, such as the Wing Gundam Zero's new "angel-winged" appearance. A compilation movie version of "Endless Waltz" (featuring additional footage, alterations of the music score and a different ending theme) was later released in Japan on August 1, 1998. "Endless Waltz" premiered on Cartoon Network in the U.S. on November 10, 2000. Both the OVA and movie versions of "Endless Waltz" were later released together on DVD. Right Stuf released both OVAs on Blu-ray and DVD in December 2017 (though "Operation Meteor" remains un-dubbed).

In addition to manga adaptations of the series and "Endless Waltz", several manga sidestories have also been produced. "" is a prequel, detailing the events leading up to series; the stories have been collected in a volume that also contains one brief open-ended interlude, "Preventer 5", that details an operation that occurs after "Endless Waltz". A coincident storyline to the series is presented in "". Several sequel manga, occurring between "Gundam Wing" and "Endless Waltz", have also been written: "Blind Target", "Ground Zero" and "Battlefield of Pacifists".

The "Gundam Wing", "Battlefield of Pacifists" and "Endless Waltz" manga series were published in English by Tokyopop, while "Blind Target", "Ground Zero" and "Episode Zero" were published by Viz Communications. Another sequel manga detailing the future of the colonies entitled "Tiel's Impulse" was printed in 1998 and has not been published in the United States.

In September 2010, "Gundam Ace" magazine began serializing a manga titled "New Mobile Report Gundam Wing Endless Waltz: The Glory of Losers" that retells the events of the anime while incorporating facts from "Episode Zero" and the novel "Frozen Teardrop". The manga also uses Hajime Katoki's Gundam redesigns from "Endless Waltz" and other subsequent media, instead of the original Kunio Okawara designs featured in the anime. Vertical began publishing English editions of the manga volumes, under the title "Mobile Suit Gundam Wing Endless Waltz: Glory of the Losers", in July 2017.

In early 2010, "Gundam Ace" magazine announced they would serialize a "New "Gundam Wing" Project". The project was eventually revealed to be a novel, titled "". Written by Katsuyuki Sumizawa, the novel begins a new timeline, following the "Mars Century" calendar ("MC") which was the successor of the previous "After Colony" calendar. According to an interview with the author, the novel spans backwards into the AC century and the Gundam pilots, Relena, and their children make appearances.

A fighting video game titled "" was developed by Natsume and released for the Super Famicom in Japan on March 29, 1996. A second fighting game titled "Shin Kidō Senki Gundam Wing: The Battle" was developed by Natsume and released for the PlayStation in Japan on October 11, 2002 as the 13th volume of the Simple Characters 2000 series. "Gundam Wing" characters and mecha have also appeared in several other video game series including "Super Robot Wars", "Gundam Battle Assault", "Another Century's Episode", "" and "".

Upon the series' debut in North America, "Gundam Wing" received a large roster of licensees for merchandise including wallscrolls, apparel, school supplies, skateboards, trading cards, model kits and action figures.




"Gundam Wing" was only a modest success in Japan during its initial run; it, along with "G Gundam", was the only "Gundam" series of the 1990s that managed an average television rating over four percent. It was ranked number two in "Animage" magazine's Anime Grand Prix in 1996 and was also ranked number 76 in the publication's list of the 100 most important anime of all time. The series is infamous within "dōjinshi" where authors tend to depict romantic relationships between several of the protagonists.

"Gundam Wing" was a greater success in North America, however, and is credited with single-handedly popularizing the "Gundam" franchise among Western audiences. Just over a week after its premiere on Cartoon Network on March 6, 2000, the series was the top rated program in all age groups. During the summer of 2000, it remained as the first or second top-rated show among kids and teens during its twelve airings per week on the Toonami block. "Gundam Wing" was ranked the 73rd best animated series by IGN, calling the series "so good that even those opposed to anime have to give the show its due credit".

 

 


</doc>
<doc id="12450" url="https://en.wikipedia.org/wiki?curid=12450" title="Gödel's completeness theorem">
Gödel's completeness theorem

Gödel's completeness theorem is a fundamental theorem in mathematical logic that establishes a correspondence between semantic truth and syntactic provability in first-order logic. It makes a close link between model theory that deals with what is true in different models, and proof theory that studies what can be formally proven in particular formal systems.

It was first proved by Kurt Gödel in 1929. It was then simplified in 1947, when Leon Henkin observed in his Ph.D. thesis that the hard part of the proof can be presented as the Model Existence Theorem (published in 1949). Henkin's proof was simplified by Gisbert Hasenjaeger in 1953.

There are numerous deductive systems for first-order logic, including systems of natural deduction and Hilbert-style systems. Common to all deductive systems is the notion of a formal deduction. This is a sequence (or, in some cases, a finite tree) of formulas with a specially-designated conclusion. The definition of a deduction is such that it is finite and that it is possible to verify algorithmically (by a computer, for example, or by hand) that a given sequence (or tree) of formulas is indeed a deduction.

A first-order formula is called logically valid if it is true in every structure for the language of the formula (i.e. for any assignment of values to the variables of the formula). To formally state, and then prove, the completeness theorem, it is necessary to also define a deductive system. A deductive system is called complete if every logically valid formula is the conclusion of some formal deduction, and the completeness theorem for a particular deductive system is the theorem that it is complete in this sense. Thus, in a sense, there is a different completeness theorem for each deductive system. A converse to completeness is soundness, the fact that only logically valid formulas are provable in the deductive system.

If some specific deductive system of first-order logic is sound and complete, then it is "perfect" (a formula is provable if and only if it is logically valid), thus equivalent to any other deductive system with the same quality (any proof in one system can be converted into the other).

We first fix a deductive system of first-order predicate calculus, choosing any of the well-known equivalent systems. Gödel's original proof assumed the Hilbert-Ackermann proof system.

The completeness theorem says that if a formula is logically valid then there is a finite deduction (a formal proof) of the formula.

Thus, the deductive system is "complete" in the sense that no additional inference rules are required to prove all the logically valid formulas. A converse to completeness is soundness, the fact that only logically valid formulas are provable in the deductive system. Together with soundness (whose verification is easy), this theorem implies that a formula is logically valid if and only if it is the conclusion of a formal deduction.

The theorem can be expressed more generally in terms of logical consequence. We say that a sentence "s" is a syntactic consequence of a theory "T", denoted formula_1, if "s" is provable from "T" in our deductive system. We say that "s" is a semantic consequence of "T", denoted formula_2, if "s" holds in every model of "T". The completeness theorem then says that for any first-order theory "T" with a well-orderable language, and any sentence "s" in the language of "T",

Since the converse (soundness) also holds, it follows that formula_2 iff formula_1, and thus that syntactic and semantic consequence are equivalent for first-order logic.

This more general theorem is used implicitly, for example, when a sentence is shown to be provable from the axioms of group theory by considering an arbitrary group and showing that the sentence is satisfied by that group.

Gödel's original formulation is deduced by taking the particular case of a theory without any axiom.

The completeness theorem can also be understood in terms of consistency, as a consequence of Henkin's model existence theorem. We say that a theory "T" is syntactically consistent if there is no sentence "s" such that both "s" and its negation ¬"s" are provable from "T" in our deductive system. The model existence theorem says that for any first-order theory "T" with a well-orderable language,

Another version, with connections to the Löwenheim–Skolem theorem, says:

Given Henkin's theorem, the completeness theorem can be proved as follows: If formula_9, then formula_10 does not have models. By the contrapositive of Henkin's, then formula_10 is syntactically inconsistent. So a contradiction (formula_12) is provable from formula_10 in the deductive system. Hence formula_14, and then by the properties of the deductive system, formula_1.

The Model Existence Theorem and its proof can be formalized in the framework of Peano arithmetic. Precisely, we can systematically define a model of any consistent effective first-order theory "T" in Peano arithmetic by interpreting each symbol of "T" by an arithmetical formula whose free variables are the arguments of the symbol. However, the definition expressed by this formula is not recursive.

An important consequence of the completeness theorem is that it is possible to recursively enumerate the semantic consequences of any effective first-order theory, by enumerating all the possible formal deductions from the axioms of the theory, and use this to produce an enumeration of their conclusions. 

This comes in contrast with the direct meaning of the notion of semantic consequence, that quantifies over all structures in a particular language, which is clearly not a recursive definition.

Also, it makes the concept of "provability," and thus of "theorem," a clear concept that only depends on the chosen system of axioms of the theory, and not on the choice of a proof system.

Gödel's second incompleteness theorem (see Gödel's incompleteness theorems), another celebrated result, shows that there are inherent limitations in what can be achieved with formal proofs in mathematics. The name for the incompleteness theorem refers to another meaning of "complete" (see model theory – Using the compactness and completeness theorems): A theory "T " is complete (or decidable) if for every formula "f" in the language of "T" either formula_16 or formula_17.

Gödel's second incompleteness theorem states that in any consistent effective theory "T" containing Peano arithmetic (PA), a formula "C" like "Cformula_18" expressing the consistency of "T" cannot be proven within "T".

The completeness theorem implies the existence of a model of "T" in which the formula "C" is false. Such a model (precisely, the set of "natural numbers" it contains) is necessarily a non-standard, as it contains the code number of a proof of a contradiction of "T".
But "T" is consistent when viewed from the outside. Thus this code number of a proof of contradiction of "T" must be a non-standard number.

In fact, the model of "any" theory containing PA obtained by the systematic construction of the arithmetical model existence theorem, is "always" non-standard with a non-equivalent provability predicate and a non-equivalent way to interpret its own construction, so that this construction is non-recursive (as recursive definitions would be unambiguous).

Also, there is no recursive non-standard model of PA.

The completeness theorem and the compactness theorem are two cornerstones of first-order logic. While neither of these theorems can be proven in a completely effective manner, each one can be effectively obtained from the other.

The compactness theorem says that if a formula φ is a logical consequence of a (possibly infinite) set of formulas Γ then it is a logical consequence of a finite subset of Γ. This is an immediate consequence of the completeness theorem, because only a finite number of axioms from Γ can be mentioned in a formal deduction of φ, and the soundness of the deductive system then implies φ is a logical consequence of this finite set. This proof of the compactness theorem is originally due to Gödel.

Conversely, for many deductive systems, it is possible to prove the completeness theorem as an effective consequence of the compactness theorem.

The ineffectiveness of the completeness theorem can be measured along the lines of reverse mathematics. When considered over a countable language, the completeness and compactness theorems are equivalent to each other and equivalent to a weak form of choice known as weak König's lemma, with the equivalence provable in RCA (a second-order variant of Peano arithmetic restricted to induction over Σ formulas). Weak König's lemma is provable in ZF, the system of Zermelo–Fraenkel set theory without axiom of choice, and thus the completeness and compactness theorems for countable languages are provable in ZF. However the situation is different when the language is of arbitrary large cardinality since then, though the completeness and compactness theorems remain provably equivalent to each other in ZF, they are also provably equivalent to a weak form of the axiom of choice known as the ultrafilter lemma. In particular, no theory extending ZF can prove either the completeness or compactness theorems over arbitrary (possibly uncountable) languages without also proving the ultrafilter lemma on a set of same cardinality, knowing that on countable sets, the ultrafilter lemma becomes equivalent to weak König's lemma.

The completeness theorem is a central property of first-order logic that does not hold for all logics. Second-order logic, for example, does not have a completeness theorem for its standard semantics (but does have the completeness property for Henkin semantics), and the set of logically-valid formulas in second-order logic is not recursively enumerable. The same is true of all higher-order logics. It is possible to produce sound deductive systems for higher-order logics, but no such system can be complete.

Lindström's theorem states that first-order logic is the strongest (subject to certain constraints) logic satisfying both compactness and completeness.

A completeness theorem can be proved for modal logic or intuitionistic logic with respect to Kripke semantics.

Gödel's original proof of the theorem proceeded by reducing the problem to a special case for formulas in a certain syntactic form, and then handling this form with an "ad hoc" argument.

In modern logic texts, Gödel's completeness theorem is usually proved with Henkin's proof, rather than with Gödel's original proof. Henkin's proof directly constructs a term model for any consistent first-order theory. James Margetson (2004) developed a computerized formal proof using the Isabelle theorem prover. Other proofs are also known.




</doc>
<doc id="12451" url="https://en.wikipedia.org/wiki?curid=12451" title="Global Boundary Stratotype Section and Point">
Global Boundary Stratotype Section and Point

A Global Boundary Stratotype Section and Point, abbreviated GSSP, is an internationally agreed upon reference point on a stratigraphic section which defines the lower boundary of a stage on the geologic time scale. The effort to define GSSPs is conducted by the International Commission on Stratigraphy, a part of the International Union of Geological Sciences. Most, but not all, GSSPs are based on paleontological changes. Hence GSSPs are usually described in terms of transitions between different faunal stages, though far more faunal stages have been described than GSSPs. The GSSP definition effort commenced in 1977. As of 2012, 64 of the 101 stages that need a GSSP have been formally defined.

A geologic section has to fulfill a set of criteria to be adapted as a GSSP by the ICS. The following list summarizes the criteria:


The Precambrian-Cambrian boundary GSSP at Fortune Head, Newfoundland is a typical GSSP. It is accessible by paved road and is set aside as a nature preserve. A continuous section is available from beds that are clearly Precambrian into beds that are clearly Cambrian. The boundary is set at the first appearance of a complex trace fossil "Treptichnus pedum" that is found worldwide. The Fortune Head GSSP is unlikely to be washed away or built over. Nonetheless, "Treptichnus pedum" is less than ideal as a marker fossil as it is not found in every Cambrian sequence, and it is not assured that it is found at the same level in every exposure. In fact, further eroding its value as a boundary marker, it has since been identified in strata 4m "below" the GSSP!
However, no other fossil is known that would be preferable. There is no radiometrically datable bed at the boundary at Fortune Head, but there is one slightly above the boundary in similar beds nearby.
These factors have led some geologists to suggest that this GSSP is in need of reassigning.

Once a GSSP boundary has been agreed upon, a "golden spike" is driven into the geologic section to mark the precise boundary for future geologists (though in practice the "spike" need neither be golden nor an actual spike). The first stratigraphic boundary was defined in 1977 by identifying the Silurian-Devonian boundary with a bronze plaque at a locality called Klonk, northeast of the village of Suchomasty in the Czech Republic. GSSPs are also sometimes referred to as Golden Spikes.

Because defining a GSSP depends on finding well-preserved geologic sections and identifying key events, this task becomes more difficult as one goes farther back in time. Before 630 million years ago, boundaries on the geologic timescale are defined simply by reference to fixed dates, known as "Global Standard Stratigraphic Ages".




</doc>
<doc id="12454" url="https://en.wikipedia.org/wiki?curid=12454" title="Gough Whitlam">
Gough Whitlam

Edward Gough Whitlam (; 11 July 191621 October 2014) was the 21st Prime Minister of Australia, serving from 1972 to 1975. The Leader of the Labor Party from 1967 to 1977, Whitlam led his party to power for the first time in 23 years at the 1972 election. He won the 1974 election before being controversially dismissed by the Governor-General of Australia, Sir John Kerr, at the climax of the 1975 Australian constitutional crisis. Whitlam remains the only Australian prime minister to have his commission terminated in that manner.

Whitlam served as an air navigator in the Royal Australian Air Force for four years during World War II, and worked as a barrister following the war. He was first elected to Parliament in 1952, representing Werriwa in the House of Representatives. Whitlam became Deputy Leader of the Labor Party in 1960, and in 1967, after the retirement of Arthur Calwell, was elected Leader and became the Leader of the Opposition. After narrowly losing the 1969 election, Whitlam led Labor to victory at the 1972 election after 23 years of continuous Liberal-Country Coalition Government.

The Whitlam Government implemented a large number of new programs and policy changes, including the termination of military conscription, institution of universal health care and free university education, and the implementation of legal aid programs. With the opposition-controlled Senate delaying passage of bills, Whitlam called a double dissolution election in 1974 in which he won a majority in the House of Representatives, albeit a slightly reduced one, and picked up three Senate seats. The Whitlam government then instituted the first and only joint sitting enabled under s. 57 of the Constitution as part of the double dissolution process. Despite the government's second election victory, the opposition, reacting to government scandals and a flagging economy suffering from the 1973 oil crisis and the 1973–75 recession, continued to obstruct the government's program in the Senate. In late 1975, the Opposition Senators refused to allow a vote on the government's appropriation bills, returning them to the House of Representatives with a demand that the government go to an election, thus denying the government supply. Whitlam refused to back down, arguing that his government, which held a clear majority in the House of Representatives, was being held to ransom by the Senate. The crisis ended on 11 November, when Whitlam arrived at a pre-arranged meeting with the Governor-General, Sir John Kerr, at Government House in order to call a half-Senate election. Kerr dismissed him and commissioned the opposition leader, Malcolm Fraser, as prime minister. Labor lost the subsequent election by a landslide.

Whitlam stepped down after losing again at the 1977 election, and retired from parliament in 1978. Upon the election of the Hawke Government in 1983, he was appointed as Ambassador to UNESCO, a position he filled with distinction, and was elected a member of the UNESCO Executive Board. He remained active into his nineties. The propriety and circumstances of his dismissal and the legacy of his government have been frequently debated in the decades after he left office.

Edward Gough Whitlam was born on 11 July 1916 at the family home 'Ngara', 46 Rowland Street, Kew, a suburb of Melbourne, the elder of two children (his sister, Freda, was born four years after him), to Martha (née Maddocks) and Fred Whitlam. His father was a federal public servant who later served as Commonwealth Crown Solicitor, and Whitlam senior's involvement in human rights issues was a powerful influence on his son. Since the boy's maternal grandfather was also named Edward, from early childhood he was called by his middle name, Gough, which in turn had come from his paternal grandfather, who had been named after the British soldier Field-Marshal Hugh Gough, 1st Viscount Gough.

In 1918, Fred Whitlam was promoted to deputy Crown solicitor and transferred to Sydney. The family lived first in the North Shore suburb of Mosman and then in Turramurra. At age six, Gough began his education at Chatswood Church of England Girls' School (early primary schooling at a girls' school was not unusual for small boys at the time). After a year there, he attended Mowbray House School and Knox Grammar School, in the suburbs of Sydney.

Fred Whitlam was promoted again in 1927, this time to Assistant Crown Solicitor. The position was located in the new national capital of Canberra, and the Whitlam family moved there. Gough Whitlam remains the only prime minister to have spent his formative years in Canberra. At the time, conditions remained primitive in what was dubbed "the bush capital" and "the land of the blowflies". Gough attended the government Telopea Park School. In 1932, Whitlam's father transferred him to Canberra Grammar School where, at the Speech Day ceremony that year, he was awarded a prize by the Governor-General, Sir Isaac Isaacs.

Whitlam enrolled at St Paul's College at the University of Sydney at the age of 18. He earned his first wages by appearing, with several other "Paulines", in a cabaret scene in the film "The Broken Melody"—the students were chosen because St Paul's requires formal wear at dinner, and they could therefore supply their own costumes. After receiving a Bachelor of Arts degree with second-class honours in classics, Whitlam remained at St Paul's to begin his law studies. He had originally contemplated an academic career, but his lacklustre marks made that unlikely. Dropping out of Greek classes, he professed himself unable to care for the "dry as dust" lectures of Enoch Powell.

Soon after the outbreak of World War II in 1939, Whitlam enlisted in the Sydney University Regiment, part of the Militia. In late 1941, following the Japanese attack on Pearl Harbor, and with a year remaining in his legal studies, he volunteered for the Royal Australian Air Force (RAAF). In 1942, while awaiting entry into the service, Whitlam met and married Margaret Elaine Dovey, who had swum for Australia in the 1938 British Empire Games and was the daughter of barrister and future New South Wales Supreme Court judge Bill Dovey. He entered the RAAF on 20 June 1942.

Whitlam trained as a navigator and bomb aimer, before serving with No. 13 Squadron RAAF, based mainly on the Gove Peninsula, Northern Territory, flying Lockheed Ventura bombers. He reached the rank of Flight Lieutenant. While in the service, he began his political activities, distributing literature for the Australian Labor Party during the 1943 federal election and urging the passage of the "Fourteen Powers" referendum of 1944, which would have expanded the powers of the federal government. Although the party was victorious, the referendum it advocated was defeated. In 1961, Whitlam said of the referendum defeat, "My hopes were dashed by the outcome and from that moment I determined to do all I could do to modernise the Australian Constitution." While still in uniform, Whitlam joined the ALP in Sydney in 1945. He was discharged from the RAAF on 17 October 1945, and continued to use Air Force log books to record all of the flights he took until 2007. Whitlam completed his studies after the war, obtained his Bachelor of Laws, and was admitted to the federal and New South Wales bars in 1947.

With his war service loan, Whitlam built a house in seaside Cronulla. He also bought the block of land next door, using the prize money (£1,000 in security bonds) he received for winning the Australian National Quiz Championship in 1948 and 1949 (he was runner-up in 1950). He sought to make a career in the ALP there, but local Labor supporters were sceptical of Whitlam's loyalties, given his privileged background. In the postwar years, he practised law, concentrating on landlord/tenant matters, and sought to build his bona fides in the party. He ran twice—unsuccessfully—for the local council, once (also unsuccessfully) for the New South Wales Legislative Assembly, and campaigned for other candidates. In 1951, Bert Lazzarini, the Labor member for the Federal electorate of Werriwa, announced that he would stand down at the next election. Whitlam won the preselection as ALP candidate. Lazzarini died in 1952 before completing his term and Whitlam was elected to the House of Representatives in the ensuing by-election on 29 November 1952. Whitlam trebled Lazzarini's majority in a 12 per cent swing to Labor.

Whitlam joined the ALP minority in the House of Representatives. His maiden speech provoked an interruption by a future prime minister, John McEwen, who was then told by the Speaker that maiden speeches are traditionally heard in silence. Whitlam responded to McEwen by stating that Benjamin Disraeli had been heckled in his maiden speech and had responded, "The time will come when you shall hear me." He told McEwen, "The time will come when you may interrupt me." According to early Whitlam biographers Laurie Oakes and David Solomon, this cool response put the Coalition government on notice that the new Member for Werriwa would be a force to be reckoned with.

In the rough and tumble debate in the House of Representatives, Whitlam called fellow MHR Bill Bourke "this grizzling Quisling", Garfield Barwick (who would, as High Court Chief Justice, play a role in Whitlam's downfall) a "bumptious bastard", and stated that Bill Wentworth exhibited a "hereditary streak of insanity". After calling future prime minister William McMahon a "quean", he apologised.

The ALP had been out of office since the Chifley Government's defeat in 1949 and, since 1951, had been under the leadership of Bert Evatt, whom Whitlam greatly admired. In 1954, the ALP seemed likely to return to power. The Prime Minister, Robert Menzies, adroitly used the defection of a Soviet official to his advantage, and his coalition of the Liberal and Country parties was returned in the 1954 election with a seven-seat majority. After the election, Evatt attempted to purge the party of industrial groupers, who had long dissented from party policy, and who were predominantly Catholic and anti-communist. The ensuing division in the ALP, which came to be known as "The Split", sparked the birth of the Democratic Labor Party (DLP). It was a conflict that helped to keep Labor out of power for a generation, since DLP supporters chose the Liberal Party in preferential voting. Whitlam supported Evatt throughout this period.

In 1955, a redistribution divided Whitlam's electorate of Werriwa in two, with his Cronulla home located in the new electorate of Hughes. Although Whitlam would have received ALP support in either division, he chose to continue standing for Werriwa and moved from Cronulla to Cabramatta. This meant even longer journeys for his older children to attend school, since neither electorate had a high school at the time, and they attended school in Sydney.

Whitlam was appointed to the Parliamentary Joint Committee on Constitutional Review in 1956. Biographer Jenny Hocking calls his service on the committee, which included members from all parties in both chambers of Parliament, one of the "great influences in his political development". According to Hocking, service on the committee caused Whitlam to focus not on internal conflicts consuming the ALP, but on Labor goals which were possible and worthwhile in the constitutional framework. Many Labor goals, such as nationalisation, ran contrary to the Constitution. Whitlam came to believe that the Constitution—and especially Section 96 (which allowed the federal government to make grants to the states)—could be used to advance a worthwhile Labor programme.

By the late 1950s Whitlam was seen as a leadership contender once the existing Labor leaders exited the scene. Most of the party's major figures, including Evatt, Deputy Leader Arthur Calwell, Eddie Ward, and Reg Pollard, were in their sixties, twenty years older than Whitlam. In 1960, after losing three elections, Evatt resigned and was replaced by Calwell, with Whitlam defeating Ward for deputy leader. Calwell came within a handful of votes of winning the cliffhanger 1961 election. He had not wanted Whitlam as deputy leader, and believed Labor would have won if Ward had been in the position.

Soon after the 1961 election, events began to turn against Labor. When President Sukarno of Indonesia announced that he intended to take over West New Guinea as the colonial Dutch departed, Calwell responded by declaring that Indonesia must be stopped by force. Calwell's statement was called "crazy and irresponsible" by Prime Minister Menzies, and the incident reduced public support for the ALP. At that time, the Federal Conference of the Labor Party, which dictated policy to parliamentary members, consisted of six members from each state, but not Calwell or Whitlam. In early 1963 a special conference met in a Canberra hotel to determine Labor policy regarding a proposed US base in northern Australia; Calwell and Whitlam were photographed by "The Daily Telegraph" peering in through the doors, waiting for the verdict. In an accompanying story, Alan Reid of the "Telegraph" wrote that Labor was ruled by "36 faceless men". The Liberals seized on it, issuing a leaflet called "Mr Calwell and the Faceless Men" which accused Calwell and Whitlam of taking direction from "36 unknown men, not elected to Parliament nor responsible to the people."

Menzies manipulated the Opposition on issues that bitterly divided it, such as direct aid to the states for private schools, and the proposed base. He called an early election for November 1963, standing in support of those two issues. The Prime Minister performed better than Calwell on television and received an unexpected boost after the assassination of US President John F. Kennedy. As a result, the Coalition easily defeated Labor on a 10-seat swing. Whitlam had hoped Calwell would step down after 1963, but he remained, reasoning that Evatt had been given three opportunities to win, and that he should be allowed a third try. Calwell dismissed proposals that the ALP leader and deputy leader should be entitled to membership of the party's conference (or on its governing 12-person Federal Executive, which had two representatives from each state), and instead ran successfully for one of the conference's Victoria seats. Labor did badly in a 1964 by-election in the Tasmanian electorate of Denison, and lost seats in the 1964 half-Senate election. The party was also defeated in the state elections in the most populous state, New South Wales, surrendering control of the state government for the first time since 1941.

Whitlam's relationship with Calwell, never good, deteriorated further after publication of a 1965 article in "The Australian". The article reported off-the-record comments Whitlam had made that his leader was "too old and weak" to win office, and that the party might be gravely damaged by an "old-fashioned" 70-year-old Calwell seeking his first term as prime minister. Later that year, at Whitlam's urging, and over Calwell's objection, the biennial party conference made major changes to the party's platform: deleting support for the White Australia policy and making the ALP's leader and deputy leader "ex officio" members of the conference and executive, along with the party's leader and deputy leader in the Senate. As Whitlam considered the Senate unrepresentative, he opposed the admission of its ALP leaders to the party's governing bodies.

Menzies retired in January 1966, and was succeeded as prime minister by the new Liberal Party leader, Harold Holt. After years of politics being dominated by the elderly Menzies and Calwell, the younger Holt was seen as a breath of fresh air, and attracted public interest and support in the run-up to the November election.

In early 1966, the 36-member conference, with Calwell's assent, banned any ALP parliamentarian from supporting federal assistance to the states for spending on both government and private schools, commonly called "state aid". Whitlam broke with the party on the issue, and was charged with gross disloyalty by the executive, an offence which carried the penalty of expulsion from the party. Before the matter could be heard, Whitlam left for Queensland, where he campaigned intensively for the ALP candidate Rex Patterson in the Dawson by-election. The ALP won, dealing the government its first by-election defeat since 1952. Whitlam survived the expulsion vote by a margin of only two, gaining both Queensland votes. At the end of April, Whitlam challenged Calwell for the leadership; though Calwell received two-thirds of the vote, he announced that if the party lost the upcoming election, he would not stand again for the leadership.

Holt called an election for November 1966, in which Australia's involvement in the Vietnam War was a major issue. Calwell called for an "immediate and unconditional withdrawal" of Australian troops from Vietnam. Whitlam, however, said that this would deprive Australia of any voice in a settlement, and that regular troops, rather than conscripts, should remain under some circumstances. Calwell considered Whitlam's remark disastrous, disputing the party line just five days before the election. The ALP suffered a crushing defeat; the party was reduced to 41 seats in the House of Representatives. Shortly after the election, Whitlam faced another expulsion vote for his stance on Vietnam, and survived. True to his word, Calwell resigned two months after the election. At the caucus meeting on 8 February 1967, Whitlam was elected party leader, defeating leading left-wing candidate Dr Jim Cairns.

Whitlam believed the Labor Party had little chance of being elected unless it could expand its appeal from the traditional working-class base to include the suburban middle class. He sought to shift control of the ALP from union officials to the parliamentary party, and hoped that even rank-and-file party members could be given a voice in the conference. In 1968, controversy erupted within the party when the executive refused to seat new Tasmanian delegate Brian Harradine, a Whitlam supporter who was considered a right-wing extremist. Whitlam resigned the leadership, demanding a vote of confidence from caucus. He defeated Cairns for the leadership in an unexpectedly close 38–32 vote. Despite the vote, the executive refused to seat Harradine.

With the ALP's governing bodies unwilling to reform themselves, Whitlam worked to build support for change among ordinary party members. He was successful in reducing union influence in the party, though he was never able to give the rank and file a direct vote in selecting the executive. The Victoria branch of the party had long been a problem; its executive was far to the left of the rest of the ALP, and had little electoral success. Whitlam was able to reconstruct the Victoria party organisation against the will of its leaders, and the reconstituted state party proved essential to victory in the 1972 election.

By the time of the 1969 party conference, Whitlam had gained considerable control over the ALP. That conference passed 61 resolutions, including broad changes to party policy and procedures. It called for the establishment of an Australian Schools Commission to consider the proper level of state aid for schools and universities, recognition of Aboriginal land claims, and expanded party policy on universal health care. The conference also called for increased federal involvement in urban planning, and would form the basis of "The Program" of modern socialism which Whitlam and the ALP would present to the voters in 1972.

Since 1918, Labor had called for the abolition of the existing Australian Constitution, with the vesting of all political power in Parliament, a plan which would turn the states into powerless geographic regions. Beginning in 1965, Whitlam had sought to change this goal. He finally succeeded at the 1971 ALP Conference in Launceston, Tasmania, which called for Parliament to receive "such plenary powers as are necessary and desirable" to achieve the ALP's goals in domestic and international affairs. Labor also pledged to abolish the Senate; this goal would not be erased from the party platform until 1979, after Whitlam had stepped down as leader.

Soon after taking the leadership, Whitlam reorganised the ALP caucus, assigning portfolios and turning the Labor frontbench into a shadow cabinet. While the Liberal-Country Coalition had a huge majority in the House of Representatives, Whitlam energised the party by campaigning intensively to win two by-elections in 1967: first in Corio in Victoria, and later that year in Capricornia (Queensland). The November half-Senate election saw a moderate swing to Labor and against the Coalition, compared with the general election the previous year. These federal victories, in which both Whitlam and Holt campaigned, helped give Whitlam the leverage he needed to carry out party reforms.

At the end of 1967, Holt vanished while swimming in rough seas near Melbourne; his body was never recovered. John McEwen, as leader of the junior Coalition partner, the Country Party, took over as prime minister for three weeks until the Liberals could elect a new leader. Senator John Gorton won the vote and became prime minister. The leadership campaign was conducted mostly by television, and Gorton appeared to have the visual appeal needed to keep Whitlam out of office. Gorton resigned his seat in the Senate, and in February 1968 won the by-election for Holt's seat of Higgins in Victoria. For the remainder of the year, Gorton appeared to have the better of Whitlam in the House of Representatives. In his chronicle of the Whitlam years, however, speechwriter Graham Freudenberg asserts that Gorton's erratic behaviour, Whitlam's strengthening of his party, and events outside Australia (such as the Vietnam War) ate away at Liberal dominance.

Gorton called an election for October 1969. Whitlam and the ALP, with little internal dissension, stood on a platform calling for domestic reform, an end to conscription, and the withdrawal of Australian troops from Vietnam by 1 July 1970. Whitlam knew that, given the ALP's poor position after the 1966 election, victory was unlikely. Nevertheless, Whitlam scored an 18-seat swing, Labor's best performance since losing government in 1949. It also scored a 7.1 percent two-party swing, the largest to not result in a change of government. Although the Coalition was returned for an eighth term in government, it was with a slim majority of three seats, down from 19 after the writs were dropped. Labor actually won a bare majority of the two-party vote; only DLP preferences in four Melbourne-area seats kept Whitlam from becoming prime minister. The 1970 half-Senate election brought little change to Coalition control, but the Liberal vote fell for the first time below 40 per cent, representing a severe threat to Gorton's leadership.

In March 1971, the resentment against Gorton came to a head when a confidence vote in the Liberal caucus resulted in a tie. Declaring that this was a sign he no longer had the confidence of the party, Gorton resigned, and William McMahon was elected his successor. With the Liberals in turmoil, Whitlam and the ALP sought to gain public trust as a credible government-in-waiting. The party's actions, such as its abandonment of the White Australia policy, gained favourable media attention. The Labor leader flew to Papua New Guinea and pledged himself to the independence of what was then an Australian possession. In 1971, Whitlam flew to Beijing and met with Chinese officials, including Zhou Enlai. McMahon attacked Whitlam for the visit and claimed that the Chinese had manipulated him. This attack backfired when US President Richard Nixon announced that he would visit China the following year. His National Security Advisor, Henry Kissinger, visited Beijing between 9–11 July (less than a week after Whitlam's visit of 4–6 July), and (unknown to Whitlam) some of Kissinger's staff had actually been in Beijing preparing for Kissinger's visit at the same time as the Labor delegation. According to Whitlam biographer Jenny Hocking, the incident transformed Whitlam into an international statesman, while McMahon was seen as reacting defensively to Whitlam's foreign policy ventures. Other errors by McMahon, such as a confused ad-lib speech while visiting Washington, and a statement to Indonesia's President Suharto that Australia was a "west European nation", also damaged the government.

By early 1972, Labor had established a clear lead in the polls; indeed, for the first time since 1955 its support was greater than the combined vote for the Coalition and DLP. Unemployment was at a ten-year peak, rising to 2.14 percent in August (though the unemployment rate was calculated differently compared to the present, and did not include thousands of rural workers on Commonwealth-financed relief work). Inflation was also at its highest rate since the early 1950s. The government recovered slightly in the August Budget session of Parliament, proposing income tax cuts and increased spending. The Labor strategy for the run-up to the election was to sit back and allow the Coalition to make mistakes. Whitlam controversially stated in March that "draft-dodging is not a crime" and that he would be open to a revaluation of the Australian dollar. With the Coalition sinking in the polls and his own personal approval ratings down as low as 28 percent, McMahon waited as long as he could, finally calling an election for the House of Representatives for 2 December. Whitlam noted that the polling day was the anniversary of the Battle of Austerlitz – at which another "ramshackle, reactionary coalition" had been given a "crushing defeat".

Labor campaigned under the slogan "It's Time", an echo of Menzies' successful 1949 slogan, "It's Time for a Change". Surveys showed that even Liberal voters approved of the Labor slogan. Whitlam pledged an end to conscription and the release of individuals who had refused the draft; an income tax surcharge to pay for universal health insurance; free dental care for students; and renovation of aging urban infrastructure. The party pledged to eliminate university tuition fees and establish a schools commission to evaluate educational needs. The party benefited from the support of the proprietor of News Limited, Rupert Murdoch, who preferred Whitlam over McMahon. Labor was so dominant in the campaign that some of Whitlam's advisers urged him to stop joking about McMahon; people were feeling sorry for him. The election saw the ALP increase its tally by 12 seats, mostly in suburban Sydney and Melbourne, for a majority of nine in the House of Representatives. The ALP gained little beyond the suburban belts, however, losing a seat in South Australia and two in Western Australia.

Whitlam took office with a majority in the House of Representatives, but without control of the Senate (elected in the 1967 and 1970 half-elections). The Senate at that time consisted of ten members from each of the six states, elected by proportional representation. Historically, when Labor won government, the parliamentary caucus chose the ministers, with the party leader only having the power to assign portfolios. However, the new Labor caucus would not meet until after the final results came in on 15 December. In the meantime, McMahon would remain caretaker prime minister. Whitlam, however, was unwilling to wait that long. On 5 December, with Labor's win beyond doubt even though counting was still underway, Whitlam had the Governor-General, Sir Paul Hasluck, swear him in as prime minister and Labor's deputy leader, Lance Barnard, as deputy prime minister. The two men held 27 portfolios during the two weeks before a full cabinet could be determined.

During the two weeks the so-called "duumvirate" held office, Whitlam sought to fulfill those campaign promises that did not require legislation. Whitlam ordered negotiations to establish full relations with the People's Republic of China, and broke those with Taiwan. Legislation allowed the defence minister to grant exemptions from conscription. Barnard held this office, and exempted everyone. Seven men were at that time incarcerated for refusing conscription; Whitlam arranged for their liberation. The Whitlam government in its first days reopened the equal pay case pending before the Commonwealth Conciliation and Arbitration Commission, and appointed a woman, Elizabeth Evatt, to the commission. Whitlam and Barnard eliminated sales tax on contraceptive pills, announced major grants for the arts, and appointed an interim schools commission. The duumvirate barred racially discriminatory sports teams from Australia, and instructed the Australian delegation at the United Nations to vote in favour of sanctions on apartheid South Africa and Rhodesia. It also ordered the Australian Army Training Team home from Vietnam, ending Australia's involvement in the war; most troops (including all conscripts) had been withdrawn by McMahon.
According to Whitlam speechwriter Graham Freudenberg, the duumvirate was a success, as it showed that the Labor government could manipulate the machinery of government, despite almost a quarter-century in opposition. However, Freudenberg noted that the rapid pace and public excitement caused by the duumvirate's actions caused the Opposition to be wary of giving Labor too easy a time, and gave rise to one post-mortem assessment of the Whitlam government: "We did too much too soon."

The McMahon government had consisted of 27 ministers, twelve of whom comprised the Cabinet. In the run-up to the election, the Labor caucus had decided that should the party take power, all 27 ministers were to be Cabinet members. Intense canvassing took place amongst ALP parliamentarians as the duumvirate did its work, and on 18 December the caucus elected the Cabinet. The results were generally acceptable to Whitlam, and within three hours, he had announced the portfolios of the Cabinet members. To give himself greater control over the Cabinet, in January 1973 Whitlam established five Cabinet committees (with the members appointed by himself, not the caucus) and took full control of the Cabinet agenda.

Gough Whitlam, prime minister for fewer than three years between 1972 and 1975, pushed through a raft of reforms that radically changed Australia's economic, legal and cultural landscape.

The Whitlam government abolished the death penalty for federal crimes. Legal aid was established, with offices in each state capital. It abolished university fees, and established the Schools Commission to allocate funds to schools. Whitlam founded the Department of Urban Development and, having lived in developing Cabramatta, most of which lacked sewage facilities, set a goal to leave no urban home unsewered. The Whitlam government gave grants directly to local government units for urban renewal, flood prevention, and the promotion of tourism. Other federal grants financed highways linking the state capitals, and paid for standard-gauge rail lines between the states. The government attempted to set up a new city at Albury–Wodonga on the Victoria–New South Wales border. The process was started for "Advance Australia Fair" to become the country's national anthem in place of "God Save the Queen". The Order of Australia replaced the British honours system in early 1975.

In 1973, the National Gallery of Australia, then called the Australian National Gallery, bought the painting "Blue Poles" by contemporary artist Jackson Pollock for US$2 million (A$1.3 million at the time of payment) – about a third of its annual budget. This required Whitlam's personal permission, which he gave on the condition the price was publicized. The purchase created a political and media scandal, and was said to symbolise, alternatively, Whitlam's foresight and vision or his profligate spending.

Whitlam travelled extensively as prime minister, and was the first Australian prime minister to visit China while in office. He was criticised for making this visit, especially after Cyclone Tracy struck Darwin; he interrupted an extensive tour of Europe for 48 hours (deemed too brief a period by many) to view the devastation.

From the start of the Whitlam government, the Opposition, led by Billy Snedden (who replaced McMahon as Liberal leader in December 1972) sought to use control of the Senate to baulk Whitlam. It did not seek to block all government legislation; the Coalition senators, led by Senate Liberal leader Reg Withers, sought to block government legislation only when the obstruction would advance the Opposition's agenda. The Whitlam government also had troubles in relations with the states. New South Wales refused the government's request that it close the Rhodesian Information Centre in Sydney. The Queensland premier, Joh Bjelke-Petersen refused to consider any adjustment in Queensland's border with Papua New Guinea, which, due to the state's ownership of islands in the Torres Strait, came within half a kilometre (about one-third of a mile) of the Papuan mainland. Liberal state governments in New South Wales and Victoria were re-elected by large margins in 1973. Whitlam and his majority in the House of Representatives proposed a constitutional referendum in December 1973, transferring control of wages and prices from the states to the federal government. The two propositions failed to attract a majority of voters in any state, and were rejected by over 800,000 votes nationwide.

In 1974, the Senate had refused to pass six bills after their twice being passed by the House of Representatives. With the Opposition threatening to disrupt money supply to government, Whitlam used the Senate's recalcitrance to trigger a double dissolution election, holding it instead of the half-Senate election. After a campaign featuring the Labor slogan "Give Gough a fair go", the Whitlam government was returned, with its majority in the House of Representatives cut from seven to five and increasing its Senate seats by three. It was only the second time since Federation that a Labor government had been elected to a second full term. The government and the opposition each had 29 Senators with two seats held by independents. The deadlock over the twice-rejected bills was broken, uniquely in Australian history, with a special joint sitting of the two houses of Parliament under Section 57 of the Constitution. This session, authorised by the new governor-general, Sir John Kerr, passed bills providing for universal health insurance (known then as Medibank, today as Medicare) and providing the Northern Territory and Australian Capital Territory with representation in the Senate, effective at the next election.

In February 1973, the Attorney General, Senator Lionel Murphy, led a police raid on the Melbourne office of the Australian Security Intelligence Organisation, which was under his ministerial responsibility. Murphy believed that ASIO might have files relating to threats against Yugoslav Prime Minister Džemal Bijedić, who was about to visit Australia, and feared ASIO might conceal or destroy them. The Opposition attacked the Government over the raid, terming Murphy a "loose cannon". A Senate investigation of the incident was cut short when Parliament was dissolved in 1974. According to journalist and author Wallace Brown, the controversy over the raid continued to dog the Whitlam government throughout its term, because the incident was "so silly".

By early 1974, the Senate had rejected nineteen government bills, ten of them twice. With a half-Senate election due by mid-year, Whitlam looked for ways to shore up support in that body. Queensland senator and former DLP leader Vince Gair signalled his willingness to leave the Senate for a diplomatic post. Gair's term would not expire until the following half-Senate election (or upon a double dissolution election). With five Queensland seats at stake in the half-Senate election, the ALP would probably win only two, but if six (including Gair's) were at stake, the party likely would win a third. Possible control of the Senate was therefore at stake; Whitlam agreed to Gair's request and had Governor-General Sir Paul Hasluck appoint him ambassador to Ireland. Word leaked of Gair's pending resignation, and Whitlam's opponents attempted to counteract his manoeuvre. On what became known as the "Night of the Long Prawns", Country Party members secreted Gair at a small party in a legislative office as the ALP searched for him to secure his written resignation. As Gair enjoyed beer and prawns, Bjelke-Petersen advised the Queensland governor, Sir Colin Hannah, to issue writs for only the usual five vacancies, since Gair's seat was not yet vacant, effectively countering Whitlam's plan.

By mid-1974, Australia was in an economic slump, suffering from the 1973 oil crisis and 1973–75 recession. The 1973 oil crisis had caused prices to spike and, according to government figures, inflation topped 13 percent for over a year between 1973 and 1974. Part of the inflation was due to Whitlam's desire to increase wages and conditions of the Commonwealth Public Service as a pacesetter for the private sector. The Whitlam government had cut tariffs by 25 percent in 1973; 1974 saw an increase in imports of 30 percent and a $1.5 billion increase in the trade deficit. Primary producers of commodities such as beef were caught in a credit squeeze as short-term rates rose to extremely high levels. Unemployment also rose significantly. Unease within the ALP led to Barnard's defeat when Jim Cairns challenged him for his deputy leadership. Whitlam gave little help to his embattled deputy, who had formed the other half of the duumvirate.

Despite these economic indicators, the Budget presented in August 1974 saw large increases in spending, especially in education. Treasury officials had advised a series of tax and fee increases, ranging from excise taxes to the cost of posting a letter; their advice was mostly rejected by Cabinet. The Budget was unsuccessful in dealing with the inflation and unemployment, and Whitlam introduced large tax cuts in November. He also announced additional spending to help the private sector.

Beginning in October 1974, the Whitlam government sought overseas loans to finance its development plans, with the newly enriched oil nations a likely target. Whitlam attempted to secure financing before informing the Loan Council (which included state officials hostile to Whitlam), and his government empowered Pakistani financier Tirath Khemlani as an intermediary in the hope of securing US$4 billion in loans. While the Loans Affair never resulted in an actual loan, according to author and Whitlam speechwriter Graham Freudenberg, "The only cost involved was the cost to the reputation of the Government. That cost was to be immense—it was government itself."

Whitlam appointed Senator Murphy to the High Court, even though Murphy's Senate seat would not be up for election if a half-Senate election were held. Labor then held three of the five short-term New South Wales Senate seats. Under proportional representation, Labor could hold its three short-term seats in the next half-Senate election but, if Murphy's seat were also contested, Labor was unlikely to win four out of six. Thus, a Murphy appointment meant the almost certain loss of a seat in the closely divided Senate at the next election. Whitlam appointed Murphy anyway. By convention, senators appointed by the state legislature to fill casual vacancies were from the same political party as the former senator. The New South Wales premier, Tom Lewis felt that this convention only applied to vacancies caused by deaths or ill-health, and arranged for the legislature to elect Cleaver Bunton, former mayor of Albury and an independent. By March 1975, many Liberal parliamentarians felt that Snedden was doing an inadequate job as leader of the Opposition, and that Whitlam was dominating him in the House of Representatives. Malcolm Fraser challenged Snedden for the leadership, and defeated him on 21 March.

Soon after Fraser's accession, controversy arose over the Whitlam government's actions in trying to restart peace talks in Vietnam. As the North prepared to end the civil war, Whitlam sent cables to both Vietnamese governments, telling Parliament that both cables were substantially the same. The Opposition contended he had misled Parliament, and a motion to censure Whitlam was defeated along party lines. The Opposition also attacked Whitlam for not allowing enough South Vietnamese refugees into Australia, with Fraser calling for the entry of 50,000. Freudenberg alleges that 1,026 Vietnamese refugees entered Australia in the final eight months of the Whitlam government, and only 399 in 1976 under Fraser. However, by 1977, Australia had accepted over five thousand refugees.

As the political situation deteriorated, Whitlam and his government continued to enact legislation: The Family Law Act 1975 provided for no-fault divorce while the Racial Discrimination Act 1975 caused Australia to ratify the International Convention on the Elimination of All Forms of Racial Discrimination that Australia had signed under Holt, but which had never been ratified. In August 1975, Whitlam gave the Gurindji people of the Northern Territory title deeds to part of their traditional lands, beginning the process of Aboriginal land reform. The next month, Australia granted independence to Papua New Guinea.
Following the 1974 Carnation Revolution, Portugal began a process of decolonisation and began a withdrawal from Portuguese Timor (later East Timor). Australians had long taken an interest in the colony; the nation had sent troops to the region during World War II, and many East Timorese had fought the Japanese as guerrillas. In September 1974, Whitlam met with President Suharto in Indonesia and indicated that he would support Indonesia if it annexed East Timor. At the height of the Cold War, and in the context of the American retreat from Indo-China, he felt that incorporation of East Timor into Indonesia would enhance the stability of the region, and reduce the risk of the East Timorese FRETILIN movement, which many feared was communist, coming to power.

Whitlam had offered Barnard a diplomatic post; in early 1975 Barnard agreed to this, triggering a by-election in his Tasmanian electorate of Bass. The election on 28 June proved a disaster for Labor, which lost the seat with a swing against it of 17 percent. The next week, Whitlam fired Barnard's successor as deputy prime minister, Cairns, who had misled Parliament regarding the Loans Affair amid controversy about his relationship with his office manager, Junie Morosi. At the time of Cairns's dismissal, one Senate seat was vacant, following the death on 30 June of Queensland ALP Senator Bertie Milliner. The state Labor party nominated Mal Colston, resulting in a deadlock. The unicameral Queensland legislature twice voted against Colston, and the party refused to submit any alternative candidates. Bjelke-Petersen finally convinced the legislature to elect a low-level union official, Albert Field, who had contacted his office and expressed a willingness to serve. In interviews, Field made it clear he would not support Whitlam. Field was expelled from the ALP for standing against Colston, and Labor senators boycotted his swearing-in. Whitlam argued that, because of the manner of filling vacancies, the Senate was "corrupted" and "tainted", with the Opposition enjoying a majority they did not win at the ballot box.

In October 1975, the Opposition, led by Malcolm Fraser, determined to withhold supply by deferring consideration of appropriation bills. With Field on leave (his Senate appointment having been challenged), the Coalition had an effective majority of 30–29 in the Senate. The Coalition believed that if Whitlam could not deliver supply, and would not advise new elections, Kerr would have to dismiss him. Supply would run out on 30 November.

The stakes were raised in the conflict on 10 October, when the High Court declared valid the Act granting the territories two senators each. In a half-Senate election, most successful candidates would not take their places until 1 July 1976, but the territories' senators, and those filling Field's and Bunton's seats, would assume their seats immediately. This gave Labor an outside chance of controlling the Senate, at least until 1 July 1976.

On 14 October, Labor minister Rex Connor, mastermind of the loans scheme, was forced to resign when Khemlani released documents showing that Connor had made misleading statements. The continuing scandal bolstered the Coalition in their stance that they would not concede supply. Whitlam on the other hand, convinced that he would win the battle, was glad of the distraction from the Loans Affair, and believed that he would "smash" not only the Senate, but Fraser's leadership as well.

Whitlam told the House of Representatives on 21 October,
Whitlam and his ministers repeatedly claimed that the Opposition was damaging not only the constitution, but the economy as well. The Coalition senators remained united, though several became increasingly concerned about the tactic of blocking supply. As the crisis dragged into November, Whitlam attempted to make arrangements for public servants and suppliers to be able to cash cheques at banks. These transactions would be temporary loans which the government would repay once supply was restored. This plan to prolong government without supply was presented to Kerr unsigned on 6 November, under the title "Draft Joint Opinion" (ostensibly of solicitor-general Maurice Byers and attorney-general Kep Enderby). It proposed that public employees, including members of the armed forces and police, "could assign arrears of pay by way of mortgage". The government's refusal to formalise this and other "advice" was a factor justifying the Governor-General's fateful resort to alternative legal advice.

Governor-General Kerr was following the crisis closely. At a luncheon with Whitlam and several of his ministers on 30 October, Kerr suggested a compromise: if Fraser conceded supply, Whitlam would agree not to call the half-Senate election until May or June 1976, or alternatively would agree not to call the Senate into session until after 1 July. Whitlam rejected the idea, seeking to end the Senate's right to deny supply. On 3 November, after a meeting with Kerr, Fraser proposed that if the government agreed to hold a House of Representatives election at the same time as the half-Senate election, the Coalition would concede supply. Whitlam rejected this offer, stating that he had no intention of advising a House election for at least a year.

With the crisis unresolved, Kerr decided to dismiss Whitlam as prime minister. Fearing that Whitlam would go to the Queen and potentially have him removed, the Governor-General gave Whitlam no prior hint. He conferred (against Whitlam's advice) with High Court Chief Justice Sir Garfield Barwick, who agreed that he had the power to dismiss Whitlam.

A meeting among the party leaders, including Whitlam and Fraser, to resolve the crisis on the morning of 11 November came to nothing. Kerr and Whitlam met at the Governor-General's office that afternoon at 1.00 pm. Unknown to Whitlam, Fraser was waiting in an ante-room; Whitlam later stated that he would not have set foot in the building if he had known Fraser was there. Whitlam, as he had told Kerr by phone earlier that day, came prepared to advise a half-Senate election, to be held on 13 December. Kerr instead told Whitlam that he had terminated his commission as prime minister, and handed him a letter to that effect. After the conversation, Whitlam returned to the Prime Minister's residence, The Lodge, had lunch and conferred with his advisers. Immediately after his meeting with Whitlam, Kerr commissioned Fraser as caretaker Prime Minister, on the assurance he could obtain supply and would then advise Kerr to dissolve both houses for election.

In the confusion, Whitlam and his advisers did not immediately tell any Senate members of the dismissal, with the result that when the Senate convened at 2.00 pm, the appropriation bills were rapidly passed, with the ALP senators assuming the Opposition had given in. The bills were soon sent to Kerr to receive Royal Assent. At 2.34 pm, ten minutes after supply had been secured, Fraser rose in the House and announced he was prime minister. Whitlam immediately moved a no confidence motion against the new prime minister in the House, which instructed the Speaker, Gordon Scholes, to advise Kerr to reinstate Whitlam.

Kerr refused to receive Scholes, keeping him waiting for more than an hour while he prorogued Parliament by proclamation: his Official Secretary, David Smith, came to Parliament House to proclaim the dissolution from the front steps. A large, angry crowd had gathered, and Smith was nearly drowned out by their noise. He concluded with the traditional "God save the Queen". The dismissed prime minister, Whitlam, who had been standing behind Smith, then addressed the crowd:
Well may we say "God save the Queen", because nothing will save the Governor-General! The Proclamation which you have just heard read by the Governor-General's Official Secretary was countersigned Malcolm Fraser, who will undoubtedly go down in Australian history from Remembrance Day 1975 as Kerr's cur. They won't silence the outskirts of Parliament House, even if the inside has been silenced for a few weeks. ... Maintain your rage and enthusiasm for the campaign for the election now to be held and until polling day.

As the ALP began the 1975 campaign, it seemed that its supporters would maintain their rage. Early rallies drew huge crowds, with attendees handing Whitlam money to pay election expenses. The crowds greatly exceeded those in any of Whitlam's earlier campaigns; in Sydney, 30,000 partisans gathered for an ALP rally in The Domain below a banner: "Shame Fraser Shame". Fraser's appearances drew protests, and a letter bomb sent to Kerr was defused by authorities. Instead of making a policy speech to keynote his campaign, Whitlam made a speech attacking his opponents and calling 11 November "a day which will live in infamy".

Polls from the first week of campaigning showed a nine-point swing against Labor, which would have decimated Labor if repeated in an election. Whitlam's campaign team disbelieved the results at first, but additional polling returns were clear: the electorate had turned against Labor. The Coalition attacked Labor for economic conditions, and released television commercials including "The Three Dark Years" showing images from Whitlam government scandals. The ALP campaign, which had concentrated on the issue of Whitlam's dismissal, did not address the economy until its final days. By that time Fraser, confident of victory, was content to sit back, avoid specifics and make no mistakes. On election night, 13 December, the Coalition won the largest majority government in Australian history, winning 91 seats to Labor's 36. Labor suffered a 6.5 percent swing against it and its caucus was cut almost in half, suffering a 30-seat swing. Labor was left with five fewer seats than it had when Whitlam took the leadership. The Coalition also won a 37–25 majority in the Senate.
Whitlam stayed on as Opposition leader, surviving a leadership challenge. In early 1976, an additional controversy broke when it was reported that Whitlam had been involved in ALP attempts to raise $500,000 during the election from the Ahmed Hassan al-Bakr government of Iraq. "Luckily, for Whitlam and Labor, the deal, ultimately, went pear-shaped." No money had actually been paid, and no charges were filed.
The Whitlams were visiting China at the time of the Tangshan earthquake in July 1976, though they were staying in Tianjin, away from the epicentre. "The Age" printed a cartoon by Peter Nicholson showing the Whitlams huddled together in bed with Margaret Whitlam saying, "Did the earth move for you too, dear?" This cartoon prompted a page full of outraged letters from Labor partisans and a telegram from Gough Whitlam, safe in Tokyo, requesting the original of the cartoon.

In early 1977 Whitlam faced a leadership challenge from Bill Hayden, the final treasurer in the Whitlam government, and won by a two-vote margin. Fraser called an election for 10 December. Although Labor managed to pick up five seats, the Coalition still enjoyed a majority of 48. According to Freudenberg, "The meaning and the message were unmistakable. It was the Australian people's rejection of Edward Gough Whitlam." Whitlam's son Tony, who had joined his father in the House of Representatives at the 1975 election, was defeated. Shortly after the election, Whitlam resigned as party leader and was succeeded by Hayden.
Whitlam was made a Companion of the Order of Australia in June 1978, and resigned from Parliament on 31 July of the same year. He then held various academic positions. When Labor returned to power under Bob Hawke in 1983, Whitlam was appointed as ambassador to UNESCO, based in Paris. He served for three years in this post, defending UNESCO against allegations of corruption. At the end of his term as Australia's Ambassador Whitlam was elected to the Executive Board of UNESCO for a 3-year term, until 1989. In 1985, he was appointed to Australia's Constitutional Commission.

Whitlam was appointed chairman of the National Gallery of Australia in 1987 after his son Nick (then managing director of the State Bank of New South Wales) turned down the position. He and Margaret Whitlam were part of the bid team that in 1993 persuaded the International Olympic Committee to give Sydney the right to host the 2000 Summer Olympics.

John Kerr died in 1991. He and Whitlam never reconciled; indeed, Whitlam always saw his dismissal from office as a "constitutional coup d'état". Whitlam and Fraser put aside their differences and became friends during the 1980s, though they never discussed the events of 1975. The two subsequently campaigned together in support of the 1999 Australian republic referendum. In March 2010, Fraser visited Whitlam at his Sydney office while on a book tour to promote his memoirs. Whitlam accepted an autographed copy of the book and presented Fraser with a copy of his 1979 book about the dismissal, "The Truth of the Matter".

In 2003, Whitlam's former research assistant Mark Latham became the leader of the ALP. Although Latham was more conservative than Whitlam, the former prime minister gave Latham much support, according to one account "anointing him as his political heir". Latham, like Whitlam, represented Werriwa in the House of Representatives. Whitlam supported Latham when he opposed the invasion and occupation of Iraq.

Whitlam supported fixed four-year terms for both houses of Parliament. In 2006, he accused the ALP of failing to press for this change. In April 2007, he and Margaret Whitlam were both made life members of the Australian Labor Party. This was the first time anyone had been made a life member of the party organisation at the national level.

In 2007, Whitlam testified at an inquest into the death of Brian Peters, one of five Australia-based TV personnel killed in East Timor in October 1975. Whitlam indicated that he had warned Peters' colleague, Greg Shackleton (who was also killed), that the Australian government could not protect them in East Timor and that they should not go there. He also said that Shackleton was "culpable" if he had not passed on Whitlam's warning.

Whitlam joined three other former prime ministers in February 2008 in returning to Parliament to witness the Federal Government apology to the Aboriginal Stolen Generations by the then prime minister Kevin Rudd. On 21 January 2009, Whitlam achieved a greater age () than any other prime minister of Australia, surpassing the previous record holder Frank Forde. On the 60th anniversary of his marriage to Margaret Whitlam, he called it "very satisfactory" and claimed a record for "matrimonial endurance". In 2010, it was reported that Whitlam had moved into an aged care facility in Sydney's inner east in 2007. Despite this, he continued to go to his office three days a week. Margaret Whitlam remained in the couple's nearby apartment. In early 2012 she suffered a fall there, leading to her death in hospital at age 92 on 17 March of that year, a month short of the Whitlams' 70th wedding anniversary.

Gough Whitlam died on the morning of 21 October 2014. His family announced that there would be a private cremation and a public memorial service. Whitlam was survived by his four children, five grandchildren and nine great-grandchildren. He was the longest-lived Australian Prime Minister, dying at the age of 98 years and 102 days.

A state memorial service was held on 5 November 2014 in the Sydney Town Hall and was led by Kerry O'Brien. The Welcome to Country was given by Auntie Millie Ingram and eulogies were delivered by Graham Freudenberg, Cate Blanchett, Noel Pearson, John Faulkner and Antony Whitlam. Pearson's contribution in particular was hailed as "one of the best political speeches of our time". Musical performances were delivered by William Barton (a didgeridoo improvisation), Paul Kelly and Kev Carmody (their land rights protest song "From Little Things Big Things Grow"), as well as the Sydney Philharmonia Choir and the Sydney Symphony Orchestra, conducted by Benjamin Northey. In accordance with Whitlam's wishes, the orchestra performed "In Tears of Grief" from Bach's "St Matthew Passion", "Va, pensiero" from Verdi's "Nabucco", "Un Bal" from "Symphonie fantastique" by Berlioz and, as the final piece, "Jerusalem" by Parry. "Jerusalem" was followed by a flypast of four RAAF F/A-18 Hornets in missing man formation. Those attending the memorial included the current and some former governors-general, the current and all living former prime ministers, and members of the family of Vincent Lingiari. The two-hour service, attended by 1,000 invited guests and 900 others, was screened to thousands outside the Hall, as well as in Cabramatta and Melbourne, and broadcast live by ABC television.

In honour of Whitlam, the Australian Electoral Commission created the Division of Whitlam in the House of Representatives in place of the Division of Throsby, with effect from the 2016 election. ACT Chief Minister Katy Gallagher announced that a future Canberra suburb will be named for Whitlam, and that his family would be consulted about other potential memorials. Gough Whitlam Park in Earlwood, New South Wales, is named after him.

Whitlam remains well remembered for the circumstances of his dismissal. It is a legacy he did little to efface; he wrote a 1979 book, "The Truth of the Matter" (the title is a play on that of Kerr's 1978 memoir, "Matters for Judgment") and devoted part of his subsequent book, "Abiding Interests", to the circumstances of his removal. According to journalist and author Paul Kelly, who penned two books on the crisis, Whitlam "achieved a paradoxical triumph: the shadow of the dismissal has obscured the sins of his government".

More books have been written about Whitlam, including his own writings, than about any other Australian prime minister. According to Whitlam biographer Jenny Hocking, for a period of at least a decade, the Whitlam era was viewed almost entirely in negative terms, but that has changed. Still, she feels that Australians take for granted programmes and policies initiated by the Whitlam government, such as recognition of China, legal aid, and Medicare. Ross McMullin, who wrote an official history of the ALP, notes that Whitlam remains greatly admired by many Labor supporters because of his efforts to reform Australian government, and his inspiring leadership. Some rankings have put Whitlam high on the list of Australia's better prime ministers. Economist and writer Ross Gittins evaluated the Whitlam Government's responses to the economic challenges of the time.

Wallace Brown describes Whitlam in his book about his experiences covering Australian prime ministers as a journalist:
Whitlam was the most paradoxical of all Prime Ministers in the last half of the 20th century. A man of superb intellect, knowledge, and literacy, he yet had little ability when it came to economics. ... Whitlam rivalled Menzies in his passion for the House of Representatives and ability to use it as his stage, and yet his parliamentary skills were rhetorical and not tactical. He could devise a strategy and then often botch the tactics in trying to implement that strategy. ... Above all he was a man of grand vision with serious blind spots.
Whitlam's last words in the documentary film "Gough Whitlam – In His Own Words" (2002) were in response to a question about his status as an icon and elder statesman. He said:
"I hope this is not just because I was a martyr; the fact was, I was an achiever".





</doc>
<doc id="12457" url="https://en.wikipedia.org/wiki?curid=12457" title="Geri and Freki">
Geri and Freki

In Norse mythology, Geri and Freki (Old Norse, both meaning "the ravenous" or "greedy one") are two wolves which are said to accompany the god Odin. They are attested in the "Poetic Edda", a collection of epic poetry compiled in the 13th century from earlier traditional sources, in the "Prose Edda", written in the 13th century by Snorri Sturluson, and in the poetry of skalds. The pair has been compared to similar figures found in Greek, Roman and Vedic mythology, and may also be connected to beliefs surrounding the Germanic "wolf-warrior bands", the Úlfhéðnar.

The names "Geri" and "Freki" have been interpreted as meaning either "the greedy one" or "the ravenous one". The name "Geri" can be traced back to the Proto-Germanic adjective , attested in Burgundian "girs", Old Norse and Old High German or , all of which mean "greedy".

The name "Freki" can be traced back to the Proto-Germanic adjective , attested in Gothic () "covetous, avaricious", Old Norse "greedy", Old English "desirous, greedy, gluttonous, audacious" and Old High German "greedy". John Lindow interprets both Old Norse names as nominalized adjectives. Bruce Lincoln further traces "Geri" back to a Proto-Indo-European stem *"", which is the same as that found in , a name referring to the hound closely associated with the events of .

In the "Poetic Edda" poem "Grímnismál", the god Odin (disguised as "Grímnir") provides the young Agnarr with information about Odin's companions. Agnarr is told that Odin feeds Geri and Freki while the god himself consumes only wine:

The pair is also alluded to via the kenning "Viðrir's (Odin's) hounds" in "Helgakviða Hundingsbana I", verse 13, where it is related that they roam the field "greedy for the corpses of those who have fallen in battle".

In the "Prose Edda" book "Gylfaginning" (chapter 38), the enthroned figure of High explains that Odin gives all of the food on his table to his wolves Geri and Freki and that Odin requires no food, for wine is to him both meat and drink. High then quotes the above-mentioned stanza from the poem "Grímnismál" in support. In chapter 75 of the "Prose Edda" book "Skáldskaparmál" a list of names for wargs and wolves is provided that includes both Geri and Freki.

In skaldic poetry "Geri" and "Freki" are used as common nouns for "wolf" in chapter 58 of "Skáldskaparmál" (quoted in works by the skalds Þjóðólfr of Hvinir and Egill Skallagrímsson) and "Geri" is again used as a common noun for "wolf" in chapter 64 of the "Prose Edda" book "Háttatal". Geri is referenced in kennings for "blood" in chapter 58 of "Skáldskaparmál" ("Geri's ales" in a work by the skald Þórðr Sjáreksson) and in for "carrion" in chapter 60 ("Geri's morsel" in a work by the skald Einarr Skúlason). "Freki" is also used in a kenning for "carrion" ("Freki's meal") in a work by Þórðr Sjáreksson in chapter 58 of "Skáldskaparmál".

If the rider on horseback on the image on the Böksta Runestone has been correctly identified as Odin, then Geri and Freki are shown taking part in hunting an elk or moose.

"Freki" is also a name applied to the monstrous wolf Fenrir in the "Poetic Edda" poem "Völuspá". Folklorist John Lindow sees irony in the fact that Odin feeds one Freki at his dinner table and another—Fenrir—with his flesh during the events of Ragnarök.

Historian Michael Spiedel connects Geri and Freki with archaeological finds depicting figures wearing wolf-pelts and frequently found wolf-related names among the Germanic peoples, including Wulfhroc ("Wolf-Frock"), Wolfhetan ("Wolf-Hide"), Isangrim ("Grey-Mask"), Scrutolf ("Garb-Wolf") and Wolfgang ("Wolf-Gait"), Wolfdregil ("Wolf-Runner"), and Vulfolaic ("Wolf-Dancer") and myths regarding wolf warriors from Norse mythology (such as the Úlfhéðnar). Michael Speidel believes this to point to the pan-Germanic wolf-warrior band cult centered on Odin that waned away after Christianization.

Scholars have also noted Indo-European parallels to the wolves Geri and Freki as companions of a divinity. 19th century scholar Jacob Grimm observed a connection between this aspect of Odin's character and the Greek Apollo, to whom both the wolf and the raven are sacred. Philologist Maurice Bloomfield further connected the pair with the two dogs of Yama in Vedic mythology, and saw them as a Germanic counterpart to a more general and widespread Indo-European "Cerberus"-theme. Speidel finds similar parallels in the Vedic Rudra and the Roman Mars. Elaborating on the connection between wolves and figures of great power, he writes: "This is why Geri and Freki, the wolves at Woden's side, also glowered on the throne of the Anglo-Saxon kings. Wolf-warriors, like Geri and Freki, were not mere animals but mythical beings: as Woden's followers they bodied forth his might, and so did wolf-warriors."

Bernd Heinrich theorizes that Geri and Freki, along with Odin and his ravens Huginn and Muninn, reflect a symbiosis observed in the natural world among ravens, wolves, and humans on the hunt:


</doc>
<doc id="12458" url="https://en.wikipedia.org/wiki?curid=12458" title="Ginnungagap">
Ginnungagap

In Norse mythology, Ginnungagap ("gaping abyss", "yawning void") is the primordial void, mentioned in the Gylfaginning, the Eddaic text recording Norse cosmogony.

"Ginnunga-" is usually interpreted as deriving from a verb meaning "gape" or "yawn", but no such word occurs in Old Norse except in verse 3 of the Eddic poem "Vǫluspá", "gap var ginnunga", which may be a play on the term. In her edition of the poem, Ursula Dronke suggested it was borrowed from Old High German "ginunga", as the term Múspell is believed to have been borrowed from Old High German. An alternative etymology links the "ginn-" prefix with that found in terms with a sacral meaning, such as "ginn-heilagr", "ginn-regin" (both referring to the gods) and "ginn-runa" (referring to the runes), thus interpreting "Ginnungagap" as signifying a "magical (and creative) power-filled space".

Ginnungagap appears as the primordial void in the Norse creation account. The "Gylfaginning" states:

In the northern part of Ginnungagap lay the intense cold of Niflheim, and in the southern part lay the equally intense heat of Muspelheim. The cosmogonic process began when the effulgence of the two met in the middle of Ginnungagap.

Scandinavian cartographers from the early 15th century attempted to localise or identify Ginnungagap as a real geographic location from which the creation myth derived. A fragment from a 15th-century (pre-Columbus) Old Norse encyclopedic text entitled "Gripla" (Little Compendium) places Ginnungagap between Greenland and Vinland:

A scholion in a 15th-century manuscript of Adam of Bremen's "Gesta Hammaburgensis Ecclesiae Pontificum" similarly refers to "Ghimmendegop" as the Norse word for the abyss in the far north.

Later, the 17th-century Icelandic bishop Guðbrandur Thorlaksson also used the name "Ginnungegap" to refer to a narrow body of water, possibly the Davis Strait, separating the southern tip of Greenland from "Estotelandia, pars America extrema", probably Baffin Island.

Ginnungagap is featured in the Marvel Universe as a place of darkness and chaos, which existed before the formation of the world. In this place were formed entities such as the Elder Gods, Xian, Ennead, Frost Giants, Fire Demons, Nyx and Amatsu-Mikaboshi.





</doc>
<doc id="12460" url="https://en.wikipedia.org/wiki?curid=12460" title="Green">
Green

Green is the color between blue and yellow on the visible spectrum. It is evoked by light which has a dominant wavelength of roughly 495570 nm. In subtractive color systems, used in painting and color printing, it is created by a combination of yellow and blue, or yellow and cyan; in the RGB color model, used on television and computer screens, it is one of the additive primary colors, along with red and blue, which are mixed in different combinations to create all other colors. By far the largest contributor to green in nature is chlorophyll, the chemical by which plants photosynthesize and convert sunlight into chemical energy. Many creatures have adapted to their green environments by taking on a green hue themselves as camouflage. Several minerals have a green color, including the emerald, which is colored green by its chromium content.
During post-classical and early modern Europe, green was the color commonly associated with wealth, merchants, bankers and the gentry, while red was reserved for the nobility. For this reason, the costume of the "Mona Lisa" by Leonardo da Vinci and the benches in the British House of Commons are green while those in the House of Lords are red. It also has a long historical tradition as the color of Ireland and of Gaelic culture. It is the historic color of Islam, representing the lush vegetation of Paradise. It was the color of the banner of Muhammad, and is found in the flags of nearly all Islamic countries.
In surveys made in American, European, and Islamic countries, green is the color most commonly associated with nature, life, health, youth, spring, hope, and envy. In the European Union and the United States, green is also sometimes associated with toxicity and poor health, but in China and most of Asia, its associations are very positive, as the symbol of fertility and happiness. Because of its association with nature, it is the color of the environmental movement. Political groups advocating environmental protection and social justice describe themselves as part of the Green movement, some naming themselves Green parties. This has led to similar campaigns in advertising, as companies have sold green, or environmentally friendly, products. Green is also the traditional color of safety and permission; a green light means go ahead, a green card permits permanent residence in the United States.

The word "green" comes from the Middle English and Old English word "grene", which, like the German word "grün", has the same root as the words "grass" and "grow". It is from a Common Germanic "*gronja-", which is also reflected in Old Norse "grænn", Old High German "gruoni" (but unattested in East Germanic), ultimately from a PIE root "*" "to grow", and root-cognate with "grass" and "to grow".
The first recorded use of the word as a color term in Old English dates to ca. AD 700.

Latin with "viridis" also has a genuine and widely used term for "green". Related to "virere" "to grow" and "ver" "spring", it gave rise to words in several Romance languages, French "vert", Italian "verde" (and English "vert", "verdure" etc.). Likewise the Slavic languages with "zelenъ". Ancient Greek also had a term for yellowish, pale green – χλωρός, "chloros" (cf. the color of chlorine), cognate with χλοερός "verdant" and χλόη "chloe, the green of new growth".

Thus, the languages mentioned above (Germanic, Romance, Slavic, Greek) have old terms for "green" which are derived from words for fresh, sprouting vegetation.
However, comparative linguistics makes clear that these terms were coined independently, over the past few millennia, and there is no identifiable single Proto-Indo-European or word for "green". For example, the Slavic "zelenъ" is cognate with Sanskrit "hari" "yellow, ochre, golden".
The Turkic languages also have "jašɨl" "green" or "yellowish green", compared to a Mongolian word for "meadow".

In some languages, including old Chinese, Thai, old Japanese, and Vietnamese, the same word can mean either blue or green. The Chinese character 青 (pronounced "qīng" in Mandarin, "ao" in Japanese, and "thanh" in Sino-Vietnamese) has a meaning that covers both blue and green; blue and green are traditionally considered shades of "青". In more contemporary terms, they are 藍 ("lán", in Mandarin) and 綠 ("lǜ", in Mandarin) respectively. Japanese also has two terms that refer specifically to the color green, 緑 ("midori", which is derived from the classical Japanese descriptive verb "midoru" "to be in leaf, to flourish" in reference to trees) and グリーン ("guriin", which is derived from the English word "green"). However, in Japan, although the traffic lights have the same colors as other countries have, the green light is described using the same word as for blue, "aoi", because green is considered a shade of aoi; similarly, green variants of certain fruits and vegetables such as green apples, green "shiso" (as opposed to red apples and red shiso) will be described with the word "aoi". Vietnamese uses a single word for both blue and green, "xanh", with variants such as "xanh da trời" (azure, lit. "sky blue"), "lam" (blue), and "lục" (green; also "xanh lá cây", lit. "leaf green").

"Green" in modern European languages corresponds to about 520–570 nm, but many historical and non-European languages make other choices, e.g. using a term for the range of ca. 450–530 nm ("blue/green") and another for ca. 530–590 nm ("green/yellow"). In the comparative study of color terms in the world's languages, green is only found as a separate category in languages with the fully developed range of six colors (white, black, red, green, yellow, and blue), or more rarely in systems with five colors (white, red, yellow, green, and black/blue). (See distinction of green from blue) These languages have introduced supplementary vocabulary to denote "green", but these terms are recognizable as recent adoptions that are not in origin color terms (much like the English adjective orange being in origin not a color term but the name of a fruit). Thus, the Thai word เขียว "kheīyw", besides meaning "green", also means "rank" and "smelly" and holds other unpleasant associations.

The Celtic languages had a term for "blue/green/grey", Proto-Celtic "*glasto-", which gave rise to Old Irish "glas" "green, grey" and to Welsh "glas" "blue". This word is cognate with the Ancient Greek γλαυκός "bluish green", contrasting with χλωρός "yellowish green" discussed above.

In modern Japanese, the term for green is 緑, while the old term for "blue/green", now means "blue". But in certain contexts, green is still conventionally referred to as 青, as in and , reflecting the absence of blue-green distinction in old Japanese (more accurately, the traditional Japanese color terminology grouped some shades of green with blue, and others with yellow tones).

The Persian language is traditionally lacking a black/blue/green distinction. The Persian word سبز "sabz" can mean "green", "black", or "dark". Thus, Persian erotic poetry, dark-skinned women are addressed as "sabz-eh", as in phrases like سبز گندم گون "sabz-eh-gandom-gun" (literally ""dark" wheat colored") or سبز مليح "sabz-eh-malih" ("a "dark" beauty"). Similarly, in Sudanese Arabic, dark-skinned people are described as أخضر "akhḍar", the term which in Standard Arabic stands unambiguously for "green".

In optics, the perception of green is evoked by light having a spectrum dominated by energy with a wavelength of roughly 495570nm. The sensitivity of the dark-adapted human eye is greatest at about 507nm, a blue-green color, while the light-adapted eye is most sensitive about 555nm, a yellow-green; these are the peak locations of the rod and cone (scotopic and photopic, respectively) luminosity functions.

The perception of greenness (in opposition to redness forming one of the opponent mechanisms in human color vision) is evoked by light which triggers the medium-wavelength "M" cone cells in the eye more than the long-wavelength "L" cones. Light which triggers this greenness response more than the yellowness or blueness of the other color opponent mechanism is called green. A green light source typically has a spectral power distribution dominated by energy with a wavelength of roughly 487570 nm.

Human eyes have color receptors known as cone cells, of which there are three types. In some cases, one is missing or faulty, which can cause color blindness, including the common inability to distinguish red and yellow from green, known as deuteranopia or redgreen color blindness. Green is restful to the eye. Studies show that a green environment can reduce fatigue.

In the subtractive color system, used in painting and color printing, green is created by a combination of yellow and blue, or yellow and cyan; in the RGB color model, used on television and computer screens, it is one of the additive primary colors, along with red and blue, which are mixed in different combinations to create all other colors. On the HSV color wheel, also known as the , the complement of green is magenta; that is, a color corresponding to an equal mixture of red and blue light (one of the purples). On a traditional color wheel, based on subtractive color, the complementary color to green is considered to be red.

In additive color devices such as computer displays and televisions, one of the primary light sources is typically a narrow-spectrum yellowish-green of dominant wavelength ~550nm; this "green" primary is combined with an orangish-red "red" primary and a purplish-blue "blue" primary to produce any color in betweenthe RGB color model. A unique green (green appearing neither yellowish nor bluish) is produced on such a device by mixing light from the green primary with some light from the blue primary.

Lasers emitting in the green part of the spectrum are widely available to the general public in a wide range of output powers. Green laser pointers outputting at 532nm (563.5 THz) are relatively inexpensive compared to other wavelengths of the same power, and are very popular due to their good beam quality and very high apparent brightness. The most common green lasers use diode pumped solid state (DPSS) technology to create the green light. An infrared laser diode at 808nm is used to pump a crystal of neodymium-doped yttrium vanadium oxide (Nd:YVO4) or neodymium-doped yttrium aluminium garnet (Nd:YAG) and induces it to emit 281.76 THz (1064 nm). This deeper infrared light is then passed through another crystal containing potassium, titanium and phosphorus (KTP), whose non-linear properties generate light at a frequency that is twice that of the incident beam (563.5 THz); in this case corresponding to the wavelength of 532nm ("green"). Other green wavelengths are also available using DPSS technology ranging from 501 nm to 543 nm. Green wavelengths are also available from gas lasers, including the helium–neon laser (543nm), the Argon-ion laser (514nm) and the Krypton-ion laser (521nm and 531nm), as well as liquid dye lasers. Green lasers have a wide variety of applications, including pointing, illumination, surgery, laser light shows, spectroscopy, interferometry, fluorescence, holography, machine vision, non-lethal weapons and bird control.

As of mid-2011, direct green laser diodes at 510nm and 500nm have become generally available, although the price remains relatively prohibitive for widespread public use. The efficiency of these lasers (peak 3%) compared to that of DPSS green lasers (peak 35%) may also be limiting adoption of the diodes to niche uses.

Many minerals provide pigments which have been used in green paints and dyes over the centuries. Pigments, in this case, are minerals which reflect the color green, rather that emitting it through luminescent or phosphorescent qualities. The large number of green pigments makes it impossible to mention them all. Among the more notable green minerals, however is the emerald, which is colored green by trace amounts of chromium and sometimes vanadium. Chromium(III) oxide (CrO), is called chrome green, also called viridian or institutional green when used as a pigment. For many years, the source of amazonite's color was a mystery. Widely thought to have been due to copper because copper compounds often have blue and green colors, the blue-green color is likely to be derived from small quantities of lead and water in the feldspar. Copper is the source of the green color in malachite pigments, chemically known as basic copper(II) carbonate.

Verdigris is made by placing a plate or blade of copper, brass or bronze, slightly warmed, into a vat of fermenting wine, leaving it there for several weeks, and then scraping off and drying the green powder that forms on the metal. The process of making verdigris was described in ancient times by Pliny. It was used by the Romans in the murals of Pompeii, and in Celtic medieval manuscripts as early as the 5th century AD. It produced a blue-green which no other pigment could imitate, but it had drawbacks: it was unstable, it could not resist dampness, it did not mix well with other colors, it could ruin other colors with which it came into contact, and it was toxic. Leonardo da Vinci, in his treatise on painting, warned artists not to use it. It was widely used in miniature paintings in Europe and Persia in the 16th and 17th centuries. Its use largely ended in the late 19th century, when it was replaced by the safer and more stable chrome green. Viridian, as described above, was patented in 1859. It became popular with painters, since, unlike other synthetic greens, it was stable and not toxic. Vincent van Gogh used it, along with Prussian blue, to create a dark blue sky with a greenish tint in his painting "Café Terrace at Night".

Green earth is a natural pigment used since the time of the Roman Empire. It is composed of clay colored by iron oxide, magnesium, aluminum silicate, or potassium. Large deposits were found in the South of France near Nice, and in Italy around Verona, on Cyprus, and in Bohemia. The clay was crushed, washed to remove impurities, then powdered. It was sometimes called Green of Verona.

Mixtures of oxidized cobalt and zinc were also used to create green paints as early as the 18th century.

Cobalt green, sometimes known as Rinman's green or zinc green, is a translucent green pigment made by heating a mixture of cobalt (II) oxide and zinc oxide. Sven Rinman, a Swedish chemist, discovered this compound in 1780. Green chrome oxide was a new synthetic green created by a chemist named Pannetier in Paris in about 1835. Emerald green was a synthetic deep green made in the 19th century by hydrating chrome oxide. It was also known as Guignet green.
There is no natural source for green food colorings which has been approved by the US Food and Drug Administration. Chlorophyll, the E numbers E140 and E141, is the most common green chemical found in nature, and only allowed in certain medicines and cosmetic materials. Quinoline Yellow (E104) is a commonly used coloring in the United Kingdom but is banned in Australia, Japan, Norway and the United States. Green S (E142) is prohibited in many countries, for it is known to cause hyperactivity, asthma, urticaria, and insomnia.

To create green sparks, fireworks use barium salts, such as barium chlorate, barium nitrate crystals, or barium chloride, also used for green fireplace logs. Copper salts typically burn blue, but cupric chloride (also known as "campfire blue") can also produce green flames. Green pyrotechnic flares can use a mix ratio 75:25 of boron and potassium nitrate. Smoke can be turned green by a mixture: solvent yellow 33, solvent green 3, lactose, magnesium carbonate plus sodium carbonate added to potassium chlorate.

Green is common in nature, as many plants are green because of a complex chemical known as chlorophyll, which is involved in photosynthesis. Chlorophyll absorbs the long wavelengths of light (red) and short wavelengths of light (blue) much more efficiently than the wavelengths that appear green to the human eye, so light reflected by plants is enriched in green. Chlorophyll absorbs green light poorly because it first arose in organisms living in oceans where purple halobacteria were already exploiting photosynthesis. Their purple color arose because they extracted energy in the green portion of the spectrum using bacteriorhodopsin. The new organisms that then later came to dominate the extraction of light were selected to exploit those portions of the spectrum not used by the halobacteria.
Animals typically use the color green as camouflage, blending in with the chlorophyll green of the surrounding environment. Most fish, reptiles, amphibians, and birds appear green because of a reflection of blue light coming through an over-layer of yellow pigment. Perception of color can also be affected by the surrounding environment. For example, broadleaf forests typically have a yellow-green light about them as the trees filter the light. Turacoverdin is one chemical which can cause a green hue in birds, especially. Invertebrates such as insects or mollusks often display green colors because of porphyrin pigments, sometimes caused by diet. This can causes their feces to look green as well. Other chemicals which generally contribute to greenness among organisms are flavins (lychochromes) and hemanovadin. Humans have imitated this by wearing green clothing as a camouflage in military and other fields. Substances that may impart a greenish hue to one's skin include biliverdin, the green pigment in bile, and ceruloplasmin, a protein that carries copper ions in chelation.

The green huntsman spider is green due to the presence of bilin pigments in the spider's hemolymph (circulatory system fluids) and tissue fluids. It hunts insects in green vegetation, where it is well camouflaged.

There is no green pigment in green eyes; like the color of blue eyes, it is an optical illusion; its appearance is caused by the combination of an amber or light brown pigmentation of the stroma, given by a low or moderate concentration of melanin, with the blue tone imparted by the Rayleigh scattering of the reflected light. Green eyes are most common in Northern and Central Europe. They can also be found in Southern Europe, West Asia, Central Asia, and South Asia. In Iceland, 89% of women and 87% of men have either blue or green eye color. A study of Icelandic and Dutch adults found green eyes to be much more prevalent in women than in men. Among European Americans, green eyes are most common among those of recent Celtic and Germanic ancestry, about 16%.

Neolithic cave paintings do not have traces of green pigments, but neolithic peoples in northern Europe did make a green dye for clothing, made from the leaves of the birch tree. It was of very poor quality, more brown than green. Ceramics from ancient Mesopotamia show people wearing vivid green costumes, but it is not known how the colors were produced.

In Ancient Egypt, green was the symbol of regeneration and rebirth, and of the crops made possible by the annual flooding of the Nile. For painting on the walls of tombs or on papyrus, Egyptian artists used finely ground malachite, mined in the west Sinai and the eastern desert; a paintbox with malachite pigment was found inside the tomb of King Tutankhamun. They also used less expensive green earth pigment, or mixed yellow ochre and blue azurite. To dye fabrics green, they first colored them yellow with dye made from saffron and then soaked them in blue dye from the roots of the woad plant.

For the ancient Egyptians, green had very positive associations. The hieroglyph for green represented a growing papyrus sprout, showing the close connection between green, vegetation, vigor and growth. In wall paintings, the ruler of the underworld, Osiris, was typically portrayed with a green face, because green was the symbol of good health and rebirth. Palettes of green facial makeup, made with malachite, were found in tombs. It was worn by both the living and the dead, particularly around the eyes, to protect them from evil. Tombs also often contained small green amulets in the shape of scarab beetles made of malachite, which would protect and give vigor to the deceased. It also symbolized the sea, which was called the "Very Green."

In Ancient Greece, green and blue were sometimes considered the same color, and the same word sometimes described the color of the sea and the color of trees. The philosopher Democritus described two different greens: "cloron", or pale green, and "prasinon", or leek green. Aristotle considered that green was located midway between black, symbolizing the earth, and white, symbolizing water. However, green was not counted among the four classic colors of Greek painting – red, yellow, black and white – and is rarely found in Greek art.

The Romans had a greater appreciation for the color green; it was the color of Venus, the goddess of gardens, vegetables and vineyards. The Romans made a fine green earth pigment that was widely used in the wall paintings of Pompeii, Herculaneum, Lyon, Vaison-la-Romaine, and other Roman cities. They also used the pigment verdigris, made by soaking copper plates in fermenting wine. By the second century AD, the Romans were using green in paintings, mosaics and glass, and there were ten different words in Latin for varieties of green.

In the Middle Ages and Renaissance, the color of clothing showed a person's social rank and profession. Red could only be worn by the nobility, brown and gray by peasants, and green by merchants, bankers and the gentry and their families. The Mona Lisa wears green in her portrait, as does the bride in the Arnolfini portrait by Jan van Eyck.

There were no good vegetal green dyes which resisted washing and sunlight for those who wanted or were required to wear green. Green dyes were made out of the fern, plantain, buckthorn berries, the juice of nettles and of leeks, the digitalis plant, the broom plant, the leaves of the fraxinus, or ash tree, and the bark of the alder tree, but they rapidly faded or changed color. Only in the 16th century was a good green dye produced, by first dyeing the cloth blue with woad, and then yellow with "Reseda luteola", also known as yellow-weed.

The pigments available to painters were more varied; monks in monasteries used verdigris, made by soaking copper in fermenting wine, to color medieval manuscripts. They also used finely-ground malachite, which made a luminous green. They used green earth colors for backgrounds.

During the early Renaissance, painters such as Duccio di Buoninsegna learned to paint faces first with a green undercoat, then with pink, which gave the faces a more realistic hue. Over the centuries the pink has faded, making some of the faces look green.

The 18th and 19th centuries brought the discovery and production of synthetic green pigments and dyes, which rapidly replaced the earlier mineral and vegetable pigments and dyes. These new dyes were more stable and brilliant than the vegetable dyes, but some contained high levels of arsenic, and were eventually banned.

In the 18th and 19th centuries, green was associated with the romantic movement in literature and art. The German poet and philosopher Goethe declared that green was the most restful color, suitable for decorating bedrooms. Painters such as John Constable and Jean-Baptiste-Camille Corot depicted the lush green of rural landscapes and forests. Green was contrasted to the smoky grays and blacks of the Industrial Revolution.

The second half of the 19th century saw the use of green in art to create specific emotions, not just to imitate nature. One of the first to make color the central element of his picture was the American artist James McNeil Whistler, who created a series of paintings called "symphonies" or "noctures" of color, including "Symphony in gray and green; The Ocean" between 1866 and 1872.

The late nineteenth century also brought the systematic study of color theory, and particularly the study of how complementary colors such as red and green reinforced each other when they were placed next to each other. These studies were avidly followed by artists such as Vincent van Gogh. Describing his painting, The "Night Cafe", to his brother Theo in 1888, Van Gogh wrote: "I sought to express with red and green the terrible human passions. The hall is blood red and pale yellow, with a green billiard table in the center, and four lamps of lemon yellow, with rays of orange and green. Everywhere it is a battle and antithesis of the most different reds and greens."

In the 1980s green became a political symbol, the color of the Green Party in Germany and in many other European countries. It symbolized the environmental movement, and also a new politics of the left which rejected traditional socialism and communism. (See section below.)

Green can communicate safety to proceed, as in traffic lights. Green and red were standardized as the colors of international railroad signals in the 19th century. The first traffic light, using green and red gas lamps, was erected in 1868 in front of the Houses of Parliament in London. It exploded the following year, injuring the policeman who operated it. In 1912, the first modern electric traffic lights were put up in Salt Lake City, Utah. Red was chosen largely because of its high visibility, and its association with danger, while green was chosen largely because it could not be mistaken for red. Today green lights universally signal that a system is turned on and working as it should. In many video games, green signifies both health and completed objectives, opposite red.

Green is the color most commonly associated in Europe and the United States with nature, vivacity and life.
It is the color of many environmental organizations, such as Greenpeace, and of the Green Parties in Europe. Many cities have designated a garden or park as a green space, and use green trash bins and containers. A green cross is commonly used to designate pharmacies in Europe.

In China, green is associated with the east, with sunrise, and with life and growth. In Thailand, the color green is considered auspicious for those born on a Wednesday day (light green for those born at night).

Green is the color most commonly associated in the United States and Europe with springtime, freshness, and hope. Green is often used to symbolize rebirth and renewal and immortality. In Ancient Egypt; the god Osiris, king of the underworld, was depicted as green-skinned. Green as the color of hope is connected with the color of springtime; hope represents the faith that things will improve after a period of difficulty, like the renewal of flowers and plants after the winter season.

Green the color most commonly associated in Europe and the United States with youth. It also often is used to describe anyone young, inexperienced, probably by the analogy to immature and unripe fruit. Examples include green cheese, a term for a fresh, unaged cheese, and greenhorn, an inexperienced person.

Surveys also show that green is the color most associated with the calm, the agreeable, and tolerance. Red is associated with heat, blue with cold, and green with an agreeable temperature. Red is associated with dry, blue with wet, and green, in the middle, with dampness. Red is the most active color, blue the most passive; green, in the middle, is the color of neutrality and calm, sometimes used in architecture and design for these reasons. Blue and green together symbolize harmony and balance.

Green is often associated with jealousy and envy. The expression "green-eyed monster" was first used by William Shakespeare in Othello: "it is the green-eyed monster which doth mock the meat it feeds on." Shakespeare also used it in the Merchant of Venice, speaking of "green-eyed jealousy."

Green today is not commonly associated in Europe and the United States with love and sexuality, but in stories of the medieval period it sometimes represented love and the base, natural desires of man. It was the color of the serpent in the Garden of Eden who caused the downfall of Adam and Eve. However, for the troubadours, green was the color of growing love, and light green clothing was reserved for young women who were not yet married.

In Persian and Sudanese poetry, dark-skinned women, called "green" women, were considered erotic. The Chinese term for cuckold is "to wear a green hat." This was because in ancient China, prostitutes were called "the family of the green lantern" and a prostitute's family would wear a green headscarf.

In Victorian England, the color green was associated with homosexuality.

In legends, folk tales and films, fairies, dragons, monsters, and the devil are often shown as green.

In the Middle Ages, the devil was usually shown as either red, black or green. Dragons were usually green, because they had the heads, claws and tails of reptiles.

Modern Chinese dragons are also often green, but unlike European dragons, they are benevolent; Chinese dragons traditionally symbolize potent and auspicious powers, particularly control over water, rainfall, hurricane, and floods. The dragon is also a symbol of power, strength, and good luck. The Emperor of China usually used the dragon as a symbol of his imperial power and strength. The dragon dance is a popular feature of Chinese festivals.

In Irish folklore and English folklore, the color was sometimes was associated with witchcraft, and with faeries and spirits. The type of Irish fairy known as a leprechaun is commonly portrayed wearing a green suit, though before the 20th century he was usually described as wearing a red suit.

In theater and film, green was often connected with monsters and the inhuman. The earliest films of Frankenstein were in black and white, but in the poster for the 1935 version "The Bride of Frankenstein", the monster had a green face. Actor Bela Lugosi wore green-hued makeup for the role of Dracula in the 1927–1928 Broadway stage production.

Like other common colors, green has several completely opposite associations. While it is the color most associated by Europeans and Americans with good health, it is also the color most often associated with toxicity and poison. There was a solid foundation for this association; in the nineteenth century several popular paints and pigments, notably verdigris, vert de Schweinfurt and vert de Paris, were highly toxic, containing copper or arsenic. The intoxicating drink absinthe was known as "the green fairy".

A green tinge in the skin is sometimes associated with nausea and sickness. The expression 'green at the gills' means appearing sick. The color, when combined with gold, is sometimes seen as representing the fading of youth. In some Far East cultures the color green is used as a symbol of sickness or nausea.

Green in Europe and the United States is sometimes associated with status and prosperity. From the Middle Ages to the 19th century it was often worn by bankers, merchants country gentlemen and others who were wealthy but not members of the nobility. The benches in the House of Commons of the United Kingdom, where the landed gentry sat, are colored green.

In the United States green was connected with the dollar bill. Since 1861, the reverse side of the dollar bill has been green. Green was originally chosen because it deterred counterfeiters, who tried to use early camera equipment to duplicate banknotes. Also, since the banknotes were thin, the green on the back did not show through and muddle the pictures on the front of the banknote. Green continues to be used because the public now associates it with a strong and stable currency.

One of the more notable uses of this meaning is found in "The Wonderful Wizard of Oz". The Emerald City in this story is a place where everyone wears tinted glasses that make everything appear green. According to the populist interpretation of the story, the city's color is used by the author, L. Frank Baum, to illustrate the financial system of America in his day, as he lived in a time when America was debating the use of paper money versus gold.


Green is one of the three colors (along with red and black, or red and gold) of Pan-Africanism. Several African countries thus use the color on their flags, including Nigeria, South Africa, Ghana, Senegal, Mali, Ethiopia, Togo, Guinea, Benin, and Zimbabwe. The Pan-African colors are borrowed from the Ethiopian flag, one of the oldest independent African countries. Green on some African flags represents the natural richness of Africa.

Many flags of the Islamic world are green, as the color is considered sacred in Islam (see below). The flag of Hamas, as well as the flag of Iran, is green, symbolizing their Islamist ideology. The 1977 flag of Libya consisted of a simple green field with no other characteristics. It was the only national flag in the world with just one color and no design, insignia, or other details. Some countries used green in their flags to represent their country's lush vegetation, as in the flag of Jamaica, and hope in the future, as in the flags of Portugal and Nigeria. The green cedar of Lebanon tree on the Flag of Lebanon officially represents steadiness and tolerance.
Green is a symbol of Ireland, which is often referred to as the "Emerald Isle". The color is particularly identified with the republican and nationalist traditions in modern times. It is used this way on the flag of the Republic of Ireland, in balance with white and the Protestant orange. Green is a strong trend in the Irish holiday St. Patrick's Day.

The first recorded green party was a political faction in Constantinople during the 6th century Byzantine Empire. which took its name from a popular chariot racing team. They were bitter opponents of the blue faction, which supported Emperor Justinian I and which had its own chariot racing team. In 532 AD rioting between the factions began after one race, which led to the massacre of green supporters and the destruction of much of the center of Constantinople. (See Nika Riots).

Green was the traditional color of Irish nationalism, beginning in the 17th century. The green harp flag, with a traditional gaelic harp, became the symbol of the movement. It was the banner of the Society of United Irishmen, which organized the Irish Rebellion of 1798, calling for Irish independence. The uprising was suppressed with great bloodshed by the British army. When Ireland achieved independence in 1922, green was incorporated into the national flag.

In the 1970s green became the color of the third biggest Swiss Federal Council political party, the Swiss People's Party SVP. The ideology is Swiss nationalism, national conservatism, right-wing populism, economic liberalism, agrarianism, isolationism, euroscepticism. The SVP was founded on September 22, 1971 and has 90,000 members.

In the 1980s green became the color of a number of new European political parties organized around an agenda of environmentalism. Green was chosen for its association with nature, health, and growth. The largest green party in Europe is Alliance '90/The Greens (German: Bündnis 90/Die Grünen) in Germany, which was formed in 1993 from the merger of the German Green Party, founded in West Germany in 1980, and Alliance 90, founded during the Revolution of 1989–1990 in East Germany. In the 2009 federal elections, the party won 11% of the votes and 68 out of 622 seats in the Bundestag.

Green parties in Europe have programs based on ecology, grassroots democracy, nonviolence, and social justice. Green parties are found in over one hundred countries, and most are members of the Global Green Network.

Greenpeace is a non-governmental environmental organization which emerged from the anti-nuclear and peace movements in the 1970s. Its ship, the Rainbow Warrior, frequently tried to interfere with nuclear tests and whaling operations. The movement now has branches in forty countries.

The Australian Greens party was founded in 1992. In the 2010 federal election, the party received 13% of the vote (more than 1.6 million votes) in the Senate, a first for any Australian minor party.

Green is the color associated with Puerto Rico's Independence Party, the smallest of that country's three major political parties, which advocates Puerto Rican independence from the United States.

Green is the traditional color of Islam. According to tradition, the robe and banner of Muhammad were green, and according to the Koran (XVIII, 31 and LXXVI, 21) those fortunate enough to live in paradise wear green silk robes. Muhammad is quoted in a hadith as saying that "water, greenery, and a beautiful face" were three universally good things.

Al-Khidr ("The Green One"), was an important Qur'anic figure who was said to have met and traveled with Moses. He was given that name because of his role as a diplomat and negotiator. Green was also considered to be the median color between light and obscurity.

Roman Catholic and more traditional Protestant clergy wear green vestments at liturgical celebrations during Ordinary Time. In the Eastern Catholic Church, green is the color of Pentecost. Green is one of the Christmas colors as well, possibly dating back to pre-Christian times, when evergreens were worshiped for their ability to maintain their color through the winter season. Romans used green holly and evergreen as decorations for their winter solstice celebration called Saturnalia, which eventually evolved into a Christmas celebration. In Ireland and Scotland especially, green is used to represent Catholics, while orange is used to represent Protestantism. This is shown on the national flag of Ireland.






</doc>
<doc id="12461" url="https://en.wikipedia.org/wiki?curid=12461" title="Gradient">
Gradient

In vector calculus, the gradient is a multi-variable generalization of the derivative. Whereas the ordinary derivative of a function of a single variable is a scalar-valued function, the gradient of a function of several variables is a vector-valued function. Specifically, the gradient of a differentiable function formula_1 of several variables, at a point formula_2, is the vector whose components are the partial derivatives of formula_1 at formula_2.

Much as the derivative of a function of a single variable represents the slope of the tangent to the graph of the function, if at a point formula_2, the gradient of a function of several variables is not the zero vector, it has the direction of greatest increase of the function at formula_2, and its magnitude is the rate of increase in that direction.

The magnitude and direction of the gradient vector are independent of the particular coordinate representation.

The Jacobian is the generalization of the gradient for vector-valued functions of several variables and differentiable maps between Euclidean spaces or, more generally, manifolds. A further generalization for a function between Banach spaces is the Fréchet derivative.

Consider a room in which the temperature is given by a scalar field, , so at each point the temperature is . (Assume that the temperature does not change over time.) At each point in the room, the gradient of at that point will show the direction in which the temperature rises most quickly. The magnitude of the gradient will determine how fast the temperature rises in that direction.

Consider a surface whose height above sea level at point is . The gradient of at a point is a vector pointing in the direction of the steepest slope or grade at that point. The steepness of the slope at that point is given by the magnitude of the gradient vector.

The gradient can also be used to measure how a scalar field changes in other directions, rather than just the direction of greatest change, by taking a dot product. Suppose that the steepest slope on a hill is 40%. If a road goes directly up the hill, then the steepest slope on the road will also be 40%. If, instead, the road goes around the hill at an angle, then it will have a shallower slope. For example, if the angle between the road and the uphill direction, projected onto the horizontal plane, is 60°, then the steepest slope along the road will be 20%, which is 40% times the cosine of 60°.

This observation can be mathematically stated as follows. If the hill height function is differentiable, then the gradient of dotted with a unit vector gives the slope of the hill in the direction of the vector. More precisely, when is differentiable, the dot product of the gradient of with a given unit vector is equal to the directional derivative of in the direction of that unit vector.

The gradient (or gradient vector field) of a scalar function is denoted or where (the nabla symbol) denotes the vector differential operator, del. The notation is also commonly used for the gradient. The gradient of is defined as the unique vector field whose dot product with any unit vector at each point is the directional derivative of along . That is,

When a function also depends on a parameter such as time, the gradient often refers simply to the vector of its spatial derivatives only (see Spatial gradient).

In the three-dimensional Cartesian coordinate system with a Euclidean metric, the gradient, if it exists, is given by:

where , , are the standard unit vectors in the directions of the , and coordinates, respectively. For example, the gradient of the function
is

In some applications it is customary to represent the gradient as a row vector or column vector of its components in a rectangular coordinate system.

In cylindrical coordinates with a Euclidean metric, the gradient is given by:

where is the axial distance, is the azimuthal or azimuth angle, is the axial coordinate, and , and are unit vectors pointing along the coordinate directions.

In spherical coordinates, the gradient is given by:

where is the radial distance, is the azimuthal angle and is the polar angle, and , and are again local unit vectors pointing in the coordinate directions (i.e. the normalized covariant basis).

For the gradient in other orthogonal coordinate systems, see Orthogonal coordinates (Differential operators in three dimensions).

We consider general coordinates, which we write as , where is the number of dimensions of the domain. Here, the upper index refers to the position in the list of the coordinate or component, so refers to the second component—not the quantity squared. The index variable refers to an arbitrary element . Using Einstein notation, the gradient can then be written as:

where formula_15 and formula_16 refer to the unnormalized local covariant and contravariant bases respectively, formula_17 is the inverse metric tensor, and the Einstein summation convention implies summation over "i" and "j". 

If the coordinates are orthogonal we can easily express the gradient (and the differential) in terms of the normalized bases, which we refer to as formula_18 and formula_19, using the scale factors (also known as Lamé coefficients) formula_20 :

where we cannot use Einstein notation, since it is impossible to avoid the repetition of more than two indices. Despite the use of upper and lower indices, formula_23, formula_24, and formula_25 are neither contravariant nor covariant.

The latter expression evaluates to the expressions given above for cylindrical and spherical coordinates.

The gradient of a function from the Euclidean space to at any particular point in characterizes the best linear approximation to at . The approximation is as follows:

for close to , where is the gradient of computed at , and the dot denotes the dot product on . This equation is equivalent to the first two terms in the multivariable Taylor series expansion of at .

The best linear approximation to a differentiable function
at a point in is a linear map from to which is often denoted by or and called the differential or (total) derivative of at . The gradient is therefore related to the differential by the formula
for any . The function , which maps to , is called the differential or exterior derivative of and is an example of a differential 1-form.

If is viewed as the space of (dimension ) column vectors (of real numbers), then one can regard as the row vector with components
so that is given by matrix multiplication. Assuming the standard Euclidean metric on , the gradient is then the corresponding column vector, i.e.,

Let be an open set in . If the function is differentiable, then the differential of is the (Fréchet) derivative of . Thus is a function from to the space such that
where · is the dot product.

As a consequence, the usual properties of the derivative hold for the gradient:

The gradient is linear in the sense that if and are two real-valued functions differentiable at the point , and and are two constants, then is differentiable at , and moreover

If and are real-valued functions differentiable at a point , then the product rule asserts that the product is differentiable at , and

Suppose that is a real-valued function defined on a subset of , and that is differentiable at a point . There are two forms of the chain rule applying to the gradient. First, suppose that the function is a parametric curve; that is, a function maps a subset into . If is differentiable at a point such that , then
where ∘ is the composition operator: .

More generally, if instead , then the following holds:
where denotes the transpose Jacobian matrix.

For the second form of the chain rule, suppose that is a real valued function on a subset of , and that is differentiable at the point . Then

A level surface, or isosurface, is the set of all points where some function has a given value.

If is differentiable, then the dot product of the gradient at a point with a vector gives the directional derivative of at in the direction . It follows that in this case the gradient of is orthogonal to the level sets of . For example, a level surface in three-dimensional space is defined by an equation of the form . The gradient of is then normal to the surface.

More generally, any embedded hypersurface in a Riemannian manifold can be cut out by an equation of the form such that is nowhere zero. The gradient of is then normal to the hypersurface.

Similarly, an affine algebraic hypersurface may be defined by an equation , where is a polynomial. The gradient of is zero at a singular point of the hypersurface (this is the definition of a singular point). At a non-singular point, it is a nonzero normal vector.

The gradient of a function is called a gradient field. A (continuous) gradient field is always a conservative vector field: its line integral along any path depends only on the endpoints of the path, and can be evaluated by the gradient theorem (the fundamental theorem of calculus for line integrals). Conversely, a (continuous) conservative vector field is always the gradient of a function.

Since the total derivative of a vector field is a linear mapping from vectors to vectors, it is a tensor quantity.

In rectangular coordinates, the gradient of a vector field is defined by:

(where the Einstein summation notation is used and the tensor product of the vectors and is a dyadic tensor of type (2,0)). Overall, this expression equals the transpose of the Jacobian matrix:

In curvilinear coordinates, or more generally on a curved manifold, the gradient involves Christoffel symbols:

where are the components of the inverse metric tensor and the are the coordinate basis vectors.

Expressed more invariantly, the gradient of a vector field can be defined by the Levi-Civita connection and metric tensor:

where is the connection.

For any smooth function on a Riemannian manifold , the gradient of is the vector field such that for any vector field ,
i.e.,
where denotes the inner product of tangent vectors at defined by the metric and is the function that takes any point to the directional derivative of in the direction , evaluated at . In other words, in a coordinate chart from an open subset of to an open subset of , is given by:
where denotes the th component of in this coordinate chart.

So, the local form of the gradient takes the form:

Generalizing the case , the gradient of a function is related to its exterior derivative, since
More precisely, the gradient is the vector field associated to the differential 1-form using the musical isomorphism
(called "sharp") defined by the metric . The relation between the exterior derivative and the gradient of a function on is a special case of this in which the metric is the flat metric given by the dot product.





</doc>
<doc id="12462" url="https://en.wikipedia.org/wiki?curid=12462" title="Gauss (unit)">
Gauss (unit)

The gauss, abbreviated as G or Gs, is the cgs unit of measurement of magnetic flux density (or "magnetic induction") (B). It is named after German mathematician and physicist Carl Friedrich Gauss. One gauss is defined as one maxwell per square centimeter. The cgs system has been superseded by the International System of Units (SI), which uses the tesla (symbol T) as the unit of magnetic flux density. One gauss equals 1 tesla (100 μT), so 1 tesla = 10,000 gauss.

As with all units whose names are derived from a person's name, the first letter of its symbol is uppercase ("G"), but when the unit is spelled out, it should be written in lowercase ("gauss"), unless it begins a sentence.


</doc>
<doc id="12463" url="https://en.wikipedia.org/wiki?curid=12463" title="Glacier">
Glacier

A glacier ( or ) is a persistent body of dense ice that is constantly moving under its own weight; it forms where the accumulation of snow exceeds its ablation (melting and sublimation) over many years, often centuries. Glaciers slowly deform and flow due to stresses induced by their weight, creating crevasses, seracs, and other distinguishing features. They also abrade rock and debris from their substrate to create landforms such as cirques and moraines. Glaciers form only on land and are distinct from the much thinner sea ice and lake ice that form on the surface of bodies of water.

On Earth, 99% of glacial ice is contained within vast ice sheets (also known as "continental glaciers") in the polar regions, but glaciers may be found in mountain ranges on every continent including Oceania's high-latitude oceanic island countries such as New Zealand and Papua New Guinea. Between 35°N and 35°S, glaciers occur only in the Himalayas, Andes, Rocky Mountains, a few high mountains in East Africa, Mexico, New Guinea and on Zard Kuh in Iran. Glaciers cover about 10 percent of Earth's land surface. Continental glaciers cover nearly or about 98 percent of Antarctica's , with an average thickness of . Greenland and Patagonia also have huge expanses of continental glaciers.

Glacial ice is the largest reservoir of fresh water on Earth. Many glaciers from temperate, alpine and seasonal polar climates store water as ice during the colder seasons and release it later in the form of meltwater as warmer summer temperatures cause the glacier to melt, creating a water source that is especially important for plants, animals and human uses when other sources may be scant. Within high-altitude and Antarctic environments, the seasonal temperature difference is often not sufficient to release meltwater.

Since glacial mass is affected by long-term climatic changes, e.g., precipitation, mean temperature, and cloud cover, glacial mass changes are considered among the most sensitive indicators of climate change and are a major source of variations in sea level.

A large piece of compressed ice, or a glacier, appears blue, as large quantities of water appear blue. This is because water molecules absorb other colors more efficiently than blue. The other reason for the blue color of glaciers is the lack of air bubbles. Air bubbles, which give a white color to ice, are squeezed out by pressure increasing the density of the created ice.

The word "glacier" is a loanword from French and goes back, via Franco-Provençal, to the Vulgar Latin ', derived from the Late Latin ', and ultimately Latin "", meaning "ice". The processes and features caused by or related to glaciers are referred to as glacial. The process of glacier establishment, growth and flow is called glaciation. The corresponding area of study is called glaciology. Glaciers are important components of the global cryosphere.

Glaciers are categorized by their morphology, thermal characteristics, and behavior. "Alpine glaciers" form on the crests and slopes of mountains. A glacier that fills a valley is called a "valley glacier", or alternatively an "alpine glacier" or "mountain glacier". A large body of glacial ice astride a mountain, mountain range, or volcano is termed an "ice cap" or "ice field". Ice caps have an area less than by definition.

Glacial bodies larger than are called "ice sheets" or "continental glaciers". Several kilometers deep, they obscure the underlying topography. Only nunataks protrude from their surfaces. The only extant ice sheets are the two that cover most of Antarctica and Greenland. They contain vast quantities of fresh water, enough that if both melted, global sea levels would rise by over . Portions of an ice sheet or cap that extend into water are called ice shelves; they tend to be thin with limited slopes and reduced velocities. Narrow, fast-moving sections of an ice sheet are called "ice streams". In Antarctica, many ice streams drain into large ice shelves. Some drain directly into the sea, often with an ice tongue, like Mertz Glacier.

"Tidewater glaciers" are glaciers that terminate in the sea, including most glaciers flowing from Greenland, Antarctica, Baffin and Ellesmere Islands in Canada, Southeast Alaska, and the Northern and Southern Patagonian Ice Fields. As the ice reaches the sea, pieces break off, or calve, forming icebergs. Most tidewater glaciers calve above sea level, which often results in a tremendous impact as the iceberg strikes the water. Tidewater glaciers undergo centuries-long cycles of advance and retreat that are much less affected by the climate change than those of other glaciers.

Thermally, a "temperate glacier" is at melting point throughout the year, from its surface to its base. The ice of a "polar glacier" is always below the freezing point from the surface to its base, although the surface snowpack may experience seasonal melting. A "subpolar glacier" includes both temperate and polar ice, depending on depth beneath the surface and position along the length of the glacier. In a similar way, the thermal regime of a glacier is often described by its basal temperature. A "cold-based glacier" is below freezing at the ice-ground interface, and is thus frozen to the underlying substrate. A "warm-based glacier" is above or at freezing at the interface, and is able to slide at this contact. This contrast is thought to a large extent to govern the ability of a glacier to effectively erode its bed, as sliding ice promotes plucking at rock from the surface below. Glaciers which are partly cold-based and partly warm-based are known as "polythermal".

Glaciers form where the accumulation of snow and ice exceeds ablation. A glacier usually originates from a landform called 'cirque' (or corrie or cwm) – a typically armchair-shaped geological feature (such as a depression between mountains enclosed by arêtes) – which collects and compresses through gravity the snow that falls into it. This snow collects and is compacted by the weight of the snow falling above it, forming névé. Further crushing of the individual snowflakes and squeezing the air from the snow turns it into "glacial ice". This glacial ice will fill the cirque until it "overflows" through a geological weakness or vacancy, such as the gap between two mountains. When the mass of snow and ice is sufficiently thick, it begins to move due to a combination of surface slope, gravity and pressure. On steeper slopes, this can occur with as little as 15 m (50 ft) of snow-ice.
In temperate glaciers, snow repeatedly freezes and thaws, changing into granular ice called firn. Under the pressure of the layers of ice and snow above it, this granular ice fuses into denser and denser firn. Over a period of years, layers of firn undergo further compaction and become glacial ice. Glacier ice is slightly less dense than ice formed from frozen water because it contains tiny trapped air bubbles.

Glacial ice has a distinctive blue tint because it absorbs some red light due to an overtone of the infrared OH stretching mode of the water molecule. Liquid water is blue for the same reason. The blue of glacier ice is sometimes misattributed to Rayleigh scattering due to bubbles in the ice.

A glacier originates at a location called its glacier head and terminates at its glacier foot, snout, or terminus.

Glaciers are broken into zones based on surface snowpack and melt conditions. The ablation zone is the region where there is a net loss in glacier mass. The equilibrium line separates the ablation zone and the accumulation zone; it is the altitude where the amount of new snow gained by accumulation is equal to the amount of ice lost through ablation. The upper part of a glacier, where accumulation exceeds ablation, is called the accumulation zone. In general, the accumulation zone accounts for 60–70% of the glacier's surface area, more if the glacier calves icebergs. Ice in the accumulation zone is deep enough to exert a downward force that erodes underlying rock. After a glacier melts, it often leaves behind a bowl- or amphitheater-shaped depression that ranges in size from large basins like the Great Lakes to smaller mountain depressions known as cirques.

The accumulation zone can be subdivided based on its melt conditions.

The health of a glacier is usually assessed by determining the glacier mass balance or observing terminus behavior. Healthy glaciers have large accumulation zones, more than 60% of their area snowcovered at the end of the melt season, and a terminus with vigorous flow.

Following the Little Ice Age's end around 1850, glaciers around the Earth have retreated substantially. A slight cooling led to the advance of many alpine glaciers between 1950 and 1985, but since 1985 glacier retreat and mass loss has become larger and increasingly ubiquitous.

Glaciers move, or flow, downhill due to gravity and the internal deformation of ice. Ice behaves like a brittle solid until its thickness exceeds about 50 m (160 ft). The pressure on ice deeper than 50 m causes plastic flow. At the molecular level, ice consists of stacked layers of molecules with relatively weak bonds between layers. When the stress on the layer above exceeds the inter-layer binding strength, it moves faster than the layer below.

Glaciers also move through basal sliding. In this process, a glacier slides over the terrain on which it sits, lubricated by the presence of liquid water. The water is created from ice that melts under high pressure from frictional heating. Basal sliding is dominant in temperate, or warm-based glaciers.

Although evidence in favour of glacial flow was known by the early 19th century, other theories of glacial motion were advanced, such as the idea that melt water, refreezing inside glaciers, caused the glacier to dilate and extend its length. As it became clear that glaciers behaved to some degree as if the ice were a viscous fluid, it was argued that "regelation", or the melting and refreezing of ice at a temperature lowered by the pressure on the ice inside the glacier, was what allowed the ice to deform and flow. James Forbes came up with the essentially correct explanation in the 1840s, although it was several decades before it was fully accepted.

The top of a glacier are rigid because they are under low pressure. This upper section is known as the "fracture zone" and moves mostly as a single unit over the plastically flowing lower section. When a glacier moves through irregular terrain, cracks called crevasses develop in the fracture zone. Crevasses form due to differences in glacier velocity. If two rigid sections of a glacier move at different speeds and directions, shear forces cause them to break apart, opening a crevasse. Crevasses are seldom more than deep but in some cases can be or even deeper. Beneath this point, the plasticity of the ice is too great for cracks to form. Intersecting crevasses can create isolated peaks in the ice, called seracs.

Crevasses can form in several different ways. Transverse crevasses are transverse to flow and form where steeper slopes cause a glacier to accelerate. Longitudinal crevasses form semi-parallel to flow where a glacier expands laterally. Marginal crevasses form from the edge of the glacier, due to the reduction in speed caused by friction of the valley walls. Marginal crevasses are usually largely transverse to flow. Moving glacier ice can sometimes separate from stagnant ice above, forming a bergschrund. Bergschrunds resemble crevasses but are singular features at a glacier's margins.

Crevasses make travel over glaciers hazardous, especially when they are hidden by fragile snow bridges.

Below the equilibrium line, glacial meltwater is concentrated in stream channels. Meltwater can pool in proglacial lakes on top of a glacier or descend into the depths of a glacier via moulins. Streams within or beneath a glacier flow in englacial or sub-glacial tunnels. These tunnels sometimes reemerge at the glacier's surface.

The speed of glacial displacement is partly determined by friction. Friction makes the ice at the bottom of the glacier move more slowly than ice at the top. In alpine glaciers, friction is also generated at the valley's side walls, which slows the edges relative to the center.

Mean speeds vary greatly, but is typically around per day. There may be no motion in stagnant areas; for example, in parts of Alaska, trees can establish themselves on surface sediment deposits. In other cases, glaciers can move as fast as per day, such as in Greenland's Jakobshavn Isbræ (). Velocity increases with increasing slope, increasing thickness, increasing snowfall, increasing longitudinal confinement, increasing basal temperature, increasing meltwater production and reduced bed hardness.

A few glaciers have periods of very rapid advancement called surges. These glaciers exhibit normal movement until suddenly they accelerate, then return to their previous state. During these surges, the glacier may reach velocities far greater than normal speed. These surges may be caused by failure of the underlying bedrock, the pooling of meltwater at the base of the glacier — perhaps delivered from a supraglacial lake — or the simple accumulation of mass beyond a critical "tipping point". Temporary rates up to per day have occurred when increased temperature or overlying pressure caused bottom ice to melt and water to accumulate beneath a glacier.

In glaciated areas where the glacier moves faster than one km per year, glacial earthquakes occur. These are large scale earthquakes that have seismic magnitudes as high as 6.1. The number of glacial earthquakes in Greenland peaks every year in July, August and September and increased rapidly in the 1990s and 2000s. In a study using data from January 1993 through October 2005, more events were detected every year since 2002, and twice as many events were recorded in 2005 as there were in any other year.

"Ogives" (or "Forbes bands") are alternating wave crests and valleys that appear as dark and light bands of ice on glacier surfaces. They are linked to seasonal motion of glaciers; the width of one dark and one light band generally equals the annual movement of the glacier. Ogives are formed when ice from an icefall is severely broken up, increasing ablation surface area during summer. This creates a swale and space for snow accumulation in the winter, which in turn creates a ridge. Sometimes ogives consist only of undulations or color bands and are described as wave ogives or band ogives.

Glaciers are present on every continent and approximately fifty countries, excluding those (Australia, South Africa) that have glaciers only on distant subantarctic island territories. Extensive glaciers are found in Antarctica, Argentina, Chile, Canada, Alaska, Greenland and Iceland. Mountain glaciers are widespread, especially in the Andes, the Himalayas, the Rocky Mountains, the Caucasus, Scandinavian mountains, and the Alps. Snezhnika glacier in Pirin Mountain, Bulgaria with a latitude of 41°46′09″ N is the southernmost glacial mass in Europe. Mainland Australia currently contains no glaciers, although a small glacier on Mount Kosciuszko was present in the last glacial period. In New Guinea, small, rapidly diminishing, glaciers are located on its highest summit massif of Puncak Jaya. Africa has glaciers on Mount Kilimanjaro in Tanzania, on Mount Kenya and in the Rwenzori Mountains. Oceanic islands with glaciers include Iceland, several of the islands off the coast of Norway including Svalbard and Jan Mayen to the far North, New Zealand and the subantarctic islands of Marion, Heard, Grande Terre (Kerguelen) and Bouvet. During glacial periods of the Quaternary, Taiwan, Hawaii on Mauna Kea and Tenerife also had large alpine glaciers, while the Faroe and Crozet Islands were completely glaciated.

The permanent snow cover necessary for glacier formation is affected by factors such as the degree of slope on the land, amount of snowfall and the winds. Glaciers can be found in all latitudes except from 20° to 27° north and south of the equator where the presence of the descending limb of the Hadley circulation lowers precipitation so much that with high insolation snow lines reach above . Between 19˚N and 19˚S, however, precipitation is higher and the mountains above usually have permanent snow.

Even at high latitudes, glacier formation is not inevitable. Areas of the Arctic, such as Banks Island, and the McMurdo Dry Valleys in Antarctica are considered polar deserts where glaciers cannot form because they receive little snowfall despite the bitter cold. Cold air, unlike warm air, is unable to transport much water vapor. Even during glacial periods of the Quaternary, Manchuria, lowland Siberia, and central and northern Alaska, though extraordinarily cold, had such light snowfall that glaciers could not form.

In addition to the dry, unglaciated polar regions, some mountains and volcanoes in Bolivia, Chile and Argentina are high () and cold, but the relative lack of precipitation prevents snow from accumulating into glaciers. This is because these peaks are located near or in the hyperarid Atacama Desert.

Glaciers erode terrain through two principal processes: abrasion and plucking.

As glaciers flow over bedrock, they soften and lift blocks of rock into the ice. This process, called plucking, is caused by subglacial water that penetrates fractures in the bedrock and subsequently freezes and expands. This expansion causes the ice to act as a lever that loosens the rock by lifting it. Thus, sediments of all sizes become part of the glacier's load. If a retreating glacier gains enough debris, it may become a rock glacier, like the Timpanogos Glacier in Utah.

Abrasion occurs when the ice and its load of rock fragments slide over bedrock and function as sandpaper, smoothing and polishing the bedrock below. The pulverized rock this process produces is called rock flour and is made up of rock grains between 0.002 and 0.00625 mm in size. Abrasion leads to steeper valley walls and mountain slopes in alpine settings, which can cause avalanches and rock slides, which add even more material to the glacier.

Glacial abrasion is commonly characterized by glacial striations. Glaciers produce these when they contain large boulders that carve long scratches in the bedrock. By mapping the direction of the striations, researchers can determine the direction of the glacier's movement. Similar to striations are chatter marks, lines of crescent-shape depressions in the rock underlying a glacier. They are formed by abrasion when boulders in the glacier are repeatedly caught and released as they are dragged along the bedrock.

The rate of glacier erosion varies. Six factors control erosion rate:
When the bedrock has frequent fractures on the surface, glacial erosion rates tend to increase as plucking is the main erosive force on the surface; when the bedrock has wide gaps between sporadic fractures, however, abrasion tends to be the dominant erosive form and glacial erosion rates become slow.

Glaciers in lower latitudes tend to be much more erosive than glaciers in higher latitudes, because they have more meltwater reaching the glacial base and facilitate sediment production and transport under the same moving speed and amount of ice.

Material that becomes incorporated in a glacier is typically carried as far as the zone of ablation before being deposited. Glacial deposits are of two distinct types:

Larger pieces of rock that are encrusted in till or deposited on the surface are called "glacial erratics". They range in size from pebbles to boulders, but as they are often moved great distances, they may be drastically different from the material upon which they are found. Patterns of glacial erratics hint at past glacial motions.

Glacial moraines are formed by the deposition of material from a glacier and are exposed after the glacier has retreated. They usually appear as linear mounds of till, a non-sorted mixture of rock, gravel and boulders within a matrix of a fine powdery material. Terminal or end moraines are formed at the foot or terminal end of a glacier. Lateral moraines are formed on the sides of the glacier. Medial moraines are formed when two different glaciers merge and the lateral moraines of each coalesce to form a moraine in the middle of the combined glacier. Less apparent are ground moraines, also called "glacial drift", which often blankets the surface underneath the glacier downslope from the equilibrium line.

The term "moraine" is of French origin. It was coined by peasants to describe alluvial embankments and rims found near the margins of glaciers in the French Alps. In modern geology, the term is used more broadly, and is applied to a series of formations, all of which are composed of till. Moraines can also create moraine dammed lakes.

Drumlins are asymmetrical, canoe shaped hills made mainly of till. Their heights vary from 15 to 50 meters and they can reach a kilometer in length. The steepest side of the hill faces the direction from which the ice advanced ("stoss"), while a longer slope is left in the ice's direction of movement ("lee").

Drumlins are found in groups called "drumlin fields" or "drumlin camps". One of these fields is found east of Rochester, New York; it is estimated to contain about 10,000 drumlins.

Although the process that forms drumlins is not fully understood, their shape implies that they are products of the plastic deformation zone of ancient glaciers. It is believed that many drumlins were formed when glaciers advanced over and altered the deposits of earlier glaciers.

Before glaciation, mountain valleys have a characteristic "V" shape, produced by eroding water. During glaciation, these valleys are often widened, deepened and smoothed to form a "U"-shaped glacial valley or glacial trough, as it is sometimes called. The erosion that creates glacial valleys truncates any spurs of rock or earth that may have earlier extended across the valley, creating broadly triangular-shaped cliffs called truncated spurs. Within glacial valleys, depressions created by plucking and abrasion can be filled by lakes, called paternoster lakes. If a glacial valley runs into a large body of water, it forms a fjord.

Typically glaciers deepen their valleys more than their smaller tributaries. Therefore, when glaciers recede, the valleys of the tributary glaciers remain above the main glacier's depression and are called hanging valleys.

At the start of a classic valley glacier is a bowl-shaped cirque, which has escarped walls on three sides but is open on the side that descends into the valley. Cirques are where ice begins to accumulate in a glacier. Two glacial cirques may form back to back and erode their backwalls until only a narrow ridge, called an arête is left. This structure may result in a mountain pass. If multiple cirques encircle a single mountain, they create pointed pyramidal peaks; particularly steep examples are called horns.

Passage of glacial ice over an area of bedrock may cause the rock to be sculpted into a knoll called a "roche moutonnée," or "sheepback" rock. Roches moutonnées may be elongated, rounded and asymmetrical in shape. They range in length from less than a meter to several hundred meters long. Roches moutonnées have a gentle slope on their up-glacier sides and a steep to vertical face on their down-glacier sides. The glacier abrades the smooth slope on the upstream side as it flows along, but tears rock fragments loose and carries them away from the downstream side via plucking.

As the water that rises from the ablation zone moves away from the glacier, it carries fine eroded sediments with it. As the speed of the water decreases, so does its capacity to carry objects in suspension. The water thus gradually deposits the sediment as it runs, creating an alluvial plain. When this phenomenon occurs in a valley, it is called a "valley train". When the deposition is in an estuary, the sediments are known as bay mud.

Outwash plains and valley trains are usually accompanied by basins known as "kettles". These are small lakes formed when large ice blocks that are trapped in alluvium melt and produce water-filled depressions. Kettle diameters range from 5 m to 13 km, with depths of up to 45 meters. Most are circular in shape because the blocks of ice that formed them were rounded as they melted.

When a glacier's size shrinks below a critical point, its flow stops and it becomes stationary. Meanwhile, meltwater within and beneath the ice leaves stratified alluvial deposits. These deposits, in the forms of columns, terraces and clusters, remain after the glacier melts and are known as "glacial deposits".

Glacial deposits that take the shape of hills or mounds are called "kames". Some kames form when meltwater deposits sediments through openings in the interior of the ice. Others are produced by fans or deltas created by meltwater. When the glacial ice occupies a valley, it can form terraces or kames along the sides of the valley.

Long, sinuous glacial deposits are called "eskers". Eskers are composed of sand and gravel that was deposited by meltwater streams that flowed through ice tunnels within or beneath a glacier. They remain after the ice melts, with heights exceeding 100 meters and lengths of as long as 100 km.

Very fine glacial sediments or rock flour is often picked up by wind blowing over the bare surface and may be deposited great distances from the original fluvial deposition site. These eolian loess deposits may be very deep, even hundreds of meters, as in areas of China and the Midwestern United States of America. Katabatic winds can be important in this process.

Large masses, such as ice sheets or glaciers, can depress the crust of the Earth into the mantle. The depression usually totals a third of the ice sheet or glacier's thickness. After the ice sheet or glacier melts, the mantle begins to flow back to its original position, pushing the crust back up. This post-glacial rebound, which proceeds very slowly after the melting of the ice sheet or glacier, is currently occurring in measurable amounts in Scandinavia and the Great Lakes region of North America.

A geomorphological feature created by the same process on a smaller scale is known as "dilation-faulting". It occurs where previously compressed rock is allowed to return to its original shape more rapidly than can be maintained without faulting. This leads to an effect similar to what would be seen if the rock were hit by a large hammer. Dilation faulting can be observed in recently de-glaciated parts of Iceland and Cumbria.

The polar ice caps of Mars show geologic evidence of glacial deposits. The south polar cap is especially comparable to glaciers on Earth. Topographical features and computer models indicate the existence of more glaciers in Mars' past.

At mid-latitudes, between 35° and 65° north or south, Martian glaciers are affected by the thin Martian atmosphere. Because of the low atmospheric pressure, ablation near the surface is solely due to sublimation, not melting. As on Earth, many glaciers are covered with a layer of rocks which insulates the ice. A radar instrument on board the Mars Reconnaissance Orbiter found ice under a thin layer of rocks in formations called lobate debris aprons (LDAs).
The pictures below illustrate how landscape features on Mars closely resemble those on the Earth.





</doc>
<doc id="12464" url="https://en.wikipedia.org/wiki?curid=12464" title="Gylfaginning">
Gylfaginning

Gylfaginning ( [ˈɟʏlvaˌɟɪnːɪŋg]; ; either "Tricking of Gylfi"; c. 20,000 words), is the first part of Snorri Sturluson's 13th century "Prose Edda" after Prologue. The "Gylfaginning" deals with the creation and destruction of the world of the Norse gods, and many other aspects of Norse mythology. The second part of the Prose Edda is called the "Skáldskaparmál" and the third "Háttatal".

The "Gylfaginning" tells the story of Gylfi, a king of "the land that men now call Sweden", who after being tricked by one of the goddesses of the Æsir, wonders if all Æsir use magic and tricks for their will to be done. This is why he journeys to Asgard, but on the way he is tricked by the gods and arrives in some other place, where he finds a great palace. Inside the palace he encounters a man who asks Gylfi's name and so King Gylfi introduces himself as Gangleri. Gangleri then is taken to the king of the palace and comes upon three men: High, Just-As-High, and Third.

Gangleri is then challenged to show his wisdom by asking questions, as is the custom in many Norse sagas. Each question made to High, Just-As-High, and Third is about an aspect of the Norse mythology or its gods, and also about the creation and destruction of the world (Ragnarök). In the end all the palace and its people just vanish and Gylfi is left standing on empty ground. It is then implied that as Gylfi returns to his nation, he retells the tales he was told. It can be argued that Snorri used this narrative device as a means of being able to safely document a vanishing and largely oral tradition within a Christian context.



</doc>
<doc id="12466" url="https://en.wikipedia.org/wiki?curid=12466" title="Glorious Revolution">
Glorious Revolution

The Glorious Revolution, also called the Revolution of 1688, refers to the November 1688 deposition and subsequent replacement of James II and VII as ruler of England, Scotland and Ireland by his daughter Mary and her Dutch husband William of Orange. The outcome of events in all three kingdoms and Europe, the Revolution was quick and relatively bloodless, though establishing the new regime took much longer and led to significant casualties. 
The term was first used by John Hampden in late 1689. 

Despite his Catholicism, James became king in February 1685 with widespread support. Many feared excluding him would lead to a repetition of the 16381651 Wars of the Three Kingdoms and since his Protestant daughter Mary was heir, it was perceived as a short-term issue. James suspended Parliament in November 1685 when it refused to repeal the anti-Catholic Test Acts; imposing the measure required him to bypass existing laws and statutes, causing the instability his supporters wanted to avoid. 

Many were Tory members of the Church of England, who remained loyal until actions like the prosecution of seven Anglican Bishops seemed to go beyond tolerance and into an assault on the church. Two events in June 1688 turned dissent into a political crisis; on 10th, the birth of his son, James Francis, raised the prospect of a Catholic dynasty. On 30th, the acquittal of the bishops led to widespread anti-Catholic riots throughout England and Scotland and destroyed James' political authority.

As stadtholder of Holland, William was de facto ruler of the Dutch Republic; the coalition he built after 1678 to defend it against French expansion was threatened by an Anglo-French alliance. With financial and political support from allies in England, Scotland and Europe, a fleet of 463 ships landed William and 14,000 men in Torbay on 5 November. As he advanced on London, desertions reduced the 30,000 strong Royal Army to 4,000; James ordered these remnants disbanded and went into exile in December. A Convention Parliament met in April 1689, making William and Mary joint monarchs of England; a separate but similar Scottish settlement was made in June. 

The Revolution was followed by pro-Stuart revolts in Scotland and Ireland, while Jacobitism persisted into the late 18th century. However, it ended a century of political dispute by confirming the primacy of Parliament over the Crown, a principle established in the Bill of Rights 1689. Restrictions on Catholics contained in the 1678 and 1681 English and Scottish Test Acts remained in force until 1828; prohibitions on the monarch were not removed until 2015.

Despite his Catholicism, when James became king in 1685 his position seemed secure, as demonstrated by the rapid defeat of the Argyll and Monmouth Rebellions; less than four years later, he was forced into exile. Often portrayed as an exclusively English event, modern historians argue it was the result of events in all three kingdoms. It is also suggested hostility to James was partly due to Charles II, whose policies were seen as being pro-France, pro-Catholic and absolutist.

Prior to the 1638-1651 Wars of the Three Kingdoms, the vast majority of the English supported monarchy and belonged to the Church of England, even if they disagreed with aspects of doctrine. In 1649, Charles I was executed and replaced with the Commonwealth, a republic dominated by religious Independents like Oliver Cromwell, who opposed any state-ordered religion. After the church was restored in 1660, the 1662 Act of Uniformity enforced greater consistency and expelled over 2,000 Dissenting clergy. Radicals like Algernon Sidney and Henry Neville ensured republican ideas retained visibility out of proportion to their numbers and increased fears of 'disorder'. 

The 1679-1681 Exclusion Crisis broadly split the English political class into those who wanted to 'exclude' James from the throne, or Whigs, and their opponents, or Tories. Many Whigs feared the consequences of bypassing James, while Tory support was conditional on preserving the primacy of the Church of England. Both saw it as a short-term issue; his second marriage remained childless and the heirs were his Protestant daughters, Mary and Anne.

These distinctions were largely absent in Scotland where support was more broadly based. In 1681, the Parliament of Scotland passed the Succession Act, which confirmed the duty of all to support the natural heir 'regardless of religion.' The Act explicitly stated one aim was to make James' exclusion from the English throne impossible without '...the fatall and dreadfull consequences of a civil war.' 
Over 95% of Scots belonged to the Church of Scotland or kirk and apart from 1653-1660, other Protestant sects like Congregationalists were barred. 'Episcopalian' and 'Presbyterian' now implies differences in doctrine but in the 17th century, it related to structure. 'Episcopalian' meant governance by bishops, usually appointed by the monarch, while Presbyterian meant rule by Elders, nominated by congregations. Conflict concerned the exercise of authority but doctrine remained broadly similar, regardless of changes in governance. Unlike the Church of England, the kirk was Calvinist in doctrine; even its bishops viewed many English practices as essentially Catholic. 

His Catholicism made James more popular in Ireland but religion was only one issue; the Church of Ireland was a minority even among Irish Protestants and the penal laws loosely enforced. A bigger concern was the percentage of Irish lands owned by Catholics, which fell from 90% in 1600 to 22% by 1685. The 1662 Settlement only benefited a few large landowners, including James and his Lord Deputy Tyrconnell, who had little interest in changing them. Catholic and Protestant merchants alike objected to the reimposition of commercial restrictions, which prevented them from trading direct with North America and imposed tariffs on Irish exports.

These issues and his response gradually destabilised each of James' kingdoms. Many supported him in 1685 for fear of civil war if he were bypassed; by 1688, it seemed only his removal could prevent one.

The first Stuart monarch, James VI and I, created a vision of a centralised state, run by a monarch whose authority came from God and where the function of Parliament, bishops or elders was to obey. His successors ruled without Parliament for long periods, using the Royal Prerogative instead; legislation passed in this way could be withdrawn as and when the king decided.

17th century society was extremely structured and most Tories viewed James' Catholicism as less important than the principle of hereditary succession. In addition, he had sworn to uphold the supremacy of the Church of England, in an age when such things mattered. Five of the seven bishops prosecuted in 1688 refused to swear allegiance to William and Mary, because they felt bound by their previous oath. Tolerance was viewed as undermining this principle and Parliament refused to pass them, despite being "the most Loyal Parliament a Stuart ever had".

Catholicism in general was associated with the absolutist policies of Louis XIV, while the Edict of Fontainebleau in October 1685 revoked tolerance for French Protestants. Over the next four years, an estimated 200,000 – 400,000 French Huguenots went into exile, 40,000 of whom settled in London. Combined with the killing of 2,000 Vaudois Protestants in 1686, it led to fears Protestant Europe was threatened by a Catholic counter-reformation. 

These concerns were reinforced by events in Ireland. Talbot wanted to create a Catholic establishment able to survive James' death, which meant replacing Protestant officials, but at a pace which was inherently destabilising. For many, land reform was as important as religion; it divided the Catholic Old English elite like Talbot, who benefitted from the 1662 Land Settlement, and the Gaelic Irish, who largely did not. These tensions resurfaced in the 1689 Patriot Parliament, which many Jacobites criticised as failing to meet the needs of all Irish Catholics.

Historians generally accept James wished to promote Catholicism, not establish an absolutist state but his stubborn and inflexible reaction to opposition had the same result. When the English and Scottish Parliaments refused to repeal the 1678 and 1681 Test Acts, he dismissed them and ruled by decree. His attempts to form a 'King's party' of Catholics, English Dissenters and dissident Scottish Presbyterians rewarded those who backed the 1685 rebellions, while undermining those who had supported him.

His supporters wanted stability and the rule of law, but James often appeared to undermine them. After suspending Parliament in November 1685, he sought to rule by decree or 'dispense'; judges who disagreed were dismissed and his right confirmed in April 1686. The principle was well-established, the scope and approach caused considerable concern. 

This was followed by actions viewed as attacks on the Church of England; Henry Compton, Bishop of London, was suspended for refusing to ban John Sharp from preaching after he gave an anti-Catholic sermon. The Commission for Ecclesiastical Causes, set up to regulate the church included suspected Catholics, like the Earl of Huntingdon. 

In addition, James frequently made things worse by an inability to accept opposition. In April 1687, he ordered the fellows of Magdalen College, Oxford to elect Anthony Farmer as President. His right to do so was not challenged but Farmer was ineligible under the college statutes and John Hough was elected instead. Farmer withdrew and Hough replaced by the Bishop of Oxford but James also demanded the fellows apologise for 'defying' him; when they refused, they were replaced by Catholics.

Creating a 'Kings Party' of Catholics and Dissenters ignored the fact neither was significant in numbers; by 1680, Catholics formed 1.1% of the English population, Dissenters 4.4%. In Scotland, the numbers were even lower; combined with 'occasional conformity', this meant in practice private worship was already tolerated. Both were also divided; moderate Catholics feared a potential backlash, particularly when thousands of French Huguenot refugees arrived in London. Among the Dissenters, Quakers and Congregationalists supported repeal of the Test Acts; others wanted to amend the 1662 Act of Uniformity and re-enter the Church of England.

Even those who benefitted did not trust James; in 1687, he nominated the Dissenter Sir John Shorter as Lord Mayor of London. Before taking office, Sir John insisted on complying with the Test Act, even taking Anglican communion; he reportedly did so due to a 'distrust of the King's favour...thus encouraging that which His Majesties whole Endeavours were intended to disannull.'

To ensure a Parliament that would vote for his Declaration of Indulgence, James made sweeping changes to local government, the power base for many Tories. Candidates for Members of Parliament had to be approved by their local Lord Lieutenant; eligibility for both offices required positive answers to the 'Three Questions', including a commitment to repeal the Test Act and those giving negative answers dismissed. James relied on an increasingly narrow support base; government positions and town corporations were purged to create an electoral machine that would return only supporters of Royal authority. Finally, on 24 August 1688, James ordered writs issued for a general election.

The expansion of the military in all three kingdoms caused great concern, particularly in England and Scotland, where the civil war left huge resistance to standing armies. In Ireland, Talbot replaced Protestant officers with Catholics; James did the same in England, while basing the troops at Hounslow appeared a deliberate attempt to overawe Parliament. By 1688, the army numbered over 34,000 men; for comparison, the Tory-dominated Parliament of 1698 approved one of 7,000.

In April 1688, James re-issued the Declaration of Indulgence and ordered it read in every church; when the Archbishop of Canterbury, head of the Church of England, and six other bishops asked him to reconsider, they were arrested on charges of seditious libel and confined in the Tower of London. Two events turned dissent into a crisis; the birth of James Francis Edward on 10 June created the prospect of a Catholic dynasty, while the acquittal of the Seven Bishops on 30th destroyed James' political authority.

In 1677, James' daughter and heir Mary married her Protestant cousin William of Orange, stadtholder of the main provinces of the Dutch Republic. They initially shared common objectives; both wanted Mary to succeed her father, while French ambitions in the Spanish Netherlands threatened English as well as Dutch commercial interests. In 1685, William sent the Anglo-Scots Brigade to suppress the Monmouth Rebellion but differences on domestic and foreign policy meant their relationship deteriorated thereafter. 

The States General was dominated by the Amsterdam merchants who preferred peace but Dutch public opinion began to change over the course of 1685. This was a combination of Monmouth's execution, the prosecution of his supporters, French demands over the Palatinate and the October 1685 expulsion of French Protestants. In 1686, Frederick William of Prussia replaced his French alliance for one with the Dutch, who also joined the anti-French League of Augsburg. 

James wanted to avoid war on either side, but since it was felt the Dutch could not resist a combined Anglo-French attack, this obliged them to rely on English neutrality. After a clash between Dutch and French ships in July 1686, William began to fear neutrality was not enough and that active participation by the Royal Navy was essential against French naval power. Mutual suspicion between the two leaders and their advisors made it hard to establish a working relationship. Those around William were largely English and Scots exiles, the latter with strong links to their co-religionists in Ireland, who felt threatened by Tyrconnell's reforms. James relied on an ever smaller circle of counsellors, chiefly the Earl of Sunderland and Catholic zealots like Melfort and Perth. 

James now sought William's support for repeal of the Test Acts. Doing so would jeopardise his decade-long efforts to build a Protestant alliance against France and inevitably he refused, further damaging their relationship. Having assumed his marriage ensured English support in a war with France, William began to fear it might even be used against him. James assured his envoy Everhard van Weede Dijkvelt rumours of a French alliance were false, but failed to appreciate the level of distrust caused by his domestic policies. In August 1687, William's cousin de Zuylestein travelled to England, officially bringing condolences on the death of the Queen's mother but also to be updated on political developments. 

After fourteen years of marriage and multiple miscarriages, the Queen was childless and in October, it was announced she was pregnant. Melfort immediately declared it was a boy and James sent Mary a letter carried by Irish Catholic Ignatius White, urging her to convert. The combination convinced many James was seeking a Catholic heir, one way or the other. It is suggested this was the key factor in William's decision to invade England. 

Early in 1688, a pamphlet titled "The Letter" circulated in England, composed by Grand Pensionary Gaspar Fagel, who handled the Dutch foreign affairs. This claimed to be a response to arguments in support of repeal by James Stewart; a Presbyterian radical and exile, in 1692 he was appointed Lord Advocate by William and was almost certainly a double agent. Fagel guaranteed freedom of worship but retained the Test Acts, which many Dissenters viewed as essential and undercut James, who offered tolerance but only in return for repeal. This demonstrates how carefully William managed the propaganda war; his supporters provided detailed information on English public opinion and developments, very little of which was intercepted.

A European war seemed inevitable, which made securing or neutralising English resources vital to both the Dutch and French. In April 1688, Louis XIV announced new tariffs on Dutch herring imports and plans to support the Royal Navy in the Channel. This was largely a gesture, as it required moving units from the Mediterranean, but viewing it as the prelude to a formal alliance between England and France, William and his supporters began to prepare a military intervention. On the pretext of fighting French privateers, in July the States General approved the recruitment of an additional 9,000 sailors and the construction of 21 new warships. 

William laid careful plans over a number of months for an invasion, which he hoped to execute in September 1688. William would not invade England without assurances of English support, and so in April, he asked for a formal invitation to be issued by a group of leading English statesmen. Gilbert Burnet recorded a conversation at the end of April between William and Admiral Edward Russell:

In May, Russell told William that the English opposition to James would not wait any longer for help and they would rise against James in any event. William feared that if he did not now head the conspiracy the English would set up a republic, even more inimical to the Dutch state. In June, William sent Count Zuylestein to England, ostensibly to congratulate James on the birth of the Prince of Wales but in reality to communicate with William's associates.

Only after the Prince of Wales had been born in June, however, and many suspected he was supposititious, did the Immortal Seven (who consisted of one bishop and six nobles) decide to comply, with the letter to William dated 18 June (Julian calendar), reaching him in The Hague on 30 June, and dispatched by Rear Admiral Herbert, disguised as a common sailor. The Seven consisted of Lord Shrewsbury, Lord Devonshire, Lord Danby, Lord Lumley, Henry Compton, Edward Russell, and Henry Sydney. The invitation declared:

The Seven went on to claim that "much the greatest part of the nobility and gentry" were dissatisfied and would rally to William, and that James's army "would be very much divided among themselves; many of the officers being so discontented that they continue in their service only for a subsistence ... and very many of the common soldiers do daily shew such an aversion to the Popish religion, that there is the greatest probability imaginable of great numbers of deserters ... and amongst the seamen, it is almost certain, there is not one in ten who would do them any service in such a war". The Seven believed that the situation would be much worse before another year due to James's plans to remodel the army by the means of a packed Parliament or, should the parliamentary route fail, through violent means which would "prevent all possible means of relieving ourselves". The Seven also promised to rally to William upon his landing in England and would "do all that lies in our power to prepare others to be in as much readiness as such an action is capable of".

Meanwhile, William's confidante Willem Bentinck launched a propaganda campaign in England. In the numerous pamphlets distributed, William was presented in the best possible light; as a true Stuart yet blessedly free from the usual Stuart vices of crypto-Catholicism, absolutism, and debauchery. Much of the later "spontaneous" support for William had been carefully organised by Bentinck and his agents.

In August, it became clear that William had surprisingly strong support within the English army, a situation brought about by James himself. In January 1688 he had forbidden any of his subjects to serve the Dutch and had demanded that the Republic dissolve its six mercenary Scottish and English regiments. When this was refused, he asked that at least those willing would be released from their martial oath to be free to return to Britain. To this William consented as it would purify his army of Jacobite elements. In total 104 officers and 44 soldiers returned. The officers were enlisted within the British armies and so favoured that the established officer corps began to fear for its position. On 14 August Lord Churchill wrote to William: "I owe it to God and my country to put my honour into the hands of Your Highness". Nothing comparable happened within the Royal Navy, however; claims after the event by certain captains that they had somehow prevented the English fleet from engaging seem to have been little more than attempts at self-aggrandisement.

Successful intervention in England required William to secure his position in Europe, the first step being to ensure support from Emperor Leopold I against French demands in the Rhineland. William's envoy Johann von Görtz provided assurances English Catholics would not be persecuted, while victories over the Ottomans, including the capture of Belgrade in early September, allowed Leopold to focus on Germany. When France attacked Philippsburg shortly afterwards, he activated the 1686 anti-French League of Augsburg. Finally, Ernest Augustus of Hanover and John George III of Saxony confirmed their neutrality, despite fears they would take the French side.
Next was to secure the Electorate of Cologne, whose support enabled France to bypass Dutch border defences and nearly over-run the Republic in 1672. Its ruler was nominated by Pope Innocent XI, who was in dispute with both Louis and James over the right to appoint Catholic bishops and clergy. When the old Elector died in June 1688, Innocent and Leopold ignored the French candidate in favour of Joseph Clemens of Bavaria. 

Ignoring objections from the English conspirators, who considered a token force sufficient, William began assembling an invasion force of 14,000 men. Total costs were estimated as around seven million guilders; this required funding from Amsterdam, which provided 30% of the Dutch budget and had not yet approved the expedition. Although tariffs imposed by Louis on Dutch imports convinced the Amsterdam merchants war was inevitable, they were concerned by the implications of placing William on the throne of England. Agreement was reached at the end of September and the financing raised in only three days but their fears were arguably justified. The Revolution resulted in a permanent diminishment of Amsterdam's power within the Republic and its status as the world's leading commercial and financial centre. 

Many were also uneasy about sending so much of the 30,000 strong Dutch States Army overseas. Bentinck negotiated contracts for 13,616 German mercenaries from Brandenburg, Württemberg, Hesse-Cassel, and Celle to man Dutch border fortresses, freeing units such as the Anglo-Scots Brigade for use against England. As the Dutch would typically double or triple their total army strength in wartime, the numbers were low enough to be explained as a limited precaution against French aggression. Shortly afterwards, Marshal Frederick Schomberg was instructed by William to prepare for a Western campaign.

Further financial support was obtained from the most disparate sources: the Jewish banker Francisco Lopes Suasso lent two million guilders; when asked what security he desired, Suasso answered: "If you are victorious, you will surely repay me; if not, the loss is mine." 

Despite all the preparations, William had great trouble convincing the Dutch class of city and provincial rulers, the regents, that such an expensive expedition was really necessary. Also, he personally feared that the French might attack the Republic through Flanders when its army was tied up in England. One of the "Seven", Lord Danby, suggested postponing the invasion until the following year. By early September, William was on the brink of cancelling the entire expedition when French policy played into his hand.

In Germany, matters had come to a head. The Pope had refused to confirm Louis's favourite candidate for the bishopric of Cologne, William Egon of Fürstenberg. Enraged, the French king decided to execute a lightning campaign into Germany before the emperor could shift his troops to the West. Louis also hoped to keep his Turkish ally in the war this way. For the immediate future James had to hold his own, something Louis expected him to be quite capable of, especially if the Dutch were intimidated. On 9 September (Gregorian calendar) the French envoy, D'Avaux, handed two letters from the French king, who had known of the invasion plans since May, to the States General of the Netherlands. In the first they were warned not to attack James. In the second they were advised not to interfere with the French policy in Germany. James hurriedly distanced himself from the first message, trying to convince the States General that there was no secret Anglo-French alliance against them. This had precisely the opposite effect: many members became extremely suspicious. The second message proved that the main French effort was directed to the east, not the north, so there was no immediate danger of a French invasion for the Republic itself.

From 22 September, Louis XIV seized all Dutch ships present in French ports, totalling about a hundred vessels, apparently proving that real war with France was imminent, though Louis had meant it to be a mere warning. On 26 September the powerful city council of Amsterdam decided to officially support the invasion. On 27 September Louis crossed the Rhine into Germany to attack Philippsburg and William began to move the Dutch field army from the eastern borders, where it had trained on the Mookerheide, to the coast, even though most of the new mercenaries had not yet arrived.

On 29 September the States of Holland, the government of the most important Dutch province, fearing a French-English alliance, gathered in secret session and approved the operation, agreeing to make the English "King and Nation live in a good relation, and useful to their friends and allies, and especially to this State". They accepted William's argument that a preventive strike was necessary to avoid a repeat of the events of 1672, when England and France had jointly attacked the Republic, "an attempt to bring this state to its ultimate ruin and subjugation, as soon as they find the occasion". William denied any intention "to remove the King from the throne or become master of England". The States ordered a Dutch fleet of 53 warships to escort the troop transports. This fleet was in fact commanded by Lieutenant-Admiral Cornelis Evertsen the Youngest on the "Cortgene" and Vice-Admiral Philips van Almonde on the "Provincie Utrecht" but in consideration of English sensitivities placed, on 6 October, under the nominal command of Rear-Admiral Herbert, who for the occasion was appointed Lieutenant-Admiral-General, i.e. acting supreme commander, of the Dutch navy. He sailed on the "Leyden", accompanied by Lieutenant-Admiral Willem Bastiaensz Schepers, the Rotterdam shipping magnate who had organised the transport fleet. Though William was himself Admiral-General of the Republic, he, as was usual, abstained from operational command, sailing conspicuously on the new frigate "Den Briel". The States General allowed the core regiments of the Dutch field army to participate under command of Marshall Schomberg. Despite being assisted in it by the regular Dutch fleet and field army, his attempt to change the situation in England was, as the States General made explicit, officially a private family affair of William, merely acting in his capacity of concerned nephew and son-in-law to James, not an undertaking of the Dutch Republic as such.

The Dutch preparations, though carried out with great speed, could not remain secret. The English envoy Ignatius White, the Marquess d'Albeville, warned his country: "an absolute conquest is intended under the specious and ordinary pretences of religion, liberty, property and a free Parliament ...". Louis XIV threatened the Dutch with an immediate declaration of war, should they carry out their plans. Embarkations, started on 22 September (Gregorian calendar), had been completed on 8 October, and the expedition was that day openly approved by the States of Holland; the same day James issued a proclamation to the English nation that it should prepare for a Dutch invasion to ward off conquest. On 30 September/10 October (Julian/Gregorian calendars) William issued the "Declaration of The Hague" (actually written by Fagel), of which 60,000 copies of the English translation by Gilbert Burnet were distributed after the landing in England, in which he assured that his only aim was to maintain the Protestant religion, install a free parliament and investigate the legitimacy of the Prince of Wales. He would respect the position of James. William declared:

William went on to condemn James's advisers for overturning the religion, laws, and liberties of England, Scotland, and Ireland by the use of the suspending and dispensing power; the establishment of the "manifestly illegal" commission for ecclesiastical causes and its use to suspend the Bishop of London and to remove the Fellows of Magdalen College, Oxford. William also condemned James's attempt to repeal the Test Acts and the penal laws through pressuring individuals and waging an assault on parliamentary boroughs, as well as his purging of the judiciary. James's attempt to pack Parliament was in danger of removing "the last and great remedy for all those evils". "Therefore", William continued, "we have thought fit to go over to England, and to carry over with us a force sufficient, by the blessing of God, to defend us from the violence of those evil Counsellors ... this our Expedition is intended for no other design, but to have, a free and lawful Parliament assembled as soon as is possible".

On 4/14 October William responded to the allegations by James in a second declaration, denying any intention to become king or conquer England. Whether he had any at that moment is still controversial.

The swiftness of the embarkations surprised all foreign observers. Louis had in fact delayed his threats against the Dutch until early September because he assumed it then would be too late in the season to set the expedition in motion anyway, if their reaction proved negative; typically such an enterprise would take at least some months. Being ready after the last week of September / first week of October would normally have meant that the Dutch could have profited from the last spell of good weather, as the autumn storms tend to begin in the third week of that month. This year they came early however. For three weeks the invasion fleet was prevented by adverse south-westerly gales from departing from the naval port of Hellevoetsluis and Catholics all over the Netherlands and the British kingdoms held prayer sessions that this "popish wind" might endure. However, on 14/24 October it became the famous "Protestant Wind" by turning to the east.

James only in late August seriously began to consider the possibility of a Dutch invasion and then overestimated the size of the naval force the Dutch would bring against him. He assumed they would equip their full battle fleet, which he himself would be unable to match for financial reasons: in October about thirty English ships-of-the-line had been assembled, all third rates or fourth rates, while heavier vessels remained laid up. Fearing a surprise attack, he declined to position this fleet at The Downs, for striking into the southern North Sea or the Channel the most convenient location, but also a very vulnerable one. When Admiral George Legge, 1st Baron Dartmouth decided to place his fleet at the Gunfleet near the Medway, in a rather withdrawn location, James therefore merely suggested to bring the fleet farther out, though he well understood it otherwise risked becoming locked up in the Thames estuary by the same easterly wind that would allow the Dutch to cross. This was influenced by his belief the Dutch might well attack France instead and his expectation that they would first seek a naval victory before daring to invade – and that it thus would be advantageous to refuse battle. Indeed, it had originally been the Dutch intention to defeat the English first to free the way for the transport fleet – though they too, to lower the cost of the invasion, had not activated any heavier ships – but because it was now so late in the season and conditions on board deteriorated rapidly, they decided to sail in convoy and, if possible, avoid battle.

On 16/26 October William boarded his ship, the "Den Briel" ("Brill" in English). His standard was hoisted, displaying the arms of Nassau quartered with those of England. The words ' ("For Liberty and [the Protestant] Religion"), the slogan of William's ancestor William the Silent while leading the Dutch Revolt against Catholic Spain, were shown next to the House of Orange's motto, ' ("I will maintain"). William's fleet, which with about 40,000 men aboard was roughly twice the size of the Spanish Armada – and assembled in a tenth of the time – consisted of 463 ships. Among these were 49 warships of more than twenty cannon (eight could count as third rates of 60–68 cannon, nine were frigates), 28 galliots, nine fireships, 76 fluyts to carry the soldiers, 120 small transports to carry five thousand horses, about seventy supply vessels and sixty fishing vessels serving as landing craft. Most of the warships had been provided by the Admiralty of Amsterdam. On 19/29 October William's fleet departed from Hellevoetsluis. The fleet was approximately halfway between the Republic and England when the wind changed to the northwest and a gale scattered the fleet, with the "Brill" returning to Hellevoetsluis on 21/31 October. Despite suffering from sea-sickness William refused to go ashore and the fleet reassembled, having lost only one ship that grounded, though about a thousand crippled horses had been thrown into the sea. Press reports were released that deliberately exaggerated the damage and claimed the expedition would be postponed till the spring. English naval command now considered to try blockading Hellevoetsluis but decided against it because it was feared that the English fleet would founder on the Dutch coast, a dangerous lee shore for a blocking force, by the stormy weather.

Taking advantage of a wind again turned to the east, resupplied and re-equipped with new horses, the invasion fleet departed again on 1/11 November and sailed north in the direction of Harwich where Bentinck had a landing site prepared. The fleet changed course to the south however when the wind turned more to the north; it has been suggested that the initial move to the north was a feint and indeed James diverted some of his forces in that direction. Thus they passed twice in sight of the English fleet, which was unable to intercept because of the adverse wind and an unfavourable tide. On 3/13 November the invasion fleet entered the English Channel through the Strait of Dover in an enormous square formation, 25 ships deep, the right and left of the fleet saluting Dover and Calais simultaneously, to show off its size. The troops were lined up on deck, firing musket volleys, with full colours flying and the military bands playing. Rapin de Thoyras, who was on board one of the ships, described it as the most magnificent and affecting spectacle that was ever seen by human eyes. William intended to land at Torbay but due to fog the fleet sailed past it by mistake. The wind made a return impossible and Plymouth was unsuitable as it had a garrison. At this point, with the English fleet in pursuit, Russell told Burnet: "You may go to prayers, Doctor. All is over". At that moment however the wind changed and the fog lifted, enabling the fleet to sail into Torbay, near Brixham, Devon. William came ashore on 5/15 November. When Burnet was ashore he hastened to William and eagerly enquired what William now intended to do. William regarded the interference in military matters by non-military personnel with disgust but he was in good humour at this moment and responded with a delicate reproof: "Well, Doctor, what do you think of predestination now?" The English squadron under Lord Dartmouth was forced by the same change in wind to shelter in Portsmouth harbour. During the next two days William's army disembarked in calm weather.

William brought over 11,212 horse and foot. William's cavalry and dragoons amounted to 3,660. His artillery train contained 21 24-pounder cannon. Including the supply train, his force consisted of about 15,000 men, compared to James's total forces of about 30,000. He also brought 20,000 stand of arms to equip his English supporters. The Dutch army was composed mostly of foreign mercenaries; there were Dutch, Scots, English, German, Swiss, and Swedish regiments, even Laplanders as well as "200 Blacks brought from the Plantations of the Netherlands in America", thus from the colony of Surinam. Many of the mercenaries were Catholic. William had his personal guard regiment with him, the Dutch Blue Guards. In response to the threat James had raised five new regiments of foot and five of horse, as well as bringing in Scottish and Irish soldiers. Louis XIV also sent James 300,000 livres.

The French fleet remained at the time concentrated in the Mediterranean, to assist a possible attack on the Papal State. Louis delayed his declaration of war until 16/26 November hoping at first that their involvement in a protracted English civil war would keep the Dutch from interfering with his German campaign. The same day a second attempt by Legge to attack the landing site again failed by an adverse southwestern gale. The Dutch call their fleet action the "Glorieuze Overtocht", the "Glorious Crossing".

William considered his veteran army to be sufficient in size to defeat any forces (all rather inexperienced) that James could throw against him, but it had been decided to avoid the hazards of battle and maintain a defensive attitude in the hope James's position might collapse by itself. Thus he landed far away from James's army, expecting that his English allies would take the initiative in acting against James while he ensured his own protection against potential attacks. William was prepared to wait; he had paid his troops in advance for a three-month campaign. A slow advance, apart from being necessitated by heavy rainfall anyway, had the added benefit of not over-extending the supply lines; the Dutch troops were under strict orders not even to forage, for fear that this would degenerate into plundering, which would alienate the population.

On 9 November (Julian calendar) William took Exeter after the magistrates had fled the city, entering on a white palfrey, with the two hundred black men forming a guard of honour, dressed in white, with turbans and feathers. In the South support from the local gentry was disappointingly limited, but from 12 November, in the North, many nobles began to declare for William, as they had promised, often by a public reading of the "Declaration". In Yorkshire, printer John White started to print the same document for a more widespread distribution. However, in the first weeks most people carefully avoided taking sides; as a whole the nation neither rallied behind its king, nor welcomed William, but passively awaited the outcome of events. In general, the mood was one of confusion, mutual distrust and depression.

James refused a French offer to send an expeditionary force, fearing that it would cost him domestic support. He tried to bring the Tories to his side by making concessions but failed because he still refused to endorse the Test Act. His forward forces had gathered at Salisbury, and James went to join them on 19 November with his main force, having a total strength of about 19,000. Amid anti-Catholic rioting in London, it rapidly became apparent that the troops were not eager to fight, and the loyalty of many of James' commanders was doubtful; he had been informed of the conspiracy within the army as early as September, but for unknown reasons had refused to arrest the officers involved. Some have argued, however, that if James had been more resolute, the army would have fought and fought well.

The first blood was shed at about this time in a skirmish at Wincanton, Somerset, where Royalist troops under Patrick Sarsfield retreated after defeating a small party of scouts; the total body count on both sides came to about fifteen. In Salisbury, after hearing that some officers had deserted, among them Lord Cornbury, a worried James was overcome by a serious nose-bleed that he interpreted as an evil omen indicating that he should order his army to retreat, which the supreme army commander, the Earl of Feversham, also advised on 23 November. The next day, Lord Churchill, one of James' chief commanders, deserted to William. On 26 November, James's younger daughter, Anne, who doubted the authenticity of her new brother, and who was greatly influenced by Churchill's wife Sarah Churchill, did the same. Both were serious losses. James returned to London that same day. On 27 November he met with all the Lords Spiritual and Temporal who were then in London.

Meanwhile, on 18 November Plymouth had surrendered to William, and on 21 November he began to advance. By 24 November, William's forces were at Sherborne and on 1 December at Hindon. On 4 December he was at Amesbury, and was received by the mayor of Salisbury; three days later they had reached Hungerford, where the following day they met with the King's Commissioners to negotiate. James offered free elections and a general amnesty for the rebels. In reality, by that point James was simply playing for time, having already decided to flee the country. He feared that his English enemies would insist on his execution and that William would give in to their demands. Convinced that his army was unreliable, he sent orders to disband it. On 9 December, the two sides fought a second engagement with the Battle of Reading, a defeat for the King's men.

In December, there was anti-Catholic rioting in Bristol, Bury St. Edmunds, Hereford, York, Cambridge, and Shropshire. On 9 December a Protestant mob stormed Dover Castle, where the Catholic Sir Edward Hales was governor, and seized it. On 8 December William met at last with James's representatives; he agreed to James's proposals but also demanded that all Catholics be immediately dismissed from state functions and that England pay for the Dutch military expenses. He received no reply, however.

In the night of 9/10 December, the Queen and the Prince of Wales fled for France. The next day saw James's attempt to escape, the King dropping the Great Seal in the Thames along the way, as no lawful Parliament could be summoned without it. However, he was captured on 11 December by fishermen in Faversham opposite Sheerness, the town on the Isle of Sheppey. On the same day, 27 Lords Spiritual and Temporal, forming a provisional government, decided to ask William to restore order but at the same time asked the king to return to London to reach an agreement with his son-in-law. It was presided over initially by William Sancroft, Archbishop of Canterbury and, after it was learned that James was still in England, by George Savile, 1st Marquess of Halifax. On the night of 11 December there were riots and lootings of the houses of Catholics and several foreign embassies of Catholic countries in London. The following night a mass panic gripped London during what was later termed the Irish night. False rumours of an impending Irish army attack on London circulated in the capital, and a mob of over 100,000 assembled ready to defend the city.

Upon returning to London on 16 December, James was welcomed by cheering crowds. He took heart at this and attempted to recommence government, even presiding over a meeting of the Privy Council. He sent the Earl of Feversham to William to arrange for a personal meeting to continue negotiations. Now it became evident that William had no longer any desire to keep James in power in England. He was extremely dismayed by the arrival of Lord Feversham. He refused the suggestion that he simply arrest James because this would violate his own declarations and burden his relationship with his wife. In the end it was decided that he should exploit James's fears; the three original commissioners were sent back to James with the message that William felt he could no longer guarantee the king's well-being and that James for his own safety had better leave London for Ham.

William at the same time ordered all English troops to depart from the capital, while his forces entered on 17 December; no local forces were allowed within a twenty-mile radius until the spring of 1690. Already the English navy had declared for William. James, by his own choice, went under Dutch protective guard to Rochester in Kent on 18 December, just as William entered London, cheered by crowds dressed in orange ribbons or waving, lavishly distributed, oranges. The Dutch officers had been ordered that "if he [James] wanted to leave, they should not prevent him, but allow him to gently slip through". James then left for France on 23 December after having received a request from his wife to join her, even though his followers urged him to stay. The lax guard on James and the decision to allow him so near the coast indicate that William may have hoped that a successful flight would avoid the difficulty of deciding what to do with him, especially with the memory of the execution of Charles I still strong. By fleeing, James ultimately helped resolve the awkward question of whether he was still the legal king or not, having created according to many a situation of interregnum.

On 28 December, William took over the provisional government by appointment of the peers of the realm, as was the legal right of the latter in circumstances when the king was incapacitated, and, on the advice of his Whig allies, summoned an assembly of all the surviving members of parliament of Charles II's reign, thus sidelining the Tories of the Loyal Parliament of 1685. This assembly called for a chosen English Convention Parliament, elected on 5 January 1689 NS, which convened on 22 January. William did not intervene in the election that followed. This elected body consisted of 513 members, 341 of whom had been elected before, 238 having been members of at least one Exclusion Bill Parliament, but only 193 having been elected in 1685. The name "Convention" was chosen because only the king could call a Parliament, although as William had been appointed "de facto" regent by the peers the Convention could be argued to be, strictly speaking, a lawful Parliament.

Although James had fled the country, he still had many followers, and William feared that the king might return, relegating William to the role of a mere regent, an outcome which was unacceptable to him. On 30 December, William, speaking to the Marquess of Halifax, threatened to leave England "if King James came again" and determined to go back to the Netherlands "if they went about to make him Regent".

The English Convention Parliament was very divided on the issue. The radical Whigs in the Lower House proposed to elect William as a king (meaning that his power would be derived from the people); the moderates wanted an acclamation of William and Mary together; the Tories wanted to make him regent or only acclaim Mary as queen. On 28 January a committee of the whole House of Commons promptly decided by acclamation that James had broken "the original contract"; had "abdicated the government"; and had left the throne "vacant". The House of Lords wished to amend this, however, as many were still loyal to James and believed in the Anglican doctrine of non-resistance. The Lords rejected the proposal for a regency in James's name by 51 to 48 on 2 February. The Lords also substituted the word "abdicated" for "deserted" and removed the "vacancy" clause. The Lords voted against proclaiming William and Mary monarchs by 52 to 47. On 4 February the Lords reaffirmed their amendments to the Commons's resolution by 55 to 51 and 54 to 53. On 5 February the Commons voted 282 to 151 for maintaining the original wording of the resolution. The next day, the two Houses entered into a conference but failed to resolve the matter. William in private conversation (with Halifax, Danby, Shrewsbury, Lord Winchester and Lord Mordaunt) made it clear that they could either accept him as king or deal with the Whigs without his military presence, for then he would leave for the Republic. But he let it be known that he was happy for Mary to be nominal monarch and preference in the succession given to Anne's children over his by a subsequent marriage. Anne declared that she would temporarily waive her right to the crown should Mary die before William, and Mary refused to be made queen without William as king. The Lords on 6 February now accepted the words "abdication" and "vacancy" and Lord Winchester's motion to appoint William and Mary monarchs. Generally there was a great fear that the situation might deteriorate into a civil war.

The proposal to draw up a statement of rights and liberties and James's invasion of them was first made on 29 January in the Commons, with members arguing that the House "can not answer it to the nation or Prince of Orange till we declare what are the rights invaded" and that William "cannot take it ill if we make conditions to secure ourselves for the future" to "do justice to those who sent us hither". On 2 February a committee specially convened reported to the Commons 23 Heads of Grievances, which the Commons approved and added some of their own. However, on 4 February the Commons decided to instruct the committee to differentiate between "such of the general heads, as are introductory of new laws, from those that are declaratory of ancient rights". On 7 February the Commons approved this revised Declaration of Right, and on 8 February instructed the committee to put into a single text the Declaration (with the heads which were "introductory of new laws" removed), the resolution of 28 January and the Lords' proposal for a revised oath of allegiance. It passed the Commons without division.

The Declaration of Right was in December 1689 enacted in an Act of Parliament, the Bill of Rights 1689. It listed twelve of James's policies by which James designed to "endeavour to subvert and extirpate the protestant religion, and the laws and liberties of this kingdom". These were:

The Bill of Rights also vindicated and asserted the nation's "ancient rights and liberties" by declaring:

On 13 February the clerk of the House of Lords read the Declaration of Right, and Halifax, in the name of all the estates of the realm, asked William and Mary to accept the throne. William replied for his wife and himself: "We thankfully accept what you have offered us". They then went in procession to the great gate at Whitehall. The Garter King at Arms proclaimed them King and Queen of England, France and Ireland, whereupon they adjourned to the Chapel Royal, with Compton preaching the sermon. They were crowned on 11 April, swearing an oath to uphold the laws made by Parliament. The Coronation Oath Act 1688 had provided a new coronation oath, whereby the monarchs were to "solemnly promise and swear to govern the people of this kingdom of England, and the dominions thereunto belonging, according to the statutes in parliament agreed on, and the laws and customs of the same". They were also to maintain the laws of God, the true profession of the Gospel, and the Protestant Reformed faith established by law.

While Scotland played no part in the landing and there was little enthusiasm for William and Mary, by November 1688 only a tiny minority actively supported James. Many of William's advisors were Scots, including Lord Melville, the Duke of Argyll, William Carstares, his personal chaplain and Gilbert Burnet. News of James's flight led to celebrations and anti-Catholic riots in Edinburgh and Glasgow. Most members of the Scottish Privy Council went to London; on 7 January 1689, they asked William to take over government. Elections were held in March for a Scottish Convention, which was also a contest between Presbyterians and Episcopalians for control of the kirk. While only 50 of the 125 delegates were classed as Episcopalian, they were hopeful of victory since William supported the retention of bishops. 

However, on 16 March a Letter from James was read out to the Convention, demanding obedience and threatening punishment for non-compliance. Public anger at its tone meant some Episcopalians stopped attending the Convention, claiming to fear for their safety and others changed sides. The 1689-1691 Jacobite Rising forced William to make concessions to the Presbyterians, ended Episcopacy in Scotland and excluded a significant portion of the political class. Many later returned to the kirk but Non-Juring Episcopalianism was the key determinant of Jacobite support in both 1715 and 1745. 

The English Parliament held James 'abandoned' his throne; the Convention argued he 'forfeited' it by his actions, as listed in the Articles of Grievances. On 11 April, the Convention ended James' reign and adopted the Articles of Grievances and the Claim of Right Act, making Parliament the primary legislative power in Scotland. On 11 May, William and Mary accepted the Crown of Scotland; after their acceptance, the "Claim" and the " Articles " were read aloud, leading to an immediate debate over whether or not an endorsement of these documents was implicit in that acceptance.

Under the 1542 Crown of Ireland Act, the English monarch was automatically king of Ireland as well. Tyrconnell had created a largely Catholic army and administration which was reinforced in March 1689 when James landed in Ireland with French military support; it took two years of fighting before the new regime controlled Ireland.

James had cultivated support on the fringes of his Three Kingdoms – in Catholic Ireland and the Highlands of Scotland. Supporters of James, known as "Jacobites", were prepared to resist what they saw as an illegal coup by force of arms. The first Jacobite rebellion, an uprising in support of James in Scotland, took place in 1689. It was led by John Graham, 1st Viscount Dundee, also known as Graham of Claverhouse or Bonnie Dundee, who raised an army from Highland clans. In Ireland, Richard Talbot, 1st Earl of Tyrconnell led local Catholics, who had been discriminated against by previous English monarchs, in the conquest of all the fortified places in the kingdom except Derry, and so held the Kingdom for James. James himself landed in Ireland with 6,000 French troops to try to regain the throne in the Williamite War in Ireland. The war raged from 1689 to 1691. James fled Ireland following his defeat at the Battle of the Boyne in 1690, but Jacobite resistance was not ended until after the battle of Aughrim in 1691, when over half of their army was killed or taken prisoner. The Irish Jacobites surrendered under the conditions of the Treaty of Limerick on 3 October 1691. England stayed relatively calm throughout, although some English Jacobites fought on James's side in Ireland. Despite the Jacobite victory at the Battle of Killiecrankie, the uprising in the Scottish Highlands was quelled due to the death of its leader, Dundee, and Williamite victories at Dunkeld and Cromdale, as well as the Glencoe massacre in early 1692. Many, particularly in Ireland and Scotland, continued to see the Stuarts as the legitimate monarchs of the Three Kingdoms, and there were further Jacobite rebellions in Scotland during the years 1715, 1719 and 1745.

Though he had carefully avoided making it public, William's main motive in organising the expedition had been the opportunity to bring England into an alliance against France. On 9 December 1688 he had already asked the States General to send a delegation of three to negotiate the conditions. On 18 February (Julian calendar) he asked the Convention to support the Republic in its war against France; but it refused, only consenting to pay £600,000 for the continued presence of the Dutch army in England. On 9 March (Gregorian calendar) the States General responded to Louis's earlier declaration of war by declaring war on France in return. On 19 April (Julian calendar) the Dutch delegation signed a naval treaty with England. It stipulated that the combined Anglo-Dutch fleet would always be commanded by an Englishman, even when of lower rank; also it specified that the two parties would contribute in the ratio of five English vessels against three Dutch vessels, meaning in practice that the Dutch navy in the future would be smaller than the English. The Navigation Acts were not repealed. On 18 May the new Parliament allowed William to declare war on France. On 9 September 1689 (Gregorian calendar), William as King of England joined the League of Augsburg against France.

Having England as an ally meant that the military situation of the Republic was strongly improved, but this very fact induced William to be uncompromising in his position towards France. This policy led to a large number of very expensive campaigns which were largely paid for with Dutch funds. In 1712 the Republic was financially exhausted; it withdrew from international politics and was forced to let its fleet deteriorate, making what was by then the Kingdom of Great Britain the dominant maritime power of the world. The Dutch economy, already burdened by the high national debt and concomitant high taxation, suffered from the other European states' protectionist policies, which its weakened fleet was no longer able to resist. To make matters worse, the main Dutch trading and banking houses moved much of their activity from Amsterdam to London after 1688. Between 1688 and 1720, world trade dominance shifted from the Republic to Britain.

After being revisited by historians in 1988—the third centennial of the event—several researchers have argued that the "revolution" was actually a successful Dutch invasion of Britain. The events were unusual because the establishment of a constitutional monarchy (a de facto republic, see Coronation Oath Act 1688) and Bill of Rights meant that the apparently invading monarchs, legitimate heirs to the throne, were prepared to govern with the English Parliament. It is difficult to classify the entire proceedings of 1687–89 but it can be seen that the events occurred in three phases: conspiracy, invasion by Dutch forces and "Glorious Revolution". It has been argued that the invasion aspect had been downplayed as a result of a combination of British pride and successful Dutch propaganda, trying to depict the course of events as a largely internal English affair.

As the invitation was initiated by figures who had little influence themselves, the legacy of the Glorious Revolution has been described as a successful propaganda act by William to cover up and justify his successful invasion. The claim that William was fighting for the Protestant cause in England was used to great effect to disguise the military, cultural and political impact that the Dutch regime had on England at the time.

The overthrow of James was hailed at the time and ever since as the "Glorious Revolution". Edmund Burke set the tone for over two centuries of historiographical analysis when he proclaimed that:

Many historians have endorsed Burke's view, including Macaulay (1848) and more recently John Morrill, who captured the consensus of contemporary historiography well when he declared that "the Sensible Revolution of 1688–89 was a conservative Revolution". On the other hand, Steven Pincus (2009) argues that it was momentous especially when looking at the alternative that James was trying to enact – a powerful centralised autocratic state, using French-style "state-building". England's role in Europe and the country's political economy in the 17th century refutes the view of many late-20th-century historians that nothing revolutionary occurred during the Glorious Revolution of 1688–89. Pincus says it was not a placid turn of events. In diplomacy and economics William III transformed the English state's ideology and policies. This occurred not because William III was an outsider who inflicted foreign notions on England but because foreign affairs and political economy were at the core of the English revolutionaries' agenda. The revolution of 1688–89 cannot be fathomed in isolation. It would have been inconceivable without the changes resulting from the events of the 1640s and 1650s. Indeed, the ideas accompanying the Glorious Revolution were rooted in the mid-century upheavals. Thus, the 17th century was a century of revolution in England, deserving of the same scholarly attention that 'modern' revolutions attract.

James II tried building a powerful militarised state on the mercantilist assumption that the world's wealth was necessarily finite and empires were created by taking land from other states. The East India Company was thus an ideal tool to create a vast new English imperial dominion by warring with the Dutch and the Mogul Empire in India. After 1689 came an alternative understanding of economics, which saw Britain as a commercial rather than an agrarian society. It lead to the foundation of the Bank of England, the creation Europe’s first widely circulating credit currency and the commencement of the "Age of Projectors". This subsequently gave weight to the view, advocated most famously by Adam Smith in 1776, that wealth was created by human endeavour and was thus potentially infinite.

The Glorious Revolution of 1688 is considered by some as being one of the most important events in the long evolution of the respective powers of Parliament and the Crown in England. With the passage of the Bill of Rights, it stamped out once and for all any possibility of a Catholic monarchy, and ended moves towards absolute monarchy in the British kingdoms by circumscribing the monarch's powers. These powers were greatly restricted; he or she could no longer suspend laws, levy taxes, make royal appointments, or maintain a standing army during peacetime without Parliament's permission – to this day the Army is known as the "British Army" not the "Royal Army" as it is, in some sense, Parliament's Army and not that of the King. (This is, however, a complex issue, as the Crown remains the source of all executive authority in the British army, with legal implications for unlawful orders etc.). Since 1689, government under a system of constitutional monarchy in England, and later the United Kingdom, has been uninterrupted. Since then, Parliament's power has steadily increased while the Crown's has steadily declined. Unlike in the English civil war of the mid-seventeenth century, the "Glorious Revolution" did not involve the masses of ordinary people in England (the majority of the bloodshed occurred in Ireland). This fact has led many historians, including Stephen Webb, to suggest that, in England at least, the events more closely resemble a coup d'état than a social revolution. This view of events does not contradict what was originally meant by "revolution": the coming round of an old system of values in a circular motion, back to its original position, as Britain's constitution was reasserted, rather than formed anew.

Prior to his arrival in England, the new king William III of England was not Anglican, but rather was a member of the Dutch Reformed Church. Consequently, as a Calvinist and Presbyterian he was now in the unenviable position of being the head of the Church of England, while technically being a Nonconformist. This was, however, not his main motive for promoting religious toleration. More important in that respect was the need to keep happy his Catholic allies in the coming struggle with Louis XIV. Though he had promised legal toleration for Catholics in his "Declaration" of October 1688, he was ultimately unsuccessful in this respect, due to opposition by the Tories in the new Parliament. The Revolution led to the Act of Toleration of 1689, which granted toleration to Nonconformist Protestants, but not to Catholics. Catholic emancipation would be delayed for 140 years.

The Williamite War in Ireland can be seen as the source of later ethno-religious conflict, including The Troubles of recent times. The Williamite victory in Ireland is still commemorated by the Orange Order for preserving British and Protestant supremacy in the country.

In North America, the Glorious Revolution precipitated the 1689 Boston revolt in which a well-organised "mob" of provincial militia and citizens successfully deposed the hated governor Edmund Andros. In New York, Leisler's Rebellion caused the colonial administrator, Francis Nicholson, to flee to England. A third event, Maryland's Protestant Rebellion was directed against the proprietary government, seen as Catholic-dominated.

Lord Macaulay's account of the Revolution in "The History of England from the Accession of James the Second" exemplifies its semi-mystical significance to later generations.






</doc>
<doc id="12468" url="https://en.wikipedia.org/wiki?curid=12468" title="Great Lakes Colleges Association">
Great Lakes Colleges Association

The Great Lakes Colleges Association (GLCA) is a consortium of 13 liberal arts colleges located in the states around the Great Lakes. The 13 schools are located in Michigan, Ohio, Pennsylvania and Indiana. It was chartered in the state of Michigan and incorporated as a 501(c)(3) non-profit organization in 1962, the consortium extended its first offer of membership in 46 years to Allegheny College in 2008.

The GLCA offices are located in Ann Arbor, Michigan.

Member institutions are:


</doc>
