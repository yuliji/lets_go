<doc id="1934" url="https://en.wikipedia.org/wiki?curid=1934" title="Abadan, Iran">
Abadan, Iran

Abadan ( "Ābādān", ) is a city and capital of Abadan County, Khuzestan Province which is located in the southwest of Iran. It lies on Abadan Island ( long, 3–19 km or 2–12 miles wide), the island is bounded in the west by the Arvand waterway and to the east by the Bahmanshir outlet of the Karun River (the Arvand Rood), from the Persian Gulf, near the Iran–Iraq border.

The earliest mention of the island of Abadan, if not the port itself is found in works of the geographer Marcian, who renders the name "Apphadana". Earlier, the classical geographer, Ptolemy notes "Apphana" as an island off the mouth of the Tigris (which is, where the modern Island of Abadan is located). An etymology for this name is presented by B. Farahvashi to be derived from the Persian word "ab" (water) and the root "pā" (guard, watch) thus "coastguard station").

In the Islamic times, a pseudo-etymology was produced by the historian Ahmad ibn Yahya al-Baladhuri (d. 892) quoting a folk story that the town was presumably founded by one ""Abbad bin Hosayn" from the Arabian Tribe of Banu Tamim", who established a garrison there during the governorship of "Hajjaj" in the Ummayad period.

In the subsequent centuries, the Persian version of the name had begun to come into general use before it was adopted by official decree in 1935.

The civilian population of the city dropped close to zero during the eight years of the Iran–Iraq War (1980–1988). The 1986 census recorded only 6 people. In 1991, 84,774 had returned to live in the city. By 2001, the population had jumped to 206,073, and it was 217,988, in 48,061 families, according to 2006 census. Abadan Refinery is one of the largest in the world. The population today has reached almost 350,000 people.

Only 9% of managers (of the oil company) were from Khuzestan. The proportion of natives of Tehran, the Caspian, Azarbaijan and Kurdistan rose from 4% of blue collar workers to 22% of white collar workers to 45% of managers, thus Arabic-speakers were concentrated on the lower rungs of the work force, managers tended to be brought in from some distance. There is also a single Armenian church in the centre of the city.

Abadan is thought to have been further developed into a major port city under the Abbasids' rule. In this time period, it was a commercial source of salt and woven mats. The siltation of the river delta forced the town further away from water; In the 14th century, however, Ibn Battutah described Abadan just as a small port in a flat salty plain. Politically, Abadan was often the subject of dispute between the nearby states; in 1847, Persia acquired it from the Ottoman Empire, in which state Abadan has remained since. From the 17th century onward, the island of Abadan was part of the lands of the Arab "Ka'ab" (Bani Kaab) tribe. One section of this tribe, "Mohaysen", had its headquarters at "Mohammara" (present-day Khorramshahr), until the removal of Shaikh Khaz'al Khan in 1924.

It was not until the 20th century that rich oil fields were discovered in the area. On 16 July 1909, after secret negotiation with the British consul, Percy Cox, assisted by Arnold Wilson, Sheik Khaz'al agreed to a rental agreement for the island including Abadan. The Sheik continued to administer the island until 1924. The Anglo-Persian Oil Company built their first pipeline terminus oil refinery in Abadan, starting in 1909 and completing it in 1912, with oil flowing by August 1912 (see Abadan Refinery). Refinery throughput numbers rose from 33,000 tons in 1912–1913 to 4,338,000 tons in 1931. By 1938, it was the largest in the world.

During World War II, Abadan was the site of brief combat between Iranian forces and British and Indian troops during the Anglo-Soviet invasion of Iran. Later, Abadan was a major logistics centre for Lend-Lease aircraft being sent to the Soviet Union by the United States.

In 1951, Iran nationalized all oil properties and refining ground to a stop on the island. Rioting broke out in Abadan, after the government had decided to nationalize the oil facilities, and three British workers were killed. It was not until 1954, that a settlement was reached, which allowed a consortium of international oil companies to manage the production and refining on the island. This continued until 1973, when the NIOC took over all facilities. After total nationalization, Iran focused on supplying oil domestically and built a pipeline from Abadan to Tehran.

Whereas Abadan was not a major cultural or religious centre, it did play an important role in the Islamic Revolution. On 19 August 1978 the anniversary of the US backed coup d'état which overthrew the nationalist and popular Iranian prime minister, Dr. Mohammed Mossadegh – the Cinema Rex, a movie theatre in Abadan, Iran, was set ablaze. The Cinema Rex Fire caused 430 deaths, but more importantly, it was another event that kept the Islamic Revolution moving ahead. At the time there was much confusion and misinformation about the perpetrators of the incident. The public largely put the blame on the local police chief and also the Shah and SAVAK. The reformist "Sobhe Emrooz" newspaper in one of its editorials revealed that the Cinema Rex was burned down by the radical Islamists. The newspaper was shut down immediately after. Over time, the true culprits, radical Islamists, were apprehended and the logic behind this act was revealed, as they were trying both to foment the general public to distrust the government even more, and also as they perceived cinema as a link to the Americans. This fire was one of four during a short period in August, with other fires in Mashhad, Rizaiya, and Shiraz.

In September 1980, Abadan was almost overrun during a surprise attack on Khuzestan by Iraq, marking the beginning of the Iran–Iraq War. For 12 months Abadan was besieged, but never captured, by Iraqi forces, and in September 1981, the Iranians broke the siege of Abadan. Much of the city, including the oil refinery which was the world's largest refinery with capacity of 628,000 barrels per day, was badly damaged or destroyed by the siege and by bombing. Previous to the war, the city's civilian population was about 300,000, but before it was over, almost the entire populace had sought refuge elsewhere in Iran.

After the war, the biggest concern was the rebuilding of Abadan's oil refinery, as it was operating at 10% of capacity due to damage. In 1993, the refinery began limited operation and the port reopened. By 1997, the refinery reached the same rate of production as before the war. Recently, Abadan has been the site of major labour activity as workers at the oil refineries in the city have staged walkouts and strikes to protest non-payment of wages and the political situation in the country.

To honour the 100th anniversary of the refining of oil in Abadan, city officials are planning an oil museum. The Abadan oil refinery was featured on the reverse side of Iran's 100-rial banknotes printed in 1965 and from 1971 to 1973. Abadan today has been declared as a free zone city. The healthy relationship between Iran and Iraq has become one of the transit cities connecting both countries through a 40-minute drive.

The climate in Abadan is arid (Köppen climate classification "BWh") and similar to Baghdad's, but slightly hotter due to Abadan's lower latitude. Summers are dry and extremely hot, with temperatures above almost daily and temperatures above can be almost common. Abadan is notably one of the few hottest populated places on earth and experiences many sand and dust storms. Winters are mildly wet and spring-like, though subject to cold spells. Winter temperatures are around . The world's highest unconfirmed temperature was a temperature flare up during a heat burst in June 1967, with a temperature of . The lowest recorded temperature in the city range is . which was recorded on January 20, 1964 and February 3, 1967 while the highest is , recorded on July 11, 1951 and August 9, 1981.

The Abadan Institute of Technology was established in Abadan in 1939. The school specialized in engineering and petroleum chemistry, and was designed to train staff for the refinery in town. The school's name has since changed several times, but since 1989 has been considered a branch campus of the Petroleum University of Technology, centred in Tehran.

There is an international airport in Abadan. It is represented by the IATA airport code ABD.

There is a large amount of external investment from East Asian countries that are building oil refineries and developing a lot of real estate.

Rangoonis Mosque


The city is served by Abadan-Ayatollah Jami International Airport with flights on various commercial airlines.





</doc>
<doc id="1935" url="https://en.wikipedia.org/wiki?curid=1935" title="Attorney">
Attorney

Attorney may refer to:



</doc>
<doc id="1937" url="https://en.wikipedia.org/wiki?curid=1937" title="Alexander Fleming">
Alexander Fleming

Sir Alexander Fleming (6 August 1881 – 11 March 1955) was a Scottish biologist, physician, microbiologist, and pharmacologist. His best-known discoveries are the enzyme lysozyme in 1923 and the world's first antibiotic substance benzylpenicillin (Penicillin G) from the mould "Penicillium notatum" in 1928, for which he shared the Nobel Prize in Physiology or Medicine in 1945 with Howard Florey and Ernst Boris Chain. He wrote many articles on bacteriology, immunology, and chemotherapy.

Fleming was knighted for his scientific achievements in 1944. In 1999, he was named in "Time" magazine's list of the . In 2002, he was chosen in the BBC's television poll for determining the 100 Greatest Britons, and in 2009, he was also voted third "greatest Scot" in an opinion poll conducted by STV, behind only Robert Burns and William Wallace.

Born on 6 August 1881 at Lochfield farm near Darvel, in Ayrshire, Scotland, Alexander was the third of four children of farmer Hugh Fleming (1816–1888) from his second marriage to Grace Stirling Morton (1848–1928), the daughter of a neighbouring farmer. Hugh Fleming had four surviving children from his first marriage. He was 59 at the time of his second marriage, and died when Alexander was seven.

Fleming went to Loudoun Moor School and Darvel School, and earned a two-year scholarship to Kilmarnock Academy before moving to London, where he attended the Royal Polytechnic Institution. After working in a shipping office for four years, the twenty-year-old Alexander Fleming inherited some money from an uncle, John Fleming. His elder brother, Tom, was already a physician and suggested to him that he should follow the same career, and so in 1903, the younger Alexander enrolled at St Mary's Hospital Medical School in Paddington; he qualified with an MBBS degree from the school with distinction in 1906.

Fleming had been a private in the London Scottish Regiment of the Volunteer Force since 1900, and had been a member of the rifle club at the medical school. The captain of the club, wishing to retain Fleming in the team, suggested that he join the research department at St Mary's, where he became assistant bacteriologist to Sir Almroth Wright, a pioneer in vaccine therapy and immunology. In 1908, he gained a BSc degree with Gold Medal in Bacteriology, and became a lecturer at St Mary's until 1914.
Fleming served throughout World War I as a captain in the Royal Army Medical Corps, and was Mentioned in Dispatches. He and many of his colleagues worked in battlefield hospitals at the Western Front in France. In 1918 he returned to St Mary's Hospital, where he was elected Professor of Bacteriology of the University of London in 1928. In 1951 he was elected the Rector of the University of Edinburgh for a term of three years.

During World War I, Fleming witnessed the death of many soldiers from sepsis resulting from infected wounds. Antiseptics, which were used at the time to treat infected wounds, often worsened the injuries. In an article he submitted for the medical journal "The Lancet" during World War I, Fleming described an ingenious experiment, which he was able to conduct as a result of his own glass blowing skills, in which he explained why antiseptics were killing more soldiers than infection itself during World War I. Antiseptics worked well on the surface, but deep wounds tended to shelter anaerobic bacteria from the antiseptic agent, and antiseptics seemed to remove beneficial agents produced that protected the patients in these cases at least as well as they removed bacteria, and did nothing to remove the bacteria that were out of reach. Sir Almroth Wright strongly supported Fleming's findings, but despite this, most army physicians over the course of the war continued to use antiseptics even in cases where this worsened the condition of the patients.

At St Mary's Hospital Fleming continued his investigations into antibacterial substances. Testing the nasal secretions from a patient with a heavy cold, he found that nasal mucus had an inhibitory effect on bacterial growth. This was the first recorded discovery of lysozyme, an enzyme present in many secretions including tears, saliva, skin, hair and nails as well as mucus. Although he was able to obtain larger amounts of lysozyme from egg whites, the enzyme was only effective against small counts of harmless bacteria, and therefore had little therapeutic potential.

By 1927, Fleming had been investigating the properties of staphylococci. He was already well known from his earlier work, and had developed a reputation as a brilliant researcher, but his laboratory was often untidy. On 3 September 1928, Fleming returned to his laboratory having spent August on holiday with his family. Before leaving, he had stacked all his cultures of staphylococci on a bench in a corner of his laboratory. On returning, Fleming noticed that one culture was contaminated with a fungus, and that the colonies of staphylococci immediately surrounding the fungus had been destroyed, whereas other staphylococci colonies farther away were normal, famously remarking "That's funny". Fleming showed the contaminated culture to his former assistant Merlin Price, who reminded him, "That's how you discovered lysozyme." Fleming grew the mould in a pure culture and found that it produced a substance that killed a number of disease-causing bacteria. He identified the mould as being from the genus "Penicillium", and, after some months of calling it "mould juice", named the substance it released "penicillin" on 7 March 1929. The laboratory in which Fleming discovered and tested penicillin is preserved as the Alexander Fleming Laboratory Museum in St. Mary's Hospital, Paddington.

He investigated its positive anti-bacterial effect on many organisms, and noticed that it affected bacteria such as staphylococci and many other Gram-positive pathogens that cause scarlet fever, pneumonia, meningitis and diphtheria, but not typhoid fever or paratyphoid fever, which are caused by Gram-negative bacteria, for which he was seeking a cure at the time. It also affected "Neisseria gonorrhoeae," which causes gonorrhoea, although this bacterium is Gram-negative.

Fleming published his discovery in 1929, in the British "Journal of Experimental Pathology," but little attention was paid to his article. Fleming continued his investigations, but found that cultivating "Penicillium" was quite difficult, and that after having grown the mould, it was even more difficult to isolate the antibiotic agent. Fleming's impression was that because of the problem of producing it in quantity, and because its action appeared to be rather slow, penicillin would not be important in treating infection. Fleming also became convinced that penicillin would not last long enough in the human body ("in vivo") to kill bacteria effectively. Many clinical tests were inconclusive, probably because it had been used as a surface antiseptic. In the 1930s, Fleming's trials occasionally showed more promise, but Fleming largely abandoned penicillin work, leaving Howard Florey and Ernst Boris Chain at the Radcliffe Infirmary in Oxford to take up research to mass-produce it, with funds from the U.S. and British governments. They started mass production after the bombing of Pearl Harbor. By D-Day in 1944, enough penicillin had been produced to treat all the wounded in the Allied forces.

In Oxford, Ernst Boris Chain and Edward Abraham were studying the molecular structure of the antibiotic. Abraham was the first to propose the correct structure of penicillin. Shortly after the team published its first results in 1940, Fleming telephoned Howard Florey, Chain's head of department, to say that he would be visiting within the next few days. When Chain heard that Fleming was coming, he remarked "Good God! I thought he was dead."

Norman Heatley suggested transferring the active ingredient of penicillin back into water by changing its acidity. This produced enough of the drug to begin testing on animals. There were many more people involved in the Oxford team, and at one point the entire Dunn School was involved in its production.

After the team had developed a method of purifying penicillin to an effective first stable form in 1940, several clinical trials ensued, and their amazing success inspired the team to develop methods for mass production and mass distribution in 1945.

Fleming was modest about his part in the development of penicillin, describing his fame as the "Fleming Myth" and he praised Florey and Chain for transforming the laboratory curiosity into a practical drug. Fleming was the first to discover the properties of the active substance, giving him the privilege of naming it: penicillin. He also kept, grew, and distributed the original mould for twelve years, and continued until 1940 to try to get help from any chemist who had enough skill to make penicillin. But Sir Henry Harris said in 1998: "Without Fleming, no Chain; without Chain, no Florey; without Florey, no Heatley; without Heatley, no penicillin."

Fleming's accidental discovery and isolation of penicillin in September 1928 marks the start of modern antibiotics. Before that, several scientists had published or pointed out that mould or "Penicillium sp." were able to inhibit bacterial growth, and even to cure bacterial infections in animals. Ernest Duchesne in 1897 in his thesis "Contribution to the study of vital competition in micro-organisms: antagonism between moulds and microbes", or also Clodomiro Picado Twight whose work at the Institut Pasteur in 1923 on the inhibiting action of fungi of the "Penicillin sp." genre in the growth of staphylococci drew little interest from the directors of the Institut at the time. Fleming was the first to push these studies further by isolating the penicillin, and by being motivated enough to promote his discovery at a larger scale.

Fleming also discovered very early that bacteria developed antibiotic resistance whenever too little penicillin was used or when it was used for too short a period. Almroth Wright had predicted antibiotic resistance even before it was noticed during experiments. Fleming cautioned about the use of penicillin in his many speeches around the world. On 26 June 1945, he made the following cautionary statements: "the microbes are educated to resist penicillin and a host of penicillin-fast organisms is bred out ... In such cases the thoughtless person playing with penicillin is morally responsible for the death of the man who finally succumbs to infection with the penicillin-resistant organism. I hope this evil can be averted." He cautioned not to use penicillin unless there was a properly diagnosed reason for it to be used, and that if it were used, never to use too little, or for too short a period, since these are the circumstances under which bacterial resistance to antibiotics develops.

The popular story of Winston Churchill's father paying for Fleming's education after Fleming's father saved young Winston from death is false. According to the biography, "Penicillin Man: Alexander Fleming and the Antibiotic Revolution" by Kevin Brown, Alexander Fleming, in a letter to his friend and colleague Andre Gratia, described this as "A wondrous fable." Nor did he save Winston Churchill himself during World War II. Churchill was saved by Lord Moran, using sulphonamides, since he had no experience with penicillin, when Churchill fell ill in Carthage in Tunisia in 1943. "The Daily Telegraph" and "The Morning Post" on 21 December 1943 wrote that he had been saved by penicillin. He was saved by the new sulphonamide drug Sulphapyridine, known at the time under the research code M&B 693, discovered and produced by May & Baker Ltd, Dagenham, Essex – a subsidiary of the French group Rhône-Poulenc. In a subsequent radio broadcast, Churchill referred to the new drug as "This admirable M&B". It is highly probable that the correct information about the sulphonamide did not reach the newspapers because, since the original sulphonamide antibacterial, Prontosil, had been a discovery by the German laboratory Bayer, and as Britain was at war with Germany at the time, it was thought better to raise British morale by associating Churchill's cure with a British discovery, penicillin.

Fleming's discovery of penicillin changed the world of modern medicine by introducing the age of useful antibiotics; penicillin has saved, and is still saving, millions of people around the world.

The laboratory at St Mary's Hospital where Fleming discovered penicillin is home to the Fleming Museum, a popular London attraction. His alma mater, St Mary's Hospital Medical School, merged with Imperial College London in 1988. The "Sir Alexander Fleming Building" on the South Kensington campus was opened in 1998, where his son Robert and his great granddaughter Claire were presented to the Queen; it is now one of the main preclinical teaching sites of the Imperial College School of Medicine.

His other alma mater, the Royal Polytechnic Institution (now the University of Westminster) has named one of its student halls of residence "Alexander Fleming House", which is near to Old Street.

On 24 December 1915, Fleming married a trained nurse, Sarah Marion McElroy of Killala, County Mayo, Ireland. Their only child, Robert Fleming (1924–2015), became a general medical practitioner. After his first wife's death in 1949, Fleming married Dr. Amalia Koutsouri-Vourekas, a Greek colleague at St. Mary's, on 9 April 1953; she died in 1986.

From 1921 until his death in 1955, Fleming owned a country home in Barton Mills, Suffolk.

On 11 March 1955, Fleming died at his home in London of a heart attack. He is buried in St Paul's Cathedral.





</doc>
<doc id="1938" url="https://en.wikipedia.org/wiki?curid=1938" title="Andrew Carnegie">
Andrew Carnegie

Andrew Carnegie (November 25, 1835August 11, 1919) was a Scottish-American industrialist, business magnate, and philanthropist. Carnegie led the expansion of the American steel industry in the late 19th century and became one of the richest Americans in history. He became a leading philanthropist in the United States and in the British Empire. During the last 18 years of his life, he gave away about $350 million to charities, foundations, and universities – almost 90 percent of his fortune. His 1889 article proclaiming "The Gospel of Wealth" called on the rich to use their wealth to improve society, and stimulated a wave of philanthropy.

Carnegie was born in Dunfermline, Scotland, and immigrated to the United States with his parents in 1848 at age 12. Carnegie started work as a telegrapher, and by the 1860s had investments in railroads, railroad sleeping cars, bridges, and oil derricks. He accumulated further wealth as a bond salesman, raising money for American enterprise in Europe. He built Pittsburgh's Carnegie Steel Company, which he sold to J. P. Morgan in 1901 for $303,450,000. It became the U.S. Steel Corporation. After selling Carnegie Steel, he surpassed John D. Rockefeller as the richest American for the next several years.

Carnegie devoted the remainder of his life to large-scale philanthropy, with special emphasis on local libraries, world peace, education, and scientific research. With the fortune he made from business, he built Carnegie Hall in New York, NY, and the Peace Palace and founded the Carnegie Corporation of New York, Carnegie Endowment for International Peace, Carnegie Institution for Science, Carnegie Trust for the Universities of Scotland, Carnegie Hero Fund, Carnegie Mellon University, and the Carnegie Museums of Pittsburgh, among others.

Andrew Carnegie was born to Margaret Morrison Carnegie and William Carnegie in Dunfermline, Scotland, in a typical weaver's cottage with only one main room, consisting of half the ground floor, which was shared with the neighboring weaver's family. The main room served as a living room, dining room and bedroom. He was named after his legal grandfather. In 1836, the family moved to a larger house in Edgar Street (opposite Reid's Park), following the demand for more heavy damask, from which his father benefited. He was educated at the Free School in Dunfermline, which had been a gift to the town by the philanthropist Adam Rolland of Gask.

Carnegie's uncle, George Lauder, Sr., a Scottish political leader, deeply influenced him as a boy by introducing him to the writings of Robert Burns and historical Scottish heroes such as Robert the Bruce, William Wallace, and Rob Roy. Lauder's son, also named George Lauder, grew up with Carnegie and would become his business partner. When Carnegie was thirteen, his father had fallen on very hard times as a handloom weaver; making matters worse, the country was in starvation. His mother helped support the family by assisting her brother (a cobbler), and by selling potted meats at her "sweetie shop", leaving her as the primary breadwinner. Struggling to make ends meet, the Carnegies then decided to borrow money from George Lauder, Sr. and move to Allegheny, Pennsylvania, in the United States in 1848 for the prospect of a better life. Carnegie's migration to America would be his second journey outside Dunfermline – the first being an outing to Edinburgh to see Queen Victoria.

In September 1848, Carnegie arrived with his family at their new prosperous home. Allegheny was rapidly populating in the 1840s, growing from around 10,000 to 21,262 residents. The city was very industrial and produced many products including wool and cotton cloth. The "Made in Allegheny" label used on these and other diversified products was becoming more and more popular. For his father, the promising circumstances still did not provide him any good fortune. Dealers were not interested in selling his product, and he himself struggled to sell it on his own. Eventually, the father and son both received job offers at the same Scottish-owned cotton mill, Anchor Cotton Mills. Carnegie's first job in 1848 was as a bobbin boy, changing spools of thread in a cotton mill 12 hours a day, 6 days a week in a Pittsburgh cotton factory. His starting wage was $1.20 per week ($ by 2018 inflation).

His father quit his position at the cotton mill soon after, returning to his loom and removing him as breadwinner once again. But Carnegie attracted the attention of John Hay, a Scottish manufacturer of bobbins, who offered him a job for $2.00 per week ($ by 2018 inflation). In his autobiography, Carnegie speaks of his past hardships he had to endure with this new job.

In 1849, Carnegie became a telegraph messenger boy in the Pittsburgh Office of the Ohio Telegraph Company, at $2.50 per week ($ by 2018 inflation) following the recommendation of his uncle. He was a hard worker and would memorize all of the locations of Pittsburgh's businesses and the faces of important men. He made many connections this way. He also paid close attention to his work, and quickly learned to distinguish the differing sounds the incoming telegraph signals produced. He developed the ability to translate signals by ear, without using the paper slip, and within a year was promoted to operator. Carnegie's education and passion for reading was given a boost by Colonel James Anderson, who opened his personal library of 400 volumes to working boys each Saturday night. Carnegie was a consistent borrower and a "self-made man" in both his economic development and his intellectual and cultural development. He was so grateful to Colonel Anderson for the use of his library that he "resolved, if ever wealth came to me, [to see to it] that other poor boys might receive opportunities similar to those for which we were indebted to the noble man". His capacity, his willingness for hard work, his perseverance and his alertness soon brought him opportunities.

Starting in 1853, when Carnegie was around 18 years old, Thomas A. Scott of the Pennsylvania Railroad Company employed him as a secretary/telegraph operator at a salary of $4.00 per week ($ by 2018 inflation). Carnegie accepted the job with the railroad as he saw more prospects for career growth and experience there than with the telegraph company. At age 24, Scott asked Carnegie if he could handle being superintendent of the Western Division of the Pennsylvania Railroad. On December 1, 1859, Carnegie officially became superintendent of the Western Division. Carnegie then hired his sixteen-year-old brother, Tom, to be his personal secretary and telegraph operator. Not only did Carnegie hire his brother, but he also hired his cousin, Maria Hogan, who became the first female telegraph operator in the country. As superintendent Carnegie made a salary of fifteen hundred dollars a year ($ by 2018 inflation). His employment by the Pennsylvania Railroad Company would be vital to his later success. The railroads were the first big businesses in America, and the Pennsylvania was one of the largest of them all. Carnegie learned much about management and cost control during these years, and from Scott in particular.

Scott also helped him with his first investments. Many of these were part of the corruption indulged in by Scott and the Pennsylvania's president, John Edgar Thomson, which consisted of inside trading in companies that the railroad did business with, or payoffs made by contracting parties "as part of a quid pro quo". In 1855, Scott made it possible for Carnegie to invest $500 in the Adams Express, which contracted with the Pennsylvania to carry its messengers. The money was secured by his mother's placing of a $600 mortgage on the family's $700 home, but the opportunity was available only because of Carnegie's close relationship with Scott. A few years later, he received a few shares in Theodore Tuttle Woodruff's sleeping car company, as a reward for holding shares that Woodruff had given to Scott and Thomson, as a payoff. Reinvesting his returns in such inside investments in railroad-related industries: (iron, bridges, and rails), Carnegie slowly accumulated capital, the basis for his later success. Throughout his later career, he made use of his close connections to Thomson and Scott, as he established businesses that supplied rails and bridges to the railroad, offering the two men a stake in his enterprises.

Before the Civil War, Carnegie arranged a merger between Woodruff's company and that of George Pullman, the inventor of a sleeping car for first class travel, which facilitated business travel at distances over . The investment proved a success and a source of profit for Woodruff and Carnegie. The young Carnegie continued to work for the Pennsylvania's Tom Scott, and introduced several improvements in the service.

In spring 1861, Carnegie was appointed by Scott, who was now Assistant Secretary of War in charge of military transportation, as Superintendent of the Military Railways and the Union Government's telegraph lines in the East. Carnegie helped open the rail lines into Washington D.C. that the rebels had cut; he rode the locomotive pulling the first brigade of Union troops to reach Washington D.C. Following the defeat of Union forces at Bull Run, he personally supervised the transportation of the defeated forces. Under his organization, the telegraph service rendered efficient service to the Union cause and significantly assisted in the eventual victory. Carnegie later joked that he was "the first casualty of the war" when he gained a scar on his cheek from freeing a trapped telegraph wire.

Defeat of the Confederacy required vast supplies of munitions, as well as railroads (and telegraph lines) to deliver the goods. The war demonstrated how integral the industries were to American success.

In 1864, Carnegie was one of the early investors in the Columbia Oil Company in Venango County, Pennsylvania. In one year, the farm yielded over $1,000,000 in cash dividends, and petroleum from oil wells on the property sold profitably. The demand for iron products, such as armor for gunboats, cannons, and shells, as well as a hundred other industrial products, made Pittsburgh a center of wartime production. Carnegie worked with others in establishing a steel rolling mill, and steel production and control of industry became the source of his fortune. Carnegie had some investments in the iron industry before the war.

After the war, Carnegie left the railroads to devote his energies to the ironworks trade. Carnegie worked to develop several ironworks, eventually forming the Keystone Bridge Works and the Union Ironworks, in Pittsburgh. Although he had left the Pennsylvania Railroad Company, he remained connected to its management, namely Thomas A. Scott and J. Edgar Thomson. He used his connection to the two men to acquire contracts for his Keystone Bridge Company and the rails produced by his ironworks. He also gave stock to Scott and Thomson in his businesses, and the Pennsylvania was his best customer. When he built his first steel plant, he made a point of naming it after Thomson. As well as having good business sense, Carnegie possessed charm and literary knowledge. He was invited to many important social functions, which Carnegie exploited to his advantage.
Carnegie believed in using his fortune for others and doing more than making money. He wrote:

Carnegie did not want to marry during his mother's lifetime, instead choosing to take care of her in her illness towards the end of her life. After she died in 1886, the 51-year-old Carnegie married Louise Whitfield, who was 21 years his junior. In 1897, the couple had their only child, a daughter, whom they named after Carnegie's mother, Margaret.

Carnegie made his fortune in the steel industry, controlling the most extensive integrated iron and steel operations ever owned by an individual in the United States. One of his two great innovations was in the cheap and efficient mass production of steel by adopting and adapting the Bessemer process, which allowed the high carbon content of pig iron to be burnt away in a controlled and rapid way during steel production. Steel prices dropped as a result, and Bessemer steel was rapidly adopted for rails; however, it was not suitable for buildings and bridges.

The second was in his vertical integration of all suppliers of raw materials. In the late 1880s, Carnegie Steel was the largest manufacturer of pig iron, steel rails, and coke in the world, with a capacity to produce approximately 2,000 tons of pig metal per day. In 1883, Carnegie bought the rival Homestead Steel Works, which included an extensive plant served by tributary coal and iron fields, a long railway, and a line of lake steamships. Carnegie combined his assets and those of his associates in 1892 with the launching of the Carnegie Steel Company.

By 1889, the U.S. output of steel exceeded that of the UK, and Carnegie owned a large part of it. Carnegie's empire grew to include the J. Edgar Thomson Steel Works in Braddock, (named for John Edgar Thomson, Carnegie's former boss and president of the Pennsylvania Railroad), Pittsburgh Bessemer Steel Works, the Lucy Furnaces, the Union Iron Mills, the Union Mill (Wilson, Walker & County), the Keystone Bridge Works, the Hartman Steel Works, the Frick Coke Company, and the Scotia ore mines. Carnegie, through Keystone, supplied the steel for and owned shares in the landmark Eads Bridge project across the Mississippi River at St. Louis, Missouri (completed 1874). This project was an important proof-of-concept for steel technology, which marked the opening of a new steel market.

In 1901, Carnegie was 66 years of age and considering retirement. He reformed his enterprises into conventional joint stock corporations as preparation for this. John Pierpont Morgan was a banker and perhaps America's most important financial deal maker. He had observed how efficiently Carnegie produced profits. He envisioned an integrated steel industry that would cut costs, lower prices to consumers, produce in greater quantities and raise wages to workers. To this end, he needed to buy out Carnegie and several other major producers and integrate them into one company, thereby eliminating duplication and waste. He concluded negotiations on March 2, 1901, and formed the United States Steel Corporation. It was the first corporation in the world with a market capitalization over $1 billion.

The buyout, secretly negotiated by Charles M. Schwab (no relation to Charles R. Schwab), was the largest such industrial takeover in United States history to date. The holdings were incorporated in the United States Steel Corporation, a trust organized by Morgan, and Carnegie retired from business. His steel enterprises were bought out for $303,450,000.

Carnegie's share of this amounted to $225.64 million (in , $), which was paid to Carnegie in the form of 5%, 50-year gold bonds. The letter agreeing to sell his share was signed on February 26, 1901. On March 2, the circular formally filing the organization and capitalization (at $1.4 billion – 4 percent of U.S. national wealth at the time) of the United States Steel Corporation actually completed the contract. The bonds were to be delivered within two weeks to the Hudson Trust Company of Hoboken, New Jersey, in trust to Robert A. Franks, Carnegie's business secretary. There, a special vault was built to house the physical bulk of nearly $230 million worth of bonds.

Carnegie continued his business career; some of his literary intentions were fulfilled. He befriended the English poet Matthew Arnold, the English philosopher Herbert Spencer, and the American humorist Mark Twain, as well as being in correspondence and acquaintance with most of the U.S. Presidents, statesmen, and notable writers.

Carnegie constructed commodious swimming-baths for the people of his hometown in Dunfermline in 1879. In the following year, Carnegie gave £8,000 for the establishment of a Dunfermline Carnegie Library in Scotland. In 1884, he gave $50,000 to Bellevue Hospital Medical College (now part of New York University Medical Center) to found a histological laboratory, now called the Carnegie Laboratory.

In 1881, Carnegie took his family, including his 70-year-old mother, on a trip to the United Kingdom. They toured Scotland by coach, and enjoyed several receptions en route. The highlight was a return to Dunfermline, where Carnegie's mother laid the foundation stone of a Carnegie library which he funded. Carnegie's criticism of British society did not mean dislike; on the contrary, one of Carnegie's ambitions was to act as a catalyst for a close association between English-speaking peoples. To this end, in the early 1880s in partnership with Samuel Storey, he purchased numerous newspapers in England, all of which were to advocate the abolition of the monarchy and the establishment of "the British Republic". Carnegie's charm, aided by his wealth, afforded him many British friends, including Prime Minister William Ewart Gladstone.

In 1886, Carnegie's younger brother Thomas died at age 43. While owning steel works, Carnegie had purchased at low cost the most valuable of the iron ore fields around Lake Superior. The same year Carnegie became a figure of controversy. Following his tour of the UK, he wrote about his experiences in a book entitled "An American Four-in-hand in Britain".
Although actively involved in running his many businesses, Carnegie had become a regular contributor to numerous magazines, most notably "The Nineteenth Century", under the editorship of James Knowles, and the influential "North American Review", led by editor Lloyd Bryce.

In 1886, Carnegie wrote his most radical work to date, entitled "Triumphant Democracy". Liberal in its use of statistics to make its arguments, the book argued his view that the American republican system of government was superior to the British monarchical system. It gave a highly favorable and idealized view of American progress and criticized the British royal family. The cover depicted an upended royal crown and a broken scepter. The book created considerable controversy in the UK. The book made many Americans appreciate their country's economic progress and sold over 40,000 copies, mostly in the US.

In 1889, Carnegie published "Wealth" in the June issue of the "North American Review". After reading it, Gladstone requested its publication in England, where it appeared as "The Gospel of Wealth" in the "Pall Mall Gazette". Carnegie argued that the life of a wealthy industrialist should comprise two parts. The first part was the gathering and the accumulation of wealth. The second part was for the subsequent distribution of this wealth to benevolent causes. Philanthropy was key to making life worthwhile.

Carnegie was a well-regarded writer. He published three books on travel.

While Carnegie did not comment on British imperialism, he strongly opposed the idea of American colonies. He opposed the annexation of the Philippines almost to the point of supporting William Jennings Bryan against McKinley in 1900. In 1898, Carnegie tried to arrange for independence for the Philippines. As the end of the Spanish–American War neared, the United States bought the Philippines from Spain for $20 million. To counter what he perceived as imperialism on the part of the United States, Carnegie personally offered $20 million to the Philippines so that the Filipino people could buy their independence from the United States. However, nothing came of the offer. In 1898 Carnegie joined the American Anti-Imperialist League, in opposition to the U.S. annexation of the Philippines. Its membership included former presidents of the United States Grover Cleveland and Benjamin Harrison and literary figures like Mark Twain.

Carnegie spent his last years as a philanthropist. From 1901 forward, public attention was turned from the shrewd business acumen which had enabled Carnegie to accumulate such a fortune, to the public-spirited way in which he devoted himself to utilizing it on philanthropic projects. He had written about his views on social subjects and the responsibilities of great wealth in "Triumphant Democracy" (1886) and "Gospel of Wealth" (1889). Carnegie bought Skibo Castle in Scotland, and made his home partly there and partly in his New York mansion located at 2 East 91st Street at Fifth Avenue. The building was completed in late 1902, and he lived there until his death in 1919. His wife Louise continued to live there until her death in 1946. The building is now the Cooper-Hewitt, Smithsonian Design Museum, part of the Smithsonian Institution. The surrounding neighborhood on Manhattan's Upper East Side has come to be called Carnegie Hill. The mansion was named a National Historic Landmark in 1966. He then devoted his life to providing the capital for purposes of public interest and social and educational advancement, saving letters of appreciation from those he helped in a desk drawer labeled "Gratitude and Sweet Words."
He was a powerful supporter of the movement for spelling reform, as a means of promoting the spread of the English language. His organisation, the Simplified Spelling Board, created the "Handbook of Simplified Spelling", which was written wholly in reformed spelling.

Among his many philanthropic efforts, the establishment of public libraries throughout the United States, Britain, Canada and other English-speaking countries was especially prominent. In this special driving interest and project of his, he was inspired by meetings with philanthropist Enoch Pratt (1808–1896). The Enoch Pratt Free Library (1886) impressed Carnegie deeply; he said, "Pratt was my guide and inspiration."

Carnegie turned over management of the library project by 1908 to his staff, led by James Bertram (1874–1934). The first Carnegie library opened in 1883 in Dunfermline. His method was to build and equip, but only on condition that the local authority matched that by providing the land and a budget for operation and maintenance. To secure local interest, in 1885, he gave $500,000 to Pittsburgh for a public library, and in 1886, he gave $250,000 to Allegheny City for a music hall and library; and $250,000 to Edinburgh for a free library. In total, Carnegie funded some 3,000 libraries, located in 47 US states, and also in Canada, Britain, Ireland, Australia, New Zealand, South Africa, the West Indies, and Fiji. He also donated £50,000 to help set up the University of Birmingham in 1899.

As Van Slyck (1991) showed, the last years of the 19th century saw acceptance of the idea that free libraries should be available to the American public. But the design of the idealized free library was the subject of prolonged and heated debate. On one hand, the library profession called for designs that supported efficiency in administration and operation; on the other, wealthy philanthropists favored buildings that reinforced the paternalistic metaphor and enhanced civic pride. Between 1886 and 1917, Carnegie reformed both library philanthropy and library design, encouraging a closer correspondence between the two.

In 1900, Carnegie gave $2 million to start the Carnegie Institute of Technology (CIT) at Pittsburgh and the same amount in 1902 to found the Carnegie Institution at Washington, D.C. He later contributed more to these and other schools. CIT is now known as Carnegie Mellon University after it merged with the Mellon Institute of Industrial Research. Carnegie also served on the Boards of Cornell University and Stevens Institute of Technology.

In 1911, Carnegie became a sympathetic benefactor to George Ellery Hale, who was trying to build the Hooker Telescope at Mount Wilson, and donated an additional ten million dollars to the Carnegie Institution with the following suggestion to expedite the construction of the telescope: "I hope the work at Mount Wilson will be vigorously pushed, because I am so anxious to hear the expected results from it. I should like to be satisfied before I depart, that we are going to repay to the old land some part of the debt we owe them by revealing more clearly than ever to them the new heavens." The telescope saw first light on November 2, 1917, with Carnegie still alive.

In 1901, in Scotland, he gave $10 million to establish the Carnegie Trust for the Universities of Scotland. It was created by a deed which he signed on June 7, 1901, and it was incorporated by Royal Charter on August 21, 1902. The establishing gift of $10 million was then an unprecedented sum: at the time, total government assistance to all four Scottish universities was about £50,000 a year. The aim of the Trust was to improve and extend the opportunities for scientific research in the Scottish universities and to enable the deserving and qualified youth of Scotland to attend a university. He was subsequently elected Lord Rector of University of St. Andrews in December 1901, and formally installed as such in October 1902, serving until 1907. He also donated large sums of money to Dunfermline, the place of his birth. In addition to a library, Carnegie also bought the private estate which became Pittencrieff Park and opened it to all members of the public, establishing the Carnegie Dunfermline Trust to benefit the people of Dunfermline. A statue of him stands there today.

He gave a further $10 million in 1913 to endow the Carnegie United Kingdom Trust, a grant-making foundation. He transferred to the trust the charge of all his existing and future benefactions, other than university benefactions in the United Kingdom. He gave the trustees a wide discretion, and they inaugurated a policy of financing rural library schemes rather than erecting library buildings, and of assisting the musical education of the people rather than granting organs to churches.

In 1901, Carnegie also established large pension funds for his former employees at Homestead and, in 1905, for American college professors. The latter fund evolved into TIAA-CREF. One critical requirement was that church-related schools had to sever their religious connections to get his money.

His interest in music led him to fund construction of 7,000 church organs. He built and owned Carnegie Hall in New York City.

Carnegie was a large benefactor of the Tuskegee Institute for African-American education under Booker T. Washington. He helped Washington create the National Negro Business League.
In 1904, he founded the Carnegie Hero Fund for the United States and Canada (a few years later also established in the United Kingdom, Switzerland, Norway, Sweden, France, Italy, the Netherlands, Belgium, Denmark, and Germany) for the recognition of deeds of heroism. Carnegie contributed $1,500,000 in 1903 for the erection of the Peace Palace at The Hague; and he donated $150,000 for a Pan-American Palace in Washington as a home for the International Bureau of American Republics.

Carnegie was honored for his philanthropy and support of the arts by initiation as an honorary member of Phi Mu Alpha Sinfonia Fraternity on October 14, 1917, at the New England Conservatory of Music in Boston, Massachusetts. The fraternity's mission reflects Carnegie's values by developing young men to share their talents to create harmony in the world.

By the standards of 19th century tycoons, Carnegie was not a particularly ruthless man but a humanitarian with enough acquisitiveness to go in the ruthless pursuit of money. "Maybe with the giving away of his money," commented biographer Joseph Wall, "he would justify what he had done to get that money."

To some, Carnegie represents the idea of the American dream. He was an immigrant from Scotland who came to America and became successful. He is not only known for his successes but his enormous amounts of philanthropist works, not only to charities but also to promote democracy and independence to colonized countries.

Carnegie died on August 11, 1919, in Lenox, Massachusetts at his Shadow Brook estate, of bronchial pneumonia. He had already given away $350,695,653 (approximately $76.9 billion, adjusted to 2015 share of GDP figures) of his wealth. After his death, his last $30,000,000 was given to foundations, charities, and to pensioners. He was buried at Sleepy Hollow Cemetery in Sleepy Hollow, New York. The grave site is located on the Arcadia Hebron plot of land at the corner of Summit Avenue and Dingle Road. Carnegie is buried only a few yards away from union organizer Samuel Gompers, another important figure of industry in the Gilded Age.

Carnegie was one of more than 50 members of the South Fork Fishing and Hunting Club, which has been blamed for the Johnstown Flood that killed 2,209 people in 1889.

At the suggestion of his friend Benjamin Ruff, Carnegie's partner Henry Clay Frick had formed the exclusive South Fork Fishing and Hunting Club high above Johnstown, Pennsylvania. The sixty-odd club members were the leading business tycoons of Western Pennsylvania and included among their number Frick's best friend, Andrew Mellon, his attorneys Philander Knox and James Hay Reed, as well as Frick's business partner, Carnegie. High above the city, near the small town of South Fork, the South Fork Dam was originally built between 1838 and 1853 by the Commonwealth of Pennsylvania as part of a canal system to be used as a reservoir for a canal basin in Johnstown. With the coming-of-age of railroads superseding canal barge transport, the lake was abandoned by the Commonwealth, sold to the Pennsylvania Railroad, and sold again to private interests and eventually came to be owned by the South Fork Fishing and Hunting Club in 1881. Prior to the flood, speculators had purchased the abandoned reservoir, made less than well-engineered repairs to the old dam, raised the lake level, built cottages and a clubhouse, and created the South Fork Fishing and Hunting Club. Less than downstream from the dam sat the city of Johnstown.

The dam was high and long. Between 1881 when the club was opened, and 1889, the dam frequently sprang leaks and was patched, mostly with mud and straw. Additionally, a previous owner removed and sold for scrap the 3 cast iron discharge pipes that previously allowed a controlled release of water. There had been some speculation as to the dam's integrity, and concerns had been raised by the head of the Cambria Iron Works downstream in Johnstown. Such repair work, a reduction in height, and unusually high snowmelt and heavy spring rains combined to cause the dam to give way on May 31, 1889 resulting in twenty million tons of water sweeping down the valley as the Johnstown Flood. When word of the dam's failure was telegraphed to Pittsburgh, Frick and other members of the South Fork Fishing and Hunting Club gathered to form the Pittsburgh Relief Committee for assistance to the flood victims as well as determining never to speak publicly about the club or the flood. This strategy was a success, and Knox and Reed were able to fend off all lawsuits that would have placed blame upon the club's members.

Although Cambria Iron and Steel's facilities were heavily damaged by the flood, they returned to full production within a year. After the flood, Carnegie built Johnstown a new library to replace the one built by Cambria's chief legal counsel Cyrus Elder, which was destroyed in the flood. The Carnegie-donated library is now owned by the Johnstown Area Heritage Association, and houses the Flood Museum.

The Homestead Strike was a bloody labor confrontation lasting 143 days in 1892, one of the most serious in U.S. history. The conflict was centered on Carnegie Steel's main plant in Homestead, Pennsylvania, and grew out of a labor dispute between the Amalgamated Association of Iron and Steel Workers (AA) and the Carnegie Steel Company.

Carnegie left on a trip to Scotland before the unrest peaked. In doing so, Carnegie left mediation of the dispute in the hands of his associate and partner Henry Clay Frick. Frick was well known in industrial circles for maintaining staunch anti-union sentiment. With the collective bargaining agreement between the union and company expiring at the end of June, Frick and the leaders of the local AA union entered into negotiations in February. With the steel industry doing well and prices higher, the AA asked for a wage increase; the AA represented about 800 of the 3,800 workers at the plant. Frick immediately countered with an average 22% wage decrease that would affect nearly half the union's membership and remove a number of positions from the bargaining unit.
The union and company failed to come to an agreement, and management locked the union out. Workers considered the stoppage a "lockout" by management and not a "strike" by workers. As such, the workers would have been well within their rights to protest, and subsequent government action would have been a set of criminal procedures designed to crush what was seen as a pivotal demonstration of the growing labor rights movement, strongly opposed by management. Frick brought in thousands of strikebreakers to work the steel mills and Pinkerton agents to safeguard them.

On July 6, the arrival of a force of 300 Pinkerton agents from New York City and Chicago resulted in a fight in which 10 men — seven strikers and three Pinkertons — were killed and hundreds were injured. Pennsylvania Governor Robert Pattison ordered two brigades of state militia to the strike site. Then allegedly in response to the fight between the striking workers and the Pinkertons, anarchist Alexander Berkman shot at Frick in an attempted assassination, wounding him. While not directly connected to the strike, Berkman was tied in for the assassination attempt. According to Berkman, "...with the elimination of Frick, responsibility for Homestead conditions would rest with Carnegie." Afterwards, the company successfully resumed operations with non-union immigrant employees in place of the Homestead plant workers, and Carnegie returned to the United States. However, Carnegie's reputation was permanently damaged by the Homestead events.

Carnegie gave "formal allegiance" to the Republican Party, though he was said to be "a violent opponent of some of the most sacred doctrines" of the party.

In his final days, Carnegie suffered from pneumonia. Before his death on August 11, 1919, Carnegie had donated $350,695,654 for various causes. The "Andrew Carnegie Dictum" was:
Carnegie was involved in philanthropic causes, but he kept himself away from religious circles. He wanted to be identified by the world as a "positivist". He was highly influenced in public life by John Bright.

As early as 1868, at age 33, he drafted a memo to himself. He wrote: "...The amassing of wealth is one of the worse species of idolatry. No idol more debasing than the worship of money." In order to avoid degrading himself, he wrote in the same memo he would retire at age 35 to pursue the practice of philanthropic giving for "... the man who dies thus rich dies disgraced." However, he did not begin his philanthropic work in all earnest until 1881, with the gift of a library to his hometown of Dunfermline, Scotland.

Carnegie wrote "The Gospel of Wealth", an article in which he stated his belief that the rich should use their wealth to help enrich society. In that article, Carnegie also expressed sympathy for the ideas of progressive taxation and an estate tax.

The following is taken from one of Carnegie's memos to himself:

Carnegie claimed to be a champion of evolutionary thought particularly the work of Herbert Spencer, even declaring Spencer his teacher. Although Carnegie claims to be a disciple of Spencer many of his actions went against the ideas espoused by Spencer.

Spencerian evolution was for individual rights and against government interference. Furthermore, Spencerian evolution held that those unfit to sustain themselves must be allowed to perish. Spencer believed that just as there were many varieties of beetles, respectively modified to existence in a particular place in nature, so too had human society "spontaneously fallen into division of labour". Individuals who survived to this, the latest and highest stage of evolutionary progress would be "those in whom the power of self-preservation is the greatest—are the select of their generation." Moreover, Spencer perceived governmental authority as borrowed from the people to perform the transitory aims of establishing social cohesion, insurance of rights, and security. Spencerian 'survival of the fittest' firmly credits any provisions made to assist the weak, unskilled, poor and distressed to be an imprudent disservice to evolution. Spencer insisted people should resist for the benefit of collective humanity, as severe fate singles out the weak, debauched, and disabled.

Andrew Carnegie's political and economic focus during the late nineteenth and early twentieth century was the defense of laissez faire economics. Carnegie emphatically resisted government intrusion in commerce, as well as government-sponsored charities. Carnegie believed the concentration of capital was essential for societal progress and should be encouraged. Carnegie was an ardent supporter of commercial "survival of the fittest" and sought to attain immunity from business challenges by dominating all phases of the steel manufacturing procedure. Carnegie's determination to lower costs included cutting labor expenses as well. In a notably Spencerian manner, Carnegie argued that unions impeded the natural reduction of prices by pushing up costs, which blocked evolutionary progress. Carnegie felt that unions represented the narrow interest of the few while his actions benefited the entire community.

On the surface, Andrew Carnegie appears to be a strict laissez-faire capitalist and follower of Herbert Spencer, often referring to himself as a disciple of Spencer. Conversely, Carnegie, a titan of industry, seems to embody all of the qualities of Spencerian survival of the fittest. The two men enjoyed a mutual respect for one another and maintained correspondence until Spencer's death in 1903. There are however, some major discrepancies between Spencer's capitalist evolutionary conceptions and Andrew Carnegie's capitalist practices.

Spencer wrote that in production the advantages of the superior individual are comparatively minor, and thus acceptable, yet the benefit that dominance provides those who control a large segment of production might be hazardous to competition. Spencer feared that an absence of "sympathetic self-restraint" of those with too much power could lead to the ruin of their competitors. He did not think free market competition necessitated competitive warfare. Furthermore, Spencer argued that individuals with superior resources who deliberately used investment schemes to put competitors out of business were committing acts of "commercial murder". Carnegie built his wealth in the steel industry by maintaining an extensively integrated operating system. Carnegie also bought out some regional competitors, and merged with others, usually maintaining the majority shares in the companies. Over the course of twenty years, Carnegie's steel properties grew to include the Edgar Thomson Steel Works, the Lucy Furnace Works, the Union Iron Mills, the Homestead Works, the Keystone Bridge Works, the Hartman Steel Works, the Frick Coke Company, and the Scotia ore mines among many other industry related assets. Furthermore, Carnegie's success was due to his convenient relationship with the railroad industries, which not only relied on steel for track, but were also making money from steel transport. The steel and railroad barons worked closely to negotiate prices instead of free market competition determinations.

Besides Carnegie's market manipulation, United States trade tariffs were also working in favor of the steel industry. Carnegie spent energy and resources lobbying congress for a continuation of favorable tariffs from which he earned millions of dollars a year. Carnegie tried to keep this information concealed, but legal documents released in 1900, during proceedings with the ex-chairman of Carnegie Steel, Henry Clay Frick, revealed how favorable the tariffs had been. Herbert Spencer absolutely was against government interference in business in the form of regulatory limitation, taxes, and tariffs as well. Spencer saw tariffs as a form of taxation that levied against the majority in service to "the benefit of a small minority of manufacturers and artisans".

Despite Carnegie's personal dedication to Herbert Spencer as a friend, his adherence to Spencer's political and economic ideas is more contentious. In particular, it appears Carnegie either misunderstood or intentionally misrepresented some of Spencer's principal arguments. Spencer remarked upon his first visit to Carnegie's steel mills in Pittsburgh, which Carnegie saw as the manifestation of Spencer's philosophy, "Six months' residence here would justify suicide."

On the subject of charity Andrew Carnegie's actions diverged in the most significant and complex manner from Herbert Spencer's philosophies. In his 1854 essay "Manners and Fashion", Spencer referred to public education as "Old schemes". He went on to declare that public schools and colleges fill the heads of students with inept, useless knowledge and exclude useful knowledge. Spencer stated that he trusted no organization of any kind, "political, religious, literary, philanthropic", and believed that as they expanded in influence so too did their regulations expand. In addition, Spencer thought that as all institutions grow they become evermore corrupted by the influence of power and money. The institution eventually loses its "original spirit, and sinks into a lifeless mechanism". Spencer insisted that all forms of philanthropy that uplift the poor and downtrodden were reckless and incompetent. Spencer thought any attempt to prevent "the really salutary sufferings" of the less fortunate "bequeath to posterity a continually increasing curse". Carnegie, a self-proclaimed devotee of Spencer, testified to Congress on February 5, 1915: "My business is to do as much good in the world as I can; I have retired from all other business."

Carnegie held that societal progress relied on individuals who maintained moral obligations to themselves and to society. Furthermore, he believed that charity supplied the means for those who wish to improve themselves to achieve their goals. Carnegie urged other wealthy people to contribute to society in the form of parks, works of art, libraries and other endeavors that improve the community and contribute to the "lasting good". Carnegie also held a strong opinion against inherited wealth. Carnegie believed that the sons of prosperous businesspersons were rarely as talented as their fathers. By leaving large sums of money to their children, wealthy business leaders were wasting resources that could be used to benefit society. Most notably, Carnegie believed that the future leaders of society would rise from the ranks of the poor. Carnegie strongly believed in this because he had risen from the bottom. He believed the poor possessed an advantage over the wealthy because they receive greater attention from their parents and are taught better work ethics.

Carnegie and his family belonged to the Presbyterian Church in the United States of America, also known informally as the Northern Presbyterian Church. In his early life Carnegie was skeptical of Calvinism, and religion as a whole, but reconciled with it later in his life. In his autobiography, Carnegie describes his family as moderate Presbyterian believers, writing that "there was not one orthodox Presbyterian" in his family; various members of his family having somewhat distanced themselves from Calvinism, some of them leaning more towards Swedenborgianism. Although, being a child, his family led vigorous theological and political disputes. His mother avoided the topic of religion. His father left the Presbyterian church after a sermon on infant damnation, while, according to Carnegie, still remaining very religious on his own.

Witnessing sectarianism and strife in 19th century Scotland regarding religion and philosophy, Carnegie kept his distance from organized religion and theism. Carnegie instead preferred to see things through naturalistic and scientific terms stating, "Not only had I got rid of the theology and the supernatural, but I had found the truth of evolution."

Later in life, Carnegie's firm opposition to religion softened. For many years he was a member of Madison Avenue Presbyterian Church, pastored from 1905 to 1926 by Social Gospel exponent Henry Sloane Coffin, while his wife and daughter belonged to the Brick Presbyterian Church. He also prepared (but did not deliver) an address in which he professed a belief in "an Infinite and Eternal Energy from which all things proceed". Records exist of a short period of correspondence around 1912–1913 between Carnegie and 'Abdu'l-Bahá, the eldest son of Bahá'u'lláh, founder of the Bahá'í Faith. In these letters, one of which was published in the "New York Times" in full text, Carnegie is extolled as a "lover of the world of humanity and one of the founders of Universal Peace".

Influenced by his "favorite living hero in public life" John Bright, Carnegie started his efforts in pursuit of world peace at a young age, and supported causes that opposed military intervention. His motto, "All is well since all grows better", served not only as a good rationalization of his successful business career, but also his view of international relations.

Despite his efforts towards international peace, Carnegie faced many dilemmas on his quest. These dilemmas are often regarded as conflicts between his view on international relations and his other loyalties. Throughout the 1880s and 1890s, for example, Carnegie allowed his steel works to fill large orders of armor plate for the building of an enlarged and modernized United States Navy, but he opposed American oversea expansion.

Despite that, Carnegie served as a major donor for the newly-established International Court of Arbitration's Peace Palace – brainchild of Russian Tsar Nicolas II.

His largest and in the long run most influential peace organization was the Carnegie Endowment for International Peace, formed in 1910 with a $10 million endowment. In 1913, at the dedication of the Peace Palace in The Hague, Carnegie predicted that the end of war was "as certain to come, and come soon, as day follows night."

In 1914, on the eve of the First World War, Carnegie founded the Church Peace Union (CPU), a group of leaders in religion, academia, and politics. Through the CPU, Carnegie hoped to mobilize the world's churches, religious organizations, and other spiritual and moral resources to join in promoting moral leadership to put an end to war forever. For its inaugural international event, the CPU sponsored a conference to be held on August 1, 1914, on the shores of Lake Constance in southern Germany. As the delegates made their way to the conference by train, Germany was invading Belgium.

Despite its inauspicious beginning, the CPU thrived. Today its focus is on ethics and it is known as the Carnegie Council for Ethics in International Affairs, an independent, nonpartisan, nonprofit organization, whose mission is to be the voice for ethics in international affairs.

The outbreak of the First World War was clearly a shock to Carnegie and his optimistic view on world peace. Although his promotion of anti-imperialism and world peace had all failed, and the Carnegie Endowment had not fulfilled his expectations, his beliefs and ideas on international relations had helped build the foundation of the League of Nations after his death, which took world peace to another level.

On the matter of American colonial expansion, Carnegie had always thought it is an unwise gesture for the United States. He did not oppose the annexation of the Hawaiian islands or Puerto Rico, but he opposed the annexation of the Philippines. Carnegie believed that it involved a denial of the fundamental democratic principle, and he also urged William McKinley to withdraw American troops and allow the Filipinos to live with their independence. This act strongly impressed the other American anti-imperialists, who soon elected him vice-president of the Anti-Imperialist League.

After he sold his steel company in 1901, Carnegie was able to get fully involved in the peace cause, both financially and personally. He gave away much of his fortunes to various peace-keeping agencies in order to keep them growing. When his friend, the British writer William T. Stead, asked him to create a new organization for the goal of a peace and arbitration society, his reply was:

Carnegie believed that it is the effort and will of the people, that maintains the peace in international relations. Money is just a push for the act. If world peace depended solely on financial support, it would not seem a goal, but more like an act of pity.

Like Stead, he believed that the United States and the British Empire would merge into one nation, telling him "We are heading straight to the Re-United States". Carnegie believed that the combined country's power would maintain world peace and disarmament. The creation of the Carnegie Endowment for International Peace in 1910 was regarded as a milestone on the road to the ultimate goal of abolition of war. Beyond a gift of $10 million for peace promotion, Carnegie also encouraged the "scientific" investigation of the various causes of war, and the adoption of judicial methods that should eventually eliminate them. He believed that the Endowment exists to promote information on the nations' rights and responsibilities under existing international law and to encourage other conferences to codify this law.

Carnegie was a frequent contributor to periodicals on labor issues. In addition to "Triumphant Democracy" (1886) and "The Gospel of Wealth" (1889), he also wrote "Our Coaching Trip, Brighton to Inverness" (1882), "An American Four-in-hand in Britain" (1883), "Round the World" (1884), "The Empire of Business" (1902), "The Secret of Business is the Management of Men" (1903), "James Watt" (1905) in the Famous Scots Series, "Problems of Today" (1907), and his posthumously published "Autobiography of Andrew Carnegie" (1920).

Carnegie received the honorary Doctor of Laws (DLL) from the University of Glasgow in June 1901, and received the Freedom of the City of Glasgow ""in recognition of his munificence"" later the same year. In July 1902 he received the Freedom of the city of St Andrews, ""in testimony of his great zeal for the welfare of his fellow-men on both sides of the Atlantic"," and in October 1902 the Freedom of the City of Perth ""in testimony of his high personal worth and beneficial influence, and in recognition of widespread benefactions bestowed on this and other lands, and especially in gratitude for the endowment granted by him for the promotion of University education in Scotland"" and the Freedom of the City of Dundee. In 1910, he received the Freedom of the City of Belfast. Carnegie received 1 July, 1914 a honorary doctorate from the University of Groningen the Netherlands.


According to biographer Burton J. Hendrick:

Hendrick argues that:

Carnegie's personal papers are at the Library of Congress Manuscript Division.
The Carnegie Collections of the Columbia University Rare Book and Manuscript Library consist of the archives of the following organizations founded by Carnegie: The Carnegie Corporation of New York (CCNY); The Carnegie Endowment for International Peace (CEIP); the Carnegie Foundation for the Advancement of Teaching (CFAT);The Carnegie Council on Ethics and International Affairs (CCEIA). These collections deal primarily with Carnegie philanthropy and have very little personal material related to Carnegie. Carnegie Mellon University and the Carnegie Library of Pittsburgh jointly administer the Andrew Carnegie Collection of digitized archives on Carnegie's life.




Collections



 


</doc>
<doc id="1939" url="https://en.wikipedia.org/wiki?curid=1939" title="Approximant consonant">
Approximant consonant

Approximants are speech sounds that involve the articulators approaching each other but not narrowly enough nor with enough articulatory precision to create turbulent airflow. Therefore, approximants fall between fricatives, which do produce a turbulent airstream, and vowels, which produce no turbulence. This class is composed of sounds like (as in "rest") and semivowels like and (as in "yes" and "west", respectively), as well as lateral approximants like (as in "less").

Before Peter Ladefoged coined the term "approximant" in the 1960s, the term "frictionless continuant" referred to non-lateral approximants.

In phonology, "approximant" is also a distinctive feature that encompasses all oral sonorants, including vowels and liquids such as taps and trills.

Some approximants resemble vowels in acoustic and articulatory properties and the terms "semivowel" and "glide" are often used for these non-syllabic vowel-like segments. The correlation between semivowels and vowels is strong enough that cross-language differences between semivowels correspond with the differences between their related vowels.

Vowels and their corresponding semivowels alternate in many languages depending on the phonological environment, or for grammatical reasons, as is the case with Indo-European ablaut. Similarly, languages often avoid configurations where a semivowel precedes its corresponding vowel. A number of phoneticians distinguish between semivowels and approximants by their location in a syllable. Although he uses the terms interchangeably, remarks that, for example, the final glides of English "par" and "buy" differ from French "par" ('through') and "baille" ('tub') in that, in the latter pair, the approximants appear in the syllable coda, whereas, in the former, they appear in the syllable nucleus. This means that opaque (if not minimal) contrasts can occur in languages like Italian (with the i-like sound of "piede" 'foot', appearing in the nucleus: , and that of "piano" 'slow', appearing in the syllable onset: ) and Spanish (with a near minimal pair being "abyecto" 'abject' and "abierto" 'opened').

In articulation and often diachronically, palatal approximants correspond to front vowels, velar approximants to back vowels, and labialized approximants to rounded vowels. In American English, the rhotic approximant corresponds to the rhotic vowel. This can create alternations (as shown in the above table).

In addition to alternations, glides can be inserted to the left or the right of their corresponding vowels when they occur next to a hiatus. For example, in Ukrainian, medial triggers the formation of an inserted that acts as a syllable onset so that when the affix is added to футбол ('football') to make футболіст 'football player', it is pronounced , but маоїст ('Maoist'), with the same affix, is pronounced with a glide. Dutch for many speakers has a similar process that extends to mid vowels:

Similarly, vowels can be inserted next to their corresponding glide in certain phonetic environments. Sievers' law describes this behaviour for Germanic.

Non-high semivowels also occur. In colloquial Nepali speech, a process of glide-formation occurs, where one of two adjacent vowels becomes non-syllabic; the process includes mid vowels so that ('cause to wish') features a non-syllabic mid vowel. Spanish features a similar process and even nonsyllabic can occur so that "ahorita" ('right away') is pronounced . It is not often clear, however, whether such sequences involve a semivowel (a consonant) or a diphthong (a vowel), and in many cases, it may not be a meaningful distinction.

Although many languages have central vowels , which lie between back/velar and front/palatal , there are few cases of a corresponding approximant . One is in the Korean diphthong or though it is more frequently analyzed as velar (as in the table above), and Mapudungun may be another, with three high vowel sounds, , , and three corresponding consonants, , and , and a third one is often described as a voiced unrounded velar fricative; some texts note a correspondence between this approximant and that is parallel to – and –. An example is "liq" (?) ('white').

In addition to less turbulence, approximants also differ from fricatives in the precision required to produce them. 
When emphasized, approximants may be slightly fricated (that is, the airstream may become slightly turbulent), which is reminiscent of fricatives. For example, the Spanish word "ayuda" ('help') features a palatal approximant that is pronounced as a fricative in emphatic speech. Spanish can be analyzed as having a meaningful distinction between fricative, approximant, and intermediate . However, such frication is generally slight and intermittent, unlike the strong turbulence of fricative consonants.

Because voicelessness has comparatively reduced resistance to air flow from the lungs, the increased air flow creates more turbulence, making acoustic distinctions between voiceless approximants (which are extremely rare cross-linguistically) and voiceless fricatives difficult. This is why, for example, no language is known to contrast the voiceless labialized velar approximant (also transcribed with the special letter ) with a voiceless labialized velar fricative . Similarly, Standard Tibetan has a voiceless lateral approximant, , and Welsh has a voiceless lateral fricative , but the distinction is not always clear from descriptions of these languages. Again, no language is known to contrast the two. Iaai is reported to have an unusually large number of voiceless approximants, with .

For places of articulation further back in the mouth, languages do not contrast voiced fricatives and approximants. Therefore, the IPA allows the symbols for the voiced fricatives to double for the approximants, with or without a lowering diacritic. 

Occasionally, the glottal "fricatives" are called approximants, since typically has no more frication than voiceless approximants, but they are often phonations of the glottis without any accompanying manner or place of articulation.


In lateral approximants, the center of tongue makes solid contact with the roof of the mouth. However, the defining location is the side of the tongue, which only approaches the teeth.



Voiceless approximants are rarely distinguished from voiceless fricatives. Iaai has an unusually large number of them, with contrasting with (as well as a large number of voiceless nasals). Attested voiceless approximants are:


Examples are:

In Portuguese, the nasal glides and historically became and in some words. In Edo, the nasalized allophones of the approximants and are nasal occlusives, and .

What are transcribed as nasal approximants may include non-syllabic elements of nasal vowels or diphthongs.




</doc>
<doc id="1940" url="https://en.wikipedia.org/wiki?curid=1940" title="Astronomer Royal">
Astronomer Royal

Astronomer Royal is a senior post in the Royal Households of the United Kingdom. There are two officers, the senior being the Astronomer Royal dating from 22 June 1675; the second is the Astronomer Royal for Scotland dating from 1834.

The post was created by King Charles II in 1675, at the same time as he founded the Royal Observatory Greenwich. He appointed John Flamsteed, instructing him "."

The Astronomer Royal was director of the Royal Observatory Greenwich from the establishment of the post in 1675 until 1972. The Astronomer Royal became an honorary title in 1972 without executive responsibilities and a separate post of Director of the Royal Greenwich Observatory was created to manage the institution.

The Astronomer Royal today receives a stipend of 100 GBP per year and is a member of the Royal Household, under the general authority of the Lord Chamberlain. After the separation of the two offices, the position of Astronomer Royal has been largely honorary, though he remains available to advise the Sovereign on astronomical and related scientific matters, and the office is of great prestige.

There was also formerly a Royal Astronomer of Ireland.




</doc>
<doc id="1941" url="https://en.wikipedia.org/wiki?curid=1941" title="Aeon">
Aeon

The word aeon , also spelled eon (in American English), originally meant "life", "vital force" or "being", "generation" or "a period of time", though it tended to be translated as "age" in the sense of "ages", "forever", "timeless" or "for eternity". It is a Latin transliteration from the koine Greek word ("ho aion"), from the archaic ("aiwon"). In Homer it typically refers to life or lifespan. Its latest meaning is more or less similar to the Sanskrit word "kalpa" and Hebrew word "olam". A cognate Latin word "aevum" or "aeuum" (cf. ) for "age" is present in words such as "longevity" and "mediaeval".

Although the term aeon may be used in reference to a period of a billion years (especially in geology, cosmology or astronomy), its more common usage is for any long, indefinite, period. Aeon can also refer to the four aeons on the Geologic Time Scale that make up the Earth's history, the Hadean, Archean, Proterozoic, and the current aeon Phanerozoic.

In astronomy an aeon is defined as a billion years (10 years, abbreviated AE).
Roger Penrose uses the word "aeon" to describe the period between successive and cyclic Big Bangs within the context of conformal cyclic cosmology.

The Bible translation is a treatment of the Hebrew word "olam" and the Greek word "aion". These words have similar meaning, and Young's Literal Translation renders them and their derivatives as "age" or "age-during". Other English versions most often translate them to indicate eternity, being translated as eternal, everlasting, forever, etc. However, there are notable exceptions to this in all major translations, such as : "...I am with you always, to the end of the age" (NRSV), the word "age" being a translation of "aion". Rendering "aion" to indicate eternality in this verse would result in the contradictory phrase "end of eternity", so the question arises whether it should ever be so. Proponents of universal reconciliation point out that this has significant implications for the problem of hell. Contrast in well-known English translations with its rendering in Young's Literal Translation:

<poem>And these shall go away to punishment age-during, but the righteous to life age-during. (YLT)

Then they will go away to eternal punishment, but the righteous to eternal life. (NIV)

These will go away into eternal punishment, but the righteous into eternal life. (NASB)

And these shall go away into everlasting punishment, but the righteous into eternal life. (KJV)

And these will depart into everlasting cutting-off, but the righteous ones into everlasting life. (NWT)</poem>

Plato used the word "aeon" to denote the eternal world of ideas, which he conceived was "behind" the perceived world, as demonstrated in his famous allegory of the cave.

Christianity's idea of "eternal life" comes from the word for life, "zoe", and a form of "aeon", which could mean life in the next aeon, the Kingdom of God, or Heaven, just as much as immortality, as in .

According to the Christian doctrine of universal reconciliation, the Greek New Testament scriptures use the word "aeon" to mean a long period (perhaps 1000 years) and the word "aeonian" to mean "during a long period"; Thus there was a time before the aeons, and the aeonian period is finite. After each man's mortal life ends, he is judged worthy of aeonian life or aeonian punishment. That is, after the period of the aeons, all punishment will cease and death is overcome and then God becomes the all in each one (). This contrasts with the conventional Christian belief in eternal life and eternal punishment.

Occultists of the Thelema and O.T.O. traditions sometimes speak of a "magical Aeon" that may last for far less time, perhaps as little as 2,000 years.

The Order of Nine Angles, a UK-based Left Hand Path/Satanic organisation propose the concept of Aeons are central to the esoteric philosophy developed by the pseudonymous Anton Long, who wrote that "an aeon is the term used [by the O9A] to describe a stage or a type of evolution. Evolution itself is taken to result from a certain specific process – and this process can be described, or explained [or 're-presented' ] via a bifurcation of time. That is, evolution is an expression of how the cosmos changes over or through or because of,'time' – this 'time' having two components. These two components are the causal and the acausal ...

"An aeon is a manifestation, in the causal, of a particular type of acausal energy. This energy re-orders, or changes, the causal. These changes have certain limits – in both causal space and causal time. That is, they have a specific beginning and a specific end. A civilization (or rather, a higher or aeonic-civilization) is how this energy becomes ordered or manifests itself in the causal: how this energy is revealed. A civilization represents the practical changes which this energy causes in the causal -in terms of the effect such energy has on individuals and this planet. A civilization is tied to, is born from, a particular aeon. By the nature of this energy, a civilization is an evolution of life – a move toward a more complex, and thus more conscious existence ..."

Aeon may also be an archaic name for omnipotent beings, such as gods.

In many Gnostic systems, the various emanations of God, who is also known by such names as the One, the Monad, "Aion teleos" ( "The Broadest Aeon"), Bythos ("depth or profundity", Greek ), "Proarkhe" ("before the beginning", Greek ), the "Arkhe" ("the beginning", Greek ), "Sophia" (wisdom), Christos (the Anointed One) are called "Aeons". In the different systems these emanations are differently named, classified, and described, but the emanation theory itself is common to all forms of Gnosticism.

In the Basilidian Gnosis they are called sonships (υἱότητες "huiotetes"; sing.: "huiotes"); according to Marcus, they are numbers and sounds; in Valentinianism they form male/female pairs called "syzygies" (Greek , from σύζυγοι "syzygoi").

Similarly, in the Greek Magical Papyri, the term "Aion" is often used to denote the All, or the supreme aspect of God.



</doc>
<doc id="1942" url="https://en.wikipedia.org/wiki?curid=1942" title="Airline">
Airline

An airline is a company that provides air transport services for traveling passengers and freight. Airlines utilize aircraft to supply these services, and may form partnerships or alliances with other airlines for codeshare agreements. Generally, airline companies are recognized with an air operating certificate or license issued by a governmental aviation body.

Airlines vary in size, from small domestic airlines to full-service international airlines with double decker airplanes. Airline services can be categorized as being intercontinental, domestic, regional, or international, and may be operated as scheduled services or charters. The largest airline currently is American Airlines Group.

DELAG, "Deutsche Luftschiffahrts-Aktiengesellschaft I" was the world's first airline. It was founded on November 16, 1909, with government assistance, and operated airships manufactured by The Zeppelin Corporation. Its headquarters were in Frankfurt. The first fixed wing scheduled airline was started on January 1, 1914, from St. Petersburg, Florida, to Tampa, Florida, operated by the St. Petersburg and Tampa Airboat Line. The four oldest non-dirigible airlines that still exist are Netherlands' KLM (1919), Colombia's Avianca (1919), Australia's Qantas (1921), and the Czech Republic's Czech Airlines (1923).

The earliest fixed wing airline in Europe was Aircraft Transport and Travel, formed by George Holt Thomas in 1916; via a series of takeovers and mergers, this company is an ancestor of modern-day British Airways. Using a fleet of former military Airco DH.4A biplanes that had been modified to carry two passengers in the fuselage, it operated relief flights between Folkestone and Ghent. On 15 July 1919, the company flew a proving flight across the English Channel, despite a lack of support from the British government. Flown by Lt. H Shaw in an Airco DH.9 between RAF Hendon and Paris – Le Bourget Airport, the flight took 2 hours and 30 minutes at £21 per passenger.

On 25 August 1919, the company used DH.16s to pioneer a regular service from Hounslow Heath Aerodrome to Le Bourget, the first regular international service in the world. The airline soon gained a reputation for reliability, despite problems with bad weather, and began to attract European competition. In November 1919, it won the first British civil airmail contract. Six Royal Air Force Airco DH.9A aircraft were lent to the company, to operate the airmail service between Hawkinge and Cologne. In 1920, they were returned to the Royal Air Force.

Other British competitors were quick to follow – Handley Page Transport was established in 1919 and used the company's converted wartime Type O/400 bombers with a capacity for 12 passengers, to run a London-Paris passenger service.

The first French airline was Société des lignes Latécoère, later known as Aéropostale, which started its first service in late 1918 to Spain. The Société Générale des Transports Aériens was created in late 1919, by the Farman brothers and the Farman F.60 Goliath plane flew scheduled services from Toussus-le-Noble to Kenley, near Croydon, England. Another early French airline was the Compagnie des Messageries Aériennes, established in 1919 by Louis-Charles Breguet, offering a mail and freight service between Le Bourget Airport, Paris and Lesquin Airport, Lille.
The first German airline to use heavier than air aircraft was Deutsche Luft-Reederei established in 1917 which started operating in February 1919. In its first year, the D.L.R. operated regularly scheduled flights on routes with a combined length of nearly 1000 miles. By 1921 the D.L.R. network was more than 3000 km (1865 miles) long, and included destinations in the Netherlands, Scandinavia and the Baltic Republics. Another important German airline was Junkers Luftverkehr, which began operations in 1921. It was a division of the aircraft manufacturer Junkers, which became a separate company in 1924. It operated joint-venture airlines in Austria, Denmark, Estonia, Finland, Hungary, Latvia, Norway, Poland, Sweden and Switzerland.

The Dutch airline KLM made its first flight in 1920, and is the oldest continuously operating airline in the world. Established by aviator Albert Plesman, it was immediately awarded a "Royal" predicate from Queen Wilhelmina. Its first flight was from Croydon Airport, London to Amsterdam, using a leased Aircraft Transport and Travel DH-16, and carrying two British journalists and a number of newspapers. In 1921, KLM started scheduled services.

In Finland, the charter establishing Aero O/Y (now Finnair) was signed in the city of Helsinki on September 12, 1923. Junkers F.13 D-335 became the first aircraft of the company, when Aero took delivery of it on March 14, 1924. The first flight was between Helsinki and Tallinn, capital of Estonia, and it took place on March 20, 1924, one week later.

In the Soviet Union, the Chief Administration of the Civil Air Fleet was established in 1921. One of its first acts was to help found Deutsch-Russische Luftverkehrs A.G. (Deruluft), a German-Russian joint venture to provide air transport from Russia to the West. Domestic air service began around the same time, when Dobrolyot started operations on 15 July 1923 between Moscow and Nizhni Novgorod. Since 1932 all operations had been carried under the name Aeroflot.

Early European airlines tended to favor comfort – the passenger cabins were often spacious with luxurious interiors – over speed and efficiency. The relatively basic navigational capabilities of pilots at the time also meant that delays due to the weather were commonplace.

By the early 1920s, small airlines were struggling to compete, and there was a movement towards increased rationalization and consolidation. In 1924, Imperial Airways was formed from the merger of Instone Air Line Company, British Marine Air Navigation, Daimler Airway and Handley Page Transport Co Ltd., to allow British airlines to compete with stiff competition from French and German airlines that were enjoying heavy government subsidies. The airline was a pioneer in surveying and opening up air routes across the world to serve far-flung parts of the British Empire and to enhance trade and integration.

The first new airliner ordered by Imperial Airways, was the Handley Page W8f "City of Washington", delivered on 3 November 1924. In the first year of operation the company carried 11,395 passengers and 212,380 letters. In April 1925, the film "The Lost World" became the first film to be screened for passengers on a scheduled airliner flight when it was shown on the London-Paris route.

Two French airlines also merged to form Air Union on 1 January 1923. This later merged with four other French airlines to become Air France, the country's flagship carrier to this day, on 7 October 1933.

Germany's Deutsche Luft Hansa was created in 1926 by merger of two airlines, one of them Junkers Luftverkehr. Luft Hansa, due to the Junkers heritage and unlike most other airlines at the time, became a major investor in airlines outside of Europe, providing capital to Varig and Avianca. German airliners built by Junkers, Dornier, and Fokker were among the most advanced in the world at the time.

In 1926, Alan Cobham surveyed a flight route from the UK to Cape Town, South Africa, following this up with another proving flight to Melbourne, Australia. Other routes to British India and the Far East were also charted and demonstrated at this time. Regular services to Cairo and Basra began in 1927 and were extended to Karachi in 1929. The London-Australia service was inaugurated in 1932 with the Handley Page HP 42 airliners. Further services were opened up to Calcutta, Rangoon, Singapore, Brisbane and Hong Kong passengers departed London on 14 March 1936 following the establishment of a branch from Penang to Hong Kong.

Like Imperial Airways, Air France and KLM's early growth depended heavily on the needs to service links with far-flung colonial possessions (North Africa and Indochina for the French and the East Indies for the Dutch). France began an air mail service to Morocco in 1919 that was bought out in 1927, renamed Aéropostale, and injected with capital to become a major international carrier. In 1933, Aéropostale went bankrupt, was nationalized and merged into Air France.

Although Germany lacked colonies, it also began expanding its services globally. In 1931, the airship Graf Zeppelin began offering regular scheduled passenger service between Germany and South America, usually every two weeks, which continued until 1937. In 1936, the airship Hindenburg entered passenger service and successfully crossed the Atlantic 36 times before crashing at Lakehurst, New Jersey, on May 6, 1937. In 1938, a weekly air service from Berlin to Kabul, Afghanistan, started operating.

From February 1934 until World War II began in 1939 Deutsche Lufthansa operated an airmail service from Stuttgart, Germany via Spain, the Canary Islands and West Africa to Natal in Brazil. This was the first time an airline flew across an ocean.

By the end of the 1930s Aeroflot had become the world's largest airline, employing more than 4,000 pilots and 60,000 other service personnel and operating around 3,000 aircraft (of which 75% were considered obsolete by its own standards). During the Soviet era Aeroflot was synonymous with Russian civil aviation, as it was the only air carrier. It became the first airline in the world to operate sustained regular jet services on 15 September 1956 with the Tupolev Tu-104.

Deregulation of the European Union airspace in the early 1990s has had substantial effect on the structure of the industry there. The shift towards 'budget' airlines on shorter routes has been significant. Airlines such as EasyJet and Ryanair have often grown at the expense of the traditional national airlines.

There has also been a trend for these national airlines themselves to be privatized such as has occurred for Aer Lingus and British Airways. Other national airlines, including Italy's Alitalia, have suffered – particularly with the rapid increase of oil prices in early 2008.

Tony Jannus conducted the United States' first scheduled commercial airline flight on 1 January 1914 for the St. Petersburg-Tampa Airboat Line. The 23-minute flight traveled between St. Petersburg, Florida and Tampa, Florida, passing some above Tampa Bay in Jannus' Benoist XIV wood and muslin biplane flying boat. His passenger was a former mayor of St. Petersburg, who paid $400 for the privilege of sitting on a wooden bench in the open cockpit. The Airboat line operated for about four months, carrying more than 1,200 passengers who paid $5 each. Chalk's International Airlines began service between Miami and Bimini in the Bahamas in February 1919. Based in Ft. Lauderdale, Chalk's claimed to be the oldest continuously operating airline in the United States until its closure in 2008.

Following World War I, the United States found itself swamped with aviators. Many decided to take their war-surplus aircraft on barnstorming campaigns, performing aerobatic maneuvers to woo crowds. In 1918, the United States Postal Service won the financial backing of Congress to begin experimenting with air mail service, initially using Curtiss Jenny aircraft that had been procured by the United States Army Air Service. Private operators were the first to fly the mail but due to numerous accidents the US Army was tasked with mail delivery. During the Army's involvement they proved to be too unreliable and lost their air mail duties. By the mid-1920s, the Postal Service had developed its own air mail network, based on a transcontinental backbone between New York City and San Francisco. To supplement this service, they offered twelve contracts for spur routes to independent bidders. Some of the carriers that won these routes would, through time and mergers, evolve into Pan Am, Delta Air Lines, Braniff Airways, American Airlines, United Airlines (originally a division of Boeing), Trans World Airlines, Northwest Airlines, and Eastern Air Lines.

Service during the early 1920s was sporadic: most airlines at the time were focused on carrying bags of mail. In 1925, however, the Ford Motor Company bought out the Stout Aircraft Company and began construction of the all-metal Ford Trimotor, which became the first successful American airliner. With a 12-passenger capacity, the Trimotor made passenger service potentially profitable. Air service was seen as a supplement to rail service in the American transportation network.

At the same time, Juan Trippe began a crusade to create an air network that would link America to the world, and he achieved this goal through his airline, Pan American World Airways, with a fleet of flying boats that linked Los Angeles to Shanghai and Boston to London. Pan Am and Northwest Airways (which began flights to Canada in the 1920s) were the only U.S. airlines to go international before the 1940s.

With the introduction of the Boeing 247 and Douglas DC-3 in the 1930s, the U.S. airline industry was generally profitable, even during the Great Depression. This trend continued until the beginning of World War II.

World War II, like World War I, brought new life to the airline industry. Many airlines in the Allied countries were flush from lease contracts to the military, and foresaw a future explosive demand for civil air transport, for both passengers and cargo. They were eager to invest in the newly emerging flagships of air travel such as the Boeing Stratocruiser, Lockheed Constellation, and Douglas DC-6. Most of these new aircraft were based on American bombers such as the B-29, which had spearheaded research into new technologies such as pressurization. Most offered increased efficiency from both added speed and greater payload.

In the 1950s, the De Havilland Comet, Boeing 707, Douglas DC-8, and Sud Aviation Caravelle became the first flagships of the Jet Age in the West, while the Eastern bloc had Tupolev Tu-104 and Tupolev Tu-124 in the fleets of state-owned carriers such as Czechoslovak ČSA, Soviet Aeroflot and East-German Interflug. The Vickers Viscount and Lockheed L-188 Electra inaugurated turboprop transport.

On 4 October 1958, BOAC started transatlantic flights between London Heathrow and New York Idlewild with a Comet 4, and Pan Am followed on 26 October with a B707 service between New York and Paris.

The next big boost for the airlines would come in the 1970s, when the Boeing 747, McDonnell Douglas DC-10, and Lockheed L-1011 inaugurated widebody ("jumbo jet") service, which is still the standard in international travel. The Tupolev Tu-144 and its Western counterpart, Concorde, made supersonic travel a reality. Concorde first flew in 1969 and operated through 2003. In 1972, Airbus began producing Europe's most commercially successful line of airliners to date. The added efficiencies for these aircraft were often not in speed, but in passenger capacity, payload, and range. Airbus also features modern electronic cockpits that were common across their aircraft to enable pilots to fly multiple models with minimal cross-training.

The 1978 U.S. airline industry deregulation lowered federally controlled barriers for new airlines just as a downturn in the nation's economy occurred. New start-ups entered during the downturn, during which time they found aircraft and funding, contracted hangar and maintenance services, trained new employees, and recruited laid-off staff from other airlines.

Major airlines dominated their routes through aggressive pricing and additional capacity offerings, often swamping new start-ups. In the place of high barriers to entry imposed by regulation, the major airlines implemented an equally high barrier called loss leader pricing. In this strategy an already established and dominant airline stomps out its competition by lowering airfares on specific routes, below the cost of operating on it, choking out any chance a start-up airline may have. The industry side effect is an overall drop in revenue and service quality. Since deregulation in 1978 the average domestic ticket price has dropped by 40%. So has airline employee pay. By incurring massive losses, the airlines of the USA now rely upon a scourge of cyclical Chapter 11 bankruptcy proceedings to continue doing business. America West Airlines (which has since merged with US Airways) remained a significant survivor from this new entrant era, as dozens, even hundreds, have gone under.

In many ways, the biggest winner in the deregulated environment was the air passenger. Although not exclusively attributable to deregulation, indeed the U.S. witnessed an explosive growth in demand for air travel. Many millions who had never or rarely flown before became regular fliers, even joining frequent flyer loyalty programs and receiving free flights and other benefits from their flying. New services and higher frequencies meant that business fliers could fly to another city, do business, and return the same day, from almost any point in the country. Air travel's advantages put long distance intercity railroad travel and bus lines under pressure, with most of the latter having withered away, whilst the former is still protected under nationalization through the continuing existence of Amtrak.

By the 1980s, almost half of the total flying in the world took place in the U.S., and today the domestic industry operates over 10,000 daily departures nationwide.

Toward the end of the century, a new style of low cost airline emerged, offering a no-frills product at a lower price. Southwest Airlines, JetBlue, AirTran Airways, Skybus Airlines and other low-cost carriers began to represent a serious challenge to the so-called "legacy airlines", as did their low-cost counterparts in many other countries. Their commercial viability represented a serious competitive threat to the legacy carriers. However, of these, ATA and Skybus have since ceased operations.

Increasingly since 1978, US airlines have been reincorporated and spun off by newly created and internally led management companies, and thus becoming nothing more than operating units and subsidiaries with limited financially decisive control. Among some of these holding companies and parent companies which are relatively well known, are the UAL Corporation, along with the AMR Corporation, among a long list of airline holding companies sometime recognized worldwide. Less recognized are the private equity firms which often seize managerial, financial, and board of directors control of distressed airline companies by temporarily investing large sums of capital in air carriers, to rescheme an airlines assets into a profitable organization or liquidating an air carrier of their profitable and worthwhile routes and business operations.

Thus the last 50 years of the airline industry have varied from reasonably profitable, to devastatingly depressed. As the first major market to deregulate the industry in 1978, U.S. airlines have experienced more turbulence than almost any other country or region. In fact, no U.S. legacy carrier survived bankruptcy-free. Among the outspoken critics of deregulation, former CEO of American Airlines, Robert Crandall has publicly stated:

"Chapter 11 bankruptcy protection filing shows airline industry deregulation was a mistake."

Congress passed the Air Transportation Safety and System Stabilization Act (P.L. 107-42) in response to a severe liquidity crisis facing the already-troubled airline industry in the aftermath of the September 11th terrorist attacks. Through the ATSB Congress sought to provide cash infusions to carriers for both the cost of the four-day federal shutdown of the airlines and the incremental losses incurred through December 31, 2001, as a result of the terrorist attacks. This resulted in the first government bailout of the 21st century. Between 2000 and 2005 US airlines lost $30 billion with wage cuts of over $15 billion and 100,000 employees laid off.

In recognition of the essential national economic role of a healthy aviation system, Congress authorized partial compensation of up to $5 billion in cash subject to review by the U.S. Department of Transportation and up to $10 billion in loan guarantees subject to review by a newly created Air Transportation Stabilization Board (ATSB). The applications to DOT for reimbursements were subjected to rigorous multi-year reviews not only by DOT program personnel but also by the Government Accountability Office and the DOT Inspector General.

Ultimately, the federal government provided $4.6 billion in one-time, subject-to-income-tax cash payments to 427 U.S. air carriers, with no provision for repayment, essentially a gift from the taxpayers. (Passenger carriers operating scheduled service received approximately $4 billion, subject to tax.) In addition, the ATSB approved loan guarantees to six airlines totaling approximately $1.6 billion. Data from the U.S. Treasury Department show that the government recouped the $1.6 billion and a profit of $339 million from the fees, interest and purchase of discounted airline stock associated with loan guarantees.

The three largest major carriers and Southwest Airlines control 70% of the U.S. passenger market.

Although Philippine Airlines (PAL) was officially founded on February 26, 1941, its license to operate as an airliner was derived from merged Philippine Aerial Taxi Company (PATCO) established by mining magnate Emmanuel N. Bachrach on December 3, 1930, making it Asia's oldest scheduled carrier still in operation. Commercial air service commenced three weeks later from Manila to Baguio, making it Asia's first airline route. Bachrach's death in 1937 paved the way for its eventual merger with Philippine Airlines in March 1941 and made it Asia's oldest airline. It is also the oldest airline in Asia still operating under its current name. Bachrach's majority share in PATCO was bought by beer magnate Andres R. Soriano in 1939 upon the advice of General Douglas MacArthur and later merged with newly formed Philippine Airlines with PAL as the surviving entity. Soriano has controlling interest in both airlines before the merger. PAL restarted service on March 15, 1941, with a single Beech Model 18 NPC-54 aircraft, which started its daily services between Manila (from Nielson Field) and Baguio, later to expand with larger aircraft such as the DC-3 and Vickers Viscount.

Korean Air was one of the first airlines to be launched among the other Asian countries in 1946 along with Asiana Airlines, which later joined in 1988. The license to operate as an airliner was granted by the federal government body after reviewing the necessity at the national assembly. The Hanjin occupies the largest ownership of Korean Air as well as few low-budget airlines as of now. The Korean Air is among the founders of SkyTeam, which was established in 2000. Asiana Airlines joined Star Alliance in 2003. Korean Air and Asiana Airlines comprise one of the largest combined airline miles and number of passenger served at the regional market of Asian airline industry

India was also one of the first countries to embrace civil aviation. One of the first Asian airline companies was Air India, which was founded as Tata Airlines in 1932, a division of Tata Sons Ltd. (now Tata Group). The airline was founded by India's leading industrialist, JRD Tata. On October 15, 1932, J. R. D. Tata himself flew a single engined De Havilland Puss Moth carrying air mail (postal mail of Imperial Airways) from Karachi to Bombay via Ahmedabad. The aircraft continued to Madras via Bellary piloted by Royal Air Force pilot Nevill Vintcent. Tata Airlines was also one of the world's first major airlines which began its operations without any support from the Government.

With the outbreak of World War II, the airline presence in Asia came to a relative halt, with many new flag carriers donating their aircraft for military aid and other uses. Following the end of the war in 1945, regular commercial service was restored in India and Tata Airlines became a public limited company on July 29, 1946, under the name Air India. After the independence of India, 49% of the airline was acquired by the Government of India. In return, the airline was granted status to operate international services from India as the designated flag carrier under the name Air India International.

On July 31, 1946, a chartered Philippine Airlines (PAL) DC-4 ferried 40 American servicemen to Oakland, California, from Nielson Airport in Makati City with stops in Guam, Wake Island, Johnston Atoll and Honolulu, Hawaii, making PAL the first Asian airline to cross the Pacific Ocean. A regular service between Manila and San Francisco was started in December. It was during this year that the airline was designated as the flag carrier of Philippines.

During the era of decolonization, newly born Asian countries started to embrace air transport. Among the first Asian carriers during the era were Cathay Pacific of Hong Kong (founded in September 1946), Orient Airways (later Pakistan International Airlines; founded in October 1946), Air Ceylon (later SriLankan Airlines; founded in 1947), Malayan Airways Limited in 1947 (later Singapore and Malaysia Airlines), El Al in Israel in 1948, Garuda Indonesia in 1949, Japan Airlines in 1951, Thai Airways International in 1960, and Korean National Airlines in 1947.

Among the first countries to have regular airlines in Latin America and the Caribbean were Bolivia with Lloyd Aéreo Boliviano, Cuba with Cubana de Aviación, Colombia with Avianca (the first airline established in the Americas), Argentina with Aerolineas Argentinas, Chile with LAN Chile (today LATAM Airlines), Brazil with Varig, Dominican Republic with Dominicana de Aviación, Mexico with Mexicana de Aviación, Trinidad and Tobago with BWIA West Indies Airways (today Caribbean Airlines), Venezuela with Aeropostal, Puerto Rico with Puertorriquena; and TACA based in El Salvador and representing several airlines of Central America (Costa Rica, Guatemala, Honduras and Nicaragua). All the previous airlines started regular operations well before World War II. Puerto Rican commercial airlines such as Prinair, Oceanair, Fina Air and Vieques Air Link came much after the second world war, as did several others from other countries like Mexico's Interjet and Volaris, Venezuela's Aserca Airlines and others.

The air travel market has evolved rapidly over recent years in Latin America. Some industry estimates indicate that over 2,000 new aircraft will begin service over the next five years in this region.

These airlines serve domestic flights within their countries, as well as connections within Latin America and also overseas flights to North America, Europe, Australia, and Asia.

Only two airlines - Avianca and LATAM Airlines - have international subsidiaries and cover many destinations within the Americas as well as major hubs in other continents. LATAM with Chile as the central operation along with Peru, Ecuador, Colombia, Brazil and Argentina and formerly with some operations in the Dominican Republic. The AviancaTACA group has control of Avianca Brazil, VIP Ecuador and a strategic alliance with AeroGal.

Many countries have national airlines that the government owns and operates. Fully private airlines are subject to a great deal of government regulation for economic, political, and safety concerns. For instance, governments often intervene to halt airline labor actions to protect the free flow of people, communications, and goods between different regions without compromising safety.

The United States, Australia, and to a lesser extent Brazil, Mexico, India, the United Kingdom, and Japan have "deregulated" their airlines. In the past, these governments dictated airfares, route networks, and other operational requirements for each airline. Since deregulation, airlines have been largely free to negotiate their own operating arrangements with different airports, enter and exit routes easily, and to levy airfares and supply flights according to market demand.
The entry barriers for new airlines are lower in a deregulated market, and so the U.S. has seen hundreds of airlines start up (sometimes for only a brief operating period). This has produced far greater competition than before deregulation in most markets. The added competition, together with pricing freedom, means that new entrants often take market share with highly reduced rates that, to a limited degree, full service airlines must match. This is a major constraint on profitability for established carriers, which tend to have a higher cost base.

As a result, profitability in a deregulated market is uneven for most airlines. These forces have caused some major airlines to go out of business, in addition to most of the poorly established new entrants.

In the United States, the airline industry is dominated by four large firms. Because of industry consolidation, after fuel prices dropped considerably in 2015, very little of the savings were passed on to consumers.

Groups such as the International Civil Aviation Organization establish worldwide standards for safety and other vital concerns. Most international air traffic is regulated by bilateral agreements between countries, which designate specific carriers to operate on specific routes. The model of such an agreement was the Bermuda Agreement between the US and UK following World War II, which designated airports to be used for transatlantic flights and gave each government the authority to nominate carriers to operate routes.

Bilateral agreements are based on the "freedoms of the air", a group of generalized traffic rights ranging from the freedom to overfly a country to the freedom to provide domestic flights within a country (a very rarely granted right known as cabotage). Most agreements permit airlines to fly from their home country to designated airports in the other country: some also extend the freedom to provide continuing service to a third country, or to another destination in the other country while carrying passengers from overseas.

In the 1990s, "open skies" agreements became more common. These agreements take many of these regulatory powers from state governments and open up international routes to further competition. Open skies agreements have met some criticism, particularly within the European Union, whose airlines would be at a comparative disadvantage with the United States' because of cabotage restrictions.

In 2017, 4.1 billion passengers have been carried by airlines in 41.9 million commercial scheduled flights (an average payload of 4100/41.9round0 passengers), for 7.75 trillion passenger kilometres (an average trip of 7750/4.100round0 km) over 45,091 airline routes served globally.
In 2016, air transport generated $704.4 billion of revenue in 2016, employed 10.2 million workers, supported 65.5 million jobs and $2.7 trillion of economic activity: 3.6% of the global GDP.

In July 2016, the total weekly airline capacity was 181.1 billion Available Seat Kilometers (+6.9% compared to July 2015): 57.6bn in Asia-Pacific, 47.7bn in Europe, 46.2bn in North America, 12.2bn in Middle East, 12.0bn in Latin America and 5.4bn in Africa.

Historically, air travel has survived largely through state support, whether in the form of equity or subsidies. The airline industry as a whole has made a cumulative loss during its 100-year history.

One argument is that positive externalities, such as higher growth due to global mobility, outweigh the microeconomic losses and justify continuing government intervention. A historically high level of government intervention in the airline industry can be seen as part of a wider political consensus on strategic forms of transport, such as highways and railways, both of which receive public funding in most parts of the world. Although many countries continue to operate state-owned or parastatal airlines, many large airlines today are privately owned and are therefore governed by microeconomic principles to maximize shareholder profit.

In December 1991, the collapse of Pan Am, an airline often credited for shaping the international airline industry, highlighted the financial complexities faced by major airline companies.

Following the 1978 deregulation, U.S. carriers did not manage to make an aggregate profit for 12 years in 31, including four years where combined losses amounted to $10 billion, but rebounded with eight consecutive years of profits since 2010, including its four with over $10 billion profits.
They drop loss-making routes, avoid fare wars and market share battles, limit capacity growth, add hub feed with regional jets to increase their profitability.
They change schedules to create more connections, buy used aircraft, reduce international frequencies and leverage partnerships to optimise capacities and benefit from overseas connectivity.

The world's largest airlines can be defined in several ways. American Airlines Group is the largest by its fleet size, revenue, profit, passengers carried and revenue passenger mile. Delta Air Lines is the largest by assets value and market capitalization. Lufthansa Group is the largest by number of employees, FedEx Express by freight tonne-kilometers, Ryanair by number of international passengers carried and Turkish Airlines by number of countries served.
Airlines assign prices to their services in an attempt to maximize profitability. The pricing of airline tickets has become increasingly complicated over the years and is now largely determined by computerized yield management systems.

Because of the complications in scheduling flights and maintaining profitability, airlines have many loopholes that can be used by the knowledgeable traveler. Many of these airfare secrets are becoming more and more known to the general public, so airlines are forced to make constant adjustments.

Most airlines use differentiated pricing, a form of price discrimination, to sell air services at varying prices simultaneously to different segments. Factors influencing the price include the days remaining until departure, the booked load factor, the forecast of total demand by price point, competitive pricing in force, and variations by day of week of departure and by time of day. Carriers often accomplish this by dividing each cabin of the aircraft (first, business and economy) into a number of travel classes for pricing purposes.

A complicating factor is that of origin-destination control ("O&D control"). Someone purchasing a ticket from Melbourne to Sydney (as an example) for A$200 is competing with someone else who wants to fly Melbourne to Los Angeles through Sydney on the same flight, and who is willing to pay A$1400. Should the airline prefer the $1400 passenger, or the $200 passenger plus a possible Sydney-Los Angeles passenger willing to pay $1300? Airlines have to make hundreds of thousands of similar pricing decisions daily.

The advent of advanced computerized reservations systems in the late 1970s, most notably Sabre, allowed airlines to easily perform cost-benefit analyses on different pricing structures, leading to almost perfect price discrimination in some cases (that is, filling each seat on an aircraft at the highest price that can be charged without driving the consumer elsewhere).

The intense nature of airfare pricing has led to the term "fare war" to describe efforts by airlines to undercut other airlines on competitive routes. Through computers, new airfares can be published quickly and efficiently to the airlines' sales channels. For this purpose the airlines use the Airline Tariff Publishing Company (ATPCO), who distribute latest fares for more than 500 airlines to Computer Reservation Systems across the world.

The extent of these pricing phenomena is strongest in "legacy" carriers. In contrast, low fare carriers usually offer pre-announced and simplified price structure, and sometimes quote prices for each leg of a trip separately.

Computers also allow airlines to predict, with some accuracy, how many passengers will actually fly after making a reservation to fly. This allows airlines to overbook their flights enough to fill the aircraft while accounting for "no-shows", but not enough (in most cases) to force paying passengers off the aircraft for lack of seats, stimulative pricing for low demand flights coupled with overbooking on high demand flights can help reduce this figure. This is especially crucial during tough economic times as airlines undertake massive cuts to ticket prices to retain demand.

Over January/February 2018, the cheapest airline surveyed by price comparator rome2rio was Tigerair Australia with $0.06/km followed by AirAsia X with $0.07/km, while the most expensive was Charterlines, Inc. with $1.26/km followed by Buddha Air with $1.18/km.

For the IATA, the global airline industry revenue was $754 billion in 2017 for a $38.4 billion collective profit, and should rise by 10.7% to $834 billion in 2018 for a $33.8 billion profit forecast, down by 12% due to rising jet fuel and labor costs.

The demand for air transport will be less elastic for longer flights than for shorter flights, and more elastic for leisure travel than for business travel.

Airlines have substantial fixed and operating costs to establish and maintain air services: labor, fuel, airplanes, engines, spares and parts, IT services and networks, airport equipment, airport handling services, booking commissions, advertising, catering, training, aviation insurance and other costs. Thus all but a small percentage of the income from ticket sales is paid out to a wide variety of external providers or internal cost centers.

Moreover, the industry is structured so that airlines often act as tax collectors. Airline fuel is untaxed because of a series of treaties existing between countries. Ticket prices include a number of fees, taxes and surcharges beyond the control of airlines. Airlines are also responsible for enforcing government regulations. If airlines carry passengers without proper documentation on an international flight, they are responsible for returning them back to the original country.

Analysis of the 1992–1996 period shows that every player in the air transport chain is far more profitable than the airlines, who collect and pass through fees and revenues to them from ticket sales. While airlines as a whole earned 6% return on capital employed (2–3.5% less than the cost of capital), airports earned 10%, catering companies 10–13%, handling companies 11–14%, aircraft lessors 15%, aircraft manufacturers 16%, and global distribution companies more than 30%. (Source: Spinetta, 2000, quoted in Doganis, 2002)

There has been continuing cost competition from low cost airlines. Many companies emulate Southwest Airlines in various respects. The lines between full-service and low-cost airlines have become blurred – e.g., with most "full service" airlines introducing baggage check fees despite Southwest not doing so.

Many airlines in the U.S. and elsewhere have experienced business difficulty. U.S. airlines that have declared Chapter 11 bankruptcy since 1990 have included American Airlines, Continental Airlines (twice), Delta Air Lines, Northwest Airlines, Pan Am, United Airlines, and US Airways (twice).

Where an airline has established an engineering base at an airport, then there may be considerable economic advantages in using that same airport as a preferred focus (or "hub") for its scheduled flights.

Operating costs for US major airlines are primarily aircraft operating expense including jet fuel, aircraft maintenance, depreciation and aircrew for 44%, servicing expense for 29% (traffic 11%, passenger 11% and aircraft 7%), 14% for reservations and sales and 13% for overheads (administration 6% and advertising 2%).
An average US major Boeing 757-200 flies stages 11.3 block hours per day and costs $2,550 per block hour : $923 of ownership, $590 of maintenance, $548 of fuel and $489 of crew; or $13.34 per 186 seats per block hour.
For a Boeing 737-500, a low-cost carrier like Southwest have lower operating costs at $1,526 than a full service one like United at $2,974, and higher productivity with 399,746 ASM per day against 264,284, resulting in a unit cost of 152600/399746round2 $cts/ASM against 297400/264284round2 $cts/ASM.

Airline financing is quite complex, since airlines are highly leveraged operations. Not only must they purchase (or lease) new airliner bodies and engines regularly, they must make major long-term fleet decisions with the goal of meeting the demands of their markets while producing a fleet that is relatively economical to operate and maintain; comparably Southwest Airlines and their reliance on a single airplane type (the Boeing 737 and derivatives), with the now defunct Eastern Air Lines which operated 17 different aircraft types, each with varying pilot, engine, maintenance, and support needs.

A second financial issue is that of hedging oil and fuel purchases, which are usually second only to labor in its relative cost to the company. However, with the current high fuel prices it has become the largest cost to an airline. Legacy airlines, compared with new entrants, have been hit harder by rising fuel prices partly due to the running of older, less fuel efficient aircraft. While hedging instruments can be expensive, they can easily pay for themselves many times over in periods of increasing fuel costs, such as in the 2000–2005 period.

In view of the congestion apparent at many international airports, the ownership of slots at certain airports (the right to take-off or land an aircraft at a particular time of day or night) has become a significant tradable asset for many airlines. Clearly take-off slots at popular times of the day can be critical in attracting the more profitable business traveler to a given airline's flight and in establishing a competitive advantage against a competing airline.

If a particular city has two or more airports, market forces will tend to attract the less profitable routes, or those on which competition is weakest, to the less congested airport, where slots are likely to be more available and therefore cheaper. For example, Reagan National Airport attracts profitable routes due partly to its congestion, leaving less-profitable routes to Baltimore-Washington International Airport and Dulles International Airport.

Other factors, such as surface transport facilities and onward connections, will also affect the relative appeal of different airports and some long distance flights may need to operate from the one with the longest runway. For example, LaGuardia Airport is the preferred airport for most of Manhattan due to its proximity, while long-distance routes must use John F. Kennedy International Airport's longer runways.

Codesharing is the most common type of airline partnership; it involves one airline selling tickets for another airline's flights under its own airline code. An early example of this was Japan Airlines' (JAL) codesharing partnership with Aeroflot in the 1960s on Tokyo–Moscow flights; Aeroflot operated the flights using Aeroflot aircraft, but JAL sold tickets for the flights as if they were JAL flights. This practice allows airlines to expand their operations, at least on paper, into parts of the world where they cannot afford to establish bases or purchase aircraft. Another example was the Austrian–Sabena partnership on the Vienna–Brussels–New York/JFK route during the late '60s, using a Sabena Boeing 707 with Austrian livery.

Since airline reservation requests are often made by city-pair (such as "show me flights from Chicago to Düsseldorf"), an airline that can codeshare with another airline for a variety of routes might be able to be listed as indeed offering a Chicago–Düsseldorf flight. The passenger is advised however, that airline no. 1 operates the flight from say Chicago to Amsterdam, and airline no. 2 operates the continuing flight (on a different airplane, sometimes from another terminal) to Düsseldorf. Thus the primary rationale for code sharing is to expand one's service offerings in city-pair terms to increase sales.

A more recent development is the airline alliance, which became prevalent in the late 1990s. These alliances can act as virtual mergers to get around government restrictions. Alliances of airlines such as Star Alliance, Oneworld, and SkyTeam coordinate their passenger service programs (such as lounges and frequent-flyer programs), offer special interline tickets, and often engage in extensive codesharing (sometimes systemwide). These are increasingly integrated business combinations—sometimes including cross-equity arrangements—in which products, service standards, schedules, and airport facilities are standardized and combined for higher efficiency. One of the first airlines to start an alliance with another airline was KLM, who partnered with Northwest Airlines. Both airlines later entered the SkyTeam alliance after the fusion of KLM and Air France in 2004.

Often the companies combine IT operations, or purchase fuel and aircraft as a bloc to achieve higher bargaining power. However, the alliances have been most successful at purchasing invisible supplies and services, such as fuel. Airlines usually prefer to purchase items visible to their passengers to differentiate themselves from local competitors. If an airline's main domestic competitor flies Boeing airliners, then the airline may prefer to use Airbus aircraft regardless of what the rest of the alliance chooses.

Fuel hedging is a contractual tool used by transportation companies like airlines to reduce their exposure to volatile and potentially rising fuel costs. Several low-cost carriers such as Southwest Airlines adopt this practice.

Southwest is credited with maintaining strong business profits between 1999 and the early 2000s due to its fuel hedging policy. Many other airlines are replicating Southwest's hedging policy to control their fuel costs.

Airlines often have a strong seasonality, with traffic low in Winter and peaking in Summer. In Europe the most extreme market are the Greek islands with July/August having more than ten times the winter traffic, as Jet2 is the most seasonal among low-cost carriers with July having seven times the January traffic, whereas legacy carriers are much less with only 85/115% variability.

Aircraft engines emit noise pollution, gases and particulate emissions, and contribute to global dimming.

Growth of the industry in recent years raised a number of ecological questions.

Domestic air transport grew in China at 15.5 percent annually from 2001 to 2006. The rate of air travel globally increased at 3.7 percent per year over the same time. In the EU greenhouse gas emissions from aviation increased by 87% between 1990 and 2006. However it must be compared with the flights increase, only in UK, between 1990 and 2006 terminal passengers increased from 100 000 thousands to 250 000 thousands., according to AEA reports every year, 750 million passengers travel by European airlines, which also share 40% of merchandise value in and out of Europe. Without even pressure from "green activists", targeting lower ticket prices, generally, airlines do what is possible to cut the fuel consumption (and gas emissions connected therewith). Further, according to some reports, it can be concluded that the last piston-powered aircraft were as fuel-efficient as the average jet in 2005.

Despite continuing efficiency improvements from the major aircraft manufacturers, the expanding demand for global air travel has resulted in growing greenhouse gas (GHG) emissions. Currently, the aviation sector, including US domestic and global international travel, make approximately 1.6 percent of global anthropogenic GHG emissions per annum. North America accounts for nearly 40 percent of the world's GHG emissions from aviation fuel use.

CO2 emissions from the jet fuel burned per passenger on an average airline flight is about 353 kilograms (776 pounds). Loss of natural habitat potential associated with the jet fuel burned per passenger on a airline flight is estimated to be 250 square meters (2700 square feet).

In the context of climate change and peak oil, there is a debate about possible taxation of air travel and the inclusion of aviation in an emissions trading scheme, with a view to ensuring that the total external costs of aviation are taken into account.

The airline industry is responsible for about 11 percent of greenhouse gases emitted by the U.S. transportation sector. Boeing estimates that biofuels could reduce flight-related greenhouse-gas emissions by 60 to 80 percent. The solution would be blending algae fuels with existing jet fuel:


There are projects on electric aircraft, and some of them are fully operational as of 2013.

Each operator of a scheduled or charter flight uses an airline call sign when communicating with airports or air traffic control centres. Most of these call-signs are derived from the airline's trade name, but for reasons of history, marketing, or the need to reduce ambiguity in spoken English (so that pilots do not mistakenly make navigational decisions based on instructions issued to a different aircraft), some airlines and air forces use call-signs less obviously connected with their trading name. For example, British Airways uses a "Speedbird" call-sign, named after the logo of its predecessor, BOAC, while SkyEurope used "Relax".

The various types of airline personnel include:
Airlines follow a corporate structure where each broad area of operations (such as maintenance, flight operations (including flight safety), and passenger service) is supervised by a vice president. Larger airlines often appoint vice presidents to oversee each of the airline's hubs as well. Airlines employ lawyers to deal with regulatory procedures and other administrative tasks.

The pattern of ownership has been privatized in the recent years, that is, the ownership has gradually changed from governments to private and individual sectors or organizations. This occurs as regulators permit greater freedom and non-government ownership, in steps that are usually decades apart. This pattern is not seen for all airlines in all regions.

Growth rates are not consistent in all regions, but countries with a de-regulated airline industry have more competition and greater pricing freedom. This results in lower fares and sometimes dramatic spurts in traffic growth. The U.S., Australia, Canada, Japan, Brazil, India and other markets exhibit this trend. The industry has been observed to be cyclical in its financial performance. Four or five years of poor earnings precede five or six years of improvement. But profitability even in the good years is generally low, in the range of 2–3% net profit after interest and tax. In times of profit, airlines lease new generations of airplanes and upgrade services in response to higher demand. Since 1980, the industry has not earned back the cost of capital during the best of times. Conversely, in bad times losses can be dramatically worse. Warren Buffett in 1999 said "the money that had been made since the dawn of aviation by all of this country's airline companies was zero. Absolutely zero."

As in many mature industries, consolidation is a trend. Airline groupings may consist of limited bilateral partnerships, long-term, multi-faceted alliances between carriers, equity arrangements, mergers, or takeovers. Since governments often restrict ownership and merger between companies in different countries, most consolidation takes place within a country. In the U.S., over 200 airlines have merged, been taken over, or gone out of business since deregulation in 1978. Many international airline managers are lobbying their governments to permit greater consolidation to achieve higher economy and efficiency.




</doc>
<doc id="1943" url="https://en.wikipedia.org/wiki?curid=1943" title="Australian Democrats">
Australian Democrats

The Australian Democrats is a centrist political party in Australia. Founded in 1977 from a merger of the Australia Party and the New Liberal Movement, both of which were descended from Liberal Party splinter group, it was Australia's largest minor party from its formation in 1977 through to 2004 and frequently held the balance of power in the Senate during that time.

The party's inaugural leader was Don Chipp, a former Liberal cabinet minister, who famously promised to "keep the bastards honest". At the 1977 federal election, the Democrats polled 11.1 percent of the Senate vote and secured two seats. The party would retain a presence in the Senate for the next 30 years, at its peak (between 1999 and 2002) holding nine out of 76 seats, though never securing a seat in the lower house. The party's share of the vote collapsed at the 2004 election and was further diminished in 2007 with the last senators leaving office in 2008.

Due to the party's numbers in the Senate, both Liberal and Labor governments required the assistance of the Democrats to pass contentious legislation, most notably in the case of the Howard Government's goods and services tax (GST). Ideologically, the Democrats were usually regarded as centrists, occupying the political middle ground between the Liberal Party and the Labor Party.

The party was formally deregistered in 2016 for not having the required 500 members.

In 2018 the Australian Democrats merged with Country Minded, an Australian political party seeking accountable regional and agricultural representation. 
On 7 April 2019 the merged entity regained registration of the name "Australian Democrats" with the Australian Electoral Commission. The party unsuccessfully contested the lower-house seat of Adelaide and a total of six Senate seats (New South Wales, Victoria and South Australia) at the 2019 federal election.

The party was founded on principles of honesty, tolerance, compassion and direct democracy through postal ballots of all members, so that "there should be no hierarchical structure ... by which a carefully engineered elite could make decisions for the members." From the outset, members' participation was fiercely protected in national and divisional constitutions prescribing internal elections, regular meeting protocols, annual conferences—and monthly journals for open discussion and balloting. Dispute resolution procedures were established, with final recourse to a party ombudsman and membership ballot.

Policies determined by the unique participatory method promoted environmental awareness and sustainability, opposition to the primacy of economic rationalism (Australian neoliberalism), preventative approaches to human health and welfare, animal rights, rejection of nuclear technology and weapons.

The Australian Democrats were the first representatives of green politics at the federal level in Australia. They played a key role in the "cause célèbre" of the Franklin River Dam.

The party's centrist role made it subject to criticism from both the right and left of the political spectrum. In particular, Chipp's former conservative affiliation was frequently recalled by opponents on the left. This problem was to torment later leaders and strategists who, by 1991, were proclaiming "the electoral objective" as a higher priority than the rigorous participatory democracy espoused by the party's founders.

Because of their numbers on the cross benches during the Hawke and Keating governments, the Democrats were sometimes regarded as exercising a balance of power—which attracted electoral support from a significant sector of the electorate which had been alienated by both Labor and Coalition policies and practices.

Over three decades, the Australian Democrats achieved representation in the legislatures of the ACT, South Australia, New South Wales, Western Australia and Tasmania as well as Senate seats in all six states. However, at the 2004 and 2007 federal elections, all seven of its Senate seats were lost. The last remaining State parliamentarian, David Winderlich, left the party and was defeated as an independent in 2010.

The Australian Democrats were formed in May 1977 from an amalgamation of the Australia Party and the New Liberal Movement.

The two groups found a common basis for a new political movement in the widespread discontent with the two major parties. In the former Liberal Government Minister, Don Chipp, the two groups found their leader.

The first Australian Democrat to sit in the federal parliamentarian was Senator Janine Haines who in 1977 was nominated by the South Australian Parliament to fill the casual vacancy caused by the resignation of Liberal Senator Steele Hall.

The party's broad aim was to achieve a balance of power in one or more parliaments and to exercise it responsibly in line with policies determined by membership.

In 1977, the Australian Democrats secured two seats in the Senate with the election of Colin Mason (NSW) and Don Chipp (VIC). In 1980, this increased to five seats with the election of Michael Macklin (QLD) and John Siddons (VIC) and the re-election of Janine Haines (SA). Thereafter they frequently held enough seats to give them the balance of power in the upper chamber.

At a Melbourne media conference on 19 September 1980, in the midst of the 1980 election campaign, Chipp described his party's aim as to "keep the bastards honest"—the "bastards" being the major parties and/or politicians in general. This became a long-lived slogan for the Democrats.

In South Australia, the New Liberal Movement dissolved and merged with the Democrats, making its sole parliamentary representative, Robin Millhouse, the Democrats' first member of the South Australian parliament. Millhouse held his seat (Mitcham) at the 1977 and 1979 state elections. In 1982, Millhouse resigned to take up a senior judicial apppointment, and Heather Southcott won the by-election for the Democrats, but lost the seat to the Liberals later that year at the 1982 state election. Mitcham was the only single-member lower-house seat anywhere in Australia to be won by the Democrats.

Don Chipp resigned from the Senate on 18 August 1986, being succeeded as party leader by Janine Haines and replaced as a senator for Victoria by Janet Powell.

At the 1987 election following a double dissolution, the reduced quota of 7.7% necessary to win a seat assisted the election of three new senators. 6-year terms were won by Paul McLean (NSW) and incumbents Janine Haines (South Australia) and Janet Powell (Victoria). In South Australia, a second senator, John Coulter, was elected for a 3-year term, as were incumbent Michael Macklin (Queensland) and Jean Jenkins (Western Australia).
1990 saw the voluntary departure from the Senate of Janine Haines (a step with which not all Democrats agreed) and the failure of her strategic goal of winning the House of Representatives seat of Kingston.

The casual vacancy was filled by Meg Lees several months before the election of Cheryl Kernot in place of retired deputy leader Michael Macklin. The ambitious Kernot immediately contested the party's national parliamentary deputy leadership. Being unemployed at the time, she requested and obtained party funds to pay for her travel to address members in all seven divisions. In the event, Victorian Janet Powell was elected as leader and John Coulter was chosen as deputy leader.

Despite the loss of Haines and the WA Senate seat (through an inconsistent national preference agreement with the ALP), the 1990 federal election heralded something of a rebirth for the party, with a dramatic rise in primary vote. This was at the same time as an economic recession was building, and events such as the Gulf War in Kuwait were beginning to shepherd issues of globalisation and transnational trade on to national government agendas.
The Australian Democrats had a long-standing policy to oppose war and so opposed Australia's support of, and participation in, the Gulf War. Whereas the House of Representatives was able to avoid any debate about the war and Australia's participation, the Democrats took full advantage of the opportunity to move for a debate in the Senate.

Because of the party's pacifist-based opposition to the Gulf War, there was mass-media antipathy and negative publicity which some construed as poor media performance by Janet Powell, the party's standing having stalled at about 10%. Before 12 months of her leadership had passed, the South Australian and Queensland divisions were circulating the party's first-ever petition to criticise and oust the parliamentary leader. The explicit grounds related to Powell's alleged responsibility for poor AD ratings in Gallup and other media surveys of potential voting support. When this charge was deemed insufficient, interested party officers and senators reinforced it with negative media 'leaks' concerning her openly established relationship with Sid Spindler and exposure of administrative failings resulting in excessive overtime to a staff member. With National Executive blessing, the party room pre-empted the ballot by replacing the leader with deputy John Coulter. In the process, severe internal divisions were generated. One major collateral casualty was the party whip Paul McLean who resigned and quit the Senate in disgust at what he perceived as in-fighting between close friends. The casual NSW vacancy created by his resignation was filled by Karin Sowada. Powell duly left the party, along with many leading figures of the Victorian branch of the party, and unsuccessfully stood as an Independent candidate when her term expired. In later years, she campaigned for the Australian Greens.

The party's parliamentary influence was weakened in 1996 after the Howard Government was elected, and a Labor senator, Mal Colston, resigned from the Labor Party. Since the Democrats now shared the parliamentary balance of power with two Independent senators, the Coalition government was able on occasion to pass legislation by negotiating with Colston and Brian Harradine.

In October 1997, party leader Cheryl Kernot resigned, announcing that she would be joining the Australian Labor Party. (Five years later it was revealed that she had been in a sexual relationship with Labor deputy leader Gareth Evans). Kernot resigned from the Senate and was replaced by Andrew Bartlett, while deputy Meg Lees became the new party leader.

Under Lees' leadership, in the 1998 federal election, the Democrats' candidate John Schumann came within 2 per cent of taking Liberal Foreign Minister Alexander Downer's seat of Mayo in the Adelaide Hills under Australia's preferential voting system. The party's representation increased to nine senators, and they regained the balance of power, holding it until the Coalition gained a Senate majority at the 2004 election.

Internal conflict and leadership tensions from 2000 to 2002, blamed on the party's support for the Government's Goods and Services Tax (GST), was damaging to the Democrats. Opposed by the Labor Party, the Australian Greens and independent Senator Harradine, the GST required Democrat support to pass. In an election fought on tax, the Democrats publicly stated that they liked neither the Liberal (GST) tax package nor the Labor package, but pledged to work with whichever party was elected to make their tax package better. They campaigned with the slogan "No GST on food".

In 1999, after negotiations with Prime Minister Howard, Meg Lees, Andrew Murray and the party room senators agreed to support the A New Tax System (ANTS) legislation with exemptions from GST for most food and some medicines, as well as many environmental and social concessions. Five Australian Democrats senators voted in favour. However, two dissident senators on the party's left Natasha Stott Despoja and Andrew Bartlett voted against the GST.

In 2001, a leadership spill saw Meg Lees replaced as leader by Natasha Stott Despoja after a very public and bitter leadership battle. Despite criticism of Stott Despoja's youth and lack of experience, the 2001 election saw the Democrats receive similar media coverage to the previous election. Despite the internal divisions, the Australian Democrats' election result in 2001 was quite good. However, it was not enough to prevent the loss of Vicki Bourne's Senate seat in NSW.

The 2002 South Australian election was the last time an Australian Democrat would be elected to an Australian parliament. Sandra Kanck was re-elected to a second eight-year term from an upper house primary vote of 7.3 percent.

Resulting tensions between Stott Despoja and Lees led to Meg Lees leaving the party in 2002, becoming an independent and forming the Australian Progressive Alliance. Stott Despoja stood down from the leadership following a loss of confidence by her party room colleagues. It led to a protracted leadership battle in 2002, which eventually led to the election of Senator Andrew Bartlett as leader. While the public fighting stopped, the public support for the party remained at record lows.

On 6 December 2003, Bartlett stepped aside temporarily as leader of the party, after an incident in which he swore at Liberal Senator Jeannie Ferris on the floor of Parliament while intoxicated. The party issued a statement stating that deputy leader Lyn Allison would serve as the acting leader of the party. Bartlett apologised to the Democrats, Jeannie Ferris and the Australian public for his behaviour and assured all concerned that it would never happen again. On 29 January 2004, after seeking medical treatment, Bartlett returned to the Australian Democrats leadership, vowing to abstain from alcohol.

Following internal conflict over GST (1998–2001) and resultant leadership changes, a dramatic decline occurred in the Democrats' membership and voting support in all states. Simultaneously, an increase was recorded in support for the Australian Greens who, by 2004, were supplanting the Democrats as a substantial third party. The trend was noted that year by political scientists Dean Jaensch et al.

Support for the Australian Democrats fell significantly at the 2004 federal election in which they achieved only 2.4 per cent of the national vote. Nowhere was this more noticeable than in their key support base of suburban Adelaide in South Australia, where they received between 1 and 4 percent of the lower house vote; by comparison, they tallied between 7 and 31 per cent of the vote in 2001. Three incumbent senators were defeated—Aden Ridgeway (NSW), Brian Greig (WA) and John Cherry (Qld). Following the loss, the customary post-election leadership ballot installed Allison as leader, with Bartlett as her deputy. From 1 July 2005 the Australian Democrats lost official parliamentary party status, being represented by only four senators while the governing Liberal-National Coalition gained a majority and potential control of the Senate—the first time this advantage had been enjoyed by any government since 1980.

On 28 August 2006, the founder of the Australian Democrats, Don Chipp, died. Former prime minister Bob Hawke said: "... there is a coincidental timing almost between the passing of Don Chipp and what I think is the death throes of the Democrats." In November 2006, the Australian Democrats fared very poorly in the Victorian state election, receiving a Legislative Council vote tally of only 0.83%, less than half of the party's result in 2002 (1.79 per cent).

The Tasmanian division of the party was deregistered for having insufficient members in January 2006. On 18 March 2006, at the 2006 South Australian election, the Australian Democrats were reduced to 1.7 per cent of the Legislative Council (upper house) vote. Their sole councillor up for re-election, Kate Reynolds, was defeated. In July 2006, Richard Pascoe, national and South Australian party president, resigned, citing slumping opinion polls and the poor result in the 2006 South Australian election as well as South Australian parliamentary leader Sandra Kanck's comments regarding the drug MDMA which he saw as damaging to the party.

In the New South Wales state election of March 2007, the Australian Democrats lost their last remaining NSW Upper House representative, Arthur Chesterfield-Evans. The party fared poorly, gaining only 1.8 per cent of the Legislative Council vote. On 13 September 2007, the ACT Democrats (Australian Capital Territory Division of the party) was deregistered by the ACT Electoral Commissioner, being unable to demonstrate a minimum membership of 100 electors.

The Democrats had no success at the 2007 federal election. Two incumbent senators, Lyn Allison (Victoria) and Andrew Bartlett (Queensland), were defeated, their seats both reverting to major parties. Their two remaining colleagues, Andrew Murray (WA) and Natasha Stott Despoja (SA), retired. All four senators' terms expired on 30 June 2008—leaving the Australian Democrats with no federal representation for the first time since its founding in 1977. Later, in 2009, Jaensch suggested it was possible the Democrats could make a political comeback at the 2010 South Australian election, but this did not occur.

The last of the party's state upper-house members, David Winderlich, resigned from the party in October 2009 and was defeated as an independent at the 2010 election.

On 16 April 2015, the Australian Electoral Commission deregistered the Australian Democrats as a political party for failure to demonstrate the requisite 500 members to maintain registration. However, the party did run candidates and remain registered for a period of time thereafter in the New South Wales Democrats and Queensland Democrat divisions. 

In November 2018 there was a report that CountryMinded, a de-registered microparty, would merge with the Australian Democrats in a new bid to seek membership growth, electoral re-registration and financial support. In February 2019, application for registration was submitted to the AEC and was upheld on 7 April 2019, despite an objection from the party's incorporated former Queensland division.









</doc>
<doc id="1944" url="https://en.wikipedia.org/wiki?curid=1944" title="Australian Capital Territory">
Australian Capital Territory

The Australian Capital Territory, formerly known as the Federal Capital Territory until 1938 and commonly referred to as the ACT, is a federal territory of Australia containing the Australian capital city of Canberra and some surrounding townships. It is located in the south-east of the country and is an enclave within the state of New South Wales. Founded after federation as the seat of government for the new nation, all important institutions of the Australian federal government are centred in the Territory.

On 1 January 1901, federation of the colonies of Australia was achieved. Section 125 of the new Australian Constitution provided that land, situated in New South Wales and at least from Sydney, would be ceded to the new federal government. Following discussion and exploration of various areas within New South Wales, the "Seat of Government Act 1908" was passed in 1908 which specified a capital in the Yass-Canberra region. The territory was transferred to the Commonwealth by New South Wales in 1911, two years prior to the capital city being founded and formally named as Canberra in 1913.

While the overwhelming majority of the population reside in the city of Canberra in the ACT's north-east, the Territory also includes some surrounding townships such as Williamsdale, Naas, Uriarra, Tharwa and Hall. The ACT also includes the Namadgi National Park which comprises the majority of land area of the Territory. Despite a common misconception, the Jervis Bay Territory is not part of the ACT although the laws of the Australian Capital Territory apply as if Jervis Bay did form part of the ACT. The Territory has a relatively dry, contintental climate experiencing warm to hot summers and cool to cold winters.

The Australian Capital Territory is home to many important institutions of the federal government, national monuments and museums. This includes the Parliament of Australia, the High Court of Australia, the Australian Defence Force Academy and the Australian War Memorial. It also hosts the majority of foreign embassies in Australia as well as regional headquarters of many international organisations, not-for-profit groups, lobbying groups and professional associations. Several major universities also have campuses in the ACT including the Australian National University, the University of Canberra, the University of New South Wales, Charles Sturt University and the Australian Catholic University.

A locally elected legislative assembly has governed the Territory since 1988. However, the Commonwealth maintains authority over the Territory and may overturn local laws. It still maintains control over the area known as the Parliamentary Triangle through the National Capital Authority. Residents of the Territory elect three members to the House of Representatives and two Senators to the Australian Senate.

With 419,200 residents, the Australian Capital Territory is second smallest mainland state or territory by population. At the , the median weekly income for people in the Territory aged over 15 was $998 and higher than the national average of $662. The average level of degree qualification in the ACT is also higher than the national average. Within the ACT, 37.1% of the population hold a bachelor's degree level or above education compared to the national figure of 20%.

Indigenous Australian peoples have long inhabited the area. Evidence indicates habitation dating back at least 21,000 years. It is possible that the area was inhabited for considerably longer, with evidence of an Aboriginal presence in south-western New South Wales dating back around 40,000–62,000 years. The principal group occupying the region were the Ngunnawal people.

Following European settlement, the growth of the new colony of New South Wales led to an increasing demand for arable land. Governor Lachlan Macquarie supported expeditions to open up new lands to the south of Sydney.

The 1820s saw further exploration in the Canberra area associated with the construction of a road from Sydney to the Goulburn plains. While working on the project, Charles Throsby learned of a nearby lake and river from the local Indigenous peoples and he accordingly sent Wild to lead a small party to investigate the site. The search was unsuccessful, but they did discover the Yass River and it is surmised that they would have set foot on part of the future territory.

A second expedition was mounted shortly thereafter and they became the first Europeans to camp at the Molonglo (Ngambri) and Queanbeyan (Jullergung) Rivers. However, they failed to find the Murrumbidgee River. The issue of the Murrumbidgee was solved in 1821 when Charles Throsby mounted a third expedition and successfully reached the watercourse, on the way providing the first detailed account of the land where Canberra now resides.

The last expedition in the region prior to settlement was undertaken by Allan Cunningham in 1824. He reported that the region was suitable for grazing and the settlement of the Limestone Plains followed immediately thereafter.

The first land grant in the region was made to Joshua John Moore in 1823 and European settlement in the area began in 1824 with the construction of a homestead by his stockmen on what is now the Acton Peninsula. Moore formally purchased the site in 1826 and named the property "Canberry" or "Canberra".

A significant influx of population and economic activity occurred around the 1850s goldrushes. The goldrushes prompted the establishment of communication between Sydney and the region by way of the Cobb & Co coaches, which transported mail and passengers. The first post offices opened in Ginninderra in 1859 and at Lanyon in 1860.

During colonial times, the European communities of Ginninderra, Molonglo and Tuggeranong settled and farmed the surrounding land. The region was also called the Queanbeyan-Yass district, after the two largest towns in the area. The villages of Ginninderra and Tharwa developed to service the local agrarian communities.

During the first 20 years of settlement, there was only limited contact between the settlers and Aboriginal people. Over the succeeding years, the Ngunnawal and other local indigenous people effectively ceased to exist as cohesive and independent communities adhering to their traditional ways of life. Those who had not succumbed to disease and other predations either dispersed to the local settlements or were relocated to more distant Aboriginal reserves set up by the New South Wales government in the latter part of the 19th century.

In 1898, a referendum on a proposed Constitution was held in four of the colonies – New South Wales, Victoria, South Australia and Tasmania. Although the referendum achieved a majority in all four colonies, the New South Wales referendum failed to gain the minimum number of votes needed for the bill to pass. Following this result, a meeting of the four Premiers in 1898 heard from George Reid, the Premier of New South Wales, who argued that locating the future capital in New South Wales would be sufficient to ensure the passage of the Bill. The 1899 referendum on this revised bill was successful and passed with sufficient numbers. Section 125 of the Australian Constitution thus provided that, following Federation in 1901, land would be ceded freely to the new Federal Government.

This, however, left open the question of where to locate the capital. In 1906 and after significant deliberations, New South Wales agreed to cede sufficient land on the condition that it was in the Yass-Canberra region, this site being closer to Sydney. Initially, Dalgety, New South Wales remained at the forefront, but Yass-Canberra prevailed after voting by federal representatives. The "Seat of Government Act 1908" was passed in 1908, which repealed the 1904 Act and specified a capital in the Yass-Canberra region. Government surveyor Charles Scrivener was deployed to the region in the same year in order to map out a specific site and, after an extensive search, settled upon the present location.

The territory was transferred to the Commonwealth by New South Wales in 1911, two years prior to the naming of Canberra as the national capital in 1913.

In 1911, an international competition to design the future capital was held, which was won by the Chicago architect Walter Burley Griffin in 1912. The official naming of Canberra occurred on 12 March 1913 and construction began immediately.

After Griffin's departure following difficulty in implementing his project, the Federal Capital Advisory Committee was established in 1920 to advise the government of the construction efforts. The Committee had limited success meeting its goals. However, the chairman, John Sulman, was instrumental in applying the ideas of the garden city movement to Griffin's plan. The Committee was replaced in 1925 by the Federal Capital Commission.

In 1930, the ACT Advisory Council was established to advise the Minister for Territories on the community's concerns. In 1934, Supreme Court of the Australian Capital Territory was established.

From 1938 to 1957, the National Capital Planning and Development Committee continued to plan the further expansion of Canberra. However, the National Capital Planning and Development Committee did not have executive power, and decisions were made on the development of Canberra without the Committee's consultation. During this time, Prime Minister Robert Menzies regarded the state of the national capital as an embarrassment.

After World War II, there was a shortage of housing and office space in Canberra. A Senate Select Committee hearing was held in 1954 to address its development requirements. This Committee recommended the creation of a single planning body with executive power. Consequently, the National Capital Planning and Development Committee was replaced by the National Capital Development Commission in 1957. The National Capital Development Commission ended four decades of disputes over the shape and design of Lake Burley Griffin and construction was completed in 1964 after four years of work. The completion of the centrepiece of Griffin's design finally the laid the platform for the development of Griffin's Parliamentary Triangle.

In 1988, the new Minister for the Australian Capital Territory Gary Punch received a report recommending the abolition of the National Capital Development Commission and the formation of a locally elected government. Punch recommended that the Hawke government accept the report's recommendations and subsequently Clyde Holding introduced legislation to grant self-government to the Territory in October 1988.

The enactment on 6 December 1988 of the "Australian Capital Territory (Self-Government) Act 1988" established the framework for self-government. The first election for the 17-member Australian Capital Territory Legislative Assembly was held on 4 March 1989.

The initial years of self-government were difficult and unstable. A majority of ACT residents had opposed self-government and had it imposed upon them by the federal parliament. At the first election, 4 of the 17 seats were won by anti-self-government single-issue parties due to a protest vote by disgruntled territorians and a total of 8 were won by minor parties and independents.

In 1992, Labor won eight seats and the minor parties and independents won only three. Stability increased, and in 1995, Kate Carnell became the first elected Liberal chief minister. In 1998, Carnell became the first chief minister to be re-elected.

The Australian Capital Territory is the smallest mainland territory (aside from the Jervis Bay Territory) and covers a total land area of .

It is bounded by the Goulburn-Cooma railway line in the east, the watershed of Naas Creek in the south, the watershed of the Cotter River in the west and the watershed of the Molonglo River in the north-east. These boundaries were set to give the ACT an adequate water supply. The ACT extends about North-South between 35.124°S and 35.921°S, and West-East between 148.763°E and 149.399°E. The city area of Canberra occupies the north-eastern corner of this area.

Apart from the city of Canberra, the Australian Capital Territory also contains agricultural land (sheep, dairy cattle, vineyards and small amounts of crops) and a large area of national park (Namadgi National Park), much of it mountainous and forested. Small townships and communities located within the ACT include Williamsdale, Naas, Uriarra, Tharwa and Hall.

Tidbinbilla is a locality to the south-west of Canberra that features the Tidbinbilla Nature Reserve and the Canberra Deep Space Communication Complex, operated by the United States' National Aeronautics and Space Administration (NASA) as part of its Deep Space Network.

There are a large range of mountains, rivers and creeks throughout the Territory and are largely contained within the Namadgi National Park. These include the Naas and Murrumbidgee Rivers.

The Territory has a relatively dry, contintental climate experiencing warm to hot summers and cool to cold winters. Under Köppen-Geiger classification, the Territory has an oceanic climate ("Cfb").

January is the hottest month with an average high of . July is the coldest month when the average high drops to . The highest maximum temperature recorded in the Territory was on 1 February 1968. The lowest minimum temperature was on 11 July 1971.

Rainfall varies significantly across the Territory. Much higher rainfall occurs in the mountains to the west of Canberra compared to the east. The mountains act as a barrier during winter with the city receiving less rainfall. Average annual rainfall in the Territory is and there is an average of 108 rain days annually. The wettest month is October with an average rainfall of and the driest month is June with an average of .

Frost is common in the winter months. Snow is rare in Canberra's city centre, but the surrounding areas get annual snowfall through winter and often the snow-capped mountains can be seen from the city. The last significant snowfall in the city centre was in 1968.

The environments range from alpine area on the higher mountains, to sclerophyll forest and to woodland. Much of the ACT has been cleared for grazing and is also burnt off by bushfires several times per century. The kinds of plants can be grouped into vascular plants, that include gymnosperms, flowering plants, and ferns, as well as bryophytes, lichens, fungi and freshwater algae. Four flowering plants are endemic to the ACT. Several lichens are unique to the Territory. Most plants in the ACT are characteristic of the Flora of Australia and include well known plants such as Grevillea, Eucalyptus trees and kangaroo grass.

The native forest in the Canberra region was almost wholly eucalypt species and provided a resource for fuel and domestic purposes. By the early 1960s, logging had depleted the eucalypt, and concern about water quality led to the forests being closed. Interest in forestry began in 1915 with trials of a number of species including "Pinus radiata" on the slopes of Mount Stromlo. Since then, plantations have been expanded, with the benefit of reducing erosion in the Cotter catchment, and the forests are also popular recreation areas.

The fauna of the Territory includes representatives from most major Australian animal groups. This includes kangaroos, wallabies, koalas, platypus, echidna, emu, kookaburras and dragon lizards.

Notable geological formations in the Australian Capital Territory include the "Canberra Formation", the "Pittman Formation", "Black Mountain Sandstone" and "State Circle Shale".

In the 1840s fossils of brachiopods and trilobites from the Silurian period were discovered at Woolshed Creek near Duntroon. At the time, these were the oldest fossils discovered in Australia, though this record has now been far surpassed. Other specific geological places of interest include the State Circle cutting and the Deakin anticline.

The oldest rocks in the ACT date from the Ordovician around 480 million years ago. During this period the region along with most of Eastern Australia was part of the ocean floor; formations from this period include the "Black Mountain Sandstone" formation and the "Pittman Formation" consisting largely of quartz-rich sandstone, siltstone and shale. These formations became exposed when the ocean floor was raised by a major volcanic activity in the Devonian forming much of the east coast of Australia.

The ACT has internal self-government, but Australia's Constitution does not afford a territory legislature the high degree of independence provided to that of a state. Instead, each territory is governed under a Commonwealth statutefor the ACT, the Australian Capital Territory (Self-Government) Act 1988. The Chief Minister performs many of the roles that a state governor normally holds in the context of a state; however, the Speaker of the Legislative Assembly gazettes the laws and summons meetings of the Assembly.

Laws are made in a 25-member Legislative Assembly that combines both state and local government functions (prior to 2016, the Assembly was made up of 17 members).

Members of the Legislative Assembly are elected via the Hare–Clark system.

The executive of the Australian Capital Territory, also known as the ACT Government, consists of the Chief Minister and such other Ministers as are appointed by the Chief Minister. The ACT Chief Minister (currently Andrew Barr, Labor) is elected by members of the Legislative Assembly. The Chief Minister represents the ACT Government as a member of the Council of Australian Governments.

Unlike other self-governing Australian territories (for example, the Northern Territory), the ACT does not have an Administrator. The Crown is represented in government of the ACT by the Australian Governor-General. Until 4 December 2011, the decisions of the assembly could be overruled by the Governor-General (effectively by the national government) under section 35 of the Australian Capital Territory (Self-Government) Act 1988, although the federal parliament voted in 2011 to abolish this veto power, instead requiring a majority of both houses of the federal parliament to override an enactment of the ACT.

The court system of the Territory consists of the Supreme Court of the Australian Capital Territory, the Magistrates Court of the Australian Capital Territory and the ACT Civil and Administrative Tribunal. It is unique in that the Territory does not have an intermediary court like other mainland states and territories; there is only the superior court and a court of summary jurisdiction. the Chief Justice is Helen Murrell and the current Chief Magistrate is Lorraine Walker.

ACT Policing is responsible for providing policing services to the ACT. Canberra had the lowest rate of crime of any capital city in Australia .

In Australia's Federal Parliament, the ACT is represented by four federal members: two members of the House of Representatives represent the Division of Fenner and the Division of Canberra and it is one of only two territories to be represented in the Senate, with two Senators (the other being the Northern Territory). The Member for Fenner and the ACT Senators also represent the constituents of the Jervis Bay Territory. An additional electorate will be added at the 2019 election following a redistribution by the Australian Electoral Commission.

In 1915, the "Jervis Bay Territory Acceptance Act 1915" created the Jervis Bay Territory as an annexe to the Federal Capital Territory. While the Act's use of the language of "annexed" is sometimes interpreted as implying that the Jervis Bay Territory was to form part of the Federal Capital Territory, the accepted legal position is that it has been a legally distinct territory from its creation despite being subject to ACT law and, prior to ACT self-government in 1988, being administratively treated as part of the ACT.

In 1988, when the ACT gained self-government, Jervis Bay was formally pronounced as a separate territory administered by the Commonwealth known as the Jervis Bay Territory. However, the laws of the ACT continue to apply to the Jervis Bay Territory. Magistrates from the ACT regularly travel to the Jervis Bay Territory to conduct court.

Another occasional misconception is that the ACT retains a small area of territory on the coast on the Beecroft Peninsula, consisting of a strip of coastline around the northern headland of Jervis Bay. While the land is owned by the Commonwealth Government, that area itself is still considered to be under the jurisdiction of New South Wales government, not a separate territory nor a part of the ACT.

The Australian Bureau of Statistics estimates that the population of the Territory was 419,200 on 31 March 2019. The population is projected to reach to approximately 700,000 by 2058.

The overwhelming majority of the population reside in the city of Canberra.

At the , the median weekly income for people in the Territory aged over 15 was $998 while the national average was $662.

The average level of degree qualification in the ACT is higher than the national average. Within the ACT, 37.1% of the population hold a bachelor's degree level or above education compared to the national figure of 20%.

The Australian Capital Territory consists of the city of Canberra and some surrounding townships including Williamsdale, Naas, Uriarra, Tharwa and Hall.

The urban areas of Canberra are organised into a hierarchy of districts, town centres, group centres, local suburbs as well as other industrial areas and villages. There are seven districts (with an eighth currently under construction), each of which is divided into smaller suburbs, and most of which have a town centre which is the focus of commercial and social activities. The districts were settled in the following chronological order:

The North and South Canberra districts are substantially based on Walter Burley Griffin's designs. In 1967, the then National Capital Development Commission adopted the "Y Plan" which laid out future urban development in Canberra around a series of central shopping and commercial area known as the 'town centres' linked by freeways, the layout of which roughly resembled the shape of the letter Y, with Tuggeranong at the base of the Y and Belconnen and Gungahlin located at the ends of the arms of the Y.

At the 2016 census, the most commonly nominated ancestries were: 
The 2016 census showed that 32% of the ACT's inhabitants were born overseas. Of inhabitants born outside of Australia, the most prevalent countries of birth were England, China, India, New Zealand and the Philippines.

1.6% of the population, or 6,476 people, identified as Indigenous Australians (Aboriginal Australians and Torres Strait Islanders) in 2016.

At the 2016 census, 72.7 of people spoke only English at home. The other languages most commonly spoken at home were Mandarin (3.1%), Vietnamese (1.1%), Cantonese (1%), Hindi (0.9%) and Spanish (0.8%).

The most common responses in the for religion in the Territory were No Religion (36.2%), Catholic (22.3%), Anglican (10.8%), Not stated (9.2%) and Hinduism (2.6%). In Australian Capital Territory, Christianity was the largest religious group reported overall (49.9%).

Almost all educational institutions in the Australian Capital Territory are located within Canberra. The ACT public education system schooling is normally split up into Pre-School, Primary School (K-6), High School (7–10) and College (11–12) followed by studies at university or CIT (Canberra Institute of Technology). Many private high schools include years 11 and 12 and are referred to as colleges. Children are required to attend school until they turn 17 under the ACT Government's "Learn or Earn" policy.

In February 2004 there were 140 public and non-governmental schools in ACT; 96 were operated by the Government and 44 are non-Government. In 2005, there were 60,275 students in the ACT school system. 59.3% of the students were enrolled in government schools with the remaining 40.7% in non-government schools. There were 30,995 students in primary school, 19,211 in high school, 9,429 in college and a further 340 in special schools.

As of May 2004, 30% of people in the ACT aged 15–64 had a level of educational attainment equal to at least a bachelor's degree, significantly higher than the national average of 19%. The two main tertiary institutions are the Australian National University (ANU) in Acton and the University of Canberra (UC) in Bruce. There are also two religious university campuses in Canberra: Signadou is a campus of the Australian Catholic University and St Mark's Theological College is a campus of Charles Sturt University. Tertiary level vocational education is also available through the multi-campus Canberra Institute of Technology.

The Australian Defence Force Academy (ADFA) and the Royal Military College, Duntroon (RMC) are in the suburb of Campbell in Canberra's inner northeast. ADFA teaches military undergraduates and postgraduates and is officially a campus of the University of New South Wales while Duntroon provides Australian Army Officer training.

The Academy of Interactive Entertainment (AIE) offers courses in computer game development and 3D animation.

The Australian Capital Territory is home to a number of major professional sports league franchise teams including the Canberra Raiders (rugby league), the Brumbies (rugby union), and the Canberra Capitals (basketball).

The Greater Western Sydney Giants (Australian rules football) play three regular season matches a year and one pre-season match in Canberra at Manuka Oval.

The Prime Minister's XI (cricket), started by Robert Menzies in the 1950s and revived by Bob Hawke in 1984, has been played every year at Manuka Oval against an overseas touring team.

The Territory is home to many national monuments and institutions such as the Australian War Memorial, the National Gallery of Australia, the National Portrait Gallery, the National Library, the National Archives, the Australian Academy of Science, the National Film and Sound Archive and the National Museum. Many Commonwealth government buildings in Canberra are open to the public, including Parliament House, the High Court and the Royal Australian Mint.

Lake Burley Griffin is the site of the Captain James Cook Memorial and the National Carillon. Other sites of interest include the Telstra Tower, the Australian National Botanic Gardens, the National Zoo and Aquarium, the National Dinosaur Museum and Questacon – the National Science and Technology Centre.

The Canberra Museum and Gallery in the city is a repository of local history and art, housing a permanent collection and visiting exhibitions. Several historic homes are open to the public: Lanyon and Tuggeranong Homesteads in the Tuggeranong Valley, Mugga-Mugga in Symonston, and Blundells' Cottage in Parkes all display the lifestyle of the early European settlers. Calthorpes' House in Red Hill is a well-preserved example of a 1920s house from Canberra's very early days.

Canberra has many venues for live music and theatre: the Canberra Theatre and Playhouse which hosts many major concerts and productions; and Llewellyn Hall (within the ANU School of Music), a world-class concert hall are two of the most notable. The Albert Hall was Canberra's first performing arts venue, opened in 1928. It was the original performance venue for theatre groups such as the Canberra Repertory Society.

There are numerous bars and nightclubs which also offer live entertainment, particularly concentrated in the areas of Dickson, Kingston and the city. Most town centres have facilities for a community theatre and a cinema, and they all have a library. Popular cultural events include the National Folk Festival, the Royal Canberra Show, the Summernats car festival, Enlighten festival and the National Multicultural Festival in February.

Canberra and the Territory have a daily newspaper, "The Canberra Times", which was established in 1926. There are also several free weekly publications, including news magazines "CityNews" and "Canberra Weekly."

There are a number of AM and FM stations broadcasting throughout the ACT (AM/FM Listing). The main commercial operators are the Capital Radio Network (2CA and 2CC), and Austereo/ARN (104.7 and Mix 106.3). There are also several community operated stations as well as the local and national stations of the Australian Broadcasting Corporation.

A DAB+ digital radio trial is also in operation, it simulcasts some of the AM/FM stations, and also provides several digital only stations (DAB+ Trial Listing).

Five free-to-air television stations service the Territory:


Each station broadcasts a primary channel and several multichannels.

Pay television services are available from Foxtel (via satellite) and telecommunications company TransACT (via cable).

The Australian Capital Territory has two large public hospitals both located in Canberra: the approximately 600-bed Canberra Hospital in Garran and the 174-bed Calvary Public Hospital in Bruce. Both are teaching institutions. The largest private hospital is the Calvary John James Hospital in Deakin. Calvary Private Hospital in Bruce and Healthscope's National Capital Private Hospital in Garran are also major healthcare providers.

Canberra has 10 aged care facilities. Canberra's hospitals receive emergency cases from throughout southern New South Wales, and ACT Ambulance Service is one of four operational agencies of the ACT Emergency Services Authority. NETS provides a dedicated ambulance service for inter-hospital transport of sick newborns within the ACT and into surrounding New South Wales.

The automobile is by far the dominant form of transport in Canberra and the Territory. The city is laid out so that arterial roads connecting inhabited clusters run through undeveloped areas of open land or forest, which results in a low population density; this also means that idle land is available for the development of future transport corridors if necessary without the need to build tunnels or acquire developed residential land. In contrast, other capital cities in Australia have substantially less green space.

Canberra's districts are generally connected by parkways—limited access dual carriageway roads with speed limits generally set at a maximum of . An example is the Tuggeranong Parkway which links Canberra's CBD and Tuggeranong, and bypasses Weston Creek. In most districts, discrete residential suburbs are bounded by main arterial roads with only a few residential linking in, to deter non-local traffic from cutting through areas of housing.

ACTION, the government-operated bus service, provides public transport throughout Canberra. Qcity Transit provides bus services between Canberra and nearby areas of New South Wales through their Transborder Express brand (Murrumbateman and Yass) and as Qcity Transit (Queanbeyan). A light rail line that opened in April 2019 links the CBD with the northern district of Gungahlin. At the 2016 census, 7.1% of the journeys to work involved public transport while 4.5% were on foot.

There are two local taxi companies. Aerial Capital Group enjoyed monopoly status until the arrival of Cabxpress in 2007. In October 2015, the ACT Government passed legislation to regulate ride sharing, allowing ride share services including Uber to operate legally in Canberra. The ACT Government was the first jurisdiction in Australia to enact legislation to regulate the service.

An interstate NSW TrainLink railway service connects Canberra to Sydney. Canberra's railway station is in the inner south suburb of Kingston. Train services to Melbourne are provided by way of a NSW TrainLink bus service which connects with a rail service between Sydney and Melbourne in Yass, about a one-hour drive from Canberra.

Canberra is about three hours by road from Sydney on the Federal Highway (National Highway 23), which connects with the Hume Highway (National Highway 31) near Goulburn, and seven hours by road from Melbourne on the Barton Highway (National Highway 25), which joins the Hume Highway at Yass. It is a two-hour drive on the Monaro Highway (National Highway 23) to the ski fields of the Snowy Mountains and the Kosciuszko National Park. Batemans Bay, a popular holiday spot on the New South Wales coast, is also two hours away via the Kings Highway.

Canberra Airport provides direct domestic services to Sydney, Melbourne, Brisbane, Adelaide, Gold Coast and Perth, with connections to other domestic centres. There are also direct flights to small regional towns: Dubbo and Newcastle in New South Wales. Regular commercial international flights operate to Singapore and Wellington from the airport four times a week. Canberra Airport is, as of September 2013, designated by the Australian Government Department of Infrastructure and Regional Development as a restricted use designated international airport. Until 2003, the civilian airport shared runways with RAAF Base Fairbairn. In June of that year, the Air Force base was decommissioned and from that time the airport was fully under civilian control.

The government-owned ACTEW Corporation manages the Territory's water and sewerage infrastructure. ActewAGL is a joint venture between ACTEW and AGL, and is the retail provider of Canberra's utility services including water, natural gas, electricity, and also some telecommunications services via a subsidiary TransACT.

Canberra's water is stored in four reservoirs, the Corin, Bendora and Cotter dams on the Cotter River and the Googong Dam on the Queanbeyan River. Although the Googong Dam is located in New South Wales, it is managed by the ACT government. ACTEW Corporation owns Canberra's two wastewater treatment plants, located at Fyshwick and on the lower reaches of the Molonglo River.

Electricity for Canberra mainly comes from the national power grid through substations at Holt and Fyshwick (via Queanbeyan). Power was first supplied from a thermal plant built in 1913, near the Molonglo River, but this was finally closed in 1957. The ACT has four solar farms, which were opened between 2014 and 2017: Royalla (rated output of 20 megawatts, 2014), Mount Majura (2.3 MW, 2016), Mugga Lane (13 MW, 2017) and Williamsdale (11 MW, 2017). In addition numerous houses in Canberra have photovoltaic panels and/or solar hot water systems. In 2015/16, rooftop solar systems supported by the ACT government's feed-in tariff had a capacity of 26.3 megawatts, producing 34,910 MWh. In the same year, retailer-supported schemes had a capacity of 25.2 megawatts and exported 28,815 MWh to the grid (power consumed locally was not recorded).

The ACT has the highest rate with internet access at home (94 per cent of households in 2014–15).

The economic activity of the Australian Capital Territory is heavily concentrated around the city of Canberra.

A stable housing market, steady employment and rapid population growth in the 21st century have led to economic prosperity and, in 2011, CommSec ranked the ACT as the second best performing economic region in the country. This trend continued into 2016, when the territory was ranked the third best performing out of all of Australia's states and territories.

In 2017-18, the ACT had the fastest rate of growth in the nation due to a rapid growth in population, a strongly performing higher education sector as well as a significant housing and infrastructure investment.

Higher education is the Territory's largest export industry. Canberra is home to a significant number of universities and higher education providers. The other major services exports of the ACT in 2017-18 were government services and personal travel. The major goods exports of the Territory in 2017-18 were gold coin, legal tender coin, metal structures and fish, though these represent a small proportion of the economy compared to services exports.

The economy of the ACT is largely dependent on the public sector with 30% of the jobs in the Territory being in the public sector. Decisions by the federal government regarding the public service can have a significant impact on the Territory's economy.

The ACT's gross state product in 2017-18 was $39,792,000,000 and the Territory's economy represents 2.2% of the overall gross domestic product of Australia.



</doc>
<doc id="1946" url="https://en.wikipedia.org/wiki?curid=1946" title="Unit of alcohol">
Unit of alcohol

Units of alcohol are used in the United Kingdom (UK) as a measure to quantify the actual alcoholic content within a given volume of an alcoholic beverage, in order to provide guidance on total alcohol consumption.

A number of other countries (including Australia, Canada, New Zealand, and the US) use the concept of a "standard drink", the definition of which varies from country to country, for the same purpose. "Standard drinks" were referred to in the first UK guidelines (1984) that published "safe limits" for drinking, but these were replaced by references to "alcohol units" in the 1987 guidelines and the latter term has been used in all subsequent UK guidance.

One unit of alcohol (UK) is defined as 10 millilitres (8 grams) of pure alcohol. Typical drinks (i.e., typical quantities or servings of common alcoholic beverages) may contain 1–3 units of alcohol.

Containers of alcoholic beverages sold directly to UK consumers are normally labelled to indicate the number of units of alcohol in a typical serving of the beverage (optional) and in the full container (can or bottle), as well as information about responsible drinking.

As an approximate guideline, a typical healthy adult can metabolise (break down) about one unit of alcohol per hour, although this may vary depending on sex, age, weight, health and many other factors.

The number of UK units of alcohol in a drink can be determined by multiplying the volume of the drink (in millilitres) by its percentage ABV, and dividing by 1000.

For example, one imperial pint (568 ml) of beer at 4% alcohol by volume (ABV) contains:

The formula uses . This results in exactly one unit per percentage point per litre, of any alcoholic beverage.

The formula can be simplified for everyday use by expressing the serving size in centilitres and the alcohol content literally as a percentage:

Thus, a 750 ml bottle of wine at 12% ABV contains 75 cl × 12% = 9 units. Alternatively, the serving size in litres multiplied by the alcohol content as a number, the above example giving 0.75 × 12 = 9 units:

Both pieces of input data are usually mentioned in this form on the bottle, so is easy to retrieve.

UK alcohol companies pledged in March 2011 to implement an innovative health labelling scheme to provide more information about responsible drinking on alcohol labels and containers. This voluntary scheme is the first of its kind in Europe and has been developed in conjunction with the UK Department of Health. The pledge stated:

At the end of 2014, 101 companies had committed to the pledge labelling scheme.

There are five elements included within the overall labelling scheme, the first three being mandatory, and the last two optional:

Drinks companies had pledged to display the three mandatory items on 80% of drinks containers on shelves in the UK off-trade by the end of December 2013. A report published in Nov 2014, confirmed that UK drinks producers had delivered on that pledge with a 79.3% compliance with the pledge elements as measured by products on shelf. Compared with labels from 2008 on a like-for-like basis, information on Unit alcohol content had increased by 46%; 91% of products displayed alcohol and pregnancy warnings (18% in 2008); and 75% showed the Chief Medical Officers’ lower risk daily guidelines (6% in 2008).

It is sometimes misleadingly stated that there is one unit per half-pint of beer, or small glass of wine, or single measure of spirits. However, such statements do not take into account the various strengths and volumes supplied in practice.

For example, the ABV of beer typically varies from 3.5% to 5.5%. A typical "medium" glass of wine with 175 ml at 12% ABV has 2.1 units. And spirits, although typically 35–40% ABV, have single measures of 25 ml or 35 ml (so 1 or 1.4 units) depending on location.

The misleading nature of "one unit per half-pint of beer, or small glass of wine, or single measure of spirits" can lead to people underestimating their alcohol intake.




Most spirits sold in the United Kingdom have 40% ABV or slightly less. In England, a single pub measure (25 ml) of a spirit contains one unit. However, a larger 35 ml measure is increasingly used (and in particular is standard in Northern Ireland ), which contains 1.4 units of alcohol at 40% ABV. Sellers of spirits by the glass must state the capacity of their standard measure in ml.


On average, it takes about one hour for the body to metabolise (break down) one unit of alcohol. However, this will vary with body weight, sex, age, personal metabolic rate, recent food intake, the type and strength of the alcohol, and medications taken. Alcohol may be metabolised more slowly if liver function is impaired.

From 1992 to 1995, the UK government advised that men should drink no more than 21 units per week, and women no more than 14. (The difference between the sexes was due to the typically lower weight and water-to-body-mass ratio of women.) "The Times" reported in October 2007 that these limits had been "plucked out of the air" and had no scientific basis.

This was changed after a government study showed that many people were in effect "saving up" their units and using them at the end of the week, a phenomenon referred to as binge drinking. Since 1995 the advice was that regular consumption of 3–4 units a day for men, or 2–3 units a day for women, would not pose significant health risks, but that consistently drinking four or more units a day (men), or three or more units a day (women), is not advisable.

An international study of about 6,000 men and 11,000 women for a total of 75,000 person-years found that people who reported that they drank more than a threshold value of 2 units of alcohol a day had a higher risk of fractures than non-drinkers. For example, those who drank over 3 units a day had nearly twice the risk of a hip fracture.




</doc>
<doc id="1947" url="https://en.wikipedia.org/wiki?curid=1947" title="Aotus">
Aotus

Aotus (the name is derived from the Ancient Greek words for "earless" in both cases: the monkey is missing external ears, and the pea is missing earlike bracteoles) may refer to:


</doc>
<doc id="1948" url="https://en.wikipedia.org/wiki?curid=1948" title="Ally McBeal">
Ally McBeal

Ally McBeal is an American legal comedy-drama television series, originally aired on Fox from September 8, 1997, to May 20, 2002. Created by David E. Kelley, the series stars Calista Flockhart in the title role as a lawyer working in the fictional Boston law firm Cage and Fish, with other lawyers whose lives and loves were eccentric, humorous, and dramatic. The series received critical acclaim in its early seasons, winning the Golden Globe Award for Best Television Series – Musical or Comedy in 1997 and 1998, and also winning the Emmy Award for Outstanding Comedy Series in 1999.

The series, set in the fictional Boston law firm Cage and Fish, begins with main character Allison Marie "Ally" McBeal joining the firm (co-owned by her law school classmate Richard Fish (Greg Germann) after leaving her previous job due to sexual harassment. On her first day, Ally is horrified to find that she will be working alongside her ex-boyfriend Billy Thomas (Gil Bellows)—whom she has never gotten over. To make things worse, Billy is now married to fellow lawyer Georgia (Courtney Thorne-Smith), who later joins Cage and Fish. The triangle among the three forms the basis for the main plot for the show's first three seasons.

Although ostensibly a legal drama, the main focus of the series was the romantic and personal lives of the main characters, often using legal proceedings as plot devices to contrast or reinforce a character's drama. For example, bitter divorce litigation of a client might provide a backdrop for Ally's decision to break up with a boyfriend. Legal arguments were also frequently used to explore multiple sides of various social issues.

Cage & Fish (which becomes Cage/Fish & McBeal or Cage, Fish, & Associates towards the end of the series), the fictional law firm where most of the characters work, is depicted as a highly sexualized environment symbolized by its unisex restroom. Lawyers and secretaries in the firm routinely date, flirt with, or have a romantic history with each other and frequently run into former or potential romantic interests in the courtroom or on the street outside.

The series had many offbeat and frequently surreal running gags and themes, such as Ally's tendency to immediately fall over whenever she met somebody she found attractive, Richard Fish's wattle fetish and humorous mottos ("Fishisms" & "Bygones"), John's gymnastic dismounts out of the office's unisex bathroom stalls, or the dancing twins (played by Eric & Steve Cohen) at the bar, that ran through the series. The show also used vivid, dramatic fantasy sequences for Ally's and other characters' wishful thinking; of particular note is the early internet sensation the dancing baby.

The series also featured regular visits to a local bar where singer Vonda Shepard regularly performed (though occasionally handing over the microphone to the characters). Star contemporary singers also performed in the bar at the end of the shows, including acts such as Barry White and Anastacia. The series also took place in the same continuity as David E. Kelley's legal drama "The Practice" (which aired on ABC), as the two shows crossed over with one another on occasion, a very rare occurrence for two shows that aired on different networks.

Ultimately, in the last installment of the fifth and final season, "Bygones", Ally decided to resign from Cage & Fish, leave Boston, and return to New York City.

Fox canceled Ally McBeal after five seasons. In addition to being the lowest-rated season of Ally McBeal and the grounds for the show's cancellation, it was also the only season of the show that failed to win any Emmy or Golden Globe awards.

In Australia, "Ally McBeal" was aired by the Seven Network from 1997 to 2002. In 2010, it was aired repeatedly by Network Ten.

Seymore Walsh, a stern judge often exasperated by the eccentricities of the Cage & Fish lawyers and played by actor Albert Hall, was also a recurring character on "The Practice". In addition, Judge Jennifer (Whipper) Cone appears on "The Practice" episode "Line of Duty" (S02 E15), while Judge Roberta Kittelson, a recurring character on "The Practice", has a featured guest role in the "Ally McBeal" episode "Do you Wanna Dance?"

Most of the primary "Practice" cast members guest starred in the "Ally McBeal" episode "The Inmates" (S01 E20), in a storyline that concluded with the "Practice" episode "Axe Murderer" (S02 E26), featuring Calista Flockhart and Gil Bellows reprising their "Ally" characters. What's unusual about this continuing storyline is that "Ally McBeal" and "The Practice" aired on different networks. Bobby Donnell, the main character of "The Practice" played by Dylan McDermott, was featured heavily in both this crossover and another "Ally McBeal" episode, "These are the Days".

Regular "Practice" cast members Lara Flynn Boyle and Michael Badalucco each had a cameo in "Ally McBeal" (Boyle as a woman who trades insults with Ally in the episode "Making Spirits Bright" and Badalucco as one of Ally's dates in the episode "I Know him by Heart") but it is unclear whether they were playing the same characters they play on "The Practice".

Upon premiering in 1997, the show was an instant hit, averaging around 11 million viewers per episode. The show's second season saw an increase in ratings and soon became a top 20 show, averaging around 13 million viewers per episode. The show's ratings began to decline in the third season, but stabilized in the fourth season after Robert Downey Jr. joined the regular cast as Ally's boyfriend Larry Paul, and a fresher aesthetic was created by new art director Matthew DeCoste. However, Downey's character was written out after the end of the season due to the actor's troubles with drug addiction.

The first two seasons, as well as the fourth, remain the most critically acclaimed and saw the most awards success at the Emmys, SAG Awards and the Golden Globes. In 2007, "Ally McBeal" placed #48 on "Entertainment Weekly" 2007 "New TV Classics" list.

"Ally McBeal" received some criticism from TV critics and feminists who found the title character annoying and demeaning to women (specifically regarding professional women) because of her perceived flightiness, lack of demonstrated legal knowledge, short skirts, and emotional instability. Perhaps the most notorious example of the debate sparked by the show was the June 29, 1998, cover story of "Time" magazine, which juxtaposed McBeal with three pioneering feminists (Susan B. Anthony, Betty Friedan, Gloria Steinem) and asked "Is Feminism Dead?" In episode 12 of the second season of the show, Ally talks to her co-worker John Cage about a dream she had, saying "You know, I had a dream that they put my face on the cover of "Time" magazine as 'the face of feminism'."

"Ally McBeal" was a heavily music-oriented show. Vonda Shepard, a virtually unknown musician at the time, was featured continually on the show. Her song "Searchin' My Soul" became the show's theme song. Many of the songs Shepard performed were established hits with lyrics that paralleled the events of the episode, including "Both Sides Now", "Hooked on a Feeling" and "Tell Him". Besides recording background music for the show, Shepard frequently appeared at the ends of episodes as a musician performing at a local piano bar frequented by the main characters. On rare occasions, her character would have conventional dialogue. A portion of "Searchin' My Soul" was played at the beginning of each episode, but remarkably the song was never played in its entirety.

Several of the characters had a musical leitmotif that played when they appeared. John Cage's was "You're the First, the Last, My Everything", Ling Woo's was the Wicked Witch of the West theme from "The Wizard of Oz", and Ally McBeal herself picked "Tell Him", when told by a psychiatrist that she needed a theme.

Due to the popularity of the show and Shepard's music, a soundtrack titled "Songs from Ally McBeal" was released in 1998, as well as a successor soundtrack titled "Heart and Soul: New Songs From Ally McBeal" in 1999. Two compilation albums from the show featuring Shepard were also released in 2000 and 2001. A Christmas album was also released under the title "Ally McBeal: A Very Ally Christmas". The album received positive reviews, and Shephard's version of Kay Starr’s Christmas song "(Everybody's Waitin' For) The Man with the Bag", received considerable airplay during the holiday season.

Other artists featured on the show include Michael Jackson, Barry White, Al Green, Tina Turner, Macy Gray, Gloria Gaynor, Chayanne, Barry Manilow, Anastacia, Elton John, Sting and Mariah Carey. Josh Groban played the role of Malcolm Wyatt in the May 2001 season finale, performing "You're Still You". The series creator, David E. Kelley, was impressed with Groban's performance at The Family Celebration event and based on the audience reaction to Groban's singing, Kelley created a character for him in that finale. The background score for the show was composed by Danny Lux.

Due to music licensing issues, none of the seasons of "Ally McBeal" were available on DVD in the United States (only 6 random episodes could be found on the R1 edition) until 2009, though the show had been available in Italy, Belgium, the Netherlands, Japan, Hong Kong, Portugal, Spain, France, Germany, the United Kingdom, Mexico, Taiwan, Australia, Brazil, and the Czech Republic with all the show's music intact since 2005. In the UK, Ireland, and Spain all seasons are available in a complete box set.

20th Century Fox released the complete first season on DVD in Region 1 on October 6, 2009. They also released a special complete series edition on the same day. Season 1 does not contain any special features, but the complete series set contains several bonus features, including featurettes, an all-new retrospective, the episode of "The Practice" in which Calista Flockhart guest starred, and a bonus disc entitled "The Best of Ally McBeal Soundtrack." In addition, both releases contain all of the original music. Season 2 was released on April 6, 2010. Seasons 3, 4, and 5 were all released on October 5, 2010.

In 1999, at the height of the show's popularity, a half-hour version entitled "Ally" began airing in parallel with the main program. This version, designed in a sitcom format, used re-edited scenes from the main program, along with previously unseen footage. The intention was to further develop the plots in the comedy-drama in a sitcom style. It also focused only on Ally's personal life, cutting all the courtroom plots. The repackaged show was cancelled partway through its initial run. While 13 episodes of "Ally" were produced, only ten aired.

McBeal and 1990s young affluent professional women were parodied in the song "Ally McBeal" (tune of "Like a Rolling Stone" by Bob Dylan) by a cappella group Da Vinci's Notebook on their album "The Life and Times of Mike Fanning", released in 2000.

In episode 2, season 3 of the British comedy "The Adam and Joe Show", the show was parodied as "Ally McSqeal" using soft toys.

Episode 2, season 2 of the show "Futurama", "When Aliens Attack", centers on an invasion of Earth by the Omicronians precipitated by a signal loss during the climax of an episode of "Single Female Lawyer", whose main character is Jenny McNeal.



</doc>
<doc id="1949" url="https://en.wikipedia.org/wiki?curid=1949" title="Andreas Capellanus">
Andreas Capellanus

Andreas Capellanus ("Capellanus" meaning "chaplain"), also known as Andrew the Chaplain, and occasionally by a French translation of his name, André le Chapelain, was the 12th-century author of a treatise commonly known as "De amore" ("About Love"), and often known in English, somewhat misleadingly, as "The Art of Courtly Love", though its realistic, somewhat cynical tone suggests that it is in some measure an antidote to courtly love. Little is known of Andreas Capellanus's life, but he is presumed to have been a courtier of Marie de Champagne, and probably of French origin.

"De Amore" was written at the request of Marie de Champagne, daughter of King Louis VII of France and of Eleanor of Aquitaine. In it, the author informs a young pupil, Walter, of the pitfalls of love. A dismissive allusion in the text to the "wealth of Hungary" has suggested the hypothesis that it was written after 1184, at the time when Bela III of Hungary had sent to the French court a statement of his income and had proposed marriage to Marie's half-sister Marguerite of France, but before 1186, when his proposal was accepted.

"De Amore" is made up of three books. The first book covers the etymology and definition of love and is written in the manner of an academic lecture. The second book consists of sample dialogues between members of different social classes; it outlines how the romantic process between the classes should work. This second work is largely considered to be a bit not good. Book three is made of stories from actual courts of love presided over by noble women.

John Jay Parry, the editor of one modern edition of "De Amore", quotes critic Robert Bossuat as describing "De Amore" as "one of those capital works which reflect the thought of a great epoch, which explains the secret of a civilization". It may be viewed as didactic, mocking, or merely descriptive; in any event it preserves the attitudes and practices that were the foundation of a long and significant tradition in Western literature.

The social system of "courtly love", as gradually elaborated by the Provençal troubadours from the mid twelfth century, soon spread. One of the circles in which this poetry and its ethic were cultivated was the court of Eleanor of Aquitaine (herself the granddaughter of an early troubadour poet, William IX of Aquitaine). It has been claimed that "De Amore" codifies the social and sexual life of Eleanor's court at Poitiers between 1170 and 1174, though it was evidently written at least ten years later and, apparently, at Troyes. It deals with several specific themes that were the subject of poetical debate among late twelfth century troubadours and trobairitz.

The meaning of "De Amore" has been debated over the centuries. In the years immediately following its release many people took Andreas’ opinions concerning Courtly Love seriously. In more recent times, however, scholars have come to view the priest's work as satirical. Many scholars now agree that Andreas was commenting on the materialistic, superficial nature of the nobles of the Middle Ages. Andreas seems to have been warning young Walter, his protege, about love in the Middle Ages.





</doc>
<doc id="1950" url="https://en.wikipedia.org/wiki?curid=1950" title="American Civil Liberties Union">
American Civil Liberties Union

The American Civil Liberties Union (ACLU) is a nonprofit organization whose stated mission is "to defend and preserve the individual rights and liberties guaranteed to every person in this country by the Constitution and laws of the United States." Officially nonpartisan, the organization has been supported and criticized by liberal and conservative organizations alike. The ACLU works through litigation and lobbying and it has over 1,200,000 members and an annual budget of over $100 million. Local affiliates of the ACLU are active in all 50 states, the District of Columbia, and Puerto Rico. The ACLU provides legal assistance in cases when it considers civil liberties to be at risk. Legal support from the ACLU can take the form of direct legal representation or preparation of "amicus curiae" briefs expressing legal arguments when another law firm is already providing representation.

In addition to representing persons and organizations in lawsuits, the ACLU lobbies for policy positions that have been established by its board of directors. Current positions of the ACLU include: opposing the death penalty; supporting same-sex marriage and the right of LGBT people to adopt; supporting birth control and abortion rights; eliminating discrimination against women, minorities, and LGBT people; supporting the rights of prisoners and opposing torture; and opposing government preference for religion over non-religion, or for particular faiths over others.

Legally, the ACLU consists of two separate but closely affiliated nonprofit organizations: the American Civil Liberties Union, a 501(c)(4) social welfare group, and the ACLU Foundation, a 501(c)(3) public charity. Both organizations engage in civil rights litigation, advocacy, and education, but only donations to the 501(c)(3) foundation are tax deductible, and only the 501(c)(4) group can engage in unlimited political lobbying. The two organizations share office space and employees.

The ACLU was founded in 1920 by a committee including Helen Keller, Roger Baldwin, Crystal Eastman, Walter Nelles, Morris Ernst, Albert DeSilver, Arthur Garfield Hays, Jane Addams, Felix Frankfurter, Elizabeth Gurley Flynn, and Rose Schneiderman. Its focus was on freedom of speech, primarily for anti-war protesters. During the 1920s, the ACLU expanded its scope to include protecting the free speech rights of artists and striking workers, and working with the National Association for the Advancement of Colored People (NAACP) to decrease racism and discrimination. During the 1930s, the ACLU started to engage in work combating police misconduct and supporting Native American rights. Many of the ACLU's cases involved the defense of Communist Party members and Jehovah's Witnesses. In 1940, the ACLU leadership voted to exclude communists from its leadership positions, a decision rescinded in 1968. During World War II, the ACLU defended Japanese-American citizens, unsuccessfully trying to prevent their forcible relocation to internment camps. During the Cold War, the ACLU headquarters was dominated by anti-communists, but many local affiliates defended members of the Communist Party.

By 1964, membership had risen to 80,000, and the ACLU participated in efforts to expand civil liberties. In the 1960s, the ACLU continued its decades-long effort to enforce separation of church and state. It defended several anti-war activists during the Vietnam War. The ACLU was involved in the "Miranda" case, which addressed conduct by police during interrogations, and in the "New York Times" case, which established new protections for newspapers reporting on government activities. In the 1970s and 1980s, the ACLU ventured into new legal areas, involving the rights of homosexuals, students, prisoners, and the poor. In the twenty-first century, the ACLU has fought the teaching of creationism in public schools and challenged some provisions of anti-terrorism legislation as infringing on privacy and civil liberties. Fundraising and membership spiked after the 2016 election; the ACLU's current membership is more than 1.2 million.

The ACLU is led by a president and an executive director, Susan N. Herman and Anthony Romero, respectively, in 2015. The president acts as chair of the ACLU's board of directors, leads fundraising, and facilitates policy-setting. The executive director manages the day-to-day operations of the organization. The board of directors consists of 80 persons, including representatives from each state affiliate, as well as at-large delegates. The organization has its headquarters in 125 Broad Street, a 40-story skyscraper located in Lower Manhattan, New York City.

The leadership of the ACLU does not always agree on policy decisions; differences of opinion within the ACLU leadership have sometimes grown into major debates. In 1937, an internal debate erupted over whether to defend Henry Ford's right to distribute anti-union literature. In 1939, a heated debate took place over whether to prohibit communists from serving in ACLU leadership roles. During the early 1950s and Cold War McCarthyism, the board was divided on whether to defend communists. In 1968, a schism formed over whether to represent Benjamin Spock's anti-war activism. In 1973, there was internal conflict over whether to call for the impeachment of Richard Nixon. In 2005, there was internal conflict about whether or not a gag rule should be imposed on ACLU employees to prevent publication of internal disputes.

In the year ending March 31, 2014, the ACLU and the ACLU Foundation had a combined income from support and revenue of $100.4 million, originating from grants (50.0%), membership donations (25.4%), donated legal services (7.6%), bequests (16.2%), and revenue (0.9%). Membership dues are treated as donations; members choose the amount they pay annually, averaging approximately $50 per member per year. In the year ending March 31, 2014, the combined expenses of the ACLU and ACLU Foundation were $133.4 million, spent on programs (86.2%), management (7.4%), and fundraising (8.2%). (After factoring in other changes in net assets of +$30.9 million, from sources such as investment income, the organization had an overall decrease in net assets of $2.1 million.) Over the period from 2011 to 2014 the ACLU Foundation, on the average, has accounted for roughly 70% of the combined budget, and the ACLU roughly 30%.

The ACLU solicits donations to its charitable foundation. The ACLU is accredited by the Better Business Bureau, and the Charity Navigator has ranked the ACLU with a four-star rating. The local affiliates solicit their own funding; however, some also receive funds from the national ACLU, with the distribution and amount of such assistance varying from state to state. At its discretion, the national organization provides subsidies to smaller affiliates that lack sufficient resources to be self-sustaining; for example, the Wyoming ACLU chapter received such subsidies until April 2015, when, as part of a round of layoffs at the national ACLU, the Wyoming office was closed.

In October 2004, the ACLU rejected $1.5 million from both the Ford Foundation and Rockefeller Foundation because the foundations had adopted language from the USA PATRIOT Act in their donation agreements, including a clause stipulating that none of the money would go to "underwriting terrorism or other unacceptable activities." The ACLU views this clause, both in federal law and in the donors' agreements, as a threat to civil liberties, saying it is overly broad and ambiguous.

Due to the nature of its legal work, the ACLU is often involved in litigation against governmental bodies, which are generally protected from adverse monetary judgments; a town, state or federal agency may be required to change its laws or behave differently, but not to pay monetary damages except by an explicit statutory waiver. In some cases, the law permits plaintiffs who successfully sue government agencies to collect money damages or other monetary relief. In particular, the Civil Rights Attorney's Fees Award Act of 1976 leaves the government liable in some civil rights cases. Fee awards under this civil rights statute are considered "equitable relief" rather than damages, and government entities are not immune from equitable relief. Under laws such as this, the ACLU and its state affiliates sometimes share in monetary judgments against government agencies. In 2006, the Public Expressions of Religion Protection Act sought to prevent monetary judgments in the particular case of violations of church-state separation.

The ACLU has received court awarded fees from opponents, for example, the Georgia affiliate was awarded $150,000 in fees after suing a county demanding the removal of a Ten Commandments display from its courthouse; a second Ten Commandments case in the state, in a different county, led to a $74,462 judgment. The State of Tennessee was required to pay $50,000, the State of Alabama $175,000, and the State of Kentucky $121,500, in similar Ten Commandments cases.

Most of the organization's workload is performed by its local affiliates. There is at least one affiliate organization in each state, as well as one in Washington, DC, and in Puerto Rico. California has three affiliates. The affiliates operate autonomously from the national organization; each affiliate has its own staff, executive director, board of directors, and budget. Each affiliate consists of two non-profit corporations: a 501(c)(3) corporation that does not perform lobbying, and a 501(c)(4) corporation which is entitled to lobby.

ACLU affiliates are the basic unit of the ACLU's organization and engage in litigation, lobbying, and public education. For example, in a twenty-month period beginning January 2004, the ACLU's New Jersey chapter was involved in fifty-one cases according to their annual report—thirty-five cases in state courts, and sixteen in federal court. They provided legal representation in thirty-three of those cases, and served as amicus in the remaining eighteen. They listed forty-four volunteer attorneys who assisted them in those cases. 

The ACLU's official position statements, , included the following policies:

The ACLU is supported by a variety of persons and organizations. There were over 1,000,000 members in 2017, and the ACLU annually receives thousands of grants from hundreds of charitable foundations. Allies of the ACLU in legal actions have included the National Association for the Advancement of Colored People, the American Jewish Congress, People For the American Way, the National Rifle Association, the Electronic Frontier Foundation, Americans United for Separation of Church and State, and the National Organization for Women.

The ACLU has been criticized by liberals, such as when it excluded communists from its leadership ranks, when it defended Neo-Nazis, when it declined to defend Paul Robeson, or when it opposed the passage of the National Labor Relations Act. Conversely, it has been criticized by conservatives, such as when it argued against official prayer in public schools, or when it opposed the Patriot Act. The ACLU has supported conservative figures such as Rush Limbaugh, George Wallace, Henry Ford, and Oliver North; and it has supported liberal figures such as Dick Gregory, Rockwell Kent, and Benjamin Spock.

A major source of criticism are legal cases in which the ACLU represents an individual or organization that promotes offensive or unpopular viewpoints, such as the Ku Klux Klan, Neo-Nazis, Nation of Islam, North American Man/Boy Love Association, Westboro Baptist Church or Unite the Right rally. The ACLU responded to these criticisms by stating "It is easy to defend freedom of speech when the message is something many people find at least reasonable. But the defense of freedom of speech is most critical when the message is one most people find repulsive."

The ACLU developed from the National Civil Liberties Bureau (CLB), co-founded in 1917 during World War I by Crystal Eastman, an attorney activist, and Roger Nash Baldwin. The focus of the CLB was on freedom of speech, primarily anti-war speech, and on supporting conscientious objectors who did not want to serve in World War I.

Three United States Supreme Court decisions in 1919 each upheld convictions under laws against certain kinds of anti-war speech. In 1919, the Court upheld the conviction of Socialist Party leader Charles Schenck for publishing anti-war literature. In "Debs v. United States," the court upheld the conviction of Eugene Debs. While the Court upheld a conviction a third time in "Abrams v. United States", Justice Oliver Wendell Holmes wrote an important dissent which has gradually been absorbed as an American principle: he urged the court to treat freedom of speech as a fundamental right, which should rarely be restricted.

In 1918, Crystal Eastman resigned from the organization due to health issues. After assuming sole leadership of the CLB, Baldwin insisted that the organization be reorganized. He wanted to change its focus from litigation to direct action and public education.

The CLB directors concurred, and on January 19, 1920, they formed an organization under a new name, the American Civil Liberties Union. Although a handful of other organizations in the United States at that time focused on civil rights, such as the National Association for the Advancement of Colored People (NAACP) and Anti-Defamation League (ADL), the ACLU was the first that did not represent a particular group of persons, or a single theme. Like the CLB, the NAACP pursued litigation to work on civil rights, including efforts to overturn the disfranchisement of African Americans in the South that had taken place since the turn of the century.

During the first decades of the ACLU, Baldwin continued as its leader. His charisma and energy attracted many supporters to the ACLU board and leadership ranks. Baldwin was ascetic, wearing hand-me-down clothes, pinching pennies, and living on a very small salary. The ACLU was directed by an executive committee, and it was not particularly democratic or egalitarian. The ACLU's base in New York resulted in its being dominated by people from the city and state. Most ACLU funding came from philanthropies, such as the Garland Fund.

In the 1920s, government censorship was commonplace. Magazines were routinely confiscated under the anti-obscenity Comstock laws; permits for labor rallies were often denied; and virtually all anti-war or anti-government literature was outlawed. Right-wing conservatives wielded vast amounts of power, and activists that promoted unionization, socialism, or government reform were often denounced as un-American or unpatriotic. In one typical instance in 1923, author Upton Sinclair was arrested for trying to read the First Amendment during an Industrial Workers of the World rally.
ACLU leadership was divided on how to challenge the civil rights violations. One faction, including Baldwin, Arthur Garfield Hays and Norman Thomas, believed that direct, militant action was the best path. Hays was the first of many successful attorneys that relinquished their private practices to work for the ACLU. Another group, including Walter Nelles and Walter Pollak felt that lawsuits taken to the Supreme Court were the best way to achieve change. Both groups worked in tandem, but equally revered the Bill of Rights and the US Constitution.

During the 1920s, the ACLU's primary focus was on freedom of speech in general, and speech within the labor movement particularly. Because most of the ACLU's efforts were associated with the labor movement, the ACLU itself came under heavy attack from conservative groups, such as the American Legion, the National Civic Federation, and Industrial Defense Association and the Allied Patriotic Societies.

In addition to labor, the ACLU also led efforts in non-labor arenas, for example, promoting free speech in public schools. The ACLU itself was banned from speaking in New York public schools in 1921. The ACLU, working with the NAACP, also supported racial discrimination cases. The ACLU defended free speech regardless of the opinions being espoused. For example, the reactionary, anti-Catholic, anti-black Ku Klux Klan (KKK) was a frequent target of ACLU efforts, but the ACLU defended the KKK's right to hold meetings in 1923. There were some civil rights that the ACLU did not make an effort to defend in the 1920s, including censorship of the arts, government search and seizure issues, right to privacy, or wiretapping.

The Communist Party USA was routinely harassed and oppressed by government officials, leading it to be the primary client of the ACLU. At the same time, the Communists were very aggressive in their tactics, often engaging in illegal conduct such as denying their party membership under oath. This led to frequent conflicts between the Communists and ACLU. Communist leaders sometimes attacked the ACLU, particularly when the ACLU defended the free speech rights of conservatives, whereas Communists tried to disrupt speeches by critics of the USSR. This uneasy relationship between the two groups continued for decades.

When 1925 arrived five years after the ACLU was formed the organization had virtually no success to show for its efforts. That changed in 1925, when the ACLU persuaded John T. Scopes to defy Tennessee's anti-evolution law in "The State of Tennessee v. John Thomas Scopes". Clarence Darrow, a member of the ACLU National Committee, headed Scopes' legal team. The prosecution, led by William Jennings Bryan, contended that the Bible should be interpreted literally in teaching creationism in school. The ACLU lost the case and Scopes was fined $100. The Tennessee Supreme Court later upheld the law but overturned the conviction on a technicality.

The Scopes trial was a phenomenal public relations success for the ACLU. The ACLU became well known across America, and the case led to the first endorsement of the ACLU by a major US newspaper. The ACLU continued to fight for the separation of church and state in schoolrooms, decade after decade, including the 1982 case "McLean v. Arkansas" and the 2005 case "Kitzmiller v. Dover Area School District".

Baldwin himself was involved in an important free speech victory of the 1920s, after he was arrested for attempting to speak at a rally of striking mill workers in New Jersey. Although the decision was limited to the state of New Jersey, the appeals court's judgement in 1928 declared that constitutional guarantees of free speech must be given "liberal and comprehensive construction", and it marked a major turning point in the civil rights movement, signaling the shift of judicial opinion in favor of civil rights.

The most important ACLU case of the 1920s was "Gitlow v. New York", in which Benjamin Gitlow was arrested for violating a state law against inciting anarchy and violence, when he distributed literature promoting communism. Although the Supreme Court did not overturn Gitlow's conviction, it adopted the ACLU's stance (later termed the incorporation doctrine) that the First Amendment freedom of speech applied to state laws, as well as federal laws.

After the First World War, many native-born Americans had a revival of concerns about assimilation of immigrants and worries about "foreign" values; they wanted public schools to teach children to be American. Numerous states drafted laws designed to use schools to promote a common American culture, and in 1922, the voters of Oregon passed the Oregon Compulsory Education Act. The law was primarily aimed at eliminating parochial schools, including Catholic schools. It was promoted by groups such as the Knights of Pythias, the Federation of Patriotic Societies, the Oregon Good Government League, the Orange Order, and the Ku Klux Klan.

The Oregon Compulsory Education Act required almost all children in Oregon between eight and sixteen years of age to attend public school by 1926. Associate Director Roger Nash Baldwin, a personal friend of Luke E. Hart, the then–Supreme Advocate and future Supreme Knight of the Knights of Columbus, offered to join forces with the Knights to challenge the law. The Knights of Columbus pledged an immediate $10,000 to fight the law and any additional funds necessary to defeat it.

The case became known as "Pierce v. Society of Sisters", a seminal United States Supreme Court decision that significantly expanded coverage of the Due Process Clause in the Fourteenth Amendment. In a unanimous decision, the court held that the act was unconstitutional and that parents, not the state, had the authority to educate children as they thought best. It upheld the religious freedom of parents to educate their children in religious schools.

Leaders of the ACLU were divided on the best tactics to use to promote civil liberties. Felix Frankfurter felt that legislation was the best long-term solution, because the Supreme Court could not (and in his opinion should not) mandate liberal interpretations of the Bill of Rights. But Walter Pollack, Morris Ernst, and other leaders felt that Supreme Court decisions were the best path to guarantee civil liberties. A series of Supreme Court decisions in the 1920s foretold a changing national atmosphere; anti-radical emotions were diminishing, and there was a growing willingness to protect freedom of speech and assembly via court decisions.

Censorship was commonplace in the early 20th century. State laws and city ordinances routinely outlawed speech deemed to be obscene or offensive, and prohibited meetings or literature that promoted unions or labor organization. Starting in 1926, the ACLU began to expand its free speech activities to encompass censorship of art and literature. In that year, H. L. Mencken deliberately broke Boston law by distributing copies of his banned "American Mercury" magazine; the ACLU defended him and won an acquittal. The ACLU went on to win additional victories, including the landmark case "United States v. One Book Called Ulysses" in 1933, which reversed a ban by the Customs Department against the book "Ulysses" by James Joyce. The ACLU only achieved mixed results in the early years, and it was not until 1966 that the Supreme Court finally clarified the obscenity laws in the "Roth v. United States" and "Memoirs v. Massachusetts" cases.

The Comstock laws banned distribution of sex education information, based on the premise that it was obscene and led to promiscuous behavior Mary Ware Dennett was fined $300 in 1928, for distributing a pamphlet containing sex education material. The ACLU, led by Morris Ernst, appealed her conviction and won a reversal, in which judge Learned Hand ruled that the pamphlet's main purpose was to "promote understanding".

The success prompted the ACLU to broaden their freedom of speech efforts beyond labor and political speech, to encompass movies, press, radio and literature. The ACLU formed the National Committee on Freedom from Censorship in 1931 to coordinate this effort. By the early 1930s, censorship in the United States was diminishing.

Two major victories in the 1930s cemented the ACLUs campaign to promote free speech. In "Stromberg v. California", decided in 1931, the Supreme Court sided with the ACLU and affirmed the right of a communist party member to salute a communist flag. The result was the first time the Supreme Court used the Due Process Clause of the 14th amendment to subject states to the requirements of the First Amendment. In "Near v. Minnesota", also decided in 1931, the Supreme Court ruled that states may not exercise prior restraint and prevent a newspaper from publishing, simply because the newspaper had a reputation for being scandalous.

The late 1930s saw the emergence of a new era of tolerance in the United States. National leaders hailed the Bill of Rights, particularly as it protected minorities, as the essence of democracy. The 1939 Supreme Court decision in "Hague v. Committee for Industrial Organization" affirmed the right of communists to promote their cause. Even conservative elements, such as the American Bar Association began to campaign for civil liberties, which were long considered to be the domain of left-leaning organizations. By 1940, the ACLU had achieved many of the goals it set in the 1920s, and many of its policies were the law of the land.

In 1929, after the Scopes and Dennett victories, Baldwin perceived that there was vast, untapped support for civil liberties in the United States. Baldwin proposed an expansion program for the ACLU, focusing on police brutality, Native American rights, African American rights, censorship in the arts, and international civil liberties. The board of directors approved Baldwin's expansion plan, except for the international efforts.

The ACLU played a major role in passing the 1932 Norris–La Guardia Act, a federal law which prohibited employers from preventing employees from joining unions, and stopped the practice of outlawing strikes, unions, and labor organizing activities with the use of injunctions. The ACLU also played a key role in initiating a nationwide effort to reduce misconduct (such as extracting false confessions) within police departments, by publishing the report "Lawlessness in Law Enforcement" in 1931, under the auspices of Herbert Hoover's Wickersham Commission. In 1934, the ACLU lobbied for the passage of the Indian Reorganization Act, which restored some autonomy to Native American tribes, and established penalties for kidnapping Native American children.

Although the ACLU deferred to the NAACP for litigation promoting civil liberties for African Americans, the ACLU did engage in educational efforts, and published "Black Justice" in 1931, a report which documented institutional racism throughout the South, including lack of voting rights, segregation, and discrimination in the justice system. Funded by the Garland Fund, the ACLU also participated in producing the influential Margold Report, which outlined a strategy to fight for civil rights for blacks. The ACLU's plan was to demonstrate that the "separate but equal" policies governing the Southern discrimination were illegal because blacks were never, in fact, treated equally.

In 1932twelve years after the ACLU was foundedit had achieved significant success; the Supreme Court had embraced the free speech principles espoused by the ACLU, and the general public was becoming more supportive of civil rights in general. But the Great Depression brought new assaults on civil liberties; the year 1930 saw a large increase in the number of free speech prosecutions, a doubling of the number of lynchings, and all meetings of unemployed persons were banned in Philadelphia.

The Franklin D. Roosevelt administration proposed the New Deal to combat the depression. ACLU leaders were of mixed opinions about the New Deal, since many felt that it represented an increase in government intervention into personal affairs, and because the National Recovery Administration suspended anti-trust legislation. Roosevelt was not personally interested in civil rights, but did appoint many civil libertarians to key positions, including Interior Secretary Harold Ickes, a member of the ACLU.

The economic policies of the New Deal leaders were often aligned with ACLU goals, but social goals were not. In particular, movies were subject to a barrage of local ordinances banning screenings that were deemed immoral or obscene. Even public health films portraying pregnancy and birth were banned; as was "Life" magazine's April 11, 1938 issue which included photos of the birth process. The ACLU fought these bans, but did not prevail.

The Catholic Church attained increasing political influence in the 1930s, and used its influence to promote censorship of movies, and to discourage publication of birth control information. This conflict between the ACLU and the Catholic Church led to the resignation of the last Catholic priest from ACLU leadership in 1934; a Catholic priest would not be represented there again until the 1970s.

The ACLU took no official position on president Franklin Delano Roosevelt's 1937 court-packing plan, which threatened to increase the number of Supreme Court justices, unless the Supreme Court reversed its course and began approving New Deal legislation. The Supreme Court responded by making a major shift in policy, and no longer applied strict constitutional limits to government programs, and also began to take a more active role in protecting civil liberties.

The first decision that marked the court's new direction was "De Jonge v. Oregon", in which a communist labor organizer was arrested for calling a meeting to discuss unionization. The ACLU attorney Osmond Fraenkel, working with International Labor Defense, defended De Jonge in 1937, and won a major victory when the Supreme Court ruled that "peaceable assembly for lawful discussion cannot be made a crime." The De Jonge case marked the start of an era lasting for a dozen years, during which Roosevelt appointees (led by Hugo Black, William O. Douglas, and Frank Murphy) established a body of civil liberties law. In 1938, Justice Harlan F. Stone wrote the famous "footnote four" in "United States v. Carolene Products Co." in which he suggested that state laws which impede civil liberties wouldhenceforthrequire compelling justification.

Senator Robert F. Wagner proposed the National Labor Relations Act in 1935, which empowered workers to unionize. Ironically, the ACLU, after 15 years of fighting for workers' rights, initially opposed the act (it later took no stand on the legislation) because some ACLU leaders feared the increased power the bill gave to the government. The newly formed National Labor Relations Board (NLRB) posed a dilemma for the ACLU, because in 1937 it issued an order to Henry Ford, prohibiting Ford from disseminating anti-union literature. Part of the ACLU leadership habitually took the side of labor, and that faction supported the NLRB's action. But part of the ACLU supported Ford's right to free speech. ACLU leader Arthur Garfield Hays proposed a compromise (supporting the auto workers union, yet also endorsing Ford's right to express personal opinions), but the schism highlighted a deeper divide that would become more prominent in the years to come.

The ACLU's support of the NLRB was a major development for the ACLU, because it marked the first time it accepted that a government agency could be responsible for upholding civil liberties. Until 1937, the ACLU felt that civil rights were best upheld by citizens and private organizations.

Some factions in the ACLU proposed new directions for the organization. In the late 1930s, some local affiliates proposed shifting their emphasis from civil liberties appellate actions, to becoming a legal aid society, centered on store front offices in low income neighborhoods. The ACLU directors rejected that proposal. Other ACLU members wanted the ACLU to shift focus into the political arena, and to be more willing to compromise their ideals in order to strike deals with politicians. This initiative was also rejected by the ACLU leadership.

The ACLU's support of defendants with unpopular, sometimes extreme, viewpoints have produced many landmark court cases and established new civil liberties. One such defendant was the Jehovah's Witnesses, who were involved in a large number of Supreme Court cases. Cases that the ACLU supported included "Lovell v. City of Griffin" (which struck down a city ordinance that required a permit before a person could distribute "literature of any kind"); "Martin v. Struthers" (which struck down an ordinance prohibiting door-to-door canvassing); and "Cantwell v. Connecticut" (which reversed the conviction of a Witness who was reciting offensive speech on a street corner).

The most important cases involved statutes requiring flag salutes. The Jehovah's Witnesses felt that saluting a flag was contrary to their religious beliefs. Two children were convicted in 1938 of not saluting the flag. The ACLU supported their appeal to the Supreme Court, but the court affirmed the conviction, in 1940. But three years later, in "West Virginia State Board of Education v. Barnette", the Supreme court reversed itself and wrote "If there is any fixed star in our constitutional constellation, it is that no official, high or petty, can prescribe what shall be orthodox in politics, nationalism, religion, or other matters of opinion or force citizens to confess by word or act their faith therein." To underscore its decision, the Supreme Court announced it on Flag Day.

The rise of totalitarian regimes in Germany, Russia, and other countries who rejected freedom of speech and association had a large impact on the civil liberties movement in the US; anti-Communist sentiment rose and civil liberties were curtailed.

The ACLU leadership was divided over whether or not to defend pro-Nazi speech in the United States; pro-labor elements within the ACLU were hostile towards Nazism and fascism, and objected when the ACLU defended Nazis. Several states passed laws outlawing the hate speech directed at ethnic groups. The first person arrested under New Jersey's 1935 hate speech law was a Jehovah's Witness who was charged with disseminating anti-Catholic literature. The ACLU defended the Jehovah's Witnesses, and the charges were dropped. The ACLU proceeded to defend numerous pro-Nazi groups, defending their rights to free speech and free association.

In the late 1930s, the ACLU allied itself with the Popular Front, a coalition of liberal organizations coordinated by the United States Communist Party. The ACLU benefited because affiliates from the Popular Front could often fight local civil rights battles much more effectively than the New York-based ACLU. The association with the Communist Party led to accusations that the ACLU was a "Communist front", particularly because Harry F. Ward was both chairman of the ACLU and chairman of the American League Against War and Fascism, a Communist organization.

The House Un-American Activities Committee (HUAC) was created in 1938 to uncover sedition and treason within the United States. When witnesses testified at its hearings, the ACLU was mentioned several times, leading the HUAC to mention the ACLU prominently in its 1939 report. This damaged the ACLU's reputation severely, even though the report said that it could not "definitely state whether or not" the ACLU was a Communist organization.

While the ACLU rushed to defend its image against allegations of being a Communist front, it also worked to protect witnesses who were being harassed by the HUAC. The ACLU was one of the few organizations to protest (unsuccessfully) against passage of the Smith Act in 1940, which would later be used to imprison many persons who supported Communism. The ACLU defended many persons who were prosecuted under the Smith Act, including labor leader Harry Bridges.

ACLU leadership was split on whether to purge its leadership of Communists. Norman Thomas, John Haynes Holmes, and Morris Ernst were anti-Communists who wanted to distance the ACLU from Communism; opposing them were Harry F. Ward, Corliss Lamont, and Elizabeth Gurley Flynn, who rejected any political test for ACLU leadership. A bitter struggle ensued throughout 1939, and the anti-Communists prevailed in February 1940, when the board voted to prohibit anyone who supported totalitarianism from ACLU leadership roles. Ward immediately resigned, andfollowing a contentious six-hour debateFlynn was voted off the ACLU's board. The 1940 resolution was considered by many to be a betrayal of its fundamental principles. The resolution was rescinded in 1968, and Flynn was posthumously reinstated to the ACLU in 1970.

When World War II engulfed the United States, the Bill of Rights was enshrined as a hallowed document, and numerous organizations defended civil liberties. Chicago and New York proclaimed "Civil Rights" weeks, and President Franklin Delano Roosevelt announced a national Bill of Rights day. Eleanor Roosevelt was the keynote speaker at the 1939 ACLU convention. In spite of this newfound respect for civil rights, Americans were becoming adamantly anti-communist, and believed that excluding communists from American society was an essential step to preserve democracy.

Contrasted with World War I, there was relatively little violation of civil liberties during World War II. President Roosevelt was a strong supporter of civil liberties, butmore importantlythere were few anti-war activists during World War II. The most significant exception was the internment of Japanese Americans.

Two months after the Japanese attack on Pearl Harbor, Roosevelt authorized the creation of military "exclusion zones" with Executive Order 9066, paving the way for the detention of all West Coast Japanese Americans in inland camps. In addition to the non-citizen Issei (prohibited from naturalization as members of an "unassimilable" race), over two-thirds of those swept up were American-born citizens. The ACLU immediately protested to Roosevelt, comparing the evacuations to Nazi concentration camps. The ACLU was the only major organization to object to the internment plan, and their position was very unpopular, even within the organization. Not all ACLU leaders wanted to defend the Japanese Americans; Roosevelt loyalists such as Morris Ernst wanted to support Roosevelt's war effort, but pacifists such as Baldwin and Norman Thomas felt that Japanese Americans needed access to due process before they could be imprisoned. In a March 20, 1942 letter to Roosevelt, Baldwin called on the administration to allow Japanese Americans to prove their loyalty at individual hearings, describing the constitutionality of the planned removal "open to grave question." His suggestions went nowhere, and opinions within the organization became increasingly divided as the Army began the "evacuation" of the West Coast. In May, the two factions, one pushing to fight the exclusion orders then being issued, the other advocating support for the President's policy of removing citizens whose "presence may endanger national security," brought their opposing resolutions to a vote before the board and the ACLU's national leaders. They decided not to challenge the eviction of Japanese American citizens, and on June 22 instructions were sent to West Coast branches not to support cases that argued the government had no constitutional right to do so.

The ACLU offices on the West Coast had been more directly involved in addressing the tide of anti-Japanese prejudice from the start, as they were geographically closer to the issue, and were already working on cases challenging the exclusion by this time. The Seattle office, assisting in Gordon Hirabayashi's lawsuit, created an unaffiliated committee to continue the work the ACLU had started, while in Los Angeles, attorney A.L. Wirin continued to represent Ernest Kinzo Wakayama but without addressing the case's constitutional questions. (Wirin would lose private clients because of his defense of Wakayama and other Japanese Americans.) However, the San Francisco branch, led by Ernest Besig, refused to discontinue its support for Fred Korematsu, whose case had been taken on prior to the June 22 directive, and attorney Wayne Collins, with Besig's full support, centered his defense on the illegality of Korematsu's exclusion.

The West Coast offices had wanted a test case to take to court, but had a difficult time finding a Japanese American who was both willing to violate the internment orders and able to meet the ACLU's desired criteria of a sympathetic, Americanized plaintiff. Of the 120,000 Japanese Americans affected by the order, only 12 disobeyed, and Korematsu, Hirabayashi, and two others were the only resisters whose cases eventually made it to the Supreme Court. "Hirabayashi v. United States" came before the Court in May 1943, and the justices upheld the government's right to exclude Japanese Americans from the West Coast; although it had earlier forced its local office in L.A. to stop aiding Hirabayashi, the ACLU donated $1,000 to the case (over a third of the legal team's total budget) and submitted an "amicus" brief. Besig, dissatisfied with Osmond Fraenkel's tamer defense, filed an additional "amicus" brief that directly addressed Hirabayashi's constitutional rights. In the meantime, A.L. Wirin served as one of the attorneys in "Yasui v. United States" (decided the same day as the Hirabayashi case, and with the same results), but he kept his arguments within the perimeters established by the national office. The only case to receive a favorable ruling, "ex parte Endo", was also aided by two "amicus" briefs from the ACLU, one from the more conservative Fraenkel and another from the more putative Wayne Collins.

"Korematsu v. United States" proved to be the most controversial of these cases, as Besig and Collins refused to bow to the national ACLU office's pressure to pursue the case without challenging the government's right to remove citizens from their homes. The ACLU board threatened to revoke the San Francisco branch's national affiliation, while Baldwin tried unsuccessfully to convince Collins to step down so he could replace him as lead attorney in the case. Eventually Collins agreed to present the case alongside Charles Horsky, although their arguments before the Supreme Court remained based in the unconstitutionality of the exclusion order Korematsu had disobeyed. The case was decided in December 1944, when the Court once again upheld the government's right to relocate Japanese Americans, although Korematsu's, Hirabayashi's and Yasui's convictions were later overturned in "coram nobis" proceedings in the 1980s.

The national office of the ACLU was even more reluctant to defend anti-war protesters. A majority of the board passed a resolution in 1942 which declared the ACLU unwilling to defend anyone who interfered with the United States' war effort. Included in this group were the thousands of Nisei who renounced their US citizenship during the war but later regretted the decision and tried to revoke their applications for "repatriation." (A significant number of those slated to "go back" to Japan had never actually been to the country and were in fact being deported rather than repatriated.) Ernest Besig had in 1944 visited the Tule Lake Segregation Center, where the majority of these "renunciants" were concentrated, and subsequently enlisted Wayne Collins' help to file a lawsuit on their behalf, arguing the renunciations had been given under duress. The national organization prohibited local branches from representing the renunciants, forcing Collins to pursue the case on his own, although Besig and the Northern California office provided some support.

During his 1944 visit to Tule Lake, Besig had also became aware of a hastily constructed stockade in which Japanese American internees were routinely being brutalized and held for months without due process. Besig was forbidden by the national ACLU office to intervene on behalf of the stockade prisoners or even to visit the Tule Lake camp without prior written approval from Baldwin. Unable to help directly, Besig turned to Wayne Collins for assistance. Collins, using the threat of habeas corpus suits managed to have the stockade closed down. A year later, after learning that the stockade had been reestablished, he returned to the camp and had it closed down for good.

When the war ended in 1945, the ACLU was 25 years old, and had accumulated an impressive set of legal victories. President Harry S. Truman sent a congratulatory telegram to the ACLU on the occasion of their 25th anniversary. American attitudes had changed since World War I, and dissent by minorities was tolerated with more willingness. The Bill of Rights was more respected, and minority rights were becoming more commonly championed. During their 1945 annual conference, the ACLU leaders composed a list of important civil rights issues to focus on in the future, and the list included racial discrimination and separation of church and state.

The ACLU supported the African-American defendants in "Shelley v. Kraemer", when they tried to occupy a house they had purchased in a neighborhood which had racially restrictive housing covenants. The African-American purchasers won the case in 1945.

Anti-Communist sentiment gripped the United States during the Cold War beginning in 1946. Federal investigations caused many persons with Communist or left-leaning affiliations to lose their jobs, become blacklisted, or be jailed. During the Cold War, although the United States collectively ignored the civil rights of Communists, other civil liberties—such as due process in law and separation of church and state—continued to be reinforced and even expanded.

The ACLU was internally divided when it purged Communists from its leadership in 1940, and that ambivalence continued as it decided whether to defend alleged Communists during the late 1940s. Some ACLU leaders were anti-Communist, and felt that the ACLU should not defend any victims. Some ACLU leaders felt that Communists were entitled to free speech protections, and the ACLU should defend them. Other ACLU leaders were uncertain about the threat posed by Communists, and tried to establish a compromise between the two extremes. This ambivalent state of affairs would last until 1954, when the civil liberties faction prevailed, leading to the resignation of most of the anti-Communist leaders.

In 1947, President Truman issued Executive Order 9835, which created the Federal Loyalty Program. This program authorized the Attorney General to create a list of organizations which were deemed to be subversive. Any association with these programs was ground for barring the person from employment. Listed organizations were not notified that they were being considered for the list, nor did they have an opportunity to present counterarguments; nor did the government divulge any factual basis for inclusion in the list. Although ACLU leadership was divided on whether to challenge the Federal Loyalty Program, some challenges were successfully made.

Also in 1947, the House Un-American Activities Committee (HUAC) subpoenaed ten Hollywood directors and writers, the "Hollywood Ten", intending to ask them to identify Communists, but the witnesses refused to testify. All were imprisoned for contempt of Congress. The ACLU supported the appeals of several of the artists, but lost on appeal. The Hollywood establishment panicked after the HUAC hearings, and created a blacklist which prohibited anyone with leftist associations from working. The ACLU supported legal challenges to the blacklist, but those challenges failed. The ACLU was more successful with an education effort; the 1952 report "The Judges and the Judged", prepared at the ACLU's direction in response to the blacklisting of actress Jean Muir, described the unfair and unethical actions behind the blacklisting process, and it helped gradually turn public opinion against McCarthyism.
The federal government took direct aim at the US Communist Party in 1948 when it indicted its top twelve leaders in the Foley Square trial. The case hinged on whether or not mere membership in a totalitarian political party was sufficient to conclude that members advocated the overthrow of the United States government. The ACLU chose to not represent any of the defendants, and they were all found guilty and sentenced to three to five years in prison. Their defense attorneys were all cited for contempt, went to prison and were disbarred. When the government indicted additional party members, the defendants could not find attorneys to represent them. Communists protested outside the courthouse; a bill to outlaw picketing of courthouses was introduced in Congress, and the ACLU supported the anti-picketing law.

The ACLU, in a change of heart, supported the party leaders during their appeal process. The Supreme Court upheld the convictions in the "Dennis v. United States" decision by softening the free speech requirements from a "clear and present danger" test, to a "grave and probable" test. The ACLU issued a public condemnation of the "Dennis" decision, and resolved to fight it. One reason for the Supreme Court's support of cold war legislation was the 1949 deaths of Supreme Court justices Frank Murphy and Wiley Rutledge, leaving Hugo Black and William O. Douglas as the only remaining civil libertarians on the Court.

The "Dennis" decision paved the way for the prosecution of hundreds of other Communist party members. The ACLU supported many of the Communists during their appeals (although most of the initiative originated with local ACLU affiliates, not the national headquarters) but most convictions were upheld. The two California affiliates, in particular, felt the national ACLU headquarters was not supporting civil liberties strongly enough, and they initiated more cold war cases than the national headquarters did.

The ACLU also challenged many loyalty oath requirements across the country, but the courts upheld most of the loyalty oath laws. California ACLU affiliates successfully challenged the California state loyalty oath. The Supreme Court, until 1957, upheld nearly every law which restricted the liberties of Communists.

The ACLU, even though it scaled back its defense of Communists during the Cold War, still came under heavy criticism as a "front" for Communism. Critics included the American Legion, Senator Joseph McCarthy, the HUAC, and the FBI. Several ACLU leaders were sympathetic to the FBI, and as a consequence, the ACLU rarely investigated any of the many complaints alleging abuse of power by the FBI during the Cold War.

In 1950, Raymond L. Wise, ACLU board member 1933–1951, defended William Perl, one of the other spies embroiled in the atomic espionage cases (made famous by the execution of Julius Rosenberg and Ethel Rosenberg).

In 1950, the ACLU board of directors asked executive director Baldwin to resign, feeling that he lacked the organizational skills to lead the 9,000 (and growing) member organization. Baldwin objected, but a majority of the board elected to remove him from the position, and he was replaced by Patrick Murphy Malin. Under Malin's guidance, membership tripled to 30,000 by 1955the start of a 24-year period of continual growth leading to 275,000 members in 1974. Malin also presided over an expansion of local ACLU affiliates.

The ACLU, which had been controlled by an elite of a few dozen New Yorkers, became more democratic in the 1950s. In 1951, the ACLU amended its bylaws to permit the local affiliates to participate directly in voting on ACLU policy decisions. A bi-annual conference, open to the entire membership, was instituted in the same year, and in later decades it became a pulpit for activist members, who suggested new directions for the ACLU, including abortion rights, death penalty, and rights of the poor.

During the early 1950s, the ACLU continued to steer a moderate course through the Cold War. When leftist singer Paul Robeson was denied a passport in 1950, even though he was not accused of any illegal acts, the ACLU chose to not defend him. The ACLU later reversed their stance, and supported William Worthy and Rockwell Kent in their passport confiscation cases, which resulted in legal victories in the late 1950s.

In response to communist witch-hunts, many witnesses and employees chose to use the fifth amendment protection against self-incrimination to avoid divulging information about their political beliefs. Government agencies and private organizations, in response, established policies which inferred communist party membership for anyone who invoked the fifth amendment. The national ACLU was divided on whether to defend employees who had been fired merely for pleading the fifth amendment, but the New York affiliate successfully assisted teacher Harry Slochower in his Supreme Court case which reversed his termination.

The fifth amendment issue became the catalyst for a watershed event in 1954, which finally resolved the ACLU's ambivalence by ousting the anti-communists from ACLU leadership. In 1953, the anti-communists, led by Norman Thomas and James Fly, proposed a set of resolutions that inferred guilt of persons that invoked the fifth amendment. These resolutions were the first that fell under the ACLU's new organizational rules permitting local affiliates to participate in the vote; the affiliates outvoted the national headquarters, and rejected the anti-communist resolutions. Anti-communists leaders refused to accept the results of the vote, and brought the issue up for discussion again at the 1954 bi-annual convention. ACLU member Frank Graham, president of the University of North Carolina, attacked the anti-communists with a counter-proposal, which stated that the ACLU "stand[s] against guilt by association, judgment by accusation, the invasion of privacy of personal opinions and beliefs, and the confusion of dissent with disloyalty." The anti-communists continued to battle Graham's proposal, but were outnumbered by the affiliates. The anti-communists finally gave up and departed the board of directors in late 1954 and 1955, ending an eight-year reign of ambivalence within the ACLU leadership ranks. Thereafter, the ACLU proceeded with firmer resolve against Cold War anti-communist legislation. The period from the 1940 resolution (and the purge of Elizabeth Flynn) to the 1954 resignation of the anti-communist leaders is considered by many to be an era in which the ACLU abandoned its core principles.

McCarthyism declined in late 1954 after television journalist Edward R. Murrow and others publicly chastised McCarthy. The controversies over the Bill of Rights that were generated by the Cold War ushered in a new era in American Civil liberties. In 1954, in "Brown v. Board of Education", the Supreme Court unanimously overturned state-sanctioned school segregation, and thereafter a flood of civil rights victories dominated the legal landscape.

The Supreme Court handed the ACLU two key victories in 1957, in "Watkins v. United States" and "Yates v. United States", both of which undermined the Smith Act and marked the beginning of the end of communist party membership inquiries. In 1965, the Supreme Court produced some decisions, including "Lamont v. Postmaster General" (in which the plaintiff was Corliss Lamont, a former ACLU board member), which upheld fifth amendment protections and brought an end to restrictions on political activity.

The decade from 1954 to 1964 was the most successful period in the ACLU's history. Membership rose from 30,000 to 80,000, and by 1965 it had affiliates in seventeen states. During the ACLU's bi-annual conference in Colorado in 1964, the Supreme Court issued rulings on eight cases in which the ACLU was involved; the ACLU prevailed on seven of the eight. The ACLU played a role in Supreme Court decisions reducing censorship of literature and arts, protecting freedom of association, prohibiting racial segregation, excluding religion from public schools, and providing due process protection to criminal suspects. The ACLU's success arose from changing public attitudes; the American populace was more educated, more tolerant, and more willing to accept unorthodox behavior.

Legal battles concerning the separation of church and state originated in laws dating to 1938 which required religious instruction in school, or provided state funding for religious schools. The Catholic church was a leading proponent of such laws; and the primary opponents (the "separationists") were the ACLU, Americans United for Separation of Church and State, and the American Jewish Congress. The ACLU led the challenge in the 1947 "Everson v. Board of Education" case, in which Justice Hugo Black wrote "[t]he First Amendment has erected a wall between church and state... That wall must be kept high and impregnable." It was not clear that the Bill of Rights forbid state governments from supporting religious education, and strong legal arguments were made by religious proponents, arguing that the Supreme Court should not act as a "national school board", and that the Constitution did not govern social issues. However, the ACLU and other advocates of church/state separation persuaded the Court to declare such activities unconstitutional. Historian Samuel Walker writes that the ACLU's "greatest impact on American life" was its role in persuading the Supreme Court to "constitutionalize" so many public controversies.

In 1948, the ACLU prevailed in the "McCollum v. Board of Education" case, which challenged public school religious classes taught by clergy paid for from private funds. The ACLU also won cases challenging schools in New Mexico which were taught by clergy and had crucifixes hanging in the classrooms. In the 1960s, the ACLU, in response to member insistence, turned its attention to in-class promotion of religion. In 1960, 42 percent of American schools included Bible reading. In 1962, the ACLU published a policy statement condemning in-school prayers, observation of religious holidays, and Bible reading. The Supreme Court concurred with the ACLU's position, when it prohibited New York's in-school prayers in the 1962 "Engel v. Vitale" decision. Religious factions across the country rebelled against the anti-prayer decisions, leading them to propose the School Prayer Constitutional Amendment, which declared in-school prayer legal. The ACLU participated in a lobbying effort against the amendment, and the 1966 congressional vote on the amendment failed to obtain the required two-thirds majority.

However, not all cases were victories; ACLU lost cases in 1949 and 1961 which challenged state laws requiring commercial businesses to close on Sunday, the Christian Sabbath. The Supreme Court has never overturned such laws, although some states subsequently revoked many of the laws under pressure from commercial interests.

During the 1940s and 1950s, the ACLU continued its battle against censorship of art and literature. In 1948, the New York affiliate of the ACLU received mixed results from the Supreme Court, winning the appeal of Carl Jacob Kunz, who was convicted for speaking without a police permit, but losing the appeal of Irving Feiner who was arrested to prevent a breach of the peace, based on his oration denouncing president Truman and the American Legion. The ACLU lost the case of Joseph Beauharnais, who was arrested for group libel when he distributed literature impugning the character of African Americans.

Cities across America routinely banned movies because they were deemed to be "harmful", "offensive", or "immoral"censorship which was validated by the 1915 "Mutual v. Ohio" Supreme Court decision which held movies to be mere commerce, undeserving of first amendment protection. The film "The Miracle" was banned in New York in 1951, at the behest of the Catholic Church, but the ACLU supported the film's distributor in an appeal of the ban, and won a major victory in the 1952 decision "Joseph Burstyn, Inc. v. Wilson". The Catholic Church led efforts throughout the 1950s attempting to persuade local prosecutors to ban various books and movies, leading to conflict with the ACLU when the ACLU published it statement condemning the church's tactics. Further legal actions by the ACLU successfully defended films such as "M" and "la Ronde", leading the eventual dismantling of movie censorship. Hollywood continued employing self-censorship with its own Production Code, but in 1956 the ACLU called on Hollywood to abolish the Code.

The ACLU defended beat generation artists, including Allen Ginsberg who was prosecuted for his poem "Howl"; andin an unorthodox case the ACLU helped a coffee house regain its restaurant license which was revoked because its Beat customers were allegedly disturbing the peace and quiet of the neighborhood.

The ACLU lost an important press censorship case when, in 1957, the Supreme Court upheld the obscenity conviction of publisher Samuel Roth for distributing adult magazines. As late as 1953, books such as "Tropic of Cancer" and "From Here to Eternity" were still banned. But public standards rapidly became more liberal though the 1960s, and obscenity was notoriously difficult to define, so by 1971 prosecutions for obscenity had halted.

A major aspect of civil liberties progress after World War II was the undoing centuries of racism in federal, state, and local governments an effort generally associated with the civil rights movement. Several civil liberties organizations worked together for progress, including the National Association for the Advancement of Colored People (NAACP), the ACLU, and the American Jewish Congress. The NAACP took primary responsibility for Supreme Court cases (often led by lead NAACP attorney Thurgood Marshall), with the ACLU focusing on police misconduct, and supporting the NAACP with amicus briefs. The NAACP achieved a key victory in 1950 with the "Henderson v. United States" decision that ended segregation in interstate bus and rail transportation.

In 1954, the ACLU filed an amicus brief in the case of "Brown v. Board of Education", which led to the ban on racial segregation in US public schools. Southern states instituted a McCarthyism-style witch-hunt against the NAACP, attempting it to disclose membership lists. The ACLU's fight against racism was not limited to segregation; in 1964 the ACLU provided key support to plaintiffs, primarily lower income urban residents, in "Reynolds v. Sims", which required states to establish the voting districts in accordance with the "one person, one vote" principle.

The ACLU regularly tackled police misconduct issues, starting with the 1932 case "Powell v. Alabama" (right to an attorney), and including 1942's "Betts v. Brady" (right to an attorney), and 1951's "Rochin v. California" (involuntary stomach pumping). In the late 1940s, several ACLU local affiliates established permanent committees to address policing issues. During the 1950s and 1960s, the ACLU was responsible for substantially advancing the legal protections against police misconduct. The Philadelphia affiliate was responsible for causing the City of Philadelphia, in 1958, to create the nation's first civilian police review board. In 1959, the Illinois affiliate published the first report in the nation, "Secret Detention by the Chicago Police", which documented unlawful detention by police.

Some of the most well known ACLU successes came in the 1960s, when the ACLU prevailed in a string of cases limiting the power of police to gather evidence; in 1961's "Mapp v. Ohio", the Supreme court required states to obtain a warrant before searching a person's home. The "Gideon v. Wainwright" decision in 1963 provided legal representation to indigents. In 1964, the ACLU persuaded the Court, in "Escobedo v. Illinois", to permit suspects to have an attorney present during questioning. And, in 1966, "Miranda v. Arizona" federal decision required police to notify suspects of their constitutional rights, which was later extended to juveniles in the following year's "in re Gault" (1967) federal ruling. Although many law enforcement officials criticized the ACLU for expanding the rights of suspects, police officers themselves took advantage of the ACLU. For example, when the ACLU represented New York City policemen in their lawsuit which objected to searches of their workplace lockers. In the late 1960s, civilian review boards in New York City and Philadelphia were abolished, over the ACLU's objection.

The 1960s was a tumultuous era in the United States, and public interest in civil liberties underwent an explosive growth. Civil liberties actions in the 1960s were often led by young people, and often employed tactics such as sit ins and marches. Protests were often peaceful, but sometimes employed militant tactics. The ACLU played a central role in all major civil liberties debates of the 1960s, including new fields such as gay rights, prisoner's rights, abortion, rights of the poor, and the death penalty. Membership in the ACLU increased from 52,000 at the beginning of the decade, to 104,000 in 1970. In 1960, there were affiliates in seven states, and by 1974 there were affiliates in 46 states. During the 1960s, the ACLU underwent a major transformation tactics; it shifted emphasis from legal appeals (generally involving amicus briefs submitted to the Supreme Court) to direct representation of defendants when they were initially arrested. At the same time, the ACLU transformed its style from "disengaged and elitist" to "emotionally engaged". The ACLU published a breakthrough document in 1963, titled "How Americans Protest", which was borne of frustration with the slow progress in battling racism, and which endorsed aggressive, even militant protest techniques.

African-American protests in the South accelerated in the early 1960s, and the ACLU assisted at every step. After four African-American college students staged a sit-in in a segregated North Carolina department store, the sit-in movement gained momentum across the United States. During 1960–61, the ACLU defended black students arrested for demonstrating in North Carolina, Florida, and Louisiana. The ACLU also provided legal help for the Freedom Rides in 1961, the integration of the University of Mississippi, the Birmingham campaign in 1963, and the 1964 Freedom Summer.

The NAACP was responsible for managing most sit-in related cases that made it to the Supreme Court, winning nearly every decision. But it fell to the ACLU and other legal volunteer efforts to provide legal representation to hundreds of protestorswhite and blackwho were arrested while protesting in the South. The ACLU joined with other civil liberties groups to form the Lawyers Constitutional Defense Committee (LCDC) which subsequently provided legal representation to many of the protesters. The ACLU provided the majority of the funding for the LCDC.

In 1964, the ACLU opened up a major office in Atlanta, Georgia, dedicated to serving Southern issues. Much of the ACLU's progress in the South was due to Charles Morgan, Jr., the charismatic leader of the Atlanta office. He was responsible for desegregating juries ("Whitus v. Georgia"), desegregating prisons ("Lee v. Washington"), and reforming election laws. The ACLU's southern office also defended African-American congressman Julian Bond in "Bond v. Floyd", when the Georgia congress refused to formally induct Bond into the legislature. Another widely publicized case defended by Morgan was that of Army doctor Howard Levy, who was convicted of refusing to train Green Berets. Despite raising the defense that the Green Berets were committing war crimes in Vietnam, Levy lost on appeal in "Parker v. Levy", 417 US 733 (1974).

In 1969, the ACLU won a major victory for free speech, when it defended Dick Gregory after he was arrested for peacefully protesting against the mayor of Chicago. The court ruled in "Gregory v. Chicago" that a speaker cannot be arrested for disturbing the peace when the hostility is initiated by someone in the audience, as that would amount to a "heckler's veto".

The ACLU was at the center of several legal aspects of the Vietnam war: defending draft resisters, challenging the constitutionality of the war, the potential impeachment of Richard Nixon, and the use of national security concerns to preemptively censor newspapers.

David J. Miller was the first person prosecuted for burning his draft card. The New York affiliate of the ACLU appealed his 1965 conviction (367 F.2d 72: "United States of America v. David J. Miller", 1966), but the Supreme Court refused to hear the appeal. Two years later, the Massachusetts affiliate took the card-burning case of David O'Brien to the Supreme Court, arguing that the act of burning was a form of symbolic speech, but the Supreme Court upheld the conviction in "United States v. O'Brien", 391 US 367 (1968). Thirteen-year-old Junior High student Mary Tinker wore a black armband to school in 1965 to object to the war, and was suspended from school. The ACLU appealed her case to the Supreme Court and won a victory in "Tinker v. Des Moines Independent Community School District". This critical case established that the government may not establish "enclaves" such as schools or prisons where all rights are forfeit.
The ACLU defended Sydney Street, who was arrested for burning an American flag to protest the reported assassination of civil rights leader James Meredith. In the "Street v. New York" decision, the court agreed with the ACLU that encouraging the country to abandon one of its national symbols was constitutionally protected form of expression. The ACLU successfully defended Paul Cohen, who was arrested for wearing a jacket with the words "fuck the draft" on its back, while he walked through the Los Angeles courthouse. The Supreme Court, in "Cohen v. California", held that the vulgarity of the wording was essential to convey the intensity of the message.

Non-war related free speech rights were also advanced during the Vietnam war era; in 1969, the ACLU defended a Ku Klux Klan member who advocated long-term violence against the government, and the Supreme Court concurred with the ACLU's argument in the landmark decision "Brandenburg v. Ohio", which held that only speech which advocated "imminent" violence could be outlawed.

A major crisis gripped the ACLU in 1968 when a debate erupted over whether to defend Benjamin Spock and the Boston Five against federal charges that they encouraged draftees to avoid the draft. The ACLU board was deeply split over whether to defend the activists; half the board harbored anti-war sentiments, and felt that the ACLU should lend its resources to the cause of the Boston Five. The other half of the board believed that civil liberties were not at stake, and the ACLU would be taking a political stance. Behind the debate was the longstanding ACLU tradition that it was politically impartial, and provided legal advice without regard to the political views of the defendants. The board finally agreed to a compromise solution that permitted the ACLU to defend the anti-war activists, without endorsing the activist's political views. Some critics of the ACLU suggest that the ACLU became a partisan political organization following the Spock case. After the Kent State shootings in 1970, ACLU leaders took another step towards politics by passing a resolution condemning the Vietnam War. The resolution was based in a variety of legal arguments, including civil liberties violations and a claim that the war was illegal.

Also in 1968, the ACLU held an internal symposium to discuss its dual roles: providing "direct" legal support (defense for accused in their initial trial, benefiting only the individual defendant), and appellate support (providing amicus briefs during the appeal process, to establish widespread legal precedent). Historically, the ACLU was known for its appellate work which led to landmark Supreme Court decisions, but by 1968, 90% of the ACLU's legal activities involved direct representation. The symposium concluded that both roles were valid for the ACLU.

The ACLU supported "The New York Times" in its 1971 suit against the government, requesting permission to publish the Pentagon papers. The court upheld the "Times" and ACLU in the "New York Times Co. v. United States" ruling, which held that the government could not preemptively prohibit the publication of classified information and had to wait until after it was published to take action.

As the Watergate saga unfolded, the ACLU became the first national organization to call for Nixon's impeachment. This, following the resolution opposing the Vietnam war, was a second major decision that caused critics of the ACLU, particularly conservatives, to claim that the ACLU had evolved into a liberal political organization.

The decade from 1965 to 1975 saw an expansion of the field of civil liberties. Administratively, the ACLU responded by appointing Aryeh Neier to take over from Pemberton as Executive Director in 1970. Neier embarked on an ambitious program to expand the ACLU; he created the ACLU Foundation to raise funds, and he created several new programs to focus the ACLU's legal efforts. By 1974, ACLU membership had reached 275,000.

During those years, the ACLU led the way in expanding legal rights in three directions: new rights for persons within government-run "enclaves", new rights for victim groups, and privacy rights for mainstream citizens. At the same time, the organization grew substantially. The ACLU helped develop the field of constitutional law that governs "enclaves", which are groups of persons that live in conditions under government control. Enclaves include mental hospital patients, members of the military, and prisoners, and students (while at school). The term enclave originated with Supreme Court justice Abe Fortas's use of the phrase "schools may not be enclaves of totalitarianism" in the "Tinker v. Des Moines" decision.

The ACLU initiated the legal field of student's rights with the "Tinker v. Des Moines" case, and expanded it with cases such as "Goss v. Lopez" which required schools to provide students an opportunity to appeal suspensions.

As early as 1945, the ACLU had taken a stand to protect the rights of the mentally ill, when it drafted a model statute governing mental commitments. In the 1960s, the ACLU opposed involuntary commitments, unless it could be demonstrated that the person was a danger to himself or the community. In the landmark 1975 "O'Connor v. Donaldson" decision the ACLU represented a non-violent mental health patient who had been confined against his will for 15 years, and persuaded the Supreme Court to rule such involuntary confinements illegal. The ACLU has also defended the rights of mentally ill individuals who are not dangerous, but who create disturbances. The New York chapter of the ACLU defended Billie Boggs, a mentally ill woman who exposed herself and defecated and urinated in public.

Prior to 1960, prisoners had virtually no recourse to the court system, because courts considered prisoners to have no civil rights. That changed in the late 1950s, when the ACLU began representing prisoners that were subject to police brutality, or deprived of religious reading material. In 1968, the ACLU successfully sued to desegregate the Alabama prison system; and in 1969, the New York affiliate adopted a project to represent prisoners in New York prisons. Private attorney Phil Hirschkop discovered degrading conditions in Virginia prisons following the Virginia State Penitentiary strike, and won an important victory in 1971's "Landman v. Royster" which prohibited Virginia from treating prisoners in inhumane ways. In 1972, the ACLU consolidated several prison rights efforts across the nation and created the National Prison Project. The ACLU's efforts led to landmark cases such as "Ruiz v. Estelle" (requiring reform of the Texas prison system) and in 1996 US Congress enacted the Prison Litigation Reform Act (PLRA) which codified prisoners' rights.

The ACLU, during the 1960s and 1970s, expanded its scope to include what it referred to as "victim groups", namely women, the poor, and homosexuals. Heeding the call of female members, the ACLU endorsed the Equal Rights Amendment in 1970 and created the Women's Rights Project in 1971. The Women's Rights Project dominated the legal field, handling more than twice as many cases as the National Organization for Women, including breakthrough cases such as "Reed v. Reed", "Frontiero v. Richardson", and " Taylor v. Louisiana".

ACLU leader Harriet Pilpel raised the issue of the rights of homosexuals in 1964, and two years later the ACLU formally endorsed gay rights. In 1972, ACLU cooperating attorneys in Oregon filed the first federal civil rights case involving a claim of unconstitutional discrimination against a gay or lesbian public school teacher. The US District Court held that a state statute that authorized school districts to fire teachers for "immorality" was unconstitutionally vague, and awarded monetary damages to the teacher. The court refused to reinstate the teacher, and the Ninth Circuit Court of Appeals affirmed that refusal by a 2 to 1 vote. "Burton v. Cascade School District", 353 F. Supp. 254 (D. Or. 1972), aff'd 512 F.2d 850 (1975). In 1973, the ACLU created the Sexual Privacy Project (later the Gay and Lesbian Rights Project) which combated discrimination against homosexuals. This support continues even today. After then-Senator Larry Craig was arrested for soliciting sex in a public restroom, the ACLU wrote an amicus brief for Craig, saying that sex between consenting adults in public places was protected under privacy rights.

Rights of the poor was another area that was expanded by the ACLU. In 1966 and again in 1968, activists within the ACLU encouraged the organization to adopt a policy overhauling the welfare system, and guaranteeing low-income families a baseline income; but the ACLU board did not approve the proposals. The ACLU played a key role in the 1968 "King v. Smith" decision, where the Supreme Court ruled that welfare benefits for children could not be denied by a state simply because the mother cohabited with a boyfriend.

The Reproductive Freedom Project is an institution founded in 1974 (within the larger context of ACLU) that is committed to defend individuals who feel abused by the government, especially with cases pertaining to a lack of access to abortions, birth control, or sexual education.

The ACLU continues to defend individuals who feel abused or improperly treated by the government. Often the American Civil Liberties Union is the group to stand up for an individual when being discriminated against because of their religion, sex, gender, sexuality, race, or class, even when they are not the popular opinion. The Reproductive Freedom Project, however, goes deeper than the ACLU. The Project promotes sexual and reproductive health by providing lessons about contraception, knowing about one's reproductive rights and assisting with the financial burdens of abortions and all of the logistics that may go into that.

The Reproductive Freedom Project of ACLU, according to their mission statement, actively works provide access to any and all reproductive health care for any human, regardless of race, gender, socioeconomic status, sexual orientation, or political standing. In some cases, Reproductive Freedom Programs fund ultrasounds and abortions and any lodging, meals, or transportation that go with that. Because women have reported finding it necessary to cross state lines or wait weeks for an abortion, The Reproductive Freedom Project states that they want to fight for individuals "state by state and law by law" until every individual can pursue the kind of lifestyle they want. As stated on their website, "states have enacted more restrictions to abortion than they did in the previous 10 years combined". The ACLU claims to be committed to fighting injustices with access to education on what accessibilities one has to abortions, birth control, religious rights, as well as trying to diminish abstinence-only sexual education, for ACLU claims that abstinence only education promotes a lack of willingness to use contraceptives.

As referenced in the larger ACLU article, in 1929, the ACLU defended Margaret Sanger's right to educate the general public about forms of birth control. In 1980, the Project filed "Poe v. Lynchburg Training School" after 8,000 women had been sterilized without their authorization. In 1985, the state decided to provide counseling and medical treatment for problems caused by what had happened 5 years prior. In 1977, the ACLU took part in and litigated "Walker v. Pierce", the Supreme Court case that created federal regulations to prevent Medicaid patients from being sterilized without their knowledge or consent. In 1981–1990, the Project litigated "Hodgson v. Minnesota", a case defending the rights of teenagers who chose not to comply with a state law requiring them to receive parental permission for an abortion. In the 1990s, the Project provided legal assistance and resource kits to those who were being attacked for educating about sexuality and AIDS. In 1995, the Project filed "Curtis v. School Committee of Falmouth", the US's first condom availability program.

The Reproductive Freedom Project is presently working on three ideas: (1) to "reverse the shortage of trained abortion providers throughout the country" (2) to "block state and federal welfare "reform" proposals that cut off benefits for children who are born to women already receiving welfare, unmarried women, or teenagers" and (3) to "stop the elimination of vital reproductive health services as a result of hospital mergers and health care networks". The Project says they are hoping to achieve these goals through legal action and litigation.

The right to privacy is not explicitly identified in the US Constitution, but the ACLU led the charge to establish such rights in the indecisive 1961 "Poe v. Ullman" case, which addressed a state statute outlawing contraception. The issue arose again in "Griswold v. Connecticut" (1965), and this time the Supreme Court adopted the ACLU's position, and formally declared a right to privacy. The New York affiliate of the ACLU pushed to eliminate anti-abortion laws starting in 1964, a year before "Griswold" was decided, and in 1967 the ACLU itself formally adopted the right to abortion as a policy. The ACLU led the defense in "United States v. Vuitch" which expanded the right of physicians to determine when abortions were necessary. These efforts culminated in one of the most controversial Supreme Court decisions of all time, "Roe v. Wade", which legalized abortion in the first three months of pregnancy. The ACLU successfully argued against state bans on interracial marriage, in the case of "Loving v. Virginia" (1967).

Related to privacy, the ACLU engaged in several battles to ensure that government records about individuals were kept private, and to give individuals the right to review their records. The ACLU supported several measures, including the 1970 Fair Credit Reporting Act required credit agencies to divulge credit information to individuals; the 1973 Family Educational Rights and Privacy Act, which provided students the right to access their records; and the 1974 Privacy Act which prevented the federal government from disclosing personal information without good cause.

In the early 1970s, conservatives and libertarians began to criticize the ACLU for being too political and too liberal. Legal scholar Joseph W. Bishop wrote that the ACLU's trend to partisanship started with its defense of Spock's anti-war protests. Critics also blamed the ACLU for encouraging the Supreme Court to embrace judicial activism. Critics claimed that the ACLU's support of controversial decisions like "Roe v. Wade" and "Griswold v. Connecticut" violated the intention of the authors of the Bill of Rights. The ACLU became an issue in the 1988 presidential campaign, when Republican candidate George H. W. Bush accused Democratic candidate Michael Dukakis (a member of the ACLU) of being a "card carrying member of the ACLU".

It is the policy of the ACLU to support the civil liberties of defendants regardless of their ideological stance. The ACLU takes pride in defending individuals with unpopular viewpoints, such as George Wallace, George Lincoln Rockwell, and KKK members. The ACLU has defended American Nazis many times, and their actions often brought protests, particularly from American Jews.

In 1977, a small group of American Nazis, led by Frank Collin, applied to the town of Skokie, Illinois, for permission to hold a demonstration in the town park. Skokie at the time had a majority population of Jews, totaling 40,000 of 70,000 citizens, some of whom were survivors of Nazi concentration camps. Skokie refused to grant permission, and an Illinois judge supported Skokie and prohibited the demonstration. Skokie immediately passed three ordinances aimed at preventing the group from meeting in Skokie. The ACLU assisted Collin and appealed to federal court. The appeal dragged on for a year, and the ACLU eventually prevailed in "Smith v. Collin", 447 F.Supp. 676.

The Skokie case was heavily publicized across America, partially because Jewish groups such as the Jewish Defense League and Anti Defamation League strenuously objected to the demonstration, leading many members of the ACLU to cancel their memberships. The Illinois affiliate of the ACLU lost about 25% of its membership and nearly one-third of its budget. The financial strain from the controversy led to layoffs at local chapters. After the membership crisis died down, the ACLU sent out a fund-raising appeal which explained their rationale for the Skokie case, and raised over $500,000 ($ in dollars).

The inauguration of Ronald Reagan as president in 1981, ushered in an eight-year period of conservative leadership in the US government. Under Reagan's leadership, the government pushed a conservative social agenda.

Fifty years after the Scopes trial, the ACLU found itself fighting another classroom case, the Arkansas 1981 creationism statute, which required schools to teach the biblical account of creation as a scientific alternative to evolution. The ACLU won the case in the "McLean v. Arkansas" decision.

In 1982, the ACLU became involved in a case involving the distribution of child pornography ("New York v. Ferber"). In an amicus brief, the ACLU argued that child pornography that violates the three prong obscenity test should be outlawed, but that the law in question was overly restrictive because it outlawed artistic displays and otherwise non-obscene material. The court did not adopt the ACLU's position.

During the 1988 presidential election, Vice President George H. W. Bush noted that his opponent Massachusetts Governor Michael Dukakis had described himself as a "card-carrying member of the ACLU" and used that as evidence that Dukakis was "a strong, passionate liberal" and "out of the mainstream". The phrase subsequently was used by the organization in an advertising campaign.

In 1990, the ACLU defended Lieutenant Colonel Oliver North, whose conviction was tainted by coerced testimonya violation of his fifth amendment rightsduring the Iran–Contra affair, where Oliver North was involved in illegal weapons sales to Iran in order to illegally fund the Contra guerillas.

In 1997, ruling unanimously in the case of "Reno v. American Civil Liberties Union", the Supreme Court voted down anti-indecency provisions of the Communications Decency Act (the CDA), finding they violated the freedom of speech provisions of the First Amendment. In their decision, the Supreme Court held that the CDA's "use of the undefined terms 'indecent' and 'patently offensive' will provoke uncertainty among speakers about how the two standards relate to each other and just what they mean."

In 2000, Marvin Johnson, a legislative counsel for the ACLU, stated that proposed anti-spam legislation infringed on free speech by denying anonymity and by forcing spam to be labeled as such, "Standardized labeling is compelled speech." He also stated, "It's relatively simple to click and delete." The debate found the ACLU joining with the Direct Marketing Association and the Center for Democracy and Technology in 2000 in criticizing a bipartisan bill in the House of Representatives. As early as 1997, the ACLU had taken a strong position that nearly all spam legislation was improper, although it has supported "opt-out" requirements in some cases. The ACLU opposed the 2003 CAN-SPAM act suggesting that it could have a chilling effect on speech in cyberspace. It has been criticized for this position.

In November 2000, 15 African-American residents of Hearne, Texas, were indicted on drug charges after being arrested in a series of "drug sweeps". The ACLU filed a class-action lawsuit, "Kelly v. Paschall", on their behalf, alleging that the arrests were unlawful. The ACLU contended that 15 percent of Hearne's male African-American population aged 18 to 34 were arrested based only on the "uncorroborated word of a single unreliable confidential informant coerced by police to make cases." On May 11, 2005, the ACLU and Robertson County announced a confidential settlement of the lawsuit, an outcome which "both sides stated that they were satisfied with." The District Attorney dismissed the charges against the plaintiffs of the suit. The 2009 film "American Violet" depicts this case.

In 2000, the ACLU's Massachusetts affiliate represented the North American Man Boy Love Association (NAMBLA), on first amendment grounds, in the "Curley v. NAMBLA" wrongful death civil suit. The organization was sued because a man who raped and murdered a child had visited the NAMBLA website. Also in 2000, the ACLU lost the "Boy Scouts of America v. Dale" case, which had asked the Supreme Court to require the Boy Scouts of America to drop their policy of prohibiting homosexuals from becoming Boy Scout leaders.

In March 2004, the ACLU, along with Lambda Legal and the National Center for Lesbian Rights, sued the state of California on behalf of six same-sex couples who were denied marriage licenses. That case, "Woo v. Lockyer", was eventually consolidated into "In re Marriage Cases", the California Supreme Court case which led to same-sex marriage being available in that state from June 16, 2008, until Proposition 8 was passed on November 4, 2008. The ACLU, Lambda Legal and the National Center for Lesbian Rights then challenged Proposition 8 and won.
During the 2004 trial regarding allegations of Rush Limbaugh's drug abuse, the ACLU argued that his privacy should not have been compromised by allowing law enforcement examination of his medical records. In June 2004, the school district in Dover, Pennsylvania, required that its high school biology students listen to a statement which asserted that the theory of evolution is not fact and mentioning intelligent design as an alternative theory. Several parents called the ACLU to complain, because they believed that the school was promoting a religious idea in the classroom and violating the Establishment Clause of the First Amendment. The ACLU, joined by Americans United for Separation of Church and State, represented the parents in a lawsuit against the school district. After a lengthy trial, Judge John E. Jones III ruled in favor of the parents in the "Kitzmiller v. Dover Area School District" decision, finding that intelligent design is not science and permanently forbidding the Dover school system from teaching intelligent design in science classes.

In April 2006, Edward Jones and the ACLU sued the City of Los Angeles, on behalf of Robert Lee Purrie and five other homeless people, for the city's violation of the 8th and 14th Amendments to the US Constitution, and Article I, sections 7 and 17 of the California Constitution (supporting due process and equal protection, and prohibiting cruel and unusual punishment). The Court ruled in favor of the ACLU, stating that, "the LAPD cannot arrest people for sitting, lying, or sleeping on public sidewalks in Skid Row." Enforcement of section 41.18(d) 24 hours a day against persons who have nowhere else to sit, lie, or sleep, other than on public streets and sidewalks, is breaking these amendments. The Court said that the anti-camping ordinance is "one of the most restrictive municipal laws regulating public spaces in the United States". Jones and the ACLU wanted a compromise in which the LAPD is barred from enforcing section 41.18(d) (arrest, seizure, and imprisonment) in Skid Row between the hours of 9:00 p.m. and 6:30 am. The compromise plan permits the homeless to sleep on the sidewalk, provided they are not "within 10 feet of any business or residential entrance" and only between these hours. One of the motivations for the compromise is the shortage of space in the prison system. Downtown development business interests and the Central City Association (CCA) were against the compromise. Police Chief William Bratton said the case had slowed the police effort to fight crime and clean up Skid Row, and that when he was allowed to clean up Skid Row, real estate profited. On September 20, 2006, the Los Angeles City Council voted to reject the compromise. On October 3, 2006, police arrested Skid Row's transients for sleeping on the streets for the first time in months.

In 2006, the ACLU of Washington State joined with a pro-gun rights organization, the Second Amendment Foundation, and prevailed in a lawsuit against the North Central Regional Library District (NCRL) in Washington for its policy of refusing to disable restrictions upon an adult patron's request. Library patrons attempting to access pro-gun web sites were blocked, and the library refused to remove the blocks. In 2012, the ACLU sued the same library system for refusing to temporarily, at the request of an adult patron, disable Internet filters which blocked access to Google Images.

In 2006, the ACLU challenged a Missouri law that prohibited picketing outside of veterans' funerals. The suit was filed in support of the Westboro Baptist Church and Shirley Phelps-Roper, who were threatened with arrest. The Westboro Baptist Church is well known for their picket signs that contain messages such as, "God Hates Fags", "Thank God for Dead Soldiers", and "Thank God for 9/11". The ACLU issued a statement calling the legislation a "law that infringes on Shirley Phelps-Roper's rights to religious liberty and free speech". The ACLU prevailed in the lawsuit.

In light of the Supreme Court's "Heller" decision recognizing that the Constitution protects an individual right to bear arms, ACLU of Nevada took a position of supporting "the individual's right to bear arms subject to constitutionally permissible regulations" and pledged to "defend this right as it defends other constitutional rights". Since 2008, the ACLU has increasingly assisted gun owners in recovering firearms that have been seized illegally by law enforcement.

In 2009, the ACLU filed an amicus brief in "Citizens United v. FEC", arguing that the Bipartisan Campaign Reform Act of 2002 violated the First Amendment right to free speech by curtailing political speech. This stance on the landmark "Citizens United" case caused considerable disagreement within the organization, resulting in a discussion about its future stance during a quarterly board meeting in 2010. On March 27, 2012, the ACLU reaffirmed its stance in support of the Supreme Court's "Citizens United" ruling, at the same time voicing support for expanded public financing of election campaigns and stating the organization would firmly oppose any future constitutional amendment limiting free speech.

In 2010, the ACLU of Illinois was inducted into the Chicago Gay and Lesbian Hall of Fame as a Friend of the Community.

In 2011, the ACLU started its Don't Filter Me project, countering LGBT-related Internet censorship in public schools in the United States.

On January 7, 2013, the ACLU reached a settlement with the federal government in "Collins v. United States" that provided for the payment of full separation pay to servicemembers discharged under "don't ask, don't tell" since November 10, 2004, who had previously been granted only half that. Some 181 were expected to receive about $13,000 each.

After the September 11 attacks, the federal government instituted a broad range of new measures to combat terrorism, including the passage of the Patriot Act. The ACLU challenged many of the measures, claiming that they violated rights regarding due process, privacy, illegal searches, and cruel and unusual punishment. An ACLU policy statement states:

During the ensuing debate regarding the proper balance of civil liberties and security, the membership of the ACLU increased by 20%, bringing the group's total enrollment to 330,000. The growth continued, and by August 2008 ACLU membership was greater than 500,000. It remained at that level through 2011.

The ACLU has been a vocal opponent of the USA PATRIOT Act of 2001, the PATRIOT 2 Act of 2003, and associated legislation made in response to the threat of domestic terrorism. In response to a requirement of the USA PATRIOT Act, the ACLU withdrew from the Combined Federal Campaign charity drive. The campaign imposed a requirement that ACLU employees must be checked against a federal anti-terrorism watch list. The ACLU has stated that it would "reject $500,000 in contributions from private individuals rather than submit to a government 'blacklist' policy."

In 2004, the ACLU sued the federal government in "American Civil Liberties Union v. Ashcroft" on behalf of Nicholas Merrill, owner of an Internet service provider. Under the provisions of the Patriot Act, the government had issued national security letters to Merrill to compel him to provide private Internet access information from some of his customers. In addition, the government placed a gag order on Merrill, forbidding him from discussing the matter with anyone.

In January 2006, the ACLU filed a lawsuit, "ACLU v. NSA", in a federal district court in Michigan, challenging government spying in the NSA warrantless surveillance controversy. On August 17, 2006, that court ruled that the warrantless wiretapping program is unconstitutional and ordered it ended immediately. However, the order was stayed pending an appeal. The Bush administration did suspend the program while the appeal was being heard. In February 2008, the US Supreme Court turned down an appeal from the ACLU to let it pursue a lawsuit against the program that began shortly after the September 11 terror attacks.

The ACLU and other organizations also filed separate lawsuits around the country against telecommunications companies. The ACLU filed a lawsuit in Illinois ("Terkel v. AT&T") which was dismissed because of the state secrets privilege and two others in California requesting injunctions against AT&T and Verizon. On August 10, 2006, the lawsuits against the telecommunications companies were transferred to a federal judge in San Francisco.

The ACLU represents a Muslim-American who was detained but never accused of a crime in "Ashcroft v. al-Kidd", a civil suit against former Attorney General John Ashcroft. In January 2010, the American military released the names of 645 detainees held at the Bagram Theater Internment Facility in Afghanistan, modifying its long-held position against publicizing such information. This list was prompted by a Freedom of Information Act lawsuit filed in September 2009 by the ACLU, whose lawyers had also requested detailed information about conditions, rules and regulations.

The ACLU has also criticized targeted killings of American citizens who fight against the United States. In 2011, the ACLU criticized the killing of radical Muslim cleric Anwar al-Awlaki on the basis that it was a violation of his Fifth Amendment right to not be deprived of life, liberty, or property without due process of law.

Following Donald Trump's election as President on November 8, 2016, the ACLU responded on Twitter saying: "Should President-elect Donald Trump attempt to implement his unconstitutional campaign promises, we'll see him in court." On January 27, 2017, President Trump signed an executive order indefinitely barring "Syrian refugees from entering the United States, suspended all refugee admissions for 120 days and blocked citizens of seven Muslim-majority countries, refugees or otherwise, from entering the United States for 90 days: Iran, Iraq, Libya, Somalia, Sudan, Syria and Yemen". The ACLU responded by filing a lawsuit against the ban on behalf of Hameed Khalid Darweesh and Haider Sameer Abdulkhaleq Alshawi, who had been detained at JFK International Airport. On January 28, 2017, a US District Court Judge Ann Donnelly granted a temporary injunction against the immigration order, saying it was difficult to see any harm from allowing the newly arrived immigrants from entering the country.
In response to Trump's order, the ACLU raised more than $24 million from more than 350,000 individual online donations in a two-day period. This amounted to six times what the ACLU normally receives in online donations in a year. Celebrities donating included Chris Sacca (who offered to match other people's donations and ultimately gave $150,000), Rosie O'Donnell, Judd Apatow, Sia, John Legend, and Adele. The number of members of the ACLU doubled in the time from the election to end of January to 1 million.

Grants and contributions increased from $106,628,381 USD reported by the 2016 year-end income statement to $274,104,575 by the 2017 year-end statement. The primary source of revenue from the segment came from individual contributions in response to the Trump presidency's infringements on civil liberties. The surge in donations more than doubled the total support and revenue of the non-profit organization year over year from 2016 to 2017.

Following WikiLeaks founder Julian Assange's arrest, Ben Wizner from the ACLU said that if authorities were to prosecute Assange "for violating U.S. secrecy laws [it] would set an especially dangerous precedent for U.S. journalists, who routinely violate foreign secrecy laws to deliver information vital to the public's interest."

The ACLU of Tennessee protested the shooting of Jocques Clemmons which occurred in Nashville, Tennessee on February 10, 2017. On May 11, 2017, as Glenn Funk, the district attorney of Davidson County, decided not to prosecute police officer Joshua Lippert, they called for an independent community review board and for Nashville police officers to wear body cameras, which was approved by local voters in a referendum.

On June 21, 2018, a leaked memo showed that the ACLU has explicitly endorsed the view that free speech can harm marginalized groups by undermining their civil rights. "Speech that denigrates such groups can inflict serious harms and is intended to and often will impede progress toward equality," the ACLU declared in guidelines governing case selection and "Conflicts Between Competing Values or Priorities." The ACLU had previously defended the free speech rights of the KKK and Nazis.

The ACLU argued that a Massachusetts law, later unanimously struck down by the Supreme Court, was constitutional. The law prohibited sidewalk counselors from approaching women outside abortion facilities and offering them alternatives to abortion but allowed escorts to speak with them and accompany them into the building. In overturning the law in McCullen v. Coakley, the Supreme Court unanimously ruled that it violated the counselors' freedom of speech and that it was viewpoint discrimination.







</doc>
<doc id="1955" url="https://en.wikipedia.org/wiki?curid=1955" title="Adobe Inc.">
Adobe Inc.

Adobe Inc. ( ) is an American multinational computer software company headquartered in San Jose, California. It has historically focused upon the creation of multimedia and creativity software products, with a more recent foray towards digital marketing software. Adobe is best known for its Adobe Flash web software ecosystem, Photoshop image editing software, Acrobat Reader, the Portable Document Format (PDF), and Adobe Creative Suite, as well as its successor Adobe Creative Cloud.

Adobe was founded in December 1982 by John Warnock and Charles Geschke, who established the company after leaving Xerox PARC in order to develop and sell the PostScript page description language. In 1985, Apple Computer licensed PostScript for use in its LaserWriter printers, which helped spark the desktop publishing revolution.

, Adobe has more than 21,000 employees worldwide, about 40% of whom work in San Jose. Adobe also has major development operations in Newton, Massachusetts; New York City, New York; Minneapolis, Minnesota; Lehi, Utah; Seattle, Washington; and San Francisco, California in the United States. It also has major development operations in Noida and Bangalore in India.

The company was started in John Warnock's garage. The name of the company, "Adobe", comes from Adobe Creek in Los Altos, California, which ran behind Warnock's house. Adobe's corporate logo features a stylized "A" and was designed by Marva Warnock, graphic designer and John Warnock's wife.

Steve Jobs asked to buy the company for five million dollars in 1982, but Warnock and Geschke refused. Their investors urged them to work something out with Jobs, so they agreed to sell him shares worth 19 percent of the company, for which Jobs paid a five-times multiple of their company's valuation at the time, plus a five-year license fee for PostScript, in advance. The purchase and advance made Adobe the first company in the history of Silicon Valley to become profitable in its first year.

Warnock and Geschke considered various business options including a copy-service business and a turnkey system for office printing. Then they chose to focus on developing specialized printing software, and created the Adobe PostScript page description language.

PostScript was the first truly international standard for computer printing as it included algorithms describing the letter-forms of many languages. Adobe added kanji printer products in 1988. Warnock and Geschke were also able to bolster the credibility of Postscript by connecting with a typesetting manufacturer. They weren't able to work with Compugraphic, but then worked with Linotype to license the Helvetica and Times Roman fonts (through the Linotron 100). By 1987, PostScript had become the industry-standard printer language with more than 400 third-party software programs and licensing agreements with 19 printer companies.

Warnock described the language as "extensible", in its ability to apply graphic arts standards to office printing.

Adobe's first products after PostScript were digital fonts, which they released in a proprietary format called Type 1. Apple subsequently developed a competing standard, TrueType, which provided full scalability and precise control of the pixel pattern created by the font's outlines, and licensed it to Microsoft.

In the mid-1980s, Adobe entered the consumer software market with Illustrator, a vector-based drawing program for the Apple Macintosh. Illustrator, which grew from the firm's in-house font-development software, helped popularize PostScript-enabled laser printers.

Adobe entered NASDAQ in August 1986. Its revenue has grown from roughly $1 billion in 1999 to $4 billion in 2012. Adobe's fiscal years run from December to November. For example, the 2007 fiscal year ended on November 30, 2007.

In 1989, Adobe introduced what was to become its flagship product, a graphics editing program for the Macintosh called Photoshop. Stable and full-featured, Photoshop 1.0 was ably marketed by Adobe and soon dominated the market.

In 1993, Adobe introduced PDF, the Portable Document Format, and its Adobe Acrobat and Reader software. PDF is now an International Standard: ISO 32000-1:2008.

In December 1991, Adobe released Adobe Premiere, which Adobe rebranded as Adobe Premiere Pro in 2003. In 1992, Adobe acquired OCR Systems, Inc. In 1994, Adobe acquired Aldus and added PageMaker and After Effects to its product line later in the year; it also controls the TIFF file format. In the same year, Adobe acquired LaserTools Corp and Compution Inc. In 1995, Adobe added FrameMaker, the long-document DTP application, to its product line after Adobe acquired Frame Technology Corp. In 1996, Adobe Inc added Ares Software Corp. In 2002, Adobe acquired Canadian company Accelio (also known as JetForm).

On December 12, 2005, Adobe acquired its main rival, Macromedia, in a stock swap valued at about $3.4 billion, adding ColdFusion, Contribute, Captivate, Adobe Connect (formerly Macromedia Breeze), Director, Dreamweaver, Fireworks, Flash, FlashPaper, Flex, FreeHand, HomeSite, JRun, Presenter, and Authorware to Adobe's product line.

Adobe released Adobe Media Player in April 2008. On April 27, Adobe discontinued development and sales of its older HTML/web development software, GoLive in favor of Dreamweaver. Adobe offered a discount on Dreamweaver for GoLive users and supports those who still use GoLive with online tutorials and migration assistance. On June 1, Adobe launched Acrobat.com, a series of web applications geared for collaborative work. Creative Suite 4, which includes Design, Web, Production Premium, and Master Collection came out in October 2008 in six configurations at prices from about US$1,700 to $2,500 or by individual application. The Windows version of Photoshop includes 64-bit processing. On December 3, 2008, Adobe laid off 600 of its employees (8% of the worldwide staff) citing the weak economic environment.On November 10, 2009, the company laid off a further 680 employees. Adobe announced it was investigating a "coordinated attack" against corporate network systems in China, managed by the company.

Adobe's 2010 was marked by continuing front-and-back arguments with Apple over the latter's non-support for Adobe Flash on its iPhone, iPad and other products. Former Apple CEO Steve Jobs claimed that Flash was not reliable or secure enough, while Adobe executives have argued that Apple wish to maintain control over the iOS platform. In April 2010, Steve Jobs published a post titled "Thoughts on Flash" where he outlined his thoughts on Flash and the rise of HTML 5.
In July 2010, Adobe bought Day Software integrating their line of CQ Products: WCM, DAM, SOCO, and Mobile

In January 2011, Adobe acquired DemDex, Inc. with the intent of adding DemDex's audience-optimization software to its online marketing suite. At Photoshop World 2011, Adobe unveiled a new mobile photo service. Carousel is a new application for iPhone, iPad, and Mac that uses Photoshop Lightroom technology for users to adjust and fine-tune images on all platforms. Carousel will also allow users to automatically sync, share and browse photos. The service was later renamed to "Adobe Revel".

In October 2011, Adobe acquired Nitobi Software, the makers of the mobile application development framework "PhoneGap". As part of the acquisition, the source code of PhoneGap was submitted to the Apache Foundation, where it became Apache Cordova.

On November 9, 2011, Adobe announced that they would cease development of Flash for mobile devices following version 11.1. Instead, it would focus on HTML 5 for mobile devices. On December 1, 2011, Adobe announced that it entered into a definitive agreement to acquire privately held Efficient Frontier.

In December 2012, Adobe opened a new 280,000 square foot corporate campus in Lehi, Utah.

In 2013, Adobe Systems endured a major security breach. Vast portions of the source code for the company's software were stolen and posted online and over 150 million records of Adobe's customers have been made readily available for download. In 2012, about 40 million sets of payment card information were compromised by a hack of Adobe.

A class-action lawsuit alleging that the company suppressed employee compensation was filed against Adobe, and three other Silicon Valley-based companies in a California federal district court in 2013. In May 2014, it was revealed the four companies, Adobe, Apple, Google, and Intel had reached agreement with the plaintiffs, 64,000 employees of the four companies, to pay a sum of $324.5 million to settle the suit.

On Wednesday, March 28, 2018, at Adobe Summit, Adobe and NVIDIA publicized a key association to quickly upgrade their industry-driving AI and profound learning innovations. Expanding on years of coordinated effort, the organizations will work to streamline the Adobe Sensei AI and machine learning structure for NVIDIA GPUs. The joint effort will speed time to showcase and enhance execution of new Sensei-powered services for Adobe Creative Cloud and Experience Cloud clients and engineers.

Adobe and NVIDIA have co-operated for over 10 years on empowering GPU quickening for a wide arrangement of Adobe's creative and computerized encounter items. This incorporates Sensei-powered features, for example, auto lip sync in Adobe Character Animator CC and face aware editing in Photoshop CC, and also cloud-based AI/ML items and features, for example, picture investigation for Adobe Stock and Lightroom CC and auto-labeling in Adobe Experience Supervisor.

On May 22, 2018, Adobe stated that they are buying e-commerce services provider Magento Commerce from private equity firm Permira for $1.68 billion. This deal will help bolster its Experience Cloud business, which provides services including analytics, advertising, and marketing. The deal is expected to close during Adobe's fiscal third quarter in 2018.

On September 20, 2018, Adobe announced its acquisition of marketing automation software company, Marketo.

On October 3, 2018, Adobe officially changed its name from Adobe Systems Incorporated to Adobe Inc.

On January 23, 2019, Adobe announced its acquisition of a 3D texturing company, Allegorithmic.

Adobe Stock

A microstock agency that presently provides over 57 million high-resolution, royalty-free images and videos available to license (via subscription or credit purchase methods). On December 11, 2014, Adobe announced it was buying Fotolia for $800 million in cash, aiming at integrating the service to its Creative Cloud solution. The purchase was completed in January 2015. It is run as a stand-alone website.

Adobe Experience Platform

In March 2019 Adobe released its Adobe Experience Platform, which consists family of content, development, and customer relationship management products, with what it's calling the "next generation" of its Sensei artificial intelligence and machine learning framework.

Since 1995, "Fortune" has ranked Adobe as an outstanding place to work. Adobe was rated the 5th best U.S. company to work for in 2003, 6th in 2004, 31st in 2007, 40th in 2008, 11th in 2009, 42nd in 2010, 65th in 2011, 41st in 2012, and 83rd in 2013. In October 2008, Adobe Systems Canada Inc. was named one of "Canada's Top 100 Employers" by Mediacorp Canada Inc., and was featured in "Maclean's" newsmagazine.

Adobe has a five star privacy rating from the Electronic Frontier Foundation.

Adobe has been criticized for its pricing practices, with retail prices being up to twice as much in non-US countries. For example, it is significantly cheaper to pay for a return airfare ticket to the United States and purchase one particular collection of Adobe's software there than to buy it locally in Australia.

After Adobe revealed the pricing for the Creative Suite 3 Master Collection, which was £1,000 higher for European customers, a petition to protest over "unfair pricing" was published and signed by 10,000 users. In June 2009, Adobe further increased its prices in the UK by 10% in spite of weakening of the pound against the dollar, and UK users were not allowed to buy from the US store.

Adobe's Reader and Flash programs were listed on "The 10 most hated programs of all time" article by "TechRadar".

Hackers have exploited vulnerabilities in Adobe programs, such as Adobe Reader, to gain unauthorized access to computers. Adobe's Flash Player has also been criticized for, among other things, suffering from performance, memory usage and security problems (see criticism of Flash Player). A report by security researchers from Kaspersky Lab criticized Adobe for producing the products having top 10 security vulnerabilities.

Observers noted that Adobe was spying on its customers by including spyware in the Creative Suite 3 software and quietly sending user data to a firm named Omniture. When users became aware, Adobe explained what the suspicious software did and admitted that they: "could and should do a better job taking security concerns into account". When a security flaw was later discovered in Photoshop CS5, Adobe sparked outrage by saying it would leave the flaw unpatched, so anyone who wanted to use the software securely would have to pay for an upgrade. Following a fierce backlash Adobe decided to provide the software patch.

Adobe has been criticized for pushing unwanted software including third-party browser toolbars and free virus scanners, usually as part of the Flash update process, and for pushing a third-party scareware program designed to scare users into paying for unneeded system repairs.

On October 3, 2013, the company initially revealed that 2.9 million customers' sensitive and personal data was stolen in security breach which included encrypted credit card information. Adobe later admitted that 38 million active users have been affected and the attackers obtained access to their IDs and encrypted passwords, as well as to many inactive Adobe accounts. The company did not make it clear if all the personal information was encrypted, such as email addresses and physical addresses, though data privacy laws in 44 states require this information to be encrypted.

A 3.8 GB file stolen from Adobe and containing 152 million usernames, reversibly encrypted passwords and unencrypted password hints was posted on AnonNews.org. LastPass, a password security firm, said that Adobe failed to use best practices for securing the passwords and has not salted them. Another security firm, Sophos, showed that Adobe used a weak encryption method permitting the recovery of a lot of information with very little effort. According to IT expert Simon Bain, Adobe has failed its customers and 'should hang their heads in shame'.

Many of the credit cards were tied to the Creative Cloud software-by-subscription service. Adobe offered its affected US customers a free membership in a credit monitoring service, but no similar arrangements have been made for non-US customers. When a data breach occurs in the US, penalties depend on the state where the victim resides, not where the company is based.

After stealing the customers' data, cyber-thieves also accessed Adobe's source code repository, likely in mid-August 2013. Because hackers acquired copies of the source code of Adobe proprietary products, they could find and exploit any potential weaknesses in its security, computer experts warned. Security researcher Alex Holden, chief information security officer of Hold Security, characterized this Adobe breach, which affected Acrobat, ColdFusion and numerous other applications, as "one of the worst in US history". Adobe also announced that hackers stole parts of the source code of Photoshop, which according to commentators could allow programmers to copy its engineering techniques and would make it easier to pirate Adobe's expensive products.

Published on a server of a Russian-speaking hacker group, the "disclosure of encryption algorithms, other security schemes, and software vulnerabilities can be used to bypass protections for individual and corporate data" and may have opened the gateway to new generation zero-day attacks. Hackers already used ColdFusion exploits to make off with usernames and encrypted passwords of PR Newswire's customers, which has been tied to the Adobe security breach. They also used a ColdFusion exploit to breach Washington state court and expose up to 200,000 Social Security numbers.

Adobe acquired Aldus Corp. in 1994, a software vendor that sold FreeHand, a competing product. Freehand was direct competition to Adobe Illustrator, Adobe's flagship vector-graphics editor. The Federal Trade Commission intervened and forced Adobe to sell FreeHand back to Altsys, and also banned Adobe from buying back FreeHand or any similar program for the next 10 years (1994-2004). Altsys was then bought by Macromedia, which released versions 5 to 11. When Adobe acquired Macromedia in December 2005, it stalled development of Freehand in 2007, effectively rendering it obsolete. With FreeHand and Illustrator, Adobe controlled the only two products that compete in the professional illustration program market for Macintosh operating systems.

In 2011, a group of 5,000 Freehand graphic designers convened under the banner "Free Freehand", and filed a civil antitrust complaint in the US District Court for the Northern District of California against Adobe. The suit alleged that "Adobe has violated federal and state antitrust laws by abusing its dominant position in the professional vector graphic illustration software market" and that "Adobe has engaged in a series of exclusionary and anti-competitive acts and strategies designed to kill FreeHand, the dominant competitor to Adobe's Illustrator software product, instead of competing on the basis of product merit according to the principals of free market capitalism." Adobe had no response to the claims and the lawsuit was eventually settled. The FreeHand community believes Adobe should release the product to an open-source community if it cannot update it internally.

, on its FreeHand product page Adobe stated ""While we recognize FreeHand has a loyal customer base, we encourage users to migrate to the new Adobe Illustrator CS4 software which supports both PowerPC and Intel-based Macs and Microsoft Windows XP and Windows Vista."" , the Freehand page no longer exists and simply redirects to the Illustrator page. Adobe's software FTP server still contains a directory for FreeHand, but it is empty




</doc>
<doc id="1957" url="https://en.wikipedia.org/wiki?curid=1957" title="Alexander Technique">
Alexander Technique

The Alexander Technique, named after its creator Frederick Matthias Alexander, is an educational process that was created to retrain habitual patterns of movement and posture. Alexander believed that poor habits in posture and movement damaged spatial self-awareness as well as health, and that movement efficiency could support overall physical well-being. He saw the technique as a mental training technique as well.

Alexander began developing his technique's principles in the 1890s in an attempt to address voice loss during public speaking. He credited his method with allowing him to pursue his passion for reciting in Shakespearean theater.

Some proponents of the Alexander Technique say that it addresses a variety of health conditions related to cumulative physical behaviors, but there is little evidence to support many of the claims made about the technique. As of 2015 there was evidence suggesting the Alexander Technique may be helpful for long-term back pain, long-term neck pain, and may help people cope with Parkinson's disease. However, both Aetna and the Australian Department of Health have conducted reviews and concluded that the technique has insufficient evidence to warrant insurance coverage.

The Alexander Technique is used and taught by classically trained vocal coaches and musicians in schools and private lessons. Its advocates state that it allows for a balanced use of all aspects of the vocal tract by consciously increasing air-flow, allowing improved vocal skill and tone. The method is said by actors to reduce stage fright and to increase spontaneity.

The Alexander Technique is a frequent component in acting training, because it can assist the actor in being more natural in performance.

According to Alexander Technique instructor Michael J. Gelb, people tend to study the Alexander Technique for reasons of personal development.

A review of evidence for Alexander Technique for various health conditions provided by UK NHS Choices last updated in 2018 said that advocates of the technique made claims for it that were not supported by evidence, but that there was evidence suggesting that it might help with:


"NHS Choices" also states that "some research has also suggested the Alexander technique may improve general long-term pain, stammering and balance skills in elderly people to help them avoid falls. But the evidence in these areas is limited and more studies are needed. There's currently little evidence to suggest the Alexander technique can help improve other health conditions, including asthma, headaches, osteoarthritis, difficulty sleeping (insomnia) and stress."

A review published in "BMC Complementary and Alternative Medicine" in 2014 focused on "the evidence for the effectiveness of AT sessions on musicians' performance, anxiety, respiratory function and posture" concluded that: "Evidence from RCTs and CTs suggests that AT sessions may improve performance anxiety in musicians. Effects on music performance, respiratory function and posture yet remain inconclusive."

A review published in the "International Journal of Clinical Practice" in 2012 found: "Strong evidence exists for the effectiveness of Alexander Technique lessons for chronic back pain and moderate evidence in Parkinson’s-associated disability. Preliminary evidence suggests that Alexander Technique lessons may lead to improvements in balance skills in the elderly, in general chronic pain, posture, respiratory function and stuttering, but there is insufficient evidence to support recommendations in these areas."

A 2012 Cochrane systematic review found that there is no conclusive evidence that the Alexander technique is effective for treating asthma, and randomized clinical trials are needed in order to assess the effectiveness of this type of treatment approach.

A review by Aetna last updated in 2016 stated: "Aetna considers the following alternative medicine interventions experimental and investigational, because there is inadequate evidence in the peer-reviewed published medical literature of their effectiveness." Included is Alexander technique in that list.

A review published in 2015 and conducted for the Australia Department of Health in order to determine what services the Australian government should pay for, reviewed clinical trials published to date and found that: "Overall, the evidence was limited by the small number of participants in the intervention arms, wide confidence intervals or a lack of replication of results." It concluded that: "The Alexander technique may improve short-term pain and disability in people with low back pain, but the longer-term effects remain uncertain. For all other clinical conditions, the effectiveness of Alexander technique was deemed to be uncertain, due to insufficient evidence." It also noted that: "Evidence for the safety of
Alexander technique was lacking, with most trials not reporting on this outcome. Subsequently in 2017 the Australian government named the Alexander Technique as a practice that would not qualify for insurance subsidy, saying this step would "ensure taxpayer funds are expended appropriately and not directed to therapies lacking evidence".

The Alexander Technique is most commonly taught privately in a series of 10 to 40 private lessons which may last from 30 minutes to an hour. Students are often performers, such as actors, dancers, musicians, athletes and public speakers, people who work on computers, or those who are in frequent pain for other reasons. Instructors observe their students, then show them how to move with better poise and less strain. Sessions include chair work – often in front of a mirror, during which the instructor and the student will stand, sit and lie down, moving efficiently while maintaining a comfortable relationship between the head, neck and spine, and table work or physical manipulation.

To qualify as a teacher of Alexander Technique, instructors are required to complete 1,600 hours, spanning three years, of supervised teacher training. The result must be satisfactory to qualified peers to gain membership in professional societies.

Alexander's approach emphasizes awareness strategies applied to conducting oneself while in action, (which could be now called "mindful" action, though in his four books he did not use that term.)

Actions such as sitting, squatting, lunging or walking are often selected by the teacher. Other actions may be selected by the student that is tailored to their interests or work activities; hobbies, computer use, lifting, driving or artistic performance or practice, sports, speech or horseback riding. Alexander teachers often use themselves as examples. They demonstrate, explain, and analyze a student's moment-to-moment responses as well as using mirrors, video feedback or classmate observations. Guided modelling with a highly skilled light hand contact is the primary tool for detecting and guiding the student into a more coordinated state in movement and at rest during in-person lessons. Suggestions for improvements are often student-specific, as everyone starts out with slightly different habits.

Exercise as a teaching tool is deliberately omitted because of a common mistaken assumption that there exists a "correct" position. There are only two specific procedures that are practiced by the student; the first is lying semi-supine. Resting in this way uses "mechanical advantage" as a means of redirecting long-term and short-term accumulated muscular tension into a more integrated and balanced state. This position is sometimes referred to as "constructive rest", or "the balanced resting state". It's also a specific time to practice Alexander's principle of conscious "directing" without "doing". The second exercise is the "Whispered Ah", which is used to co-ordinate freer breathing and vocal production.

Freedom, efficiency and patience are the prescribed values. Proscribed are unnecessary effort, self-limiting habits as well as mistaken perceptual conclusions about the nature of training and experimentation. Students are led to change their largely automatic routines that are interpreted by the teacher to currently or cumulatively be physically limiting, inefficient, or not in keeping with best "use" of themselves as a whole. The Alexander teacher provides verbal coaching while monitoring, guiding and preventing unnecessary habits at their source with a specialized hands-on assistance.

This specialized hands-on skill also allows Alexander teachers to bring about a balanced working of the student's supportive musculature as it relates to gravity's downward pull from moment to moment. Often, students require a great deal of hands-on work in order to first gain an experience of a fully poised relation to gravity and themselves. The hands-on skill requires Alexander teachers to maintain in themselves from moment-to-moment their own improved psycho-physical co-ordination that the teacher is communicating to the student.

Alexander developed terminology to describe his methods, outlined in his four books that explain the experience of learning and substituting new improvements.





"Directing" serves to counteract the common backward and downward pull and shortening in stature that can be detected at the beginning of every movement – particularly addressing a startle pattern of "fight, flight or freeze". A mere thought, as a projection of intention, shapes preparatory movement below the level of sensing it. Alexander used these words for reshaping these subliminal preparations: "The neck to be free, the head to go forward and up, the back to lengthen and widen". Some teachers have shortened this to a suggestion of, "Freer?" Negative directions (that use Alexander's other preventive principle of "inhibition") have also been found to be effective, because negative directions leave the positive response open-ended.
Whichever is used, all "Directing" is suggestively thought, (rather than willfully accomplished.) This is because the neuro-muscular responses to "Directing" often occur underneath one's ability to perceive how they are actually carried out neuro-physiologically and neuro-cognitively. As freedom of expression or movement is the objective, the most appropriate responses cannot be anticipated or expected, only observed and chosen in the moment. 
Teacher trainees gradually learn to include a constant attending to their lengthening in stature in every movement. It becomes a basis for initiating and continuing every action, every response to stimuli or while remaining constructively at rest.


Frederick Matthias Alexander (1869–1955) was a Shakespearean orator from Tasmania, who developed voice loss during his unamplified performances. After doctors found no physical cause, Alexander reasoned that he was inadvertently damaging himself while speaking. He observed himself in multiple mirrors and saw that he was contracting his posture in preparation for any speech. He hypothesized that a habitual conditioned pattern (of pulling his head backwards and downwards) needlessly was disrupting the normal working of his total postural, breathing, and vocal processes.

With experimentation, Alexander developed the ability to stop the unnecessary and habitual contracting in his neck, displacement of his head, and shortening of his stature. As he became practised at speaking without these interferences, he found that his problem with recurrent voice loss was resolved. While on a recital tour in New Zealand (1895), he came to believe in the wider significance of improved carriage for overall physical functioning although evidence from his own publications appears to indicate it happened less systematically and over a long period of time.

The American philosopher and educator John Dewey became impressed with the Alexander Technique after his headaches, neck pains, blurred vision, and stress symptoms largely improved during the time he used Alexander's advice to change his posture. In 1923, Dewey wrote the introduction to Alexander's "Constructive Conscious Control of the Individual".

Aldous Huxley had transformative lessons with Alexander, and continued doing so with other teachers after moving to the US. He rated Alexander's work highly enough to base the character of the doctor who saves the protagonist in "Eyeless in Gaza" (an experimental form of autobiographical work) on F.M. Alexander, putting many of his phrases into the character's mouth. Huxley's work "The Art of Seeing" also discusses his views on the technique.

Sir Stafford Cripps, George Bernard Shaw, Henry Irving and other stage grandees, Lord Lytton and other eminent people of the era also wrote positive appreciations of his work after taking lessons with Alexander.

Since Alexander's work in the field came at the start of the 20th century, his ideas influenced many originators in the field of mind-body improvement. Fritz Perls, who originated Gestalt therapy, credited Alexander as an inspiration for his psychological work. The Mitzvah Technique was influenced by the Alexander Technique; as was the Feldenkrais Method – who expanded on the one exercise in Alexander Technique called "The Whispered Ah."




</doc>
<doc id="1960" url="https://en.wikipedia.org/wiki?curid=1960" title="Andrea Alciato">
Andrea Alciato

Andrea Alciato (8 May 149212 January 1550), commonly known as Alciati (Andreas Alciatus), was an Italian jurist and writer. He is regarded as the founder of the French school of legal humanists.

Alciati was born in Alzate Brianza, near Milan, and settled in France in the early 16th century. He displayed great literary skill in his exposition of the laws, and was one of the first to interpret the civil law by the history, languages and literature of antiquity, and to substitute original research for the servile interpretations of the glossators. He published many legal works, and some annotations on Tacitus and accumulated a sylloge of Roman inscriptions from Milan and its territories, as part of his preparation for his history of Milan, written in 1504-05.

Alciati is most famous for his "Emblemata," published in dozens of editions from 1531 onward. This collection of short Latin verse texts and accompanying woodcuts created an entire European genre, the emblem book, which attained enormous popularity in continental Europe and Great Britain.

Alciati died at Pavia in 1550.




</doc>
<doc id="1962" url="https://en.wikipedia.org/wiki?curid=1962" title="Apparent magnitude">
Apparent magnitude

Apparent magnitude () is a measure of the relative brightness of a star or other astronomical objects as seen by an observer. An object's apparent magnitude depends on its intrinsic luminosity, its distance, and any extinction of the object's light by interstellar dust along the line of sight to the observer. 

The magnitude scale is an inverse logarithmic relation, where a difference of 1.0 in magnitude corresponds to a brightness ratio of or about 2.512. The brighter an object appears, the lower its magnitude. For example, a star of apparent magnitude 2.0 is 2.512 times brighter than a star of apparent magnitude 3.0. The brightest astronomical objects have negative apparent magnitudes: for example, Venus at −4.2 or Sirius at −1.46. The faintest naked-eye stars visible on the darkest night have apparent magnitudes of about +6.5. Apparent magnitudes range from −26.7 (the Sun) to fainter than +30 (such as the faintest objects detected in deep Hubble Space Telescope images). 

Measurement of the apparent magnitude of celestial objects is termed photometry. It is often quantified at ultraviolet, visible, and infrared wavelengths, as measured through standard passband filters corresponding to various adopted photometric systems such as the UBV system or the Strömgren uvbyβ system. In accepted astronomical notation, apparent magnitude may be denoted as "m", as in ""m" = 15" to describe a 15th-magnitude object, where "V" coresponds to the visual filter band. In amateur astronomy, apparent magnitude is often understood as meaning apparent visual magnitude (v), defined as the brightness of a star or other astronomical source across the visible part of the electromagnetic spectrum when viewed by the human eye.

Absolute magnitude rather than apparent brightness is a measure of its true intrinsic luminosity, and is expressed on the same inverse logarithmic scale. Absolute magnitude is defined as the apparent magnitude that a star or object would have if it were observed from a standard reference distance of 10 parsecs.

The scale used to indicate magnitude originates in the Hellenistic practice of dividing stars visible to the naked eye into six "magnitudes". The brightest stars in the night sky were said to be of first magnitude ( = 1), whereas the faintest were of sixth magnitude ( = 6), which is the limit of human visual perception (without the aid of a telescope). Each grade of magnitude was considered twice the brightness of the following grade (a logarithmic scale), although that ratio was subjective as no photodetectors existed. This rather crude scale for the brightness of stars was popularized by Ptolemy in his "Almagest" and is generally believed to have originated with Hipparchus.

In 1856, Norman Robert Pogson formalized the system by defining a first magnitude star as a star that is 100 times as bright as a sixth-magnitude star, thereby establishing the logarithmic scale still in use today. This implies that a star of magnitude is about 2.512 times as bright as a star of magnitude . This figure, the fifth root of 100, became known as Pogson's Ratio. The zero point of Pogson's scale was originally defined by assigning Polaris a magnitude of exactly 2. Astronomers later discovered that Polaris is slightly variable, so they switched to Vega as the standard reference star, assigning the brightness of Vega as the definition of zero magnitude at any specified wavelength.

Apart from small corrections, the brightness of Vega still serves as the definition of zero magnitude for visible and near infrared wavelengths, where its spectral energy distribution (SED) closely approximates that of a black body for a temperature of . However, with the advent of infrared astronomy it was revealed that Vega's radiation includes an infrared excess presumably due to a circumstellar disk consisting of dust at warm temperatures (but much cooler than the star's surface). At shorter (e.g. visible) wavelengths, there is negligible emission from dust at these temperatures. However, in order to properly extend the magnitude scale further into the infrared, this peculiarity of Vega should not affect the definition of the magnitude scale. Therefore, the magnitude scale was extrapolated to "all" wavelengths on the basis of the black-body radiation curve for an ideal stellar surface at uncontaminated by circumstellar radiation. On this basis the spectral irradiance (usually expressed in janskys) for the zero magnitude point, as a function of wavelength, can be computed. Small deviations are specified between systems using measurement apparatuses developed independently so that data obtained by different astronomers can be properly compared, but of greater practical importance is the definition of magnitude not at a single wavelength but applying to the response of standard spectral filters used in photometry over various wavelength bands.

With the modern magnitude systems, brightness over a very wide range is specified according to the logarithmic definition detailed below, using this zero reference. In practice such apparent magnitudes do not exceed 30 (for detectable measurements). The brightness of Vega is exceeded by four stars in the night sky at visible wavelengths (and more at infrared wavelengths) as well as the bright planets Venus, Mars, and Jupiter, and these must be described by "negative" magnitudes. For example, Sirius, the brightest star of the celestial sphere, has an apparent magnitude of −1.4 in the visible. Negative magnitudes for other very bright astronomical objects can be found in the table below.

Astronomers have developed other photometric zeropoint systems as alternatives to the Vega system. The most widely used is the AB magnitude system, in which photometric zeropoints are based on a hypothetical reference spectrum having constant flux per unit frequency interval, rather than using a stellar spectrum or blackbody curve as the reference. The AB magnitude zeropoint is defined such that an object's AB and Vega-based magnitudes will be approximately equal in the V filter band.

As the amount of light actually received by a telescope is reduced by transmission through the Earth's atmosphere, any measurement of apparent magnitude is corrected for what it would have been as seen from above the atmosphere. The dimmer an object appears, the higher the numerical value given to its apparent magnitude, with a difference of 5 magnitudes corresponding to a brightness factor of exactly 100. Therefore, the apparent magnitude , in the spectral band , would be given by

which is more commonly expressed in terms of common (base-10) logarithms as

where is the observed flux density using spectral filter , and is the reference flux (zero-point) for that photometric filter. Since an increase of 5 magnitudes corresponds to a decrease in brightness by a factor of exactly 100, each magnitude increase implies a decrease in brightness by the factor ≈ 2.512 (Pogson's ratio). Inverting the above formula, a magnitude difference implies a brightness factor of

"What is the ratio in brightness between the Sun and the full Moon?"

The apparent magnitude of the Sun is −26.74 (brighter), and the mean apparent magnitude of the full moon is −12.74 (dimmer).

Difference in magnitude: 

Brightness factor: 

The Sun appears about times brighter than the full moon.

Sometimes one might wish to add brightnesses. For example, photometry on closely separated double stars may only be able to produce a measurement of their combined light output. How would we reckon the combined magnitude of that double star knowing only the magnitudes of the individual components? This can be done by adding the brightnesses (in linear units) corresponding to each magnitude.

Solving for formula_7 yields

where is the resulting magnitude after adding the brightnesses referred to by and .

While apparent magnitude generally refers to a measurement in a particular filter band corresponding to some range of wavelengths, the apparent bolometric magnitude (m) is a measure of an object's apparent brightness integrated over all wavelengths of the electromagnetic spectrum (also known as the object's irradiance). The zeropoint of the apparent bolometric magnitude scale is based on the definition that an apparent bolometric magnitude of 0 mag is equivalent to a received irradiance of 2.518×10 W·m (Watts per square metre.)

While apparent magnitude is a measure of the brightness of an object as seen by a particular observer, absolute magnitude is a measure of the "intrinsic" brightness of an object. Flux decreases with distance according to an inverse-square law, so the apparent magnitude of a star depends on both its absolute brightness and its distance (and any extinction). For example, a star at one distance will have the same apparent magnitude as a star four times brighter at twice that distance. In contrast, the intrinsic brightness of an astronomical object, does not depend on the distance of the observer or any extinction.

The absolute magnitude , of a star or astronomical object is defined as the apparent magnitude it would have as seen from a distance of 10 parsecs (about 32.6 light-years). The absolute magnitude of the Sun is 4.83 in the V band (green) and 5.48 in the B band (blue).

In the case of a planet or asteroid, the absolute magnitude rather means the apparent magnitude it would have if it were 1 astronomical unit from both the observer and the Sun, and fully illuminated (a configuration that is only theoretically achievable, with the observer situated on the surface of the Sun).

It is important to note that the scale is logarithmic: the relative brightness of two objects is determined by the difference of their magnitudes. For example, a difference of 3.2 means that one object is about 19 times as bright as the other, because Pogson's Ratio raised to the power 3.2 is approximately 19.05.

A common misconception is that the logarithmic nature of the scale is because the human eye itself has a logarithmic response. In Pogson's time this was thought to be true (see Weber–Fechner law), but it is now believed that the response is a power law (see Stevens' power law).

Magnitude is complicated by the fact that light is not monochromatic. The sensitivity of a light detector varies according to the wavelength of the light, and the way it varies depends on the type of light detector. For this reason, it is necessary to specify how the magnitude is measured for the value to be meaningful. For this purpose the UBV system is widely used, in which the magnitude is measured in three different wavelength bands: U (centred at about 350 nm, in the near ultraviolet), B (about 435 nm, in the blue region) and V (about 555 nm, in the middle of the human visual range in daylight). The V band was chosen for spectral purposes and gives magnitudes closely corresponding to those seen by the light-adapted human eye, and when an apparent magnitude is given without any further qualification, it is usually the V magnitude that is meant, more or less the same as visual magnitude.

Because cooler stars, such as red giants and red dwarfs, emit little energy in the blue and UV regions of the spectrum their power is often under-represented by the UBV scale. Indeed, some L and T class stars have an estimated magnitude of well over 100, because they emit extremely little visible light, but are strongest in infrared.

Measures of magnitude need cautious treatment and it is extremely important to measure like with like. On early 20th century and older orthochromatic (blue-sensitive) photographic film, the relative brightnesses of the blue supergiant Rigel and the red supergiant Betelgeuse irregular variable star (at maximum) are reversed compared to what human eyes perceive, because this archaic film is more sensitive to blue light than it is to red light. Magnitudes obtained from this method are known as photographic magnitudes, and are now considered obsolete.

For objects within the Milky Way with a given absolute magnitude, 5 is added to the apparent magnitude for every tenfold increase in the distance to the object. For objects at very great distances (far beyond the Milky Way), this relationship must be adjusted for redshifts and for non-Euclidean distance measures due to general relativity.

For planets and other Solar System bodies the apparent magnitude is derived from its phase curve and the distances to the Sun and observer.

Some of the above magnitudes are only approximate. Telescope sensitivity also depends on observing time, optical bandpass, and interfering light from scattering and airglow.


</doc>
<doc id="1963" url="https://en.wikipedia.org/wiki?curid=1963" title="Absolute magnitude">
Absolute magnitude

Absolute magnitude () is a measure of the luminosity of a celestial object, on an inverse logarithmic astronomical magnitude scale. An object's absolute magnitude is defined to be equal to the apparent magnitude that the object would have if it were viewed from a distance of exactly , without extinction (or dimming) of its light due to absorption by interstellar matter and cosmic dust. By hypothetically placing all objects at a standard reference distance from the observer, their luminosities can be directly compared on a magnitude scale. 

As with all astronomical magnitudes, the absolute magnitude can be specified for different wavelength ranges corresponding to specified filter bands or passbands; for stars a commonly quoted absolute magnitude is the absolute visual magnitude, which uses the visual (V) band of the spectrum (in the UBV photometric system). Absolute magnitudes are denoted by a capital M, with a subscript representing the filter band used for measurement, such as M for absolute magnitude in the V band.

The more luminous an object, the smaller the numerical value of its absolute magnitude. A difference of 5 magnitudes between the absolute magnitudes of two objects corresponds to a ratio of 100 in their luminosities, and a difference of n magnitudes in absolute magnitude corresponds to a luminosity ratio of 100. For example, a star of absolute magnitude M=3.0 would be 100 times more luminous than a star of absolute magnitude M=8.0 as measured in the V filter band. The Sun has absolute magnitude M=+4.83. Highly luminous objects can have negative absolute magnitudes: for example, the Milky Way galaxy has an absolute B magnitude of about −20.8.

An object's absolute bolometric magnitude (M) represents its total luminosity over all wavelengths, rather than in a single filter band, as expressed on a logarithmic magnitude scale. To convert from an absolute magnitude in a specific filter band to absolute bolometric magnitude, a bolometric correction (BC) is applied.

For Solar System bodies that shine in reflected light, a different definition of absolute magnitude (H) is used, based on a standard reference distance of one astronomical unit.

In stellar and galactic astronomy, the standard distance is 10 parsecs (about 32.616 light-years, 308.57 petameters or 308.57 trillion kilometres). A star at 10 parsecs has a parallax of 0.1″ (100 milliarcseconds). Galaxies (and other extended objects) are much larger than 10 parsecs, their light is radiated over an extended patch of sky, and their overall brightness cannot be directly observed from relatively short distances, but the same convention is used. A galaxy's magnitude is defined by measuring all the light radiated over the entire object, treating that integrated brightness as the brightness of a single point-like or star-like source, and computing the magnitude of that point-like source as it would appear if observed at the standard 10 parsecs distance. Consequently, the absolute magnitude of any object "equals" the apparent magnitude it "would have" if it were 10 parsecs away.

The measurement of absolute magnitude is made with an instrument called a bolometer. When using an absolute magnitude, one must specify the type of electromagnetic radiation being measured. When referring to total energy output, the proper term is bolometric magnitude. The bolometric magnitude usually is computed from the visual magnitude plus a bolometric correction, . This correction is needed because very hot stars radiate mostly ultraviolet radiation, whereas very cool stars radiate mostly infrared radiation (see Planck's law).

Some stars visible to the naked eye have such a low absolute magnitude that they would appear bright enough to outshine the planets and cast shadows if they were at 10 parsecs from the Earth. Examples include Rigel (−7.0), Deneb (−7.2), Naos (−6.0), and Betelgeuse (−5.6). For comparison, Sirius has an absolute magnitude of 1.4, which is brighter than the Sun, whose absolute visual magnitude is 4.83 (it actually serves as a reference point). The Sun's absolute bolometric magnitude is set arbitrarily, usually at 4.75.
Absolute magnitudes of stars generally range from −10 to +17. The absolute magnitudes of galaxies can be much lower (brighter). For example, the giant elliptical galaxy M87 has an absolute magnitude of −22 (i.e. as bright as about 60,000 stars of magnitude −10).

The Greek astronomer Hipparchus established a numerical scale to describe the brightness of each star appearing in the sky. The brightest stars in the sky were assigned an apparent magnitude , and the dimmest stars visible to the naked eye are assigned . The difference between them corresponds to a factor of 100 in brightness. For objects within the immediate neighborhood of the Sun, the absolute magnitude and apparent magnitude from any distance (in parsecs) is related by:

where is the radiant flux measured at distance (in parsecs), the radiant flux measured at distance . The relation can be written in terms of logarithm:

where the insignificance of extinction by gas and dust is assumed. Typical extinction rates within the galaxy are 1 to 2 magnitudes per kiloparsec, when dark clouds are taken into account.

For objects at very large distances (outside the Milky Way) the luminosity distance (distance defined using luminosity measurements) must be used instead of (in parsecs), because the Euclidean approximation is invalid for distant objects and general relativity must be taken into account. Moreover, the cosmological redshift complicates the relation between absolute and apparent magnitude, because the radiation observed was shifted into the red range of the spectrum. To compare the magnitudes of very distant objects with those of local objects, a K correction might have to be applied to the magnitudes of the distant objects.

The absolute magnitude can also be approximated using apparent magnitude and stellar parallax :

or using apparent magnitude and distance modulus :

Rigel has a visual magnitude of 0.12 and distance about 860 light-years

Vega has a parallax of 0.129″, and an apparent magnitude of 0.03

The Black Eye Galaxy has a visual magnitude of 9.36 and a distance modulus of 31.06

The bolometric magnitude , takes into account electromagnetic radiation at all wavelengths. It includes those unobserved due to instrumental passband, the Earth's atmospheric absorption, and extinction by interstellar dust. It is defined based on the luminosity of the stars. In the case of stars with few observations, it must be computed assuming an effective temperature.

Classically, the difference in bolometric magnitude is related to the luminosity ratio according to:

which makes by inversion:

where

In August 2015, the International Astronomical Union passed Resolution B2 defining the zero points of the absolute and apparent bolometric magnitude scales in SI units for power (watts) and irradiance (W/m), respectively. Although bolometric magnitudes had been used by astronomers for many decades, there had been systematic differences in the absolute magnitude-luminosity scales presented in various astronomical references, and no international standardization. This led to systematic differences in bolometric corrections scales. Combined with incorrect assumed absolute bolometric magnitudes for the Sun could lead to systematic errors in estimated stellar luminosities (and stellar properties calculated which rely on stellar luminosity, such as radii, ages, and so on).

Resolution B2 defines an absolute bolometric magnitude scale where corresponds to luminosity , with the zero point luminosity set such that the Sun (with nominal luminosity ) corresponds to absolute bolometric magnitude 4.74. Placing a radiation source (e.g. star) at the standard distance of 10 parsecs, it follows that the zero point of the apparent bolometric magnitude scale corresponds to irradiance . Using the IAU 2015 scale, the nominal total solar irradiance ("solar constant") measured at 1 astronomical unit () corresponds to an apparent bolometric magnitude of the Sun of −26.832.

Following Resolution B2, the relation between a star's absolute bolometric magnitude and its luminosity is no longer directly tied to the Sun's (variable) luminosity:

where

The new IAU absolute magnitude scale permanently disconnects the scale from the variable Sun. However, on this SI power scale, the nominal solar luminosity corresponds closely to 4.74, a value that was commonly adopted by astronomers before the 2015 IAU resolution.

The luminosity of the star in watts can be calculated as a function of its absolute bolometric magnitude as:

using the variables as defined previously.

For planets and asteroids a definition of absolute magnitude that is more meaningful for non-stellar objects is used. The absolute magnitude, commonly called formula_12, is defined as the apparent magnitude that the object would have if it were one Astronomical Unit (AU) from both the Sun and the observer, and in conditions of ideal solar opposition (an arrangement that is impossible in practice). Solar System bodies are illuminated by the Sun, therefore the magnitude varies as a function of illumination conditions, described by the phase angle. This relationship is referred to as the phase curve. The absolute magnitude is the brightness at phase angle zero, an arrangement known as opposition.

The absolute magnitude formula_12 can be used to calculate the apparent magnitude formula_14 of a body. For an object reflecting sunlight, formula_12 and formula_14 are connected by the relation
where formula_18 is the phase angle, the angle between the body-Sun and body–observer lines. formula_19 is the phase integral (the integration of reflected light; a number in the 0 to 1 range).

By the law of cosines, we have:

Distances:

The value of formula_19 depends on the properties of the reflecting surface, in particular on its roughness. In practice, different approximations are used based on the known or assumed properties of the surface.

Planetary bodies can be approximated reasonably well as ideal diffuse reflecting spheres. Let formula_18 be the phase angle in degrees, then

A full-phase diffuse sphere reflects two-thirds as much light as a diffuse flat disk of the same diameter. A quarter phase (formula_25) has formula_26 as much light as full phase (formula_27).

For contrast, a "diffuse disk reflector model" is simply formula_28, which isn't realistic, but it does represent the opposition surge for rough surfaces that reflect more uniform light back at low phase angles.

The definition of the geometric albedo formula_29, a measure for the reflectivity of planetary surfaces, is based on the diffuse disk reflector model. The absolute magnitude formula_12, diameter formula_31 (in kilometers) and geometric albedo formula_29 of a body are related by

Example: The Moon's absolute magnitude formula_12 can be calculated from its diameter formula_35 and geometric albedo formula_36:
We have formula_38, formula_39
At quarter phase, formula_40 (according to the diffuse reflector model), this yields an apparent magnitude of formula_41 The actual value is somewhat lower than that, formula_42 The phase curve of the Moon is too complicated for the diffuse reflector model.

Because Solar System bodies are never perfect diffuse reflectors, astronomers use different models to predict apparent magnitudes based on known or assumed properties of the body. For planets, approximations for the correction term formula_43 in the formula for have been derived empirically, to match observations at different phase angles. The approximations recommended by the Astronomical Almanac are (with formula_18 in degrees):
Here formula_45 is the effective inclination of Saturn's rings (their tilt relative to the observer), which as seen from Earth varies between 0° and 27° over the course of one Saturn orbit, and formula_46 is a small correction term depending on Uranus' sub-Earth and sub-solar latitudes. formula_47 is the Common Era year. Neptune's absolute magnitude is changing slowly due to seasonal effects as the planet moves along its 165-year orbit around the Sun, and the approximation above is only valid after the year 2000. For some circumstances, like formula_48 for Venus, no observations are available, and the phase curve is unknown in those cases.

Example: On 1 January 2019, Venus was formula_49 from the Sun, and formula_50 from Earth, at a phase angle of formula_51 (near quarter phase). Under full-phase conditions, Venus would have been visible at formula_52 Accounting for the high phase angle, the correction term above yields an actual apparent magnitude of formula_53 This is close to the value of formula_54 predicted by the Jet Propulsion Laboratory.

Earth's albedo varies by a factor of 6, from 0.12 in the cloud-free case to 0.76 in the case of altostratus cloud. The absolute magnitude here corresponds to an albedo of 0.434. Earth's apparent magnitude cannot be predicted as accurately as that of most other planets.

If an object has an atmosphere, it reflects light more or less isotropically in all directions, and its brightness can be modelled as a diffuse reflector. Atmosphereless bodies, like asteroids or moons, tend to reflect light more strongly to the direction of the incident light, and their brightness increases rapidly as the phase angle approaches formula_55. This rapid brightening near opposition is called the opposition effect. Its strength depends on the physical properties of the body's surface, and hence it differs from asteroid to asteroid.

In 1985, the IAU adopted the semi-empirical formula_56-system, based on two parameters formula_12 and formula_58 called "absolute magnitude" and "slope", to model the opposition effect for the ephemerides published by the Minor Planet Center.

where 
and

This relation is valid for phase angles formula_68, and works best when formula_69.

The slope parameter formula_58 relates to the surge in brightness, typically , when the object is near opposition. It is known accurately only for a small number of asteroids, hence for most asteroids a value of formula_71 is assumed. In rare cases, formula_58 can be negative. An example is 101955 Bennu, with formula_73.

In 2012, the formula_56-system was officially replaced by an improved system with three parameters formula_12, formula_76 and formula_77, which produces more satisfactory results if the opposition effect is very small or restricted to very small phase angles. However, as of 2019, this formula_78-system has not been adopted by either the Minor Planet Center nor Jet Propulsion Laboratory.

The apparent magnitude of asteroids varies as they rotate, on time scales of seconds to weeks depending on their rotation period, by up to formula_79 or more. In addition, their absolute magnitude can vary with the viewing direction, depending on their axial tilt. In many cases, neither the rotation period nor the axial tilt are known, limiting the predictability. The models presented here do not capture those effects.

The brightness of comets is given separately as "total magnitude" (formula_80, the brightness integrated over the entire visible extend of the coma) and "nuclear magnitude" (formula_81, the brightness of the core region alone). Both are different scales than the magnitude scale used for planets and asteroids, and can not be used for a size comparison with an asteroid's absolute magnitude .

The activity of comets varies with their distance from the Sun. Their brightness can be approximated as
where formula_84 are the total and nuclear apparent magnitudes of the comet, respectively, formula_85 are its "absolute" total and nuclear magnitudes, formula_86 and formula_87 are the body-sun and body-observer distances, formula_88 is the Astronomical Unit, and formula_89 are the slope parameters characterising the comet's activity. For formula_90, this reduces to the formula for a purely reflecting body.

For example, the lightcurve of comet C/2011 L4 (PANSTARRS) can be approximated by formula_91 On the day of its perihelion passage, 10 March 2013, comet PANSTARRS was formula_92 from the Sun and formula_93 from Earth. The total apparent magnitude formula_80 is predicted to have been formula_95 at that time. The Minor Planet Center gives a value close to that, formula_96.

At the same distance, Comet Hale-Bopp is about 130 times brighter than Comet Halley.

The absolute magnitude of any given comet can vary dramatically. It can change as the comet becomes more or less active over time, or if it undergoes an outburst. This makes it difficult to use the absolute magnitude for a size estimate. When comet 289P/Blanpain was discovered in 1819, its absolute magnitude was estimated as formula_97. It was subsequently lost, and was only rediscovered in 2003. At that time, its absolute magnitude had decreased to formula_98, and it was realised that the 1819 apparition coincided with an outburst. 289P/Blanpain reached naked eye brightness (5-8 mag) in 1819, even though it is the comet with the smallest nucleus that has ever been physically characterised, and usually doesn't become brighter than 18 mag.

For some comets that have been observed at heliocentric distances large enough to distinguish between light reflected from the coma, and light from the nucleus itself, an absolute magnitude analogous to that used for asteroids has been calculated, allowing to estimate the sizes of their nuclei.

For a meteor, the standard distance for measurement of magnitudes is at an altitude of at the observer's zenith.


/5}</math>, where formula_99, the absolute magnitude of the Sun, and formula_100</ref>



</doc>
<doc id="1965" url="https://en.wikipedia.org/wiki?curid=1965" title="Apollo 1">
Apollo 1

Apollo 1, initially designated AS-204, was the first crewed mission of the United States Apollo program, the program to land the first men on the Moon. Planned as the first low Earth orbital test of the Apollo command and service module with a crew, to launch on February 21, 1967, the mission never flew; a cabin fire during a launch rehearsal test at Cape Kennedy Air Force Station Launch Complex 34 on January 27 killed all three crew members—Command Pilot Virgil I. "Gus" Grissom, Senior Pilot Ed White, and Pilot Roger B. Chaffee—and destroyed the command module (CM). The name "Apollo 1", chosen by the crew, was officially retired by NASA in commemoration of them.

Immediately after the fire, NASA convened the "Apollo 204 Accident Review Board" to determine the cause of the fire, and both houses of the United States Congress conducted their own committee inquiries to oversee NASA's investigation. The ignition source of the fire was determined to be electrical, and the fire spread rapidly due to combustible nylon material, and the high pressure, pure oxygen cabin atmosphere. Rescue was prevented by the plug door hatch, which could not be opened against the internal pressure of the cabin. Because the rocket was unfueled, the test had not been considered hazardous, and emergency preparedness for it was poor.

During the Congressional investigation, Senator Walter Mondale publicly revealed a NASA internal document citing problems with prime Apollo contractor North American Aviation, which became known as the "Phillips Report". This disclosure embarrassed NASA Administrator James E. Webb, who was unaware of the document's existence, and attracted controversy to the Apollo program. Despite congressional displeasure at NASA's lack of openness, both congressional committees ruled that the issues raised in the report had no bearing on the accident.

Manned Apollo flights were suspended for 20 months while the command module's hazards were addressed. However, the development and unmanned testing of the lunar module (LM) and Saturn V Moon rocket continued. The Saturn IB launch vehicle for Apollo 1, SA-204, was used for the first LM test flight, Apollo 5. The first successful manned Apollo mission was flown by Apollo 1's backup crew on Apollo 7 in October 1968.

AS-204 was to be the first manned test flight of the Apollo command and service module (CSM) to Earth orbit, launched on a Saturn IB rocket. AS-204 was to test launch operations, ground tracking and control facilities and the performance of the Apollo-Saturn launch assembly and would have lasted up to two weeks, depending on how the spacecraft performed.

The CSM for this flight, number 012 built by North American Aviation (NAA), was a Block I version designed before the lunar orbit rendezvous landing strategy was chosen; therefore it lacked capability of docking with the lunar module. This was incorporated into the Block II CSM design, along with lessons learned in Block I. Block II would be test-flown with the LM when the latter was ready, and would be used on the Moon landing flights.

Director of Flight Crew Operations Deke Slayton selected the first Apollo crew in January 1966, with Grissom as Command Pilot, White as Senior Pilot, and rookie Donn F. Eisele as Pilot. But Eisele dislocated his shoulder twice aboard the KC135 weightlessness training aircraft, and had to undergo surgery on January 27. Slayton replaced him with Chaffee, and NASA announced the crew selection on March 21, 1966. James McDivitt, David Scott and Russell Schweickart were named as the backup crew.

On September 29, Walter Schirra, Eisele, and Walter Cunningham were named as the prime crew for a second Block I CSM flight, AS-205. NASA planned to follow this with an unmanned test flight of the LM (AS-206), then the third manned mission would be a dual flight designated AS-278 (or AS-207/208), in which AS-207 would launch the first manned Block II CSM, which would then rendezvous and dock with the LM launched unmanned on AS-208.

In March, NASA was studying the possibility of flying the first Apollo mission as a joint space rendezvous with the final Project Gemini mission, Gemini 12 in November 1966. But by May, delays in making Apollo ready for flight just by itself, and the extra time needed to incorporate compatibility with the Gemini, made that impractical. This became moot when slippage in readiness of the AS-204 spacecraft caused the last-quarter 1966 target date to be missed, and the mission was rescheduled for February 21, 1967.

Grissom declared his intent to keep his craft in orbit for a full 14 days. A newspaper article published on August 4, 1966, referred to the flight as "Apollo 1". CM-012 arrived at the Kennedy Space Center on August 26, labeled "Apollo One" by NAA on its packaging.

In October 1966, NASA announced the flight would carry a small television camera to broadcast live from the command module. The camera would also be used to allow flight controllers to monitor the spacecraft's instrument panel in flight. Television cameras were carried aboard all manned Apollo missions.

Grissom's crew received approval in June 1966 to design a mission patch with the name "Apollo 1". The design's center depicts a command and service module flying over the southeastern United States with Florida (the launch point) prominent. The Moon is seen in the distance, symbolic of the eventual program goal. A yellow border carries the mission and astronaut names with another border set with stars and stripes, trimmed in gold. The insignia was designed by the crew, with the artwork done by North American Aviation employee Allen Stevens.

The Apollo command and service module was much bigger and far more complex than any previously implemented spacecraft design. In October 1963, Joseph F. Shea was named Apollo Spacecraft Program Office (ASPO) manager, responsible for managing the design and construction of both the CSM and the LM.
In a spacecraft review meeting held with Shea on August 19, 1966 (a week before delivery), the crew expressed concern about the amount of flammable material (mainly nylon netting and Velcro) in the cabin, which both astronauts and technicians found convenient for holding tools and equipment in place. Although Shea gave the spacecraft a passing grade, after the meeting they gave him a crew portrait they had posed with heads bowed and hands clasped in prayer, with the inscription:

Shea gave his staff orders to tell North American to remove the flammables from the cabin, but did not supervise the issue personally.

North American shipped spacecraft CM-012 to Kennedy Space Center on August 26, 1966, under a conditional Certificate of Flight Worthiness: 113 significant incomplete planned engineering changes had to be completed at KSC. But that was not all; an additional 623 engineering change orders were made and completed after delivery. Grissom became so frustrated with the inability of the training simulator engineers to keep up with the spacecraft changes, that he took a lemon from a tree by his house and hung it on the simulator.

The command and service modules were mated in the KSC altitude chamber in September, and combined system testing was performed. Altitude testing was performed first unmanned, then with both the prime and backup crews, from October 10 through December 30. During this testing, the environmental control unit in the command module was found to have a design flaw, and was sent back to the manufacturer for design changes and rework. The returned ECU then leaked water/glycol coolant, and had to be returned a second time. Also during this time, a propellant tank in service module 017 had ruptured during testing at NAA, prompting the separation of the modules and removal from the chamber so the service module could be tested for signs of the tank problem. These tests were negative.
In December, the second Block I flight AS-205 was canceled as unnecessary; and Schirra, Eisele and Cunningham were reassigned as the backup crew for Apollo 1. McDivitt's crew was now promoted to prime crew of the Block II / LM mission, re-designated AS-258 because the AS-205 launch vehicle would be used in place of AS-207. A third manned mission was planned to launch the CSM and LM together on a Saturn V (AS-503) to an elliptical medium Earth orbit (MEO), to be crewed by Frank Borman, Michael Collins and William Anders. McDivitt, Scott and Schweickart had started their training for AS-258 in CM-101 at the NAA plant in Downey, California, when the Apollo 1 accident occurred.

Once all outstanding CSM-012 hardware problems were fixed, the reassembled spacecraft finally completed a successful altitude chamber test with Schirra's backup crew on December 30. According to the final report of the accident investigation board, "At the post-test debriefing the backup flight crew expressed their satisfaction with the condition and performance of the spacecraft." This would appear to contradict the account given in "Lost Moon: The Perilous Voyage of Apollo 13" by Jeffrey Kluger and astronaut James Lovell, that "When the trio climbed out of the ship, … Schirra made it clear that he was not pleased with what he had seen," and that he later warned Grissom and Shea that "there's nothing wrong with this ship that I can point to, but it just makes me uncomfortable. Something about it just doesn't ring right," and that Grissom should get out at the first sign of trouble.

Following the successful altitude tests, the spacecraft was removed from the altitude chamber on January 3, 1967, and mated to its Saturn IB launch vehicle on pad 34 on January 6.

The launch simulation on January 27, 1967, on pad 34, was a "plugs-out" test to determine whether the spacecraft would operate nominally on (simulated) internal power while detached from all cables and umbilicals. Passing this test was essential to making the February 21 launch date. The test was considered non-hazardous because neither the launch vehicle nor the spacecraft was loaded with fuel or cryogenics, and all pyrotechnic systems (explosive bolts) were disabled.

At 1:00 pm EST (1800 GMT) on January 27, first Grissom, then Chaffee, and White entered the command module fully pressure-suited, and were strapped into their seats and hooked up to the spacecraft's oxygen and communication systems. Grissom immediately noticed a strange odor in the air circulating through his suit which he compared to "sour buttermilk", and the simulated countdown was held at 1:20 pm, while air samples were taken. No cause of the odor could be found, and the countdown was resumed at 2:42 pm. The accident investigation found this odor not to be related to the fire.

Three minutes after the count was resumed, the hatch installation was started. The hatch consisted of three parts: a removable inner hatch, which stayed inside the cabin; a hinged outer hatch, which was part of the spacecraft's heat shield; and an outer hatch cover, which was part of the boost protective cover enveloping the entire command module to protect it from aerodynamic heating during launch, and from launch escape rocket exhaust in the event of a launch abort. The boost hatch cover was partially, but not fully, latched in place because the flexible boost protective cover was slightly distorted by some cabling run under it to provide the simulated internal power. (The spacecraft's fuel cell reactants were not loaded for this test.) After the hatches were sealed, the air in the cabin was replaced with pure oxygen at , higher than atmospheric pressure.

Movement by the astronauts was detected by the spacecraft's inertial measurement unit and the astronaut's biomedical sensors, and also indicated by increases in oxygen spacesuit flow, and sounds from Grissom's stuck-open microphone. There was no evidence to identify the movement, or whether it was related to the fire. The stuck microphone was part of a problem with the communications loop connecting the crew, the Operations and Checkout Building, and the Complex 34 blockhouse control room. The poor communications led Grissom to remark: "How are we going to get to the Moon if we can't talk between two or three buildings?" The simulated countdown was held again at 5:40 pm while attempts were made to troubleshoot the communications problem. All countdown functions up to the simulated internal power transfer had been successfully completed by 6:20 pm, but at 6:30 the count remained on hold at T minus 10 minutes.

The crew members were using the time to run through their checklist again, when a momentary increase in AC Bus 2 voltage occurred. Nine seconds later (at 6:31:04.7), one of the astronauts (some listeners and laboratory analysis indicate Grissom) exclaimed "Hey!", "Fire!", or "Flame!"; this was followed by two seconds of scuffling sounds through Grissom's open microphone. This was immediately followed at 6:31:06.2 (23:31:06.2 GMT) by someone (believed by most listeners, and supported by laboratory analysis, to be Chaffee) saying, "[I've, or We've] got a fire in the cockpit." After 6.8 seconds of silence, a second, badly garbled transmission occurred, interpreted by various listeners as:
This transmission lasted 5.0 seconds and ended with a cry of pain.

Some blockhouse witnesses said that they saw White on the television monitors, reaching for the inner hatch release handle as flames in the cabin spread from left to right.

The intensity of the fire fed by pure oxygen caused the pressure to rise to , which ruptured the command module's inner wall at 6:31:19 (23:31:19 GMT, initial phase of the fire). Flames and gases then rushed outside the command module through open access panels to two levels of the pad service structure. Intense heat, dense smoke, and ineffective gas masks designed for toxic fumes rather than heavy smoke hampered the ground crew's attempts to rescue the men. There were fears the command module had exploded, or soon would, and that the fire might ignite the solid fuel rocket in the launch escape tower above the command module, which would have likely killed nearby ground personnel, and possibly have destroyed the pad.

As the pressure was released by the cabin rupture, the convective rush of air caused the flames to spread across the cabin, beginning the second phase. The third phase began when most of the oxygen was consumed and was replaced with atmospheric air, essentially quenching the fire, but causing high concentrations of carbon monoxide and heavy smoke to fill the cabin, and large amounts of soot to be deposited on surfaces as they cooled.

It took five minutes for the pad workers to open all three hatch layers, and they could not drop the inner hatch to the cabin floor as intended, so they pushed it out of the way to one side. Although the cabin lights remained lit, they were at first unable to find the astronauts through the dense smoke. As the smoke cleared, they found the bodies, but were not able to remove them. The fire had partly melted Grissom's and White's nylon space suits and the hoses connecting them to the life support system. Grissom had removed his restraints and was lying on the floor of the spacecraft. White's restraints were burned through, and he was found lying sideways just below the hatch. It was determined that he had tried to open the hatch per the emergency procedure, but was not able to do so against the internal pressure. Chaffee was found strapped into his right-hand seat, as procedure called for him to maintain communication until White opened the hatch. Because of the large strands of melted nylon fusing the astronauts to the cabin interior, removing the bodies took nearly 90 minutes.

Deke Slayton was possibly the first NASA official to examine the spacecraft interior. His testimony contradicted the official report concerning the position of Grissom's body. Slayton said of Grissom and White's bodies, "It is very difficult for me to determine the exact relationships of these two bodies. They were sort of jumbled together, and I couldn't really tell which head even belonged to which body at that point. I guess the only thing that was real obvious is that both bodies were at the lower edge of the hatch. They were not in the seats. They were almost completely clear of the seat areas."

As a result of the in-flight failure of the Gemini 8 mission on March 17, 1966, NASA Deputy Administrator Robert Seamans wrote and implemented "Management Instruction 8621.1" on April 14, 1966, defining "Mission Failure Investigation Policy And Procedures". This modified NASA's existing accident procedures, based on military aircraft accident investigation, by giving the Deputy Administrator the option of performing independent investigations of major failures, beyond those for which the various Program Office officials were normally responsible. It declared, "It is NASA policy to investigate and document the causes of all major mission failures which occur in the conduct of its space and aeronautical activities and to take appropriate corrective actions as a result of the findings and recommendations."

Immediately after the Apollo 1 fire, to avoid appearance of a conflict of interest, NASA Administrator James E. Webb asked President Lyndon B. Johnson to allow NASA to handle the investigation according to its established procedure, promising to be truthful in assessing blame, and to keep the appropriate leaders of Congress informed. Seamans then directed establishment of the "Apollo 204 Review Board" chaired by Langley Research Center director Floyd L. Thompson, which included astronaut Frank Borman, spacecraft designer Maxime Faget, and six others. On February 1, Cornell University professor Frank A. Long left the board, and was replaced by Dr. Robert W. Van Dolah, of the U.S. Bureau of Mines. The next day, North American's chief engineer for Apollo, George Jeffs, also left.

Seamans immediately ordered all Apollo 1 hardware and software impounded, to be released only under control of the board. After thorough stereo photographic documentation of the CM-012 interior, the board ordered its disassembly using procedures tested by disassembling the identical CM-014, and conducted a thorough investigation of every part. The board also reviewed the astronauts' autopsy results and interviewed witnesses. Seamans sent Webb weekly status reports of the investigation's progress, and the board issued its final report on April 5, 1967.

According to the Board, Grissom suffered severe third degree burns on over one-third of his body and his spacesuit was mostly destroyed. White suffered third degree burns on almost half of his body and a quarter of his spacesuit had melted away. Chaffee suffered third degree burns over almost a quarter of his body and a small portion of his spacesuit was damaged. The autopsy report confirmed that the primary cause of death for all three astronauts was cardiac arrest caused by high concentrations of carbon monoxide. Burns suffered by the crew were not believed to be major factors, and it was concluded that most of them had occurred postmortem. Asphyxiation occurred after the fire melted the astronauts' suits and oxygen tubes, exposing them to the lethal atmosphere of the cabin.

The review board identified several major factors which combined to cause the fire and the astronauts' deaths:

The review board determined that the electrical power momentarily failed at 23:30:55 GMT, and found evidence of several electric arcs in the interior equipment. They were unable to conclusively identify a single ignition source. They determined that the fire most likely started near the floor in the lower left section of the cabin, close to the Environmental Control Unit. It spread from the left wall of the cabin to the right, with the floor being affected only briefly.

The board noted that a silver-plated copper wire, running through an environmental control unit near the center couch, had become stripped of its Teflon insulation and abraded by repeated opening and closing of a small access door.

This weak point in the wiring also ran near a junction in an ethylene glycol/water cooling line that had been prone to leaks. The electrolysis of ethylene glycol solution with the silver anode was discovered at MSC on May 29, 1967, to be a hazard capable of causing a violent exothermic reaction, igniting the ethylene glycol mixture in the CM's pure oxygen atmosphere. Experiments at the Illinois Institute of Technology confirmed the hazard existed for silver-plated wires, but not for copper-only or nickel-plated copper. In July, ASPO directed both North American and Grumman to ensure no silver or silver-coated electrical contacts existed in the vicinity of possible glycol spills in the Apollo spacecraft.

The plugs-out test had been run to simulate the launch procedure, with the cabin pressurized with pure oxygen at the nominal launch level of , above standard sea level atmospheric pressure. This is more than five times the partial pressure of oxygen in the atmosphere, and provides an environment in which materials not normally considered highly flammable will burst into flame.

The high-pressure oxygen atmosphere was similar to that which had been used successfully in the Mercury and Gemini programs. The pressure before launch was deliberately greater than ambient in order to drive out the nitrogen-containing air and replace it with pure oxygen, and also to seal the plug door hatch cover. During launch, the pressure would have been gradually reduced to the in-flight level of , providing sufficient oxygen for the astronauts to breathe while reducing the fire risk. The Apollo 1 crew had successfully tested this procedure with their spacecraft in the Operations and Checkout Building altitude (vacuum) chamber on October 18 and 19, 1966, and the backup crew of Schirra, Eisele and Cunningham had repeated it on December 30. The investigation board noted that, during these tests, the command module had been fully pressurized with pure oxygen four times, for a total of six hours and fifteen minutes, two and a half hours longer than it had been during the plugs-out test.

The review board cited "many types and classes of combustible material" close to ignition sources. The NASA crew systems department had installed of Velcro throughout the spacecraft, almost like carpeting. This Velcro was found to be flammable in a high-pressure 100% oxygen environment. Astronaut Buzz Aldrin states in his book "Men From Earth" that the flammable material had been removed per the crew's August 19 complaints and Joseph Shea's order, but was replaced before the August 26 delivery to Cape Kennedy.

The inner hatch cover used a plug door design, sealed by higher pressure inside the cabin than outside. The normal pressure level used for launch ( above ambient) created sufficient force to prevent removing the cover until the excess pressure was vented. Emergency procedure called for Grissom to open the cabin vent valve first, allowing White to remove the cover, but Grissom was prevented from doing this because the valve was located to the left, behind the initial wall of flames. Also, while the system could easily vent the normal pressure, its flow capacity was utterly incapable of handling the rapid increase to absolute caused by the intense heat of the fire.

North American had originally suggested the hatch open outward and use explosive bolts to blow the hatch in case of emergency, as had been done in Project Mercury. NASA did not agree, arguing the hatch could accidentally open, as it had on Grissom's "Liberty Bell 7" flight, so the Manned Spacecraft Center designers rejected the explosive design in favor of a mechanically operated one for the Gemini and Apollo programs. Before the fire, the Apollo astronauts had recommended changing the design to an outward-opening hatch, and this was already slated for inclusion in the Block II command module design. According to Donald K. Slayton's testimony before the House investigation of the accident, this was based on ease of exit for spacewalks and at the end of flight, rather than for emergency exit.

The board noted that the test planners had failed to identify the test as hazardous; the emergency equipment (such as gas masks) were inadequate to handle this type of fire; that fire, rescue, and medical teams were not in attendance; and that the spacecraft work and access areas contained many hindrances to emergency response such as steps, sliding doors, and sharp turns.

When designing the Mercury spacecraft, NASA had considered using a nitrogen/oxygen mixture to reduce the fire risk near launch, but rejected it based on two considerations. First, nitrogen used with the in-flight pressure reduction carried the risk of decompression sickness (known as "the bends"). But the decision to eliminate the use of any gas but oxygen was crystalized when a serious accident occurred on April 21, 1960, in which McDonnell Aircraft test pilot G.B. North passed out and was seriously injured when testing a Mercury cabin / spacesuit atmosphere system in a vacuum chamber. The problem was found to be nitrogen-rich (oxygen-poor) air leaking from the cabin into his spacesuit feed. North American Aviation had suggested using an oxygen/nitrogen mixture for Apollo, but NASA overruled this. The pure oxygen design was judged to be safer, less complicated, and lighter in weight.

In his monograph "Project Apollo: The Tough Decisions", Deputy Administrator Seamans wrote that NASA's worst mistake in engineering judgment was not to run a fire test on the command module before the plugs-out test. In the first episode of the 2009 BBC documentary series "NASA: Triumph and Tragedy", Jim McDivitt said that NASA had no idea how a 100% oxygen atmosphere would influence burning. Similar remarks by other astronauts were expressed in the 2007 documentary film "In the Shadow of the Moon".

Several fires in high-oxygen test environments had occurred before the Apollo fire. In 1962, USAF Colonel B. Dean Smith was conducting a test of the Gemini space suit with a colleague in a pure oxygen chamber at Brooks Air Force Base in San Antonio, Texas when a fire broke out, destroying the chamber. Smith and his partner narrowly escaped. On February 16, 1965, United States Navy Divers Fred Jackson and John Youmans were killed in a decompression chamber fire at the Experimental Diving Unit in Washington, D.C., shortly after additional oxygen was added to the chamber's atmospheric mix.

Other oxygen fire occurrences are documented in reports archived in the National Air and Space Museum, such as:

Incidents had also occurred in the Soviet space program, but due to the government's policy of secrecy, these were not disclosed until well after the Apollo 1 fire. Cosmonaut Valentin Bondarenko died on March 23, 1961, from burns sustained in a fire while participating in a 15-day endurance experiment in a high-oxygen isolation chamber, less than three weeks before the first Vostok manned space flight; this was disclosed on January 28, 1986.

During the Voskhod 2 mission in March 1965, cosmonauts Pavel Belyayev and Alexei Leonov could not completely seal the spacecraft hatch after Leonov's historic first walk in space. The spacecraft's environmental control system responded to the leaking air by adding more oxygen to the cabin, causing the concentration level to rise as high as 45%. The crew and ground controllers worried about the possibility of fire, remembering Bondarenko's death four years earlier.

On January 31, 1967, four days after the Apollo 1 fire, United States Air Force airmen William F. Bartley, Jr., and Richard G. Harmon were killed in a flash fire while tending laboratory rabbits in the Two Man Space Environment Simulator, a pure oxygen chamber at the School of Aerospace Medicine at Brooks Air Force Base. Like the Apollo 1 fire, the School fire was caused by an electrical spark in a pure oxygen environment. The widows of the Apollo 1 crew sent condolence letters to Bartley and Harmon's families.

Committees in both houses of the United States Congress with oversight of the space program soon launched investigations, including the Senate Committee on Aeronautical and Space Sciences, chaired by Senator Clinton P. Anderson. Seamans, Webb, Manned Space Flight Administrator Dr. George E. Mueller, and Apollo Program Director Maj Gen Samuel C. Phillips were called to testify before Anderson's committee.

In the February 27 hearing, Senator Walter F. Mondale asked Webb if he knew of a report of extraordinary problems with the performance of North American Aviation on the Apollo contract. Webb replied he did not, and deferred to his subordinates on the witness panel. Mueller and Phillips responded they too were unaware of any such "report".

However, in late 1965, just over a year before the accident, Phillips had headed a "tiger team" investigating the causes of inadequate quality, schedule delays, and cost overruns in both the Apollo CSM and the Saturn V second stage (for which North American was also prime contractor). He gave an oral presentation (with transparencies) of his team's findings to Mueller and Seamans, and also presented them in a memo to North American president John L. Atwood, to which Mueller appended his own strongly worded memo to Atwood.

During Mondale's 1967 questioning about what was to become known as the "Phillips Report", Seamans was afraid Mondale might actually have seen a hard copy of Phillips' presentation, and responded that contractors have occasionally been subjected to on-site progress reviews; perhaps this was what Mondale's information referred to. Mondale continued to refer to "the Report" despite Phillips' refusal to characterize it as such, and angered by what he perceived as Webb's deception and concealment of important program problems from Congress, he questioned NASA's selection of North American as prime contractor. Seamans later wrote that Webb roundly chastised him in the cab ride leaving the hearing, for volunteering information which led to the disclosure of Phillips' memo.

On May 11, Webb issued a statement defending NASA's November 1961 selection of North American as the prime contractor for Apollo. This was followed on June 9 by Seamans filing a seven-page memorandum documenting the selection process. Webb eventually provided a controlled copy of Phillips' memo to Congress. The Senate committee noted in its final report NASA's testimony that "the findings of the [Phillips] task force had no effect on the accident, did not lead to the accident, and were not related to the accident", but stated in its recommendations:
Freshman Senators Edward W. Brooke III and Charles H. Percy jointly wrote an "Additional Views" section appended to the committee report, chastising NASA more strongly than Anderson for not having disclosed the Phillips review to Congress. Mondale wrote his own, even more strongly worded Additional View, accusing NASA of "evasiveness, … lack of candor, … patronizing attitude toward Congress, … refusal to respond fully and forthrightly to legitimate Congressional inquiries, and … solicitous concern for corporate sensitivities at a time of national tragedy."

The potential political threat to Apollo blew over, due in large part to the support of President Lyndon B. Johnson, who at the time still wielded a measure of influence with the Congress from his own Senatorial experience. He was a staunch supporter of NASA since its inception, had even recommended the Moon program to President John F. Kennedy in 1961, and was skilled at portraying it as part of Kennedy's legacy.

Relations between NASA and North American deteriorated over assignment of blame. North American argued unsuccessfully it was not responsible for the fatal error in spacecraft atmosphere design. Finally, Webb contacted Atwood, and demanded either he or Chief Engineer Harrison A. Storms resign. Atwood elected to fire Storms.

On the NASA side, Joseph Shea resorted to barbiturates and alcohol in order to help him cope. NASA administrator James Webb became increasingly worried about Shea's mental state. Shea was asked to take an extended voluntary leave of absence, but Shea refused, threatening to resign rather than take leave. As a compromise, he agreed to meet with a psychiatrist and to abide by an independent assessment of his psychological fitness. This approach to remove Shea from his position was also unsuccessful. Finally, six months after the fire, Shea's superiors reassigned him to NASA headquarters in Washington, D.C. Shea felt that his new post was a "non-job," and left after only two months.

Gene Kranz called a meeting of his staff in Mission Control three days after the accident, delivering a speech which has subsequently become one of NASA's principles. Speaking of the errors and overall attitude surrounding the Apollo program before the accident, he stated: "We were too 'gung-ho' about the schedule and we blocked out all of the problems we saw each day in our work. Every element of the program was in trouble and so were we." He reminded the team of the perils and mercilessness of their endeavor, and stated the new requirement that every member of every team in mission control be "tough and competent", requiring nothing less than perfection throughout NASA's programs. In 2003, following the Space Shuttle "Columbia" disaster, NASA administrator Sean O'Keefe quoted Kranz's speech, applying it to the "Columbia" crew.

After the fire, the Apollo program was grounded for review and redesign. The command module was found to be extremely hazardous and, in some instances, carelessly assembled (for example, a misplaced wrench socket was found in the cabin).

It was decided that remaining Block I spacecraft would be used only for unmanned Saturn V test flights. All manned missions would use the Block II spacecraft, to which many command module design changes were made:

Thorough protocols were implemented for documenting spacecraft construction and maintenance.

The astronauts' widows asked that "Apollo 1" be reserved for the flight their husbands never made, and on April 24, 1967, Mueller, as Associate Administrator for Manned Space Flight, announced this change officially: AS-204 would be recorded as Apollo 1, "first manned Apollo Saturn flight – failed on ground test". Even though three unmanned Apollo missions (AS-201, AS-202, and AS-203) had previously occurred, only AS-201 and AS-202 carried spacecraft. Therefore, the next mission, the first unmanned Saturn V test flight (AS-501) would be designated Apollo 4, with all subsequent flights numbered sequentially in the order flown. The first three flights would not be renumbered, and the names "Apollo 2" and "Apollo 3" would officially go unused. Mueller considered AS-201 and AS-202, the first and second flights of the Apollo Block I CSM, as Apollo 2 and 3 respectively.

The manned flight hiatus allowed work to catch up on the Saturn V and lunar module, which were encountering their own delays. Apollo 4 flew in November 1967. Apollo 1's (AS-204) Saturn IB rocket was taken down from Launch Complex 34, later reassembled at Launch complex 37B and used to launch Apollo 5, an unmanned Earth orbital test flight of the first lunar module, LM-1, in January 1968. A second unmanned Saturn V AS-502 flew as Apollo 6 in April 1968, and Grissom's backup crew of Wally Schirra, Don Eisele, and Walter Cunningham, finally flew the orbital test mission as Apollo 7 (AS-205), in a Block II CSM in October 1968.

Gus Grissom and Roger Chaffee were buried at Arlington National Cemetery. Ed White was buried at West Point Cemetery on the grounds of the United States Military Academy in West Point, New York. Their names are among those of several astronauts and cosmonauts who have died in the line of duty, listed on the Space Mirror Memorial at the Kennedy Space Center Visitor Complex in Merritt Island, Florida. President Jimmy Carter awarded the Congressional Space Medal of Honor posthumously to Grissom on October 1, 1978. President Bill Clinton awarded it to White and Chaffee on December 17, 1997.
An Apollo 1 mission patch was left on the Moon's surface after the first manned lunar landing by Apollo 11 crew members Neil Armstrong and Buzz Aldrin. The Apollo 15 mission left on the surface of the Moon a tiny memorial statue, "Fallen Astronaut", along with a plaque containing the names of the Apollo 1 astronauts, among others including Soviet cosmonauts, who perished in the pursuit of human space flight.

After the Apollo 1 fire, Launch Complex 34 was subsequently used only for the launch of Apollo 7 and later dismantled down to the concrete launch pedestal, which remains at the site () along with a few other concrete and steel-reinforced structures. The pedestal bears two plaques commemorating the crew. Each year the families of the Apollo 1 crew are invited to the site for a memorial, and the Kennedy Space Center Visitor Complex includes the site during the tour of the historic Cape Canaveral launch sites.

In January 2005, three granite benches, built by a college classmate of one of the astronauts, were installed at the site on the southern edge of the launch pad. Each bears the name of one of the astronauts and his military service insignia.


The Apollo 1 command module has never been on public display. After the accident, the spacecraft was removed and taken to Kennedy Space Center to facilitate the review board's disassembly in order to investigate the cause of the fire. When the investigation was complete, it was moved to the NASA Langley Research Center in Hampton, Virginia, and placed in a secured storage warehouse.
On February 17, 2007, the parts of CM-012 were moved approximately to a newer, environmentally controlled warehouse. Only a few weeks earlier, Gus Grissom's brother Lowell publicly suggested CM-012 be permanently entombed in the concrete remains of Launch Complex 34.

On January 27, 2017, the 50th anniversary of the fire, NASA put the hatch from Apollo 1 on display at the Saturn V Rocket Center at Kennedy Space Center Visitors Center. KSC's Visitor Center also houses memorials that include parts of "Challenger" and "Columbia," which is located in the Atlantis exhibit. "This is way, way, way long overdue. But we're excited about it," said Scott Grissom, Gus Grissom's older son.



Notes

Citations




</doc>
<doc id="1966" url="https://en.wikipedia.org/wiki?curid=1966" title="Apollo 10">
Apollo 10

Apollo 10 was a May 1969 human spaceflight, the fourth crewed mission in the United States Apollo program, and the second (after Apollo 8) to orbit the Moon. It was the F mission: a "dress rehearsal" for the first Moon landing, testing all of the components and procedures, just short of actually landing. The Apollo Lunar Module (LM) was flown to a descent orbit within of the lunar surface, at the point where powered descent for landing would normally begin. After orbiting the Moon 31 times Apollo 10 returned safely to Earth, and its success enabled the first landing to be attempted on the Apollo 11 mission two months later.

According to the 2002 "Guinness World Records", Apollo 10 set the record for the highest speed attained by a crewed vehicle: 39,897 km/h (11.08 km/s or 24,791 mph) on May 26, 1969, during the return from the Moon.

The mission's call signs were the names of the "Peanuts" characters Charlie Brown and Snoopy, who became Apollo 10's semi-official mascots. "Peanuts" creator Charles Schulz also drew mission-related artwork for NASA. 



Apollo 10 and Apollo 11 were the only Apollo missions whose crew were all veterans of spaceflight. Thomas P. Stafford had flown on Gemini 6 and Gemini 9; John W. Young had flown on Gemini 3 and Gemini 10, and Eugene A. Cernan had flown with Stafford on Gemini 9.

In addition, Apollo 10 was the only Saturn V flight from Launch Complex 39B, as preparations for Apollo 11 at LC-39A had begun in March almost immediately after Apollo 9's launch.

They were also the only Apollo crew all of whose members went on to fly subsequent missions aboard Apollo spacecraft: Young later commanded Apollo 16, Cernan commanded Apollo 17 and Stafford commanded the U.S. vehicle on the Apollo–Soyuz Test Project. It was on Apollo 10 that John Young became the first human to fly solo around the Moon, while Stafford and Cernan flew the LM in lunar orbit as part of the preparations for Apollo 11. Young was also backup commander of Apollo 13 and Apollo 17 and Cernan was backup commander of Apollo 14.

The Apollo 10 crew are also the humans who have traveled the farthest away from home, some from their homes and families in Houston. While most Apollo missions orbited the Moon at the same from the lunar surface, the distance between the Earth and Moon varies by about , between perigee and apogee, throughout the year, and the Earth's rotation make the distance to Houston vary by another each day. The Apollo 10 crew reached the farthest point in their orbit around the far side of the Moon at about the same time Earth's rotation put Houston nearly a full Earth diameter away.

By the normal rotation in place during Apollo, the backup crew would have been scheduled to fly on Apollo 13. However, Alan Shepard, then number two at the Astronaut Office, gave himself the Apollo 13 command slot instead. L. Gordon Cooper Jr., Commander of the Apollo 10 backup crew, was enraged and resigned from NASA. Later, Shepard's crew was forced to switch places with Jim Lovell's tentative Apollo 14 crew.

Deke Slayton wrote in his memoirs that Cooper and Donn F. Eisele were never intended to rotate to another mission as both were out of favor with NASA management for various reasons (Cooper for his lax attitude towards training and Eisele for incidents aboard Apollo 7 and an extramarital affair) and were assigned to the backup crew simply because of a lack of qualified manpower in the Astronaut Office at the time the assignment needed to be made. Cooper, Slayton noted, had a very small chance of receiving the Apollo 13 command if he did an outstanding job with the assignment, which he did not. Eisele, despite his issues with management, was always intended for future assignment to the Apollo Applications Program (which was eventually cut down to only the Skylab component) and not a lunar mission.

This dress rehearsal for a Moon landing brought the Apollo Lunar Module to from the lunar surface, at the point where powered descent would begin on the actual landing. Practicing this approach orbit would refine knowledge of the lunar gravitational field needed to calibrate the powered descent guidance system to within needed for a landing. Earth-based observations, uncrewed spacecraft, and Apollo 8 had respectively allowed calibration to within , , and . Except for this final stretch, the mission was designed to duplicate how a landing would have gone, both in space and for ground control, putting NASA's flight controllers and extensive tracking and control network through a rehearsal.

The ascent stage was loaded with the amount of fuel and oxidizer it would have had remaining if it had lifted off from the surface and reached the altitude at which the Apollo 10 ascent stage fired; this was only about half the total amount required for lift off and rendezvous with the CSM. The mission-loaded LM weighed , compared to for the Apollo 11 LM which made the first landing. Craig Nelson wrote in his book "Rocket Men" that NASA took special precaution to ensure Stafford and Cernan would not attempt to make the first landing. Nelson quoted Cernan as saying "A lot of people thought about the kind of people we were: 'Don't give those guys an opportunity to land, 'cause they might!' So the ascent module, the part we lifted off the lunar surface with, was short-fueled. The fuel tanks weren't full. So had we literally tried to land on the Moon, we couldn't have gotten off."






On May 22, 1969 at 20:35:02 UTC, a 27.4 second LM descent propulsion system burn inserted the LM into a descent orbit of so that the resulting lowest point in the orbit occurred about 15° from lunar landing site 2 (the Apollo 11 landing site). The lowest measured point in the trajectory was above the lunar surface at 21:29:43 UTC.

Shortly after trans-lunar injection, Young performed the transposition, docking, and extraction maneuver, separating the command and service module (CSM) from the S-IVB stage, turning around, and docking its nose to the top of the lunar module (LM), before separating from the S-IVB. Apollo 10 was the first mission to carry a color television camera inside the spacecraft, and made the first live color TV transmissions from space.

After reaching lunar orbit three days later, Young remained in the command module (CM) "Charlie Brown" while Stafford and Cernan entered the LM "Snoopy" and flew it separately. The LM crew performed the descent orbit insertion maneuver by firing their descent engine, and tested their craft's landing radar as they approached the altitude where the subsequent Apollo 11 mission would begin powered descent to actually land on the Moon. They surveyed the future Apollo 11 landing site in the Sea of Tranquility, then jettisoned the descent stage and fired the engine of the ascent stage to return to "Charlie Brown" Command Module. The descent stage was left in orbit, but eventually crashed onto the lunar surface because of the Moon's non-uniform gravitational field. Its location is unknown as it was not tracked.

During descent stage separation, the lunar module began to roll unexpectedly because the crew accidentally duplicated commands into the flight computer which took the LM out of abort mode, the correct configuration for this maneuver. The live network broadcasts caught Cernan and Stafford uttering several expletives before regaining control of the LM. Decades later, Cernan said he observed the horizon spinning eight times over, indicating eight rolls of the spacecraft under ascent engine power. Recordings from the flight do not support this dramatic memory. While the incident was downplayed by NASA, the roll was just several revolutions from being unrecoverable, which would have resulted in the LM crashing into the lunar surface.

After Stafford and Cernan docked with "Charlie Brown" and re-entered it, "Snoopy's" ascent stage was sent on a trajectory past the Moon into a heliocentric orbit by firing its engine to fuel depletion (unlike the subsequent Apollo 11 ascent stage, which was left in lunar orbit to eventually crash; all ascent stages after Apollo 11 were instead intentionally steered into the Moon to obtain readings from seismometers placed on the surface, except for the one on Apollo 13, which did not land but was used as a "life boat" to get the crew back to Earth, and burned up in Earth's atmosphere.)

"Snoopy"'s ascent stage orbit was not tracked after 1969, and its current location is unknown. In 2011, a group of amateur astronomers in the UK started a project to search for it. In 2019, the Royal Astronomical Society announced a possible rediscovery of "Snoopy," determining that small Earth-crossing asteroid "2018 AV2" is likely the capsule with "98%" certainty. It is the only once-crewed spacecraft still in outer space without a crew.

Splashdown occurred in the Pacific Ocean on May 26, 1969, at 16:52:23 UTC, about east of American Samoa. The astronauts were recovered by , and subsequently flown to Pago Pago International Airport in Tafuna for a greeting reception, before being flown on a C-141 cargo plane to Honolulu.

After Apollo 10, NASA required astronauts to choose more "dignified" names for their command and lunar modules. This proved unenforceable: Apollo 16 astronauts Young, Mattingly and Duke chose "Casper", as in Casper the Friendly Ghost, for their command module name. The idea was to give children a way to identify with the mission by using humor.

The Smithsonian has been accountable for the command module "Charlie Brown" since 1970. The spacecraft was on display in several countries until it was placed on loan to the London Science Museum in 1978. "Charlie Brown"'s service module (SM) was jettisoned just before re-entry and burned up in the Earth's atmosphere.

After translunar injection, the Saturn V's S-IVB third stage was accelerated past Earth escape velocity and became a object where , it remains in a heliocentric orbit.

The ascent stage of the Apollo Lunar Module "Snoopy" was jettisoned into a heliocentric orbit. On June 10, 2019 Nick Howes, a fellow of the Royal Astronomical Society, announced that he and his colleagues had located "Snoopy", whose location was previously unknown, based on radar astronomy data with 98% certainty.

The shield-shaped emblem for the flight shows a large, three-dimensional Roman numeral X sitting on the Moon's surface, in Stafford's words, "to show that we had left our mark." Although it did not land on the Moon, the prominence of the number represents the significant contributions the mission made to the Apollo program. A CSM circles the Moon as an LM ascent stage flies up from its low pass over the lunar surface with its engine firing. The Earth is visible in the background. On the mission patch, a wide, light blue border carries the word APOLLO at the top and the crew names around the bottom. The patch is trimmed in gold. The insignia was designed by Allen Stevens of Rockwell International.

In February 2016 Discovery Channel broadcast a TV show suggesting that the mission witnessed mysterious or alien signals while on the far side of the Moon. The astronomers mention the odd whistling sound that lasted nearly an hour. It was speculated that this is an evidence for UFO coverup.
According to space journalist James Oberg, the sound was most probably radio interference between the command module and the lunar module landing vehicles. Describing it as "outer-space type music" was most probably due to priming, as suggested by Benjamin Radford.


NASA reports

Multimedia


</doc>
<doc id="1967" url="https://en.wikipedia.org/wiki?curid=1967" title="Apollo 12">
Apollo 12

Apollo 12 was the sixth manned flight in the United States Apollo program and the second to land on the Moon. It was launched on November 14, 1969, from the Kennedy Space Center, Florida, four months after Apollo 11. Commander Charles "Pete" Conrad and Lunar Module Pilot Alan L. Bean performed just over one day and seven hours of lunar surface activity while Command Module Pilot Richard F. Gordon remained in lunar orbit. The landing site for the mission was located in the southeastern portion of the Ocean of Storms.

Unlike the first landing on Apollo 11, Conrad and Bean achieved a precise landing at their expected location, the site of the "Surveyor 3" unmanned probe, which had landed on April 20, 1967. They carried the first color television camera to the lunar surface on an Apollo flight, but transmission was lost after Bean accidentally destroyed the camera by pointing it at the Sun. On one of two moonwalks, they visited the "Surveyor" and removed some parts for return to Earth. The lunar module lifted off from the Moon and docked with the command module which then, after completing its 45th lunar orbit, traveled back to Earth. The Apollo 12 mission ended on November 24 with a successful splashdown.








Apollo 12 launched on schedule from Kennedy Space Center, under completely overcast rainy skies, encountering wind speeds of during ascent, the highest of any Apollo mission.

Lightning struck the Saturn V 36.5 seconds after lift-off, triggered by the vehicle itself, discharging down to the Earth through the ionized exhaust plume. Protective circuits on the fuel cells in the service module (SM) detected overloads and took all three fuel cells offline, along with much of the command and service module (CSM) instrumentation. A second strike at 52 seconds knocked out the "8-ball" attitude indicator. The telemetry stream at Mission Control was garbled. However, the vehicle continued to fly correctly; the strikes had not affected the Saturn V instrument unit.

The loss of all three fuel cells put the CSM entirely on batteries, which were unable to maintain normal 75-ampere launch loads on the 28-volt DC bus. One of the AC inverters dropped offline. These power supply problems lit nearly every warning light on the control panel and caused much of the instrumentation to malfunction.

Electrical, Environmental and Consumables Manager (EECOM) John Aaron remembered the telemetry failure pattern from an earlier test when a power supply malfunctioned in the CSM signal conditioning electronics (SCE), which converted raw signals from instrumentation to standard voltages for the spacecraft instrument displays and telemetry encoders.

Aaron made a call, "Flight, EECOM. Try SCE to Aux", which switched the SCE to a backup power supply. The switch was fairly obscure, and neither Flight Director Gerald Griffin, CAPCOM Gerald Carr, nor Mission Commander Pete Conrad immediately recognized it. Lunar Module Pilot Alan Bean, flying in the right seat as the spacecraft systems engineer, remembered the SCE switch from a training incident a year earlier when the same failure had been simulated. Aaron's quick thinking and Bean's memory saved what could have been an aborted mission, and earned Aaron the reputation of a "steely-eyed missile man". Bean put the fuel cells back on line, and with telemetry restored, the launch continued successfully. Once in Earth parking orbit, the crew carefully checked out their spacecraft before re-igniting the S-IVB third stage for trans-lunar injection. The lightning strikes had caused no serious permanent damage.

Initially, it was feared that the lightning strike could have caused the explosive bolts that open the Command Module's parachute compartment to fire prematurely, rendering the parachutes useless making safe return impossible. The decision was made not to share this with the astronauts since there was little that could be done to verify or resolve the problem if it existed. The parachutes deployed and functioned normally at the end of the mission.

After LM separation, the S-IVB was intended to fly into solar orbit. The S-IVB auxiliary propulsion system was fired, and the remaining propellants vented to slow it down to fly past the Moon's trailing edge (the Apollo spacecraft always approached the Moon's leading edge). The Moon's gravity would then slingshot the stage into solar orbit. However, a small error in the state vector in the Saturn's guidance system caused the S-IVB to fly past the Moon at too high an altitude to achieve Earth escape velocity. It remained in a semi-stable Earth orbit after passing the Moon on November 18, 1969. It finally escaped Earth orbit in 1971 but was briefly recaptured in Earth orbit 31 years later. It was discovered by amateur astronomer Bill Yeung who gave it the temporary designation J002E3 before it was determined to be an artificial object.

The Apollo 12 mission landed on November 19, 1969, on an area of the Ocean of Storms (Latin "Oceanus Procellarum") that had been visited earlier by several unmanned missions ("Luna 5", "Surveyor 3", and "Ranger 7"). The International Astronomical Union, recognizing this, christened this region "Mare Cognitum (Known Sea)". The Lunar coordinates of the landing site were 3.01239° S latitude, 23.42157° W longitude. The landing site would thereafter be listed as "Statio Cognitum" on lunar maps. Conrad and Bean did not formally name their landing site, though Conrad nicknamed the intended touchdown area "Pete's Parking Lot".

The second lunar landing was an exercise in precision targeting, which would be needed for future Apollo missions. Most of the descent was automatic, with manual control assumed by Conrad during the final few hundred feet of descent. Unlike Apollo 11, where Neil Armstrong had to use the manual control to direct his lander downrange of the computer's target which was strewn with boulders, Apollo 12 succeeded in landing at its intended target – within walking distance of the "Surveyor 3" probe, which had landed on the Moon in April 1967. This was the first – and, to date, only – occasion in which humans have "caught up" to a probe sent to land on another world.

Conrad actually landed "Intrepid" short of "Pete's Parking Lot", because it looked rougher during final approach than anticipated, and was a little under from "Surveyor 3", a distance that was chosen to eliminate the possibility of lunar dust (being kicked up by "Intrepid's" descent engine during landing) from covering "Surveyor 3". But the actual touchdown point – approximately from "Surveyor 3" – did cause high velocity sandblasting of the probe. It was later determined that the sandblasting removed more dust than it delivered onto the "Surveyor", because the probe was covered by a thin layer that gave it a tan hue as observed by the astronauts, and every portion of the surface exposed to the direct sandblasting was lightened back toward the original white color through the removal of lunar dust.

When Conrad, who was somewhat shorter than Neil Armstrong, stepped onto the lunar surface, his first words were "Whoopie! Man, that may have been a small one for Neil, but that's a long one for me." This was not an off-the-cuff remark: Conrad had made a bet with reporter Oriana Fallaci he would say these words, after she had queried whether NASA had instructed Neil Armstrong what to say as he stepped onto the Moon. Conrad later said he was never able to collect the money.

To improve the quality of television pictures from the Moon, a color camera was carried on Apollo 12 (unlike the monochrome camera that was used on Apollo 11). Unfortunately, when Bean carried the camera to the place near the LM where it was to be set up, he inadvertently pointed it directly into the Sun, destroying the Secondary Electron Conduction (SEC) tube. Television coverage of this mission was thus terminated almost immediately. See also: Apollo TV camera.

Apollo 12 successfully landed within walking distance of the Surveyor 3 probe. Conrad and Bean removed pieces of the probe to be taken back to Earth for analysis. It is claimed that the common bacterium "Streptococcus mitis" was found to have accidentally contaminated the spacecraft's camera prior to launch and survived dormant in this harsh environment for two and a half years. However, this finding has since been disputed: see Reports of "Streptococcus mitis" on the Moon.

Astronauts Conrad and Bean also collected rocks and set up equipment that took measurements of the Moon's seismicity, solar wind flux and magnetic field, and relayed the measurements to Earth. The instruments were part of the first complete nuclear-powered ALSEP station set up by astronauts on the Moon to relay long-term data from the lunar surface. The instruments on Apollo 11 were not as extensive or designed to operate long term. The astronauts also took photographs, although by accident Bean left several rolls of exposed film on the lunar surface. Meanwhile, Gordon, on board the "Yankee Clipper" in lunar orbit, took multi-spectral photographs of the surface.

The lunar plaque attached to the descent stage of "Intrepid" is unique in that unlike the other plaques, it (a) did not have a depiction of the Earth, and (b) it was textured differently: The other plaques had black lettering on polished stainless steel while the Apollo 12 plaque had the lettering in polished stainless steel while the background was brushed flat.

"Intrepid's" ascent stage was dropped (per normal procedures) after Conrad and Bean rejoined Gordon in orbit. It impacted the Moon on November 20, 1969, at . The seismometers the astronauts had left on the lunar surface registered the vibrations for more than an hour.

The crew stayed an extra day in lunar orbit taking photographs, for a total lunar surface stay of 31 and a half hours and a total time in lunar orbit of eighty-nine hours.

On the return flight to Earth after leaving lunar orbit, the crew of Apollo 12 witnessed (and photographed) a solar eclipse, though this one was of the Earth eclipsing the Sun.

"Yankee Clipper" returned to Earth on November 24, 1969 at 20:58 UTC (3:58pm EST, 10:58am HST), in the Pacific Ocean, approximately 500 nautical miles (800 km) east of American Samoa. During splashdown, a 16 mm film camera dislodged from storage and struck Bean in the forehead, rendering him briefly unconscious. He suffered a mild concussion and needed six stitches. After recovery by , they were flown to Pago Pago International Airport in Tafuna for a reception, before being flown on a C-141 cargo plane to Honolulu.


The Apollo 12 mission patch shows the crew's navy background; all three astronauts at the time of the mission were U.S. Navy commanders. It features a clipper ship arriving at the Moon, representing the CM "Yankee Clipper". The ship trails fire, and flies the flag of the United States. The mission name APOLLO XII and the crew names are on a wide gold border, with a small blue trim. Blue and gold are traditional U.S. Navy colors. The patch has four stars on it – one each for the three astronauts who flew the mission and one for Clifton Williams, a U.S. Marine Corps aviator and astronaut who was killed on October 5, 1967, after a mechanical failure caused the controls of his T-38 trainer to stop responding, resulting in a crash. He trained with Conrad and Gordon as part of the backup crew for what would be the Apollo 9 mission, and would have been assigned as Lunar Module Pilot for Apollo 12.

The Apollo 12 command module "Yankee Clipper" is on display at the Virginia Air and Space Center in Hampton, Virginia.

In 2002, astronomers thought they might have discovered another moon orbiting Earth, which they designated J002E3, that turned out to be the S-IVB third stage of the Apollo 12 Saturn V rocket.

The lunar module "Intrepid" impacted the Moon November 20, 1969 at 22:17:17.7 UT (5:17 PM EST) . In 2009, the Lunar Reconnaissance Orbiter (LRO) photographed the Apollo 12 landing site. The "Intrepid" lunar module descent stage, experiment package (ALSEP), "Surveyor 3" spacecraft, and astronaut footpaths are all visible. In 2011, the LRO returned to the landing site at a lower altitude to take higher resolution photographs.

Portions of the Apollo 12 mission are dramatized in the miniseries "From the Earth to the Moon" episode entitled "That's All There Is". Conrad, Gordon, and Bean were portrayed by Paul McCrane, Tom Verica, and Dave Foley, respectively. Conrad had been portrayed by a different actor, Peter Scolari, in the first episode.




NASA reports

Multimedia


</doc>
<doc id="1968" url="https://en.wikipedia.org/wiki?curid=1968" title="Apollo 14">
Apollo 14

Apollo 14 was the eighth crewed mission in the United States Apollo program, the third to land on the Moon, and the first to land in the lunar highlands. It was the last of the "H missions," targeted landings with two-day stays on the Moon with two lunar EVAs, or moonwalks.

Commander Alan Shepard, Command Module Pilot Stuart Roosa, and Lunar Module Pilot Edgar Mitchell launched on their nine-day mission on Sunday, January 31, 1971, at 4:03:02 p.m. EST. Liftoff was delayed forty minutes and two seconds, due to launch site weather restrictions, the first such delay in the Apollo program.

Shepard and Mitchell made their lunar landing on February 5 in the Fra Mauro highlands – originally the target of the aborted Apollo 13 mission. During the two lunar EVAs, of Moon rocks were collected, and several scientific experiments were performed. Shepard hit two golf balls on the lunar surface with a makeshift club he had brought with him. Shepard and Mitchell spent 33 hours on the Moon, with almost 9 hours of EVA.

In the aftermath of Apollo 13, several modifications had been made to the service module electrical power system to prevent a repeat of that accident, including a redesign of the oxygen tanks and the addition of a third tank. The launch had been scheduled for October 1, and was delayed about 

While Shepard and Mitchell were on the surface, Roosa remained in lunar orbit aboard the command and service module "Kitty Hawk", performing scientific experiments and photographing the Moon, including the landing site of the future Apollo 16 mission. He took several hundred seeds on the mission, many of which were germinated on return, resulting in the so-called Moon trees. 

Shepard and Mitchell successfully lifted "Antares" off the Moon to dock with the command module and, after a total of 34 lunar orbits, the ship was flown back to Earth where the three astronauts landed in the Pacific Ocean on February 9.

Shepard was the oldest U.S. astronaut when he made his trip aboard Apollo 14. He is the only astronaut from Project Mercury (the original Mercury Seven astronauts) to reach the Moon. Another of the original seven, Gordon Cooper, had (as Apollo 10's backup commander) tentatively been scheduled to command the mission, but according to author Andrew Chaikin, his casual attitude toward training, along with problems with NASA hierarchy (reaching all the way back to the Mercury-Atlas 9 flight), resulted in his removal.

The mission was a personal triumph for Shepard, who had battled back from Ménière's disease which grounded him from 1964 to 1968. He and his crew were originally scheduled to fly on Apollo 13, but in 1969 NASA officials switched the scheduled crews for Apollos 13 and 14. This was done to allow Shepard more time to train for his flight, as he had been grounded for four years.



Geocentric:
Selenocentric:




Apollo 14 launched during heavy cloud cover and the Saturn V booster quickly disappeared from view. NASA's long-range cameras, based 60 miles south in Vero Beach, had a clear shot of the remainder of the launch. Following the launch, the Launch Control Center at Kennedy Space Center was visited by U.S. Vice President Spiro T. Agnew, Prince Juan Carlos of Spain, and his wife, Princess Sofía.

At the beginning of the mission, the Apollo CSM "Kitty Hawk" had difficulty achieving capture and docking with the LM "Antares". Repeated attempts to dock went on for 1 hour and 42 minutes, until it was suggested that Roosa hold "Kitty Hawk" against "Antares" using its thrusters, then the docking probe would be retracted out of the way, hopefully triggering the docking latches. The sixth attempt was successful, and no further docking problems were encountered during the mission.

After separating from the command module in lunar orbit, the LM "Antares" had two serious problems. First, the LM computer began getting an ABORT signal from a faulty switch. NASA believed that the computer might be getting erroneous readings like this if a tiny ball of solder had shaken loose and was floating between the switch and the contact, closing the circuit. The immediate solution – tapping on the panel next to the switch – did work briefly, but the circuit soon closed again. If the problem recurred after the descent engine fired, the computer would think the signal was real and would initiate an auto-abort, causing the ascent stage to separate from the descent stage and climb back into orbit. NASA and the software teams at the Massachusetts Institute of Technology scrambled to find a solution. The software was hard-wired, preventing it from being updated directly. The fix involved indicating that abort mode was already active, so that if the signal were to arise again, it would be ignored rather than initiating what would have appeared to the software to be a second abort. The software modifications were transmitted to the crew via voice communication, and Mitchell manually entered the changes (amounting to over 80 keystrokes on the LM computer pad) just in time.

A second problem occurred during the powered descent, when the LM landing radar failed to lock automatically onto the Moon's surface, depriving the navigation computer of vital information on the vehicle's altitude and vertical descent speed (this was not a result of the modifications to the ABORT command; rather, the post-mission report indicated it was an unrelated bug in the radar's operation). After the astronauts cycled the landing radar breaker, the unit successfully acquired a signal near , again just in time. Shepard then manually landed the LM closer to its intended target than any of the other five Moon landing missions. Mitchell believed that Shepard would have continued with the landing attempt without the radar, using the LM inertial guidance system and visual cues. A post-flight review of the descent data showed the inertial system alone would have been inadequate, and the astronauts probably would have been forced to abort the landing as they approached the surface.

Shepard and Mitchell named their landing site "Fra Mauro Base", and this designation is recognized by the International Astronomical Union (depicted in Latin on lunar maps as "Statio Fra Mauro").

Shepard's first words, after stepping onto the lunar surface were, "And it's been a long way, but we're here." Unlike Neil Armstrong on Apollo 11 and Pete Conrad on Apollo 12, Shepard had already stepped off the LM footpad and was a few yards away before he spoke.

Shepard's moonwalking suit was the first to utilize red stripes on the arms and legs and on the top of the lunar EVA sunshade "hood," so as to allow easy identification between the commander and LM pilot on the surface; on the Apollo 12 pictures, it had been almost impossible to distinguish between the two crewmen, causing a great deal of confusion. This feature was included on Jim Lovell's Apollo 13 suit; because no landing was made on that mission, Apollo 14 was the first to make use of it. This feature was used for the remaining Apollo missions, and for the EVAs of Space Shuttle flights afterwards, and it is still in use today on both the U.S. and Russian space suits on the International Space Station.

After landing in the Fra Mauro formation—the destination for Apollo 13—Shepard and Mitchell took two moonwalks, adding new seismic studies to the by now familiar Apollo Lunar Surface Experiments Package (ALSEP), and using the Modular Equipment Transporter (MET), a pull-cart for carrying equipment and samples, nicknamed "lunar rickshaw". Roosa, meanwhile, took pictures from on board command module "Kitty Hawk" in lunar orbit.

The second moonwalk, or EVA, was intended to reach the rim of the wide Cone Crater. The two astronauts were not able to find the rim amid the rolling terrain of the crater's slopes. They became physically exhausted from the attempt and with their suits' oxygen supplies starting to run low, the effort was called off. Later analysis, using the pictures that they took, determined that they had come within an estimated of the crater's rim. Images from the Lunar Reconnaissance Orbiter (LRO) show the tracks of the astronauts and the MET come to within 30 m of the rim.

Shepard and Mitchell deployed and activated various scientific instruments and experiments and collected almost of lunar samples for return to Earth, including the famous 20 pound (9 kg) Big Bertha rock. Other Apollo 14 achievements included the only use of MET; longest distance traversed by foot on the lunar surface; first use of shortened lunar orbit rendezvous techniques; and the first extensive orbital science period conducted during CSM solo operations.

The astronauts also engaged in less serious activities on the Moon. Shepard brought along a six iron golf club head which he could attach to the handle of a lunar excavation tool, and two golf balls, and took several one-handed swings (due to the limited flexibility of the EVA suit). He exuberantly exclaimed that the second ball went "miles and miles and miles" in the low lunar gravity, but later estimated the distance as . Mitchell then threw a lunar scoop handle as if it were a javelin.

The Moon rocks, or lunar samples, from Apollo 14 are unique in that most of the 94 pounds of rocks are breccia, which are rocks that are composed of fragments of other, older rocks. Breccias form when the heat and pressure of meteorite impacts fuse small rock fragments together. There were a few basalts that were collected in this mission in the form of clasts (fragments) in breccia. The Apollo 14 basalts are generally richer in aluminum and sometimes richer in potassium than other lunar basalts. Most lunar mare basalts collected during the Apollo program were formed from 3.0 to 3.8 billion years ago. The Apollo 14 basalts were formed 4.0 to 4.3 billion years ago, older than the volcanism observed at any of the mare locations studied during the Apollo program.

In January 2019 research showed that Big Bertha, a 19.837 pound rock, has numerous characteristics that make it likely to be a terrestrial (Earth) meteorite. Granite and quartz, which are commonly found on Earth but very rare to find on the Moon, were confirmed to exist on Big Bertha. To find the sample's age, the research team from Curtin University looked at bits of the mineral zircon embedded in its structure. "By determining the age of zircon found in the sample, we were able to pinpoint the age of the host rock at about four billion years old, making it similar to the oldest rocks on Earth," researcher Alexander Nemchin said, adding that "the chemistry of the zircon in this sample is very different from that of every other zircon grain ever analyzed in lunar samples, and remarkably similar to that of zircons found on Earth." This means that Big Bertha is both the first discovered terrestrial meteorite and the oldest known Earth rock.

On the way back to Earth, the crew conducted the first U.S. materials processing experiments in space.

The command module "Kitty Hawk" splashed down in the South Pacific Ocean on February 9, 1971 at 21:05 [UTC], approximately south of American Samoa. After recovery by the ship USS "New Orleans", the crew was flown to Pago Pago International Airport in Tafuna for a reception before being flown on a C-141 cargo plane to Honolulu. The Apollo 14 astronauts were the last lunar explorers to be quarantined on their return from the Moon.

Roosa, who worked in forestry in his youth, took several hundred tree seeds on the flight. These were germinated after the return to Earth, and widely distributed around the world as commemorative Moon trees.

The oval insignia shows a gold NASA Astronaut Pin, given to U.S. astronauts upon completing their first space flight, traveling from the Earth to the Moon. A gold band around the edge includes the mission and astronaut names. The designer was Jean Beaulieu.

The backup crew spoofed the patch with its own version, with revised artwork showing a Wile E. Coyote cartoon character depicted as gray-bearded (for Shepard, who was 47 at the time of the mission and the oldest man on the Moon), pot-bellied (for Mitchell, who had a pudgy appearance) and red furred (for Roosa's red hair), still on the way to the Moon, while Road Runner (for the backup crew) is already on the Moon, holding a U.S. flag and a flag labeled "1st Team." The flight name is replaced by "BEEP BEEP" and the backup crew's names are given. Several of these patches were hidden by the backup crew and found during the flight by the crew in notebooks and storage lockers in both the CSM "Kitty Hawk" and the LM "Antares" spacecraft, and one patch was even stored on the MET lunar hand cart.

The Apollo 14 command module "Kitty Hawk" is on display at the Apollo/Saturn V Center building at the Kennedy Space Center after being on display at the United States Astronaut Hall of Fame near Titusville, Florida, for several years.

The ascent stage of lunar module "Antares" impacted the Moon on February 7, 1971 at 00:45:25.7 UT (February 6, 7:45 PM EST) . "Antares"' descent stage and the mission's other equipment remain at Fra Mauro at .

Photographs taken in 2009 by the Lunar Reconnaissance Orbiter were released on July 17, and the Fra Mauro equipment was the most visible Apollo hardware at that time, owing to particularly good lighting conditions. In 2011, the LRO returned to the landing site at a lower altitude to take higher resolution photographs.



NASA reports

Multimedia


</doc>
<doc id="1969" url="https://en.wikipedia.org/wiki?curid=1969" title="Apollo 15">
Apollo 15

Apollo 15 was the ninth crewed mission in the United States' Apollo program, the eighth to be successful, and the fourth to land on the Moon. It was the first J mission, with a longer stay on the Moon and a greater focus on science than earlier landings. Apollo 15 saw the first use of the Lunar Roving Vehicle.

The mission began on July 26, 1971, and ended on August 7, the lunar surface exploration taking place between July 30 and August 2. Commander David Scott and Lunar Module Pilot James Irwin landed near Hadley Rille and explored the local area using the rover, allowing them to travel further from the lunar module than had been possible on previous missions. They spent 18 hours on the Moon's surface on extravehicular activity (EVA), and collected of surface material.

At the same time, Command Module Pilot Alfred Worden orbited the Moon, operating the sensors in the SIM bay of the service module. This suite of instruments collected data on the Moon and its environment using a panoramic camera, a gamma-ray spectrometer, a mapping camera, a laser altimeter, a mass spectrometer, and a lunar subsatellite deployed at the end of the moonwalks. The lunar module returned safely to the command module and, at the end of Apollo 15's 74th lunar orbit the engine was fired for the journey home. During the return trip Worden performed the first spacewalk in deep space. The Apollo 15 mission splashed down safely on August 7 despite the loss of one of its three parachutes.

The mission accomplished its goals but was marred by negative publicity the following year when it emerged that the crew had carried unauthorized postal covers to the lunar surface, some of which were sold by a West German stamp dealer. The members of the crew were reprimanded for poor judgment, and did not fly in space again. Apollo 15 is also remembered for the finding of the Genesis Rock, and for Scott's use of a hammer and a feather to validate Galileo's theory that absent air resistance, objects drop at the same rate.

In 1962, NASA contracted for fifteen Saturn V rockets to achieve the Apollo program's goal of a crewed landing on the Moon by 1970; at the time no one knew how many missions this would require. Since success was obtained in 1969 with the sixth Saturn V on Apollo 11, nine rockets remained available for a hoped-for total of ten landings. These plans included a heavier, extended version of the Apollo spacecraft to be used in the last five missions (Apollo 16 through 20). The revamped lunar module would be capable of up to a 75-hour stay, and would carry a Lunar Roving Vehicle to the Moon's surface. The service module would house a package of orbital experiments to gather data on the Moon. In the original plan, Apollo 15 was to be the last of the non-extended missions, to land in Censorinus crater. But in anticipation of budget cuts, NASA cancelled the last three landing missions by September 1970. Apollo 15 became the first of three extended missions, known as J missions, and the landing site was moved to Hadley Rille, originally planned for Apollo 19.

Scott was born in 1932 in San Antonio, Texas, and had graduated from the United States Military Academy in 1954. Serving in the Air Force, Scott had received two advanced degrees from MIT in 1962 before being selected as one of the third group of astronauts the following year. He flew in Gemini 8 in 1966 alongside Neil Armstrong and as command module pilot of Apollo 9 in 1969. Worden was born in 1932 in Jackson, Michigan, and like his commander, had attended West Point (class of 1955) and served in the Air Force. Worden earned two master's degrees in engineering from the University of Michigan in 1963. Irwin had been born in 1930 in Pittsburgh, and had attended the United States Naval Academy, graduating in 1951 and serving in the Air Force, receiving a master's degree from Michigan in 1957. Both Worden and Irwin were selected in the fifth group of astronauts (1966), and Apollo 15 would be their only spaceflight.

The backup crew was Richard F. Gordon Jr. as commander, Vance D. Brand as command module pilot and Harrison H. Schmitt as lunar module pilot. By the usual rotation of crews, the three would most likely have flown Apollo 18, which was canceled. Brand flew later on the Apollo-Soyuz Test Project and on STS-5, the first operational Space Shuttle mission. With NASA under intense pressure to send a professional scientist to the Moon, Schmitt, a geologist, was selected as LMP of Apollo 17 instead of Joe Engle.
Apollo 15's support crew consisted of astronauts Joseph P. Allen, Robert A. Parker and Karl G. Henize. All three were scientist-astronauts, selected in 1967, as the prime crew felt they needed more assistance with the science than with the piloting. None of the support crew would fly during the Apollo program, waiting until the Space Shuttle program to go into space.

The flight controllers for Apollo 15 were as follows:


During a mission the capsule communicators (CAPCOMs), always fellow astronauts, were the only people who normally would speak to the crew. For Apollo 15, the CAPCOMs were Allen, Brand, C. Gordon Fullerton, Gordon, Henize, Edgar D. Mitchell, Parker, Schmitt and Alan B. Shepard.

Schmitt and other scientist-astronauts advocated for a greater place for science on the early Apollo missions. They were often met with disinterest from other astronauts, or found science displaced by higher priorities. Schmitt realized that what was needed was an expert teacher who could fire the astronauts' enthusiasm, and contacted Caltech geologist Lee Silver, whom Schmitt introduced to Apollo 13's commander, Jim Lovell, and to its lunar module pilot, Fred Haise, then in training for their mission. Lovell and Haise were willing to go on a field expedition with Silver, and geology became a significant part of their training. Geologist Farouk El-Baz trained the prime crew's command module pilot, Ken Mattingly to inform his planned observations from lunar orbit. The crew's newly-acquired skills mostly went unused, due to the explosion that damaged the Apollo 13 spacecraft, and caused an abort of the mission. Apollo 14's CMP, Stu Roosa, was enthusiastic about geology, but the mission commander, Shepard, less so.
Already familiar with the spacecraft as the backup crew for Apollo 12, Scott, Worden and Irwin could devote more of their training time as prime crew for Apollo 15 to geology and sampling techniques. Scott was determined that his crew bring back the maximum amount of scientific data possible, and met with Silver in April 1970 to begin planning the geological training. Schmitt's assignment as Apollo 15's backup LMP made him an insider, and allowed him to spark competition between the prime and backup crews. The cancellation of two Apollo missions in September 1970 transformed Apollo 15 into a J mission, with a longer stay on the lunar surface, and the first Lunar Roving Vehicle (LRV). This change was welcomed by Scott, who according to David West Reynolds in his account of the Apollo Program, was "something more than a hotshot pilot. Scott had the spirit of a true explorer", one determined to get the most from the J mission. The additional need for communications, including from planned experiments and the rover, required the near-rebuilding of the Honeysuckle Creek Tracking Station in Australia.
Geology field trips took place about once a month throughout the crew's 20 months of training. At first Silver would take the commanders and LMPs from the prime and backup crews to geological sites in Arizona and New Mexico as if for a normal field geology lesson, but closer to launch, these trips became more realistic. Crews began to wear mock-ups of the backpacks they would carry, and communicate using walkie-talkies to a CAPCOM in a tent. The CAPCOM was accompanied by a geologist unfamiliar with the area who would rely on the astronauts' descriptions to interpret the findings, and familiarized the crew members with describing landscapes to people who could not see them. Considering himself a serious amateur, Scott came to enjoy field geology.

The decision to land at Hadley came in September 1970. The Site Selection Committee had narrowed the field down to two sites — Hadley Rille, a deep channel on the edge of Mare Imbrium close to the Apennine mountains or the crater Marius, near which were a group of low, possibly volcanic, domes. Although not ultimately his decision, the commander of a mission always held great sway. To David Scott the choice was clear, as Hadley "had more variety. There is a certain intangible quality which drives the spirit of exploration and I felt that Hadley had it. Besides it looked beautiful and usually when things look good they are good." The selection of Hadley was made although NASA lacked high resolution images of the landing site; none had been made as the site was considered too rough to risk one of the earlier Apollo missions. The proximity of the Apennine mountains to the Hadley site required a landing approach trajectory of 26 degrees, far steeper than the 15 degrees in earlier Apollo landings.

The expanded mission meant that Worden spent much of his time at North American Rockwell's facilities at Downey, California, where the command and service module (CSM) was being built. He undertook a different kind of geology training. Working with El-Baz, he studied maps and photographs of the craters he would pass over while orbiting alone in the CSM. As El-Baz listened and gave feedback, Worden learned how to describe lunar features in a way that would be useful to the scientists who would listen to his transmissions back on Earth. Worden found El-Baz to be an enjoyable and inspiring teacher. Worden usually accompanied his crewmates on their geology field trips, though he was often in an airplane overhead, describing features of the landscape as the plane simulated the speed at which the lunar landscape would pass below the CSM.

The demands of the training strained Worden's marriage and also that of Irwin; each sought Scott's advice, fearing that divorce might endanger their places on the mission as not projecting the image NASA wanted for the astronauts. Scott consulted Director of Flight Crew Operations Deke Slayton, their boss, who stated what was important was that the astronauts do their jobs. Although the Irwins overcame their marital difficulties, Worden divorced before the mission.

Apollo 15 used command and service module CSM-112, which was given the call sign "Endeavour", named after HMS "Endeavour", and lunar module LM-10, call sign "Falcon", named after the United States Air Force Academy mascot. Scott explained the choice of the name "Endeavour" on the grounds that its captain, James Cook had commanded the first purely scientific sea voyage, and Apollo 15 was the first lunar landing mission on which there was a heavy emphasis on science. Apollo 15 took with it a small piece of wood from Cook's ship while "Falcon" carried two falcon feathers to the Moon in recognition of the crew's service in the Air Force.
Technicians at the Kennedy Space Center had some problems with the instruments in the service module's scientific instrument module (SIM) bay. Some instruments were late in arriving, and principal investigators or representatives of NASA contractors sought further testing or to make small changes. Mechanical problems came from the fact the instruments were designed to operate in space, but had to be tested on the surface of the Earth. As such, things like the 7.5 m (24 ft) booms for the mass and gamma ray spectrometers could only be tested using equipment that tried to mimic the space environment, and, in space, the mass spectrometer boom several times did not fully retract.

On the lunar module, the fuel and oxidizer tanks were enlarged on both the descent and ascent stages and the engine bell on the descent stage was extended. Batteries and solar cells were added for increased electrical power. In all this increased the weight of the lunar module to , heavier than previous models.

If Apollo 15 had flown as an H mission, it would have been with CSM-111 and LM-9. That CSM was used by the Apollo–Soyuz Test Project in 1975, but the lunar module went unused and is now at the Kennedy Space Center Visitor Complex. "Endeavour" is on display at the National Museum of the United States Air Force at Wright-Patterson Air Force Base in Dayton, Ohio.

The Saturn V that launched Apollo 15 was designated SA-510, the tenth flight-ready model of the rocket. As the payload of the rocket was greater, changes were made to the rocket and to its launch trajectory. It was launched in a more southerly direction (80–100 degrees azimuth) than that of previous missions, and the Earth parking orbit was lowered to . These two changes meant more could be launched. The propellant reserves were reduced and the number of retrorockets on the S-IC first stage (used to separate the spent first stage from the S-II second stage) reduced from eight to four. The four outboard engines of the S-IC would be burned longer and the center engine would also burn longer. Changes were also made to the S-II to dampen pogo oscillations.

Once all major systems were installed in the Saturn V, it was moved from the Vehicle Assembly Building to the launch site, Launch Complex 39A. During late June and early July 1971, the rocket and Launch Umbilical Tower (LUT) were struck by lightning at least four times. There was no damage to the vehicle, and only minor damage to ground support equipment.

The Apollo 15 astronauts wore redesigned space suits. On all previous Apollo flights, including the non-lunar flights, the commander and lunar module pilot had worn suits with the life support, liquid cooling, and communications connections in two parallel rows of three. On Apollo 15, the new suits, dubbed the "A7LB", had the connectors situated in triangular pairs. This new arrangement, along with the relocation of the entry zipper (which went in an up-down motion on the old suits), to run diagonally from the right shoulder to the left hip, aided in suiting and unsuiting in the cramped confines of the spacecraft. It also allowed for a new waist joint, letting the astronauts bend completely over, and also sit on the rover. Upgraded backpacks allowed for longer-duration moonwalks. As in all missions from and after Apollo 13, the commander's suit bore a red stripe on the helmet, arms and legs.

Worden wore a suit similar to those worn by the Apollo 14 astronauts, but modified to interface with Apollo 15's equipment. Gear only needed for lunar surface EVAs, such as the liquid cooling garment, was not included with Worden's suit, as the only EVA he was expected to do was one to retrieve film cartridges from the SIM bay on the flight home.

A vehicle that could operate on the surface of the Moon had been considered by NASA since the early 1960s. An early version was called MOLAB, which had a closed cabin and would have massed about ; some scaled-down prototypes were tested in Arizona. As it became clear NASA would not soon establish a lunar base, such a large vehicle seemed unnecessary. Still, a rover would enhance the J missions, which were to concentrate on science, though its mass was limited to about and it was not then clear that so light a vehicle could be useful. NASA did not decide to proceed with a rover until May 1969, as Apollo 10, the dress rehearsal for the Moon landing, made its way home from lunar orbit. Boeing got the contract for three rovers on a cost plus basis; overruns (especially in the navigation system) meant that the three vehicles eventually cost a total of $40 million. These cost overruns gained considerable media attention at a time of greater public weariness with the space program, when NASA's budget was being cut.

The Lunar Roving Vehicle could be folded into a space 5 ft by 20 in (1.5 m by 0.5 m). Unloaded, it weighed 460 lb (209 kg) and when carrying two astronauts and their equipment, 1500 lb (700 kg). Each wheel was independently driven by a ¼ horsepower (200 W) electric motor. Although it could be driven by either astronaut, the commander always drove. Travelling at speeds up to 6 to 8 mph (10 to 12 km/h), it meant that for the first time the astronauts could travel far afield from their lander and still have enough time to do some scientific experiments. During pre-launch testing, the LRV was given additional bracing, lest it collapse if someone sat on it under Earth conditions.

The Apollo 15 Particles and Fields Subsatellite (PFS-1) was a small satellite released into lunar orbit from the SIM bay just before the mission left orbit to return to Earth. Its main objectives were to study the plasma, particle, and magnetic field environment of the Moon and map the lunar gravity field. Specifically, it measured plasma and energetic particle intensities and vector magnetic fields, and facilitated tracking of the satellite velocity to high precision. A basic requirement was that the satellite acquire fields and particle data everywhere on the orbit around the Moon. As well as measuring magnetic fields, the satellite contained sensors to study the Moon's mass concentrations, or mascons. The satellite orbited the Moon and returned data from August 4, 1971 until January 1973, when, following multiple failures of the subsatellite's electronics, ground support was terminated. It is believed to have crashed into the Moon sometime thereafter.

Apollo 15 was launched on July 26, 1971, at 9:34 AM EDT from the Kennedy Space Center at Merritt Island, Florida. The time of launch was at the very start of the two-hour, 37 minute launch window, which would allow Apollo 15 to arrive at the Moon with the proper lighting conditions at Hadley Rille; had the mission been postponed beyond another window on July 27, it could not have been rescheduled until late August. The astronauts had been wakened five and a quarter hours before launch by Slayton, and after breakfast and suiting up, had been taken to Pad 39A, launch site of all seven attempts at crewed lunar landing, and entered the spacecraft about three hours before launch. There were no unplanned delays in the countdown.

At 000:11:36 into the mission, the S-IVB engine shut down, leaving Apollo 15 in its planned parking orbit in Low Earth Orbit. The mission remained there for some 2 hours and 40 minutes, allowing the crew (and Houston, via telemetry) to check the spacecraft's systems. At 002:50.02.6 into the mission, the S-IVB was restarted for trans-lunar injection (TLI), placing the craft on a path to the Moon. Before TLI, the craft had completed 1.5 orbits around the Earth.
The command and service module (CSM) and the lunar module remained attached to the nearly-exhausted S-IVB booster. Once trans-lunar injection had been achieved, placing the spacecraft on a trajectory towards the Moon, explosive cords separated the CSM from the booster as Worden operated the CSM's thrusters to push it away. Worden then maneuvered the CSM to dock with the LM (mounted on the end of the S-IVB), and the combined craft was then separated from the S-IVB by explosives. After Apollo 15 separated from the booster, the S-IVB maneuvered away, and, as planned, impacted the Moon about an hour after the crewed spacecraft entered lunar orbit, though due to an error the impact was away from the intended target. The booster's impact was detected by the seismometers left on the Moon by Apollo 12 and Apollo 14, providing useful scientific data.

There was a malfunctioning light on the craft's service propulsion system (SPS); after considerable troubleshooting, the astronauts did a test burn of the system that also served as a midcourse correction. This occurred about 028:40:00 into the mission. Fearing that the light meant the SPS might unexpectedly fire, the astronauts avoided using the control bank that had the faulty light, bringing it online only for major burns, and controlling it manually. After the mission returned, the malfunction proved to be caused by a tiny bit of wire trapped within the switch.
After purging and renewing the LM's atmosphere to eliminate any contamination, the astronauts entered the LM about 34 hours into the mission, needing to check the condition of its equipment and move in items that would be required on the Moon. Much of this work was televised back to Earth, the camera operated by Worden. The crew discovered a broken outer cover on the Range/Range Rate tapemeter. This was a concern not only because an important piece of equipment, providing information on distance and rate of approach, might not work properly, but because bits of the glass cover were floating around "Falcon"'s interior. The tapemeter was supposed to be in a helium atmosphere, but due to the breakage, it was in the LM's oxygen atmosphere. Testing on the ground verified the tapemeter would still work properly, and the crew removed most of the glass using a vacuum cleaner and adhesive tape.

As yet, there had been only minor problems, but at about 61:15:00 mission time (the evening of July 28 in Houston), Scott discovered a leak in the water system while preparing to chlorinate the water supply. The crew could not tell where it was coming from, and the issue had the potential to become serious. The experts in Houston found a solution, which was successfully implemented by the crew. The water was mopped up with towels, which were then put out to dry in the tunnel between the command module (CM) and lunar module—Scott stated it looked like someone's laundry.

At 073:31:14 into the mission, a second midcourse correction, with less than a second of burn, was made. Although there were four opportunities to make midcourse corrections following TLI, only two needed to be used. Apollo 15 approached the Moon on July 29, and the lunar orbit insertion (LOI) burn had to be made using the SPS, on the far side of the Moon, out of radio contact with Earth. If no burn occurred, Apollo 15 would emerge from the lunar shadow and come back in radio contact faster than expected; the continued lack of communication allowed Mission Control to conclude that the burn had taken place. When contact resumed, Scott did not immediately give the particulars of the burn, but spoke admiringly of the beauty of the Moon, causing Alan Shepard, the Apollo 14 commander, who was awaiting a television interview, to grumble, "To hell with that shit, give us details of the burn." The 398.36-second burn took place at 078:31:46.7 into the mission at an altitude of above the Moon, and placed Apollo 15 in an elliptical lunar orbit of .

On Apollo 11 and 12, the lunar module decoupled from the CSM and descended to a much lower orbit from which the lunar landing attempt commenced; to save fuel in an increasingly heavy lander, beginning with Apollo 14, the SPS in the service module made that burn, known as descent orbit insertion (DOI), with the lunar module still attached to the CSM. The initial orbit Apollo 15 was in had its apocynthion, or high point, over the landing site at Hadley; a burn at the opposite point in the orbit was performed, with the result that Hadley would now be under the craft's pericynthion, or low point. The DOI burn was performed at 082:39:49.09 and took 24.53 seconds; the result was an orbit with apocynthion of and pericynthion of . Overnight between July 29 and 30, as the crew rested, it became apparent to Mission Control that mass concentrations in the Moon were making Apollo 15's orbit increasingly elliptical—pericynthion was by the time the crew was awakened on July 30. This, and uncertainty as to the exact altitude of the landing site, made it desirable that the orbit be modified, or trimmed. Using the craft's RCS thrusters, this took place at 095:56:44.70, lasting 30.40 seconds, and raised the pericynthion to and the apocynthion to .

As well as preparing the lunar module for its descent, the crew continued observations of the Moon (including of the landing site at Hadley) and provided television footage of the surface. Then, Scott and Irwin entered the lunar module in preparation for the landing attempt. Undocking was planned for 100:13:56, over the far side of the Moon, but nothing happened when separation was attempted. After analyzing the problem, the crew and Houston decided the probe instrumentation umbilical was likely loose or disconnected; Worden went into the tunnel connecting the command and lunar modules and determined this was so, seating it more firmly. With the problem resolved, "Falcon" separated from "Endeavour" at 100:39:16.2, about 25 minutes late, at an altitude of . Worden in "Endeavour" executed a SPS burn at 101:38:58.98 to send "Endeavour" to an orbit of by in preparation for his scientific work.

Aboard "Falcon", Scott and Irwin prepared for powered descent initiation (PDI), the burn that was to place them on the lunar surface, and, after Mission Control gave them permission, they initiated PDI at 104:30:09.4 at an altitude of , slightly higher than planned. During the first part of the descent, "Falcon" was aligned so that the astronauts were on their backs and thus could not see the lunar surface below them, but after the craft made a pitchover maneuver, they were upright and could see the surface in front of them. Scott, who as commander performed the landing, was confronted with a landscape that did not at first seem to resemble what he had seen during simulations. Part of this was due to an error in the landing path of some , of which CAPCOM Ed Mitchell informed the crew prior to pitchover; part because the craters Scott had relied on in the simulator were difficult to make out under lunar conditions, and he initially could not see Hadley Rille. He concluded that they were likely to overshoot the planned landing site, and, once he could see the rille, started maneuvering the vehicle to move the computer's landing target back towards the planned spot, and looked for a relatively smooth place to land.
Below about , Scott could see nothing of the surface because of the quantities of lunar dust being displaced by "Falcon"'s exhaust. "Falcon" had a larger engine bell than previous LMs, in part to accommodate a heavier load, and the importance of shutting down the engine at initial contact rather than risk "blowback", the exhaust reflecting off the lunar surface and going back into the engine (possibly causing an explosion) had been impressed on the astronauts by mission planners. Thus, when Irwin called "Contact", indicating that one of the probes on the landing leg extensions had touched the surface, Scott immediately shut off the engine, letting the lander fall the remaining distance to the surface. Already moving downward at about per second, "Falcon" dropped from a height of . Scott's speed resulted in what was likely the hardest lunar landing of any of the crewed missions, at about per second, causing a startled Irwin to yell "Bam!" Scott had landed "Falcon" on the rim of a small crater he could not see, and the lander settled back at an angle of 6.9 degrees and to the left of 8.6 degrees. Irwin described it in his autobiography as the hardest landing he had ever been in, and he feared that the craft would keep tipping over, forcing an immediate abort.

"Falcon" landed at 104:42:29.3 (22:16:29 GMT on July 30), with approximately 103 seconds of fuel remaining, about from the planned landing site. After Irwin's exclamation, Scott reported, "Okay, Houston. The "Falcon" is on the Plain at Hadley." Once within the planned landing zone, the increased mobility provided by the Lunar Roving Vehicle made unnecessary any further maneuvering.

With "Falcon" due to remain on the lunar surface for almost three days, Scott deemed it important to maintain the circadian rhythm they were used to, and as they had landed in the late afternoon, Houston time, the two astronauts were to sleep before going onto the surface. But the time schedule allowed Scott to open the lander's top hatch (usually used for docking) and spend a half hour looking at their surroundings, describing them, and taking photographs. Lee Silver had taught him the importance of going to a high place to survey a new field site, and the top hatch served that purpose. Deke Slayton and other managers had initially been in opposition, due to the oxygen that would be lost, but Scott got his way. During the only standup extravehicular activity (standup EVA) ever performed through the top hatch on the lunar surface, Scott was able to make plans for the following day's EVA. He offered Irwin a chance to look out as well, but this would have required rearranging the umbilicals connecting Irwin to "Falcon"'s life support system, and he declined. After repressurizing the spacecraft, Scott and Irwin removed their space suits for sleep, becoming the first astronauts to doff their suits while on the Moon.
Throughout the sleep period Mission Control in Houston monitored a slow but steady oxygen loss. Scott and Irwin eventually were awakened an hour early, and the source of the problem was found to be an open valve on the urine transfer device. In post-mission debriefing, Scott recommended that future crews be woken at once under similar circumstances. After the problem was solved, the crew began preparation for the first Moon walk.

After donning their suits and depressurizing the cabin, Scott and Irwin began their first full EVA, becoming the seventh and eighth humans, respectively, to walk on the Moon. They attempted to deploy the lunar rover, stored folded up on the outside of "Falcon"'s descent stage, but this proved troublesome due to the slant of the lander. The experts in Houston suggested lifting the front end of the rover as the astronauts pulled it out, and this worked. One of the batteries gave a zero voltage reading, but this proved to be an instrumentation problem. A greater concern was that the front wheel steering would not work, but the rear wheel steering was sufficient to maneuver the vehicle. The rover carried a television camera, controlled remotely from Houston by NASA's Ed Fendell. The resolution was not high compared to the still photographs that would be taken, but the camera allowed the geologists on Earth to indirectly participate in Scott and Irwin's activities.

The rille was not visible from the landing site, but as Scott and Irwin drove over the rolling terrain, it came into view. They were able to see Elbow crater, and they began to drive in that direction. Reaching Elbow, a known location, allowed Mission Control to backtrack and get closer to pinpointing the location of the lander. The astronauts took samples there, and then drove to another crater on the flank of Mons Hadley Delta, where they took more. After concluding this stop, they returned to the lander to drop off their samples and prepare to set up the Apollo Lunar Surface Experiments Package (ALSEP), the scientific instruments that would remain when they left. Scott had difficulty drilling the holes required for the heat flow experiment, and the work was not completed when they had to return to the lander. The first EVA lasted 6 hours and 32 minutes.

The rover's front steering, inoperative during the first EVA, worked during the second and third ones. The target of the second EVA, on August 1, was the slope of Mons Hadley Delta, where the pair sampled boulders and craters along the Apennine Front. They spent an hour at Spur crater, during which the astronauts secured what came to be one of the more famous lunar samples, #15415, more commonly known as the "Genesis Rock". This rock, an anorthosite, is believed to be part of the early lunar crust—the hope of finding such a specimen had been one reason the Hadley area had been chosen. Once back at the landing site, Scott continued to try to drill holes for experiments at the ALSEP site, with which he had struggled the day before. After conducting soil-mechanics experiments and raising the U.S. flag, Scott and Irwin returned to the LM. EVA 2 lasted 7 hours and 12 minutes.

Although Scott had eventually been successful at drilling the holes, he and Irwin had been unable to retrieve a core sample, and this was an early order of business during EVA 3, their third and final moonwalk. Time that could have been devoted to geology ticked away as Scott and Irwin attempted to pull it out. Once it had been retrieved, more time passed as they attempted to break the core into pieces for transport to Earth. Hampered by an incorrectly-mounted vise on the rover, they eventually gave up on this—the core would be transported home with one segment longer than planned. Scott wondered if the core was worth the amount of time and effort invested, and the CAPCOM, Joe Allen, assured him that it was. The core proved one of the most important items brought back from the Moon, revealing much about its history, but the expended time meant the planned visit to a group of hills known as the North Complex had to be scrubbed. Instead, the crew again ventured to the edge of Hadley Rille, this time to the northwest of the immediate landing site.
Once the astronauts were beside the LM, Scott used a kit provided by the Postal Service to cancel a first day cover of two stamps being issued on August 2, the current date. Scott then performed an experiment in view of the television camera, using a feather and hammer to demonstrate Galileo's theory that all objects in a given gravity field fall at the same rate, regardless of mass, in the absence of aerodynamic drag. He dropped the hammer and feather at the same time; because of the negligible lunar atmosphere, there was no drag on the feather, which hit the ground at the same time as the hammer. This was Joe Allen's idea (he also served as CAPCOM during it) and was part of an effort to find a memorable popular science experiment to do on the Moon along the lines of Shepard's hitting of golf balls. The feather was from a falcon, a mascot at the United States Air Force Academy.
Scott then drove the rover to a position away from the LM, where the television camera could be used to observe the lunar liftoff. Near the rover, he left a small aluminum statuette called "Fallen Astronaut", along with a plaque bearing the names of 14 known American astronauts and Soviet cosmonauts who had died in the furtherance of space exploration. The memorial was left while the television camera was turned away; he told Mission Control he was doing some cleanup activities around the rover. Scott disclosed the memorial in a post-flight news conference. He also placed a Bible on the control panel of the rover before leaving it for the last time to enter the LM.

The EVA lasted 4 hours, 49 minutes and 50 seconds. In total, the two astronauts spent 18 hours outside the LM and collected approximately of lunar samples.

After the departure of "Falcon", Worden in "Endeavour" executed a burn to take the CSM to a higher orbit. While "Falcon" was on the Moon, the mission effectively split, Worden and the CSM being assigned their own CAPCOM and flight support team.
Worden got busy with the tasks that were to occupy him for much of the time he spent in space alone: photography and operating the instruments in the SIM bay. The door to the SIM bay had been explosively jettisoned during the translunar coast. Filling previously-unused space in the service module, the SIM bay contained a gamma-ray spectrometer, mounted on the end of a boom, an X-ray spectrometer and a laser altimeter, which failed part way through the mission. Two cameras, a stellar camera and a metric camera, together comprised the mapping camera, which was complimented by a panoramic camera, derived from spy technology. The altimeter and cameras permitted the exact time and location from which pictures were taken to be determined. Also present were an alpha particle spectrometer, which could be used to detect evidence of lunar volcanism, and a mass spectrometer, also on a boom in the hope it would be unaffected by contamination from the ship. The boom would prove troublesome, as Worden would not always be able to get it to retract.
"Endeavour" was slated to pass over the landing site at the moment of planned landing, but Worden could not see "Falcon" and did not spot it until a subsequent orbit. He also exercised to avoid muscle atrophy, and Houston kept him up to date on Scott and Irwin's activities on the lunar surface. The panoramic camera did not operate perfectly, but provided enough images that no special adjustment was made. Worden took many photographs through the command module's windows, often with shots taken at regular intervals. His task was complicated by the lack of a working mission timer in the Lower Equipment Bay of the command module, as its circuit breaker had popped en route to the Moon. Worden's observations and photographs would inform the decision to send Apollo 17 to Taurus-Littrow to search for evidence of volcanic activity. There was a communications blackout when the CSM passed over the far side of the Moon from Earth; Worden greeted each resumption of contact with the words, "Hello, Earth. Greetings from "Endeavour"", expressed in different languages. Worden and El-Baz had come up with the idea, and the geology instructor had aided the astronaut in accumulating translations. 

Results from the SIM bay experiments would include the conclusion, from data gathered by the X-ray spectrometer that there was greater fluorescent X-ray flux than anticipated, and that the lunar highlands were richer in aluminum than were the mares. "Endeavour" was in a more inclined orbit than previous crewed missions, and Worden saw features that were not known previously, supplementing photographs with thorough descriptions.

By the time Scott and Irwin were ready to take off from the lunar surface and return to "Endeavor", the CSM's orbit had drifted due to the rotation of the Moon, and a plane change burn was required to ensure that the CSM's orbit would be in the same plane as that of the LM once it took off from the Moon. Worden accomplished the 18-second burn with the SPS.

"Falcon" lifted off the Moon at 17:11:22 GMT on August 2 after 66 hours and 55 minutes on the lunar surface. Docking with the CSM took place just under two hours later. After the astronauts transferred samples and other items from the LM to the CSM, the LM was sealed off, jettisoned, and intentionally crashed into the lunar surface, an impact registered by the seismometers left by Apollo 12, 14 and 15. The jettison proved difficult because of problems getting airtight seals, requiring a delay in discarding the LM. After the jettison, Slayton came on the loop to recommend that the astronauts take sleeping pills, or at least that Scott and Irwin do so. Scott as mission commander refused to allow it, feeling there was no need. During the EVAs, the doctors had noticed irregularities in the heartbeats of both Scott and Irwin, of which the crew was not informed during the flight. Irwin had heart problems after retiring as an astronaut and died in 1991 of a heart attack; Scott felt that he as commander should have been informed of the biomedical readings. NASA doctors at the time theorized the heart readings were due to potassium deficiency, due to their hard work on the surface and inadequate resupply through liquids.
The crew spent the next two days working on orbital science experiments, including more observations of the Moon from orbit and releasing the subsatellite. The three-person crew departed lunar orbit with another burn of the SPS engine of 2 minutes 21 seconds at 21:22:45 GMT on August 4. The next day, on the return trip to Earth, Worden performed a spacewalk in deep space, the first of its kind, to retrieve exposed film from the SIM bay. Later on in the day, the crew set a record for the longest Apollo flight to that point.

On approach to Earth on August 7, the service module was jettisoned, and the command module reentered the Earth's atmosphere. Although one of the three parachutes on the CM failed after deploying, likely due to damage as the spacecraft vented fuel, only two were required for a safe landing (one extra for redundancy). Upon landing in the North Pacific Ocean, the CM and crew were recovered and taken aboard the recovery ship, , after a mission lasting 12 days, 7 hours, 11 minutes and 53 seconds.

The mission objectives for Apollo 15 were to "perform selenological inspection, survey, and sampling of materials and surface features in a pre-selected area of the Hadley-Appenine region. Emplace and activate surface experiments. Evaluate the capability of the Apollo equipment to provide extended lunar surface stay time, increased extravehicular operations, and surface mobility. [and] Conduct inflight experiments and photographic tasks from lunar orbit." It achieved all those objectives. The mission also completed a long list of other tasks, including experiments. One of the photographic objectives, to obtain images of the gegenschein from lunar orbit, was not completed, as the camera was not pointed at the proper spot in the sky. According to the conclusions in the "Apollo 15 Mission Report", the journey "was the fourth lunar landing and resulted in the collection of a wealth of scientific information. The Apollo system, in addition to providing a means of transportation, excelled as an operational scientific facility."

According to David Woods in the "Apollo Lunar Flight Journal",
Despite the successful mission, the careers of the crew were tarnished by a deal they had made before the flight to carry postal covers to the Moon in exchange for about $7,000 each, which they planned to set aside for their children. Walter Eiermann, who had many professional and social contacts with NASA employees and the astronaut corps, served as intermediary between the astronauts and a West German stamp dealer, Hermann Sieger, and Scott carried about 400 covers onto the spacecraft; they were subsequently transferred into "Falcon" and remained inside the lander during the astronauts' activities on the surface of the Moon. After the return to Earth, 100 of the covers were given to Eiermann, who passed them on to Sieger, receiving a commission. No permission had been received from Slayton to carry the covers, as required.

The 100 covers were put on sale to Sieger's customers in late 1971 at a price of about $1,500 each. After receiving the agreed payments, the astronauts returned them, and accepted no compensation. In April 1972, Slayton learned that unauthorized covers had been carried, and removed the three as the backup crew for Apollo 17. The matter became public in June 1972 and the three astronauts were reprimanded for poor judgment; none ever flew in space again. During the investigation, the astronauts had surrendered those covers still in their possession; after Worden filed suit, they were returned in 1983, something "Slate" magazine deemed an exoneration..

Another controversy surrounding the "Fallen Astronaut" statuette that Scott had left on the Moon, arose later. Before the mission, Scott had made a verbal agreement with Belgian artist Paul Van Hoeydonck to sculpt the statuette. Scott's intent, in keeping with NASA's strict policy against commercial exploitation of the US government's space program, was for a simple memorial with a minimum of publicity, keeping the artist anonymous, no commercial replicas being made except for a single copy for public exhibit at the National Air and Space Museum commissioned after the sculpture's public disclosure during the post-flight press conference. Van Hoeydonck claims to have had a different understanding of the agreement, by which he would have received recognition as the creator of a tribute to human space exploration, with rights to sell replicas to the public. Under pressure from NASA, Van Hoeydonck canceled a plan to publicly sell 950 signed copies. 

The Apollo 15 mission patch carries Air Force motifs, a nod to the crew's service there, just as the Apollo 12 all-Navy crew's patch had featured a sailing ship. The circular patch features stylized red, white and blue birds flying over Hadley Rille. Immediately behind the birds, a line of craters form the Roman numeral XV. The Roman numerals were hidden in emphasized outlines of some craters after NASA insisted that the mission number be displayed in Arabic numerals. The artwork is circled in red, with a white band giving the mission and crew names and a blue border. Scott contacted fashion designer Emilio Pucci to design the patch, who came up with the basic idea of the three-bird motif on a square patch. The crew changed the shape to round and the colors from blues and greens to a patriotic red, white and blue. Worden stated that each bird also represented an astronaut, white being his own color (and as Command Module Pilot, uppermost), Scott being the blue bird and Irwin the red. The colors also matched Chevrolet Corvettes driven by the astronauts at KSC; they were photographed with the cars and the training LRV for the June 11, 1971 edition of "Life" magazine.

The halo area of the Apollo 15 landing site, created by the LM's exhaust plume, was observed by a camera aboard the Japanese lunar orbiter SELENE and confirmed by comparative analysis of photographs in May 2008. This corresponds well to photographs taken from the Apollo 15 command module showing a change in surface reflectivity due to the plume, and was the first visible trace of crewed landings on the Moon seen from space since the close of the Apollo program.



NASA reports

Multimedia


</doc>
<doc id="1970" url="https://en.wikipedia.org/wiki?curid=1970" title="Apollo 16">
Apollo 16

Apollo 16 was the tenth crewed mission in the United States Apollo space program, the fifth and second-to-last to land on the Moon, and the second to land in the lunar highlands. The second of the so-called "J missions," it was crewed by Commander John Young, Lunar Module Pilot Charles Duke and Command Module Pilot Ken Mattingly. Launched from the Kennedy Space Center in Florida at 12:54 PM EST on April 16, 1972, the mission lasted 11 days, 1 hour, and 51 minutes, and concluded at 2:45 PM EST on April 27.

Young and Duke spent 71 hours—just under three days—on the lunar surface, during which they conducted three extra-vehicular activities or moonwalks, totaling 20 hours and 14 minutes. The pair drove the Lunar Roving Vehicle (LRV), the second produced and used on the Moon, for . On the surface, Young and Duke collected of lunar samples for return to Earth, while Command Module Pilot Ken Mattingly orbited in the command and service module (CSM) above to perform observations. Mattingly, staying with the command module, spent 126 hours and 64 revolutions in lunar orbit. After Young and Duke rejoined Mattingly in lunar orbit, the crew released a subsatellite from the service module (SM). During the return trip to Earth, Mattingly performed a one-hour spacewalk to retrieve several film cassettes from the exterior of the service module.

Apollo 16's landing spot in the highlands was chosen to allow the astronauts to gather geologically older lunar material than the samples obtained in three of the first four Moon landings, which were in or near lunar maria (Apollo 14 landed in the Fra Mauro Highlands). Samples from the Descartes Formation and the Cayley Formation disproved a hypothesis that the formations were volcanic in origin.

Mattingly had originally been assigned to the prime crew of Apollo 13, but was exposed to rubella through Duke, at that time on the back-up crew for Apollo 13, who had caught it from one of his children. He never contracted the illness, but was nevertheless removed from the crew and replaced by his backup, Jack Swigert, three days before the launch. Young, a captain in the United States Navy, had flown on three spaceflights prior to Apollo 16: Gemini 3, Gemini 10 and Apollo 10, which orbited the Moon. One of 19 astronauts selected by NASA in April 1966, Duke had never flown in space before Apollo 16. He served on the support crew of Apollo 10 and was a capsule communicator (CAPCOM) for Apollo 11.

Although not officially announced, the original backup crew consisted of Fred W. Haise (CDR), William R. Pogue (CMP) and Gerald P. Carr (LMP), who were targeted for the prime crew assignment on Apollo 19. However, after the cancellations of Apollos 18 and 19 were finalized in September 1970 this crew would not rotate to a lunar mission as planned. Subsequently, Roosa and Mitchell were recycled to serve as members of the backup crew after returning from Apollo 14, while Pogue and Carr were reassigned to the Skylab program where they flew on Skylab 4.


The insignia of Apollo 16 is dominated by a rendering of an American eagle and a red, white and blue shield, representing the people of the United States, over a gray background representing the lunar surface. Overlaying the shield is a gold NASA vector, orbiting the Moon. On its gold-outlined blue border, there are 16 stars, representing the mission number, and the names of the crew members: Young, Mattingly, Duke. The insignia was designed from ideas originally submitted by the crew of the mission.

Apollo 16 was the second of the Apollo type J missions, featuring the use of the Lunar Roving Vehicle, increased scientific capability, and lunar surface stays of three days. As Apollo 16 was the penultimate mission in the Apollo program and there was no new hardware or procedures to test on the lunar surface, the last two missions (the other being Apollo 17) presented opportunities for astronauts to clear up some uncertainties in understanding the Moon's properties. Although previous Apollo expeditions, including Apollo 14 and Apollo 15, obtained samples of pre-mare lunar material, before lava began to upwell from the Moon's interior and flood the low areas and basins, none had actually visited the lunar highlands.

Apollo 14 had visited and sampled a ridge of material that had been ejected by the impact that created the Mare Imbrium impact basin. Likewise, Apollo 15 had also sampled material in the region of Imbrium, visiting the basin's edge. There remained the possibility, because the Apollo 14 and Apollo 15 landing sites were closely associated with the Imbrium basin, that different geologic processes were prevalent in areas of the lunar highlands far from Mare Imbrium. Several members of the scientific community remarked that the central lunar highlands resembled regions on Earth that were created by volcanic processes and hypothesized the same might be true on the Moon. They had hoped that scientific output from the Apollo 16 mission would provide an answer.

Two locations on the Moon were given primary consideration for exploration by the Apollo 16 expedition: the Descartes Highlands region west of Mare Nectaris and the crater Alphonsus. At Descartes, the Cayley and Descartes formations were the primary areas of interest in that scientists suspected, based on telescopic and orbital imagery, that the terrain found there was formed by magma more viscous than that which formed the lunar maria. The Cayley Formation's age was approximated to be about the same as Mare Imbrium based on the local frequency of impact craters. The considerable distance between the Descartes site and previous Apollo landing sites would be beneficial for the network of geophysical instruments, portions of which were deployed on each Apollo expedition beginning with Apollo 12.

At the Alphonsus, three scientific objectives were determined to be of primary interest and paramount importance: the possibility of old, pre-Imbrium impact material from within the crater's wall, the composition of the crater's interior and the possibility of past volcanic activity on the floor of the crater at several smaller "dark halo" craters. Geologists feared, however, that samples obtained from the crater might have been contaminated by the Imbrium impact, thus preventing Apollo 16 from obtaining samples of pre-Imbrium material. There also remained the distinct possibility that this objective had already been satisfied by the Apollo 14 and Apollo 15 missions, as the Apollo 14 samples had not yet been completely analyzed and samples from Apollo 15 had not yet been obtained.

It was decided to target the Apollo 16 mission for the Descartes site. Following the decision, the Alphonsus site was considered the most likely candidate for Apollo 17, but was eventually rejected. With the assistance of orbital photography obtained on the Apollo 14 mission, the Descartes site was determined to be safe enough for a crewed landing. The specific landing site was between two young impact craters, North Ray and South Ray craters – in diameter, respectively – which provided "natural drill holes" which penetrated through the lunar regolith at the site, thus leaving exposed bedrock that could be sampled by the crew.

After selecting the landing site for Apollo 16, sampling the Descartes and Cayley formations, two geologic units of the lunar highlands, was determined by mission planners to be the primary sampling interest of the mission. It was these formations that the scientific community widely suspected were formed by lunar volcanism, but this hypothesis was proven incorrect by the composition of lunar samples from the mission.

In preparing for their mission, in addition to the usual Apollo spacecraft training, Young and Duke, along with backup commander Fred Haise, underwent an extensive geological training program that included several field trips to introduce them to concepts and techniques they would use in analyzing features and collecting samples on the lunar surface. During these trips, they visited and provided scientific descriptions of geologic features they were likely to encounter. In July 1971, they visited Sudbury, Ontario, Canada for geology training exercises, the first time U.S. astronauts did so. Geologists chose the area because of a wide crater created about 1.8 billion years ago by a large meteorite. The Sudbury Basin shows evidence of shatter cone geology familiarizing the Apollo crew with geologic evidence of a meteor impact. During the training exercises the astronauts did not wear space suits, but carried radio equipment to converse with each other and scientist-astronaut Anthony W. England, practicing procedures they would use on the lunar surface.

In addition to the field geology training, Young and Duke also trained to use their EVA space suits, adapt to the reduced lunar gravity, collect samples, and drive the Lunar Roving Vehicle. They also received survival training and preparation for other technical aspects of the mission.

Command Module Pilot Mattingly also received training in recognizing geological features from orbit by flying over the field areas in an airplane, and trained to operate the Scientific Instrument Module from lunar orbit.

The launch of Apollo 16 was delayed one month from March 17 to April 16. This was the first launch delay in the Apollo program due to a technical problem. During the delay, the space suits, a spacecraft separation mechanism and batteries in the lunar module (LM) were modified and tested. There were concerns that the explosive mechanism designed to separate the docking ring from the command module (CM) would not create enough pressure to completely sever the ring. This, along with a dexterity issue in Young's space suit and fluctuations in the capacity of the lunar module batteries, required investigation and trouble-shooting. In January 1972, three months before the planned April launch date, a fuel tank in the command module was accidentally damaged during a routine test. The rocket was returned to the Vertical Assembly Building (VAB) and the fuel tank replaced, and the rocket returned to the launch pad in February in time for the scheduled launch.

The official mission countdown began on Monday, April 10, 1972, at 8:30 AM, six days before the launch. At this point the Saturn V rocket's three stages were powered up and drinking water was pumped into the spacecraft. As the countdown began, the crew of Apollo 16 was participating in final training exercises in anticipation of a launch on April 16. The astronauts underwent their final preflight physical examination on April 11. On April 15, liquid hydrogen and liquid oxygen propellants were pumped into the spacecraft, while the astronauts rested in anticipation of their launch the next day.

The Apollo 16 mission launched from the Kennedy Space Center in Florida at 12:54 PM EST on April 16, 1972. The launch was nominal; the crew experienced vibration similar to that of previous crews. The first and second stages of the Saturn V rocket performed nominally; the spacecraft entered orbit around Earth just under 12 minutes after lift-off. After reaching orbit, the crew spent time adapting to the zero-gravity environment and preparing the spacecraft for Trans Lunar Injection (TLI), the burn of the third-stage rocket that would propel them to the Moon. In Earth orbit, the crew faced minor technical issues, including a potential problem with the environmental control system and the S-IVB third stage's attitude control system, but eventually resolved or compensated for them as they prepared to depart towards the Moon. After two orbits, the rocket's third stage reignited for just over five minutes, propelling the craft towards the Moon at about . Six minutes after the burn of the S-IVB, the command and service module, containing the crew, separated from the rocket and traveled for before turning around and retrieving the lunar module from inside the expended rocket stage. The maneuver, known as transposition, went smoothly and the LM was extracted from the S-IVB. Following transposition and docking, the crew noticed the exterior surface of the lunar module was giving off particles from a spot where the LM's skin appeared torn or shredded; at one point, Duke estimated they were seeing about five to ten particles per second. The crew entered the lunar module through the docking tunnel connecting it with the command module to inspect its systems, at which time they did not spot any major issues. Once on course towards the Moon, the crew put the spacecraft into a rotisserie "barbecue" mode in which the craft rotated along its long axis three times per hour to ensure even heat distribution about the spacecraft from the Sun. After further preparing the craft for the voyage, the crew began the first sleep period of the mission just under 15 hours after launch.

By the time Mission Control issued the wake-up call to the crew for flight day two, the spacecraft was about away from the Earth, traveling at about . As it was not due to arrive in lunar orbit until flight day four, flight days two and three were largely preparatory days, consisting of spacecraft maintenance and scientific research. On day two, the crew performed an electrophoresis experiment, also performed on Apollo 14, in which they attempted to prove the higher purity of particle migrations in the zero-gravity environment. The remainder of day two included a two-second mid-course correction burn performed by the CSM's service propulsion system engine to tweak the spacecraft's trajectory. Later in the day, the astronauts entered the lunar module for the second time in the mission to further inspect the landing craft's systems. The crew reported they had observed additional paint peeling from a portion of the LM's outer aluminum skin. Despite this, the crew discovered that the spacecraft's systems were performing nominally. Following the LM inspection, the crew reviewed checklists and procedures for the following days in anticipation of their arrival and the Lunar Orbit Insertion burn. Command Module Pilot Mattingly reported a "gimbal lock" warning light, indicating the craft was not reporting an attitude. Mattingly alleviated this by realigning the guidance system using the Sun and Moon. At the end of day two, Apollo 16 was about away from Earth.

At the beginning of day three, the spacecraft was about away from the Earth. The velocity of the craft steadily decreased, as it had not yet reached the lunar sphere of gravitational influence. The early part of day three was largely housekeeping, spacecraft maintenance and exchanging status reports with Mission Control in Houston. The crew performed the Apollo light flash experiment, or ALFMED, to investigate "light flashes" that were seen by the astronauts when the spacecraft was dark, regardless of whether or not their eyes were open, on Apollo lunar flights. This was thought to be caused by the penetration of the eye by cosmic ray particles. During the second half of the day, Young and Duke again entered the lunar module to power it up and check its systems, and perform housekeeping tasks in preparation for lunar landing. The systems were found to be functioning as expected. Following this, the crew donned their space suits and rehearsed procedures that would be used on landing day. Just before the end of flight day three at 59 hours, 19 minutes, 45 seconds after liftoff, while from the Earth and from the Moon, the spacecraft's velocity began increasing as it accelerated towards the Moon after entering the lunar sphere of influence.

After waking up on flight day four, the crew began preparations for the maneuver that would brake the spacecraft into orbit around the Moon, or lunar orbit insertion. At a distance of from the Moon, the scientific instrument module (SIM) bay cover was jettisoned. At just over 74 hours into the mission, the spacecraft passed behind the Moon, losing direct contact with Mission Control. While over the far side of the Moon, the CSM's service propulsion system engine burned for 6 minutes and 15 seconds, braking the spacecraft into an orbit around the Moon with a low point (pericynthion) of 58.3 and a high point (apocynthion) of 170.4 nautical miles (108.0 and 315.6 km, respectively). After entering lunar orbit, the crew began preparations for the Descent Orbit Insertion (DOI) maneuver to further modify the spacecraft's orbital trajectory. The maneuver was successful, decreasing the craft's pericynthion to . The remainder of flight day four was spent making observations and preparing for activation of the lunar module, undocking, and landing the next day.

The crew continued preparing for lunar module activation and undocking shortly after waking up to begin flight day five. The boom that extended the mass spectrometer out from the CSM's scientific instruments bay was stuck in a semi-deployed position. It was decided that Young and Duke would visually inspect the boom after undocking from the CSM in the LM. They entered the LM for activation and checkout of the spacecraft's systems. Despite entering the LM 40 minutes ahead of schedule, they completed preparations only 10 minutes early due to numerous delays in the process. With the preparations finished, they undocked in the LM "Orion" from Mattingly in the CSM "Casper" 96 hours, 13 minutes, 13 seconds into the mission. For the rest of the two crafts' passes over the near side of the Moon, Mattingly prepared to shift "Casper" to a circular orbit while Young and Duke prepared "Orion" for the descent to the lunar surface. At this point, during tests of the CSM's steerable rocket engine in preparation for the burn to modify the craft's orbit, a malfunction occurred in the engine's backup system. According to mission rules, "Orion" would have then re-docked with "Casper", in case Mission Control decided to abort the landing and use the lunar module's engines for the return trip to Earth. After several hours of analysis, however, mission controllers determined that the malfunction could be worked around and Young and Duke could proceed with the landing. As a result of this, powered descent to the lunar surface began about six hours behind schedule. Because of the delay, Young and Duke began their descent to the surface at an altitude higher than that of any previous mission, at . At an altitude of about , Young was able to view the landing site in its entirety. Throttle-down of the LM's landing engine occurred on time and the spacecraft tilted forward to its landing orientation at an altitude of . The LM landed north and west of the planned landing site at 104 hours, 29 minutes, and 35 seconds into the mission, at 2:23:35 UTC on April 21.

After landing, Young and Duke began powering down some of the LM's systems to conserve battery power. Upon completing their initial adjustments, the pair configured "Orion" for their three-day stay on the lunar surface, removed their space suits and took initial geological observations of the immediate landing site. They then settled down for their first meal on the surface. After eating, they configured the cabin for their first sleep period on the Moon. The landing delay caused by the malfunction in the CSM's main engine necessitated significant modifications to the mission schedule. Apollo 16 would spend one less day in lunar orbit after surface exploration had been completed to afford the crew contingency time to compensate for any further problems and to conserve expendables. In order to improve Young's and Duke's sleep schedule, the third and final moonwalk of the mission was trimmed from seven hours to five.

The next morning, flight day five, Young and Duke ate breakfast and began preparations for the first extra-vehicular activity (EVA), or moonwalk. After the pair donned and pressurized their space suits and depressurized the lunar module cabin, Young climbed out onto the "porch" of the LM, a small platform above the ladder. Duke handed Young a jettison bag full of trash to dispose of on the surface. Young then lowered the equipment transfer bag (ETB), containing equipment for use during the EVA, to the surface. Young descended the ladder and, upon setting foot on the lunar surface, became the ninth human to walk on the Moon. Upon stepping onto the surface, Young expressed his sentiments about being there: "There you are: Mysterious and Unknown Descartes. Highland plains. Apollo 16 is gonna change your image. I'm sure glad they got ol' Brer Rabbit, here, back in the briar patch where he belongs." Duke soon descended the ladder and joined Young on the surface, becoming the tenth and youngest human to walk on the Moon, at age 36. After setting foot on the lunar surface, Duke expressed his excitement, commenting: "Fantastic! Oh, that first foot on the lunar surface is super, Tony!" The pair's first task of the moonwalk was to unload the Lunar Roving Vehicle, the Far Ultraviolet Camera/Spectrograph (UVC), and other equipment, from the lunar module. This was done without problems. On first driving the lunar rover, Young discovered that the rear steering was not working. He alerted Mission Control to the problem before setting up the television camera and planting the flag of the United States with Duke.

The day's next task was to deploy the Apollo Lunar Surface Experiments Package (ALSEP); while they were parking the lunar rover, on which the TV camera was mounted, to observe the deployment, the rear steering began functioning without explanation. While deploying a heat-flow experiment (that had burned up with the lunar module "Aquarius" on Apollo 13 and had been attempted with limited success on Apollo 15), a cable was inadvertently snapped after getting caught around Young's foot. After ALSEP deployment, they collected samples in the vicinity. About four hours after the beginning of EVA-1, they mounted the lunar rover and drove to the first geologic stop, Plum Crater, a crater on the rim of Flag crater, about across. There, at a distance of from the LM, they sampled material from the vicinity of Flag Crater, which scientists believed penetrated through the upper regolith layer to the underlying Cayley Formation. It was there that Duke retrieved, at the request of Mission Control, the largest rock returned by an Apollo mission, a breccia nicknamed Big Muley after mission geology principal investigator William R. Muehlberger. The next stop of the day was Buster Crater, about from the LM. There, Duke took pictures of Stone Mountain and South Ray Crater while Young deployed a magnetic field experiment. At that point, scientists began to reconsider their pre-mission hypothesis that Descartes had been the setting of ancient volcanic activity, as the two astronauts had yet to find any volcanic material. Following their stop at Buster, Young did a demonstration drive of the lunar rover while Duke filmed with a 16 mm movie camera. After completing more tasks at the ALSEP, they returned to the LM to close out the moonwalk. They reentered the LM 7 hours, 6 minutes, and 56 seconds after the start of the EVA. Once inside, they pressurized the LM cabin, went through a half-hour briefing with scientists in Mission Control, and configured the cabin for the sleep period.

Shortly after waking up on the morning of flight day six three and a half minutes early, they discussed with Mission Control in Houston the day's timeline of events. The second lunar excursion's primary objective was to visit Stone Mountain to climb up the slope of about 20 degrees to reach a cluster of five craters known as "Cinco Craters." After preparations for the day's moonwalk were completed, the astronauts climbed out of the lunar module. After departing the immediate landing site in the lunar rover, they arrived at the day's first destination, the Cinco craters, from the LM. At above the valley floor, the pair were at the highest elevation above the LM of any Apollo mission. After marveling at the view (including South Ray) from the side of Stone Mountain, which Duke described as "spectacular," the astronauts gathered samples in the vicinity. After spending 54 minutes on the slope, they climbed aboard the lunar rover en route to the day's second stop, station five, a crater across. There, they hoped to find Descartes material that had not been contaminated by ejecta from South Ray Crater, a large crater south of the landing site. The samples they collected there, although their origin is still not certain, are, according to geologist Don Wilhelms, "a reasonable bet to be Descartes." The next stop, station six, was a blocky crater, where the astronauts believed they could sample the Cayley Formation as evidenced by the firmer soil found there. Bypassing station seven to save time, they arrived at station eight on the lower flank of Stone Mountain, where they sampled material on a ray from South Ray Crater for about an hour. There, they collected black and white breccias and smaller, crystalline rocks rich in plagioclase. At station nine, an area known as the "Vacant Lot," which was believed to be free of ejecta from South Ray, they spent about 40 minutes gathering samples. Twenty-five minutes after departing station nine, they arrived at the final stop of the day, halfway between the ALSEP site and the LM. There, they dug a double core and conducted several penetrometer tests along a line stretching east of the ALSEP. At the request of Young and Duke, the moonwalk was extended by ten minutes. After returning to the LM to wrap up the second lunar excursion, they climbed back inside the landing craft's cabin, sealing and pressurizing the interior after 7 hours, 23 minutes, and 26 seconds of EVA time, breaking a record that had been set on Apollo 15. After eating a meal and proceeding with a debriefing on the day's activities with Mission Control, they reconfigured the LM cabin and prepared for the sleep period.

Flight day seven was their third and final day on the lunar surface, returning to orbit to rejoin Mattingly in the CSM following the day's moonwalk. During the third and final lunar excursion, they were to explore North Ray Crater, the largest of any of the craters any Apollo expedition had visited. After exiting "Orion", the pair drove the lunar rover away from the LM before adjusting their heading to travel to North Ray Crater. The drive was smoother than that of the previous day, as the craters were shallower and boulders were less abundant north of the immediate landing site. After passing Palmetto crater, boulders gradually became larger and more abundant as they approached North Ray in the lunar rover. Upon arriving at the rim of North Ray crater, they were away from the LM. After their arrival, the duo took photographs of the wide and deep crater. They visited a large boulder, taller than a four-story building, which became known as 'House Rock'. Samples obtained from this boulder delivered the final blow to the pre-mission volcanic hypothesis, proving it incorrect. House Rock had numerous bullet hole-like marks where micrometeoroids from space had impacted the rock. About 1 hour and 22 minutes after arriving, they departed for station 13, a large boulder field about from North Ray. On the way, they set a lunar speed record, traveling at an estimated downhill. They arrived at a high boulder, which they called 'Shadow Rock'. Here, they sampled permanently shadowed soil. During this time, Mattingly was preparing the CSM in anticipation of their return approximately six hours later. After three hours and six minutes, they returned to the LM, where they completed several experiments and offloaded the rover. A short distance from the LM, Duke placed a photograph of his family and a United States Air Force commemorative medallion on the surface. Young drove the rover to a point about east of the LM, known as the 'VIP site,' so its television camera, controlled remotely by Mission Control, could observe Apollo 16's liftoff from the Moon. They then reentered the LM after a 5-hour and 40 minute final excursion. After pressurizing the LM cabin, the crew began preparing to return to lunar orbit.

Eight minutes before departing the lunar surface, CAPCOM James Irwin notified Young and Duke from Mission Control that they were go for liftoff. Two minutes before launch, they activated the "Master Arm" switch and then the "Abort Stage" button, after which they awaited ignition of "Orion"’s ascent stage engine. When the ascent stage ignited, small explosive charges severed the ascent stage from the descent stage and cables connecting the two were severed by a guillotine-like mechanism. Six minutes after liftoff, at a speed of about , Young and Duke reached lunar orbit. Young and Duke successfully rendezvoused and re-docked with Mattingly in the CSM. To minimize the transfer of lunar dust from the LM cabin into the CSM, Young and Duke cleaned the cabin before opening the hatch separating the two spacecraft. After opening the hatch and reuniting with Mattingly, the crew transferred the samples Young and Duke had collected on the surface into the CSM for transfer to Earth. After transfers were completed, the crew would sleep before jettisoning the empty lunar module ascent stage the next day, when it was to be crashed intentionally into the lunar surface.

The next day, after final checks were completed, the expended LM ascent stage was jettisoned. Because of a failure by the crew to activate a certain switch in the LM before sealing it off, it initially tumbled after separation and did not execute the rocket burn necessary for the craft's intentional de-orbit. The ascent stage eventually crashed into the lunar surface nearly a year after the mission. The crew's next task, after jettisoning the lunar module ascent stage, was to release a subsatellite into lunar orbit from the CSM's scientific instrument bay. The burn to alter the CSM's orbit to that desired for the subsatellite had been cancelled; as a result, the subsatellite lasted half of its anticipated lifetime. Just under five hours later, on the CSM's 65th orbit around the Moon, its service propulsion system main engine was reignited to propel the craft on a trajectory that would return it to Earth. The SPS engine performed the burn flawlessly despite the malfunction that had delayed the lunar landing several days before.

At a distance of about from Earth, Mattingly performed a "deep-space" extra-vehicular activity, or spacewalk, during which he retrieved several film cassettes from the CSM's SIM bay. While outside the spacecraft, Mattingly set up a biological experiment, the Microbial Ecology Evaluation Device (MEED). The MEED experiment was only performed on Apollo 16. The crew carried out various housekeeping and maintenance tasks aboard the spacecraft and ate a meal before concluding the day.

The penultimate day of the flight was largely spent performing experiments, aside from a twenty-minute press conference during the second half of the day. During the press conference, the astronauts answered questions pertaining to several technical and non-technical aspects of the mission prepared and listed by priority at the Manned Spacecraft Center in Houston by journalists covering the flight. In addition to numerous housekeeping tasks, the astronauts prepared the spacecraft for its atmospheric reentry the next day. At the end of the crew's final full day in space, the spacecraft was approximately from Earth and closing at a rate of about .

When the wake-up call was issued to the crew for their final day in space by CAPCOM Tony England, it was about out from Earth, traveling just over . Just over three hours before splashdown in the Pacific Ocean, the crew performed a final course correction burn, changing their velocity by . Approximately ten minutes before reentry into Earth's atmosphere, the cone-shaped command module containing the three crewmembers separated from the service module, which would burn up during reentry. At 265 hours and 37 minutes into the mission, at a velocity of about , Apollo 16 began atmospheric reentry. At its maximum, the temperature of the heat shield was between . After successful parachute deployment and less than 14 minutes after reentry began, the command module splashed down in the Pacific Ocean southeast of the island of Kiritimati (or "Christmas Island"), 290 hours, 37 minutes, 6 seconds after liftoff. The spacecraft and its crew was retrieved by the . They were safely aboard the "Ticonderoga" 37 minutes after splashdown.

The Apollo 16 Particles and Fields Subsatellite (PFS-2) was a small satellite released into lunar orbit from the service module. Its principal objective was to measure charged particles and magnetic fields all around the Moon as the Moon orbited Earth, similar to its sister spacecraft, PFS-1, released eight months earlier by Apollo 15. "The low orbits of both subsatellites were to be similar ellipses, ranging from above the lunar surface."

Instead, something unexpected happened. "The orbit of PFS-2 rapidly changed shape and distance from the Moon. In 2-1/2 weeks the satellite was swooping to within a hair-raising of the lunar surface at closest approach. As the orbit kept changing, PFS-2 backed off again, until it seemed to be a safe 30 miles away. But not for long: inexorably, the subsatellite's orbit carried it back toward the Moon. And on May 29, 1972—only 35 days and 425 orbits after its release"—PFS-2 crashed into the Lunar surface.

The aircraft carrier USS "Ticonderoga" delivered the Apollo 16 command module to the North Island Naval Air Station, near San Diego, California, on Friday, May 5, 1972. On Monday, May 8, 1972, ground service equipment being used to empty the residual toxic reaction control system fuel in the command module tanks exploded in a Naval Air Station hangar. Forty-six people were sent to the hospital for 24 to 48 hours observation, most suffering from inhalation of toxic fumes. Most seriously injured was a technician who suffered a fractured kneecap when the GSE cart overturned on him. A hole was blown in the hangar roof 250 feet above; about 40 windows in the hangar were shattered. The command module suffered a three-inch gash in one panel.

The Apollo 16 command module "Casper" is on display at the U.S. Space & Rocket Center in Huntsville, Alabama. The lunar module ascent stage separated 24 April 1972 but a loss of attitude control rendered it out of control. It orbited the Moon for about a year. Its impact site remains unknown. The S-IVB was deliberately crashed into the Moon. However, due to a communication failure before impact the exact location was unknown until January 2016, when it was discovered within Mare Insularum by the Lunar Reconnaissance Orbiter, approximately southwest of Copernicus Crater.

Duke donated some flown items, including a lunar map, to Kennesaw State University in Kennesaw, Georgia. He left two items on the Moon, both of which he photographed. The most famous is a plastic-encased photo portrait of his family (NASA Photo AS16-117-18841). The reverse of the photo is signed by Duke's family and bears this message: "This is the family of Astronaut Duke from Planet Earth. Landed on the Moon, April 1972." The other item was a commemorative medal issued by the United States Air Force, which was celebrating its 25th anniversary in 1972. He took two medals, leaving one on the Moon and donating the other to the Wright-Patterson Air Force Base museum.

In 2006, shortly after Hurricane Ernesto affected Bath, North Carolina, eleven-year-old Kevin Schanze discovered a piece of metal debris on the ground near his beach home. Schanze and a friend discovered a "stamp" on the flat metal sheet, which upon further inspection turned out to be a faded copy of the Apollo 16 mission insignia. NASA later confirmed the object to be a piece of the first stage of the Saturn V rocket that launched Apollo 16 into space. In July 2011, after returning the piece of debris at NASA's request, 16-year-old Schanze was given an all-access tour of the Kennedy Space Center and VIP seating for the launch of STS-135, the final mission of the Space Shuttle program.




</doc>
<doc id="1971" url="https://en.wikipedia.org/wiki?curid=1971" title="Apollo 17">
Apollo 17

Apollo 17 (December 7-19, 1972) was the final mission of NASA's Apollo program; it remains the most recent time humans have travelled beyond low Earth orbit. Its crew consisted of Commander Eugene Cernan, Lunar Module Pilot Harrison Schmitt, and Command Module Pilot Ronald Evans.

Launched at 12:33 a.m. Eastern Standard Time (EST) on December 7, 1972, Apollo 17 was a "J-type mission" that included three days on the lunar surface, extended scientific capability, and the use of the third Lunar Roving Vehicle (LRV). 

Cernan and Schmitt landed in the Taurus–Littrow valley and completed three moonwalks, taking lunar samples and deploying scientific instruments. The landing site had been chosen to further the mission's main goals: to sample lunar highland material older than Mare Imbrium, and to investigate the possibility of relatively recent volcanic activity. Evans remained in lunar orbit in the command and service module (CSM), taking scientific measurements and photographs.

Cernan, Evans, and Schmitt returned to Earth on December 19.

Apollo 17 was the first mission to have no one on board who had been a test pilot; X-15 test pilot Joe Engle lost the lunar module pilot assignment to Schmitt, a geologist. The mission included the first night launch of a U.S. human spaceflight and the final crewed launch of a Saturn V rocket. It was also the final use of Apollo hardware for its original purpose (extra Apollo spacecraft were later used in the Skylab and Apollo–Soyuz programs).

The mission broke several crewed spaceflight records: the longest Moon landing, longest total extravehicular activities (moonwalks), largest lunar sample, longest time in lunar orbit, and, at 75, most lunar orbits.

In 1969, NASA announced that the backup crew of Apollo 14, slated to fly in 1971, would be Eugene Cernan, Ronald Evans, and former X-15 pilot Joe Engle (whose 16 flights in the X-15 had thrice taken him past the border of space). Because the Apollo program generally slated a backup crew to fly as prime crew three missions later, Cernan, Evans, and Engle were in line to be prime crew of Apollo 17. Meanwhile, Harrison Schmitt — a professional geologist — was assigned to the backup crew of Apollo 15 and slated to fly as Lunar Module Pilot on Apollo 18. 

However, Apollo 18 was cancelled in September 1970. The scientific community subsequently pressed NASA to find a way to assign a geologist — and not just a pilot with geology training — to an Apollo landing. So NASA assigned Schmidt as the Lunar Module Pilot of Apollo 17, bumping astronaut Curt Michel, who had a Ph.D in physics. 

That opened the question of who would fill the other two Apollo 17 slots: the rest of the Apollo 15 backup crew (Dick Gordon and Vance Brand) or the Apollo 14 backup crew (minus Engle)? NASA Director of Flight Crew Operations Deke Slayton ultimately chose Cernan and Evans.

The Apollo 15 prime crew received the backup assignment since this was to be the last lunar mission and the backup crew would not rotate to another mission. However, when the Apollo 15 postage stamp incident became public in early 1972 the crew was reprimanded by NASA and the United States Air Force (they were active duty officers). Director of Flight Crew Operations Deke Slayton removed them from flight status and replaced them with Young and Duke from the Apollo 16 prime crew and Roosa from the Apollo 14 prime and Apollo 16 backup crews.


The insignia's most prominent feature is an image of the Greek sun god Apollo backdropped by a rendering of an American eagle, the red bars on the eagle mirroring those on the flag of the United States. Three white stars above the red bars represent the three crewmen of the mission. The background includes the Moon, the planet Saturn, and a galaxy or nebula. The wing of the eagle partially overlays the Moon, suggesting man's established presence there. The gaze of Apollo and the direction of the eagle's motion embody man's intention to explore further destinations in space.

The patch includes, along with the colors of the U.S. flag (red, white, and blue), the color gold, representative of a "golden age" of spaceflight that was to begin with Apollo 17. The image of Apollo in the mission insignia is a rendering of the "Apollo Belvedere" sculpture. The insignia was designed by Robert McCall, with input from the crew.

Like Apollo 15 and Apollo 16, Apollo 17 was slated to be a "J-mission", an Apollo mission type that featured lunar surface stays of three days, higher scientific capability, and the usage of the Lunar Roving Vehicle. Since Apollo 17 was to be the final lunar landing of the Apollo program, high-priority landing sites that had not been visited previously were given consideration for potential exploration. A landing in the crater Copernicus was considered, but was ultimately rejected because Apollo 12 had already obtained samples from that impact, and three other Apollo expeditions had already visited the vicinity of Mare Imbrium. A landing in the lunar highlands near the crater Tycho was also considered, but was rejected because of the rough terrain found there and a landing on the lunar far side in the crater Tsiolkovskiy was rejected due to technical considerations and the operational costs of maintaining communication during surface operations. A landing in a region southwest of Mare Crisium was also considered, but rejected on the grounds that a Soviet spacecraft could easily access the site; Luna 21 eventually did so shortly after the Apollo 17 site selection was made.

After the elimination of several sites, three sites made the final consideration for Apollo 17: Alphonsus crater, Gassendi crater, and the Taurus-Littrow valley. In making the final landing site decision, mission planners took into consideration the primary objectives for Apollo 17: obtaining old highlands material from a substantial distance from Mare Imbrium, sampling material from young volcanic activity (i.e., less than three billion years), and having minimal ground overlap with the orbital ground tracks of Apollo 15 and Apollo 16 to maximize the amount of new data obtained.

The Taurus-Littrow site was selected with the prediction that the crew would be able to obtain samples of old highland material from the remnants of a landslide event that occurred on the south wall of the valley and the possibility of relatively young, explosive volcanic activity in the area. Although the valley is similar to the landing site of Apollo 15 in that it is on the border of a lunar mare, the advantages of Taurus-Littrow were believed to outweigh the drawbacks, thus leading to its selection as the Apollo 17 landing site.

As with previous lunar landings, the Apollo 17 astronauts underwent an extensive training program that included training to collect samples on the surface, usage of the spacesuits, navigation in the Lunar Roving Vehicle, field geology training, survival training, splashdown and recovery training, and equipment training.

Apollo 17 was the only Apollo lunar landing mission to carry the Traverse Gravimeter Experiment (TGE), built by Draper Laboratory at the Massachusetts Institute of Technology. As gravimeters had proven to be useful in the geologic investigation of the Earth, the objective of this experiment was to determine the feasibility of using the same techniques on the Moon to learn about its internal structure. The gravimeter was used to obtain relative gravity measurements at the landing site in the immediate vicinity of the lunar module, as well as various locations on the mission's traverse routes. Scientists would then use this data to help determine the geological substructure of the landing site and the surrounding vicinity.

The TGE was carried on the Lunar Roving Vehicle; measurements were taken by the astronauts while the LRV was not in motion or after the gravimeter was placed on the surface. A total of twenty-six measurements were taken with the TGE during the mission's three moonwalks, with productive results. As part of the Apollo Lunar Surface Experiments Package (ALSEP), the astronauts also deployed the Lunar Surface Gravimeter, a similar experiment, which ultimately failed to function properly.

Sector one of the Apollo 17 SM contained the scientific instrument module (SIM) bay. The SIM bay housed three experiments for use in lunar orbit: a lunar sounder, an infrared scanning radiometer, and a far-ultraviolet spectrometer. A mapping camera, panoramic camera, and a laser altimeter were also included in the SIM bay.

The lunar sounder beamed electromagnetic impulses toward the lunar surface, which were designed with the objective of obtaining data to assist in developing a geological model of the interior of the Moon to an approximate depth of .

The infrared scanning radiometer was designed with the objective of generating a temperature map of the lunar surface to aid in locating surface features such as rock fields, structural differences in the lunar crust, and volcanic activity.

The far-ultraviolet spectrometer was to be used to obtain data pertaining to the composition, density, and constituency of the lunar atmosphere. The spectrometer was also designed to detect far-UV radiation emitted by the Sun that has been reflected off the lunar surface.

The laser altimeter was designed with the intention of measuring the altitude of the spacecraft above the lunar surface within approximately , and providing altitude information to the panoramic and mapping cameras.

Throughout the Apollo lunar missions, the crew members observed light flashes that penetrated closed eyelids. These flashes, described as "streaks" or "specks" of light, were usually observed by astronauts while the spacecraft was darkened during a sleep period. These flashes, while not observed on the lunar surface, would average about two per minute and were observed by the crew members during the trip out to the Moon, back to Earth, and in lunar orbit.

The Apollo 17 crew conducted an experiment, also conducted on Apollo 16, with the objective of linking these light flashes with cosmic rays. As part of an experiment conducted by NASA and the University of Houston, one astronaut wore a device that recorded the time, strength, and path of high-energy atomic particles that penetrated the device. Analysis of the results concluded that the evidence supported the hypothesis that the flashes occurred when charged particles travelled through the retina in the eye.

Apollo 17 was the only lunar surface expedition to include the surface electrical properties (SEP) experiment. The experiment included two major components: a transmitting antenna deployed near the lunar module and a receiving antenna located on the Lunar Roving Vehicle. At different stops during the mission's traverses, electrical signals traveled from the transmitting device, through the ground, and received at the LRV. The electrical properties of the lunar soil could be determined by comparison of the transmitted and received electrical signals. The results of this experiment, which are consistent with lunar rock composition, show that the top of the Moon are extremely dry.

Apollo 17 was the third mission (the others being Apollo 15 and Apollo 16) to make use of a Lunar Roving Vehicle. The LRV, in addition to being used by the astronauts for transport from station to station on the mission's three moonwalks, was used to transport the astronauts' tools, communications equipment, and samples. The Apollo 17 LRV was also used to carry experiments unique to the mission, such as the Traverse Gravimeter and Surface Electrical Properties experiment. The Apollo 17 LRV traveled a cumulative distance of approximately in a total drive time of about four hours and twenty-six minutes; the greatest distance Eugene Cernan and Harrison Schmitt traveled from the lunar module was about .

Apollo 17 included a biological cosmic ray experiment (BIOCORE), carrying five mice that had been implanted with radiation monitors to see whether they suffered damage from cosmic rays.

The five pocket mice ("Perognathus longimembris"), nicknamed Fe, Fi, Fo, Fum, and Phooey by the Apollo 17 crew, were implanted with radiation monitors under their scalps and flown on the mission. The species was chosen because it was well-documented, small, easy to maintain in an isolated state (not requiring drinking water for the duration of the mission and with highly concentrated waste), and for its ability to withstand environmental stress. Four of the five mice survived the flight; the cause of death of the fifth mouse was not determined.

The study found lesions in the scalp itself and liver. The scalp lesions and liver lesions appeared to be unrelated to one another, and were not thought to be the result of cosmic rays. No damage was found in the mice's retinas or viscera. At the time of the publication of the Apollo 17 Preliminary Science Report, the mouse brains had not yet been examined. However, subsequent studies showed no significant effect on the brains.

Officially, the mice—four male and one female—were assigned the identification numbers A3326, A3400, A3305, A3356 and A3352. Unofficially, according to Cernan, the Apollo 17 crew dubbed them "Fe", "Fi", "Fo", "Fum" and "Phooey".

Apollo 17 was the last crewed Saturn V launch and the only night launch. The launch was delayed by two hours and forty minutes due to an automatic cutoff in the launch sequencer at the T-30 second mark in the countdown. The issue was quickly determined to be a minor technical error. The clock was reset and held at the T-22 minute mark while technicians worked around the malfunction in order to continue with the launch. This pause was the only launch delay in the Apollo program caused by this type of hardware failure. The count then resumed, and the liftoff occurred at 12:33 am EST.

Approximately 500,000 people were estimated to have observed the launch in the immediate vicinity of Kennedy Space Center, despite the early morning hour. The launch was visible as far away as ; observers in Miami, Florida, saw a "red streak" crossing the northern sky.

At 3:46 am EST, the S-IVB third stage was re-ignited to propel the spacecraft towards the Moon.

At approximately 2:47 pm EST on December 10, the service propulsion system engine on the CSM ignited to slow down the CSM/LM stack into lunar orbit. Following orbit insertion and orbital stabilization, the crew began preparations for landing in the Taurus-Littrow valley.

After separating from the CSM, the LM "Challenger" and its crew of two, Eugene Cernan and Harrison Schmitt, adjusted their orbit and began preparations for the descent to Taurus-Littrow. While Cernan and Schmitt prepared for landing, Command Module Pilot Ron Evans remained in orbit to take observations, perform experiments and await the return of his crew-mates a few days later.

Soon after completing their preparations for landing, Cernan and Schmitt began their descent to the Taurus-Littrow valley on the lunar surface. Several minutes after the descent phase was initiated, the LM pitched over, giving the crew their first look at the landing site during the descent phase and allowing Cernan to guide the spacecraft to a desirable landing target while Schmitt provided data from the flight computer essential for landing. The LM touched down on the lunar surface at 2:55 pm EST on December 11. Shortly thereafter, the two astronauts began re-configuring the LM for their stay on the surface and began preparations for the first moonwalk of the mission, or EVA-1.

The first moonwalk (EVA) of the mission began approximately four hours after landing, at about 6:55 pm on December 11. The first task of the first lunar excursion was to offload the Lunar Roving Vehicle and other equipment from the LM. While working near the rover, a fender was accidentally broken off when Gene Cernan brushed up against it, his hammer getting caught under the right-rear fender, breaking off the rear extension. The same incident had also occurred on Apollo 16 as Commander John Young maneuvered around the rover. Although this was not a mission-critical issue, the loss of the fender caused Cernan and Schmitt to be covered with dust thrown up when the rover was in motion. The crew used duct tape to fix the problem by attaching a map to the damaged fender, but the dust picked up on the tape surface prevented it from sticking properly and the first fix was short lived. After an overnight rethink by the flight controllers, a better method of applying the tape resulted in a satisfactory fix that lasted for the length of the exploration. The crew then deployed the Apollo Lunar Surface Experiments Package (ALSEP) west of the immediate landing site. After completing this, Cernan and Schmitt departed on the first geologic traverse of the mission towards Steno crater to the south of the landing site, during which they gathered of samples; took seven gravimeter measurements; and deployed two explosive packages, which were later detonated remotely to test geophones that had been placed by the astronauts and seismometers that had been placed on previous Apollo missions. The EVA ended after seven hours and twelve minutes.

On December 12, at 6:28 pm EST, Cernan and Schmitt began their second lunar excursion. One of the first tasks of the EVA was repairing the right-rear fender on the LRV, the rearward extension of which had been broken off the previous day. The pair did this by taping together four cronopaque maps with duct tape and clamping the replacement fender extension to the fender, thus providing a means of preventing dust from raining down upon them while in motion. During this EVA, the pair sampled several different types of geologic deposits found in the valley, including the avalanche at the base of the South Massif, orange-colored soil at Shorty crater, and ejecta of Camelot crater. The crew completed this moonwalk after seven hours and thirty-seven minutes. They collected of samples, deployed three more explosive packages and took seven gravimeter measurements.

The third moonwalk, the last of the Apollo program, began at 5:26 pm EST on December 13. During this excursion, the crew collected of lunar samples and took nine gravimeter measurements. They drove the rover to the north and east of the landing site and explored the base of the North Massif, the Sculptured Hills, and the unusual crater Van Serg. Before ending the moonwalk, the crew collected a rock, a breccia, and dedicated it to several different nations which were represented in Mission Control Center in Houston, Texas, at the time. A plaque located on the LM, commemorating the achievements made during the Apollo program, was then unveiled. Before reentering the LM for the final time, Gene Cernan expressed his thoughts:

Cernan then followed Schmitt into the LM after spending approximately seven hours and 15 minutes outside during the mission's final lunar excursion.

Eugene Cernan and Harrison Schmitt successfully lifted off from the lunar surface in the ascent stage of the LM on December 14, at 5:55 pm EST. After a successful rendezvous and docking with Ron Evans in the CSM in orbit, the crew transferred equipment and lunar samples between the LM and the CSM for return to Earth. Following this, the LM ascent stage was sealed off and jettisoned at 1:31 am on December 15. The ascent stage was then deliberately crashed into the Moon in a collision recorded by seismometers deployed on Apollo 17 and previous Apollo expeditions.

On December 17, during the trip back to Earth, at 3:27 pm EST, Ron Evans successfully conducted a one-hour and seven minute spacewalk to retrieve exposed film from the instrument bay on the exterior of the CSM.

On December 19, the crew jettisoned the no-longer-needed SM, leaving only the CM for return to Earth. The Apollo 17 spacecraft reentered Earth's atmosphere and landed safely in the Pacific Ocean at 2:25 pm, from the recovery ship, . Cernan, Evans, and Schmitt were then retrieved by a recovery helicopter and were safely aboard the recovery ship 52 minutes after landing.

The Command Module "America" is currently on display at Space Center Houston at the Lyndon B. Johnson Space Center in Houston, Texas.

The ascent stage of Lunar Module "Challenger" impacted the Moon December 15, 1972 at 06:50:20.8 UT (1:50 am EST), at . The descent stage remains on the Moon at the landing site, .

In 2009 and again in 2011, the Lunar Reconnaissance Orbiter photographed the landing site from increasingly low orbits.

The German space company PTScientists is planning to land two lunar rovers near the landing site in 2020 or later.

Portions of the Apollo 17 mission are dramatized in the 1998 HBO miniseries "From the Earth to the Moon" episode entitled "Le Voyage dans la Lune."

The prologue to the 1999 novel "Back to the Moon", by Homer Hickam, begins with a dramatized depiction of the end of the second Apollo 17 EVA. The orange soil then becomes the major driver of the plot of the rest of the story.

The 2005 novel "Tyrannosaur Canyon" by Douglas Preston opens with a depiction of the Apollo 17 moonwalks using quotes taken from the official mission transcript.

Additionally, there have been fictional astronauts in film, literature and television who have been described as "the last man to walk on the Moon", implying they were crew members on Apollo 17. One such character was Steve Austin in the television series "The Six Million Dollar Man". In the 1972 novel "Cyborg", upon which the series was based, Austin remembers watching the Earth "fall away during Apollo XVII." In the 1998 film "Deep Impact" fictional astronaut Spurgeon "Fish" Tanner, portrayed by Robert Duvall, was described at a Presidential press conference as the "last man to walk on the Moon" by the President of the United States, portrayed by Morgan Freeman.

In the Anime "Aldnoah.Zero", the Apollo 17 mission locates an ancient transporter gate leading to Mars left by an unknown, extinct alien race. This discovery is the divergence point for the story's alternative history.

The song "Contact" from Daft Punk includes audio from the Apollo 17 mission, courtesy of NASA and Captain Eugene Cernan.

The song "Tomorrow" by Public Service Broadcasting also includes audio of Commander Eugene A. Cernan and Lunar Module Pilot Harrison Schmitt from the mission.





</doc>
<doc id="1973" url="https://en.wikipedia.org/wiki?curid=1973" title="American Revolution">
American Revolution

The American Revolution was a colonial revolt which occurred between 1765 and 1783. The American Patriots in the Thirteen Colonies defeated the British in the American Revolutionary War (1775–1783) with the assistance of France, winning independence from Great Britain and establishing the United States of America.

The American colonials proclaimed "no taxation without representation" starting with the Stamp Act Congress in 1765. They rejected the authority of the British Parliament to tax them because they had no representatives in that governing body. Protests steadily escalated to the Boston Massacre in 1770 and the burning of the "Gaspee" in Rhode Island in 1772, followed by the Boston Tea Party in December 1773. The British responded by closing Boston Harbor and enacting a series of punitive laws which effectively rescinded Massachusetts Bay Colony's rights of self-government. The other colonies rallied behind Massachusetts, and a group of American Patriot leaders set up their own government in late 1774 at the Continental Congress to coordinate their resistance of Britain; other colonists retained their allegiance to the Crown and were known as "Loyalists" or "Tories".

Tensions erupted into battle between Patriot militia and British regulars when King George's redcoats attempted to destroy Colonial military supplies at Lexington and Concord on April 19, 1775. The conflict then developed into war, during which the Patriots (and later their French allies) fought the British and Loyalists in what became known as the American Revolutionary War (1775–1783). Each of the thirteen colonies formed a Provincial Congress which assumed power from the former colonial governments, suppressed Loyalism, and recruited a Continental Army led by General George Washington. The Continental Congress declared King George a tyrant who trampled the colonists' rights as Englishmen, and they declared the colonies free and independent states on July 2, 1776. The Patriot leadership professed the political philosophies of liberalism and republicanism to reject monarchy and aristocracy, and they proclaimed that all men are created equal.

The Continental Army forced the redcoats out of Boston in March 1776, but that summer the British captured New York City and its strategic harbor, which they held for the duration of the war. The Royal Navy blockaded ports and captured other cities for brief periods, but they failed to destroy Washington's forces. The Patriots attempted to invade Canada during the winter of 1775–76 without success, but they captured a British army at the Battle of Saratoga in October 1777. France entered the war as an ally of the United States with a large army and navy. The war then moved to the Southern states, where Charles Cornwallis captured an army at Charleston, South Carolina in early 1780, but he failed to enlist enough volunteers from Loyalist civilians to take effective control of the territory. Finally, a combined American and French force captured a second British army at Yorktown in the fall of 1781, effectively ending the war. The Treaty of Paris was signed September 3, 1783, formally ending the conflict and confirming the new nation's complete separation from the British Empire. The United States took possession of nearly all the territory east of the Mississippi River and south of the Great Lakes, with the British retaining control of Canada, and Spain taking Florida.

Among the significant results of the revolution was the creation of the United States Constitution, establishing a relatively strong federal national government which included an executive, a national judiciary, and a bicameral Congress representing states in the Senate and the population in the House of Representatives. The Revolution also resulted in the migration of around 60,000 Loyalists to other British territories, especially British North America (Canada).

As early as 1651, the English government had sought to regulate trade in the American colonies. On October 9, the Navigation Acts were passed pursuant to a mercantilist policy intended to ensure that trade enriched only Great Britain, and barring trade with foreign nations. Some argue that the economic impact was minimal on the colonists, but the political friction which the acts triggered was more serious, as the merchants most directly affected were most politically active. King Philip's War ended in 1678, and much of it was fought without significant assistance from England. This contributed to the development of a unique identity, separate from that of the British people.

In the 1680s, King Charles II determined to bring the New England colonies under a more centralized administration in order to regulate trade more effectively. His efforts were fiercely opposed by the colonists, resulting in the abrogation of their colonial charter by the Crown. Charles' successor James II finalized these efforts in 1686, establishing the Dominion of New England. Dominion rule triggered bitter resentment throughout New England; the enforcement of the unpopular Navigation Acts and the curtailing of local democracy angered the colonists. New Englanders were encouraged, however, by a change of government in England that saw James II effectively abdicate, and a populist uprising overthrew Dominion rule on April 18, 1689. Colonial governments reasserted their control in the wake of the revolt, and successive governments made no more attempts to restore the Dominion.

Subsequent English governments continued in their efforts to tax certain goods, passing acts regulating the trade of wool, hats, and molasses. The Molasses Act of 1733 in particular was egregious to the colonists, as a significant part of colonial trade relied on the product. The taxes severely damaged the New England economy, and the taxes were rarely paid, resulting in a surge of smuggling, bribery, and intimidation of customs officials. Colonial wars fought in America were often the source of considerable tension. The British captured the fortress of Louisbourg during the War of the Austrian Succession, but then ceded it back to France in 1748. New England colonists resented their losses of lives, as well as the effort and expenditure involved in subduing the fortress, only to have it returned to their erstwhile enemy.

The Royal Proclamation of 1763 may also have played a role in the separation of the Thirteen Colonies from England, as colonists wanted to continue migrating west to lands awarded by the Crown for their wartime service. The Proclamation, however, cut them off. The lands west of Quebec and west of a line running along the crest of the Allegheny Mountains became Indian territory, barred to settlement for two years.

The colonists protested, and the boundary line was adjusted in a series of treaties with the Indians. In 1768, Indians agreed to the Treaty of Fort Stanwix and the Treaty of Hard Labour, followed in 1770 by the Treaty of Lochaber. The treaties opened most of Kentucky and West Virginia to colonial settlement. The new map was drawn up at the Treaty of Fort Stanwix in 1768 which moved the line much farther to the west, from the green line to the red line on the map at right.

In 1764, Parliament passed the Currency Act to restrain the use of paper money, fearing that otherwise the colonists might evade debt payments. Parliament also passed the Sugar Act, imposing customs duties on a number of articles. That same year, Prime Minister George Grenville proposed direct taxes on the colonies to raise revenue, but he delayed action to see whether the colonies would propose some way to raise the revenue themselves. Parliament finally passed the Stamp Act in March 1765 which imposed direct taxes on the colonies for the first time. All official documents, newspapers, almanacs, and pamphlets were required to have the stamps—even decks of playing cards.

The colonists did not object that the taxes were high; they were actually low. They objected to the fact that they had no representation in the Parliament, and thus no voice concerning legislation that affected them. Benjamin Franklin testified in Parliament in 1766 that Americans already contributed heavily to the defense of the Empire. He said that local governments had raised, outfitted, and paid 25,000 soldiers to fight France—as many as Britain itself sent—and spent many millions from American treasuries doing so in the French and Indian War alone. London had to deal with 1,500 politically well-connected British Army soldiers. The decision was to keep them on active duty with full pay, but they had to be stationed somewhere. Stationing a standing army in Great Britain during peacetime was politically unacceptable, so the decision was made to station them in America and have the Americans pay them. The soldiers had no military mission; they were not there to defend the colonies because there was no threat to the colonies.

The Sons of Liberty were formed in 1765. They used public demonstrations, boycott, violence, and threats of violence to ensure that the British tax laws were unenforceable. In Boston, the Sons of Liberty burned the records of the vice admiralty court and looted the home of chief justice Thomas Hutchinson. Several legislatures called for united action, and nine colonies sent delegates to the Stamp Act Congress in New York City in October 1765. Moderates led by John Dickinson drew up a "Declaration of Rights and Grievances" stating that taxes passed without representation violated their rights as Englishmen. Colonists emphasized their determination by boycotting imports of British merchandise.

The Parliament at Westminster saw itself as the supreme lawmaking authority throughout all British possessions and thus entitled to levy any tax without colonial approval. They argued that the colonies were legally British corporations that were completely subordinate to the British parliament and pointed to numerous instances where Parliament had made laws binding on the colonies in the past. They did not see anything in the unwritten British constitution that made taxes special and noted that they had taxed American trade for decades. Parliament insisted that the colonies effectively enjoyed a "virtual representation" as most British people did, as only a small minority of the British population elected representatives to Parliament. Americans such as James Otis maintained that the Americans were not in fact virtually represented.

In London, the Rockingham government came to power (July 1765) and Parliament debated whether to repeal the stamp tax or to send an army to enforce it. Benjamin Franklin made the case for repeal, explaining that the colonies had spent heavily in manpower, money, and blood in defense of the empire in a series of wars against the French and Indians, and that further taxes to pay for those wars were unjust and might bring about a rebellion. Parliament agreed and repealed the tax (February 21, 1766), but insisted in the Declaratory Act of March 1766 that they retained full power to make laws for the colonies "in all cases whatsoever". The repeal nonetheless caused widespread celebrations in the colonies.

In 1767, the Parliament passed the Townshend Acts which placed duties on a number of essential goods, including paper, glass, and tea, and established a Board of Customs in Boston to more rigorously execute trade regulations. The new taxes were enacted on the belief that Americans only objected to internal taxes and not to external taxes such as custom duties. The Americans, however, argued against the constitutionality of the act because its purpose was to raise revenue and not regulate trade. Colonists responded by organizing new boycotts of British goods. These boycotts were less effective, however, as the Townshend goods were widely used.

In February 1768, the Assembly of Massachusetts Bay issued a circular letter to the other colonies urging them to coordinate resistance. The governor dissolved the assembly when it refused to rescind the letter. Meanwhile, a riot broke out in Boston in June 1768 over the seizure of the sloop "Liberty", owned by John Hancock, for alleged smuggling. Customs officials were forced to flee, prompting the British to deploy troops to Boston. A Boston town meeting declared that no obedience was due to parliamentary laws and called for the convening of a convention. A convention assembled but only issued a mild protest before dissolving itself. In January 1769, Parliament responded to the unrest by reactivating the Treason Act 1543 which called for subjects outside the realm to face trials for treason in England. The governor of Massachusetts was instructed to collect evidence of said treason, and the threat caused widespread outrage, though it was not carried out.

On March 5, 1770, a large crowd gathered around a group of British soldiers. The crowd grew threatening, throwing snowballs, rocks, and debris at them. One soldier was clubbed and fell. There was no order to fire, but the soldiers fired into the crowd anyway. They hit 11 people; three civilians died at the scene of the shooting, and two died after the incident. The event quickly came to be called the Boston Massacre. The soldiers were tried and acquitted (defended by John Adams), but the widespread descriptions soon began to turn colonial sentiment against the British. This, in turn, began a downward spiral in the relationship between Britain and the Province of Massachusetts.

A new ministry under Lord North came to power in 1770, and Parliament withdrew all taxes except the tax on tea, giving up its efforts to raise revenue while maintaining the right to tax. This temporarily resolved the crisis, and the boycott of British goods largely ceased, with only the more radical patriots such as Samuel Adams continuing to agitate.

In June 1772, American patriots, including John Brown, burned a British warship that had been vigorously enforcing unpopular trade regulations in what became known as the "Gaspee" Affair. The affair was investigated for possible treason, but no action was taken.

In 1772, it became known that the Crown intended to pay fixed salaries to the governors and judges in Massachusetts, which had been paid by local authorities. This would reduce the influence of colonial representatives over their government. Samuel Adams in Boston set about creating new Committees of Correspondence, which linked Patriots in all 13 colonies and eventually provided the framework for a rebel government. Virginia, the largest colony, set up its Committee of Correspondence in early 1773, on which Patrick Henry and Thomas Jefferson served.

A total of about 7000 to 8000 Patriots served on "Committees of Correspondence" at the colonial and local levels, comprising most of the leadership in their communities. Loyalists were excluded. The committees became the leaders of the American resistance to British actions, and largely determined the war effort at the state and local level. When the First Continental Congress decided to boycott British products, the colonial and local Committees took charge, examining merchant records and publishing the names of merchants who attempted to defy the boycott by importing British goods.

In 1773, private letters were published in which Massachusetts Governor Thomas Hutchinson claimed that the colonists could not enjoy all English liberties, and Lieutenant Governor Andrew Oliver called for the direct payment of colonial officials. The letters' contents were used as evidence of a systematic plot against American rights, and discredited Hutchinson in the eyes of the people; the Assembly petitioned for his recall. Benjamin Franklin, postmaster general for the colonies, acknowledged that he leaked the letters, which led to him being berated by British officials and fired from his job.

Meanwhile, Parliament passed the Tea Act to lower the price of taxed tea exported to the colonies in order to help the East India Company undersell smuggled Dutch tea. Special consignees were appointed to sell the tea in order to bypass colonial merchants. The act was opposed by those who resisted the taxes and also by smugglers who stood to lose business. In most instances, the consignees were forced to resign and the tea was turned back, but Massachusetts governor Hutchinson refused to allow Boston merchants to give in to pressure. A town meeting in Boston determined that the tea would not be landed, and ignored a demand from the governor to disperse. On December 16, 1773, a group of men, led by Samuel Adams and dressed to evoke the appearance of American Indians, boarded the ships of the British East India Company and dumped £10,000 worth of tea from their holds (approximately £636,000 in 2008) into Boston Harbor. Decades later, this event became known as the Boston Tea Party and remains a significant part of American patriotic lore.

The British government responded by passing several Acts which came to be known as the Intolerable Acts, which further darkened colonial opinion towards the British. They consisted of four laws enacted by the British parliament. The first was the Massachusetts Government Act which altered the Massachusetts charter and restricted town meetings. The second act was the Administration of Justice Act which ordered that all British soldiers to be tried were to be arraigned in Britain, not in the colonies. The third Act was the Boston Port Act, which closed the port of Boston until the British had been compensated for the tea lost in the Boston Tea Party. The fourth Act was the Quartering Act of 1774, which allowed royal governors to house British troops in the homes of citizens without requiring permission of the owner.

In response, Massachusetts patriots issued the Suffolk Resolves and formed an alternative shadow government known as the "Provincial Congress" which began training militia outside British-occupied Boston. In September 1774, the First Continental Congress convened, consisting of representatives from each of the colonies, to serve as a vehicle for deliberation and collective action. During secret debates, conservative Joseph Galloway proposed the creation of a colonial Parliament that would be able to approve or disapprove of acts of the British Parliament, but his idea was not accepted. The Congress instead endorsed the proposal of John Adams that Americans would obey Parliament voluntarily but would resist all taxes in disguise. Congress called for a boycott beginning on 1 December 1774 of all British goods; it was enforced by new committees authorized by the Congress.

Massachusetts was declared in a state of rebellion in February 1775 and the British garrison received orders to disarm the rebels and arrest their leaders, leading to the Battles of Lexington and Concord on 19 April 1775. The Patriots laid siege to Boston, expelled royal officials from all the colonies, and took control through the establishment of Provincial Congresses. The Battle of Bunker Hill followed on June 17, 1775. It was a British victory—but at a great cost: about 1,000 British casualties from a garrison of about 6,000, as compared to 500 American casualties from a much larger force. The Second Continental Congress was divided on the best course of action, but eventually produced the Olive Branch Petition, in which they attempted to come to an accord with King George. The king, however, issued a Proclamation of Rebellion which stated that the states were "in rebellion" and the members of Congress were traitors.

The war that arose was in some ways a classic insurgency. As Benjamin Franklin wrote to Joseph Priestley in October 1775: "Britain, at the expense of three millions, has killed 150 Yankees this campaign, which is £20,000 a head... During the same time, 60,000 children have been born in America. From these data his mathematical head will easily calculate the time and expense necessary to kill us all.".

In the winter of 1775, the Americans invaded Canada under generals Benedict Arnold and Richard Montgomery. The attack was a failure; many Americans who weren't killed were either captured or died of smallpox.

In March 1776, the Continental Army forced the British to evacuate Boston, with George Washington as the commander of the new army. The revolutionaries were now in full control of all 13 colonies and were ready to declare independence. There still were many Loyalists, but they were no longer in control anywhere by July 1776, and all of the Royal officials had fled.

Following the Battle of Bunker Hill in June 1775, the Patriots had control of Massachusetts outside the Boston city limits, and the Loyalists suddenly found themselves on the defensive with no protection from the British army. In all 13 colonies, Patriots had overthrown their existing governments, closing courts and driving away British officials. They had elected conventions and "legislatures" that existed outside any legal framework; new constitutions were drawn up in each state to supersede royal charters. They declared that they were states, not colonies.

On January 5, 1776, New Hampshire ratified the first state constitution. In May 1776, Congress voted to suppress all forms of crown authority, to be replaced by locally created authority. Virginia, South Carolina, and New Jersey created their constitutions before July 4. Rhode Island and Connecticut simply took their existing royal charters and deleted all references to the crown. The new states were all committed to republicanism, with no inherited offices. They decided what form of government to create, and also how to select those who would craft the constitutions and how the resulting document would be ratified. On 26 May 1776, John Adams wrote James Sullivan from Philadelphia:

The resulting constitutions in states such as Maryland, Virginia, Delaware, New York, and Massachusetts featured:


In Pennsylvania, New Jersey, and New Hampshire, the resulting constitutions embodied:


The radical provisions of Pennsylvania's constitution lasted only 14 years. In 1790, conservatives gained power in the state legislature, called a new constitutional convention, and rewrote the constitution. The new constitution substantially reduced universal male suffrage, gave the governor veto power and patronage appointment authority, and added an upper house with substantial wealth qualifications to the unicameral legislature. Thomas Paine called it a constitution unworthy of America.

In April 1776, the North Carolina Provincial Congress issued the Halifax Resolves explicitly authorizing its delegates to vote for independence. By June, nine Provincial Congresses were ready for independence; one by one, the last four fell into line: Pennsylvania, Delaware, Maryland, and New York. Richard Henry Lee was instructed by the Virginia legislature to propose independence, and he did so on June 7, 1776. On June 11, a committee was created to draft a document explaining the justifications for separation from Britain. After securing enough votes for passage, independence was voted for on July 2.

The Declaration of Independence was drafted largely by Thomas Jefferson and presented by the committee; it was unanimously adopted by the entire Congress on July 4, and each of the colonies became independent and autonomous. The next step was to form a union to facilitate international relations and alliances.

The Second Continental Congress approved the "Articles of Confederation" for ratification by the states on November 15, 1777; the Congress immediately began operating under the Articles' terms, providing a structure of shared sovereignty during prosecution of the war and facilitating international relations and alliances with France and Spain. The articles were ratified on March 1, 1781. At that point, the Continental Congress was dissolved and a new government of the United States in Congress Assembled took its place on the following day, with Samuel Huntington as presiding officer.

According to British historian Jeremy Black, the British had significant advantages, including a highly trained army, the world's largest navy, and an efficient system of public finance that could easily fund the war. However, they seriously misunderstood the depth of support for the American Patriot position and ignored the advice of General Gage, misinterpreting the situation as merely a large-scale riot. The British government believed that they could overawe the Americans by sending a large military and naval force, forcing them to be loyal again:

Washington forced the British out of Boston in the spring of 1776, and neither the British nor the Loyalists controlled any significant areas. The British, however, were massing forces at their naval base at Halifax, Nova Scotia. They returned in force in July 1776, landing in New York and defeating Washington's Continental Army in August at the Battle of Brooklyn. Following that victory, they requested a meeting with representatives from Congress to negotiate an end to hostilities.

A delegation including John Adams and Benjamin Franklin met British admiral Richard Howe on Staten Island in New York Harbor on September 11 in what became known as the Staten Island Peace Conference. Howe demanded that the Americans retract the Declaration of Independence, which they refused to do, and negotiations ended. The British then seized New York City and nearly captured Washington's army. They made New York their main political and military base of operations, holding it until November 1783. The city became the destination for Loyalist refugees and a focal point of Washington's intelligence network.

The British also took New Jersey, pushing the Continental Army into Pennsylvania. Washington crossed the Delaware River back into New Jersey in a surprise attack in late December 1776 and defeated the Hessian and British armies at Trenton and Princeton, thereby regaining control of most of New Jersey. The victories gave an important boost to Patriots at a time when morale was flagging, and they have become iconic events of the war.

In 1777, the British sent Burgoyne's invasion force from Canada south to New York to seal off New England. Their aim was to isolate New England, which the British perceived as the primary source of agitation. Rather than move north to support Burgoyne, the British army in New York City went to Philadelphia in a major case of mis-coordination, capturing it from Washington. The invasion army under Burgoyne was much too slow and became trapped in northern New York state. It surrendered after the Battles of Saratoga in October 1777. From early October 1777 until November 15, a siege distracted British troops at Fort Mifflin, Philadelphia, Pennsylvania and allowed Washington time to preserve the Continental Army by safely leading his troops to harsh winter quarters at Valley Forge.

In August 1775, George III declared Americans to be traitors to the Crown if they took up arms against royal authority. There were thousands of British and Hessian soldiers in American hands following their surrender at the Battles of Saratoga in October 1777. Lord Germain took a hard line, but the British generals on American soil never held treason trials and treated captured American soldiers as prisoners of war. The dilemma was that tens of thousands of Loyalists were under American control and American retaliation would have been easy. The British built much of their strategy around using these Loyalists. The British maltreated the prisoners whom they held, resulting in more deaths to American prisoners of war than from combat operations. At the end of the war, both sides released their surviving prisoners.

The capture of a British army at Saratoga encouraged the French to formally enter the war in support of Congress, and Benjamin Franklin negotiated a permanent military alliance in early 1778; France thus became the first foreign nation to officially recognize the Declaration of Independence. On February 6, 1778, the United States and France signed the Treaty of Amity and Commerce and the Treaty of Alliance. William Pitt spoke out in Parliament urging Britain to make peace in America and to unite with America against France, while British politicians who had sympathized with colonial grievances now turned against the Americans for allying with Britain's rival and enemy.

The Spanish and the Dutch became allies of the French in 1779 and 1780 respectively, forcing the British to fight a global war without major allies and requiring it to slip through a combined blockade of the Atlantic. Britain began to view the American war for independence as merely one front in a wider war, and the British chose to withdraw troops from America to reinforce the sugar-producing Caribbean colonies, which were more lucrative to British investors. British commander Sir Henry Clinton evacuated Philadelphia and returned to New York City. General Washington intercepted him in the Battle of Monmouth Court House, the last major battle fought in the north. After an inconclusive engagement, the British retreated to New York City. The northern war subsequently became a stalemate, as the focus of attention shifted to the smaller southern theater.
The British strategy in America now concentrated on a campaign in the southern states. With fewer regular troops at their disposal, the British commanders saw the "southern strategy" as a more viable plan, as they perceived the south as strongly Loyalist with a large population of recent immigrants and large numbers of slaves who might be captured or run away to join the British.

Beginning in late December 1778, they captured Savannah and controlled the Georgia coastline. In 1780, they launched a fresh invasion and took Charleston, as well. A significant victory at the Battle of Camden meant that royal forces soon controlled most of Georgia and South Carolina. The British set up a network of forts inland, hoping that the Loyalists would rally to the flag. Not enough Loyalists turned out, however, and the British had to fight their way north into North Carolina and Virginia with a severely weakened army. Behind them, much of the territory that they had already captured dissolved into a chaotic guerrilla war, fought predominantly between bands of Loyalists and American militia, which negated many of the gains that the British had previously made.

The British army under Cornwallis marched to Yorktown, Virginia where they expected to be rescued by a British fleet. The fleet did arrive, but so did a larger French fleet. The French were victorious in the Battle of the Chesapeake, and the British fleet returned to New York for reinforcements, leaving Cornwallis trapped. In October 1781, the British surrendered their second invading army of the war, under a siege by the combined French and Continental armies commanded by Washington.

Historians continue to debate whether the odds were long or short for American victory. John E. Ferling says that the odds were so long that the American victory was "almost a miracle". On the other hand, Joseph Ellis says that the odds favored the Americans, and asks whether there ever was any realistic chance for the British to win. He argues that this opportunity came only once, in the summer of 1776, and the British failed that test. Admiral Howe and his brother General Howe "missed several opportunities to destroy the Continental Army…. Chance, luck, and even the vagaries of the weather played crucial roles." Ellis's point is that the strategic and tactical decisions of the Howes were fatally flawed because they underestimated the challenges posed by the Patriots. Ellis concludes that, once the Howe brothers failed, the opportunity "would never come again" for a British victory.

Support for the conflict had never been strong in Britain, where many sympathized with the Americans, but now it reached a new low. King George personally wanted to fight on, but his supporters lost control of Parliament and they launched no further offensives in America. War erupted between America and Britain three decades later with the War of 1812, which firmly established the permanence of the United States and its complete autonomy.

Washington did not know whether the British might reopen hostilities after Yorktown. They still had 26,000 troops occupying New York City, Charleston, and Savannah, together with a powerful fleet. The French army and navy departed, so the Americans were on their own in 1782–83. The treasury was empty, and the unpaid soldiers were growing restive, almost to the point of mutiny or possible "coup d'état". Washington personally dispelled the unrest among officers of the Newburgh Conspiracy in 1783, and Congress subsequently created the promise of a five years bonus for all officers.

During negotiations in Paris, the American delegation discovered that France supported American independence but no territorial gains, hoping to confine the new nation to the area east of the Appalachian Mountains. The Americans opened direct secret negotiations with London, cutting out the French. British Prime Minister Lord Shelburne was in full charge of the British negotiations, and he saw a chance to make the United States a valuable economic partner. The US obtained all the land east of the Mississippi River, south of Canada, and north of Florida. It gained fishing rights off Canadian coasts, and agreed to allow British merchants and Loyalists to recover their property. Prime Minister Shelburne foresaw highly profitable two-way trade between Britain and the rapidly growing United States, which did come to pass. The blockade was lifted and all British interference had been driven out, and American merchants were free to trade with any nation anywhere in the world.

The British largely abandoned their American Indian allies, who were not a party to this treaty and did not recognize it until they were defeated militarily by the United States. However, the British did sell them munitions and maintain forts in American territory until the Jay Treaty of 1795.

Losing the war and the Thirteen Colonies was a shock to Britain. The war revealed the limitations of Britain's fiscal-military state when they discovered that they suddenly faced powerful enemies with no allies, and they were dependent on extended and vulnerable transatlantic lines of communication. The defeat heightened dissension and escalated political antagonism to the King's ministers. Inside Parliament, the primary concern changed from fears of an over-mighty monarch to the issues of representation, parliamentary reform, and government retrenchment. Reformers sought to destroy what they saw as widespread institutional corruption, and the result was a crisis from 1776 to 1783. The peace in 1783 left France financially prostrate, while the British economy boomed thanks to the return of American business. The crisis ended after 1784 thanks to the King's shrewdness in outwitting Charles James Fox (the leader of the Fox-North Coalition), and renewed confidence in the system engendered by the leadership of Prime Minister William Pitt. Some historians suggest that loss of the American colonies enabled Britain to deal with the French Revolution with more unity and better organization than would otherwise have been the case. Britain turned towards Asia, the Pacific, and later Africa with subsequent exploration leading to the rise of the Second British Empire.

Britain's war against the Americans, the French, and the Spanish cost about £100 million, and the Treasury borrowed 40-percent of the money that it needed. Heavy spending brought France to the verge of bankruptcy and revolution, while the British had relatively little difficulty financing their war, keeping their suppliers and soldiers paid, and hiring tens of thousands of German soldiers. Britain had a sophisticated financial system based on the wealth of thousands of landowners who supported the government, together with banks and financiers in London. The British tax system collected about 12 percent of the GDP in taxes during the 1770s.
In sharp contrast, Congress and the American states had no end of difficulty financing the war. In 1775, there was at most 12 million dollars in gold in the colonies, not nearly enough to cover current transactions, let alone finance a major war. The British made the situation much worse by imposing a tight blockade on every American port, which cut off almost all imports and exports. One partial solution was to rely on volunteer support from militiamen and donations from patriotic citizens. Another was to delay actual payments, pay soldiers and suppliers in depreciated currency, and promise that it would be made good after the war. Indeed, the soldiers and officers were given land grants in 1783 to cover the wages that they had earned but had not been paid during the war. The national government did not have a strong leader in financial matters until 1781, when Robert Morris was named Superintendent of Finance of the United States. Morris used a French loan in 1782 to set up the private Bank of North America to finance the war. He reduced the civil list, saved money by using competitive bidding for contracts, tightened accounting procedures, and demanded the national government's full share of money and supplies from the individual states.

Congress used four main methods to cover the cost of the war, which cost about 66 million dollars in specie (gold and silver). Congress made issues of paper money in 1775–1780 and in 1780–81. The first issue amounted to 242 million dollars. This paper money would supposedly be redeemed for state taxes, but the holders were eventually paid off in 1791 at the rate of one cent on the dollar. By 1780, the paper money was "not worth a Continental", as people said. The skyrocketing inflation was a hardship on the few people who had fixed incomes, but 90 percent of the people were farmers and were not directly affected by it. Debtors benefited by paying off their debts with depreciated paper. The greatest burden was borne by the soldiers of the Continental Army whose wages were usually in arrears and declined in value every month, weakening their morale and adding to the hardships of their families.

Beginning in 1777, Congress repeatedly asked the states to provide money, but the states had no system of taxation and were of little help. By 1780, Congress was making requisitions for specific supplies of corn, beef, pork, and other necessities, an inefficient system which barely kept the army alive. Starting in 1776, the Congress sought to raise money by loans from wealthy individuals, promising to redeem the bonds after the war. The bonds were in fact redeemed in 1791 at face value, but the scheme raised little money because Americans had little specie, and many of the rich merchants were supporters of the Crown. The French secretly supplied the Americans with money, gunpowder, and munitions in order to weaken Great Britain; the subsidies continued when France entered the war in 1778, and the French government and Paris bankers lent large sums to the American war effort. These loans were repaid in full in the 1790s.

The war ended in 1783 and was followed by a period of prosperity. The national government was still operating under the Articles of Confederation and was able to settle the issue of the western territories, which the states ceded to Congress. American settlers moved rapidly into those areas, with Vermont, Kentucky, and Tennessee becoming states in the 1790s.

However, the national government had no money either to pay the war debts owed to European nations and the private banks, or to pay Americans who had been given millions of dollars of promissory notes for supplies during the war. Nationalists led by Washington, Alexander Hamilton, and other veterans feared that the new nation was too fragile to withstand an international war, or even internal revolts such as the Shays' Rebellion of 1786 in Massachusetts. They convinced Congress to call the Philadelphia Convention in 1787 and named their party the Federalist party. The Convention adopted a new Constitution which provided for a much stronger federal government, including an effective executive in a check-and-balance system with the judiciary and legislature. The Constitution was ratified in 1788, after a fierce debate in the states over the nature of the proposed new government. The new government under President George Washington took office in New York in March 1789. James Madison spearheaded Congressional amendments to the Constitution as assurances to those who were cautious about federal power, guaranteeing many of the inalienable rights that formed a foundation for the revolution, and Rhode Island was the final state to ratify the Constitution in 1791.

The national debt fell into three categories after the American Revolution. The first was the $12 million owed to foreigners, mostly money borrowed from France. There was general agreement to pay the foreign debts at full value. The national government owed $40 million and state governments owed $25 million to Americans who had sold food, horses, and supplies to the Patriot forces. There were also other debts which consisted of promissory notes issued during the war to soldiers, merchants, and farmers who accepted these payments on the premise that the new Constitution would create a government that would pay these debts eventually.

The war expenses of the individual states added up to $114 million, compared to $37 million by the central government. In 1790, Congress combined the remaining state debts with the foreign and domestic debts into one national debt totaling $80 million at the recommendation of first Secretary of the Treasury Alexander Hamilton. Everyone received face value for wartime certificates, so that the national honor would be sustained and the national credit established.

The population of the Thirteen States was not homogeneous in political views and attitudes. Loyalties and allegiances varied widely within regions and communities and even within families, and sometimes shifted during the course of the Revolution.

The American Enlightenment was a critical precursor of the American Revolution. Chief among the ideas of the American Enlightenment were the concepts of Natural Law, Natural Rights, Consent of the Governed, Individualism, Property Rights, Self-Ownership, Self-Determination, liberalism, republicanism, and defense against corruption. A growing number of American colonists embraced these views and fostered an intellectual environment which led to a new sense of political and social identity.

John Locke's (1632–1704) ideas on liberty influenced the political thinking behind the revolution, especially through his indirect influence on English writers such as John Trenchard, Thomas Gordon, and Benjamin Hoadly, whose political ideas in turn had a strong influence on the American Patriots. Locke is often referred to as "the philosopher of the American Revolution" due to his work in the Social Contract and Natural Rights theories that underpinned the Revolution's political ideology. Locke's Two Treatises of Government published in 1689 was especially influential. He argued that all humans were created equally free, and governments therefore needed the "consent of the governed". In late eighteenth-century America, belief was still widespread in "equality by creation" and "rights by creation".

The theory of the "social contract" influenced the belief among many of the Founders that the right of the people to overthrow their leaders was one of the "natural rights" of man, should those leaders betray the historic rights of Englishmen. The Americans heavily used Montesquieu's analysis of the wisdom of the "balanced" British Constitution (mixed government) in writing the state and national constitutions.

The American ideology called "republicanism" was inspired by the Whig party in Great Britain which openly criticized the corruption within the British government. Americans were increasingly embracing republican values, seeing Britain as corrupt and hostile to American interests. The colonists associated political corruption with luxury and inherited aristocracy, which they condemned.

The Founding Fathers were strong advocates of republican values, particularly Samuel Adams, Patrick Henry, John Adams, Benjamin Franklin, Thomas Jefferson, Thomas Paine, George Washington, James Madison, and Alexander Hamilton, which required men to put civic duty ahead of their personal desires. Men had a civic duty to be prepared and willing to fight for the rights and liberties of their countrymen. John Adams wrote to Mercy Otis Warren in 1776, agreeing with some classical Greek and Roman thinkers: "Public Virtue cannot exist without private, and public Virtue is the only Foundation of Republics." He continued:
"Republican motherhood" became the ideal for American women, exemplified by Abigail Adams and Mercy Otis Warren; the first duty of the republican woman was to instill republican values in her children and to avoid luxury and ostentation.
Thomas Paine published his pamphlet "Common Sense" in January 1776, after the Revolution had started. It was widely distributed and often read aloud in taverns, contributing significantly to spreading the ideas of republicanism and liberalism together, bolstering enthusiasm for separation from Great Britain and encouraging recruitment for the Continental Army. Paine offered a solution for Americans who were alarmed by the threat of tyranny.

Protestant churches that had separated from the Church of England (called "dissenters") were the "school of democracy", in the words of historian Patricia Bonomi. Before the Revolution, the Southern Colonies and three of the New England Colonies had officially established churches: Congregational in Massachusetts Bay, Connecticut, and New Hampshire, and Anglican in Maryland, Virginia, North-Carolina, South Carolina, and Georgia. New York, New Jersey, Pennsylvania, Delaware, and the Colony of Rhode Island and Providence Plantations had no officially established churches. Church membership statistics from the period are unreliable and scarce, but what little data exists indicates that Anglicans were not in the majority, not even in the colonies where the Church of England was the established church, and they probably did not comprise even 30 percent of the population (with the possible exception of Virginia).
President John Witherspoon of the College of New Jersey (now Princeton University) wrote widely circulated sermons linking the American Revolution to the teachings of the Bible. Throughout the colonies, dissenting Protestant ministers (Congregational, Baptist, and Presbyterian) preached Revolutionary themes in their sermons, while most Church of England clergymen preached loyalty to the king, the titular head of the English state church. Religious motivation for fighting tyranny transcended socioeconomic lines to encompass rich and poor, men and women, frontiersmen and townsmen, farmers and merchants. The Declaration of Independence also referred to the "Laws of Nature and of Nature's God" as justification for the Americans' separation from the British monarchy. Most eighteenth-century Americans believed that the entire universe ("nature") was God's creation and he was "Nature's God". Everything was part of the "universal order of things" which began with God and was directed by his providence. Accordingly, the signers of the Declaration professed their "firm reliance on the Protection of divine Providence", and they appealed to "the Supreme Judge for the rectitude of our intentions". George Washington was firmly convinced that he was an instrument of providence, to the benefit of the American people and of all humanity.

Historian Bernard Bailyn argues that the evangelicalism of the era challenged traditional notions of natural hierarchy by preaching that the Bible teaches that all men are equal, so that the true value of a man lies in his moral behavior, not in his class. Kidd argues that religious disestablishment, belief in God as the source of human rights, and shared convictions about sin, virtue, and divine providence worked together to unite rationalists and evangelicals and thus encouraged a large proportion of Americans to fight for independence from the Empire. Bailyn, on the other hand, denies that religion played such a critical role. Alan Heimert argues that New Light anti-authoritarianism was essential to furthering democracy in colonial American society, and set the stage for a confrontation with British monarchical and aristocratic rule.

John Adams concluded in 1818:

In the mid-20th century, historian Leonard Woods Labaree identified eight characteristics of the Loyalists that made them essentially conservative, opposite to the characteristics of the Patriots. Loyalists tended to feel that resistance to the Crown was morally wrong, while the Patriots thought that morality was on their side. Loyalists were alienated when the Patriots resorted to violence, such as burning houses and tarring and feathering. Loyalists wanted to take a centrist position and resisted the Patriots' demand to declare their opposition to the Crown. Many Loyalists had maintained strong and long-standing relations with Britain, especially merchants in port cities such as New York and Boston. Many Loyalists felt that independence was bound to come eventually, but they were fearful that revolution might lead to anarchy, tyranny, or mob rule. In contrast, the prevailing attitude among Patriots was a desire to seize the initiative. Labaree also wrote that Loyalists were pessimists who lacked the confidence in the future displayed by the Patriots.

Historians in the early 20th century such as J. Franklin Jameson examined the class composition of the Patriot cause, looking for evidence of a class war inside the revolution. More recent historians have largely abandoned that interpretation, emphasizing instead the high level of ideological unity. Both Loyalists and Patriots were a "mixed lot", but ideological demands always came first. The Patriots viewed independence as a means to gain freedom from British oppression and taxation and to reassert their basic rights. Most yeomen farmers, craftsmen, and small merchants joined the Patriot cause to demand more political equality. They were especially successful in Pennsylvania but less so in New England, where John Adams attacked Thomas Paine's "Common Sense" for the "absurd democratical notions" that it proposed.

The war became a personal issue for the king, fueled by his growing belief that British leniency would be taken as weakness by the Americans. He also sincerely believed that he was defending Britain's constitution against usurpers, rather than opposing patriots fighting for their natural rights.

Those who fought for independence were called "Patriots", "Whigs", "Congress-men", or "Americans" during and after the war. They included a full range of social and economic classes but were unanimous regarding the need to defend the rights of Americans and uphold the principles of republicanism in terms of rejecting monarchy and aristocracy, while emphasizing civic virtue on the part of the citizens. Newspapers were strongholds of patriotism (although there were a few Loyalist papers) and printed many pamphlets, announcements, patriotic letters, and pronouncements.

According to historian Robert Calhoon, 40– to 45-percent of the white population in the Thirteen Colonies supported the Patriots' cause, 15– to 20-percent supported the Loyalists, and the remainder were neutral or kept a low profile. Mark Lender analyzes why ordinary people became insurgents against the British, even if they were unfamiliar with the ideological reasons behind the war. He concludes that such people held a sense of rights which the British were violating, rights that stressed local autonomy, fair dealing, and government by consent. They were highly sensitive to the issue of tyranny, which they saw manifested in the British response to the Boston Tea Party. The arrival in Boston of the British Army heightened their sense of violated rights, leading to rage and demands for revenge. They had faith that God was on their side. The signers of the Declaration of Independence were mostly well-educated, of British stock, and of the Protestant faith.

The consensus of scholars is that about 15– to 20-percent of the white population remained loyal to the British Crown. Those who actively supported the king were known at the time as "Loyalists", "Tories", or "King's men". The Loyalists never controlled territory unless the British Army occupied it. They were typically older, less willing to break with old loyalties, and often connected to the Church of England; they included many established merchants with strong business connections throughout the Empire, as well as royal officials such as Thomas Hutchinson of Boston. There were 500 to 1,000 black loyalists, slaves who escaped to British lines and joined the British army. Most died of disease, but Britain took the survivors to Canada as free men.

The revolution could divide families, such as William Franklin, son of Benjamin Franklin and royal governor of the Province of New Jersey who remained loyal to the Crown throughout the war. He and his father never spoke again. Recent immigrants who had not been fully Americanized were also inclined to support the King, such as Flora MacDonald who was a Scottish settler in the back country.

After the war, the great majority of the approximately 500,000 Loyalists remained in America and resumed normal lives. Some became prominent American leaders, such as Samuel Seabury. Approximately 46,000 Loyalists relocated to Canada; others moved to Britain (7,000), Florida, or the West Indies (9,000). The exiles represented approximately two percent of the total population of the colonies. Nearly all black loyalists left for Nova Scotia, Florida, or England, where they could remain free. Loyalists who left the South in 1783 took thousands of their slaves with them to be slaves in the British West Indies.

A minority of uncertain size tried to stay neutral in the war. Most kept a low profile, but the Quakers were the most important group to speak out for neutrality, especially in Pennsylvania. The Quakers continued to do business with the British even after the war began, and they were accused of being supporters of British rule, "contrivers and authors of seditious publications" critical of the revolutionary cause. The majority of Quakers attempted to remain neutral, although a sizeable number nevertheless participated to some degree.

Women contributed to the American Revolution in many ways and were involved on both sides. Formal politics did not include women, but ordinary domestic behaviors became charged with political significance as Patriot women confronted a war which permeated all aspects of political, civil, and domestic life. They participated by boycotting British goods, spying on the British, following armies as they marched, washing, cooking, and tending for soldiers, delivering secret messages, and even fighting disguised as men in a few cases, such as Deborah Samson. Mercy Otis Warren held meetings in her house and cleverly attacked Loyalists with her creative plays and histories. Above all, women continued the agricultural work at home to feed their families and the armies. They maintained their families during their husbands' absences and sometimes after their deaths.

American women were integral to the success of the boycott of British goods, as the boycotted items were largely household items such as tea and cloth. Women had to return to knitting goods, and to spinning and weaving their own cloth—skills that had fallen into disuse. In 1769, the women of Boston produced 40,000 skeins of yarn, and 180 women in Middletown, Massachusetts wove of cloth. A woman's loyalty to her husband could become an open political act, especially for women in America committed to men who remained loyal to the King. Legal divorce, usually rare, was granted to Patriot women whose husbands supported the King.

In early 1776, France set up a major program of aid to the Americans, and the Spanish secretly added funds. Each country spent one million "livres tournaises" to buy munitions. A dummy corporation run by Pierre Beaumarchais concealed their activities. American Patriots obtained some munitions through the Dutch Republic, as well as French and Spanish ports in the West Indies.

Spain did not officially recognize the U.S. but it separately declared war on Britain on June 21, 1779. Bernardo de Gálvez y Madrid, general of the Spanish forces in New Spain, also served as governor of Louisiana. He led an expedition of colonial troops to force the British out of Florida and to keep open a vital conduit for supplies.

Most American Indians rejected pleas that they remain neutral and instead supported the British Crown. The great majority of the 200,000 Indians east of the Mississippi distrusted the Colonists and supported the British cause, hoping to forestall continued colonial expansion into their territories. Those tribes that were more closely involved in trade tended to side with the Patriots, although political factors were important, as well.

Most Indians did not participate directly in the war, except for warriors and bands associated with four of the Iroquois tribes in New York and Pennsylvania which allied with the British. The British did have other allies, especially in the upper Midwest. They provided Indians with funding and weapons to attack American outposts. Some Indians tried to remain neutral, seeing little value in joining what they perceived to be a European conflict, and fearing reprisals from whichever side they opposed. The Oneida and Tuscarora tribes among the Iroquois of central and western New York supported the American cause. The British provided arms to Indians who were led by Loyalists in war parties to raid frontier settlements from the Carolinas to New York. They killed many settlers on the frontier, especially in Pennsylvania and New York's Mohawk Valley.

In 1776, Cherokee war parties attacked American Colonists all along the southern frontier of the uplands throughout the Washington District, North Carolina (now Tennessee) and the Kentucky wilderness area. They would launch raids with roughly 200 warriors, as seen in the Cherokee–American wars; they could not mobilize enough forces to invade Colonial areas without the help of allies, most often the Creek. The Chickamauga Cherokee under Dragging Canoe allied themselves closely with the British, and fought on for an additional decade after the Treaty of Paris was signed. Joseph Brant of the powerful Mohawk tribe in New York was the most prominent Indian leader against the Patriot forces. In 1778 and 1780, he led 300 Iroquois warriors and 100 white Loyalists in multiple attacks on small frontier settlements in New York and Pennsylvania, killing many settlers and destroying villages, crops, and stores. The Seneca, Onondaga, and Cayuga of the Iroquois Confederacy also allied with the British against the Americans.

In 1779, the Americans forced the hostile Indians out of upstate New York when Washington sent an army under John Sullivan which destroyed 40 empty Iroquois villages in central and western New York. The Battle of Newtown proved decisive, as the Patriots had an advantage of three-to-one, and it ended significant resistance; there was little combat otherwise. Sullivan systematically burned the empty villages and destroyed about 160,000 bushels of corn that composed the winter food supply. Facing starvation and homeless for the winter, the Iroquois fled to Canada. The British resettled them in Ontario, providing land grants as compensation for some of their losses.

At the peace conference following the war, the British ceded lands which they did not really control, and they did not consult their Indian allies. They transferred control to the United States of all the land east of the Mississippi and north of Florida. Calloway concludes:

The British did not give up their forts until 1796 in the eastern Midwest, stretching from Ohio to Wisconsin; they kept alive the dream of forming a satellite Indian nation there, which they called a Neutral Indian Zone. That goal was one of the causes of the War of 1812.

Free blacks in the North and South fought on both sides of the Revolution, but most fought for the Patriots. Gary Nash reports that there were about 9,000 black Patriots, counting the Continental Army and Navy, state militia units, privateers, wagoneers in the Army, servants to officers, and spies. Ray Raphael notes that thousands did join the Loyalist cause, but "a far larger number, free as well as slave, tried to further their interests by siding with the patriots." Crispus Attucks was shot dead by British soldiers in the Boston Massacre in 1770 and is considered the first American casualty of the Revolutionary War.

Many black slaves sided with the Loyalists. Tens of thousands in the South used the turmoil of war to escape, and the southern plantation economies of South Carolina and Georgia were disrupted in particular. During the Revolution, the British tried to turn slavery against the Americans. Historian David Brion Davis explains the difficulties with a policy of wholesale arming of the slaves:

Davis underscores the British dilemma: "Britain, when confronted by the rebellious American colonists, hoped to exploit their fear of slave revolts while also reassuring the large number of slave-holding Loyalists and wealthy Caribbean planters and merchants that their slave property would be secure". The Colonists, however, accused the British of encouraging slave revolts.

American advocates of independence were commonly lampooned in Great Britain for what was termed their hypocritical calls for freedom, at the same time that many of their leaders were planters who held hundreds of slaves. Samuel Johnson snapped, "how is it we hear the loudest yelps for liberty among the drivers of the Negroes?" Benjamin Franklin countered by criticizing the British self-congratulation about "the freeing of one Negro" named Somersett while they continued to permit the overall slave trade. Phyllis Wheatley was a black poet who popularized the image of Columbia to represent America. She came to public attention when her "Poems on Various Subjects, Religious and Moral" appeared in 1773.

The effects of the war were more dramatic in the South. In Virginia, royal governor Lord Dunmore recruited black men into the British forces with the promise of freedom, protection for their families, and land grants. Tens of thousands of slaves escaped to British lines throughout the South, causing dramatic losses to slaveholders and disrupting cultivation and harvesting of crops. For instance, South Carolina was estimated to have lost about 25,000 slaves to flight, migration, or death—amounting to one third of its slave population. From 1770 to 1790, the black proportion of the population (mostly slaves) in South Carolina dropped from 60.5 percent to 43.8 percent, and from 45.2 percent to 36.1 percent in Georgia.

British forces gave transportation to 10,000 slaves when they evacuated Savannah and Charleston, carrying through on their promise. They evacuated and resettled more than 3,000 Black Loyalists from New York to Nova Scotia, Upper Canada, and Lower Canada. Others sailed with the British to England or were resettled as freedmen in the West Indies of the Caribbean. But slaves who were carried to the Caribbean under control of Loyalist masters generally remained slaves until British abolition in its colonies in 1834. More than 1,200 of the Black Loyalists of Nova Scotia later resettled in the British colony of Sierra Leone, where they became leaders of the Krio ethnic group of Freetown and the later national government. Many of their descendants still live in Sierra Leone, as well as other African countries.

Tens of thousands of Loyalists left the United States; Maya Jasanoff restimates 70,000. Some migrated to Britain. The great majority received land and subsidies for resettlement in British colonies in North America, known as United Empire Loyalists, especially Quebec (concentrating in the Eastern Townships), Prince Edward Island, and Nova Scotia. Britain created the colonies of Upper Canada (Ontario) and New Brunswick expressly for their benefit, and the Crown awarded land to Loyalists as compensation for losses in the United States. Britain wanted to develop the frontier of Upper Canada on a British colonial model. But about 85% of the Loyalists stayed in the United States and became full, loyal citizens; some of the exiles later returned to the U.S.

Interpretations vary concerning the effect of the Revolution. Contemporaries of the period referred to it as "the revolution", although the war is sometimes known as the "American War of Independence" outside the United States, particularly in the United Kingdom.

Historians such as Bernard Bailyn, Gordon Wood, and Edmund Morgan view the American Revolution as a unique and radical event that produced deep changes and had a profound effect on world affairs, such as an increasing belief in the principles of the Enlightenment. These were demonstrated by a leadership and government that espoused protection of natural rights, and a system of laws chosen by the people. John Murrin, by contrast, argues that the definition of "the people" at that time was mostly restricted to free men who were able to pass a property-qualification. This view argues that any significant gain of the revolution was irrelevant in the short term to women, black Americans and slaves, poor white men, youth, and American Indians.

Morgan has argued that, in terms of long-term impact on American society and values:

After the Revolution, genuinely democratic politics became possible in the former colonies. The rights of the people were incorporated into state constitutions. Concepts of liberty, individual rights, equality among men and hostility toward corruption became incorporated as core values of liberal republicanism. The greatest challenge to the old order in Europe was the challenge to inherited political power and the democratic idea that government rests on the consent of the governed. The example of the first successful revolution against a European empire, and the first successful establishment of a republican form of democratically elected government, provided a model for many other colonial peoples who realized that they too could break away and become self-governing nations with directly elected representative government.
The Dutch Republic, also at war with Britain, was the next country to sign a treaty with the United States, on October 8, 1782. On April 3, 1783, Ambassador Extraordinary Gustaf Philip Creutz, representing King Gustav III of Sweden, and Benjamin Franklin, signed a Treaty of Amity and Commerce with the U.S.

The American Revolution was the first wave of the Atlantic Revolutions: the French Revolution, the Haitian Revolution, and the Latin American wars of independence. Aftershocks reached Ireland in the Irish Rebellion of 1798, in the Polish–Lithuanian Commonwealth, and in the Netherlands.

The Revolution had a strong, immediate influence in Great Britain, Ireland, the Netherlands, and France. Many British and Irish Whigs spoke in favor of the American cause. In Ireland, there was a profound impact; the Protestants who controlled Ireland were demanding more and more self-rule. Under the leadership of Henry Grattan, the so-called "Patriots" forced the reversal of mercantilist prohibitions against trade with other British colonies. The King and his cabinet in London could not risk another rebellion on the American model, and made a series of concessions to the Patriot faction in Dublin. Armed Protestant volunteer units were set up to protect against an invasion from France. As in America, so too in Ireland the King no longer had a monopoly of lethal force.

The Revolution, along with the Dutch Revolt (end of the 16th century) and the 17th century English Civil War, was among the examples of overthrowing an old regime for many Europeans who later were active during the era of the French Revolution, such as the Marquis de Lafayette. The American Declaration of Independence influenced the French Declaration of the Rights of Man and the Citizen of 1789. The spirit of the Declaration of Independence led to laws ending slavery in all the Northern states and the Northwest Territory, with New Jersey the last in 1804. States such as New Jersey and New York adopted gradual emancipation, which kept some people as slaves for more than two decades longer.

The democratic ideals of the Revolution inspired changes in the roles of women.

The concept of republican motherhood was inspired by this period and reflects the importance of Republicanism as the dominant American ideology. It assumed that a successful republic rested upon the virtue of its citizens. Women were considered to have the essential role of instilling their children with values conducive to a healthy republic. During this period, the wife's relationship with her husband also became more liberal, as love and affection instead of obedience and subservience began to characterize the ideal marital relationship. In addition, many women contributed to the war effort through fundraising and running family businesses in the absence of husbands.

The traditional constraints gave way to more liberal conditions for women. Patriarchy faded as an ideal; young people had more freedom to choose their spouses and more often used birth control to regulate the size of their families. Society emphasized the role of mothers in child rearing, especially the patriotic goal of raising republican children rather than those locked into aristocratic value systems. There was more permissiveness in child-rearing. Patriot women married to Loyalists who left the state could get a divorce and obtain control of the ex-husband's property.
Whatever gains they had made, however, women still found themselves subordinated, legally and socially, to their husbands, disfranchised and usually with only the role of mother open to them. But, some women earned livelihoods as midwives and in other roles in the community, which were not originally recognized as significant by men.

Abigail Adams expressed to her husband, the president, the desire of women to have a place in the new republic: "I desire you would remember the Ladies, and be more generous and favourable to them than your ancestors. Do not put such unlimited power into the hands of the Husbands."

The Revolution sparked a discussion on the rights of woman and an environment favorable to women's participation in politics. Briefly the possibilities for women's rights were highly favorable, but a backlash led to a greater rigidity that excluded women from politics.

For more than thirty years, however, the 1776 New Jersey State Constitution gave the vote to "all inhabitants" who had a certain level of wealth, including unmarried women and blacks (not married women because they could not own property separately from their husbands), until in 1807, when that state legislature passed a bill interpreting the constitution to mean universal "white male" suffrage, excluding paupers.

In the first two decades after the American Revolution, state legislatures and individuals took actions to free numerous slaves, in part based on revolutionary ideals. Northern states passed new constitutions that contained language about equal rights or specifically abolished slavery; some states, such as New York and New Jersey, where slavery was more widespread, passed laws by the end of the 18th century to abolish slavery by a gradual method; in New York, the last slaves were freed in 1827.

While no southern state abolished slavery, for a period individual owners could free their slaves by personal decision, often providing for manumission in wills but sometimes filing deeds or court papers to free individuals. Numerous slaveholders who freed their slaves cited revolutionary ideals in their documents; others freed slaves as a reward for service. Records also suggest that some slaveholders were freeing their own mixed-race children, born into slavery to slave mothers.

The American Revolution has a central place in the American memory as the story of the nation's founding. It is covered in the schools, memorialized by a national holiday, and commemorated in innumerable monuments. George Washington's estate at Mount Vernon was one of the first national pilgrimages for tourists and attracted 10,000 visitors a year by the 1850s.

The Revolution became a matter of contention in the 1850s in the debates leading to the American Civil War (1861–65), as spokesmen of both the Northern United States and the Southern United States claimed that their region was the true custodian of the legacy of 1776. The United States Bicentennial in 1976 came a year after the American withdrawal from the Vietnam War, and speakers stressed the themes of renewal and rebirth based on a restoration of traditional values.

Today, more than 100 are protected and maintained by the government. The National Park Service alone owns and maintains more than 50 battlefield parks and sites related to the Revolution. The American Battlefield Trust preserves almost 700 acres of battlefield land in six states.









</doc>
<doc id="1974" url="https://en.wikipedia.org/wiki?curid=1974" title="April 17">
April 17





</doc>
<doc id="1975" url="https://en.wikipedia.org/wiki?curid=1975" title="Alan Ayckbourn">
Alan Ayckbourn

Sir Alan Ayckbourn, (born 12 April 1939) is a prolific British playwright and director. He has written and produced more than seventy full-length plays in Scarborough and London and was, between 1972 and 2009, the artistic director of the Stephen Joseph Theatre in Scarborough, where all but four of his plays have received their first performance. More than 40 have subsequently been produced in the West End, at the Royal National Theatre or by the Royal Shakespeare Company since his first hit "Relatively Speaking" opened at the Duke of York's Theatre in 1969.

Major successes include "Absurd Person Singular" (1975), "The Norman Conquests" trilogy (1973), "Bedroom Farce" (1975), "Just Between Ourselves" (1976), "A Chorus of Disapproval" (1984), "Woman in Mind" (1985), "A Small Family Business" (1987), "Man Of The Moment" (1988), "House" & "Garden" (1999) and "Private Fears in Public Places" (2004). His plays have won numerous awards, including seven London "Evening Standard" Awards. They have been translated into over 35 languages and are performed on stage and television throughout the world. Ten of his plays have been staged on Broadway, attracting two Tony nominations, and one Tony award.

Ayckbourn was born in Hampstead, London. His mother Irene Worley ("Lolly") (1906–1998) was a writer of short stories who published under the name "Mary James". His father, Horace Ayckbourn (1904–1965), was an orchestral violinist, at one time deputy leader of the London Symphony Orchestra. His parents, who separated shortly after World War II, never married, and Ayckbourn's mother divorced her first husband to marry again in 1948.

Ayckbourn wrote his first play at Wisborough Lodge (a preparatory school in the village of Wisborough Green) when he was about 10. Whilst at prep school as a boarder, his mother wrote to tell him she was marrying Cecil Pye, a bank manager. When he went home for the holidays, his new family consisted of his mother, his stepfather and Christopher, his stepfather's son by an earlier marriage. This relationship too, reportedly ran into difficulties early on.

Ayckbourn attended Haileybury and Imperial Service College, in the village of Hertford Heath, and whilst there toured Europe and America with the school's Shakespeare company.

After leaving school at 17, Ayckbourn's career took several temporary jobs in various places before starting a temporary job at the Scarborough Library Theatre, where he was introduced to the artistic director, Stephen Joseph. It is said that Joseph became both a mentor and father figure for Ayckbourn until his untimely death in 1967, and he has consistently spoken highly of him.

Ayckbourn's career was briefly interrupted when he was called for National Service. He was swiftly discharged, officially on medical grounds, but it is suggested that a doctor who noticed his reluctance to join the Armed Forces deliberately failed the medical as a favour. Although Ayckbourn continued to move where his career took him, he settled in Scarborough, eventually buying Longwestgate House, the house formerly owned by Stephen Joseph.

In 1957, Ayckbourn married Christine Roland, another member of the Library Theatre company, and indeed Ayckbourn's first two plays were written jointly with her under the pseudonym of "Roland Allen". They had two sons, Steven and Philip. However, the marriage had difficulties which eventually led to their separation in 1971. Ayckbourn said that his relationship with Roland became easy once they agreed their marriage was over. Around this time, he started to share a home with Heather Stoney, an actress he had first met ten years earlier. Like his mother, neither he nor Roland sought a divorce for the next thirty years and it was only in 1997 that they formally divorced; Ayckbourn married Stoney. One side-effect of the timing is that, as Ayckbourn was awarded a knighthood a few months before the divorce, both his first and second wife were entitled to take the title of Lady Ayckbourn.

In February 2006, he suffered a stroke in Scarborough, and stated: "I hope to be back on my feet, or should I say my left leg, as soon as possible, but I know it is going to take some time. In the meantime I am in excellent hands and so is the Stephen Joseph Theatre." He left hospital after eight weeks and returned to directing after six months, but the following year he announced he would step down as artistic director of the Stephen Joseph Theatre. Ayckbourn, however, continues to write and direct his own work at the theatre.

Since Ayckbourn's plays started becoming established in the West End, interviewers have raised the question of whether his work is autobiographical. There is no clear answer to this question. There has only been one biography, written by Paul Allen, and this primarily covers his career in the theatre. Ayckbourn has frequently said he sees aspects of himself in all his characters. For example, in "Bedroom Farce" (1975), he admitted to being, in some respects, all four of the men in the play. It has been suggested that, after Ayckbourn himself, the person who is used the most in his plays is his mother, particularly as Susan in "Woman in Mind" (1985).

What is less clear is how much influence events in Ayckbourn's life have had on his writing. It is true that the theme of marriages in various difficulties was heavily present throughout his plays in the early seventies, around the time his own marriage was coming to an end. However, by this time, he had also witnessed the failures of his parents' relationships as well as those of some of his friends. Which relationships, if any, he drew on for his plays, is unclear. In Paul Allen's biography, Ayckbourn is briefly compared to Dafydd and Guy in "A Chorus of Disapproval" (1984). Both characters feel themselves in trouble, and there was speculation that Ayckbourn himself may have felt himself to be in trouble. At the time, he had reportedly become seriously involved with another actress, which threatened his relationship with Stoney. But again, it is unclear whether this had any effect on the writing, and Paul Allen's view is that it is not current experience that Ayckbourn uses for his plays.

It could be that Ayckbourn had written plays with himself and his own issues in mind, but as Ayckbourn is portrayed as a guarded and private man, it is hard to imagine him exposing his own life in his plays to any great degree. In the biography, Paul Allen wrote, regarding a suggestion in "Cosmopolitan" that his plays were becoming autobiographical: "If we take that to mean that his plays tell his own life story, he still hasn't started."

On leaving school his theatrical career started immediately, with an introduction to Sir Donald Wolfit by his French master. Ayckbourn joined Wolfit on tour to the Edinburgh Festival Fringe as an acting assistant stage manager (meaning a role that involved both acting and stage management) for three weeks, with his first role on the professional stage being various parts in "The Strong are Lonely" by Fritz Hochwälder. In the following year, Ayckbourn appeared in six other plays at the Connaught Theatre, Worthing, and the Thorndyke theatre, Leatherhead.

In 1957, Ayckbourn was employed by the director Stephen Joseph at the Library Theatre, Scarborough, the predecessor to the modern Stephen Joseph Theatre. His role, again, was initially an acting stage manager. This employment led to Ayckbourn's first professional script commission, in 1958. When he complained about the quality of a script he was performing, Joseph challenged him to write a better one. The result was "The Square Cat", written under the pseudonym Roland Allen and first performed in 1959. In this play, Ayckbourn himself played the character Jerry Watiss.

After thirty-four appearances in plays at the Library Theatre, including four of his own, in 1962 Ayckbourn moved to Stoke-on-Trent to help set up the Victoria Theatre, (now the New Vic), where he appeared in a further eighteen plays. His final appearance in one of his own plays was as the Crimson Gollywog in the disastrous children's play "Christmas v Mastermind". He left the Stoke company in 1964, officially to commit his time to the London production of "Mr. Whatnot", but reportedly because was having trouble working with the artistic director, Peter Cheeseman. By now, his career as a writer was coming to fruition, and his acting career was sidelined.

His final role on stage was as Jerry in "Two for the Seesaw" by William Gibson, at the Civic Theatre in Rotherham. He was left stranded on stage because Heather Stoney was unable to re-appear because the props had been left unpacked, and this led him to decide acting was more trouble than it was worth. The assistant stage manager on the production, Bill Kenwright, would become one of the UK's most successful producers.

Ayckbourn's earliest plays were written and produced at a time when the Scarborough Library theatre, like most regional theatres, regularly commissioned work from their own actors to keep costs down (the other notable actor whose work was being commissioned being David Campton). His first play, "The Square Cat", was sufficiently popular locally to secure further commissions although not this or the following three plays had much impact beyond Scarborough. But, after his transfer to Victoria Theatre in Stoke-on-Trent, there came "Christmas v Mastermind", which flopped and is now universally regarded as Ayckbourn's greatest disaster.

His fortunes began to revive in 1963 with "Mr. Whatnot", again premiering at the Victoria Theatre. This was the first play that Ayckbourn was sufficiently happy with to allow performances today, and the first play to receive a West End performance. However, the West End production flopped, in part down to misguided casting. After this, Ayckbourn experimented by collaborating with comedians, first writing a monologue for Tommy Cooper, and later with Ronnie Barker, who played Lord Slingsby-Craddock in the London production of "Mr Whatnot" in 1964, for the scripts of for LWT's "Hark at Barker". Ayckbourn used the pseudonym 'Peter Caulfield' because he was under exclusive contract to the BBC at the time.

Then, in 1965, back at the Scarborough Library Theatre, "Meet my Father" was produced, later retitled "Relatively Speaking". This time, the play was a massive success, both in Scarborough and the West End, making Alan Ayckbourn rich and earning him a congratulatory telegram from Noël Coward. This was not quite the end of Ayckbourn's hit-and-miss record, because his following play, "The Sparrow" only ran for three weeks at Scarborough. However, the following play, "How the Other Half Loves", secured his runaway success as a playwright.

The height of Ayckbourn's commercial success included "Absurd Person Singular" (1975), "The Norman Conquests" trilogy (1973), "Bedroom Farce" (1975) and "Just Between Ourselves" (1976), all plays that focused heavily on marriage in the British middle classes. The only failure during this period was a 1975 musical with Andrew Lloyd Webber, "Jeeves", and even this did little to dent Ayckbourn's popularity. Although his plays have received major West End productions almost from the beginning of his writing career, and hence have been reviewed in British newspapers, Ayckbourn's work was for years routinely dismissed as being too slight for serious study. Recently, scholars have begun to view Ayckbourn as an important commentator on the lifestyles of the British suburban middle class, and as a stylistic innovator who experiments with theatrical styles within the boundaries set by popular tastes.

From the 1980s, Ayckbourn began to move away from the recurring themes of marriage and explore other contemporary themes, one example being "Woman in Mind", a play performed entirely from the perspective of a Woman going through a nervous breakdown. He also experimented with several more unconventional ways of writing plays, such as "Intimate Exchanges", which has one beginning and sixteen possible endings, and "House & Garden", where two plays take place simultaneously of two different stages, as well as diversifying into children's theatre (such as "Mr A's Amazing Maze Plays" and musical plays, such as "By Jeeves" (a more successful rewrite of the original "Jeeves").

With a résumé of over seventy plays, of which more than forty have played at the National Theatre or in the West End, Alan Ayckbourn is one of England's most successful living playwrights. Despite his success, honours and awards (which include a prestigious Laurence Olivier Award), Alan Ayckbourn remains a relatively anonymous figure dedicated to regional theatre. Throughout his writing career, all but four of his plays were premiered at the Stephen Joseph Theatre in Scarborough in its three different locations.

Ayckbourn received the CBE in 1987 and was knighted in the 1997 New Year Honours. It is frequently claimed (but not proven) that Alan Ayckbourn is the most performed living English playwright, and the second most performed of all time after Shakespeare.

Although Ayckbourn's plays no longer dominate the theatrical scene on the scale of his earlier works, he continues to write, his most recent major success being "Private Fears in Public Places" that had a hugely successful Off-Broadway run at 59E59 Theaters, and in 2006 was made into a film "Cœurs", directed by Alain Resnais. After suffering a stroke, there was uncertainty as to whether he could continue to write (the Ayckbourn play premiered immediately after the stroke, "If I Were You", was written before his illness), but his first play written afterwards, "Life and Beth", was premiered in the summer of 2008. Ayckbourn continues to write for the Stephen Joseph Theatre on invitation of his successor as artistic director, Chris Monks, with the first new play under this arrangement, "My Wonderful Day", performed in October 2009. His latest play, "Roundelay" is scheduled to open in September 2014; the order in which each of the five acts is played in each performance is to be left to chance (allowing 120 possible permutations), with members of the audience being invited to extract five coloured ping pong balls from a bag beforehand.

Many of Ayckbourn's plays have had their New York premiere at 59E59 Theaters as part of their annual Brits Off Broadway Festitval including "Private Fears in Public Places", "Intimate Exchanges", "My Wonderful Day" and "Neighbourhood Watch" among others.

Although Ayckbourn is best known as a writer, it is said that he only spends 10% of his time writing plays. Most of the rest of his time is spent directing.

Ayckbourn began directing at the Scarborough Library Theatre in 1961, with a production of "Gaslight" by Patrick Hamilton. He directed five other plays that year and the following year in Scarborough, and after transferring to the Victoria Theatre, directed a further six plays in 1963. Between 1964 and 1967 (when much of his time was taken up by various productions of his early successes "Mr. Whatnot" and "Relatively Speaking") he only directed one play ("The Sparrow", written by himself, later withdrawn), but in 1968 he resumed regularly directing plays, mostly at Scarborough. At this time he also worked as a radio drama producer for the BBC, based in Leeds.

At first, his directing career was separate from his writing career. It was not until 1963 that Ayckbourn directed a play of his own (a revival of "Standing Room Only"), 1967 that Ayckbourn directed a premiere of his own ("The Sparrow"). The London premieres remained in the hands of other directors for longer, with the first play of his both written and directed by him in London ("Bedroom Farce") waiting until 1977.

After the death of Stephen Joseph in 1967, the position of Director of Productions was appointed on an annual basis. Ayckbourn was offered this position in 1969 and 1970, succeeding Rodney Wood, but he handed the position over to Caroline Smith in 1971 (having spent most of his time that year in the US with "How the Other Half Loves"). He became Director of Productions again in 1972, and this time, on 12 November that same year, he was made the permanent artistic director of the theatre.

In mid-1986, Ayckbourn accepted an invitation to work as a visiting director for two years at the Royal National Theatre in London, form his own company, and perform a play in each of the three auditoria provided at least one was a new play of his own. Using a stock company that included established performers like Michael Gambon, Polly Adams and Simon Cadell. The three plays became four, and were: "Tons of Money" by Will Evans and Valentine, with adaptations by Ayckbourn (Lyttelton), Arthur Miller's "A View From the Bridge" (Cottesloe), his own "A Small Family Business" (Olivier) and John Ford's "'Tis Pity She's a Whore" (Olivier again). During this time, Ayckbourn shared his role of artistic director of the Stephen Joseph Theatre with Robin Herford and returned in 1987 to direct the premiere of "Henceforward...".

He announced in 1999 that he would step back from directing the work of other playwrights, in order to concentrate on his own plays, the last one being Rob Shearman's "Knights in Plastic Armour" in 1999; the exception being in 2002 when he directed the world premiere of Tim Firth's "The Safari Party".

In 2002, following a dispute over the Duchess Theatre's handling of "Damsels in Distress", Ayckbourn sharply criticised both this and the West End's treatment of theatre in general, in particular their casting of celebrities. Although he did not explicitly say he would boycott the West End, he did not return to direct in the West End again until 2009 with a revival of "Woman in Mind" (although he did allow other West End producers to revive "Absurd Person Singular" in 2007 and "The Norman Conquests" in 2008).

After Ayckbourn suffered a stroke in February 2006, he returned to work in September and premiered his 70th play "If I Were You" at the Stephen Joseph Theatre the following month.

He announced in June 2007 that he would retire as artistic director of the Stephen Joseph Theatre after the 2008 season. His successor, Chris Monks, took over at the start of the 2009–2010 season, but Ayckbourn remained to direct premieres and revivals of his work at the theatre, beginning with "How the Other Half Loves" in June 2009.

In March 2010 he directed an in-the-round revival of his play "Taking Steps" at the Orange Tree Theatre, winning universal press acclaim.

In July 2014, Ayckbourn directed a musical adaptation of "The Boy Who Fell Into A Book", with musical adaptation and lyrics by Paul James and music by Eric Angus and Cathy Shostak. The show ran in The Stephen Joseph Theatre and received critical acclaim.


Ayckbourn also sits on the Council of the Society of Authors.

There are eight one-act plays written by Alan Ayckbourn. Five of them ("Mother Figure", "Drinking Companion", "Between Mouthfuls", "Gosforth’s Fete" and "Widows Might") were written for "Confusions", first performed in 1974.

The other three one-act plays were:


Plays adapted as films include:




</doc>
<doc id="1979" url="https://en.wikipedia.org/wiki?curid=1979" title="Alpha Centauri">
Alpha Centauri

Alpha Centauri (Latinized from α Centauri, abbreviated Alpha Cen or α Cen) is the closest star system and closest planetary system to the Solar System at from the Sun. It is a triple star system, consisting of three stars: α Centauri A (officially Rigil Kentaurus), α Centauri B (officially Toliman), and α Centauri C (officially Proxima Centauri).

Alpha Centauri A and B are Sun-like stars (Class G and K), and together they form the binary star Alpha Centauri AB. To the naked eye, the two main components appear to be a single star with an apparent magnitude of −0.27, forming the brightest star in the southern constellation of Centaurus and the third-brightest in the night sky, outshone only by Sirius and Canopus.

Alpha Centauri A has 1.1 times the mass and 1.519 times the luminosity of the Sun, while Alpha Centauri B is smaller and cooler, at 0.907 times the Sun's mass and 0.445 times its luminosity. The pair orbit around a common centre with an orbital period of 79.91 years. Their elliptical orbit is eccentric, so that the distance between A and B varies from 35.6 astronomical units (AU), or about the distance between Pluto and the Sun, to that between Saturn and the Sun (11.2 AU).

Alpha Centauri C, or Proxima Centauri, is a small and faint red dwarf (Class M). Though not visible to the naked eye, Proxima Centauri is the closest star to the Sun at a distance of , slightly closer than Alpha Centauri AB. Currently, the distance between Proxima Centauri and Alpha Centauri AB is about , equivalent to about 430 times the radius of Neptune's orbit. Proxima Centauri b is an Earth-sized exoplanet in the habitable zone of Proxima Centauri; it was discovered in 2016.

"α Centauri" (Latinised to "Alpha Centauri") is the system's designation given by Johann Bayer in 1603. It bears the traditional name "Rigil Kentaurus", which is a Latinisation of the Arabic name "ar-Rijl al-Qanṭūris," meaning 'the Foot of the Centaur'.
The name is frequently abbreviated to "Rigil Kent" or even "Rigil", though the latter name is better known for Beta Orionis (Rigel).

An alternative name found in European sources, "Toliman", is an approximation of the Arabic "aẓ-Ẓalīmān" (in older transcription, "aṭ-Ṭhalīmān"), meaning 'the (two male) Ostriches', an appellation Kazwini had applied to Lambda and Mu Sagittarii, also in the southern hemisphere.

A third name that has been applied is "Bungula" , of obscure origin. Allen can only surmise it may have been coined from β and Latin "ungula" 'hoof'.

"Alpha Centauri C" was discovered in 1915 by Robert T. A. Innes, who suggested that it be named "Proxima Centaurus", . The name "Proxima Centauri" later became more widely used and is now listed by the IAU as the approved proper name.

In 2016, the Working Group on Star Names of the International Astronomical Union (IAU), having decided to attribute proper names to individual component stars rather than to multiple systems, approved the name "Rigil Kentaurus" as being restricted to "Alpha Centauri A" and the name "Proxima Centauri" for "Alpha Centauri C". 
On 10 August 2018, the IAU approved the name "Toliman" for "Alpha Centauri B".

Alpha Centauri is a triple star system, with its two main stars, Alpha Centauri A and Alpha Centauri B, being a binary component. The "AB" designation, or older "A×B", denotes the mass centre of a main binary system relative to companion star(s) in a multiple star system. "AB-C" refers to the component of Proxima Centauri in relation to the central binary, being the distance between the centre of mass and the outlying companion. Because the distance between Proxima (C) and either of Alpha Centauri A or B is similar, the AB binary system is sometimes treated as a single gravitational object.

The A and B components of Alpha Centauri have an orbital period of 79.91 years. Their orbit is moderately eccentric, "e" = 0.5179; their closest approach is , or about the distance between the Sun and Saturn; and their furthest separation is , about the distance between the Sun and Pluto.

Viewed from Earth, the "apparent orbit" of A and B means that their separation and position angle (PA) are in continuous change throughout their projected orbit. Observed stellar positions in 2019 are separated by 4.92 arcsec through the PA of 337.1°, increasing to 5.49 arcsec through 345.3° in 2020. The closest recent approach was in February 2016, at 4.0 arcsec through the PA of 300°. The observed maximum separation of these stars is about 22 arcsec, while the minimum distance is 1.7 arcsec. The widest separation occurred during February 1976, and the next will be in January 2056.

The most recent, "true orbit", closest approach or periastron was in August 1955, and the next will be in May 2035. The furthest orbital separation or apastron last occurred in May 1995, and the next will be in 2075. The apparent distance between Alpha Centauri A and B is rapidly decreasing, at least until 2019.

Alpha Centauri C is about 13,000 astronomical units (AU) away from Alpha Centauri AB. This is equivalent to —about 5% the distance between Alpha Centauri AB and the Sun. Until 2017, measurements of its small speed and its trajectory were of too little accuracy and duration in years to determine whether it is bound to Alpha Centauri AB or unrelated.

Radial velocity measurements made in 2017 were precise enough to show that Proxima Centauri and Alpha Centauri AB are gravitationally bound. The orbital period of Proxima Centauri is approximately years, with an eccentricity of 0.50 ± 0.08, much more eccentric than Mercury's. Proxima Centauri comes within of AB at periastron, and its apastron occurs at .

Asteroseismic studies, chromospheric activity, and stellar rotation (gyrochronology) are all consistent with the Alpha Centauri system being similar in age to, or slightly older than, the Sun. Asteroseismic analyses that incorporate tight observational constraints on the stellar parameters for the Alpha Centauri stars have yielded age estimates of  Gyr,  Gyr, 5.2 ± 1.9 Gyr, 6.4 Gyr, and  Gyr. Age estimates for the stars based on chromospheric activity (Calcium H & K emission) yield 4.4 ± 2.1 Gyr, whereas gyrochronology yields  Gyr. Stellar evolution theory implies both stars are slightly older than the Sun at 5 to 6 billion years, as derived by their mass and spectral characteristics.

From the orbital elements, the total mass of Alpha Centauri AB is about —or twice that of the Sun. The average individual stellar masses are and , respectively, though slightly higher masses have been quoted in recent years, such as and , or totalling . Alpha Centauri A and B have absolute magnitudes of +4.38 and +5.71, respectively.

Alpha Centauri A, also known as Rigil Kentaurus, is the principal member, or "primary", of the binary system. It is a solar-like main-sequence star with a similar yellowish colour, whose stellar classification is spectral type G2 V; it is slightly larger and more luminous than the Sun. Alpha Centauri A is about 10 percent more massive than the Sun, with a radius about 22 percent larger. When considered among the individual brightest stars in the sky (excluding the Sun), it is the fourth brightest at an apparent magnitude of −0.01, being slightly fainter than Arcturus at an apparent magnitude of −0.04.

The type of magnetic activity on Alpha Centauri A is comparable to that of the Sun, showing coronal variability due to star spots, as modulated by the rotation of the star. However, since 2005 the activity level has fallen into a deep minimum that might be similar to the Sun's historical Maunder Minimum. Alternatively, it may have a very long stellar activity cycle and is slowly recovering from a minimum phase.

Alpha Centauri B, also known as Toliman, is the "secondary" star of the binary system. It is a main-sequence star of spectral type K1 V, making it more an orange colour than Alpha Centauri A; it has around 90 percent the mass of the Sun and a 14 percent smaller diameter. Although it has a lower luminosity than A, Alpha Centauri B emits more energy in the X-ray band. Its light curve varies on a short time scale, and there has been at least one observed flare. It is more magnetically active than Alpha Centauri A, showing a cycle of compared to 11 years for the Sun, and about half the minimum-to-peak variation in coronal luminosity of the Sun. Alpha Centauri B has an apparent magnitude of +1.35, slightly dimmer than Mimosa.

Alpha Centauri C, better known as Proxima Centauri, is a small main-sequence red dwarf of spectral class M6 Ve. It has an absolute magnitude of +15.60, over 20,000 times fainter than the Sun. Its mass is calculated to be .

To the naked eye, Alpha Centauri AB appears to be a single star, the brightest in the southern constellation of Centaurus. Their apparent angular separation varies over about 80 years between 2 and 22 arcsec (the naked eye has a resolution of 60 arcsec), but through much of the orbit, both are easily resolved in binoculars or small telescopes. At −0.27 apparent magnitude (combined for A and B magnitudes), Alpha Centauri is fainter only than Sirius and Canopus. It forms the outer star of "The Pointers" or "The Southern Pointers", so called because the line through Beta Centauri (Hadar/Agena),
some 4.5° west, points to the constellation Crux—the Southern Cross. The Pointers easily distinguish the true Southern Cross from the fainter asterism known as the False Cross.

South of about 29° S latitude, Alpha Centauri is circumpolar and never sets below the horizon. North of about 29° N latitude, Alpha Centauri never rises. Alpha Centauri lies close to the southern horizon when viewed from the 29° N latitude to the equator (close to Hermosillo, Chihuahua City in Mexico, Galveston, Texas, Ocala, Florida and Lanzarote, the Canary Islands of Spain), but only for a short time around its culmination. The star culminates each year at local midnight on 24 April and at local 9 p.m. on 8 June.

As seen from Earth, Proxima Centauri is 2.2° southwest from Alpha Centauri AB, about four times the angular diameter of the Moon. Proxima Centauri appears as a deep-red star of a typical apparent magnitude of 11.1 in a sparsely populated star field, requiring moderately sized telescopes to be seen. Listed as V645 Cen in the "General Catalogue of Variable Stars Version 4.2", this UV Ceti-type flare star can unexpectedly brighten rapidly by as much as 0.6 magnitudes at visual wavelengths, then fade after only a few minutes. Some amateur and professional astronomers regularly monitor for outbursts using either optical or radio telescopes. In August 2015, the largest recorded flares of the star occurred, with the star becoming 8.3 times brighter than normal on 13 August, in the B band (blue light region).

Alpha Centauri is listed in the 2nd-century star catalog of Ptolemy. He gave its ecliptic coordinates, but texts differ as to whether the ecliptic latitude reads or . (Presently the ecliptic latitude is , but it has decreased by a fraction of a degree since Ptolemy's time due to proper motion.) In Ptolemy's time, Alpha Centauri was visible from Alexandria, Egypt, at but, due to precession, its declination is now , and it can no longer be seen at that latitude. English explorer Robert Hues brought Alpha Centauri to the attention of European observers in his 1592 work "Tractatus de Globis", along with Canopus and Achernar, noting:

The binary nature of Alpha Centauri AB was recognised in December 1689 by Jean Richaud, while observing a passing comet from his station in Puducherry. Alpha Centauri was only the second binary star to be discovered, preceded by Acrux.

The large proper motion of Alpha Centauri AB was discovered by Manuel John Johnson, observing from Saint Helena, who informed Thomas Henderson at the Royal Observatory, Cape of Good Hope of it. The parallax of Alpha Centauri was subsequently determined by Henderson from many exacting positional observations of the AB system between April 1832 and May 1833. He withheld his results, however, because he suspected they were too large to be true, but eventually published them in 1839 after Friedrich Wilhelm Bessel released his own accurately determined parallax for 61 Cygni in 1838. For this reason, Alpha Centauri is sometimes considered as the second star to have its distance measured because Henderson's work was not fully acknowledged at first. (The distance of Alpha Centauri from the Earth is now reckoned at .)
Later, John Herschel made the first micrometrical observations in 1834. Since the early 20th century, measures have been made with photographic plates.

By 1926, William Stephen Finsen calculated the approximate orbit elements close to those now accepted for this system. All future positions are now sufficiently accurate for visual observers to determine the relative places of the stars from a binary star ephemeris. Others, like D. Pourbaix (2002), have regularly refined the precision of new published orbital elements.

Robert T. A. Innes discovered Proxima Centauri in 1915 by blinking photographic plates taken at different times during a proper motion survey. These showed large proper motion and parallax similar in both size and direction to those of Alpha Centauri AB, suggesting that Proxima Centauri is part of the Alpha Centauri system and slightly closer to Earth than Alpha Centauri AB. Lying away, Proxima Centauri is the nearest star to the Sun.

All components of Alpha Centauri display significant proper motion against the background sky. Over centuries, this causes their apparent positions to slowly change. Proper motion was unknown to ancient astronomers. Most assumed that the stars are immortal and permanently fixed on the celestial sphere, as stated in the works of the philosopher Aristotle. In 1718, Edmond Halley found that some stars had significantly moved from their ancient astrometric positions.

In the 1830s, Thomas Henderson discovered the true distance to Alpha Centauri by analysing his many astrometric mural circle observations. He then realised this system also likely had a high proper motion. In this case, the apparent stellar motion was found using Nicolas Louis de Lacaille's astrometric observations of 1751–1752, by the observed differences between the two measured positions in different epochs.

Calculated proper motion of the centre of mass for Alpha Centauri AB is about 3620 mas (milli-arcseconds) per year toward the west and 694 mas/y toward the north, giving an overall motion of 3686 mas/y in a direction 11° north of west. The motion of the centre of mass is about 6.1 arcmin each century, or 1.02° each millennium. The velocity in the western direction is 23.0 km/s and in the northerly direction 4.4 km/s. Using spectroscopy the mean radial velocity has been determined to be around 22.4 km/s towards the Solar System.

Since Alpha Centauri AB is almost exactly in the plane of the Milky Way as viewed from Earth, there are many stars behind them. In early May 2028, Alpha Centauri A will pass between us and a distant red star, when there will be a 45% probability that an Einstein ring will be observed. Other conjunctions will also occur in the coming decades, allowing accurate measurement of proper motions and possibly giving information on planets.

As the stars of Alpha Centauri move closer to the Solar System, their measured proper motions, trigonometric parallaxes and radial velocities slowly increase.
These effects will continue until the star system reaches its nearest point to the Sun, and then reverse as the distance increases again. Furthermore, other small changes also occur with the binary star's orbital elements. For example, in the apparent size of the semi-major axis of the orbital ellipse will increase by 0.03 arcsec per century. Also, the observed position angles of the stars are also subject to small cumulative changes (additional to position angle changes caused by the precession of the equinoxes), as first determined by W. H. van den Bos in 1926.
Based on the system's common known proper motion and radial velocities, Alpha Centauri will continue to change its position in the sky significantly and will gradually brighten. For example, in about 6,200 AD, α Centauri's true motion will cause an extremely rare first-magnitude stellar conjunction with Beta Centauri, forming a brilliant optical double star in the southern sky. It will then pass just north of the Southern Cross or Crux, before moving northwest and up towards the present celestial equator and away from the galactic plane. By about 29,700 AD, in the present-day constellation of Hydra, Alpha Centauri will be away, though later calculations suggest in 29,000 AD. At nearest approach, Alpha Centauri will attain a maximum apparent magnitude of −0.86, comparable to present-day magnitude of Canopus, but it will still not surpass that of Sirius, which will brighten incrementally over the next 60,000 years, and will continue to be the brightest star as seen from Earth (other than the Sun) for the next 210,000 years.

About 28,000 years from now, the Alpha Centauri system will begin to slowly move away from the Solar System, and this bright yellow star will eventually fall below naked-eye visibility.

Only one planet has been confirmed for the Alpha Centauri system: Proxima Centauri b. It is slightly larger than the Earth, and orbits around Proxima Centauri in its habitable zone. The existence of Proxima Centauri b was announced in 2016 by the European Southern Observatory. It was found using the radial velocity method, where periodic Doppler shifts of spectral lines of the host star suggest an orbiting object.

In 2012, a planet around Alpha Centauri B was announced, Alpha Centauri Bb, but in 2015 a new analysis concluded that it almost certainly does not exist and was just a spurious artefact of the data analysis.

Whilst ruling out the existence of Alpha Centauri Bb, a possible transit of a separate exoplanet in 2013 was observed. The transit event could correspond to a planetary body with a radius around . This planet would most likely orbit Alpha Centauri B with an orbital period of 20.4 days or less, with only a 5 percent chance of it having a longer orbit. The median of the likely orbits is 12.4 days with an impact parameter of around 0–0.3. Its orbit would likely have an eccentricity of 0.24 or less. Like the probably spurious Alpha Centauri Bb, it likely has lakes of molten lava and would be far too close to Alpha Centauri B to harbour life.

Additional planets may exist in the Alpha Centauri system, either orbiting Alpha Centauri A or Alpha Centauri B individually, or in large orbits around Alpha Centauri AB. Because both stars are fairly similar to the Sun (for example, in age and metallicity), astronomers have been especially interested in making detailed searches for planets in the Alpha Centauri system. Several established planet-hunting teams have used various radial velocity or star transit methods in their searches around these two bright stars. All the observational studies have so far failed to find evidence for brown dwarfs or gas giants.

In 2009, computer simulations showed that a planet might have been able to form near the inner edge of Alpha Centauri B's habitable zone, which extends from 0.5 to 0.9 AU from the star. Certain special assumptions, such as considering that the Alpha Centauri pair may have initially formed with a wider separation and later moved closer to each other (as might be possible if they formed in a dense star cluster), would permit an accretion-friendly environment farther from the star. Bodies around Alpha Centauri A would be able to orbit at slightly farther distances due to its stronger gravity. In addition, the lack of any brown dwarfs or gas giants in close orbits around Alpha Centauri make the likelihood of terrestrial planets greater than otherwise. A theoretical study indicates that a radial velocity analysis might detect a hypothetical planet of in Alpha Centauri B's habitable zone.

Radial velocity measurements of Alpha Centauri B with High Accuracy Radial Velocity Planet Searcher spectrograph ruled out planets of more than to the distance of the habitable zone of the star (orbital period P = 200 days).

Current estimates place the probability of finding an Earth-like planet around Alpha Centauri at roughly 75%. The observational thresholds for planet detection in the habitable zones by the radial velocity method are currently (2017) estimated to be about for Alpha Centauri A, for Alpha Centauri B, and for Proxima Centauri.

Early computer-generated models of planetary formation predicted the existence of terrestrial planets around both Alpha Centauri A and B, but most recent numerical investigations have shown that the gravitational pull of the companion star renders the accretion of planets difficult. Despite these difficulties, given the similarities to the Sun in spectral types, star type, age and probable stability of the orbits, it has been suggested that this stellar system could hold one of the best possibilities for harbouring extraterrestrial life on a potential planet.

In the Solar System, Jupiter and Saturn were probably crucial in perturbing comets into the inner Solar System, providing the inner planets with a source of water and various other ices. In the Alpha Centauri system, Proxima Centauri may have influenced the planetary disk as the Alpha Centauri system was forming, enriching the area around Alpha Centauri with volatile materials. This would be discounted if, for example, Alpha Centauri B happened to have gas giants orbiting Alpha Centauri A (or vice versa), or if Alpha Centauri A and B themselves were able to perturb comets into each other's inner system as Jupiter and Saturn presumably have done in the Solar System. Such icy bodies probably also reside in Oort clouds of other planetary systems. When they are influenced gravitationally by either the gas giants or disruptions by passing nearby stars, many of these icy bodies then travel star-wards. Such ideas also apply to the close approach of Alpha Centauri or other stars to the Solar System, when, in the distant future, the Oort Cloud might be disrupted enough to increase the number of active comets.

To be in the habitable zone, a planet around Alpha Centauri A would have an orbital radius of about 1.25 AU so as to have similar planetary temperatures and conditions for liquid water to exist. For the slightly less luminous and cooler Alpha Centauri B, the habitable zone is closer at about .

With the goal of finding evidence of such planets, both Proxima Centauri and Alpha Centauri AB were among the listed "Tier 1" target stars for NASA's Space Interferometry Mission (SIM). Detecting planets as small as three Earth-masses or smaller within two astronomical units of a "Tier 1" target would have been possible with this new instrument. The SIM mission, however, was cancelled due to financial issues in 2010.

Based on observations between 2007 and 2012, a study found a slight excess of emissions in the 24 µm (mid/far-infrared) band surrounding , which may be interpreted as evidence for a sparse circumstellar disc or dense interplanetary dust. The total mass was estimated to be between to the mass of the Moon, or 10–100 times the mass of the Solar System's zodiacal cloud. If such a disc existed around both stars, disc would likely be stable to 2.8 AU, and would likely be stable to 2.5 AU. This would put A's disc entirely within the frost line, and a small part of B's outer disc just outside.

The sky from Alpha Centauri AB would appear much as it does from the Earth, except that Centaurus would be missing its brightest star. The Sun would appear as a yellow star of apparent magnitude +0.5, roughly the same as the average brightness of Betelgeuse from Earth. It would be at the antipodal point of Alpha Centauri AB's current right ascension and declination, at (2000), in eastern Cassiopeia, easily outshining all the rest of the stars in the constellation. With the placement of the Sun east of the magnitude 3.4 star Epsilon Cassiopeiae, nearly in front of the Heart Nebula, the "W" line of stars of Cassiopeia would have a "/W" shape.

The Winter Triangle would not look equilateral, but very thin and long, with Procyon outshining Pollux in the middle of Gemini, and Sirius lying less than a degree from Betelgeuse in Orion. With a magnitude of −1.2, Sirius would be a little fainter than from Earth but still the brightest star in the night sky. Both Vega and Altair would be shifted northwestward relative to Deneb, giving the Summer Triangle a more equilateral appearance.

Alpha Centauri is inside the G-cloud, and its nearest known system is the binary brown dwarf system Luhman 16 at .

In modern literature, "Rigil Kent" (also "Rigel Kent" and variants; ) and "Toliman", are used as colloquial alternative names of Alpha Centauri (then became the proper name of Alpha Centauri B in 10 August 2018 by approval of IAU).

"Rigil Kent" is short for "Rigil Kentaurus", which is sometimes further abbreviated to "Rigil" or "Rigel", though that is ambiguous with Beta Orionis, which is also called Rigel.

The name "Toliman" originates with Jacobus Golius' 1669 edition of Al-Farghani's "Compendium". "Tolimân" is Golius' latinisation of the Arabic name "the ostriches", the name of an asterism of which Alpha Centauri formed the main star.

During the 19th century, the northern amateur popularist Elijah H. Burritt used the now-obscure name "Bungula", possibly coined from "β" and the Latin "ungula" ("hoof").

Together, Alpha and Beta Centauri form the "Southern Pointers" or "The Pointers", as they point towards the Southern Cross, the asterism of the constellation of Crux.

In Chinese astronomy, "Nán Mén", meaning "Southern Gate", refers to an asterism consisting of Alpha Centauri and Epsilon Centauri. Consequently, the Chinese name for Alpha Centauri itself is "Nán Mén Èr", the Second Star of the Southern Gate.

To the Australian aboriginal Boorong people of northwestern Victoria, Alpha Centauri and Beta Centauri are "Bermbermgle", two brothers noted for their courage and destructiveness, who speared and killed "Tchingal" "The Emu" (the Coalsack Nebula). The form in Wotjobaluk is "Bram-bram-bult".
Alpha Centauri is a likely first target for manned or unmanned interstellar exploration. Using current spacecraft technologies, crossing the distance between the Sun and Alpha Centauri would take several millennia, though the possibility of nuclear pulse propulsion or laser light sail technology, as considered in the Breakthrough Starshot program, could reduce the journey time to decades. An objective of such a mission would be to make a fly-by of, and possibly photograph, planets that might exist in the system. The existence of Proxima Centauri b, announced by the European Southern Observatory (ESO) in August 2016, would be a target for the Starshot program.

In January 2017, Breakthrough Initiatives and the ESO entered a collaboration to search for habitable planets in the Alpha Centauri system. The agreement involves Breakthrough Initiatives providing funding for an upgrade to the VISIR (VLT Imager and Spectrometer for mid-Infrared) instrument on ESO's Very Large Telescope (VLT) in Chile. This upgrade will greatly increase the likelihood of planet detection in the system.





</doc>
<doc id="1980" url="https://en.wikipedia.org/wiki?curid=1980" title="Amiga">
Amiga

The Amiga is a family of personal computers introduced by Commodore in 1985. The original model was part of a wave of 16- and 32-bit computers that featured 256 KB or more of RAM, mouse-based GUIs, and significantly improved graphics and audio over 8-bit systems. This wave included the Atari ST—released the same year—Apple's Macintosh, and later the Apple IIGS. Based on the Motorola 68000 microprocessor, the Amiga differed from its contemporaries through the inclusion of custom hardware to accelerate graphics and sound, including sprites and a blitter, and a pre-emptive multitasking operating system called AmigaOS.

The Amiga 1000 was released in July 1985, but a series of production problems kept it from becoming widely available until early 1986. The best selling model, the Amiga 500, was introduced in 1987 and became one of the leading home computers of the late 1980s and early 1990s with four to six million sold. The A3000 was introduced in 1990, followed by the A500+, and the A600 in March 1992. Finally, the A1200 and the A4000 were released in late 1992. The platform became particularly popular for gaming and programming demos. It also found a prominent role in the desktop video, video production, and show control business, leading to video editing systems such as the Video Toaster. The Amiga's native ability to simultaneously play back multiple digital sound samples made it a popular platform for early tracker music software. The relatively powerful processor and ability to access several megabytes of memory enabled the development of several 3D rendering packages, including LightWave 3D, Imagine, Aladdin4D, TurboSilver and Traces, a predecessor to Blender.

Although early Commodore advertisements attempt to cast the computer as an all-purpose business machine, especially when outfitted with the Amiga Sidecar PC compatibility add-on, the Amiga was most commercially successful as a home computer, with a wide range of games and creative software. Poor marketing and the failure of the later models to repeat the technological advances of the first systems meant that the Amiga quickly lost its market share to competing platforms, such as the fourth generation game consoles, Macintosh, and the rapidly dropping prices of IBM PC compatibles which gained 256-color VGA graphics in 1987. Commodore ultimately went bankrupt in April 1994 after the Amiga CD32 model failed in the marketplace.

Since the demise of Commodore, various groups have marketed successors to the original Amiga line, including Genesi, Eyetech, ACube Systems Srl and A-EON Technology. Likewise, AmigaOS has influenced replacements, clones and compatible systems such as MorphOS, AmigaOS 4 and AROS.

Jay Miner joined Atari in the 1970s to develop custom integrated circuits, and led development of the Atari 2600's TIA. Almost as soon as its development was complete, the team began developing a much more sophisticated set of chips, CTIA, ANTIC and POKEY, that formed the basis of the Atari 8-bit family.

With the 8-bit line's launch in 1979, the team once again started looking at a next generation chipset. Nolan Bushnell had sold the company to Warner Communications in 1978, and the new management was much more interested in the existing lines than development of new products that might cut into their sales. Miner wanted to start work with the new Motorola 68000, but management was only interested in another 6502 based system. Miner left the company, and, for a time, the industry.

In 1979, Larry Kaplan left Atari and founded Activision. In 1982, Kaplan was approached by a number of investors who wanted to develop a new game platform. Kaplan hired Miner to run the hardware side of the newly formed company, "Hi-Toro". The system was code-named "Lorraine" in keeping with Miner's policy of giving systems female names, in this case the company president's wife, Lorraine Morse. When Kaplan left the company late in 1982, Miner was promoted to head engineer and the company relaunched as Amiga Corporation.

A breadboard prototype was largely completed by late 1983, and shown at the January 1984 Consumer Electronics Show (CES). At the time, the operating system was not ready, so the machine was demonstrated with the Boing Ball demo. A further developed version of the system was demonstrated at the June 1984 CES and shown to many companies in hopes of garnering further funding, but found little interest in a market that was in the final stages of the North American video game crash of 1983.

In March, Atari expressed a tepid interest in Lorraine for its potential use in a games console or home computer tentatively known as the 1850XLD. But the talks were progressing slowly, and Amiga was running out of money. A temporary arrangement in June led to a $500,000 loan from Atari to Amiga to keep the company going. The terms required the loan to be repaid at the end of the month, otherwise Amiga would forfeit the Lorraine design to Atari.

During 1983, Atari lost over $1 million a week, due to the combined effects of the crash and the ongoing price war in the home computer market. By the end of the year, Warner was desperate to sell the company. In January 1984, Jack Tramiel resigned from Commodore due to internal battles over the future direction of the company. A number of Commodore employees followed him to his new company, Tramiel Technology. This included a number of the senior technical staff, where they began development of a 68000-based machine of their own. In June, Tramiel arranged a no-cash deal to take over Atari, reforming it as Atari Corporation.

As many Commodore technical staff had moved to Atari, Commodore was left with no workable path to design their own next-generation computer. The company approached Amiga offering to fund development as a home computer system. They quickly arranged to repay the Atari loan, ending that threat. The two companies were initially arranging a $4 million license agreement before Commodore offered $24 million to purchase Amiga outright.

By late 1984 the prototype breadboard chipset had successfully been turned into integrated circuits, and the system hardware was being readied for production. At this time the operating system (OS) was not as ready, and led to a deal to port an OS known as TRIPOS to the platform. TRIPOS was a multitasking system that had been written in BCPL during the 1970s for minicomputer systems like the PDP-11, but later experimentally ported to the 68000. This early version was known as AmigaDOS and the GUI as Workbench. The BCPL parts were later rewritten in the C language, and the entire system became AmigaOS.

The system was enclosed in a pizza box form factor case; a late change was the introduction of vertical supports on either side of the case to provide a "garage" under the main section of the system where the keyboard could be stored.

The first model was announced in 1985 as simply "The Amiga from Commodore", later to be retroactively dubbed the Amiga 1000. They were first offered for sale in August, but by October only 50 had been built, all of which were used by Commodore. Machines only began to arrive in quantity in mid-November, meaning they missed the Christmas buying rush. By the end of the year, they had sold 35,000 machines, and severe cashflow problems made the company pull out of the January 1986 CES. Bad or entirely missing marketing, forcing the development team to move to the east coast, notorious stability problems and other blunders limited sales in early 1986 to between 10,000 and 15,000 units a month.

In late 1985 Thomas Rattigan was promoted to COO of Commodore, and then to CEO in February 1986. He immediately implemented an ambitious plan that covered almost all of the company's operations. Among these were the long overdue cancelation of the now outdated PET and VIC-20 lines, as well as a variety of poorly selling Commodore 64 offshoots and the Commodore 900 workstation effort.

Another one of the changes was to split the Amiga into two products, a new high-end version of the Amiga aimed at the creative market, and a cost-reduced version that would take over for the Commodore 64 in the low-end market. These new designs were released in 1987 as the Amiga 2000 and Amiga 500, the latter of which went on to widespread success and became their best selling model.

Similar high-end/low-end models would make up the Amiga line for the rest of its history; follow-on designs included the Amiga 3000/Amiga 500 Plus/Amiga 600, and the Amiga 4000/Amiga 1200. These models incorporated a series of technical upgrades known as the ECS and AGA, which added higher resolution displays among many other improvements and simplifications.

Ultimately the Amiga line would sell an estimated 4,850,000 machines over its lifetime. The machines were most popular in the UK and Germany, with about 1.5 million sold in each country, and sales in the high hundreds of thousands in other European nations. The machine was less popular in North America, where an estimated 700,000 were sold. In particular, in the U.S. the Amiga did not achieve any success outside of Commodore's traditional enthusiast market except in vertical markets for video processing and editing.

In spite of his successes in making the company profitable and bringing the Amiga line to market, Rattigan was soon forced out in a power struggle with majority shareholder, Irving Gould. This is widely regarded as the turning point, as further improvements to the Amiga were eroded by rapid improvements in other platforms.

On April 29, 1994, Commodore filed for bankruptcy and its assets were purchased by Escom, a German PC manufacturer, who created the subsidiary company Amiga Technologies. They re-released the A1200 and A4000T, and introduced a new 68060 version of the A4000T. However, Escom in turn went bankrupt in 1997.

The Amiga brand was then sold to a US Wintel PC manufacturer, Gateway 2000, which had announced grand plans for it. However, in 2000, Gateway sold the Amiga brand without having released any products. The current owner of the trademark, Amiga, Inc., licensed the rights to sell hardware using either the Amiga or AmigaOne brand to Eyetech Group, Hyperion Entertainment and Commodore USA.

At its core, the Amiga has a custom chipset consisting of several coprocessors, which handle audio, video and direct memory access independently of the Central Processing Unit (CPU). This architecture freed up the Amiga's processor for other tasks and gave the Amiga a performance edge over its competitors, particularly in terms of video-intensive applications and games.

The general Amiga architecture uses two distinct bus subsystems, namely, the chipset bus and the CPU bus. The chipset bus allows the custom coprocessors and CPU to address "Chip RAM". The CPU bus provides addressing to other subsystems, such as conventional RAM, ROM and the Zorro II or Zorro III expansion subsystems. This architecture enables independent operation of the subsystems; the CPU "Fast" bus can be much faster than the chipset bus. CPU expansion boards may provide additional custom buses. Additionally, "busboards" or "bridgeboards" may provide ISA or PCI buses.

The Motorola 68000 series of microprocessors was used in all Amiga models from Commodore. While all CPU in the 68000 family have a 32-bit ISA design (programmer uses and sees a 32-bit model), the MC68000 used in the most popular models is a 16-bit (or 16/32-bit) processor because its ALU operates in 16-bit (32-bit operations require additional clock cycles, consuming more time). The MC68000 has a 16-bit external data bus so 32-bits of data is transferred in two consecutive steps, a technique called multiplexing. This is transparent to the software, which was 32-bit from the beginning. The MC68000 can address 16 MB of physical memory. Later Amiga models featured higher-speed, full 32-bit CPUs with a larger address space and instruction pipeline facilities.

CPU upgrades were offered by both Commodore and third-party manufacturers. Most Amiga models can be upgraded either by direct CPU replacement or through expansion boards. Such boards often featured faster and higher capacity memory interfaces and hard disk controllers.

Towards the end of Commodore's time in charge of Amiga development there were suggestions that Commodore intended to move away from the 68000 series to higher performance RISC processors, such as the PA-RISC. However, these ideas were never developed before Commodore filed for bankruptcy. Despite this, third-party manufacturers designed upgrades featuring a combination of 68000 series and PowerPC processors along with a PowerPC native microkernel and software. Later Amiga clones featured PowerPC processors only.

The custom chipset at the core of the Amiga design appeared in three distinct generations, with a large degree of backward-compatibility. The Original Chip Set (OCS) appeared with the launch of the A1000 in 1985. OCS was eventually followed by the modestly improved Enhanced Chip Set (ECS) in 1990 and finally by the partly 32-bit Advanced Graphics Architecture (AGA) in 1992. Each chipset consists of several coprocessors which handle graphics acceleration, digital audio, direct memory access and communication between various peripherals (e.g., CPU, memory and floppy disks). In addition, some models featured auxiliary custom chips which performed tasks such as SCSI control and display de-interlacing.

All Amiga systems can display full-screen animated graphics with 2, 4, 8, 16, 32, 64 (EHB Mode), or 4096 colors (HAM Mode). Models with the AGA chipset (A1200 and A4000) also have non-EHB 64, 128, 256, and (HAM8 Mode) color modes and a palette expanded from 4096 to 16.8 million colors.

The Amiga chipset can "genlock", which is the ability to adjust its own screen refresh timing to match an incoming NTSC or PAL video signal. When combined with setting transparency, this allows an Amiga to overlay an external video source with graphics. This ability made the Amiga popular for many applications, and provides the ability to do character generation and CGI effects far more cheaply than earlier systems. This ability has been frequently utilized by wedding videographers, TV stations and their weather forecasting divisions (for weather graphics and radar), advertising channels, music video production, and desktop videographers. The NewTek Video Toaster was made possible by the genlock ability of the Amiga.

In 1988, the release of the Amiga A2024 fixed-frequency monochrome monitor with built-in framebuffer and flicker fixer hardware provided the Amiga with a choice of high-resolution graphic modes (1024×800 for NTSC and 1024×1024 for PAL).

ReTargetable Graphics is an API for device drivers mainly used by 3rd party graphics hardware to interface with AmigaOS via a set of libraries. The software libraries may include software tools to adjust resolution, screen colors, pointers and screenmodes. The standard Intuition interface is limited to display depths of 8-bits, while RTG makes it possible to handle higher depths like 24-bits.

The sound chip, named Paula, supports four PCM-sample-based sound channels (two for the left speaker and two for the right) with 8-bit resolution for each channel and a 6-bit volume control per channel. The analog output is connected to a low-pass filter, which filters out high-frequency aliases when the Amiga is using a lower sampling rate (see Nyquist frequency). The brightness of the Amiga's power LED is used to indicate the status of the Amiga's low-pass filter. The filter is active when the LED is at normal brightness, and deactivated when dimmed (or off on older A500 Amigas). On Amiga 1000 (and first Amiga 500 and Amiga 2000 model), the power LED had no relation to the filter's status, and a wire needed to be manually soldered between pins on the sound chip to disable the filter. Paula can read directly from the system's RAM, using direct memory access (DMA), making sound playback without CPU intervention possible.

Although the hardware is limited to four separate sound channels, software such as "OctaMED" uses software mixing to allow eight or more virtual channels, and it was possible for software to mix two hardware channels to achieve a single 14-bit resolution channel by playing with the volumes of the channels in such a way that one of the source channels contributes the most significant bits and the other the least.

The quality of the Amiga's sound output, and the fact that the hardware is ubiquitous and easily addressed by software, were standout features of Amiga hardware unavailable on PC platforms for years. Third-party sound cards exist that provide DSP functions, multi-track direct-to-disk recording, multiple hardware sound channels and 16-bit and beyond resolutions. A retargetable sound API called AHI was developed allowing these cards to be used transparently by the OS and software.

Kickstart is the firmware upon which AmigaOS is bootstrapped. Its purpose is to initialize the Amiga hardware and core components of AmigaOS and then attempt to boot from a bootable volume, such as a floppy disk or hard disk drive. Most models (excluding the Amiga 1000) come equipped with Kickstart on an embedded ROM-chip.

The keyboard on Amiga computers is similar to that found on a mid 80s IBM PC: Ten function keys, a numeric keypad, and four separate directional arrow keys. Caps Lock and Control share space to the left of A. Missing are the Home, End, Page Up, and Page Down keys: These are accomplished on Amigas by pressing shift and the appropriate arrow key. The Amiga keyboard adds a Help key, which a function key usually acts as on PCs (usually F1). In addition to the Control and Alt modifier keys, the Amiga has 2 'Amiga' keys, rendered as 'Open Amiga' and 'Closed Amiga' similar to the Open/Closed Apple logo keys on Apple II keyboards. The left is used to manipulate the operating system (moving screens and the like) and the right delivered commands to the application. The absence of Num lock frees space for more math symbols around the number pad. Contemporary Macintosh computers, for comparison, lack function keys completely.

The mouse has two buttons like Windows, but unlike Windows pressing and holding the right button replaces the system status line at the top of the screen with a Maclike menu bar. As with Apple's Mac OS prior to Mac OS 8, menu options are selected by releasing the button over that option, not by left clicking. Menu items that have a boolean toggle state can be left clicked whilst the menu is kept open with the right button, which allows the user – for example – to set some selected text to bold, underline and italics all at once.

The mouse plugs into one of two Atari joystick ports used for joysticks, game paddles, and graphics tablets. Although compatible with analog joysticks, Atari-style digital joysticks became standard.

The Amiga was one of the first computers for which inexpensive sound sampling and video digitization accessories were available. As a result of this and the Amiga's audio and video capabilities, the Amiga became a popular system for editing and producing both music and video.

Many expansion boards were produced for Amiga computers to improve the performance and capability of the hardware, such as memory expansions, SCSI controllers, CPU boards, and graphics boards. Other upgrades include genlocks, network cards for Ethernet, modems, sound cards and samplers, video digitizers, extra serial ports, and IDE controllers. Additions after the demise of Commodore company are USB cards. The most popular upgrades were memory, SCSI controllers and CPU accelerator cards. These were sometimes combined into the one device.

Early CPU accelerator cards feature full 32-bit CPUs of the 68000 family such as the Motorola 68020 and Motorola 68030, almost always with 32-bit memory and usually with FPUs and MMUs or the facility to add them. Later designs feature the Motorola 68040 or Motorola 68060. Both CPUs feature integrated FPUs and MMUs. Many CPU accelerator cards also had integrated SCSI controllers.

Phase5 designed the PowerUP boards (Blizzard PPC and CyberStorm PPC) featuring both a 68k (a 68040 or 68060) and a PowerPC (603 or 604) CPU, which are able to run the two CPUs at the same time and share the system memory. The PowerPC CPU on PowerUP boards is usually used as a coprocessor for heavy computations; a powerful CPU is needed to run MAME for example, but even decoding JPEG pictures and MP3 audio was considered heavy computation at the time. It is also possible to ignore the 68k CPU and run Linux on the PPC via project Linux APUS, but a PowerPC-native AmigaOS promised by Amiga Technologies GmbH was not available when the PowerUP boards first appeared.

24-bit graphics cards and video cards were also available. Graphics cards were designed primarily for 2D artwork production, workstation use, and later, gaming. Video cards are designed for inputting and outputting video signals, and processing and manipulating video.

In the North American market, the "NewTek Video Toaster" was a video effects board which turned the Amiga into an affordable video processing computer which found its way into many professional video environments. One well-known use was to create the special effects in early series of "Babylon 5". Due to its NTSC-only design, it did not find a market in countries that used the PAL standard, such as in Europe. In those countries, the "OpalVision" card was popular, although less featured and supported than the Video Toaster. Low-cost time base correctors (TBC) specifically designed to work with the Toaster quickly came to market, most of which were designed as standard Amiga bus cards.

Various manufacturers started producing PCI busboards for the A1200, A3000 and A4000, allowing standard Amiga computers to use PCI cards such as graphics cards, Sound Blaster sound cards, 10/100 Ethernet cards, USB cards, and television tuner cards. Other manufacturers produced hybrid boards which contained an Intel x86 series chip, allowing the Amiga to emulate a PC.

PowerPC upgrades with Wide SCSI controllers, PCI busboards with Ethernet, sound and 3D graphics cards, and tower cases allowed the A1200 and A4000 to survive well into the late nineties.

Expansion boards were made by Richmond Sound Design that allow their show control and sound design software to communicate with their custom hardware frames either by either ribbon cable or fiber optic cable for long distances, allowing the Amiga to control up to eight million digitally controlled external audio, lighting, automation, relay and voltage control channels spread around a large theme park, for example. See Amiga software for more information on these applications.

Other devices included the following:

The Commodore A2232 board provides serial ports in addition to the Amiga's built-in serial port. Each port can be driven independently at speeds of There is however a driver available on Aminet that allows two of the serial ports to be driven at The serial card used the 65CE02 CPU clocked at . This CPU was also part of the CSG 4510 CPU core that was used in the Commodore 65 computer.

Amiga has three networking interface APIs:

Different network media were used:

The original Amiga models were produced from 1985 to 1996. They are, in order of production: 1000, 2000, 500, 1500, 2500, 3000, 3000UX, 3000T, CDTV, 500+, 600, 4000, 1200, CD32, and 4000T. The PowerPC based AmigaOne computers were later marketed since 2002. Several companies and private persons have also released Amiga clones and still do so today.

The first Amiga model, the Amiga 1000, was launched in 1985. In 2006, PC World rated the Amiga 1000 as the seventh greatest PC of all time, stating "Years ahead of its time, the Amiga was the world's first multimedia, multitasking personal computer".

Commodore updated the desktop line of Amiga computers with the Amiga 2000 in 1987, the Amiga 3000 in 1990, and the Amiga 4000 in 1992, each offering improved capabilities and expansion options. However, the best selling models were the budget models, particularly the highly successful Amiga 500 (1987) and the Amiga 1200 (1992). The Amiga 500+ (1991) was the shortest lived model, replacing the Amiga 500 and lasting only six months until it was phased out and replaced with the Amiga 600 (1992), which in turn was also quickly replaced by the Amiga 1200.

The CDTV, launched in 1991, was a CD-ROM based all-in-one multimedia system. It was an early attempt at a multi-purpose multimedia appliance in an era before multimedia consoles and CD-ROM drives were common. Unfortunately for Commodore, the system never achieved any real commercial success. Like the Commodore 64GS that was a video game console based on a computer, the CDTV was designed as a video game console and multimedia platform. It had existed before the Sony PlayStation and Sega Saturn, but had influenced them. It competed with the Turbo-Grafx CD and Sega CD system add ons when it was being sold.

Commodore's last Amiga offering before filing for bankruptcy was an attempt to capture a portion of the highly competitive 1990s console market with the Amiga CD32 (1993), a 32-bit CD-ROM games console. Although discontinued after Commodore's demise it met with moderate commercial success in Europe. The CD32 was a next generation CDTV, and it was designed to save Commodore by entering the growing video game console market.

Following purchase of Commodore's assets by Escom in 1995, the A1200 and A4000T continued to be sold in small quantities until 1996, though the ground lost since the initial launch and the prohibitive expense of these units meant that the Amiga line never regained any real popularity.

Several Amiga models contained references to songs by the rock band The B-52's. Early A500 units had the words "B52/ROCK LOBSTER" silk-screen printed onto their printed circuit board, a reference to the song "Rock Lobster" The Amiga 600 referenced "JUNE BUG" (after the song "Junebug") and the Amiga 1200 had "CHANNEL Z" (after "Channel Z")., and the CD-32 had "Spellbound."

AmigaOS 4 is designed for PowerPC Amiga systems. It is mainly based on AmigaOS 3.1 source code, with some parts of version 3.9. Currently runs on both Amigas equipped with CyberstormPPC or BlizzardPPC accelerator boards, on the Teron series based AmigaOne computers built by Eyetech under license by Amiga, Inc., on the Pegasos II from Genesi/bPlan GmbH, on the ACube Systems Srl Sam440ep / Sam460ex / AmigaOne 500 systems and on the A-EON AmigaOne X1000.

AmigaOS 4.0 had been available only in developer pre-releases for numerous years until it was officially released in December 2006. Due to the nature of some provisions of the contract between Amiga Inc. and Hyperion Entertainment (the Belgian company which is developing the OS), the commercial AmigaOS 4 had been available only to licensed buyers of AmigaOne motherboards.

AmigaOS 4.0 for Amigas equipped with PowerUP accelerator boards was released in November 2007. Version 4.1 was released in August 2008 for AmigaOne systems, and in May 2011 for Amigas equipped with PowerUP accelerator boards. The most recent release of AmigaOS for all supported platforms is 4.1 update 5. Starting with release 4.1 update 4 there is an Emulation drawer containing official AmigaOS 3.x ROMs (all classic Amiga models including CD32) and relative Workbench files.

Acube Systems entered an agreement with Hyperion under which it has ported AmigaOS 4 to its Sam440ep and Sam460ex line of PowerPC-based motherboards. In 2009 a version for Pegasos II was released in co-operation with Acube Systems. In 2012, A-EON Technology Ltd manufactured and released the AmigaOne X1000 to consumers through their partner, Amiga Kit who provided end-user support, assembly and worldwide distribution of the new system.

Long-time Amiga developer MacroSystem entered the Amiga-clone market with their DraCo non-linear video editing system. It appears in two versions, initially a tower model and later a cube. DraCo expanded upon and combined a number of earlier expansion cards developed for Amiga (VLabMotion, Toccata, WarpEngine, RetinaIII) into a true Amiga-clone powered by the Motorola 68060 processor. The DraCo can run AmigaOS 3.1 up through AmigaOS 3.9. It is the only Amiga-based system to support FireWire for video I/O. DraCo also offers an Amiga-compatible Zorro-II expansion bus and introduced a faster custom DraCoBus, capable of transfer rates (faster than Commodore's Zorro-III). The technology was later used in the Casablanca system, a set-top-box also designed for non-linear video editing.

In 1998, Index Information released the Access, an Amiga-clone similar to the Amiga 1200, but on a motherboard which could fit into a standard 5¼" drive bay. It features either a 68020 or 68030 CPU, with a redesigned AGA chipset, and runs AmigaOS 3.1.

In 1998, former Amiga employees (John Smith, Peter Kittel, Dave Haynie and Andy Finkel to mention few) formed a new company called PIOS. Their hardware platform, PIOS One, was aimed at Amiga, Atari and Macintosh users. The company was renamed to Met@box in 1999 until it folded.

The NatAmi (short for "Native Amiga") hardware project began in 2005 with the aim of designing and building an Amiga clone motherboard that is enhanced with modern features. The NatAmi motherboard is a standard Mini-ITX-compatible form factor computer motherboard, powered by a Motorola/Freescale 68060 and its chipset. It is compatible with the original Amiga chipset, which has been inscribed on a programmable FPGA Altera chip on the board. The NatAmi is the second Amiga clone project after the Minimig motherboard, and its history is very similar to that of the C-One mainboard developed by Jeri Ellsworth and Jens Schönfeld. From a commercial point of view, Natami's circuitry and design are currently closed source. One goal of the NatAmi project is to design an Amiga-compatible motherboard that includes up-to-date features but that does not rely on emulation (as in WinUAE), modern PC Intel components, or a modern PowerPC mainboard. As such, NatAmi is not intended to become another evolutionary heir to classic Amigas, such as with AmigaOne or Pegasos computers. This "purist" philosophy essentially limits the resulting processor speed but puts the focus on bandwidth and low latencies. The developers also recreated the entire Amiga chipset, freeing it from legacy Amiga limitations such as two megabytes of audio and video graphics RAM as in the AGA chipset, and rebuilt this new chipset by programming a modern FPGA Altera Cyclone IV chip. Later, the developers decided to create from scratch a new software-form processor chip, codenamed "N68050" that resides in the physical Altera FPGA programmable chip.

In 2006, two new Amiga clones were announced, both using FPGA based hardware synthesis to replace the Amiga OCS custom chipset. The first, the Minimig, is a personal project of Dutch engineer Dennis van Weeren. Referred to as "new Amiga hardware", the original model was built on a Xilinx Spartan-3 development board, but soon a dedicated board was developed. The minimig uses the FPGA to reproduce the custom Denise, Agnus, Paula and Gary chips as well as both 8520 CIAs and implements a simple version of Amber. The rest of the chips are an actual 68000 CPU, ram chips, and a PIC microcontroller for BIOS control. The design for Minimig was released as open-source on July 25, 2007. In February 2008, an Italian company Acube Systems began selling Minimig boards. A third party upgrade replaces the PIC microcontroller with a more powerful ARM processor, providing more functionality such as write access and support for hard disk images. The Minimig core has been ported to the FPGArcade "Replay" board. The Replay uses an FPGA with about more capacity and which does support the AGA chipset and a 68020 soft core with 68030 capabilities. The Replay board is designed to implement many older computers and classic arcade machines.

The second is the Clone-A system announced by Individual Computers. As of mid 2007 it has been shown in its development form, with FPGA-based boards replacing the Amiga chipset and mounted on an Amiga 500 motherboard.

Like many popular but discontinued platforms, the Amiga has been emulated so that software developed for the Amiga can be run on other computer platforms without the original hardware. Such emulators attempt to replicate the functionality of the Amiga architecture in software. As mentioned above, attempts have also been made to replicate the Amiga chipset in FPGA chips.

One of the most challenging aspects of emulation is the design of the Amiga chipset, which relies on cycle-critical timings. As a result, early emulators did not always achieve the intended results though later emulator versions can now accurately reproduce the behavior of Amiga systems.

AmigaOS is a single-user multitasking operating system. It was developed first by Commodore International, and initially introduced in 1985 with the Amiga 1000. Original versions run on the Motorola 68000 series of microprocessors, while AmigaOS 4 runs only on PowerPC microprocessors. At the time of release AmigaOS put an operating system that was well ahead of its time into the hands of the average consumer. It was one of the first commercially available consumer operating systems for personal computers to implement preemptive multitasking.

Another notable feature was the combined use of both a command-line interface and graphical user interface. AmigaDOS was the disk operating system and command line portion of the OS and Workbench the native graphical windowing, icons, menu and pointer environment for file management and launching applications. Notably, AmigaDOS allowed long filenames (up to 107 characters) with whitespace and did not require filename extensions. The windowing system and user interface engine which handles all input events is called Intuition.

The multi-tasking kernel is called Exec. It acts as a scheduler for tasks running on the system, providing pre-emptive multitasking with prioritised round-robin scheduling. It enabled true pre-emptive multitasking in as little as 256 KB of free memory.

AmigaOS does not implement memory protection, because the 68000 CPU does not include a memory management unit. Although this speeds and eases inter-process communication because programs can communicate by simply passing a pointer back and forth, the lack of memory protection made the AmigaOS more vulnerable to crashes from badly behaving programs than other multitasking systems that did implement memory protection, and Amiga OS is fundamentally incapable of enforcing any form of security model since any program had full access to the system. A co-operational memory protection feature was implemented in AmigaOS 4 and could be retrofitted to old AmigaOS systems using Enforcer or CyberGuard tools.

The problem was somewhat exacerbated by Commodore's initial decision to release documentation relating not only to the OS's underlying software routines, but also to the hardware itself, enabling intrepid programmers who had developed their skills on the Commodore 64 to POKE the hardware directly, as was done on the older platform. While the decision to release the documentation was a popular one and allowed the creation of fast, sophisticated sound and graphics routines in games and demos, it also contributed to system instability as some programmers lacked the expertise to program at this level. For this reason, when the new AGA chipset was released, Commodore declined to release low-level documentation in an attempt to force developers into using the approved software routines.

AmigaOS directly or indirectly inspired the development of various operating systems. MorphOS and AROS clearly inherit heavily from the structure of AmigaOS as explained directly in articles regarding these two operating systems. AmigaOS also influenced BeOS, which featured a centralized system of Datatypes, similar to that present in AmigaOS. Likewise, DragonFly BSD was also inspired by AmigaOS as stated by Dragonfly developer Matthew Dillon who is a former Amiga developer. WindowLab and amiwm are among several window managers for the X Window System seek to mimic the Workbench interface. IBM licensed the Amiga GUI from Commodore in exchange for the REXX language license. This allowed OS/2 to have the WPS (Work Place Shell) GUI shell for OS/2 2.0 a 32-bit operating system.

Commodore-Amiga produced Amiga Unix, informally known as Amix, based on AT&T SVR4. It supports the Amiga 2500 and Amiga 3000 and is included with the Amiga 3000UX. Among other unusual features of Amix is a hardware-accelerated windowing system which can scroll windows without copying data. Amix is not supported on the later Amiga systems based on 68040 or 68060 processors.

Other, still maintained, operating systems are available for the classic Amiga platform, including Linux and NetBSD. Both require a CPU with MMU such as the 68020 with 68851 or full versions of the 68030, 68040 or 68060. There is also a version of Linux for Amigas with PowerPC accelerator cards. Debian and Yellow Dog Linux can run on the AmigaOne.

There is an official, older version of OpenBSD. The last Amiga release is 3.2. MINIX 1.5.10 also runs on Amiga.

The Amiga is able to emulate other computer platforms ranging from many 8-bit systems such as the ZX Spectrum, Commodore 64, Nintendo Game Boy, Nintendo Entertainment System, Apple II and the TRS-80. The Commodore PC-Transformer software emulated an IBM 5150 at 1 MHz in Monochrome mode. Later PC-Bridgecards were a full hardware PC on a card with 8086/80286/80386 Intel chips running MS-DOS and Windows in an Amiga window. A-Max emulated an Apple Macintosh using a serial port dongle that had a Macintosh ROM on it. The Amiga had the same 68000 CPU as the Macintosh and, using a Macintosh emulator, could run Mac 68K operating systems and programs. However, the Amiga could not directly read Macintosh 3.5" floppies due to their proprietary format. Further, it required a compatible Macintosh for a copy of its ROM. The Atari ST was also emulated. MAME (the arcade machine emulator) is also available for Amiga systems with PPC accelerator card upgrades.

In the late 1980s and early 1990s the platform became particularly popular for gaming, demoscene activities and creative software uses. During this time commercial developers marketed a wide range of games and creative software, often developing titles simultaneously for the Atari ST due to the similar hardware architecture. Popular creative software included 3D rendering (ray-tracing) packages, bitmap graphics editors, desktop video software, software development packages and "tracker" music editors.

Until the late 1990s the Amiga remained a popular platform for non-commercial software, often developed by enthusiasts, and much of which was freely redistributable. An on-line archive, Aminet, was created in 1992 and until around 1996 was the largest public archive of software, art and documents for any platform.

The name "Amiga" was chosen by the developers from the Spanish word for a female friend, because they knew Spanish, and because it occurred before Apple and Atari alphabetically. It also conveyed the message that the Amiga computer line was "user friendly" as a pun or play on words.

The first official Amiga logo was a rainbow-colored double check mark. In later marketing material Commodore largely dropped the checkmark and used logos styled with various typefaces. Although it was never adopted as a trademark by Commodore, the "Boing Ball" has been synonymous with Amiga since its launch. It became an unofficial and enduring theme after a visually impressive animated demonstration at the 1984 Winter Consumer Electronics Show in January 1984 showing a checkered ball bouncing and rotating. Following Escom's purchase of Commodore in 1996, the Boing Ball theme was incorporated into a new logo.

Early Commodore advertisements attempted to cast the computer as an all-purpose business machine, though the Amiga was most commercially successful as a home computer. Throughout the 1980s and early 1990s Commodore primarily placed advertising in computer magazines and occasionally in national newspapers and on television.

Since the demise of Commodore, various groups have marketed successors to the original Amiga line:


AmigaOS and MorphOS are commercial proprietary operating systems. AmigaOS 4, based on AmigaOS 3.1 source code with some parts of version 3.9, is developed by Hyperion Entertainment and runs on PowerPC based hardware. MorphOS, based on some parts of AROS source code, is developed by MorphOS Team and is continued on Apple and other PowerPC based hardware.

There is also AROS, a free and open source operating system (re-implementation of the AmigaOS 3.1 APIs), for Amiga 68k, x86 and ARM hardware (one version runs Linux-hosted on the Raspberry Pi). In particular, AROS for Amiga 68k hardware aims to create an open source Kickstart ROM replacement for emulation purpose and/or for use on real "classic" hardware.

After Commodore went bankrupt in 1994, an active Amiga community continued to support the platform long after mainstream commercial vendors abandoned it. The most popular Amiga magazine, "Amiga Format", continued to publish editions until 2000, some six years after Commodore filed for bankruptcy. Another magazine, "Amiga Active", was launched in 1999 and was published until 2001. In spite of declining interest in the platform, there was a bi-weekly specialist column in the UK weekly magazine "Micro Mart".

Several notable magazines are in publication today: "Amiga Future", which is available in both English and German; "Bitplane.it", a bi-monthly magazine in Italian; and "AmigaPower", a long-running French magazine.

The Amiga series of computers found a place in early computer graphic design and television presentation. Below are some examples of notable uses and users:

In addition, many other celebrities and notable individuals have made use of the Amiga:


The Amiga was also used in a number of special purpose applications:




</doc>
<doc id="1985" url="https://en.wikipedia.org/wiki?curid=1985" title="Absorption">
Absorption

Absorption may refer to:





</doc>
<doc id="1986" url="https://en.wikipedia.org/wiki?curid=1986" title="Actinophryid">
Actinophryid

The actinophryids are an order of heliozoa. They are the most common heliozoa in fresh water and can also be found in marine and soil habitats. Actinophryids are unicellular and roughly spherical in shape, with many axopodia that radiate outward from the cell body. Axopodia are a type of pseudopodia that are supported by hundreds of microtubules arranged in a needle-like internal structure. These axopods adhere to passing prey and assist with cell movement, as well as playing a part in cell division and cell fusion.

Actinophryids are largely aquatic protozoa with a spherical cell body and many needle-like axopodia. They resemble the shape of a sun due to this structure, which is the inspiration for their common name: heliozoa, or "sun-animalcules". They range in size from a few micrometers to a full millimeter across.

The cell body is largely vacuolated, with the ectoplasm consisting almost entirely of these structures. The endoplasm of actinophryids is often darker and denser than the outer layer, and can sometimes be seen as a sharp boundary under a light microscope. The organisms can be either mononucleate, with a single, well defined nucleus in the center of the cell body, or multinucleate, with 10 or more nuclei dispersed throughout the organism. The cytoplasm of actinophryids is often granular, similar to that of "Amoeba".
Contractile vacuoles are common in these organisms, who use them to maintain homeostasis and control buoyancy. These are visible as clear bulges from the surface of the cell body that slowly fill then rapidly deflate, expelling the contents into the environment.

The most distinctive characteristic of the actinophryids is their axopodia. These axopodia consist of a central, rigid rod which is coated in a thin layer of ectoplasm. These axonemes are rooted in the endoplasm and terminate there, sometimes close to a nucleus. The axonemes are composed microtubules arranged in a double spiral pattern characteristic of the order. Due to their long, parallel construction these microtubules demonstrate strong birefringence.

These axopodia are used for prey capture, mobility, and cell fusion and division. They can be flexible, especially when the organisms are starved, and are highly dynamic, undergoing frequent construction and destruction. When used to collect prey items, two methods of capture have been noted, termed axopodial flow and rapid axopodial contraction. Axopodial flow involves the slow movement of a prey item along the surface of the axopod as the ectoplasm itself moves, while rapid axopodial contraction involves the collapse of the axoneme's microtubule structure. This behavior has been documented in many species, including "Actinosphaerium nucleofilum", "Actinophrys sol", and "Raphidiophrys contractilis". The rapid axopodial contraction occurs at high speed, often in excess of 5mm/s or tens of body lengths per second.

The axopodial contractions have been shown to be highly sensitive to environmental factors such as temperature and pressure as well as chemical signals like Ca and colchine. They may also be triggered by mechanical or electrical stimulation.

Reproduction in actinophryids generally takes place via fission, where one parent cell divides into two or more daughter cells. For multinucleate heliozoa, this process is plasmotomic as the nuclei are not duplicated prior to division. It has been observed that reproduction appears to be a response to food scarcity, with an increased number of divisions following the removal of food and larger organisms during times of food excess.

Actinophryids also undergo autogamy during times of food scarcity. This is better described as genetic reorganization than reproduction, as the number of individuals produced is the same as the initial number. Nonetheless, it serves as a way to increase genetic diversity within an individual which may improve the likelihood of expressing favorable genetic traits.

Plastogamy has also been extensively documented in actinophryids, especially in multinucleate ones. "Actinosphaerium" were observed to combine freely without the combination of nuclei, and this process sometimes resulted in more or less individuals than originally combined. This process is not caused merely by contact between two individuals but can be caused by damage to the cell body.

Under unfavourable conditions, some species will form a cyst. This is often the product of autogamy, in which case the cysts produced are zygotes. Cells undergoing this process withdraw their axopodia, adhere to the substrate, and take on an opaque and grayish appearance. This cyst then divides until only uninucleate cells remain. The cyst wall is thickly layered 7-8 times and includes gelatinous layers, layers of silica plates, and iron.

Originally placed in Heliozoa (Sarcodina), the group's current location within the larger tree of life is debated. It may belong to either the Actinochrysophyceae (Axodines), or to Raphidomonadea.

There are several genera included within this classification. "Actinophrys" are smaller and have a single, central nucleus. Most have a cell body 40-50 micrometer in diameter with axopods around 100 μm in length, though this varies significantly. "Actinosphaerium" are several times larger, from 200-1000 μm in diameter, with many nuclei and are found exclusively in fresh water. A third genus, "Camptonema", was named as a junior subjective synonym of "Actinosphaerium" by Mikrjukov & Patterson in 2001, but Cavalier-Smith & Scoble (2013) preserve the genus. "Heliorapha" was also added to this classification by Cavalier & Smith (2013), which was previously the genus "Ciliophrys".

Classification based on Cavalier-Smith and Scoble 2013


</doc>
<doc id="1988" url="https://en.wikipedia.org/wiki?curid=1988" title="Abel Tasman">
Abel Tasman

Abel Janszoon Tasman (; 1603 – 10 October 1659) was a Dutch seafarer, explorer, and merchant, best known for his voyages of 1642 and 1644 in the service of the Dutch East India Company (VOC). He was the first known European explorer to reach the islands of Van Diemen's Land (now Tasmania) and New Zealand, and to sight the Fiji islands.

Tasman originated from Lutjegast, a small village in the province of Groningen, in the north of the Netherlands.
The oldest available source mentioning him is dated 27 December 1631 when, as a seafarer living in Amsterdam, the 28-year-old became engaged to marry 21-year-old Jannetje Tjaers, of Palmstraat in the Jordaan district of the city.

Employed by the Dutch East India Company (VOC), Tasman sailed from Texel to Batavia in 1633, taking the southern Brouwer Route. During this period, Tasman took part in a voyage to Seram Island; the locals had sold spices to other European nationalities than the Dutch. He had a narrow escape from death, when in an incautious landing several of his companions were killed by people of Seram.

In August 1637, Tasman was back in Amsterdam, and the following year he signed on for another ten years and took his wife with him to Batavia. On 25 March 1638 he tried to sell his property in the Jordaan, but the purchase was cancelled.

He was second-in-command of a 1639 exploration expedition in the north Pacific under Matthijs Quast. The fleet included the ships "Engel" and "Gracht" and reached Fort Zeelandia (Dutch Formosa) and Deshima.

In August 1642, the Council of the Indies, consisting of Antonie van Diemen, Cornelis van der Lijn, Joan Maetsuycker, Justus Schouten, Salomon Sweers, Cornelis Witsen, and Pieter Boreel in Batavia despatched Tasman and Franchoijs Jacobszoon Visscher on a voyage of exploration to little-charted areas east of the Cape of Good Hope, west of Staten Land (near Cape Horn, South America) and south of the Solomon Islands.

One of the objectives was to obtain knowledge of "all the totally unknown" Provinces of Beach: a purported, yet non-existent landmass with plentiful gold (which had appeared on European maps since the 15th century, as a result of an error in some editions of Marco Polo's works – see the box, right for more information).

This expedition was to use two small ships, "Heemskerck" and "Zeehaen".

In accordance with Visscher's directions, Tasman sailed from Batavia on 14 August 1642 and arrived at Mauritius on 5 September 1642, according to the captain's journal. The reason for this was the crew could be fed well on the island; there was plenty of fresh water and timber to repair the ships. Tasman got the assistance of the governor Adriaan van der Stel.

Because of the prevailing winds Mauritius was chosen as a turning point. After a four-week stay on the island both ships left on 8 October using the Roaring Forties to sail east as fast as possible. (No-one had gone as far as Pieter Nuyts in 1626/27.) On 7 November snow and hail influenced the ship's council to alter course to a more north-eastern direction, expecting to arrive one day at the Solomon Islands.

On 24 November 1642 Abel Tasman reached and sighted the west coast of Tasmania, north of Macquarie Harbour. He named his discovery Van Diemen's Land after Antonio van Diemen, Governor-General of the Dutch East Indies.

Proceeding south Tasman skirted the southern end of Tasmania and turned north-east. He then tried to work his two ships into Adventure Bay on the east coast of South Bruny Island where he was blown out to sea by a storm. This area he named Storm Bay. Two days later, on December 1, Tasman anchored to the north of Cape Frederick Hendrick just north of the Forestier Peninsula. On December 2, two ship's boats under the command of the Pilot Major Visscher, rowed through the Marion Narrows into Blackman Bay, and across the west to the outflow of Boomer Creek where they gather some edible "greens". Tasman named Frederick Hendrik Bay, which included the present North Bay, Marion Bay and the inlet Blackman Bay (The name Frederick Henry Bay was mistakenly transferred to its present location by Marion Dufresne in 1772). The next day, an attempt was made to land in North Bay. However, because the sea was too rough the carpenter swam through the surf and planted the Dutch flag. Tasman then claimed formal possession of the land on 3 December 1642.

For two more days, he continued to follow the east coast northward to see how far it went. When the land veered to the north-west at Eddystone Point, he tried to keep in with it but his ships were suddenly hit by the Roaring Forties howling through Bass Strait. The impenetrable wind wall indicated that here was a strait, not a bay. Tasman was on a mission to find the Southern Continent, not more islands, so he abruptly turned away to the east and continued his continent-hunting.

After some exploration, Tasman had intended to proceed in a northerly direction but as the wind was unfavourable he steered east. The expedition endured an extremely rough voyage and in one of his diary entries Tasman credited his compass, claiming it was the only thing that had kept him alive.

On 13 December 1642 they sighted land on the north-west coast of the South Island, New Zealand, becoming the first Europeans to sight New Zealand. Tasman named it "Staten Landt" "in honour of the States General" (Dutch parliament). He wrote, "it is possible that this land joins to the Staten Land but it is uncertain", referring to Isla de los Estados, a landmass of the same name at the southern tip of South America, discovered by the Dutch navigator Jacob Le Maire in 1616. He continued: "We believe that this is the mainland coast of the unknown Southland." Tasman thought he had found the western side of the long-imagined Terra Australis that stretched across the Pacific to near the southern tip of South America.

After sailing north, then east for five days, the expedition anchored about 7 km from the coast off what is now believed to have been Golden Bay. Tasman sent ship's boats to gather water, but one of his boats was attacked by Māori in a double-hulled waka (canoe) and four of his men were killed with mere (clubs). As Tasman sailed out of the bay he observed 22 waka near the shore, of which "eleven swarming with people came off towards us." The waka approached the "Zeehaen" which fired and hit a man in the largest waka holding a small white flag. Canister shot also hit the side of a waka. Archeological research has shown the Dutch had tried to land at a major agricultural area, which the Māori may have been trying to protect. Tasman named the area "Murderers' Bay".

The expedition then sailed north, sighting Cook Strait, which it mistook for a bight and named "Zeehaen's Bight". Two names that the expedition gave to landmarks in the far north of New Zealand still endure: Cape Maria van Diemen and Three Kings Islands. ("Kaap Pieter Boreels" was renamed Cape Egmont by Captain James Cook 125 years later.)

En route back to Batavia, Tasman came across the Tongan archipelago on 20 January 1643. While passing the Fiji Islands Tasman's ships came close to being wrecked on the dangerous reefs of the north-eastern part of the Fiji group. He charted the eastern tip of Vanua Levu and Cikobia before making his way back into the open sea.

The expedition turned north-west towards New Guinea and arrived at Batavia on 15 June 1643.

Tasman left Batavia on 30 January 1644 on his second voyage with three ships ("Limmen", "Zeemeeuw" and the tender "Braek"). He followed the south coast of New Guinea eastwards in an attempt to find a passage to the eastern side of New Holland. However, he missed the Torres Strait between New Guinea and Australia, probably due to the numerous reefs and islands obscuring potential routes, and continued his voyage by following the shore of the Gulf of Carpentaria westwards along the north Australian coast. He mapped the north coast of Australia making observations on New Holland, and its people. He arrived back in Batavia in August 1644.

From the point of view of the Dutch East India Company, Tasman's explorations were a disappointment: he had neither found a promising area for trade nor a useful new shipping route. Although received modestly, the company was upset to a degree that Tasman did not fully explore the lands he found, and decided that a more "persistent explorer" should be chosen for any future expeditions. For over a century, until the era of James Cook, Tasmania and New Zealand were not visited by Europeans – mainland Australia was visited, but usually only by accident.

On 2 November 1644 Abel Tasman was appointed a member of the Council of Justice at Batavia. He went to Sumatra in 1646, and in August 1647 to Siam (now Thailand) with letters from the company to the King. In May 1648 he was in charge of an expedition sent to Manila to try to intercept and loot the Spanish silver ships coming from America, but he had no success and returned to Batavia in January 1649. In November 1649 he was charged and found guilty of having in the previous year hanged one of his men without trial, was suspended from his office of commander, fined, and made to pay compensation to the relatives of the sailor. On 5 January 1651 he was formally reinstated in his rank and spent his remaining years at Batavia. He was in good circumstances, being one of the larger landowners in the town. He died at Batavia on 10 October 1659 and was survived by his second wife and a daughter by his first wife. His property was divided between his wife and his daughter by his first marriage. In his testimony (dating from 1657) he left 25 guilders to the poor of his village Lutjegast.

Although Tasman's pilot, Frans Visscher, published "Memoir concerning the discovery of the South land" in 1642, Tasman's detailed journal was not published until 1898; however, some of his charts and maps were in general circulation and used by subsequent explorers.

Tasman's ten-month voyage in 1642-43 had significant consequences. By circumnavigating Australia (albeit at a distance) Tasman proved that the small fifth continent was not joined to any larger sixth continent, such as the long-imagined Southern Continent. Further, Tasman's suggestion that New Zealand was the western side of that Southern Continent was seized upon by many European cartographers who, for the next century, depicted New Zealand as the west coast of a Terra Australis rising gradually from the waters around Tierra del Fuego. This theory was eventually disproved when Captain Cook circumnavigated New Zealand in 1769.

Multiple places have been named after Tasman, including:
Also named after Tasman are:


His portrait has been on 4 New Zealand postage stamp issues, on a 1992 5 NZD coin, and on 1963, 1966 and 1985 Australian postage stamps.

In The Netherlands many streets are named after him. In Lutjegast, the village he was born, there is a museum dedicated to his life and travels.

Held within the collection of the State Library of New South Wales is the Tasman Map, thought to have been drawn by Isaac Gilsemans, or completed under the supervision of Franz Jacobszoon Visscher. The map is also known as the Bonaparte map, as it was once owned by Prince Roland Bonaparte, the great-nephew of Napoleon. The map was completed sometime after 1644 and is based on the original charts drawn during Tasman's first and second voyages. As none of the journals or logs composed during Tasman's second voyage have survived, the Bonaparte map remains as an important contemporary artefact of Tasman's voyage to the northern coast of the Australian continent.

The Tasman map largely reveals the extent of understanding the Dutch had of the Australian continent at the time. The map includes the western and southern coasts of Australia, accidentally encountered by Dutch voyagers as they journeyed by way of the Cape of Good Hope to the VOC headquarters in Batavia. In addition, the map shows the tracks of Tasman's two voyages. Of his second voyage, the map shows the area of the Banda Islands, the southern coast of New Guinea and much of the northern coast of Australia. However, the area of the Torres Strait is shown unexamined; this is despite having been given orders by VOC Council at Batavia to explore the possibility of a channel between New Guinea and the Australian continent.

There is debate as to the origin of the map. It is widely believed that the map was produced in Batavia; however, it has also been argued that the map was produced in Amsterdam. The authorship of the map has also been debated: while the map is commonly attributed to Tasman, it is now thought to have been the result of a collaboration, probably involving Franchoijs Visscher and Isaack Gilsemans, who took part in both of Tasman's voyages. Whether the map was produced in 1644 is also subject to debate, as a VOC company report in December 1644 suggests that at that time no maps showing Tasman's voyages were yet complete.

In 1943, a mosaic version of the map, composed of coloured marble and brass, was inlaid into the vestibule floor of the Mitchell Library in Sydney. The work was commissioned by the Principal Librarian William Ifould, and completed by the Melocco Brothers of Annandale, who also worked on ANZAC War Memorial in Hyde Park and the crypt at St Mary's Cathedral, Sydney.





</doc>
<doc id="1990" url="https://en.wikipedia.org/wiki?curid=1990" title="August 5">
August 5





</doc>
<doc id="1991" url="https://en.wikipedia.org/wiki?curid=1991" title="Angula">
Angula

The word Angula may refer to one of the following:



</doc>
<doc id="1994" url="https://en.wikipedia.org/wiki?curid=1994" title="ASP">
ASP

ASP may refer to:











</doc>
<doc id="1997" url="https://en.wikipedia.org/wiki?curid=1997" title="Algebraic geometry">
Algebraic geometry

Algebraic geometry is a branch of mathematics, classically studying zeros of multivariate polynomials. Modern algebraic geometry is based on the use of abstract algebraic techniques, mainly from commutative algebra, for solving geometrical problems about these sets of zeros.

The fundamental objects of study in algebraic geometry are algebraic varieties, which are geometric manifestations of solutions of systems of polynomial equations. Examples of the most studied classes of algebraic varieties are: plane algebraic curves, which include lines, circles, parabolas, ellipses, hyperbolas, cubic curves like elliptic curves, and quartic curves like lemniscates and Cassini ovals. A point of the plane belongs to an algebraic curve if its coordinates satisfy a given polynomial equation. Basic questions involve the study of the points of special interest like the singular points, the inflection points and the points at infinity. More advanced questions involve the topology of the curve and relations between the curves given by different equations.

Algebraic geometry occupies a central place in modern mathematics and has multiple conceptual connections with such diverse fields as complex analysis, topology and number theory. Initially a study of systems of polynomial equations in several variables, the subject of algebraic geometry starts where equation solving leaves off, and it becomes even more important to understand the intrinsic properties of the totality of solutions of a system of equations, than to find a specific solution; this leads into some of the deepest areas in all of mathematics, both conceptually and in terms of technique.
In the 20th century, algebraic geometry split into several subareas.

Much of the development of the mainstream of algebraic geometry in the 20th century occurred within an abstract algebraic framework, with increasing emphasis being placed on "intrinsic" properties of algebraic varieties not dependent on any particular way of embedding the variety in an ambient coordinate space; this parallels developments in topology, differential and complex geometry. One key achievement of this abstract algebraic geometry is Grothendieck's scheme theory which allows one to use sheaf theory to study algebraic varieties in a way which is very similar to its use in the study of differential and analytic manifolds. This is obtained by extending the notion of point: In classical algebraic geometry, a point of an affine variety may be identified, through Hilbert's Nullstellensatz, with a maximal ideal of the coordinate ring, while the points of the corresponding affine scheme are all prime ideals of this ring. This means that a point of such a scheme may be either a usual point or a subvariety. This approach also enables a unification of the language and the tools of classical algebraic geometry, mainly concerned with complex points, and of algebraic number theory. Wiles' proof of the longstanding conjecture called Fermat's last theorem is an example of the power of this approach.

In classical algebraic geometry, the main objects of interest are the vanishing sets of collections of polynomials, meaning the set of all points that simultaneously satisfy one or more polynomial equations. For instance, the two-dimensional sphere of radius 1 in three-dimensional Euclidean space R could be defined as the set of all points ("x","y","z") with

A "slanted" circle in R can be defined as the set of all points ("x","y","z") which satisfy the two polynomial equations

First we start with a field "k". In classical algebraic geometry, this field was always the complex numbers C, but many of the same results are true if we assume only that "k" is algebraically closed. We consider the affine space of dimension "n" over "k", denoted A("k") (or more simply A, when "k" is clear from the context). When one fixes a coordinate system, one may identify A("k") with "k". The purpose of not working with "k" is to emphasize that one "forgets" the vector space structure that "k" carries.

A function "f" : A → A is said to be "polynomial" (or "regular") if it can be written as a polynomial, that is, if there is a polynomial "p" in "k"["x"...,"x"] such that "f"("M") = "p"("t"...,"t") for every point "M" with coordinates ("t"...,"t") in A. The property of a function to be polynomial (or regular) does not depend on the choice of a coordinate system in A.

When a coordinate system is chosen, the regular functions on the affine "n"-space may be identified with the ring of polynomial functions in "n" variables over "k". Therefore, the set of the regular functions on A is a ring, which is denoted "k"[A].

We say that a polynomial "vanishes" at a point if evaluating it at that point gives zero. Let "S" be a set of polynomials in "k"[A]. The "vanishing set of S" (or "vanishing locus" or "zero set") is the set "V"("S") of all points in A where every polynomial in "S" vanishes. Symbolically,

A subset of A which is "V"("S"), for some "S", is called an "algebraic set". The "V" stands for "variety" (a specific type of algebraic set to be defined below).

Given a subset "U" of A, can one recover the set of polynomials which generate it? If "U" is "any" subset of A, define "I"("U") to be the set of all polynomials whose vanishing set contains "U". The "I" stands for ideal: if two polynomials "f" and "g" both vanish on "U", then "f"+"g" vanishes on "U", and if "h" is any polynomial, then "hf" vanishes on "U", so "I"("U") is always an ideal of the polynomial ring "k"[A].

Two natural questions to ask are:

The answer to the first question is provided by introducing the Zariski topology, a topology on A whose closed sets are the algebraic sets, and which directly reflects the algebraic structure of "k"[A]. Then "U" = "V"("I"("U")) if and only if "U" is an algebraic set or equivalently a Zariski-closed set. The answer to the second question is given by Hilbert's Nullstellensatz. In one of its forms, it says that "I"("V"("S")) is the radical of the ideal generated by "S". In more abstract language, there is a Galois connection, giving rise to two closure operators; they can be identified, and naturally play a basic role in the theory; the example is elaborated at Galois connection.

For various reasons we may not always want to work with the entire ideal corresponding to an algebraic set "U". Hilbert's basis theorem implies that ideals in "k"[A] are always finitely generated.

An algebraic set is called "irreducible" if it cannot be written as the union of two smaller algebraic sets. Any algebraic set is a finite union of irreducible algebraic sets and this decomposition is unique. Thus its elements are called the "irreducible components" of the algebraic set. An irreducible algebraic set is also called a "variety". It turns out that an algebraic set is a variety if and only if it may be defined as the vanishing set of a prime ideal of the polynomial ring.

Some authors do not make a clear distinction between algebraic sets and varieties and use "irreducible variety" to make the distinction when needed.

Just as continuous functions are the natural maps on topological spaces and smooth functions are the natural maps on differentiable manifolds, there is a natural class of functions on an algebraic set, called "regular functions" or "polynomial functions". A regular function on an algebraic set "V" contained in A is the restriction to "V" of a regular function on A. For an algebraic set defined on the field of the complex numbers, the regular functions are smooth and even analytic.

It may seem unnaturally restrictive to require that a regular function always extend to the ambient space, but it is very similar to the situation in a normal topological space, where the Tietze extension theorem guarantees that a continuous function on a closed subset always extends to the ambient topological space.

Just as with the regular functions on affine space, the regular functions on "V" form a ring, which we denote by "k"["V"]. This ring is called the "coordinate ring of V".

Since regular functions on V come from regular functions on A, there is a relationship between the coordinate rings. Specifically, if a regular function on "V" is the restriction of two functions "f" and "g" in "k"[A], then "f" − "g" is a polynomial function which is null on "V" and thus belongs to "I"("V"). Thus "k"["V"] may be identified with "k"[A]/"I"("V").

Using regular functions from an affine variety to A, we can define regular maps from one affine variety to another. First we will define a regular map from a variety into affine space: Let "V" be a variety contained in A. Choose "m" regular functions on "V", and call them "f", ..., "f". We define a "regular map" "f" from "V" to A by letting . In other words, each "f" determines one coordinate of the range of "f".

If "V"′ is a variety contained in A, we say that "f" is a "regular map" from "V" to "V"′ if the range of "f" is contained in "V"′.

The definition of the regular maps apply also to algebraic sets.
The regular maps are also called "morphisms", as they make the collection of all affine algebraic sets into a category, where the objects are the affine algebraic sets and the morphisms are the regular maps. The affine varieties is a subcategory of the category of the algebraic sets.

Given a regular map "g" from "V" to "V"′ and a regular function "f" of "k"["V"′], then . The map is a ring homomorphism from "k"["V"′] to "k"["V"]. Conversely, every ring homomorphism from "k"["V"′] to "k"["V"] defines a regular map from "V" to "V"′. This defines an equivalence of categories between the category of algebraic sets and the opposite category of the finitely generated reduced "k"-algebras. This equivalence is one of the starting points of scheme theory.

In contrast to the preceding sections, this section concerns only varieties and not algebraic sets. On the other hand, the definitions extend naturally to projective varieties (next section), as an affine variety and its projective completion have the same field of functions.

If "V" is an affine variety, its coordinate ring is an integral domain and has thus a field of fractions which is denoted "k"("V") and called the "field of the rational functions" on "V" or, shortly, the "function field" of "V". Its elements are the restrictions to "V" of the rational functions over the affine space containing "V". The domain of a rational function "f" is not "V" but the complement of the subvariety (a hypersurface) where the denominator of "f" vanishes.

As with regular maps, one may define a "rational map" from a variety "V" to a variety "V"<nowiki>'</nowiki>. As with the regular maps, the rational maps from "V" to "V"<nowiki>'</nowiki> may be identified to the field homomorphisms from "k"("V"<nowiki>'</nowiki>) to "k"("V").

Two affine varieties are "birationally equivalent" if there are two rational functions between them which are inverse one to the other in the regions where both are defined. Equivalently, they are birationally equivalent if their function fields are isomorphic.

An affine variety is a "rational variety" if it is birationally equivalent to an affine space. This means that the variety admits a rational parameterization. For example, the circle of equation formula_5 is a rational curve, as it has the parameterization
which may also be viewed as a rational map from the line to the circle.

The problem of resolution of singularities is to know if every algebraic variety is birationally equivalent to a variety whose projective completion is nonsingular (see also smooth completion). It was solved in the affirmative in characteristic 0 by Heisuke Hironaka in 1964 and is yet unsolved in finite characteristic.

Just as the formulas for the roots of second, third, and fourth degree polynomials suggest extending real numbers to the more algebraically complete setting of the complex numbers, many properties of algebraic varieties suggest extending affine space to a more geometrically complete projective space. Whereas the complex numbers are obtained by adding the number "i", a root of the polynomial , projective space is obtained by adding in appropriate points "at infinity", points where parallel lines may meet.

To see how this might come about, consider the variety . If we draw it, we get a parabola. As "x" goes to positive infinity, the slope of the line from the origin to the point ("x", "x") also goes to positive infinity. As "x" goes to negative infinity, the slope of the same line goes to negative infinity.

Compare this to the variety "V"("y" − "x"). This is a cubic curve. As "x" goes to positive infinity, the slope of the line from the origin to the point ("x", "x") goes to positive infinity just as before. But unlike before, as "x" goes to negative infinity, the slope of the same line goes to positive infinity as well; the exact opposite of the parabola. So the behavior "at infinity" of "V"("y" − "x") is different from the behavior "at infinity" of "V"("y" − "x").

The consideration of the "projective completion" of the two curves, which is their prolongation "at infinity" in the projective plane, allows us to quantify this difference: the point at infinity of the parabola is a regular point, whose tangent is the line at infinity, while the point at infinity of the cubic curve is a cusp. Also, both curves are rational, as they are parameterized by "x", and the Riemann-Roch theorem implies that the cubic curve must have a singularity, which must be at infinity, as all its points in the affine space are regular.

Thus many of the properties of algebraic varieties, including birational equivalence and all the topological properties, depend on the behavior "at infinity" and so it is natural to study the varieties in projective space. Furthermore, the introduction of projective techniques made many theorems in algebraic geometry simpler and sharper: For example, Bézout's theorem on the number of intersection points between two varieties can be stated in its sharpest form only in projective space. For these reasons, projective space plays a fundamental role in algebraic geometry.

Nowadays, the "projective space" P of dimension "n" is usually defined as the set of the lines passing through a point, considered as the origin, in the affine space of dimension , or equivalently to the set of the vector lines in a vector space of dimension . When a coordinate system has been chosen in the space of dimension , all the points of a line have the same set of coordinates, up to the multiplication by an element of "k". This defines the homogeneous coordinates of a point of P as a sequence of elements of the base field "k", defined up to the multiplication by a nonzero element of "k" (the same for the whole sequence).

A polynomial in variables vanishes at all points of a line passing through the origin if and only if it is homogeneous. In this case, one says that the polynomial "vanishes" at the corresponding point of P. This allows us to define a "projective algebraic set" in P as the set , where a finite set of homogeneous polynomials vanishes. Like for affine algebraic sets, there is a bijection between the projective algebraic sets and the reduced homogeneous ideals which define them. The "projective varieties" are the projective algebraic sets whose defining ideal is prime. In other words, a projective variety is a projective algebraic set, whose homogeneous coordinate ring is an integral domain, the "projective coordinates ring" being defined as the quotient of the graded ring or the polynomials in variables by the homogeneous (reduced) ideal defining the variety. Every projective algebraic set may be uniquely decomposed into a finite union of projective varieties.

The only regular functions which may be defined properly on a projective variety are the constant functions. Thus this notion is not used in projective situations. On the other hand, the "field of the rational functions" or "function field " is a useful notion, which, similarly to the affine case, is defined as the set of the quotients of two homogeneous elements of the same degree in the homogeneous coordinate ring.

Real algebraic geometry is the study of the real points of algebraic varieties.

The fact that the field of the real numbers is an ordered field cannot be ignored in such a study. For example, the curve of equation formula_8 is a circle if formula_9, but does not have any real point if formula_10. It follows that real algebraic geometry is not only the study of the real algebraic varieties, but has been generalized to the study of the "semi-algebraic sets", which are the solutions of systems of polynomial equations and polynomial inequalities. For example, a branch of the hyperbola of equation formula_11 is not an algebraic variety, but is a semi-algebraic set defined by formula_12 and formula_13 or by formula_12 and formula_15.

One of the challenging problems of real algebraic geometry is the unsolved Hilbert's sixteenth problem: Decide which respective positions are possible for the ovals of a nonsingular plane curve of degree 8.

One may date the origin of computational algebraic geometry to meeting EUROSAM'79 (International Symposium on Symbolic and Algebraic Manipulation) held at Marseille, France in June 1979. At this meeting,

Since then, most results in this area are related to one or several of these items either by using or improving one of these algorithms, or by finding algorithms whose complexity is simply exponential in the number of the variables.

A body of mathematical theory complementary to symbolic methods called numerical algebraic geometry has been developed over the last several decades. The main computational method is homotopy continuation. This supports, for example, a model of floating point computation for solving problems of algebraic geometry.

A Gröbner basis is a system of generators of a polynomial ideal whose computation allows the deduction of many properties of the affine algebraic variety defined by the ideal.

Given an ideal "I" defining an algebraic set "V":

Gröbner basis computations do not allow one to compute directly the primary decomposition of "I" nor the prime ideals defining the irreducible components of "V", but most algorithms for this involve Gröbner basis computation. The algorithms which are not based on Gröbner bases use regular chains but may need Gröbner bases in some exceptional situations.

Gröbner bases are deemed to be difficult to compute. In fact they may contain, in the worst case, polynomials whose degree is doubly exponential in the number of variables and a number of polynomials which is also doubly exponential. However, this is only a worst case complexity, and the complexity bound of Lazard's algorithm of 1979 may frequently apply. Faugère F5 algorithm realizes this complexity, as it may be viewed as an improvement of Lazard's 1979 algorithm. It follows that the best implementations allow one to compute almost routinely with algebraic sets of degree more than 100. This means that, presently, the difficulty of computing a Gröbner basis is strongly related to the intrinsic difficulty of the problem.

CAD is an algorithm which was introduced in 1973 by G. Collins to implement with an acceptable complexity the Tarski–Seidenberg theorem on quantifier elimination over the real numbers.

This theorem concerns the formulas of the first-order logic whose atomic formulas are polynomial equalities or inequalities between polynomials with real coefficients. These formulas are thus the formulas which may be constructed from the atomic formulas by the logical operators "and" (∧), "or" (∨), "not" (¬), "for all" (∀) and "exists" (∃). Tarski's theorem asserts that, from such a formula, one may compute an equivalent formula without quantifier (∀, ∃).

The complexity of CAD is doubly exponential in the number of variables. This means that CAD allows, in theory, to solve every problem of real algebraic geometry which may be expressed by such a formula, that is almost every problem concerning explicitly given varieties and semi-algebraic sets.

While Gröbner basis computation has doubly exponential complexity only in rare cases, CAD has almost always this high complexity. This implies that, unless if most polynomials appearing in the input are linear, it may not solve problems with more than four variables.

Since 1973, most of the research on this subject is devoted either to improve CAD or to find alternative algorithms in special cases of general interest.

As an example of the state of art, there are efficient algorithms to find at least a point in every connected component of a semi-algebraic set, and thus to test if a semi-algebraic set is empty. On the other hand, CAD is yet, in practice, the best algorithm to count the number of connected components.

The basic general algorithms of computational geometry have a double exponential worst case complexity. More precisely, if "d" is the maximal degree of the input polynomials and "n" the number of variables, their complexity is at most formula_16 for some constant "c", and, for some inputs, the complexity is at least formula_17 for another constant "c"′.

During the last 20 years of 20th century, various algorithms have been introduced to solve specific subproblems with a better complexity. Most of these algorithms have a complexity formula_18.

Among these algorithms which solve a sub problem of the problems solved by Gröbner bases, one may cite "testing if an affine variety is empty" and "solving nonhomogeneous polynomial systems which have a finite number of solutions." Such algorithms are rarely implemented because, on most entries Faugère's F4 and F5 algorithms have a better practical efficiency and probably a similar or better complexity ("probably" because the evaluation of the complexity of Gröbner basis algorithms on a particular class of entries is a difficult task which has been done only in a few special cases).

The main algorithms of real algebraic geometry which solve a problem solved by CAD are related to the topology of semi-algebraic sets. One may cite "counting the number of connected components", "testing if two points are in the same components" or "computing a Whitney stratification of a real algebraic set". They have a complexity of
formula_18, but the constant involved by "O" notation is so high that using them to solve any nontrivial problem effectively solved by CAD, is impossible even if one could use all the existing computing power in the world. Therefore, these algorithms have never been implemented and this is an active research area to search for algorithms with have together a good asymptotic complexity and a good practical efficiency.

The modern approaches to algebraic geometry redefine and effectively extend the range of basic objects in various levels of generality to schemes, formal schemes, ind-schemes, algebraic spaces, algebraic stacks and so on. The need for this arises already from the useful ideas within theory of varieties, e.g. the formal functions of Zariski can be accommodated by introducing nilpotent elements in structure rings; considering spaces of loops and arcs, constructing quotients by group actions and developing formal grounds for natural intersection theory and deformation theory lead to some of the further extensions.

Most remarkably, in late 1950s, algebraic varieties were subsumed into Alexander Grothendieck's concept of a scheme. Their local objects are affine schemes or prime spectra which are locally ringed spaces which form a category which is antiequivalent to the category of commutative unital rings, extending the duality between the category of affine algebraic varieties over a field "k", and the category of finitely generated reduced "k"-algebras. The gluing is along Zariski topology; one can glue within the category of locally ringed spaces, but also, using the Yoneda embedding, within the more abstract category of presheaves of sets over the category of affine schemes. The Zariski topology in the set theoretic sense is then replaced by a Grothendieck topology. Grothendieck introduced Grothendieck topologies having in mind more exotic but geometrically finer and more sensitive examples than the crude Zariski topology, namely the étale topology, and the two flat Grothendieck topologies: fppf and fpqc; nowadays some other examples became prominent including Nisnevich topology. Sheaves can be furthermore generalized to stacks in the sense of Grothendieck, usually with some additional representability conditions leading to Artin stacks and, even finer, Deligne-Mumford stacks, both often called algebraic stacks.

Sometimes other algebraic sites replace the category of affine schemes. For example, Nikolai Durov has introduced commutative algebraic monads as a generalization of local objects in a generalized algebraic geometry. Versions of a tropical geometry, of an absolute geometry over a field of one element and an algebraic analogue of Arakelov's geometry were realized in this setup.

Another formal generalization is possible to universal algebraic geometry in which every variety of algebras has its own algebraic geometry. The term "variety of algebras" should not be confused with "algebraic variety".

The language of schemes, stacks and generalizations has proved to be a valuable way of dealing with geometric concepts and became cornerstones of modern algebraic geometry.

Algebraic stacks can be further generalized and for many practical questions like deformation theory and intersection theory, this is often the most natural approach. One can extend the Grothendieck site of affine schemes to a higher categorical site of derived affine schemes, by replacing the commutative rings with an infinity category of differential graded commutative algebras, or of simplicial commutative rings or a similar category with an appropriate variant of a Grothendieck topology. One can also replace presheaves of sets by presheaves of simplicial sets (or of infinity groupoids). Then, in presence of an appropriate homotopic machinery one can develop a notion of derived stack as such a presheaf on the infinity category of derived affine schemes, which is satisfying certain infinite categorical version of a sheaf axiom (and to be algebraic, inductively a sequence of representability conditions). Quillen model categories, Segal categories and quasicategories are some of the most often used tools to formalize this yielding the "derived algebraic geometry", introduced by the school of Carlos Simpson, including Andre Hirschowitz, Bertrand Toën, Gabrielle Vezzosi, Michel Vaquié and others; and developed further by Jacob Lurie, Bertrand Toën, and Gabrielle Vezzosi. Another (noncommutative) version of derived algebraic geometry, using A-infinity categories has been developed from early 1990s by Maxim Kontsevich and followers.

Some of the roots of algebraic geometry date back to the work of the Hellenistic Greeks from the 5th century BC. The Delian problem, for instance, was to construct a length "x" so that the cube of side "x" contained the same volume as the rectangular box "a""b" for given sides "a" and "b". Menaechmus (circa 350 BC) considered the problem geometrically by intersecting the pair of plane conics "ay" = "x" and "xy" = "ab". The later work, in the 3rd century BC, of Archimedes and Apollonius studied more systematically problems on conic sections, and also involved the use of coordinates. The Arab mathematicians were able to solve by purely algebraic means certain cubic equations, and then to interpret the results geometrically. This was done, for instance, by Ibn al-Haytham in the 10th century AD. Subsequently, Persian mathematician Omar Khayyám (born 1048 A.D.) discovered a method for solving cubic equations by intersecting a parabola with a circle and seems to have been the first to conceive a general theory of cubic equations. A few years after Omar Khayyám, Sharaf al-Din al-Tusi's "Treatise on equations" has been described as "inaugurating the beginning of algebraic geometry".

Such techniques of applying geometrical constructions to algebraic problems were also adopted by a number of Renaissance mathematicians such as Gerolamo Cardano and Niccolò Fontana "Tartaglia" on their studies of the cubic equation. The geometrical approach to construction problems, rather than the algebraic one, was favored by most 16th and 17th century mathematicians, notably Blaise Pascal who argued against the use of algebraic and analytical methods in geometry. The French mathematicians Franciscus Vieta and later René Descartes and Pierre de Fermat revolutionized the conventional way of thinking about construction problems through the introduction of coordinate geometry. They were interested primarily in the properties of "algebraic curves", such as those defined by Diophantine equations (in the case of Fermat), and the algebraic reformulation of the classical Greek works on conics and cubics (in the case of Descartes).

During the same period, Blaise Pascal and Gérard Desargues approached geometry from a different perspective, developing the synthetic notions of projective geometry. Pascal and Desargues also studied curves, but from the purely geometrical point of view: the analog of the Greek "ruler and compass construction". Ultimately, the analytic geometry of Descartes and Fermat won out, for it supplied the 18th century mathematicians with concrete quantitative tools needed to study physical problems using the new calculus of Newton and Leibniz. However, by the end of the 18th century, most of the algebraic character of coordinate geometry was subsumed by the "calculus of infinitesimals" of Lagrange and Euler.

It took the simultaneous 19th century developments of non-Euclidean geometry and Abelian integrals in order to bring the old algebraic ideas back into the geometrical fold. The first of these new developments was seized up by Edmond Laguerre and Arthur Cayley, who attempted to ascertain the generalized metric properties of projective space. Cayley introduced the idea of "homogeneous polynomial forms", and more specifically quadratic forms, on projective space. Subsequently, Felix Klein studied projective geometry (along with other types of geometry) from the viewpoint that the geometry on a space is encoded in a certain class of transformations on the space. By the end of the 19th century, projective geometers were studying more general kinds of transformations on figures in projective space. Rather than the projective linear transformations which were normally regarded as giving the fundamental Kleinian geometry on projective space, they concerned themselves also with the higher degree birational transformations. This weaker notion of congruence would later lead members of the 20th century Italian school of algebraic geometry to classify algebraic surfaces up to birational isomorphism.

The second early 19th century development, that of Abelian integrals, would lead Bernhard Riemann to the development of Riemann surfaces.

In the same period began the algebraization of the algebraic geometry through commutative algebra. The prominent results in this direction are Hilbert's basis theorem and Hilbert's Nullstellensatz, which are the basis of the connexion between algebraic geometry and commutative algebra, and Macaulay's multivariate resultant, which is the basis of elimination theory. Probably because of the size of the computation which is implied by multivariate resultants, elimination theory was forgotten during the middle of the 20th century until it was renewed by singularity theory and computational algebraic geometry.

B. L. van der Waerden, Oscar Zariski and André Weil developed a foundation for algebraic geometry based on contemporary commutative algebra, including valuation theory and the theory of ideals. One of the goals was to give a rigorous framework for proving the results of Italian school of algebraic geometry. In particular, this school used systematically the notion of generic point without any precise definition, which was first given by these authors during the 1930s.

In the 1950s and 1960s, Jean-Pierre Serre and Alexander Grothendieck recast the foundations making use of sheaf theory. Later, from about 1960, and largely led by Grothendieck, the idea of schemes was worked out, in conjunction with a very refined apparatus of homological techniques. After a decade of rapid development the field stabilized in the 1970s, and new applications were made, both to number theory and to more classical geometric questions on algebraic varieties, singularities, moduli, and formal moduli.

An important class of varieties, not easily understood directly from their defining equations, are the abelian varieties, which are the projective varieties whose points form an abelian group. The prototypical examples are the elliptic curves, which have a rich theory. They were instrumental in the proof of Fermat's last theorem and are also used in elliptic-curve cryptography.

In parallel with the abstract trend of the algebraic geometry, which is concerned with general statements about varieties, methods for effective computation with concretely-given varieties have also been developed, which lead to the new area of computational algebraic geometry. One of the founding methods of this area is the theory of Gröbner bases, introduced by Bruno Buchberger in 1965. Another founding method, more specially devoted to real algebraic geometry, is the cylindrical algebraic decomposition, introduced by George E. Collins in 1973.

See also: derived algebraic geometry.

An analytic variety is defined locally as the set of common solutions of several equations involving analytic functions. It is analogous to the included concept of real or complex algebraic variety. Any complex manifold is an analytic variety. Since analytic varieties may have singular points, not all analytic varieties are manifolds.

Modern analytic geometry is essentially equivalent to real and complex algebraic geometry, as has been shown by Jean-Pierre Serre in his paper "GAGA", the name of which is French for "Algebraic geometry and analytic geometry". Nevertheless, the two fields remain distinct, as the methods of proof are quite different and algebraic geometry includes also geometry in finite characteristic.

Algebraic geometry now finds applications in statistics, control theory, robotics, error-correcting codes, phylogenetics and geometric modelling. There are also connections to string theory, game theory, graph matchings, solitons and integer programming.







</doc>
<doc id="1998" url="https://en.wikipedia.org/wiki?curid=1998" title="Austin, Texas">
Austin, Texas

Austin is the capital of the U.S. state of Texas and the seat of Travis County, with portions extending into Hays and Williamson counties. It is the 11th-most populous city in the United States and the 4th-most populous city in Texas. It is also the fastest growing large city in the United States, the second most populous state capital after Phoenix, Arizona, and the southernmost state capital in the contiguous United States. As of the U.S. Census Bureau's July 1, 2018 estimate, Austin had a population of 964,254 up from 790,491 at the 2010 census. The city is the cultural and economic center of the metropolitan statistical area, which had an estimated population of 2,168,316 . Located in within the greater Texas Hill Country, it is home to numerous lakes, rivers, and waterways, including Lady Bird Lake and Lake Travis on the Colorado River, Barton Springs, McKinney Falls, and Lake Walter E. Long.

In the 1830s, pioneers began to settle the area in central Austin along the Colorado River. In 1839, the site was chosen to replace Houston as the capital of the Republic of Texas and was incorporated under the name "Waterloo". Shortly afterward, the name was changed to Austin in honor of Stephen F. Austin, the "Father of Texas" and the republic's first secretary of state. The city grew throughout the 19th century and became a center for government and education with the construction of the Texas State Capitol and the University of Texas at Austin. After a severe lull in economic growth from the Great Depression, Austin resumed its steady development, and by the 1990s it emerged as a center for technology and business. A number of Fortune 500 companies have headquarters or regional offices in Austin including, 3M, Amazon.com, Apple Inc., Cisco, eBay, General Motors, Google, IBM, Intel, Oracle Corporation, PayPal, Texas Instruments, and Whole Foods Market. Dell's worldwide headquarters is located in a nearby suburb, Round Rock.

Residents of Austin are known as Austinites. They include a diverse mix of government employees, college students, musicians, high-tech workers, blue-collar workers, and a vibrant LGBT community. The city's official slogan promotes Austin as "The Live Music Capital of the World," a reference to the city's many musicians and live music venues, as well as the long-running PBS TV concert series "Austin City Limits". The city also adopted "Silicon Hills" as a nickname in the 1990s due to a rapid influx of technology and development companies. In recent years, some Austinites have adopted the unofficial slogan "Keep Austin Weird," which refers to the desire to protect small, unique, and local businesses from being overrun by large corporations. In the late 19th century, Austin was known as the "City of the Violet Crown," because of the colorful glow of light across the hills just after sunset. Even today, many Austin businesses use the term "Violet Crown" in their name. Austin is known as a "clean-air city" for its stringent no-smoking ordinances that apply to all public places and buildings, including restaurants and bars.

"U.S. News & World Report" named Austin the #1 place to live in the U.S. for 2017 and 2018. In 2016, "Forbes" ranked Austin #1 on its "Cities of the Future" list, then in 2017 placed the city at that same position on its list for the "Next Biggest Boom Town in the U.S." Also in 2017, "Forbes" awarded the South River City neighborhood of Austin its #2 ranking for "Best Cities and Neighborhoods for Millennials". WalletHub named Austin the #6 best place in the country to live for 2017. The FBI ranked Austin as the #2 safest major city in the U.S. for 2012.

Austin, Travis County and Williamson County have been the site of human habitation since at least 9200 BC. The area's earliest known inhabitants lived during the late Pleistocene (Ice Age) and are linked to the Clovis culture around 9200 BC (over 11,200 years ago), based on evidence found throughout the area and documented at the much-studied Gault Site, midway between Georgetown and Fort Hood.

When settlers arrived from Europe, the Tonkawa tribe inhabited the area. The Comanches and Lipan Apaches were also known to travel through the area. Spanish colonists, including the Espinosa-Olivares-Aguirre expedition, traveled through the area for centuries, though few permanent settlements were created for some time. In 1730, three missions from East Texas were combined and reestablished as one mission on the south side of the Colorado River, in what is now Zilker Park, in Austin. The mission was in this area for only about seven months, and then was moved to San Antonio de Béxar and split into three missions.

Early in the 19th century, Spanish forts were established in what are now Bastrop and San Marcos. Following Mexico's independence, new settlements were established in Central Texas, but growth in the region was stagnant because of conflicts with the regional Native Americans.

In 1835–1836, Texans fought and won independence from Mexico. Texas thus became an independent country with its own president, congress, and monetary system. After Vice President Mirabeau B. Lamar visited the area during a buffalo-hunting expedition between 1837 and 1838, he proposed that the republic's capital, then in Houston, be relocated to the area situated on the north bank of the Colorado River (near the present-day Congress Avenue Bridge). In 1839, the Texas Congress formed a commission to seek a site for a new capital to be named for Stephen F. Austin. Mirabeau B. Lamar, second president of the newly formed Republic of Texas, advised the commissioners to investigate the area named Waterloo, noting the area's hills, waterways, and pleasant surroundings. Waterloo was selected, and "Austin" was chosen as the town's new name. The location was seen as a convenient crossroads for trade routes between Santa Fe and Galveston Bay, as well as routes between northern Mexico and the Red River.

Edwin Waller was picked by Lamar to survey the village and draft a plan laying out the new capital. The original site was narrowed to that fronted the Colorado River between two creeks, Shoal Creek and Waller Creek, which was later named in his honor. The 14-block grid plan was bisected by a broad north-south thoroughfare, Congress Avenue, running up from the river to Capital Square, where the new Texas State Capitol was to be constructed. A temporary one-story capitol was erected on the corner of Colorado and 8th Streets. On August 1, 1839, the first auction of 217 out of 306 lots total was held. The grid plan Waller designed and surveyed now forms the basis of downtown Austin.

In 1840, a series of conflicts between the Texas Rangers and the Comanches, known as the Council House Fight and the Battle of Plum Creek, pushed the Comanches westward, mostly ending conflicts in Central Texas. Settlement in the area began to expand quickly. Travis County was established in 1840, and the surrounding counties were mostly established within the next two decades.

Initially, the new capital thrived. But Lamar's political enemy, Sam Houston, used two Mexican army incursions to San Antonio as an excuse to move the government. Sam Houston fought bitterly against Lamar's decision to establish the capital in such a remote wilderness. The men and women who traveled mainly from Houston to conduct government business were intensely disappointed as well. By 1840, the population had risen to 856, of whom nearly half fled from Austin when Congress recessed. The resident African American population listed in January of this same year was 176. The fear of Austin's proximity to the Indians and Mexico, which still considered Texas a part of their land, created an immense motive for Sam Houston, the first and third President of the Republic of Texas, to relocate the capital once again in 1841. Upon threats of Mexican troops in Texas, Houston raided the Land Office to transfer all official documents to Houston for safe keeping in what was later known as the Archive War, but the people of Austin would not allow this unaccompanied decision to be executed. The documents stayed, but the capital would temporarily move from Austin to Houston to Washington-on-the-Brazos. Without the governmental body, Austin's population declined to a low of only a few hundred people throughout the early 1840s. The voting by the fourth President of the Republic, Anson Jones, and Congress, who reconvened in Austin in 1845, settled the issue to keep Austin the seat of government, as well as annex the Republic of Texas into the United States.

In 1860, 38% of Travis County residents were slaves. In 1861, with the outbreak of the American Civil War, voters in Austin and other Central Texas communities voted against secession. However, as the war progressed and fears of attack by Union forces increased, Austin contributed hundreds of men to the Confederate forces. The African American population of Austin swelled dramatically after the enforcement of the Emancipation Proclamation in Texas by Union General Gordon Granger at Galveston, in an event commemorated as Juneteenth. Black communities such as Wheatville, Pleasant Hill, and Clarksville were established, with Clarksville being the oldest surviving freedomtown ‒ the original post-Civil War settlements founded by former African-American slaves ‒ west of the Mississippi River. In 1870, blacks made up 36.5% of Austin's population.

The postwar period saw dramatic population and economic growth. The opening of the Houston and Texas Central Railway (H&TC) in 1871 turned Austin into the major trading center for the region, with the ability to transport both cotton and cattle. The Missouri, Kansas & Texas (MKT) line followed close behind. Austin was also the terminus of the southernmost leg of the Chisholm Trail, and "drovers" pushed cattle north to the railroad. Cotton was one of the few crops produced locally for export, and a cotton gin engine was located downtown near the trains for "ginning" cotton of its seeds and turning the product into bales for shipment. However, as other new railroads were built through the region in the 1870s, Austin began to lose its primacy in trade to the surrounding communities. In addition, the areas east of Austin took over cattle and cotton production from Austin, especially in towns like Hutto and Taylor that sit over the blackland prairie, with its deep, rich soils for producing cotton and hay.

In September 1881, Austin public schools held their first classes. The same year, Tillotson Collegiate and Normal Institute (now part of Huston–Tillotson University) opened its doors. The University of Texas held its first classes in 1883, although classes had been held in the original wooden state capitol for four years before.

During the 1880s, Austin gained new prominence as the state capitol building was completed in 1888 and claimed as the seventh largest building in the world. In the late 19th century, Austin expanded its city limits to more than three times its former area, and the first granite dam was built on the Colorado River to power a new street car line and the new "moon towers". Unfortunately, the first dam washed away in a flood on April 7, 1900.

In the 1920s and 1930s, Austin launched a series of civic development and beautification projects that created much of the city's infrastructure and many of its parks. In addition, the state legislature established the Lower Colorado River Authority (LCRA) that, along with the city of Austin, created the system of dams along the Colorado River to form the Highland Lakes. These projects were enabled in large part because the Public Works Administration provided Austin with greater funding for municipal construction projects than other Texas cities.

During the early twentieth century, a three-way system of social segregation emerged in Austin, with Anglos, African Americans and Mexicans being separated by custom or law in most aspects of life, including housing, health care, and education. Many of the municipal improvement programs initiated during this period—such as the construction of new roads, schools, and hospitals—were deliberately designed to institutionalize this system of segregation. Deed restrictions also played an important role in residential segregation. After 1935 most housing deeds prohibited African Americans (and sometimes other nonwhite groups) from using land. Combined with the system of segregated public services, racial segregation increased in Austin during the first half of the twentieth century, with African Americans and Mexicans experiencing high levels of discrimination and social marginalization.

In 1940, the destroyed granite dam on the Colorado River was finally replaced by a hollow concrete dam that formed Lake McDonald (now called Lake Austin) and which has withstood all floods since. In addition, the much larger Mansfield Dam was built by the LCRA upstream of Austin to form Lake Travis, a flood-control reservoir. In the early 20th century, the Texas Oil Boom took hold, creating tremendous economic opportunities in Southeast Texas and North Texas. The growth generated by this boom largely passed by Austin at first, with the city slipping from fourth largest to 10th largest in Texas between 1880 and 1920.

After the mid-20th century, Austin became established as one of Texas' major metropolitan centers. In 1970, the U.S. Census Bureau reported Austin's population as 14.5% Hispanic, 11.9% black, and 73.4% non-Hispanic white. In the late 20th century, Austin emerged as an important high tech center for semiconductors and software. The University of Texas at Austin emerged as a major university.

The 1970s saw Austin's emergence in the national music scene, with local artists such as Willie Nelson, Asleep at the Wheel, and Stevie Ray Vaughan and iconic music venues such as the Armadillo World Headquarters. Over time, the long-running television program "Austin City Limits", its namesake Austin City Limits Festival, and the South by Southwest music festival solidified the city's place in the music industry.

Austin, the southernmost state capital of the contiguous 48 states, is located in Central Texas. Austin is northwest of Houston, south of Dallas and northeast of San Antonio.

In 2010, the city occupied a total area of . Approximately of this area is water.

Austin is situated at the foot of the Balcones Escarpment, on the Colorado River, with three artificial lakes within the city limits: Lady Bird Lake (formerly known as Town Lake), Lake Austin (both created by dams along the Colorado River), and Lake Walter E. Long that is partly used for cooling water for the Decker Power Plant. Mansfield Dam and the foot of Lake Travis are located within the city's limits. Lady Bird Lake, Lake Austin, and Lake Travis are each on the Colorado River.

The elevation of Austin varies from to approximately above sea level. Due to the fact that it straddles the Balcones Fault, much of the eastern part of the city is flat, with heavy clay and loam soils, whereas the western part and western suburbs consist of rolling hills on the edge of the Texas Hill Country. Because the hills to the west are primarily limestone rock with a thin covering of topsoil, portions of the city are frequently subjected to flash floods from the runoff caused by thunderstorms. To help control this runoff and to generate hydroelectric power, the Lower Colorado River Authority operates a series of dams that form the Texas Highland Lakes. The lakes also provide venues for boating, swimming, and other forms of recreation within several parks on the lake shores. Austin is located at the intersection of four major ecological regions, and is consequently a temperate-to-hot green oasis with a highly variable climate having some characteristics of the desert, the tropics, and a wetter climate. The area is very diverse ecologically and biologically, and is home to a variety of animals and plants. Notably, the area is home to many types of wildflowers that blossom throughout the year but especially in the spring. This includes the popular bluebonnets, some planted by "Lady Bird" Johnson, wife of former President Lyndon B. Johnson.

The soils of Austin range from shallow, gravelly clay loams over limestone in the western outskirts to deep, fine sandy loams, silty clay loams, silty clays or clays in the city's eastern part. Some of the clays have pronounced shrink-swell properties and are difficult to work under most moisture conditions. Many of Austin's soils, especially the clay-rich types, are slightly to moderately alkaline and have free calcium carbonate.

Austin's skyline historically was modest, dominated by the Texas State Capitol and the University of Texas Main Building. However, since the 2000s, many new high-rise towers have been constructed. Austin is currently undergoing a skyscraper boom, which includes recent construction on new office, hotel and residential buildings. Downtown's buildings are somewhat spread out, partly due to a set of zoning restrictions that preserve the view of the Texas State Capitol from various locations around Austin, known as the Capitol View Corridors.

At night, parts of Austin are lit by "artificial moonlight" from moonlight towers built to illuminate the central part of the city. The moonlight towers were built in the late 19th century and are now recognized as historic landmarks. Only 15 of the 31 original innovative towers remain standing in Austin, and none remain in any of the other cities where they were installed. The towers are featured in the 1993 film "Dazed and Confused".

The central business district of Austin is home to the tallest condo towers in the state, with The Independent (58 stories and tall) and The Austonian (topping out at 56 floors and tall). The Independent became the tallest all-residential building in the U.S. west of Chicago when topped out in 2018.In 2005, then-Mayor Will Wynn set out a goal of having 25,000 people living Downtown by 2015. Although Downtown's growth did not meet this goal, Downtown's residential population did surge from an estimated 5,000 in 2005 to 12,000 in 2015. The skyline has drastically changed in recent years, and the residential real estate market has remained relatively strong. , there are 31 high-rise projects either under construction, approved or planned to be completed in Austin's downtown core between 2017 and 2020. Sixteen of those are set to rise above tall, including four above 600', and eight above 500'. An additional 15 towers are slated to stand between 300' and 399' tall.

Austin is located within the middle of a unique, narrow transitional zone between the dry deserts of the American Southwest and the lush, green, more humid regions of the American Southeast. Its climate, topography, and vegetation share characteristics of both. Officially, Austin has a humid subtropical climate under the Köppen climate classification. This climate is typified by very long and hot summers; short, mild winters; and pleasantly warm spring and fall seasons in-between. Austin averages of annual rainfall and it is distributed mostly evenly throughout the year, though spring and fall are the wettest seasons. Sunshine is common during all seasons, with 2,650 hours, or 60.3% of the possible total, of bright sunshine per year. Austin falls in USDA hardiness zones 8b (15 °F to 20 °F) and 9a (20 °F to 25 °F).

Summers in Austin are very hot, with average July and August highs frequently reaching the high-90s (34–36 °C) or above. Highs reach on 116 days per year, of which 18 days reach . The average daytime high is or warmer between March 6 and November 20, rising to or warmer between April 14 and October 24, and reaching or warmer between May 30 and September 18. The highest ever recorded temperature was occurring on September 5, 2000, and August 28, 2011. An uncommon characteristic of Austin's climate is its highly variable humidity, which fluctuates frequently depending on the shifting patterns of air flow and wind direction. It is common for a lengthy series of warm, dry, low-humidity days to be occasionally interrupted by very warm and humid days, and vice versa. Humidity rises with winds from the east or southeast, when the air drifts inland from the Gulf of Mexico, but decreases significantly with winds from the west or southwest, bringing air flowing from Chihuahuan Desert areas of West Texas or northern Mexico.

Winters in Austin are mild with cool nights, although occasional short-lived bursts of cold weather known as "Blue Northers" can occur. January is the coolest month with an average daytime high of . The overnight low drops to or below freezing 19 times per year, and sinks below during 88 evenings per year, including most nights between mid-December and mid-February. Lows in the upper 30s also occur commonly during the winter. Conversely, winter months are also capable of occasionally producing warm days. On average, eight days in January reach or exceed and one day reaches . The lowest ever recorded temperature in the city was on January 31, 1949. Roughly every two years Austin experiences an ice storm that freezes roads over and cripples travel in the city for 24 to 48 hours. When Austin received of ice on January 24, 2014, there were 278 vehicular collisions. Similarly, snowfall is rare in Austin. A snow event of on February 4, 2011, caused more than 300 car crashes and a snowstorm brought the city to a near standstill in 1985. The most recent major snow event occurred on December 7, 2017, when 1.3 inches was recorded at Austin-Bergstrom International Airport.

Typical of Central Texas, severe weather in Austin is a threat that can strike during any season. However, it is most common during the spring. According to most classifications, Austin lies within the extreme southern periphery of Tornado Alley, although many sources place Austin outside of Tornado Alley altogether. Consequently, tornadoes strike Austin less frequently than areas farther to the north. However, severe weather and/or supercell thunderstorms can occur multiple times per year, bringing damaging winds, lightning, heavy rain, and occasional flash flooding to the city. The deadliest storm to ever strike city limits was the twin tornadoes storm of May 4, 1922, while the deadliest tornado outbreak to ever strike the metro area was the Central Texas tornado outbreak of May 27, 1997.

From October 2010 through September 2011, both major reporting stations in Austin, Camp Mabry and Bergstrom Int'l, had the least rainfall of a water year on record, receiving less than a third of normal precipitation. This was a result of La Niña conditions in the eastern Pacific Ocean where water was significantly cooler than normal. David Brown, a regional official with the National Oceanic and Atmospheric Administration, has explained that "these kinds of droughts will have effects that are even more extreme in the future, given a warming and drying regional climate."

In Fall 2018, Austin and surrounding areas received heavy rainfall and flash flooding following Hurricane Sergio. The Lower Colorado River Authority opened four floodgates of the Mansfield Dam after Lake Travis was recorded at 146% full at 704.3 feet. From October 22–28, 2018, the City of Austin issued a mandatory citywide boil-water advisory after the Highland Lakes, home to the city's main water supply, became overwhelmed by unprecedented amounts of silt, dirt, and debris that washed in from the Llano River. Austin Water, the city's water utility, has the capacity to process up to 300 million gallons of water per day, but the elevated level of turbidity reduced output to only 105 million gallons per day; Austin residents consumed an average of 120 million gallons of water per day, so the infrastructure was not able to keep up with demand.

According to the 2010 United States Census, the racial composition of Austin is 68.3% White (48.7% Non-Hispanic Whites), 35.1% Hispanic or Latino (29.1% Mexican, 0.5% Puerto Rican, 0.4% Cuban, 5.1% Other), 8.1% African American, 6.3% Asian (1.9% Indian, 1.5% Chinese, 1.0% Vietnamese, 0.7% Korean, 0.3% Filipino, 0.2% Japanese, 0.8% Other), 0.9% American Indian, 0.1% Native Hawaiian and Other Pacific Islander, and 3.4% two or more races.
At the 2000 United States Census, there were people, households, and families residing in the city (roughly comparable in size to San Francisco, Leeds, UK; and Ottawa, Ontario, Canada). The population density was . There were housing units at an average density of . There were households out of which 26.8% had children under the age of 18 living with them, 38.1% were married couples living together, 10.8% had a female householder with no husband present, and 46.7% were non-families. 32.8% of all households were made up of individuals and 4.6% had someone living alone who was 65 years of age or older. The average household size was 2.40 and the average family size was 3.14.

In the city, the population was spread out with 22.5% under the age of 18, 16.6% from 18 to 24, 37.1% from 25 to 44, 17.1% from 45 to 64, and 6.7% who were 65 years of age or older. The median age was 30 years. For every 100 females, there were 105.8 males.

The median income for a household in the city was , and the median income for a family was $. Males had a median income of $ vs. $ for females. The per capita income for the city was $. About 9.1% of families and 14.4% of the population were below the poverty line, including 16.5% of those under age 18 and 8.7% of those age 65 or over. The median house price was $ in 2009, and it has increased every year since 2004. The median value of a house in which the owner occupies it was $227,800 in 2014, which is higher than the average American home value of $175,700.
A 2014 University of Texas study stated that Austin was the only U.S. city with a fast growth rate between 2000 and 2010 with a net loss in African Americans. , Austin's African American and Non-Hispanic White percentage share of the total population is declining despite the absolute number of both ethnic groups increasing. Austin's Non-Hispanic White population first dropped below 50% in 2005. The rapid growth of the Hispanic and Asian population has outpaced all other ethnic groups in the city.

According to a survey completed in 2014 by Gallup, it is estimated that 5.3% of residents in the Austin Metropolitan area identify as lesbian, gay, bisexual, or transgender. The Austin metropolitan area had the third highest rate in the nation.

According to Sperling's BestPlaces, 52.4% of Austin's population are religious. The majority of Austinites identified themselves as Christians, about 25.2% of whom claimed affiliation with the Catholic Church, owing in part to Spanish colonialism in the region. The city's Catholic population is served by the Roman Catholic Diocese of Austin, headquartered at the Cathedral of Saint Mary. Nationwide, 23% of Americans identify as Catholic. Other significant Christian groups in Austin include Baptists (8.7%), followed by Methodists (4.3%), Latter-Day Saints (1.5%), Episcopalians (1.0%), Lutherans (0.8%), Presbyterians (0.6%), Pentecostals (0.3%), and other Christians such as the Disciples of Christ and Eastern Orthodox Church (7.1%). The second largest religion Austinities identify with is Islam (1.7%); 0.8% of Americans nationwide claim affiliation with the Islamic faith. The dominant branch of Islam is Sunni Islam. Established in 1977, the largest mosque in Austin is the Islamic Center of Greater Austin. The community is affiliated with the Islamic Society of North America. The same study says that eastern faiths including Buddhism, Sikhism, and Hinduism make up 0.9% of the city's religious population. Judaism forms less than 0.1% of the religious demographic in Austin, although Orthodox, Reform, and Conservative congregations exist. In addition to those denominations, Austin is also home to an active secular humanist community, hosting nationwide television shows and charity work.

The Greater Austin metropolitan statistical area had a gross domestic product (GDP) of $86 billion in 2010. Austin is considered to be a major center for high tech. Thousands of graduates each year from the engineering and computer science programs at the University of Texas at Austin provide a steady source of employees that help to fuel Austin's technology and defense industry sectors. The region's rapid growth has led "Forbes" to rank the Austin metropolitan area number one among all big cities for jobs for 2012 in their annual survey and WSJ Marketwatch to rank the area number one for growing businesses. By 2013, Austin was ranked No. 14 on "Forbes"' list of the Best Places for Business and Careers (directly below Dallas, No. 13 on the list). As a result of the high concentration of high-tech companies in the region, Austin was strongly affected by the dot-com boom in the late 1990s and subsequent bust. Austin's largest employers include the Austin Independent School District, the City of Austin, Dell, the U.S. Federal Government, NXP Semiconductors, IBM, St. David's Healthcare Partnership, Seton Family of Hospitals, the State of Texas, the Texas State University, and the University of Texas at Austin.

Other high-tech companies with operations in Austin include 3M, Apple, Amazon, AMD, Apartment Ratings, Applied Materials, Arm Holdings, Bigcommerce, BioWare, Blizzard Entertainment, Buffalo Technology, Cirrus Logic, Cisco Systems, Dropbox, eBay, PayPal, Electronic Arts, Flextronics, Facebook, Google, Hewlett-Packard, Hoover's, HomeAway, Hostgator, Intel Corporation, National Instruments, Nvidia, Oracle, Polycom, Qualcomm, Inc., Rackspace, RetailMeNot, Rooster Teeth, Samsung Group, Silicon Laboratories, Spansion, United Devices, and Xerox. In 2010, Facebook accepted a grant to build a downtown office that could bring as many as 200 jobs to the city. The proliferation of technology companies has led to the region's nickname, "Silicon Hills," and spurred development that greatly expanded the city.

Austin is also emerging as a hub for pharmaceutical and biotechnology companies; the city is home to about 85 of them. The city was ranked by the Milken Institute as the No.12 biotech and life science center in the United States. Companies such as Hospira, Pharmaceutical Product Development, and ArthroCare Corporation are located there.

Whole Foods Market, an international grocery store chain specializing in fresh and packaged food products, was founded and is headquartered in Austin.

Other companies based in Austin include NXP Semiconductors, GoodPop, Temple-Inland, Sweet Leaf Tea Company, Keller Williams Realty, National Western Life, GSD&M, Dimensional Fund Advisors, Golfsmith, Forestar Group, EZCorp, Outdoor Voices, Tito's Vodka, Indeed, and YETI.

In addition to national and global corporations, Austin features a strong network of independent, unique, locally owned firms and organizations.

"Keep Austin Weird" has been a local motto for years, featured on bumper stickers and T-shirts. This motto has not only been used in promoting Austin's eccentricity and diversity, but is also meant to bolster support of local independent businesses. According to the 2010 book, "Weird City", the phrase was begun by a local Austin Community College librarian, Red Wassenich, and his wife, Karen Pavelka, who were concerned about Austin's "rapid descent into commercialism and overdevelopment." The slogan has been interpreted many ways since its inception, but remains an important symbol for many Austinites who wish to voice concerns over rapid growth and irresponsible development. Austin has a long history of vocal citizen resistance to development projects perceived to degrade the environment, or to threaten the natural and cultural landscapes.

According to the Nielsen Company, adults in Austin read and contribute to blogs more than those in any other U.S. metropolitan area. Austin residents have the highest internet usage in all of Texas. In 2013, Austin was the most active city on Reddit, having the largest number of views per capita. Austin was selected as the No. 2 Best Big City in "Best Places to Live" by "Money" magazine in 2006, and No. 3 in 2009, and also the "Greenest City in America" by MSN. According to "Travel & Leisure" magazine, Austin ranks No. 1 on the list of cities with the best people, referring to the personalities and attributes of the citizens. In 2012, the city was listed among the 10 best places to retire in the U.S. by "CBS Money Watch". In 2015, "Forbes" listed Austin as #1 Boom Town because of its economic strength, including jobs among other appealing attributes.

South Congress is a shopping district stretching down South Congress Avenue from Downtown. This area is home to coffee shops, eccentric stores, restaurants, food trucks, trailers, and festivals. It prides itself on "Keeping Austin Weird," especially with development in the surrounding area(s). Many Austinites attribute its enduring popularity to the magnificent and unobstructed view of the Texas State Capitol.

The Rainey Street Historic District is a neighborhood in Downtown Austin consisting mostly of bungalow style homes built in the early 20th Century. Since the early 2010s, the former working class residential street has turned into a popular nightlife district. Much of the historic homes have been renovated into bars and restaurants, many of which feature large porches and outdoor yards for patrons. The Rainey Street district is also home to the Emma S. Barrientos Mexican American Cultural Center.

Austin has been part of the UNESCO Creative Cities Network under Media Arts the category.

"Old Austin" is an adage often used by the native citizens in Austin, Texas when being nostalgic to refer to the olden days of the capital city of Texas. Although Austin is also known internationally as the live music capital of the world and its catch phrase/slogan Keep Austin Weird can be heard echoed in places as far as Buffalo, NY and Santa Monica, CA - the term "Old Austin" refers to a time when the city was smaller and more bohemian with a considerably lower cost of living and better known for its lack of traffic, hipsters, and urban sprawl. It is often employed by longtime residents expressing displeasure at the rapidly changing culture.

The growth and popularity of Austin can be seen by the expansive development taking place in its downtown landscape. Forbes ranked Austin as the second fastest-growing city in 2015. This growth can have a negative impact on longtime small businesses that cannot keep up with the expenses associated with gentrification and the rising cost of real estate. A former Austin Musician, Dale Watson, described his move away from Austin, "I just really feel the city has sold itself. Just because you're going to get $45 million for a company to come to town – if it's not in the best interest of the town, I don't think they should do it. This city was never about money. It was about quality of life."

The O. Henry House Museum hosts the annual O. Henry Pun-Off, a pun contest where the successful contestants exhibit wit akin to that of the author William Sydney Porter.

Other annual events include Eeyore's Birthday Party, Spamarama, Austin Gay Pride in August, the Austin Reggae Festival in April, Kite Festival, Texas Craft Brewers Festival in September, Art City Austin in April, East Austin Studio Tour in November, and Carnaval Brasileiro in February. Sixth Street features annual festivals such as the Pecan Street Festival and Halloween night. The three-day Austin City Limits Music Festival has been held in Zilker Park every year since 2002. Every year around the end of March and the beginning of April, Austin is home to "Texas Relay Weekend."

Austin's Zilker Park Tree is a Christmas display made of lights strung from the top of a Moonlight tower in Zilker Park. The Zilker Tree is lit in December along with the "Trail of Lights," an Austin Christmas tradition. The Trail of Lights was canceled four times, first starting in 2001 and 2002 due to the September 11 Attacks, and again in 2010 and 2011 due to budget shortfalls, but the trail was turned back on for the 2012 holiday season.

Austin is perhaps best known for its Texas barbecue and Tex-Mex cuisine. Franklin Barbecue is perhaps Austin's most famous barbecue restaurant; the restaurant has sold out of brisket every day since its establishment. Breakfast tacos and queso are popular food items in the city; Austin is sometimes called the "home of the breakfast taco." Kolaches are a common pastry in Austin bakeries due to the large Czech and German immigrant population in Texas. The Oasis Restaurant is the largest outdoor restaurant in Texas, which promotes itself as the "Sunset Capital of Texas" with its terraced views looking West over Lake Travis. P. Terry's, a Austin-based fast food burger chain, has a loyal following among Austinites. Some other Austin-based chain restaurants include Amy's Ice Creams, Bush's Chicken, Chuy's, DoubleDave's Pizzaworks, and Schlotzky's.

Austin is also home to a large number of food trucks, with 1,256 food trucks operating in 2016. The city of Austin has the second-largest number of food trucks per capita in the United States. Austin's first food hall, "Fareground," features a number of Austin-based food vendors and a bar in the ground level and courtyard of One Congress Plaza.

Austin has a large craft beer scene, with over 50 microbreweries in the metro area. Drinks publication VinePair named Austin as the "top beer destination in the world" in 2019. Notable Austin-area breweries include Jester King Brewery, Live Oak Brewing Company, NLand Brewing Company, and Real Ale Brewing Company.

As Austin's official slogan is "The Live Music Capital of the World", the city has a vibrant live music scene with more music venues per capita than any other U.S. city. Austin's music revolves around the many nightclubs on 6th Street and an annual film/music/interactive festival known as South by Southwest (SXSW). The concentration of restaurants, bars, and music venues in the city's downtown core is a major contributor to Austin's live music scene, as the ZIP Code encompassing the downtown entertainment district hosts the most bar or alcohol-serving establishments in the U.S.

The longest-running concert music program on American television, "Austin City Limits", is recorded at ACL Live at The Moody Theater, located in the bottom floor of the W Hotel. "Austin City Limits" and C3 Presents produce the Austin City Limits Music Festival, an annual music and art festival held at Zilker Park in Austin. Other music events include the Urban Music Festival, Fun Fun Fun Fest, Chaos In Tejas and Old Settler's Music Festival. Austin Lyric Opera performs multiple operas each year (including the 2007 opening of Philip Glass's "Waiting for the Barbarians", written by University of Texas at Austin alumnus J. M. Coetzee). The Austin Symphony Orchestra performs a range of classical, pop and family performances and is led by Music Director and Conductor Peter Bay. The Austin Baroque Orchestra and La Follia Austin Baroque ensembles both give historically-informed performances of Baroque music.

Austin hosts several film festivals including SXSW Film Festival and Austin Film Festival, which hosts international films. Alamo Drafthouse Cinema was founded in Austin in 1997; the South Lamar location is home to the annual week-long Fantastic Fest film festival. In 2004 the city was first in "MovieMaker Magazine's" annual top ten cities to live and make movies.

Austin has been the location for a number of motion pictures, partly due to the influence of The University of Texas at Austin Department of Radio-Television-Film. Films produced in Austin include "The Texas Chain Saw Massacre" (1974), "Songwriter" (1984), "Man of the House", "Secondhand Lions", "Texas Chainsaw Massacre 2", "Nadine", "Waking Life", "Spy Kids", "The Faculty", "Dazed and Confused", "The Guards Themselves", "Wild Texas Wind", "Office Space", "The Life of David Gale", "Miss Congeniality", "Doubting Thomas", "Slacker", "Idiocracy", "The New Guy", "Hope Floats", "The Alamo", "Blank Check", "The Wendall Baker Story", "School of Rock", "A Slipping-Down Life", "A Scanner Darkly", "Saturday Morning Massacre", and most recently, the Coen brothers' "True Grit", "Grindhouse", "Machete", "How to Eat Fried Worms", "Bandslam" and "Lazer Team". In order to draw future film projects to the area, the Austin Film Society has converted several airplane hangars from the former Mueller Airport into filmmaking center Austin Studios. Projects that have used facilities at Austin Studios include music videos by The Flaming Lips and feature films such as "25th Hour" and "Sin City".

Austin also hosted the MTV series, "" in 2005. Season 4 of the AMC show "Fear the Walking Dead" was filmed in various locations around Austin in 2018. The film review websites Spill.com and Ain't It Cool News are based in Austin. Rooster Teeth Productions, creator of popular web series such as "Red vs. Blue" and "RWBY", is also located in Austin.

Austin has a strong theater culture, with dozens of itinerant and resident companies producing a variety of work. The Church of the Friendly Ghost is a volunteer-run arts organization supporting creative expression and counter-culture community. The city also has live performance theater venues such as the Zachary Scott Theatre Center, Vortex Repertory Company, Salvage Vanguard Theater, Rude Mechanicals' the Off Center, Austin Playhouse, Scottish Rite Children's Theater, Hyde Park Theatre, the Blue Theater, The Hideout Theatre, and Esther's Follies. The Victory Grill was a renowned venue on the Chitlin' circuit. Public art and performances in the parks and on bridges are popular. Austin hosts the Fuse Box Festival each April featuring theater artists.

The Paramount Theatre, opened in downtown Austin in 1915, contributes to Austin's theater and film culture, showing classic films throughout the summer and hosting regional premieres for films such as "Miss Congeniality". The Zilker Park Summer Musical is a long-running outdoor musical.

The Long Center for the Performing Arts is a 2,300-seat theater built partly with materials reused from the old Lester E. Palmer Auditorium.

Ballet Austin is the fourth largest ballet academy in the country. Each year Ballet Austin's 20-member professional company performs ballets from a wide variety of choreographers, including their international award-winning artistic director, Stephen Mills. The city is also home to the Ballet East Dance Company, a modern dance ensemble, and the Tapestry Dance Company which performs a variety of dance genres.

The Austin improvisational theatre scene has several theaters: ColdTowne Theater, The Hideout Theater, The Fallout Theater, and The Institution Theater. Austin also hosts the Out of Bounds Comedy Festival, which draws comedic artists in all disciplines to Austin.

The Austin Public Library is a public library system operated by the City of Austin and consists of the Central Library on Cesar Chavez Boulevard, the Austin History Center, 20 branches and the Recycled Reads bookstore and upcycling facility. The APL library system also has mobile libraries – bookmobile buses and a human-powered trike and trailer called "unbound: sin fronteras."

The Central Library, which is an anchor to the redevelopment of the former Seaholm Power Plant site and the Shoal Creek Walk, opened on October 28, 2017. The 6-story Central Library contains a living rooftop garden, reading porches, an indoor reading room, bicycle parking station, large indoor and outdoor event spaces, a gift shop, an art gallery, café, and a "technology petting zoo" where visitors can play with next-generation gadgets like 3D printers. In 2018, Time magazine named the Austin Central Library on its list of "World's Greatest Places."

Museums in Austin include the Texas Memorial Museum, the George Washington Carver Museum and Cultural Center, Thinkery, the Blanton Museum of Art (reopened in 2006), the Bob Bullock Texas State History Museum across the street (which opened in 2000), The Contemporary Austin, the Elisabet Ney Museum and the galleries at the Harry Ransom Center. The Texas State Capitol itself is also a major tourist attraction.

The Driskill Hotel, built in 1886, once owned by George W. Littlefield, and located at 6th and Brazos streets, was finished just before the construction of the Capitol building. Sixth Street is a musical hub for the city. The Enchanted Forest, a multi-acre outdoor music, art, and performance art space in South Austin hosts events such as fire-dancing and circus-like-acts. Austin is also home to the Lyndon Baines Johnson Library and Museum, which houses documents and artifacts related to the Johnson administration, including LBJ's limousine and a re-creation of the Oval Office.

Locally produced art is featured at the South Austin Museum of Popular Culture. The Mexic-Arte Museum is a Mexican and Mexican-American art museum founded in 1983. Austin is also home to the O. Henry House Museum, which served as the residence of O. Henry from 1893 to 1895. Farmers' markets are popular attractions, providing a variety of locally grown and often organic foods.

Austin also has many odd statues and landmarks, such as the Stevie Ray Vaughan statue, the Willie Nelson statue, the Mangia dinosaur, the Loca Maria lady at Taco Xpress, the Hyde Park Gym's giant flexed arm, and Daniel Johnston's "Hi, How are You?" Jeremiah the Innocent frog mural.

The Ann W. Richards Congress Avenue Bridge houses the world's largest urban population of Mexican free-tailed bats. Starting in March, up to 1.5 million bats take up residence inside the bridge's expansion and contraction zones as well as in long horizontal grooves running the length of the bridge's underside, an environment ideally suited for raising their young. Every evening around sunset, the bats emerge in search of insects, an exit visible on weather radar. Watching the bat emergence is an event that is popular with locals and tourists, with more than 100,000 viewers per year. The bats migrate to Mexico each winter.

The Austin Zoo, located in unincorporated western Travis County, is a rescue zoo that provides sanctuary to displaced animals from a variety of situations, including those involving neglect.

The HOPE Outdoor Gallery is a public, three-story outdoor street art project located on Baylor Street in the Clarksville neighborhood. The gallery, which consists of the foundations of a failed multifamily development, is a constantly-evolving canvas of graffiti and murals. Also known as "Castle Hill" or simply "Graffiti Park," the site on Baylor Street was closed to the public in early January 2019 but remained intact, behind a fence and with an armed guard, in mid-March 2019. The gallery will build a new art park at Carson Creek Ranch in Southeast Austin.

Many Austinites support the athletic programs of the University of Texas at Austin known as the Texas Longhorns. During the 2005–06 academic term, Longhorns football team was named the NCAA Division I FBS National Football Champion, and Longhorns baseball team won the College World Series. The Texas Longhorns play home games in the state's second-largest sports stadium, Darrell K Royal–Texas Memorial Stadium, seating over 101,000 fans. Baseball games are played at UFCU Disch–Falk Field.

Austin is the most populous city in the United States without a major-league professional sports team. Minor-league professional sports came to Austin in 1996, when the Austin Ice Bats began playing at the Travis County Expo Center; they were later replaced by the AHL Texas Stars. Austin has hosted a number of other professional teams, including the Austin Spurs of the NBA G League, the Austin Aztex of the United Soccer League, the Austin Outlaws in WFA football, and the Austin Aces in WTT tennis.

Natural features like the bicycle-friendly Texas Hill Country and generally mild climate make Austin the home of several endurance and multi-sport races and communities. The Capitol 10,000 is the largest race in Texas, and approximately fifth largest in the United States. The Austin Marathon has been run in the city every year since 1992. Additionally the city is home to the largest 5 mile race in Texas, named the Turkey Trot as it is run annually on thanksgiving. Started in 1991 by Thundercloud Subs, a local sandwich chain (who still sponsors the event), the event has grown to host over 20,000 runners. All proceeds are donated to Caritas of Austin, a local charity.

The Austin-founded American Swimming Association hosts several swim races around town. Austin is also the hometown of several cycling groups and the disgraced cyclist Lance Armstrong. Combining these three disciplines is a growing crop of triathlons, including the Capital of Texas Triathlon held every Memorial Day on and around Lady Bird Lake, Auditorium Shores, and Downtown Austin.

Austin is home to the Circuit of the Americas (COTA), a grade 1 FIA specification motor racing facility which hosts the Formula One United States Grand Prix. The State of Texas has pledged $25 million in public funds annually for 10 years to pay the sanctioning fees for the race. Built at an estimated cost of $250 to $300 million, the circuit opened in 2012 and is located just east of the Austin Bergstrom International Airport. In August 2017, a new soccer-specific stadium was announced to be built between the Austin360 Amphitheater and the Grand Plaza at COTA. A professional soccer team known as Austin Bold FC will start playing in the United Soccer League in 2019.

The summer of 2014 marked the inaugural season for World TeamTennis team Austin Aces, formerly Orange County Breakers of the southern California region. Austin Aces played their matches at the Cedar Park Center northwest of Austin, and featured former professionals Andy Roddick and Marion Bartoli, as well as current WTA tour player Vera Zvonareva. The team left after the 2015 season.

In 2017, Precourt Sports Ventures announced a plan to move the Columbus Crew SC soccer franchise from Columbus, Ohio to Austin. Precourt negotiated an agreement with the City of Austin to build a $200 million stadium on public land at 10414 McKalla Place, following initial interest in Butler Shores Metropolitan Park and Roy G. Guerrero Colorado River Park. As part of an arrangement with the league, operational rights of Columbus Crew SC were sold in late 2018, and Austin FC was announced as Major League Soccer's 27th franchise on January 15, 2019, with the expansion team starting play in 2021.

The Austin Parks and Recreation Department received the Excellence in Aquatics award in 1999 and the Gold Medal Awards in 2004 from the National Recreation and Park Association.

To strengthen the region's parks system, which spans more than , The Austin Parks Foundation (APF) was established in 1992 to develop and improve parks in and around Austin. APF works to fill the city's park funding gap by leveraging volunteers, philanthropists, park advocates, and strategic collaborations to develop, maintain and enhance Austin's parks, trails and green spaces.

Lady Bird Lake (formerly Town Lake) is a river-like reservoir on the Colorado River. The lake is a popular recreational area for paddleboards, kayaks, canoes, dragon boats, and rowing shells. Austin's warm climate and the river's calm waters, nearly length and straight courses are especially popular with crew teams and clubs. Other recreational attractions along the shores of the lake include swimming in Deep Eddy Pool, the oldest swimming pool in Texas, and Red Bud Isle, a small island formed by the 1900 collapse of the McDonald Dam that serves as a recreation area with a dog park and access to the lake for canoeing and fishing. The Ann and Roy Butler Hike and Bike Trail forms a complete circuit around the lake. A local nonprofit, The Trail Foundation, is the Trail's private steward and has made built amenities and infrastructure including trailheads, lakefront gathering areas, restrooms, exercise equipment, as well as doing Trailwide ecological restoration work on an ongoing basis. The Butler Trail loop was completed in 2014 with the public-private partnership 1-mile Boardwalk project.

Along the shores of Lady Bird Lake is the 350 acre (142 ha) Zilker Park, which contains large open lawns, sports fields, cross country courses, historical markers, concession stands, and picnic areas. Zilker Park is also home to numerous attractions, including the Zilker Botanical Garden, the Umlauf Sculpture Garden, Zilker Hillside Theater, the Austin Nature & Science Center, and the Zilker Zephyr, a gauge miniature railway carries passengers on a tour around the park. Auditorium Shores, an urban park along the lake, is home to the Palmer Auditorium, the Long Center for the Performing Arts, and an off-leash dog park on the water. Both Zilker Park and Auditorium Shores have a direct view of the Downtown skyline.

The Barton Creek Greenbelt is a public green belt managed by the City of Austin's Park and Recreation Department. The Greenbelt, which begins at Zilker Park and stretches South/Southwest to the Woods of Westlake subdivision, is characterized by large limestone cliffs, dense foliage, and shallow bodies of water. Popular activities include rock climbing, mountain biking, and hiking. Some well known naturally forming swimming holes along Austin's greenbelt include Twin Falls, Sculpture Falls, Gus Fruh Pool, and Campbell's Hole. During years of heavy rainfall, the water level of the creek rises high enough to allow swimming, cliff diving, kayaking, and tubing.

Austin is home to more than 50 public pools and swimming holes. These include Deep Eddy Pool, Texas' oldest man-made swimming pool, and Barton Springs Pool, the nation's largest natural swimming pool in an urban area. Barton Springs Pool is spring-fed while Deep Eddy is well-fed. Both range in temperature from about during the winter to about during the summer. Hippie Hollow Park, a county park situated along Lake Travis, is the only officially sanctioned clothing-optional public park in Texas. Hamilton Pool Preserve is a natural pool that was created when the dome of an underground river collapsed due to massive erosion thousands of years ago. The pool, located about 23 miles (37 km) west of Austin, is a popular summer swimming spot for visitors and residents. Hamilton Pool Preserve consists of 232 acres (0.94 km2) of protected natural habitat featuring a jade green pool into which a 50-foot (15 m) waterfall flows.

Camping is legal on all public property except in front of City Hall since 2019.

McKinney Falls State Park is a state park administered by the Texas Parks and Wildlife Department, located at the confluence of Onion Creek and Williamson Creek. The park includes several designated hiking trails and cap sites with water and electric. The namesake features of the park are the scenic upper and lower falls along Onion Creek. The Emma Long Metropolitan Park is a municipal park along the shores of Lake Austin, originally constructed by the Civilian Conservation Corps. The 284-acre Lady Bird Johnson Wildflower Center is a botanical garden and arboretum that features more than 800 species of native Texas plants in both garden and natural settings; the Wildflower Center is located 10 miles southwest of Downtown in Circle C Ranch. Roy G. Guerrero Park is located along the Colorado River in East Riverside and contains miles of wooded trails, a sandy beach along the river, and a disc golf course.

Covert Park, located on the top of Mount Bonnell, is a popular tourist destination overlooking Lake Austin and the Colorado River. The mount provides a vista for viewing the city of Austin, Lake Austin, and the surrounding hills. It was designated a Recorded Texas Historic Landmark in 1969, bearing Marker number 6473, and was listed on the National Register of Historic Places in 2015.

The Austin Country Club is a private golf club located along the shores of the Colorado River, right next to the Pennybacker Bridge. Founded in 1899, the club moved to its third and present site in 1984, which features a challenging layout designed by noted course architect Pete Dye.

The city had 39 homicides in 2016, the most since 1997.

FBI statistics show that overall violent and property crimes dropped in Austin in 2015, but increased in suburban areas of the city. One such southeastern suburb, Del Valle, reported eight homicides within two months in 2016. According to 2016 APD crime statistics, the 78723 census tract had the most violent crime, with 6 murders, 25 rapes, and 81 robberies.

One of the first American school mass-shooting incidents took place in Austin on August 1, 1966, when a gunman shot 43 people, killing 13 from the top of the University of Texas tower (see University of Texas tower shooting). This event led to the formation of the SWAT team.

In 2010, Andrew Joseph Stack III deliberately crashed his Piper Cherokee PA-28 into Echelon 1, an IRS building housing 190 employees. The resulting explosion killed 1 person (excluding the pilot), injured 13, and completely destroyed the building, costing the IRS a total of 38.6 million (see 2010 Austin suicide attack).

A series of bombings occurred in Austin in March 2018.

Austin is administered by an 11-member city council (10 council members elected by geographic district plus a mayor elected at large). The council is accompanied by a hired city manager under the manager-council system of municipal governance. Council and mayoral elections are non-partisan, with a runoff in case there is no majority winner. A referendum approved by voters on November 6, 2012 changed the council composition from six council members plus a mayor elected at large to the current "10+1" district system. November 2014 marked the first election under the new system. The Federal government had forced San Antonio and Dallas to abandon at-large systems before 1987, however the court could not show a racist pattern in Austin and upheld the city's at-large system during a 1984 lawsuit. In five elections between 1973 and 1994 Austin voters rejected single-member districts.

Austin formerly operated its city hall at 128 West 8th Street. Antoine Predock and Cotera Kolar Negrete & Reed Architects designed a new city hall building, which was intended to reflect what "The Dallas Morning News" referred to as a "crazy-quilt vitality, that embraces everything from country music to environmental protests and high-tech swagger." The new city hall, built from recycled materials, has solar panels in its garage. The city hall, at 301 West Second Street, opened in November 2004. The mayor of Austin is Steve Adler.

Law enforcement in Austin is provided by the Austin Police Department, except for state government buildings, which are patrolled by the Texas Department of Public Safety. The University of Texas Police operate from the University of Texas.

Fire protection within the city limits is provided by the Austin Fire Department, while the surrounding county is divided into twelve geographical areas known as Emergency Services Districts, which are covered by separate regional fire departments. Emergency Medical Services are provided for the whole county by "Austin-Travis County Emergency Medical Services."

Austin is the county seat of Travis County and hosts the Heman Marion Sweatt Travis County Courthouse downtown, as well as other county government offices.

The Texas Department of Transportation operates the Austin District Office in Austin.

The Texas Department of Criminal Justice (TDCJ) operates the Austin I and Austin II district parole offices in Austin.

The United States Postal Service operates several post offices in Austin.

Austin is known as an enclave of liberal politics in an otherwise conservative state—so much so, that the city is sometimes sarcastically called the "People's Republic of Austin" by residents of other parts of Texas, and conservatives in the Texas Legislature.

Since redistricting following the 2010 United States Census, Austin has been divided between six congressional districts at the federal level: Texas's 35th, Texas's 25th, Texas's 10th, Texas's 21st, Texas's 17th, and Texas's 31st. Texas's 35th congressional district is represented by Democrat Lloyd Doggett. The other five districts are represented by Republicans, of whom only one, Michael McCaul of the 10th district, lives in Travis County.

As a result of the major party realignment that began in the 1970s, central Austin became a stronghold of the Democratic Party, while the suburbs tend to vote Republican. Overall, the city is a blend of downtown liberalism and suburban conservatism but leans to the political left as a whole. The city last went to a Republican candidate in 2000 when former Texas Governor George W. Bush successfully ran for President. In 2004, the Democrats rebounded strongly as John Kerry enjoyed a 14.0% margin over Bush, who once again won Texas.

City residents have been supportive of alternative candidates; for example, Ralph Nader won 10.4% of the vote in Austin in 2000.

In 2003, the city adopted a resolution against the USA PATRIOT Act that reaffirmed constitutionally guaranteed rights.

Of Austin's six state legislative districts, three are strongly Democratic and three are swing districts, two of which are held by Democrats and one of which is held by a Republican.

Travis County was also the only county in Texas to reject Texas Constitutional Amendment Proposition 2 that effectively outlawed gay marriage and status equal or similar to it and did so by a wide margin (40% for, 60% against).

Two of the candidates for president in the 2004 race called Austin home. Michael Badnarik, the Libertarian Party candidate, and David Cobb of the Green Party both had lived in Austin. During the run up to the election in November, a presidential debate was held at the University of Texas at Austin student union involving the two candidates. While the Commission on Presidential Debates only invites Democrats and Republicans to participate in televised debates, the debate at UT was open to all presidential candidates. Austin also hosted one of the last presidential debates between Barack Obama and Hillary Clinton during their heated race for the Democratic nomination in 2008.

In the 2016 presidential election, Travis County, which contains the majority of Austin, voted for Hillary Clinton (D) by a 38.9-point margin (66.3% to 27.4%).

A controversial turning point in the political history of the Austin area was the 2003 Texas redistricting. Before then, Austin had been entirely or almost entirely within the borders of a single congressional district–what was then the 10th District–for over a century. Opponents characterized the resulting district layout as excessively partisan gerrymandering, and the plan was challenged in court by Democratic and minority activists; of note, the Supreme Court of the United States has never struck down a redistricting plan for being excessively partisan. The plan was subsequently upheld by a three-judge federal panel in late 2003, and on June 28, 2006, the matter was largely settled when the Supreme Court, in a 7–2 decision, upheld the entire congressional redistricting plan with the exception of a Hispanic-majority district in southwest Texas. This affected Austin's districting, as U.S. Rep. Lloyd Doggett's district (U.S. Congressional District 25) was found to be insufficiently compact to compensate for the reduced minority influence in the southwest district; it was redrawn so that it took in most of southeastern Travis County and several counties to its south and east.

The distinguishing political movement of Austin politics has been that of the environmental movement, which spawned the parallel neighborhood movement, then the more recent conservationist movement (as typified by the Hill Country Conservancy), and eventually the current ongoing debate about "sense of place" and preserving the Austin quality of life. Much of the environmental movement has matured into a debate on issues related to saving and creating an Austin "sense of place." In 2012, Austin became just one of a few cities in Texas to ban the sale and use of plastic bags. However, the ban ended in 2018 due to a court ruling that regarded all bag bans in the state to contravene the Texas Solid Waste Disposal Act.

Researchers at Central Connecticut State University ranked Austin the 16th most literate city in the United States for 2008. In addition, the University of Texas at Austin operates the seventh-largest academic library in the nation.

Austin was voted "America's No.1 College Town" by the Travel Channel. Over 43 percent of Austin residents age 25 and over hold a bachelor's degree, while 16 percent hold a graduate degree. In 2009, greater Austin ranked eighth among metropolitan areas in the United States for bachelor's degree attainment with nearly 39 percent of area residents over 25 holding a bachelor's degree.

Austin is home to the University of Texas at Austin, the flagship institution of the University of Texas System with over 38,000 undergraduate students and 12,000 graduate students. In 2019 rankings, the university was ranked 49th among "National Universities" by "U.S. News & World Report." UT has annual research expenditures of over $600 million and has the highest-ranked business, engineering, and law programs of any university in the state of Texas.

Other institutions of higher learning in Austin include St. Edward's University, Huston-Tillotson University, Austin Community College, Concordia University, the Seminary of the Southwest, the Acton School of Business, Texas Health and Science University, University of St. Augustine for Health Sciences, Austin Graduate School of Theology, Austin Presbyterian Theological Seminary, Virginia College's Austin Campus, The Art Institute of Austin, Southern Careers Institute of Austin, Austin Conservatory and a branch of Park University.

The University of Texas System and Texas State University System are headquartered in downtown Austin.

The Austin area has 29 public school districts, 17 charter schools and 69 private schools. Most of the city is served by the Austin Independent School District. This district includes notable schools such as the magnet Liberal Arts and Science Academy High School of Austin, Texas (LASA), which, by test scores, has consistently been within the top thirty high schools in the nation, as well as The Ann Richards School for Young Women Leaders. Some parts of Austin are served by other districts, including Round Rock, Pflugerville, Leander, Manor, Del Valle, Lake Travis, Hays, and Eanes ISDs. Four of the metro's major public school systems, representing 54% of area enrollment, are included in "Expansion Management" magazine's latest annual education quality ratings of nearly 2,800 school districts nationwide. Two districts—Eanes and Round Rock—are rated "gold medal," the highest of the magazine's cost-performance categories.

Austin has a large network of private and alternative education institutions for children in preschool-12th grade exists.

Austin is also home to child developmental institutions.

Austin's main daily newspaper is the "Austin American-Statesman". "The Austin Chronicle" is Austin's alternative weekly, while "The Daily Texan" is the student newspaper of the University of Texas at Austin. Austin's business newspaper is the weekly "Austin Business Journal". "The Austin Monitor" is an online outlet that specializes in insider reporting on City Hall, Travis County Commissioners Court, AISD, and other related local civics beats. The "Monitor" is backed by the nonprofit Capital of Texas Media Foundation. Austin also has numerous smaller special interest or sub-regional newspapers such as the "Oak Hill Gazette", "Westlake Picayune", "Hill Country News", "Round Rock Leader", "NOKOA", and "The Villager" among others. "Texas Monthly", a major regional magazine, is also headquartered in Austin. The "Texas Observer", a muckraking biweekly political magazine, has been based in Austin for over five decades. The weekly "Community Impact Newspaper" published by John Garrett, former publisher of the "Austin Business Journal" has five regional editions and is delivered to every house and business within certain ZIP Codes and all of the news is specific to those ZIP Codes. Another statewide publication based in Austin is "The Texas Tribune", an on-line publication focused on Texas politics. The "Tribune" is "user-supported" through donations, a business model similar to public radio. The editor is Evan Smith, former editor of "Texas Monthly". Smith co-founded the "Texas Tribune", a nonprofit, non-partisan public media organization, with Austin venture capitalist John Thornton and veteran journalist Ross Ramsey.

Commercial radio stations include KASE-FM (country), KVET (sports), KVET-FM (country), KKMJ-FM (adult contemporary), KLBJ (talk), KLBJ-FM (classic rock), KTSN (progressive country), KFMK (contemporary Christian), KOKE-FM (progressive country) and KPEZ (rhythmic contemporary). KUT-FM is the leading public radio station in Texas and produces the majority of its content locally. KOOP (FM) is a volunteer-run radio station with more than 60 locally produced programs. KVRX is the student-run college radio station of the University of Texas at Austin with a focus on local and non-mainstream music and community programming. Other listener-supported stations include KAZI (urban contemporary), and KMFA (classical)

Network television stations (affiliations in parentheses) include KTBC (Fox O&O), KVUE (ABC), KXAN (NBC), KEYE-TV (CBS), KLRU (PBS), KNVA (The CW), KBVO (My Network TV), and KAKW (Univision O&O). KLRU produces several award-winning locally produced programs such as "Austin City Limits".

Alex Jones, conspiracist, radio show host and filmmaker, produces his talk show "The Alex Jones Show" in Austin which broadcasts nationally on more than 60 AM and FM radio stations in the United States, WWCR Radio shortwave and XM Radio: Channel 166.

In 2009, 72.7% of Austin (city) commuters drove alone, with other mode shares being: 10.4% carpool, 6% work from home, 5% use transit, 2.3% walk, and 1% bicycle. In 2016, the American Community Survey estimated modal shares for Austin (city) commuters of 73.5% for driving alone, 9.6% for carpooling, 3.6% for riding transit, 2% for walking, and 1.5% for cycling. The city of Austin has a lower than average percentage of households without a car. In 2015, 6.9 percent of Austin households lacked a car, and decreased slightly to 6 percent in 2016. The national average is 8.7 percent in 2016. Austin averaged 1.65 cars per household in 2016, compared to a national average of 1.8.

Austin has the worst traffic in Texas and one of the worst in the country. 

Central Austin lies between two major north-south freeways: Interstate 35 to the east and the Mopac Expressway (Loop 1) to the west. U.S. Highway 183 runs from northwest to southeast, and State Highway 71 crosses the southern part of the city from east to west, completing a rough "box" around central and north-central Austin. Austin is the largest city in the United States to be served by only one Interstate Highway.

U.S. Highway 290 enters Austin from the east and merges into Interstate 35. Its highway designation continues south on I-35 and then becomes part of Highway 71, continuing to the west. Highway 290 splits from Highway 71 in southwest Austin, in an interchange known as "The Y." Highway 71 continues to Brady, Texas, and Highway 290 continues west to intersect Interstate 10 near Junction. Interstate 35 continues south through San Antonio to Laredo on the Texas-Mexico border. Interstate 35 is the highway link to the Dallas-Fort Worth metro-plex in northern Texas. There are two links to Houston, Texas (Highway 290 and State Highway 71/Interstate 10). Highway 183 leads northwest of Austin toward Lampasas.

In the mid-1980s, construction was completed on Loop 360, a scenic highway that curves through the hill country from near the 71/Mopac interchange in the south to near the 183/Mopac interchange in the north. The iconic Pennybacker Bridge, also known as the "360 Bridge," crosses Lake Austin to connect the northern and southern portions of Loop 360.

State Highway 130 is a bypass route designed to relieve traffic congestion, starting from Interstate 35 just north of Georgetown and running along a parallel route to the east, where it bypasses Round Rock, Austin, San Marcos and New Braunfels before ending at Interstate 10 east of Seguin, where drivers could drive west to return to Interstate 35 in San Antonio. The first segment was opened in November 2006, which was located east of Austin–Bergstrom International Airport at Austin's southeast corner on State Highway 71. Highway 130 runs concurrently with Highway 45 from Pflugerville on the north until it reaches US 183 well south of Austin, where it splits off and goes west. The entire route of State Highway 130 is now complete with last leg, which opened on November 1, 2012. The highway is noted for having the entire route with a speed limit of at least . The 41-mile section of the toll road between Mustang Ridge and Seguin has a posted speed limit of , the highest posted speed limit in the United States.

State Highway 45 runs east-west from just south of Highway 183 in Cedar Park to 130 inside Pflugerville (just east of Round Rock). A tolled extension of State Highway Loop 1 was also created. A new southeast leg of Highway 45 has recently been completed, running from US 183 and the south end of Segment 5 of TX-130 south of Austin due west to I-35 at the FM 1327/Creedmoor exit between the south end of Austin and Buda. The 183A Toll Road opened March 2007, providing a tolled alternative to U.S. 183 through the cities of Leander and Cedar Park. Currently under construction is a change to East US 290 from US 183 to the town of Manor. Officially, the tollway will be dubbed Tollway 290 with the Manor Expressway as a nickname.
Despite the overwhelming initial opposition to the toll road concept when it was first announced, all three toll roads have exceeded revenue projections.

Austin's airport is Austin–Bergstrom International Airport (ABIA) ( AUS), located southeast of the city. The airport is on the site of the former Bergstrom Air Force Base, which was closed in 1993 as part of the Base Realignment and Closure process. Previously, Robert Mueller Municipal Airport was the commercial airport of Austin. Austin Executive Airport serves the general aviation coming into the city, as well as other smaller airports outside of the city center.

Greyhound Lines operates the Austin Station at 916 East Koenig Lane, just east of Airport Boulevard and adjacent to Highland Mall. Turimex Internacional operates bus service from Austin to Nuevo Laredo and on to many destinations in Mexico. The Turimex station is located at 5012 East 7th Street, near Shady Lane.

Megabus offers daily service to San Antonio, Dallas/Fort Worth and Houston from a stop at Dobie Center.

An Amtrak "Texas Eagle" station is located in west downtown. Railway segments between Austin and San Antonio have been evaluated for a proposed regional passenger rail project called "Lone Star Rail"; however, failure to come to an agreement with the Union Pacific Railroad, the tracks' current owner, ended the project in 2016.

The Capital Metropolitan Transportation Authority ("Capital Metro") provides public transportation to the city, primarily by bus. Some heavily utilized routes feature bus rapid transit, with long, train-like, high-tech buses.

Capital Metro opened a commuter rail system known as Capital MetroRail on March 22, 2010. The system operates on existing freight rail lines and serves downtown Austin, East Austin, North Central Austin, Northwest Austin, and Leander in its first phase. Future expansion could include a line to Manor and another to Round Rock. The MetroRail system has struggled to build ridership and has faced heavy criticism for its high per-rider cost to the public.

Capital Metro has also explored building a light rail system to connect the MetroRail line to key destinations in Central Austin. On August 7, 2014, the Austin City Council unanimously voted to place a $600 million light rail bond proposal on the November 4, 2014 ballot; the ballot measure was voted down, and no further rail expansions have been put to voters since.

Capital Area Rural Transportation System connects Austin with outlying suburbs.

In Summer 2018, Capital Metro began testing autonomous electric shuttles on Downtown streets; the pilot program tested two driverless bus models from EasyMile and Navya on a route from the Austin Convention Center to the Austin Central Library. Capital Metro is also considering implementing full-size driverless buses, likely to be included on a 2020 transportation referendum.

Austin is served by several ride-sharing companies including Uber, Lyft, and RideAustin. On May 9, 2016, Uber and Lyft voluntarily ceased operations in Austin in response to a city ordinance that required drivers for Uber, Lyft, and other transportation network companies to get fingerprint checks, to have their vehicles labeled, and to not pick up and drop off in certain city lanes. Uber and Lyft resumed service in Summer 2017. The city was also served by Fasten until they ceased all Austin operations in March 2018.

The City of Austin is partnered with Austin B-cycle, a nonprofit bike-sharing service with 63 stations in and around downtown for electric bicycles. In 2018, LimeBike began offering dockless bikes, which do not need to be docked at a designation station.

In 2018, scooter-sharing companies LimeBike and Bird debuted electric scooters in Austin. The city briefly banned the scooters - which were operating without a permit - until the city unveiled their "dockless mobility" permitting process on May 1, 2018. Dockless electric scooters and bikes are banned from Austin city parks, the University of Texas campus, and the Ann and Roy Butler Trail and boardwalk. For the 2018 Austin City Limits Music Festival, the city of Austin offered a designated parking area for dockless bikes and scooters.

Austin is also served by Electric Cab of North America's six-passenger electric cabs that operate on a flexible route from the Kramer MetroRail Station to Domain Northside and from the Downtown MetroRail station and MetroRapid stops to locations between the Austin Convention Center and near Sixth and Bowie streets by Whole Foods.

The city also has access to carsharing services from Car2Go and Zipcar.

Austin is known as the most bike-friendly city in Texas, and was ranked the #7 city in the US by Bicycling Magazine in 2016.

The city's bike advocacy organization is Bike Austin. Bike Texas, a state-level advocacy organization, also has its main office in Austin.

Bicycles are a popular transportation choice among students, faculty, and staff at the University of Texas. According to a survey done at the University of Texas, 57% of commuters bike to campus.

A 2013 study by Walk Score ranked Austin 35th most walkable of the 50 largest U.S. cities. More recently, Walk Score rated some Austin neighborhoods among the most walkable in Texas. Downtown Austin scored 88 points out of a possible 100, with the West Campus neighborhood scoring 87, and East Austin scoring 81.

The following are sister cities of Austin, Texas, designated by Sister Cities International:

The cities of Belo Horizonte, Minas Gerais, Brazil and Elche, Alicante, Valencian Community, Spain were formerly sister cities, but upon a vote of the Austin City Council in 1991, their status was de-activated.






</doc>
<doc id="2003" url="https://en.wikipedia.org/wiki?curid=2003" title="Argument from morality">
Argument from morality

The argument from morality is an argument for the existence of God. Arguments from morality tend to be based on moral normativity or moral order. Arguments from moral normativity observe some aspect of morality and argue that God is the best or only explanation for this, concluding that God must exist. Arguments from moral order are based on the asserted need for moral order to exist in the universe. They claim that, for this moral order to exist, God must exist to support it. The argument from morality is noteworthy in that one cannot evaluate the soundness of the argument without attending to almost every important philosophical issue in meta-ethics.

German philosopher Immanuel Kant devised an argument from morality based on practical reason. Kant argued that the goal of humanity is to achieve perfect happiness and virtue (the summum bonum) and believed that an afterlife must exist in order for this to be possible, and that God must exist to provide this. In his book "Mere Christianity", C. S. Lewis argued that "conscience reveals to us a moral law whose source cannot be found in the natural world, thus pointing to a supernatural Lawgiver." Lewis argued that accepting the validity of human reason as a given must include accepting the validity of practical reason, which could not be valid without reference to a higher cosmic moral order which could not exist without a God to create and/or establish it. A related argument is from conscience; John Henry Newman argued that the conscience supports the claim that objective moral truths exist because it drives people to act morally even when it is not in their own interest. Newman argued that, because the conscience suggests the existence of objective moral truths, God must exist to give authority to these truths.

Contemporary defenders of the argument from morality are Graham Ward, Alister McGrath and William Lane Craig.

All variations of the argument from morality begin with an observation about moral thought or experiences and conclude with the existence of God. Some of these arguments propose moral facts which they claim evident through human experience, arguing that God is the best explanation for these. Other versions describe some end which humans should strive to attain that is only possible if God exists.

Many arguments from morality are based on moral normativity, which suggests that objective moral truths exist and require God's existence to give them authority. Often, they consider that morality seems to be binding – obligations are seen to convey more than just a preference, but imply that the obligation will stand, regardless of other factors or interests. For morality to be binding, God must exist. In its most general form, the argument from moral normativity is:


Some arguments from moral order suggest that morality is based on rationality and that this can only be the case if there is a moral order in the universe. The arguments propose that only the existence of God as orthodoxly conceived could support the existence of moral order in the universe, so God must exist. Alternative arguments from moral order have proposed that we have an obligation to attain the perfect good of both happiness and moral virtue. They attest that whatever we are obliged to do must be possible, and achieving the perfect good of both happiness and moral virtue is only possible if a natural moral order exists. A natural moral order requires the existence of God as orthodoxly conceived, so God must exist.

In his "Critique of Pure Reason", German philosopher Immanuel Kant stated that no successful argument for God's existence arises from reason alone. In his "Critique of Practical Reason" he went on to argue that, despite the failure of these arguments, morality requires that God's existence is assumed, owing to practical reason. Rather than proving the existence of God, Kant was attempting to demonstrate that all moral thought requires the assumption that God exists. Kant argued that humans are obliged to bring about the "summum bonum": the two central aims of moral virtue and happiness, where happiness arises out of virtue. As ought implies can, Kant argued, it must be possible for the "summum bonum" to be achieved. He accepted that it is not within the power of humans to bring the "summum bonum" about, because we cannot ensure that virtue always leads to happiness, so there must be a higher power who has the power to create an afterlife where virtue can be rewarded by happiness.

Philosopher G. H. R. Parkinson notes a common objection to Kant's argument: that what ought to be done does not necessarily entail that it is possible. He also argues that alternative conceptions of morality exist which do not rely on the assumptions that Kant makes – he cites utilitarianism as an example which does not require the "summum bonum". Nicholas Everitt argues that much moral guidance is unattainable, such as the Biblical command to be Christ-like. He proposes that Kant's first two premises only entail that we must try to achieve the perfect good, not that it is actually attainable.

Both theists and non-theists have accepted that the existence of objective moral truths might entail the existence of God. Atheist philosopher J. L. Mackie accepted that, if objective moral truths existed, they would warrant a supernatural explanation. Scottish philosopher W. R. Sorley presented the following argument:

Many critics have challenged the second premise of this argument, by offering a biological and sociological account of the development of human morality which suggests that it is neither objective nor absolute. This account, supported by biologist E. O. Wilson and philosopher Michael Ruse, proposes that the human experience of morality is a by-product of natural selection, a theory philosopher Mark D. Linville calls evolutionary naturalism. According to the theory, the human experience of moral obligations was the result of evolutionary pressures, which attached a sense of morality to human psychology because it was useful for moral development; this entails that moral values do not exist independently of the human mind. Morality might be better understood as an evolutionary imperative in order to propagate genes and ultimately reproduce. No human society today advocates immorality, such as theft or murder, because it would undoubtedly lead to the end of that particular society and any chance for future survival of offspring. Scottish empiricist David Hume made a similar argument, that belief in objective moral truths is unwarranted and to discuss them is meaningless.

Because evolutionary naturalism proposes an empirical account of morality, it does not require morality to exist objectively; Linville considers the view that this will lead to moral scepticism or antirealism. C. S. Lewis argued that, if evolutionary naturalism is accepted, human morality cannot be described as absolute and objective because moral statements cannot be right or wrong. Despite this, Lewis argued, those who accept evolutionary naturalism still act as if objective moral truths exist, leading Lewis to reject naturalism as incoherent. As an alternative ethical theory, Lewis offered a form of divine command theory which equated God with goodness and treated goodness as an essential part of reality, thus asserting God's existence.

J.C.A. Gaskin challenges the first premise of the argument from moral objectivity, arguing that it must be shown why absolute and objective morality entails that morality is commanded by God, rather than simply a human invention. It could be the consent of humanity that gives it moral force, for example. American philosopher Michael Martin argues that it is not necessarily true that objective moral truths must entail the existence of God, suggesting that there could be alternative explanations: he argues that naturalism may be an acceptable explanation and, even if a supernatural explanation is necessary, it does not have to be God (polytheism is a viable alternative). Martin also argues that a non-objective account of ethics might be acceptable and challenges the view that a subjective account of morality would lead to moral anarchy.

William Lane Craig has argued for this form of the moral argument.

Related to the argument from morality is the argument from conscience, associated with eighteenth-century bishop Joseph Butler and nineteenth-century cardinal John Henry Newman. Newman proposed that the conscience, as well as giving moral guidance, provides evidence of objective moral truths which must be supported by the divine. He argued that emotivism is an inadequate explanation of the human experience of morality because people avoid acting immorally, even when it might be in their interests. Newman proposed that, to explain the conscience, God must exist.

British philosopher John Locke argued that moral rules cannot be established from conscience because the differences in people's consciences would lead to contradictions. Locke also noted that the conscience is influenced by "education, company, and customs of the country", a criticism mounted by J. L. Mackie, who argued that the conscience should be seen as an "introjection" of other people into an agent's mind. Michael Martin challenges the argument from conscience with a naturalistic account of conscience, arguing that naturalism provides an adequate explanation for the conscience without the need for God's existence. He uses the example of the internalization by humans of social pressures, which leads to the fear of going against these norms. Even if a supernatural cause is required, he argues, it could be something other than God; this would mean that the phenomenon of the conscience is no more supportive of monotheism than polytheism.

C. S. Lewis argues for the existence of God in a similar way in his book "Mere Christianity", but he does not directly refer to it as the argument from morality.




</doc>
<doc id="2004" url="https://en.wikipedia.org/wiki?curid=2004" title="ASL (disambiguation)">
ASL (disambiguation)

ASL is a common initialism for American Sign Language, the sign language of the United States and Canada, and may also refer to:










</doc>
<doc id="2006" url="https://en.wikipedia.org/wiki?curid=2006" title="Auschwitz concentration camp">
Auschwitz concentration camp

The Auschwitz concentration camp ("Konzentrationslager Auschwitz") was a complex of over 40 concentration and extermination camps built and operated by Nazi Germany in occupied Poland during World War II and the Holocaust. It consisted of Auschwitz I, the main camp ("Stammlager") and administrative headquarters in Oświęcim; Auschwitz II–Birkenau, a combined concentration and extermination camp three kilometers away in Brzezinka; , a labor camp created to staff an IG Farben synthetic-rubber factory; and dozens of other subcamps.

After Germany invaded Poland in September 1939, sparking World War II, the Germans converted Auschwitz I, a former army barracks, to hold Polish political prisoners. The first prisoners, German criminals brought to the camp as functionaries, arrived in May 1940, and the first gassing of prisoners took place in block 11 of Auschwitz I in September 1941. Auschwitz II–Birkenau went on to become a major site of the Nazis' Final Solution to the Jewish Question. From early 1942 until late 1944, transport trains delivered Jews from all over German-occupied Europe to the camp's gas chambers. Of the estimated 1.3 million people sent to Auschwitz, at least 1.1 million died, around 90 percent of them Jews. Approximately one in six Jews killed in the Holocaust died at the camp. Others deported to Auschwitz included 150,000 non-Jewish Poles, 23,000 Roma, 15,000 Soviet prisoners of war, 400 Jehovah's Witnesses, tens of thousands of others of diverse nationalities, and an unknown number of gay men. Many of those not killed in the gas chambers died because of starvation, forced labor, infectious diseases, individual executions, and medical experiments.

In the course of the war, the camp was staffed by 7,000 members of the German "Schutzstaffel" (SS), approximately 12 percent of whom were later convicted of war crimes; several, including camp commandant Rudolf Höss, were executed. The Allies did not act on early reports of atrocities at the camp, and their failure to bomb the camp or its railways remains controversial. At least 802 prisoners tried to escape from Auschwitz, 144 successfully, and on 7 October 1944 two "Sonderkommando" units, consisting of prisoners assigned to staff the gas chambers, launched a brief, unsuccessful uprising.

As Soviet troops approached Auschwitz in January 1945, most of its population was sent west on a death march. The remaining prisoners were liberated on 27 January 1945, a day commemorated as International Holocaust Remembrance Day. In the following decades, survivors such as Primo Levi, Viktor Frankl, and Elie Wiesel wrote memoirs of their experiences in Auschwitz, and the camp became a dominant symbol of the Holocaust. In 1947 Poland founded the Auschwitz-Birkenau Memorial and Museum on the site of Auschwitz I and II, and in 1979 it was named a World Heritage Site by UNESCO.

The ideology of Nazism brought together elements of antisemitism, racial hygiene and eugenics, and combined them with pan-Germanism and territorial expansionism with the goal of obtaining more "Lebensraum" (living space) for the Germanic people. Immediately after the Nazi seizure of power in Germany, boycotts of German Jews and acts of violence against them became ubiquitous, and legislation was passed excluding them from the civil service and certain professions, including the law. Harassment and economic pressure were used to encourage them to leave Germany; their businesses were denied access to markets, forbidden to advertise in newspapers, and deprived of government contracts.

On 15 September 1935, the Reichstag passed the Nuremberg Laws, prohibiting marriages between Jews and people of Germanic extraction, extramarital relations between Jews and Germans, and the employment of German women under the age of 45 as domestic servants in Jewish households. The Reich Citizenship Law defined as citizens those of "German or kindred blood". Thus Jews and other minorities were stripped of their citizenship. By the start of World War II in 1939, around 250,000 of Germany's 437,000 Jews had emigrated to the United States, Palestine, the United Kingdom, and other countries.

When Germany invaded Poland in September 1939, triggering World War II, Adolf Hitler ordered that the Polish leadership and intelligentsia be destroyed. Approximately 65,000 civilians, viewed as inferior to the Aryan master race, had been killed by the end of 1939. In addition to leaders of Polish society, the Nazis killed Jews, prostitutes, the Roma, and the mentally ill. SS-"Obergruppenführer" Reinhard Heydrich, then head of the Gestapo, ordered on 21 September 1939 that Polish Jews be rounded up and concentrated into cities with good rail links. Initially the intention was to deport them to points further east, or possibly to Madagascar. Two years later, in June 1941, in an attempt to obtain new territory, Hitler invaded the Soviet Union.

Auschwitz I, a former Polish army barracks, was the main camp ("Stammlager") and administrative headquarters of the camp complex. Intending to use it to house political prisoners, "Reichsführer-SS" Heinrich Himmler, head of the "Schutzstaffel" (SS), approved the site in April 1940 on the recommendation of SS-"Obersturmbannführer" (lieutenant colonel) Rudolf Höss, then of the Concentration Camps Inspectorate. Höss oversaw the development of the camp and served as its first commandant, with SS-"Obersturmführer" (senior lieutenant) Josef Kramer as his deputy. Around 1,000 m long and 400 m wide, Auschwitz I consisted of 20 brick buildings, six of them two-story; a second story was added to the others in 1943 and eight new blocks were built. The camp housed the SS barracks and by 1943 held 30,000 inmates.

The first 30 prisoners arrived on 20 May 1940 after being transported from the Sachsenhausen concentration camp in Oranienburg, Germany. Convicted German criminals ("Berufsverbrecher"), the men were known as "greens" after the green triangles they were required to wear on their prison clothing. Brought to the camp as functionaries, this group did much to establish the sadism of early camp life, which was directed particularly at Polish inmates, until the political prisoners began to take over their roles. Bruno Brodniewitsch, the first prisoner, became "Lagerältester" (camp elder), and the others were given positions such as kapo and block supervisor.

The first mass transport of 728 Polish male political prisoners, including Catholic priests and Jews, arrived on 14 June 1940 from Tarnów, Poland. They were given serial numbers 31 to 758. By the end of 1940, the SS had confiscated land around the camp to create a "zone of interest" surrounded by a double ring of electrified barbed wire fences and watchtowers. The inmate population grew quickly. By March 1941, 10,900 were imprisoned there, most of them Poles.

An inmate's first encounter with the camp, if they were being registered and not sent straight to the gas chamber, would be at the prisoner reception centre, where they were tattooed, shaved, disinfected, and given their striped prison uniform. Built between 1942 and 1944, the center contained a bathhouse, laundry, and 19 gas chambers for delousing clothes. Debórah Dwork and Robert Jan van Pelt write that inmates would then leave this area via a porch that faced the gate with the "Arbeit macht frei" sign. The prisoner reception center of Auschwitz I became the visitor reception center of the Auschwitz-Birkenau Memorial and Museum.

Construction of crematorium I began at Auschwitz I at the end of June or beginning of July 1940. Initially intended not for mass murder but for prisoners who had been executed or had otherwise died in the camps, the crematorium was in operation from August 1940 until July 1943, by which time the crematoria at Auschwitz II had taken over. By May 1942 three ovens had been installed in crematorium I, which together could burn 340 bodies in 24 hours.

The first experimental gassing took place in September 1941, when Lagerführer Karl Fritzsch, at the instruction of Rudolf Höss, killed a group of Soviet prisoners of war by throwing Zyklon B crystals into their basement cell in block 11 of Auschwitz I. A second group of 600 Soviet prisoners of war and around 250 sick Polish prisoners was gassed on 3–5 September. The morgue was later converted to a gas chamber able to hold at least 700–800 people. Zyklon B was dropped into the room through slits in the ceiling. In the view of Filip Müller, one of the "Sonderkommando" who worked in crematorium I, tens of thousands of Jews were killed there from France, Holland, Slovakia, Upper Silesia, Yugoslavia, and from the Theresienstadt, Ciechanow, and Grodno ghettos. The last inmates to be gassed in Auschwitz I, in December 1942, were 300–400 members of the Auschwitz II "Sonderkommando", who had been forced to dig up that camp's mass graves, thought to hold 100,000 corpses, and burn the remains.

The site was first suggested as a concentration camp for Polish prisoners by "SS-Oberführer" Arpad Wigand, an aide to Erich von dem Bach-Zelewski, Higher SS and Police Leader for Silesia. After this part of Poland was annexed by Nazi Germany, Oświęcim (Auschwitz) was located administratively in Germany, in the Province of Upper Silesia, Regierungsbezirk Kattowitz, Landkreis Bielitz. Bach-Zelewski had been searching for a site to hold prisoners in the Silesia region, as the local prisons were filled to capacity. Richard Glücks, head of the Concentration Camps Inspectorate, sent former Sachsenhausen concentration camp commandant Walter Eisfeld to inspect the site, which housed 16 dilapidated one-story buildings that had served as an Austrian and later Polish Army barracks and a camp for transient workers. German citizens were offered tax concessions and other benefits if they would relocate to the area. By October 1943, more than 6,000 Reich Germans had arrived. The Nazis planned to build a model modern residential area for incoming Germans, including schools, playing fields, and other amenities. Some of the plans went forward, including the construction of several hundred apartments, but many were never fully implemented. Basic amenities such as water and sewage disposal were inadequate, and water-borne illnesses were commonplace.

The victories of Operation Barbarossa in the summer and fall of 1941 against Hitler's new enemy, the Soviet Union, led to dramatic changes in Nazi anti-Jewish ideology and the profile of prisoners brought to Auschwitz. Construction on Auschwitz II-Birkenau began in October 1941 to ease congestion at the main camp. "Reichsführer-SS" Heinrich Himmler, head of the "Schutzstaffel" (SS), intended the camp to house 50,000 prisoners of war, who would be interned as forced laborers. Plans called for the expansion of the camp first to house 150,000 and eventually as many as 200,000 inmates. An initial contingent of 10,000 Soviet prisoners of war arrived at Auschwitz I in October 1941, but by March 1942 only 945 were still alive, and these were transferred to Birkenau, where most of them died from disease or starvation by May. By this time the Nazis had decided to annihilate the Jewish people, so Birkenau became a labor and extermination camp.

The chief of construction of Auschwitz II-Birkenau was Karl Bischoff, a competent and dynamic bureaucrat who, in spite of the ongoing war, carried out the construction deemed necessary. The Birkenau camp, the four crematoria, a new reception building, and hundreds of other buildings were planned and constructed. Bischoff's plans, based on an initial budget of RM 8.9 million, called for each barracks to hold 550 prisoners. He later changed this to 744 per barracks, which meant the camp could hold 125,000, rather than 97,000. The SS designed the barracks not so much to house people as to destroy them. There were 174 barracks, each measuring , divided into 62 bays of . The bays were divided into "roosts", initially for three inmates and later for four. With personal space of to sleep and place whatever belongings they had, inmates were deprived, Robert-Jan van Pelt wrote, "of the minimum space needed to exist".

The first gas chamber at Birkenau was in what prisoners called the "little red house" (known as bunker 1 by the SS), a brick cottage that had been converted into a gassing facility. The windows were bricked up and its four rooms converted into two insulated rooms, the doors of which said ""Zur Desinfektion"" ("to disinfection"). It was operational by March 1942. A second brick cottage, the "little white house" or bunker 2, was converted and operational by June 1942. When Himmler visited the camp on 17 and 18 July 1942, he was given a demonstration of a selection of Dutch Jews, a mass killing in a gas chamber in bunker 2, and a tour of the building site of the new IG Farben plant being constructed at the nearby town of Monowitz.

Use of bunkers I and 2 stopped in spring 1943 when the new crematoria were built, although bunker 2 became operational again in May 1944 for the murder of the Hungarian Jews. Crematorium II, which had been designed as a mortuary with morgues in the basement and ground-level incinerators, was converted by installing gas-tight doors, vents for the Zyklon B to be dropped into the chamber, and ventilation equipment to remove the gas thereafter. It went into operation in March 1943. Crematorium III was built using the same design. Crematoria IV and V, designed from the start as gassing centers, were also constructed that spring. By June 1943, all four crematoria were operational. Most of the victims were killed using these four structures.

After examining several sites for a new plant to manufacture Buna-N, a type of synthetic rubber essential to the war effort, the German chemical cartel IG Farben chose a site near the towns of Dwory and Monowice (Monowitz in German), about east of Auschwitz I. Tax exemptions were available to corporations prepared to develop industries in the frontier regions under the Eastern Fiscal Assistance Law, passed in December 1940. The site had good railway connections and access to raw materials. In February 1941, Himmler ordered that the Jewish population of Oświęcim be expelled to make way for skilled laborers; that all Poles able to work remain in the town and work on building the factory; and that Auschwitz prisoners be used in the construction work.

Auschwitz inmates began working at the plant, known as Buna Werke and IG Auschwitz, in April 1941, and demolishing houses in Monowitz to make way for it. By May, because of a shortage of trucks, several hundred of them were rising at 3 am to walk there twice a day from Auschwitz I. Anticipating that a long line of exhausted inmates walking through the town of Oświęcim might harm German-Polish relations, the inmates were told to shave daily, make sure they were clean, and sing as they walked. From late July they were taken there by train on freight wagons. Because of the difficulty of moving them, including during the winter, IG Farben decided to build a camp at the plant. The first inmates moved there on 30 October 1942. Known as "KL Auschwitz III-Aussenlager" (Auschwitz III-subcamps), and later as Monowitz concentration camp, it was the first concentration camp to be financed and built by private industry.
Measuring , the camp was larger than Auschwitz I. By the end of 1944, it housed 60 barracks measuring , each with a day room and a sleeping room containing 56 three-tiered wooden bunks. IG Farben paid the SS three or four Reichsmark for nine- to eleven-hour shifts from each worker. In 1943–1944, about 35,000 inmates worked at the plant; 23,000 (32 a day on average) died as a result of malnutrition, disease, and the workload. Deaths and transfers to Birkenau reduced the population by nearly a fifth each month; site managers constantly threatened inmates with the gas chambers. In addition to the Auschwitz inmates, who comprised a third of the work force, IG Auschwitz employed slave laborers from all over Europe. When the camp was liquidated in January 1945, 9,054 out of the 9,792 inmates were Jews.

Although the factory had been expected to begin production in 1943, shortages of labor and raw materials meant start-up had to be postponed repeatedly. The Allies bombed the plant in 1944 on 20 August, 13 September, 18 December, and again on 26 December. On 19 January 1945, the SS ordered that the site be evacuated, sending 9,000 inmates on a death march to another Auschwitz subcamp at Gliwice. The plant had almost been ready to commence production. From Gliwice, prisoners were taken by rail in open freight wagons to Buchenwald and Mauthausen concentration camps. The 800 inmates who had been left behind in the Monowitz hospital were liberated on 27 January 1945 by the 1st Ukrainian Front of the Red Army.

Various other German industrial enterprises, such as Krupp and Siemens-Schuckert, built factories with their own subcamps. There were around 40 or 50 such camps, 28 of them near industrial plants, each camp holding hundreds or thousands of prisoners. Designated as "Aussenlager" (external camp), "Nebenlager" (extension or subcamp), or "Arbeitslager" (labor camp), camps were built at Blechhammer, Jawiszowice, Jaworzno, Lagisze, Mysłowice, Trzebinia, and centers as far afield as the Protectorate of Bohemia and Moravia in Czechoslovakia. Industries with satellite camps included coal mines, foundries and other metal works, and chemical plants. Prisoners were also made to work in forestry and farming. Budy, for example, was a farming subcamp where prisoners worked 12-hour days, often in the fields, but sometimes tending animals, cleaning ponds, digging ditches, and making compost. Human ashes from the crematorium were mixed with sod and manure to make the compost. Incidents of sabotage to decrease production took place in several subcamps, including Charlottengrube, Gleiwitz II, and Rajsko.

Born in Baden-Baden in 1900, "SS Obersturmbannführer" Rudolf Höss became the first commandant of Auschwitz when the camp was founded in April 1940, living with his wife and children in a villa just outside the camp grounds. Appointed by Heinrich Himmler, he served until 11 November 1943, when he became director of Office DI of the "SS-Wirtschafts-und Verwaltungshauptamt" (SS Business and Administration Head Office or WVHA) in Oranienburg. This post made Höss deputy of the Concentration Camps Inspectorate, under "SS-Gruppenführer" Richard Glücks. He returned to Auschwitz between 8 May and 29 July 1944 as commander of the SS garrison ("Standortältester") to oversee the arrival of Hungary's Jews, a post that made him the superior officer of all the commandants of the Auschwitz camps.

Höss was succeeded as Auschwitz commandant in November 1943 by "SS Obersturmbannführer" Arthur Liebehenschel, who served until 15 May 1944. "SS Sturmbannführer" Richard Baer became commandant of Auschwitz I on 11 May 1944, and "SS Obersturmbannführer" Fritz Hartjenstein of Auschwitz II from 22 November 1943, followed by "SS Obersturmbannführer" Josef Kramer from 15 May 1944 until the camp's liquidation in January 1945. Heinrich Schwarz was commandant of Auschwitz III from the point at which it became an autonomous camp in November 1943 until its liquidation.

Around 7,000 SS personnel were posted to Auschwitz during the war. Of these, 4 percent of SS personnel were officers and 26 percent were non-commissioned officers, while the remainder were rank-and-file members. Camp guards were members of the "SS-Totenkopfverbände" (Death's Head Units). Approximately three in four SS personnel worked in security. Others worked in the medical or political departments, in the camp headquarters, or in the economic administration, which was responsible for the property of dead prisoners. SS personnel at the camp included 200 women, who worked as guards, nurses, or messengers. About 120 SS personnel were assigned to the gas chambers and lived on site at the crematoria.

Auschwitz was considered a comfortable posting by many SS members, because of its many amenities. SS personnel were initially allowed to bring partners, spouses, and children to live at the camp, but when the SS camp grew more crowded, Höss restricted further arrivals. Facilities for the SS personnel and their families included a library, swimming pool, coffee house, and a theater that hosted regular performances.

Some prisoners—usually Aryan—were assigned positions of authority, such as "Blockschreiber" ("block clerk"), "Funktionshäftling" ("functionary"), "Kapo" ("head" or "overseer"), and "Stubendienst" ("barracks orderly"). They were considered members of the camp elite, and had better food and lodgings than the other prisoners. The "Kapos" in particular wielded tremendous power over other prisoners, whom they often abused. Very few "Kapos" were prosecuted after the war, because of the difficulty in determining which "Kapo" atrocities had been performed under SS orders and which had been individual actions.

Several SS personnel oversaw the killings at each gas chamber, while the bulk of the work was done by the mostly Jewish prisoners known as "Sonderkommandos" (special squads). Hungarian doctor Miklós Nyiszli reported that the "Sonderkommando" numbered around 860 prisoners when the Hungarian Jews were being killed in May–July 1944. Their responsibilities included removing goods and corpses from the incoming trains, guiding victims to the dressing rooms and gas chambers, and working in the "Canada" barracks, where the victims' possessions were stored. Housed separately from other prisoners, in somewhat better conditions, their quality of life was further improved by access to the goods taken from murdered prisoners, which they were sometimes able to steal and trade on Auschwitz's black market. Many "Sonderkommandos" committed suicide in response to the horrors of their work; others were generally shot by the SS in a matter of weeks. New "Sonderkommando" units were formed from incoming transports. Almost none of the 2,000 prisoners placed in these units survived to the camp's liberation.

Uniquely at Auschwitz, prisoners were tattooed with a serial number, on their left breast for Soviet prisoners of war and on the left arm for civilians. Categories of prisoner were distinguishable by triangular pieces of cloth (German: "Winkel") sewn onto on their jackets below their prisoner number. Political prisoners "(Schutzhäftlinge" or Sch), mostly Poles, had a red triangle, while criminals ("Berufsverbrecher" or BV) were mostly German and wore green. Asocial prisoners ("Asoziale" or Aso), which included vagrants, prostitutes and the Roma, wore black. Purple was for Jehovah's Witnesses ("Internationale Bibelforscher-Vereinigung" or IBV)'s and pink for gay men, who were mostly German. An estimated 5,000–15,000 gay men prosecuted under German Penal Code Section 175 (proscribing sexual acts between men) were detained in concentration camps, of whom an unknown number were sent to Auschwitz. Jews wore a yellow badge, the shape of the Star of David, overlaid by a second triangle if they also belonged to a second category. The nationality of the inmate was indicated by a letter stitched onto the cloth. A racial hierarchy existed, with German prisoners at the top. Next were non-Jewish prisoners from other countries. Jewish prisoners were at the bottom.

Deportees were brought to Auschwitz crammed in wretched conditions into goods or cattle wagons, arriving near a railway station or at one of several dedicated trackside ramps, including one next to Auschwitz I. The "Altejudenrampe" (old Jewish ramp), part of the Oświęcim freight railway station, was used from 1942 to 1944 for Jewish transports. Located between Auschwitz I and Auschwitz II, arriving at this ramp meant a 2.5 km journey to Auschwitz II and the gas chambers. Most deportees were forced to walk, accompanied by SS men and a car with a Red Cross symbol that carried the Zyklon B, as well as an SS doctor in case officers were poisoned by mistake. Inmates arriving at night, or who were too weak to walk, were taken by truck. Work on another railway line and "Judenrampe" "(pictured right)" between sectors BI and BII in Auschwitz II, was completed in May 1944 for the arrival of Hungarian Jews, who between May and early July 1944 were deported to Auschwitz II at a rate of 12,000 a day. The rails led directly to the area around the gas chambers.

The prisoners' days began at 4:30 am for the men (an hour later in winter), and earlier for the women, when the block supervisor sounded a gong and started beating inmates with sticks to encourage them to wash and use the latrines quickly. Sanitary arrangements were atrocious, with few latrines and a lack of clean water. Each washhouse had to service thousands of prisoners. In sectors BIa and BIb in Auschwitz II-Birkenau, two buildings containing latrines and washrooms were installed in 1943. These contained troughs for washing and 90 faucets; the toilet facilities were "sewage channels" covered by concrete with 58 holes for seating. There were three barracks with washing facilities or toilets to serve 16 residential barracks in BIIa, and six washrooms/latrines for 32 barracks in BIIb, BIIc, BIId, and BIIe. Primo Levi described a 1944 Auschwitz III washroom:

Prisoners received half a liter of coffee substitute or a herbal "tea" in the morning, but no food. A second gong heralded roll call, when inmates had to line up outside in rows of ten to be counted. No matter how cold the weather, prisoners had to wait for the SS to arrive for the count. How long they stood there depended on the officers' mood, and whether there had been escapes or other events attracting punishment. Guards might force the prisoners to squat for an hour with their hands above their heads, or hand out beatings or detention for infractions such as having a missing button or an improperly cleaned food bowl. The inmates were counted and re-counted.

After roll call, to the sound of ""Arbeitskommandos formieren"" ("form work details"), prisoners walked to their place of work, five abreast, to begin a working day that was normally 11 hours long—longer in summer and shorter in winter. A prison orchestra, such as the Women's Orchestra of Auschwitz, was forced to play cheerful music as the workers left the camp. "Kapos" were responsible for the prisoners' behavior while they worked, as was an SS escort. Much of the work took place outdoors at construction sites, gravel pits, and lumber yards. No rest periods were allowed. One prisoner was assigned to the latrines to measure the time the workers took to empty their bladders and bowels.

Lunch was three quarters of a liter of watery soup at midday, reportedly foul-tasting, with meat in the soup four times a week and vegetables (mostly potatoes and rutabaga) three times. The evening meal was 300 grams of bread, often moldy, part of which the inmates were expected to keep for breakfast the next day, with a tablespoon of cheese or marmalade, or 25 grams of margarine or sausage. Prisoners engaged in hard labor were given extra rations.

Sunday was not a work day, but prisoners were required to clean the barracks and take their weekly shower, and were allowed to write (in German) to their families, although the SS censored the outgoing mail. Inmates who did not speak German would trade some of their bread for help composing their letters. Observant Jews tried to keep track of the Hebrew calendar and Jewish holidays, including Shabbat, and the weekly Torah portion. No watches, calendars, or clocks were permitted in the camp. Jewish calendars were rare among prisoners; being in possession of one was dangerous. Only two Jewish calendars made in Auschwitz survived to the end of the war. Prisoners kept track of the days in other ways, such as obtaining information from newcomers.

A second roll call took place at seven in the evening after the long day's work. Prisoners might be hanged or flogged in the course of it. If a prisoner was missing, the others had to remain standing until he or she was found or the reason for the absence discovered, even if it took hours. On 6 July 1940, roll call lasted 19 or 20 hours because of the escape of a Polish prisoner, Tadeusz Wiejowski; following another escape in 1941, a group of prisoners was sent to block 11 to be starved to death. After roll call, prisoners were allowed to retire to their blocks for the night and receive their bread rations and water. Curfew was at nine o'clock. Inmates slept in long rows of brick or wooden bunks, lying in and on their clothes and shoes to prevent them from being stolen. The wooden bunks had blankets and paper mattresses filled with wood shavings; in the brick barracks, inmates lay on straw. According to Nyiszli:

The women's concentration camp ("Frauenkonzentrationslager" or FKL) was established in August 1942, in 15 brick and 15 wooden barracks in sector BIa ("Bauabschnitt" Ia) in Auschwitz II, when 13,000 women were transferred from Auschwitz I. The camp was later extended into sector BIb, and by October 1943 it held 32,066 women. Conditions in the camp were so poor that, in October 1942, when a group of male prisoners arrived to set up an infirmary, their first task, according to researchers from the Auschwitz museum, was to distinguish the corpses from the women who were still alive. Gisella Perl, a Romanian-Jewish gynecologist and inmate of the women's camp, wrote in 1948:

SS-Oberaufseherin Maria Mandl was the commandant of the women's camp until July 1943, followed by SS-Hauptsturmfuhrer Franz Hössler. Both were executed after the war. Sterilization experiments were carried out in barracks 30 by a German gynecologist, Carl Clauberg, and another German doctor, Horst Schumann.

German doctors performed a variety of experiments on prisoners at Auschwitz. SS doctors tested the efficacy of X-rays as a sterilization device by administering large doses to female prisoners. Carl Clauberg injected chemicals into women's uteruses in an effort to glue them shut. Prisoners were infected with spotted fever for vaccination research and exposed to toxic substances to study the effects. In one experiment Bayer, then part of IG Farben, paid RM 150 each for 150 female inmates from Auschwitz (the camp had asked for RM 200 per woman), who were transferred to a Bayer facility to test an anesthetic. A Bayer employee wrote to Rudolf Höss: "The transport of 150 women arrived in good condition. However, we were unable to obtain conclusive results because they died during the experiments. We would kindly request that you send us another group of women to the same number and at the same price." The Bayer research was led at Auschwitz by Helmuth Vetter of Bayer/IG Farben, who was also an Auschwitz physician and SS captain, and by Auschwitz physicians Friedrich Entress and Eduard Wirths.
The most infamous doctor at Auschwitz was Josef Mengele, the "Angel of Death", who worked in Auschwitz II from 30 May 1943, at first in the gypsy family camp. Particularly interested in performing research on identical twins, dwarfs, and those with hereditary disease, Mengele set up a kindergarten in barracks 29 and 31 for children he was experimenting on, and for all Romani children under six, where they were given better food rations. From May 1944, he would select twins and dwarfs during selection on the "Judenrampe", reportedly calling for twins with ""Zwillinge heraus!"" ("twins step forward!"). He and other doctors (the latter prisoners) would measure the twins' body parts, photograph them, and subject them to dental, sight and hearing tests, x-rays, blood tests, surgery, and blood transfusions between them. Then he would have them killed and dissected. Kurt Heissmeyer, another German doctor and SS officer, took 20 Jewish children from Auschwitz to use in pseudoscientific medical experiments at the Neuengamme concentration camp. In April 1945, the children were killed by hanging to conceal the project.

A Jewish skeleton collection was obtained from among a pool of 115 Jewish Auschwitz inmates, chosen for their perceived stereotypical racial characteristics. Rudolf Brandt and Wolfram Sievers, general manager of the "Ahnenerbe" (a Nazi research institute), delivered the skeletons to the collection of the Anatomy Institute at the Reichsuniversität Straßburg in Occupied France. The collection was sanctioned by Himmler and under the direction of August Hirt. Ultimately 87 of the inmates were shipped to Natzweiler-Struthof and killed in August 1943. Brandt and Sievers were executed in 1948 after being convicted during the Doctors' trial, part of the Subsequent Nuremberg trials.

Known as block 13 until 1941, block 11 of Auschwitz I was the prison within the prison, where violators of the numerous rules were punished. To extract information from them, guards would hold inmates' heads held against the stove, burning their faces and eyes. Some prisoners were made to spend the nights in standing cells. Measuring , the cells held four men who could do nothing but stand, and who were forced the following day to work as usual. In other cells, inmates were subjected to hanging with their hands behind their backs, thus dislocating their shoulder joints. In the basement were the "dark cells", which had only a 5 x 5 cm opening and a solid door. Prisoners placed in these cells gradually suffocated as they ran out of oxygen; sometimes the SS lit a candle in the cell to use up the oxygen more quickly.

The courtyard between blocks 10 and 11, known as the "death wall" served as an execution area for Poles not in Auschwitz who had been sentenced to death by a criminal court—presided over by German judges—including for petty crimes such as stealing food. Several rooms in block 11 were deemed the "Polizei-Ersatz-Gefängnis Myslowitz in Auschwitz" ("Alternative jail of the police station at Mysłowice"). There were also "Sonderbehandlung" cases ("special treatment") for Poles and others regarded as dangerous to the Third Reich. Members of the camp resistance were shot there, as were 200 of the "Sonderkommandos" who took part in the Sonderkommando revolt in October 1944. Thousands of Poles were executed at the death wall; Höss wrote that "execution orders arrived in an unbroken stream".

A separate camp for the Roma, the "Zigeunerfamilienlager" ("Gypsy family camp"), was set up in the BIIe sector of Auschwitz II-Birkenau in February 1943. For unknown reasons, they were not subject to selection and families were allowed to stay together. The first transport of German Roma arrived at Auschwitz II on 26 February that year. There had been a small number of Romani inmates before that; two Czech Romani prisoners, Ignatz and Frank Denhel, tried to escape in December 1942, the latter successfully, and a Polish Romani woman, Stefania Ciuron, arrived on 12 February 1943 and escaped in April.

The Auschwitz registry ("Hauptbücher") shows that 20,946 Roma were registered prisoners, and another 3,000 are thought to have entered unregistered. On 22 March 1943, one transport of 1,700 Polish Sinti and Roma was gassed on arrival because of illness, as was a second group of 1,035 on 25 May 1943. The SS tried to liquidate the camp on 16 May 1944, but the Roma fought them, armed with knives and iron pipes, and the SS retreated. Shortly after this, the SS removed nearly 2,908 from the family camp to work, and on 2 August 1944 gassed the other 2,897. Ten thousand remain unaccounted for.

The Theresienstadt family camp, which existed between September 1943 and July 1944, served a different purpose. A group of around 5,000 Jews had arrived in Auschwitz in September 1943 from the Theresienstadt ghetto in Czechoslovakia. The families were allowed to stay together, their heads were not shaved, and they could wear their own clothes. Correspondence between Adolf Eichmann's office and the International Red Cross suggests that the Germans set up the camp to cast doubt on reports, in time for a planned Red Cross visit to Auschwitz, that mass murder was taking place in Auschwitz. A second group of 5,000 arrived from Theresienstadt in December 1943. On 7 March 1944, the first group was sent to the gas chamber at crematorium III; before they died, they were asked to send postcards to relatives, postdated to 25 March. This was the largest massacre of Czechoslovak citizens in history. News of the liquidation reached the Czechoslovak government-in-exile, which initiated diplomatic manoeuvers to save the remaining Jews. After the Red Cross visited Theresienstadt in June 1944 and were persuaded by the SS that no deportations were taking place from there, about 3,500 Jews were removed from the family camp to other sections of Auschwitz. The remaining 6,500 were murdered in the gas chambers between 10 and 12 July 1944.

On 31 July 1941, Hermann Göring gave written authorization to Reinhard Heydrich, Chief of the Reich Security Head Office (RSHA), to prepare and submit a plan for "Die Endlösung der Judenfrage" (the Final Solution of the Jewish question) in territories under German control and to coordinate the participation of all involved government organizations. Plans for the extermination of the European Jews—eleven million people—were formalized at the Wannsee Conference in Berlin on 20 January 1942. Some would be worked to death and the rest killed. Initially the victims were killed with gas vans or by "Einsatzgruppen" firing squads, but these methods were impractical for an operation of this scale. By 1942, killing centers at Auschwitz, Sobibór, Treblinka, and other extermination camps had become the primary method of mass killing.
The first gassings at Auschwitz took place in early September 1941, when around 850 inmates—Soviet prisoners of war and sick Polish inmates—were killed with Zyklon B in the basement of block 11 in Auschwitz I. The building proved unsuitable, so gassings were conducted instead in crematorium I, also in at Auschwitz I, which operated until December 1942. There, more than 700 victims could be killed at once. Tens of thousands were killed in crematorium I. To keep the victims calm, they were told they were to undergo disinfection and de-lousing; they were ordered to undress outside, then were locked in the building and gassed. After its decommissioning as a gas chamber, the building was converted to a storage facility and later served as an SS air raid shelter. The gas chamber and crematorium were reconstructed after the war. Dwork and van Pelt write that a chimney was recreated; four openings in the roof were installed to show where the Zyklon B had entered; and two of the three furnaces were rebuilt with the original components.

In early 1942, mass exterminations were moved to two provisional gas chambers (the "red house" and "white house", known as bunkers 1 and 2) in Auschwitz II, while the larger crematoria (II, III, IV, and V) were under construction. Bunker 2 was temporarily reactivated from May to November 1944, when large numbers of Hungarian Jews were gassed. In summer 1944 the combined capacity of the crematoria and outdoor incineration pits was 20,000 bodies per day. A planned sixth facility—crematorium VI—was never built. Prisoners were transported from all over German-occupied Europe by rail, arriving in daily convoys. By July 1942, the SS were conducting "selections". Incoming Jews were segregated; those deemed able to work were sent to the selection officer's right and admitted into the camp, and those deemed unfit for labor were sent to the left and immediately gassed. The group selected to die, about three-quarters of the total, included almost all children, women with small children, the elderly, and all those who appeared on brief and superficial inspection by an SS doctor not to be fit for work.

After the selection process was complete, those too ill or too young to walk to the crematoria were transported there on trucks or killed on the spot with a bullet to the head. The belongings of the arrivals were seized by the SS and sorted in an area of the camp called "Canada", so called because Canada was seen as a land of plenty. Many of the SS at the camp enriched themselves by pilfering the confiscated property.

The crematoria consisted of a dressing room, gas chamber, and furnace room. In crematoria II and III, the dressing room and gas chamber were underground; in IV and V, they were on the ground floor. The dressing room had numbered hooks on the wall to hang clothes. In crematorium II, there was also a dissection room ("Sezierraum"). SS officers told the victims they were to take a shower and undergo delousing. The victims undressed in the dressing room and walked into the gas chamber, which was disguised as a shower facility; signs in German said "To the baths" and "To disinfection". Some inmates were even given soap and a towel.
The Zyklon B was delivered by ambulance to the crematoria by a special SS bureau known as the Hygienic Institute. The actual delivery of the gas to the victims was always handled by the SS, on the order of the supervising SS doctor. After the doors were shut, SS men dumped in the Zyklon B pellets through vents in the roof or holes in the side of the chamber. The victims were dead within 20 minutes. Despite the thick concrete walls, screaming and moaning from within could be heard outside. In one failed attempt to muffle the noise, two motorcycle engines were revved up to full throttle nearby, but the sound of yelling could still be heard over the engines.

"Sonderkommando" wearing gas masks then dragged the bodies from the chamber. The victims' glasses, artificial limbs, jewelry, and hair were removed, and any dental work was extracted so the gold could be melted down. The corpses were burned in the nearby incinerators, and the ashes were buried, thrown in the river, or used as fertilizer.

The gas chambers worked to their fullest capacity from April to July 1944, during the massacre of Hungary's Jews. Hungary was an ally of Germany during the war, but it had resisted turning over its Jews until Germany invaded that March. A rail spur leading to crematoria II and III in Auschwitz II was completed that May, and a new ramp was built between sectors BI and BII to deliver the victims closer to the gas chambers. On 29 April the first 1,800 Hungarian Jews arrived at the camp; from 14 May until early July 1944, 437,000 Hungarian Jews, half the pre-war population, were deported to Auschwitz, at a rate of 12,000 a day for a considerable part of that period. The crematoria had to be overhauled. Crematoria II and III were given new elevators leading from the stoves to the gas chambers, new grates were fitted, and several of the dressing rooms and gas chambers were painted. Cremation pits were dug behind crematorium V. The last mass transports to arrive in Auschwitz were 60,000–70,000 Jews from the Łódź Ghetto, some 2,000 from Theresienstadt, and 8,000 from Slovakia. The last selection took place on 30 October 1944. Crematorium IV was demolished after the "Sonderkommando" revolt on 7 October 1944. The SS blew up crematorium V on 14 January 1945, and crematoria II and III on 20 January.

Overall 268,657 male and 131,560 female prisoners were registered in Auschwitz, 400,207 in total. Many prisoners were never registered and much evidence was destroyed by the SS in the final days of the war, making the number of victims hard to ascertain. Himmler visited the camp on 17 July 1942 and watched a gassing; a few days later, according to Höss's post-war memoir, Höss received an order from Himmler, via Adolf Eichmann's office and SS commander Paul Blobel, that "[a]ll mass graves were to be opened and the corpses burned. In addition the ashes were to be disposed of in such a way that it would be impossible at some future time to calculate the number of corpses burned."

Following the camp's liberation, the Soviet government issued a statement, on 8 May 1945, that four million people had been killed on the site, a figure based on the capacity of the crematoria and later regarded as too high. Höss told prosecutors at Nuremberg that at least 2,500,000 people had been murdered in Auschwitz by gassing and burning, and that another 500,000 had died of starvation and disease. He testified that the figure of over two million had come from Eichmann. In his memoirs, written in custody, he wrote that he regarded this figure as "far too high. Even Auschwitz had limits to its destructive possibilities." Raul Hilberg's 1961 work, "The Destruction of the European Jews", estimated that up to 1,000,000 Jews had died in Auschwitz.

In 1983, French scholar George Wellers was one of the first to use German data on deportations; he arrived at a figure of 1,471,595 deaths, including 1.35 million Jews and 86,675 Poles. A larger study in the late 1980s by Franciszek Piper, published by Yad Vashem in 1991, used timetables of train arrivals combined with deportation records to calculate that, of the 1.3 million deported to the camp, 1,082,000 died there between 1940 and 1945, a figure (rounded up to 1.1 million) that he regarded as a minimum and that came to be widely accepted.

Around one in six Jews killed in the Holocaust died in Auschwitz. By nation, the greatest number of Auschwitz's Jewish victims originated from Hungary, accounting for 430,000 deaths, followed by Poland (300,000), France (69,000), Netherlands (60,000), Greece (55,000), Protectorate of Bohemia and Moravia (46,000), other camps (34,000), Slovakia (27,000), Belgium (25,000), Germany and Austria (23,000), Yugoslavia (10,000), Italy (7,500), and Norway (690). Fewer than one percent of Soviet Jews murdered in the Holocaust were killed in Auschwitz; German forces had already been driven from Russia when the killing at Auschwitz reached its peak in 1944. Of the 400 Jehovah's Witnesses who were imprisoned at Auschwitz, 132 died there.

Information about Auschwitz became available to the Allies as a result of reports by Captain Witold Pilecki of the Polish Home Army (Armia Krajowa), who volunteered to be imprisoned there in 1940. As "Thomasz Serfiński", he allowed himself to be arrested in Warsaw and spent 945 days in the camp, from 22 September 1940 until his escape on 27 April 1943. Michael Fleming writes that Pilecki was instructed to sustain morale, organize food, clothing and resistance, prepare to take over the camp if possible, and smuggle information out to the Polish military. Pilecki called his resistance movement Związek Organizacji Wojskowej (ZOW, "Union of Military Organization").
The resistance sent out the first oral message about Auschwitz with Dr. Aleksander Wielkopolski, a Polish engineer who was released in October 1940. The following month the Polish underground in Warsaw prepared a report on the basis of that information, "The camp in Auschwitz", part of which was published in London in May 1941 in a booklet, "The German Occupation of Poland", by the Polish Ministry of Foreign Affairs. The report said of the Jews in the camp that "scarcely any of them came out alive". According to Fleming, the booklet was "widely circulated amongst British officials". The "Polish Fortnightly Review" based a story on it, writing that "three crematorium furnaces were insufficient to cope with the bodies being cremated", as did "The Scotsman" on 8 January 1942, the only British news organization to do so.

On 24 December 1941 the resistance groups representing the various prisoner factions met in block 45 and agreed to cooperate. Fleming writes that it has not been possible to track Pilecki's early intelligence from the camp. Pilecki compiled two reports after he escaped in April 1943; the second, Raport W, detailed his life in Auschwitz I and estimated that 1.5 million people, mostly Jews, had been killed. On 1 July 1942, the "Polish Fortnightly Review" published a report describing Birkenau, writing that "prisoners call this supplementary camp 'Paradisal', presumably because there is only one road, leading to Paradise". Reporting that inmates were being killed "through excessive work, torture and medical means", it noted the gassing of the Soviet prisoners of war and Polish inmates in Auschwitz I in September 1941, the first gassing in the camp. It said: "It is estimated that the Oswiecim camp can accommodate fifteen thousand prisoners, but as they die on a mass scale there is always room for new arrivals."
From 1942, members of the Bureau of Information and Propaganda of the Warsaw-area Home Army published reports based on the accounts of escapees. The first was a fictional memoir, "Oświęcim. Pamiętnik więźnia" ("Auschwitz: Diary of a prisoner") by Halina Krahelska, published in April 1942 in Warsaw. Also published in 1942 was the pamphlet "Obóz śmierci" ("Camp of Death") by Natalia Zarembina, and "W piekle" ("In Hell") by Zofia Kossak-Szczucka, founder of Żegota. In March 1944, the Polish Labor Group in New York published a report in English, "Oswiecim, Camp of Death (Underground Report)", with a foreword by Florence Jaffray Harriman, which described the gassing of prisoners from 1942.

The Polish government-in-exile in London first reported the gassing of prisoners in Auschwitz on 21 July 1942, and reported the gassing of Soviet POWs and Jews on 4 September 1942. In 1943, the "Kampfgruppe Auschwitz" (Combat Group Auschwitz) was organized within the camp with the aim of sending out information about what was happening. "Sonderkommandos" buried notes in the ground, hoping they would be found by the camp's liberators. The group also smuggled out photographs; the "Sonderkommando" photographs, of events around the gas chambers in Auschwitz II, were smuggled out of the camp in September 1944 in a toothpaste tube. According to Fleming, the British press responded, in 1943 and the first half of 1944, either by not publishing reports about Auschwitz or by burying them on the inside pages. The exception was the "Polish Jewish Observer", published as a supplement to the "City and East London Observer" and edited by Joel Cang, a former Warsaw correspondent for the "Manchester Guardian". The British reticence stemmed from a Foreign Office concern that the public might pressure the government to respond or provide refuge for the Jews, and that British actions on behalf of the Jews might affect its relationships in the Middle East. There was similar reticence in the United States, and indeed within the Polish government-in-exile and the Polish resistance. According to Fleming, the scholarship suggests that the Polish resistance distributed information about the Holocaust in Auschwitz without challenging the Allies' reluctance to highlight it.

From the first escape on 6 July 1940 of Tadeusz Wiejowski, at least 802 prisoners (757 men and 45 women) tried to escape from the camp, according to Polish historian Henryk Świebocki. He writes that most escapes were attempted from work sites outside the camp. Of these, 144 were successful and the fate of 331 is unknown. Four Polish prisoners—Eugeniusz Bendera (a car mechanic at the camp), Kazimierz Piechowski, Stanisław Gustaw Jaster, and a priest, Józef Lempart—escaped successfully on 20 June 1942. After breaking into a warehouse, the four dressed as members of the "SS-Totenkopfverbände" (the SS units responsible for concentration camps), armed themselves, and stole an SS staff car, which they drove unchallenged through the main gate, greeting several officers with "Heil Hitler!" as they drove past. On 21 July 1944, Polish inmate Jerzy Bielecki dressed in an SS uniform and, using a faked pass, managed to cross the camp's gate with his Jewish girlfriend, Cyla Cybulska (known as Cyla Stawiska), pretending that she was wanted for questioning. Both survived the war. For having saved her, Bielecki was recognized by Yad Vashem as Righteous Among the Nations.

Jerzy Tabeau (prisoner no. 27273, registered as Jerzy Wesołowski) and Roman Cieliczko (no. 27089), both Polish prisoners, escaped on 19 November 1943; Tabeau made contact with the Polish underground and, between December 1943 and early 1944, wrote what became known as the "Polish Major's report" about the situation in the camp. On 27 April 1944, Rudolf Vrba (no. 44070) and Alfréd Wetzler (no. 29162) escaped to Slovakia, carrying detailed information to the Slovak Jewish Council about the gas chambers. The distribution of the "Vrba-Wetzler report", and publication of parts of it in June 1944, helped to halt the deportation of Hungarian Jews to Auschwitz. On 27 May 1944, Arnost Rosin (no. 29858) and Czesław Mordowicz (no. 84216) also escaped to Slovakia; the "Rosin-Mordowicz report" was added to the Vrba-Wetzler and Tabeau reports to become what is known as the "Auschwitz Protocols". The reports were first published in their entirety in November 1944 by the United States War Refugee Board, in a document entitled "The Extermination Camps of Auschwitz (Oświęcim) and Birkenau in Upper Silesia".

Slovak rabbi Michael Dov Weissmandl was the first to suggest, in May 1944, that the Allies bomb the rails leading to Auschwitz. At one point British Prime Minister Winston Churchill ordered that such a plan be prepared, but he was told that precision bombing the camp to free the prisoners or disrupt the railway was not technically feasible. In 1978, historian David Wyman published an essay in "Commentary" entitled "Why Auschwitz Was Never Bombed", arguing that the United States Army Air Forces had the capability to attack Auschwitz and should have done so; he expanded his arguments in his book "The Abandonment of the Jews: America and the Holocaust 1941–1945" (1984). Wyman argued that, since the IG Farben plant at Auschwitz III had been bombed three times between August and December 1944 by the US Fifteenth Air Force in Italy, it would have been feasible for the other camps or railway lines to be bombed too. Bernard Wasserstein's "Britain and the Jews of Europe" (1979) and Martin Gilbert's "Auschwitz and the Allies" (1981) raised similar questions about British inaction. Since the 1990s, other historians have argued that Allied bombing accuracy was not sufficient for Wyman's proposed attack, and that counterfactual history is an inherently problematic endeavor.

Aware that as witnesses to the killings they would eventually be killed themselves, the "Sonderkommandos" of Birkenau "Kommando" III staged an uprising on 7 October 1944, following an announcement that some of them would be selected to be "transferred to another camp"—a common Nazi ruse for the murder of prisoners. They attacked the SS guards with stones, axes, and makeshift hand grenades, which they also used to damage Crematorium IV and set it on fire. As the SS set up machine guns to attack the prisoners in Crematorium IV, the "Sonderkommandos" in Crematorium II also revolted, some of them managing to escape the compound. The rebellion was suppressed by nightfall.

Ultimately, three SS guards were killed—one of whom was burned alive by the prisoners in the oven of Crematorium II—and 451 "Sonderkommandos" were killed. Hundreds of prisoners escaped, but all were soon captured and executed, along with an additional group who had participated in the revolt. Crematorium IV was destroyed in the fighting. A group of prisoners in the gas chamber of Crematorium V was spared in the chaos.

According to Polish historian Andrzej Strzelecki, the evacuation of the prisoners by the SS in January 1945 was one of the camp's "most tragic chapters". In mid-1944, about 130,000 prisoners were in Auschwitz when the SS moved around half of them to other concentration camps. In November 1944, with the Soviet Red Army approaching through Poland, Himmler ordered gassing operations to cease. The crematorium IV building was dismantled, and the "Sonderkommando" was ordered to remove evidence of the killings, including the mass graves. The SS destroyed written records, and in the final week before the camp's liberation, burned or demolished many of its buildings. The plundered goods from the "Canada" barracks at Birkenau, together with building supplies, were transported to the German interior. On 20 January, the overflowing warehouses were set ablaze. Crematoria II and III at Birkenau were blown up on 20 January and crematorium V six days later, just one day ahead of the Soviet attack.

That month, Himmler ordered the evacuation of all camps, charging camp commanders with "making sure that not a single prisoner from the concentration camps falls alive into the hands of the enemy". Beginning on 17 January, 56,000–58,000 Auschwitz detainees—over 20,000 from Auschwitz I and II, over 30,000 from subcamps, and two-thirds of them Jews—were evacuated under guard, largely on foot, in severe winter conditions, heading west. Around 2,200 were evacuated by rail from two subcamps; fewer than 9,000 were left behind, deemed too sick to move. During the marches, camp staff shot anyone too sick or exhausted to continue, or anyone stopping to urinate or tie a shoelace. SS officers walked behind the marchers killing anyone lagging behind who had not already been shot. Peter Longerich estimates that a quarter of the detainees were thus killed. Those who managed to walk to Wodzisław Śląski and Gliwice were sent on open freight cars, without food, to concentration camps in Germany: Bergen-Belsen, Buchenwald, Dachau, Flossenburg, Gross-Rosen, Mauthausen, Dora-Mittelbau, Ravensbruck, and Sachsenhausen.

A column of inmates reached the Gross-Rosen complex. Throughout February, the terribly overcrowded main camp at Gross-Rosen was cleared, and all 44,000 inmates were moved further west. An unknown number died in this last journey. In March 1945, Himmler ordered that no more prisoners should be killed, as he hoped to use them as hostages in negotiations with the Allies. Approximately 20,000 Auschwitz prisoners made it to Bergen-Belsen, where they were liberated by the British in April 1945.

When the 322nd Rifle Division of the Red Army liberated Auschwitz on 27 January 1945, the soldiers found 7,500 prisoners alive and over 600 corpses. Auschwitz II-Birkenau was liberated at around 3:30 p.m., and the main camp (Auschwitz I) two hours later. Items found by the Soviet soldiers included 370,000 men's suits, 837,000 women's garments, and of human hair. Primo Levi described seeing the first four Russian soldiers on horseback approach the camp at Monowitz, where he had been in the sick bay. The soldiers threw "strangely embarrassed glances at the sprawling bodies, at the battered huts and at us few still alive ...":

Military trucks loaded with bread arrived on 28 January, and volunteers began to offer first aid and improvised assistance the following week. The liberation of the camp received little Western press attention at the time. Laurence Rees attributes this to three factors: the previous discovery of similar crimes at the Majdanek concentration camp, competing news from the Allied summit at Yalta, and the Soviet Union's Marxist presentation of the camp "as the ultimate capitalist factory where the workers were dispensible", combined with its interest in minimizing attention to Jewish suffering.

In early February, the Polish Red Cross hospital opened in blocks 14, 21, and 22 at Auschwitz I, headed by Dr. Józef Bellert and staffed by 30 volunteer doctors and nurses from Kraków, along with around 90 former inmates. The critically injured patients—estimated at several thousands—were relocated from Birkenau and Monowitz to the main camp. Some orphaned children were adopted by Oświęcim residents, while others were transferred to Kraków, where several were adopted by Polish families, or placed in an orphanage at Harbutowice. The hospital cared for more than 4,500 patients (most of them Jews) from 20 countries, suffering from starvation, alimentary dystrophy, gangrene, necrosis, internal haemorrhaging, and typhoid fever. At least 500 died. Assistance was provided by volunteers from Oświęcim and Brzeszcze, who donated money and food, cleaned hospital rooms, delivered water, washed patients, cooked meals, buried the dead, and transported the sick in horse-drawn carts between locations. Securing enough food for thousands of former prisoners was a constant challenge. The hospital director personally went from village to village to collect milk.

In June 1945 the Soviet authorities took over Auschwitz I and converted it into a POW camp for German prisoners. The hospital had to move beyond the camp perimeter into former administrative buildings, where it functioned until October 1945. Many of the barracks at Birkenau were taken apart by civilians, who used the materials to rebuild their own homes, which had been levelled out in the construction of Auschwitz II. The poorest residents sifted the crematoria ashes in search of nuggets from melted gold, before warning shots were fired. The POW camp for German prisoners of war was used until 1947 by the Soviet NKVD (People's Commissariat for Internal Affairs). The NKVD and its Polish counterpart, the MBP, used the Auschwitz Neu-Dachs sub-camp at Jaworzno to the north of Oświęcim as a concentration camp from 1945 to 1956. The Soviets dismantled and exported the IG Farben factories to the USSR. Meanwhile, Soviet and Polish investigators worked to document the war crimes of the SS. After the site became a museum in 1947, exhumation work lasted for more than a decade.

Only 789 Auschwitz staff, 15 percent, ever stood trial; most of the cases were pursued in Poland and, following them, the Federal Republic of Germany. Female SS officers were treated more harshly than male; of the 17 women sentenced, four received the death penalty and the others longer prison terms than the men.

Camp commandant Rudolf Höss was arrested by the British at a farm near Flensburg, Germany, on 11 March 1946, where he had been working under the pseudonym Franz Lang. He was imprisoned in Heide, then transferred to Minden for interrogation, part of the British occupation zone. From there he was taken to Nuremberg to testify for the defense in the trial of "SS-Obergruppenführer" Ernst Kaltenbrunner. Höss was straightforward about his own role in the mass murder and said he had followed the orders of Heinrich Himmler. Extradited to Poland on 25 May 1946, he wrote his memoirs in custody, first published in Polish in 1951 then in German in 1958 as "Kommandant in Auschwitz". His trial before the Supreme National Tribunal in Warsaw opened on 11 March 1947; he was sentenced to death on 2 April and hanged in Auschwitz I, near crematorium I, on 16 April.

On 25 November 1947, the Auschwitz trial began in Kraków, when Poland's Supreme National Tribunal brought to court 40 former Auschwitz staff. The trial's defendants included commandant Arthur Liebehenschel, women's camp leader Maria Mandel, and camp leader Hans Aumeier. The trials ended on 22 December 1947, with 23 death sentences, 7 life sentences, and 9 prison sentences ranging from three to fifteen years. Hans Münch, an SS doctor who had several former prisoners testify on his behalf, was the only person to be acquitted.

Other former staff were hanged for war crimes in the Dachau Trials and the Belsen Trial, including camp leaders Josef Kramer, Franz Hössler, and Vinzenz Schöttl; doctor Friedrich Entress; and guards Irma Grese and Elisabeth Volkenrath. The Frankfurt Auschwitz trials, held in West Germany from 20 December 1963 to 20 August 1965, convicted 17 of 22 defendants, giving them prison sentences ranging from life to three years and three months. Bruno Tesch and Karl Weinbacher, the owner and the chief executive officer of the firm Tesch & Stabenow, one of the suppliers of Zyklon B, were executed for knowingly supplying the chemical for use on humans.

In the decades since its liberation, Auschwitz has become a primary symbol of the Holocaust. Historian Timothy D. Snyder attributes this to the camp's high death toll and "unusual combination of an industrial camp complex and a killing facility", which left behind far more witnesses than single-purpose killing facilities such as Chełmno or Treblinka. In 2005 the United Nations General Assembly designated 27 January, the date of the camp's liberation, as International Holocaust Remembrance Day. Helmut Schmidt visited the site in November 1977, the first West German chancellor to do so, followed by his successor, Helmut Kohl, in November 1989. In a written statement on the fiftieth anniversary of the liberation, Kohl described Auschwitz as the "darkest and most horrific chapter of German history".

Notable memoirists of the camp include Primo Levi, Elie Wiesel, and Tadeusz Borowski. Levi's "If This is a Man", first published in Italy in 1947 as "Se questo è un uomo", became a classic of Holocaust literature, an "imperishable masterpiece". Wiesel wrote about his imprisonment at Auschwitz in "Night" (1960) and other works, and became a prominent spokesman against ethnic violence; in 1986, he was awarded the Nobel Peace Prize. Camp survivor Simone Veil was later elected President of the European Parliament, serving from 1979 to 1982. Two Auschwitz victims—Maximilian Kolbe, a priest who volunteered to die by starvation in place of a stranger, and Edith Stein, a Jewish convert to Catholicism—were later named saints of the Catholic Church.

In 2017 a Körber Foundation survey found that 40 percent of 14-year-olds in Germany did not know what Auschwitz was. The following year a survey organized by the Claims Conference, United States Holocaust Memorial Museum and others found that 41 percent of 1,350 American adults surveyed, and 66 percent of millennials, did not know what Auschwitz was, while 22 percent said they had never heard of the Holocaust. A CNN-ComRes poll in 2018 found a similar situation in Europe.

On 2 July 1947, the Polish government passed a law establishing a state memorial to remember "the martyrdom of the Polish nation and other nations in Oswiecim". The museum established its exhibits at Auschwitz I; after the war, the barracks in Auschwitz II-Birkenau had been mostly dismantled and moved to Warsaw to be used on building sites. Dwork and van Pelt write that, in addition, Auschwitz I played a more central role in the persecution of the Polish people, in opposition to the importance of Auschwitz II to the Jews, including Polish Jews. An exhibition opened in Auschwitz I in 1955, displaying prisoner mug shots; hair, suitcases, and shoes taken from murdered prisoners; canisters of Zyklon B pellets; and other objects related to the killings. UNESCO added the camp to its list of World Heritage Sites in 1979. All the museum's directors were, until 1990, former Auschwitz prisoners. Visitors to the site have increased from 492,500 in 2001, to over one million in 2009, to two million in 2016.

There have been protracted disputes over the perceived Christianization of the site. Pope John Paul II celebrated mass over the train tracks leading to Auschwitz II-Birkenau on 7 June 1979, and called the camp "the Golgotha of our age", referring to the crucifixion of Jesus. More controversy followed when Carmelite nuns founded a convent in 1984 in a former theater outside the camp's perimeter, near block 11 of Auschwitz I, after which a local priest and some survivors erected a large cross—one that had been used during the pope's mass—behind block 11 to commemorate 152 Polish inmates shot by the Germans in 1941. After a long dispute, Pope John Paul II intervened, and the nuns moved the convent elsewhere in 1993. The cross remained, triggering the "War of the Crosses", as more crosses were erected to commemorate Christian victims, despite international objections. The Polish government and Catholic Church eventually agreed to remove all but the original.

On 4 September 2003, despite a protest from the museum, three Israeli Air Force F-15 Eagles performed a fly-over of Auschwitz II-Birkenau during a ceremony at the camp below. All three pilots were descendants of Holocaust survivors, including the man who led the flight, Major-General Amir Eshel. On 27 January 2015, some 300 Auschwitz survivors gathered with world leaders under a giant tent at the entrance to Auschwitz II to commemorate the 70th anniversary of the camp's liberation.

Museum curators consider visitors who pick up items from the ground to be thieves, and local police will charge them as such. The maximum penalty is a prison sentence of ten years. In June 2015, two British youths from the Perse School were convicted of theft after picking up buttons and shards of decorative glass from the ground near the area where camp victims' personal effects were stored. Curators said that similar incidents happen once or twice a year. The 16-ft "Arbeit Macht Frei" sign over the main camp's gate was stolen in December 2009 by a Swedish former neo-Nazi and two Polish men. The sign was later recovered.

In 2018 the Polish government passed an amendment to its Act on the Institute of National Remembrance, making it a criminal offence to make false suggestions of Polish complicity in the Holocaust, which would include referring to Auschwitz and other camps as "Polish death camps". After discussions with Israel's prime minister, amid international concern that the law would stifle research, the Polish government adjusted the amendment so that anyone falsely accusing Poland of complicity would be guilty only of a civil offence.






</doc>
<doc id="2007" url="https://en.wikipedia.org/wiki?curid=2007" title="Archery">
Archery

Archery is the art, sport, practice, or skill of using a bow to shoot arrows. The word comes from the Latin "arcus". Historically, archery has been used for hunting and combat. In modern times, it is mainly a competitive sport and recreational activity. A person who participates in archery is typically called an archer or a "bowman", and a person who is fond of or an expert at archery is sometimes called a toxophilite.

The bow and arrow seems to have been invented in the later Paleolithic or early Mesolithic periods. The oldest signs of its use in Europe come from the in the north of Hamburg, Germany and dates from the late Paleolithic, about 10,000–9000 BC. The arrows were made of pine and consisted of a main shaft and a long fore shaft with a flint point. There are no definite earlier bows; previous pointed shafts are known, but may have been launched by spear-throwers rather than bows. The oldest bows known so far comes from the Holmegård swamp in Denmark. Bows eventually replaced the spear-thrower as the predominant means for launching shafted projectiles, on every continent except Australasia, though spear-throwers persisted alongside the bow in parts of the Americas, notably Mexico and among the Inuit.

Bows and arrows have been present in Egyptian & neighboring Nubian culture since its respective predynastic & Pre-Kerma origins. In the Levant, artifacts that could be arrow-shaft straighteners are known from the Natufian culture, (c. 10,800–8,300 BC) onwards. The Khiamian and PPN A shouldered Khiam-points may well be arrowheads.

Classical civilizations, notably the Assyrians, Greeks, Armenians, Persians, Parthians, Indians, Koreans, Chinese, and Japanese fielded large numbers of archers in their armies. Akkadians were the first to use composite bows in war according to the victory stele of Naram-Sin of Akkad. Egyptians referred to Nubia as "Ta-Seti," or "The Land of the Bow," since the Nubians were known to be expert archers, and by the 16th Century BC Egyptians were using the composite bow in warfare . The Bronze Age Aegean Cultures were able to deploy a number of state-owned specialized bow makers for warfare and hunting purposes already from the 15th century BC. The Welsh longbow proved its worth for the first time in Continental warfare at the Battle of Crécy. In the Americas archery was widespread at European contact.

Archery was highly developed in Asia. The Sanskrit term for archery, dhanurveda, came to refer to martial arts in general. In East Asia, Goguryeo, one of the Three Kingdoms of Korea was well known for its regiments of exceptionally skilled archers.

Central tribesmen of Asia (after the domestication of the horse) and American Plains Indians (after gaining access to horses) became extremely adept at archery on horseback. Lightly armored, but highly mobile archers were excellently suited to warfare in the Central Asian steppes, and they formed a large part of armies that repeatedly conquered large areas of Eurasia. Shorter bows are more suited to use on horseback, and the composite bow enabled mounted archers to use powerful weapons. Empires throughout the Eurasian landmass often strongly associated their respective "barbarian" counterparts with the usage of the bow and arrow, to the point where powerful states like the Han Dynasty referred to their neighbors, the Xiong-nu, as "Those Who Draw the Bow". For example, Xiong-nu mounted bowmen made them more than a match for the Han military, and their threat was at least partially responsible for Chinese expansion into the Ordos region, to create a stronger, more powerful buffer zone against them. It is possible that "barbarian" peoples were responsible for introducing archery or certain types of bows to their "civilized" counterparts—the Xiong-nu and the Han being one example. Similarly, short bows seem to have been introduced to Japan by northeast Asian groups.

The development of firearms rendered bows obsolete in warfare, although efforts were sometimes made to preserve archery practice. In England and Wales, for example, the government tried to enforce practice with the longbow until the end of the 16th century. This was because it was recognized that the bow had been instrumental to military success during the Hundred Years' War. Despite the high social status, ongoing utility, and widespread pleasure of archery in Armenia, China, Egypt, England and Wales, America, India, Japan, Korea, Turkey and elsewhere, almost every culture that gained access to even early firearms used them widely, to the neglect of archery. Early firearms were inferior in rate-of-fire, and were very sensitive to wet weather. However, they had longer effective range and were tactically superior in the common situation of soldiers shooting at each other from behind obstructions. They also required significantly less training to use properly, in particular penetrating steel armor without any need to develop special musculature. Armies equipped with guns could thus provide superior firepower, and highly trained archers became obsolete on the battlefield. However, the bow and arrow is still an effective weapon, and archers have seen action in the 21st century. Traditional archery remains in use for sport, and for hunting in many areas.

Early recreational archery societies included the Finsbury Archers and the Ancient Society of Kilwinning Archers. The latter's annual Papingo event was first recorded in 1483. (In this event, archers shoot vertically from the base of an abbey tower to dislodge a wood pigeon placed approximately 30 meters above.) The Royal Company of Archers was formed in 1676 and is one of the oldest sporting bodies in the world. Archery remained a small and scattered pastime, however, until the late 18th century when it experienced a fashionable revival among the aristocracy. Sir Ashton Lever, an antiquarian and collector, formed the Toxophilite Society in London in 1781, with the patronage of George, the Prince of Wales.

Archery societies were set up across the country, each with its own strict entry criteria and outlandish costumes. Recreational archery soon became extravagant social and ceremonial events for the nobility, complete with flags, music and 21 gun salutes for the competitors. The clubs were "the drawing rooms of the great country houses placed outside" and thus came to play an important role in the social networks of the local upper class. As well as its emphasis on display and status, the sport was notable for its popularity with females. Young women could not only compete in the contests but retain and show off their sexuality while doing so. Thus, archery came to act as a forum for introductions, flirtation and romance. It was often consciously styled in the manner of a Medieval tournament with titles and laurel wreaths being presented as a reward to the victor. General meetings were held from 1789, in which local lodges convened together to standardise the rules and ceremonies. Archery was also co-opted as a distinctively British tradition, dating back to the lore of Robin Hood and it served as a patriotic form of entertainment at a time of political tension in Europe. The societies were also elitist, and the new middle class bourgeoisie were excluded from the clubs due to their lack of social status.

After the Napoleonic Wars, the sport became increasingly popular among all classes, and it was framed as a nostalgic reimagining of the preindustrial rural Britain. Particularly influential was Sir Walter Scott's 1819 novel, "Ivanhoe" that depicted the heroic character Lockseley winning an archery tournament.

The 1840s saw the second attempts at turning the recreation into a modern sport. The first Grand National Archery Society meeting was held in York in 1844 and over the next decade the extravagant and festive practices of the past were gradually whittled away and the rules were standardized as the 'York Round' - a series of shoots at 60, 80, and 100 yards. Horace A. Ford helped to improve archery standards and pioneered new archery techniques. He won the Grand National 11 times in a row and published a highly influential guide to the sport in 1856.
Towards the end of the 19th century, the sport experienced declining participation as alternative sports such as croquet and tennis became more popular among the middle class. By 1889, just 50 archery clubs were left in Britain, but it was still included as a sport at the 1900 Paris Olympics.

In the United States, primitive archery was revived in the early 20th century. The last of the Yahi Indian tribe, a native known as Ishi, came out of hiding in California in 1911. His doctor, Saxton Pope, learned many of Ishi's traditional archery skills, and popularized them. 

From the 1920s, professional engineers took an interest in archery, previously the exclusive field of traditional craft experts. They led the commercial development of new forms of bow including the modern recurve and compound bow. These modern forms are now dominant in modern Western archery; traditional bows are in a minority. In the 1980s, the skills of traditional archery were revived by American enthusiasts, and combined with the new scientific understanding. Much of this expertise is available in the "Traditional Bowyer's Bibles" (see Further reading). Modern game archery owes much of its success to Fred Bear, an American bow hunter and bow manufacturer.

Deities and heroes in several mythologies are described as archers, including the Greek Artemis and Apollo, the Roman Diana and Cupid, the Germanic Agilaz, continuing in legends like those of Wilhelm Tell, Palnetoke, or Robin Hood. Armenian Hayk and Babylonian Marduk, Indian Karna (also known as Radheya/son of Radha), Abhimanyu, Eklavya, Arjuna, Bhishma, Drona, Rama, and Shiva were known for their shooting skills. The famous archery competition of hitting the eye of a rotating fish while watching its reflection in the water bowl was one of the many archery skills depicted in the Mahabharata. 

Persian Arash was a famous archer. Earlier Greek representations of Heracles normally depict him as an archer.

The () were worshipped on the Greek island of Delos as attendants of Artemis, presiding over aspects of archery; (), represented distancing, (), trajectory, and (), aim.

Yi the archer and his apprentice Feng Meng appear in several early Chinese myths, and the historical character of Zhou Tong features in many fictional forms. Jumong, the first Taewang of the Goguryeo kingdom of the Three Kingdoms of Korea, is claimed by legend to have been a near-godlike archer. Archery features in the story of Oguz Khagan.

In West African Yoruba belief, Osoosi is one of several deities of the hunt who are identified with bow and arrow iconography and other insignia associated with archery.

While there is great variety in the construction details of bows (both historic and modern), all bows consist of a string attached to elastic limbs that store mechanical energy imparted by the user drawing the string. Bows may be broadly split into two categories: those drawn by pulling the string directly and those that use a mechanism to pull the string.

Directly drawn bows may be further divided based upon differences in the method of limb construction, notable examples being self bows, laminated bows and composite bows. Bows can also be classified by the bow shape of the limbs when unstrung; in contrast to traditional European straight bows, a recurve bow and some types of longbow have tips that curve away from the archer when the bow is unstrung. The cross-section of the limb also varies; the classic longbow is a tall bow with narrow limbs that are D-shaped in cross section, and the flatbow has flat wide limbs that are approximately rectangular in cross-section. Cable-backed bows use cords as the back of the bow; the draw weight of the bow can be adjusted by changing the tension of the cable. They were widespread among Inuit who lacked easy access to good bow wood. One variety of cable-backed bow is the Penobscot bow or Wabenaki bow, invented by Frank Loring (Chief Big Thunder) about 1900. It consists of a small bow attached by cables on the back of a larger main bow.

In different cultures, the arrows are released from either the left or right side of the bow, and this affects the hand grip and position of the bow. In Arab archery, Turkish archery and Kyūdō, the arrows are released from the right hand side of the bow, and this affects construction of the bow. In western archery, the arrow is usually released from the left hand side of the bow for a right-handed archer.

Compound bows are designed to reduce the force required to hold the string at full draw, hence allowing the archer more time to aim with less muscular stress. Most compound designs use cams or elliptical wheels on the ends of the limbs to achieve this. A typical let-off is anywhere from 65% to 80%. For example, a 60-pound bow with 80% let-off only requires 12 pounds of force to hold at full draw. Up to 99% let-off is possible. The compound bow was invented by Holless Wilbur Allen in the 1960s (a US patent was filed in 1966 and granted in 1969) and it has become the most widely used type of bow for all forms of archery in North America.

Mechanically drawn bows typically have a stock or other mounting, such as the crossbow. Crossbows typically have shorter draw lengths compared to compound bows. Because of this, heavier draw weights are required to achieve the same energy transfer to the arrow. These mechanically drawn bows also have devices to hold the tension when the bow is fully drawn. They are not limited by the strength of a single archer and larger varieties have been used as siege engines.

The most common form of arrow consists of a shaft, with an arrowhead at the front end, and fletchings and a nock at the other end. Arrows across time and history have normally been carried in a container known as a quiver, which can take many different forms. Shafts of arrows are typically composed of solid wood, bamboo, fiberglass, aluminium alloy, carbon fiber, or composite materials. Wooden arrows are prone to warping. Fiberglass arrows are brittle, but can be produced to uniform specifications easily. Aluminium shafts were a very popular high-performance choice in the latter half of the 20th century, due to their straightness, lighter weight, and subsequently higher speed and flatter trajectories. Carbon fiber arrows became popular in the 1990s because they are very light, flying even faster and flatter than aluminium arrows. Today, the most popular arrows at tournaments and Olympic events are made of composite materials, in particular the X10 and A/C/E, made by Easton,

The arrowhead is the primary functional component of the arrow. Some arrows may simply use a sharpened tip of the solid shaft, but separate arrowheads are far more common, usually made from metal, stone, or other hard materials. The most commonly used forms are target points, field points, and broadheads, although there are also other types, such as bodkin, judo, and blunt heads.
Fletching is traditionally made from bird feathers, but solid plastic vanes and thin sheet-like spin vanes are used. They are attached near the nock (rear) end of the arrow with thin double sided tape, glue, or, traditionally, sinew. The most common configuration in all cultures is three fletches, though as many as six have been used. Two makes the arrow unstable in flight. When the arrow is "three-fletched", the fletches are equally spaced around the shaft, with one placed such that it is perpendicular to the bow when nocked on the string, though variations are seen with modern equipment, especially when using the modern spin vanes. This fletch is called the "index fletch" or "cock feather" (also known as "the odd vane out" or "the nocking vane"), and the others are sometimes called the "hen feathers". Commonly, the cock feather is of a different color. However, if archers are using fletching made of feather or similar material, they may use same color vanes, as different dyes can give varying stiffness to vanes, resulting in less precision. When an arrow is "four-fletched", two opposing fletches are often cock feathers, and occasionally the fletches are not evenly spaced.

The fletching may be either "parabolic" cut (short feathers in a smooth parabolic curve) or "shield" cut (generally shaped like half of a narrow shield), and is often attached at an angle, known as "helical" fletching, to introduce a stabilizing spin to the arrow while in flight. Whether helicial or straight fletched, when natural fletching (bird feathers) is used it is critical that all feathers come from the same side of the bird. Oversized fletchings can be used to accentuate drag and thus limit the range of the arrow significantly; these arrows are called "flu-flus". Misplacement of fletchings can change the arrow's flight path dramatically.

Dacron and other modern materials offer high strength for their weight and are used on most modern bows. Linen and other traditional materials are still used on traditional bows. Several modern methods of making a bowstring exist, such as the 'endless loop' and 'Flemish twist'. Almost any fiber can be made into a bowstring. The author of "Arab Archery" suggests the hide of a young, emaciated camel. Njál's saga describes the refusal of a wife, Hallgerður, to cut her hair to make an emergency bowstring for her husband, Gunnar Hámundarson, who is then killed.

Most archers wear a bracer (also known as an arm-guard) to protect the inside of the bow arm from being hit by the string and prevent clothing from catching the bowstring. The bracer does not brace the arm; the word comes from the armoury term "brassard", meaning an armoured sleeve or badge. The Navajo people have developed highly ornamented bracers as non-functional items of adornment. Some archers (nearly all female archers) wear protection on their chests, called chestguards or plastrons. The myth of the Amazons was that they had one breast removed to solve this problem. Roger Ascham mentions one archer, presumably with an unusual shooting style, who wore a leather guard for his face.

The drawing digits are normally protected by a leather tab, glove, or thumb ring. A simple tab of leather is commonly used, as is a skeleton glove. Medieval Europeans probably used a complete leather glove.

Eurasiatic archers who used the thumb or Mongolian draw protected their thumbs, usually with leather according to the author of "Arab Archery", but also with special rings of various hard materials. Many surviving Turkish and Chinese examples are works of considerable art. Some are so highly ornamented that the users could not have used them to loose an arrow. Possibly these were items of personal adornment, and hence value, remaining extant whilst leather had virtually no intrinsic value and would also deteriorate with time. In traditional Japanese archery a special glove is used that has a ridge to assist in drawing the string.

A release aid is a mechanical device designed to give a crisp and precise loose of arrows from a compound bow. In the most commonly used, the string is released by a finger-operated trigger mechanism, held in the archer's hand or attached to their wrist. In another type, known as a back-tension release, the string is automatically released when drawn to a pre-determined tension.

Stabilizers are mounted at various points on the bow. Common with competitive archery equipment are special brackets that allow multiple stabilizers to be mounted at various angles to fine tune the bow's balance.

Stabilizers aid in aiming by improving the balance of the bow. Sights, quivers, rests, and design of the riser (the central, non-bending part of the bow) make one side of the bow heavier. One purpose of stabilizers are to offset these forces. A reflex riser design will cause the top limb to lean towards the shooter. In this case a heavier front stabilizer is desired to offset this action. A deflex riser design has the opposite effect and a lighter front stabilizer may be used.

Stabilizers can reduce noise and vibration. These energies are absorbed by viscoelastic polymers, gels, powders, and other materials used to build stabilizers.

Stabilizers improve the forgiveness and accuracy by increasing the moment of inertia of the bow to resist movement during the shooting process. Lightweight carbon stabilizers with weighted ends are desirable because they improve the moment of interia while minimizing the weight added.

The standard convention on teaching archery is to hold the bow depending upon eye dominance. (One exception is in modern Kyudo where all archers are trained to hold the bow in the left hand.) Therefore, if one is right-eye dominant, they would hold the bow in the left hand and draw the string with the right hand. However, not everyone agrees with this line of thought. A smoother, and more fluid release of the string will produce the most consistently repeatable shots, and therefore may provide greater accuracy of the arrow flight. Some believe that the hand with the greatest dexterity should therefore be the hand that draws and releases the string. Either eye can be used for aiming, and the less dominant eye can be trained over time to become more effective for use. To assist with this, an eye patch can be temporarily worn over the dominant eye.

The hand that holds the bow is referred to as the "bow hand" and its arm the "bow arm". The opposite hand is called the "drawing hand" or "string hand". Terms such as "bow shoulder" or "string elbow" follow the same convention.

If shooting according to eye dominance, right-eye-dominant archers shooting conventionally hold the bow with their left hand. If shooting according to hand dexterity, the archer draws the string with the hand that possesses the greatest dexterity, regardless of eye dominance.

To shoot an arrow, an archer first assumes the correct stance. The body should be at or nearly perpendicular to the target and the shooting line, with the feet placed shoulder-width apart. As an archer progresses from beginner to a more advanced level other stances such as the "open stance" or the "closed stance" may be used, although many choose to stick with a "neutral stance". Each archer has a particular preference, but mostly this term indicates that the leg furthest from the shooting line is a half to a whole foot-length from the other foot, on the ground.

To load, the bow is pointed toward the ground, tipped slightly clockwise of vertical (for a right handed shooter) and the shaft of the arrow is placed on the arrow rest or shelf. The back of the arrow is attached to the bowstring with the nock (a small locking groove located at the proximal end of the arrow). This step is called "nocking the arrow". Typical arrows with three vanes should be oriented such that a single vane, the "cock feather", is pointing away from the bow, to improve the clearance of the arrow as it passes the arrow rest.

A compound bow is fitted with a special type of arrow rest, known as a launcher, and the arrow is usually loaded with the cock feather/vane pointed either up, or down, depending upon the type of launcher being used.

The bowstring and arrow are held with three fingers, or with a mechanical arrow release. Most commonly, for finger shooters, the index finger is placed above the arrow and the next two fingers below, although several other techniques have their adherents around the world, involving three fingers below the arrow, or an arrow pinching technique. "Instinctive" shooting is a technique eschewing sights and is often preferred by traditional archers (shooters of longbows and recurves). In either the split finger or three finger under case, the string is usually placed in the first or second joint, or else on the pads of the fingers. When using a mechanical release aid, the release is hooked onto the D-loop.

Another type of string hold, used on traditional bows, is the type favoured by the Mongol warriors, known as the "thumb release", style. This involves using the thumb to draw the string, with the fingers curling around the thumb to add some support. To release the string, the fingers are opened out and the thumb relaxes to allow the string to slide off the thumb. When using this type of release, the arrow should rest on the same side of the bow as the drawing hand i.e. Left hand draw = arrow on left side of bow.

The archer then raises the bow and draws the string, with varying alignments for vertical versus slightly canted bow positions. This is often one fluid motion for shooters of recurves and longbows, which tend to vary from archer to archer. Compound shooters often experience a slight jerk during the drawback, at around the last inch and a half, where the draw weight is at its maximum—before relaxing into a comfortable stable full draw position. The archer draws the string hand towards the face, where it should rest lightly at a fixed "anchor point". This point is consistent from shot to shot, and is usually at the corner of the mouth, on the chin, to the cheek, or to the ear, depending on preferred shooting style. The archer holds the bow arm outwards, toward the target. The elbow of this arm should be rotated so that the inner elbow is perpendicular to the ground, though archers with hyper extendable elbows tend to angle the inner elbow toward the ground, as exemplified by the Korean archer Jang Yong-Ho. This keeps the forearm out of the way of the bowstring.

In modern form, the archer stands erect, forming a "T". The archer's lower trapezius muscles are used to pull the arrow to the anchor point. Some modern recurve bows are equipped with a mechanical device, called a clicker, which produces a clicking sound when the archer reaches the correct draw length. In contrast, traditional English Longbow shooters step "into the bow", exerting force with both the bow arm and the string hand arm simultaneously, especially when using bows having draw weights from 100 lbs to over 175 lbs. Heavily stacked traditional bows (recurves, long bows, and the like) are released immediately upon reaching full draw at maximum weight, whereas compound bows reach their maximum weight around the last inch and a half, dropping holding weight significantly at full draw. Compound bows are often held at full draw for a short time to achieve maximum accuracy.

The arrow is typically released by relaxing the fingers of the drawing hand (see Bow draw), or triggering the mechanical release aid. Usually the release aims to keep the drawing arm rigid, the bow hand relaxed, and the arrow is moved back using the back muscles, as opposed to using just arm motions. An archer should also pay attention to the recoil or "follow through" of his or her body, as it may indicate problems with form (technique) that affect accuracy.

There are two main forms of aiming in archery: using a mechanical or fixed sight, or barebow.

Mechanical sights can be affixed to the bow to aid in aiming. They can be as simple as a pin, or may use optics with magnification. They usually also have a peep sight (rear sight) built into the string, which aids in a consistent anchor point. Modern compound bows automatically limit the draw length to give a consistent arrow velocity, while traditional bows allow great variation in draw length. Some bows use mechanical methods to make the draw length consistent. Barebow archers often use a sight picture, which includes the target, the bow, the hand, the arrow shaft and the arrow tip, as seen at the same time by the archer. With a fixed "anchor point" (where the string is brought to, or close to, the face), and a fully extended bow arm, successive shots taken with the sight picture in the same position fall on the same point. This lets the archer adjust aim with successive shots to achieve accuracy.

Modern archery equipment usually includes sights. Instinctive aiming is used by many archers who use traditional bows. The two most common forms of a non-mechanical release are split-finger and three-under. Split-finger aiming requires the archer to place the index finger above the nocked arrow, while the middle and ring fingers are both placed below. Three-under aiming places the index, middle, and ring fingers under the nocked arrow. This technique allows the archer to better look down the arrow since the back of the arrow is closer to the dominant eye, and is commonly called "gun barreling" (referring to common aiming techniques used with firearms).

When using short bows or shooting from horseback, it is difficult to use the sight picture. The archer may look at the target, but without including the weapon in the field of accurate view. Aiming then involves hand-eye coordination—which includes proprioception and motor-muscle memory, similar to that used when throwing a ball. With sufficient practice, such archers can normally achieve good practical accuracy for hunting or for war. Aiming without a sight picture may allow more rapid shooting, not however increasing accuracy.

Instinctive shooting is a style of shooting that includes the barebow aiming method that relies heavily upon the subconscious mind, proprioception, and motor/muscle memory to make aiming adjustments; the term used to refer to a general category of archers who did not use a mechanical or fixed sight.

When a projectile is thrown by hand, the speed of the projectile is determined by the kinetic energy imparted by the thrower's muscles performing work. However, the energy must be imparted over a limited distance (determined by arm length) and therefore (because the projectile is accelerating) over a limited time, so the limiting factor is not work but rather power, which determined how much energy can be added in the limited time available. Power generated by muscles, however, is limited by force–velocity relationship, and even at the optimal contraction speed for power production, total work by the muscle is less than half of what it would be if the muscle contracted over the same distance at slow speeds, resulting in less than 1/4 the projectile launch velocity possible without the limitations of the force–velocity relationship.

When a bow is used, the muscles are able to perform work much more slowly, resulting in greater force and greater work done. This work is stored in the bow as elastic potential energy, and when the bowstring is released, this stored energy is imparted to the arrow much more quickly than can be delivered by the muscles, resulting in much higher velocity and, hence, greater distance. This same process is employed by frogs, which use elastic tendons to increase jumping distance. In archery, some energy dissipates through elastic hysteresis, reducing the overall amount released when the bow is shot. Of the remaining energy, some is dampened both by the limbs of the bow and the bowstring. Depending on the arrow's elasticity, some of the energy is also absorbed by compressing the arrow, primarily because the release of the bowstring is rarely in line with the arrow shaft, causing it to flex out to one side. This is because the bowstring accelerates faster than the archer's fingers can open, and consequently some sideways motion is imparted to the string, and hence arrow nock, as the power and speed of the bow pulls the string off the opening fingers.

Even with a release aid mechanism some of this effect is usually experienced, since the string always accelerates faster than the retaining part of the mechanism. This makes the arrow oscillate in flight—its center flexing to one side and then the other repeatedly, gradually reducing as the arrow's flight proceeds. This is clearly visible in high-speed photography of arrows at discharge. A direct effect of these energy transfers can clearly be seen when dry firing. Dry firing refers to releasing the bowstring without a nocked arrow. Because there is no arrow to receive the stored potential energy, almost all the energy stays in the bow. Some have suggested that dry firing may cause physical damage to the bow, such as cracks and fractures—and because most bows are not specifically made to handle the high amounts of energy dry firing produces, should never be done.
Modern arrows are made to a specified 'spine', or stiffness rating, to maintain matched flexing and hence accuracy of aim. This flexing can be a desirable feature, since, when the spine of the shaft is matched to the acceleration of the bow(string), the arrow bends or flexes around the bow and any arrow-rest, and consequently the arrow, and fletchings, have an un-impeded flight. This feature is known as the archer's paradox. It maintains accuracy, for if part of the arrow struck a glancing blow on discharge, some inconsistency would be present, and the excellent accuracy of modern equipment would not be achieved.

The accurate flight of an arrow depends on its fletchings. The arrow's manufacturer (a "fletcher") can arrange fletching to cause the arrow to rotate along its axis. This improves accuracy by evening pressure buildups that would otherwise cause the arrow to "plane" on the air in a random direction after shooting. Even with a carefully made arrow, the slightest imperfection or air movement causes some unbalanced turbulence in air flow. Consequently, rotation creates an equalization of such turbulence, which, overall, maintains the intended direction of flight i.e. accuracy. This rotation is not to be confused with the rapid gyroscopic rotation of a rifle bullet. Fletching that is not arranged to induce rotation still improves accuracy by causing a restoring drag any time the arrow tilts from its intended direction of travel.

The innovative aspect of the invention of the bow and arrow was the amount of power delivered to an extremely small area by the arrow. The huge ratio of length vs. cross sectional area, coupled with velocity, made the arrow more powerful than any other hand held weapon until firearms were invented. Arrows can spread or concentrate force, depending on the application. Practice arrows, for instance, have a blunt tip that spreads the force over a wider area to reduce the risk of injury or limit penetration. Arrows designed to pierce armor in the Middle Ages used a very narrow and sharp tip ("bodkinhead") to concentrate the force. Arrows used for hunting used a narrow tip ("broadhead") that widens further, to facilitate both penetration and a large wound.

Using archery to take game animals is known as "bow hunting". Bow hunting differs markedly from hunting with firearms, as distance between hunter and prey must be much shorter to ensure a humane kill. The skills and practices of bow hunting therefore emphasize very close approach to the prey, whether by still hunting, stalking, or waiting in a blind or tree stand. In many countries, including much of the United States, bow hunting for large and small game is legal. Bow hunters generally enjoy longer seasons than are allowed with other forms of hunting such as black powder, shotgun, or rifle. Usually, compound bows are used for large game hunting due to the relatively short time it takes to master them as opposed to the longbow or recurve bow. These compound bows may feature fiber optic sights, stabilizers, and other accessories designed to increase accuracy at longer distances. Using a bow and arrow to take fish is known as "bow fishing".

Competitive archery involves shooting arrows at a target for accuracy from a set distance or distances. This is the most popular form of competitive archery worldwide and is called target archery. A form particularly popular in Europe and America is field archery, shot at targets generally set at various distances in a wooded setting. Competitive archery in the United States is governed by USA Archery and National Field Archery Association (NFAA), which also certifies instructors.

Para-Archery is an adaptation of archery for athletes with a disability governed by the World Archery Federation (WA), and is one of the sports in the Summer Paralympic Games. There are also several other lesser-known and historical forms of archery, as well as archery novelty games and flight archery, where the aim is to shoot the greatest distance.




</doc>
<doc id="2009" url="https://en.wikipedia.org/wiki?curid=2009" title="Alvar Aalto">
Alvar Aalto

Hugo Alvar Henrik Aalto (; 3 February 1898 – 11 May 1976) was a Finnish architect and designer. His work includes architecture, furniture, textiles and glassware, as well as sculptures and paintings, though he never regarded himself as an artist, seeing painting and sculpture as "branches of the tree whose trunk is architecture." Aalto's early career runs in parallel with the rapid economic growth and industrialization of Finland during the first half of the twentieth century and many of his clients were industrialists; among these were the Ahlström-Gullichsen family. The span of his career, from the 1920s to the 1970s, is reflected in the styles of his work, ranging from Nordic Classicism of the early work, to a rational International Style Modernism during the 1930s to a more organic modernist style from the 1940s onwards. What is typical for his entire career, however, is a concern for design as a Gesamtkunstwerk, a "total work of art"; whereby he – together with his first wife Aino Aalto – would design not just the building, but give special treatments to the interior surfaces and design furniture, lamps, and furnishings and glassware. His furniture designs are considered Scandinavian Modern, in the sense of a concern for materials, especially wood, and simplification but also technical experimentation, which led to him receiving patents for various manufacturing processes, such as bent wood. The Alvar Aalto Museum, designed by Aalto himself, is located in what is regarded as his home city Jyväskylä.

Hugo Alvar Henrik Aalto was born in Kuortane, Finland. His father, Johan Henrik Aalto, was a Finnish-speaking land-surveyor and his mother, Selma Matilda "Selly" (née Hackstedt) was a Swedish-speaking postmistress. When Aalto was 5 years old, the family moved to Alajärvi, and from there to Jyväskylä in Central Finland.

He studied at the Jyväskylä Lyceum school, where he completed his basic education in 1916, and took drawing lessons from a local artist named Jonas Heiska. In 1916, he then enrolled to study architecture at the Helsinki University of Technology. His studies were interrupted by the Finnish Civil War, which he fought in. He fought on the side of the "White Army" and fought at the Battle of Länkipohja and the Battle of Tampere.

He built his first piece of architecture while still a student, a house for his parents, at Alajärvi. Afterwards, he continued his education, graduating in 1921. In the summer of 1922 he began his official military service, finishing at the Hamina reserve officer training school, and was promoted to reserve second lieutenant in June 1923.

In 1920, while still a student, Aalto made his first trip abroad, travelling via Stockholm to Gothenburg, where he even briefly found work with the architect Arvid Bjerke. In 1922, he accomplished his first independent piece at the Industrial Exposition in Tampere. In 1923, he returned to Jyväskylä, where he opened his first architectural office under the name 'Alvar Aalto, Architect and Monumental Artist'. At that same time he also wrote articles for the Jyväskylä newspaper "Sisä-Suomi" under the pseudonym Remus. During this time, he designed a number of small single-family houses in Jyväskylä, and the office's workload steadily increased.

On October 6, 1924, Aalto married architect Aino Marsio; their honeymoon journey to Italy was Aalto's first trip there, though Aino had previously made a study trip there. The latter trip together sealed an intellectual bond with the culture of the Mediterranean region that was to remain important to Aalto for the rest of his life.

On their return, they continued with a number of local projects, notably the Jyväskylä Worker's Club, which incorporated a number of motifs which they had studied during their trip, most notably the decorations of the Festival hall modelled on the Rucellai Sepulchre in Florence by Leon Battista Alberti. Following winning the architecture competition for the Southwest Finland Agricultural Cooperative building in 1927 the Aaltos moved their office to Turku. They had made contact with the city's most progressive architect, Erik Bryggman, already before moving, and they then began collaborating with him, most notably on the Turku Fair of 1928-29. Aalto's biographer, Göran Schildt, claimed that Bryggman was the only architect with whom Aalto cooperated as an equal. With increasing works in the Finnish capital, the Aaltos' office moved again in 1933 to Helsinki.

The Aaltos designed and built a joint house-office (1935–36) for themselves in Munkkiniemi, Helsinki, but later (1954–56) had a purpose-built office erected in the same neighbourhood – nowadays the former is a "home museum" and the latter the premises of the Alvar Aalto Academy. In 1926, the young Aaltos designed and had built for themselves a summer cottage in Alajärvi, Villa Flora.

Aino Aalto died of cancer in 1949. Aino and Alvar Aalto had two children, a daughter, Johanna "Hanni", Mrs Alanen (born 1925), and a son, Hamilkar Aalto (born 1928). In 1952, Aalto married architect Elissa Mäkiniemi (died 1994), who had been working as an assistant in his office.

In 1952, he designed and built a summer cottage, the so-called Experimental House, for himself and his new wife in Muuratsalo in Central Finland. Alvar Aalto died on 11 May 1976, in Helsinki, and is buried in the Hietaniemi cemetery in Helsinki. His wife and the office employees continued the works of the office which were still in progress. In 1978 the Museum of Finnish Architecture in Helsinki arranged a major exhibition of Aalto's works.

Although he is sometimes regarded as among the first and most influential architects of Nordic modernism, a closer examination of the historical facts reveals that Aalto (while a pioneer in Finland) closely followed and had personal contacts with other pioneers in Sweden, in particular Gunnar Asplund and Sven Markelius. What they and many others of that generation in the Nordic countries had in common was that they started off from a classical education and were first designing classical architecture, though what historians now call Nordic Classicism – a style that had been a reaction to the previous dominant style of National Romanticism – before moving, in the late 1920s, towards Modernism.

Upon returning to Jyväskylä in 1923 to establish his own architect's office, Aalto busied himself with a number of single-family homes, all designed in the Nordic Classicism style, such as the manor-like house for his mother's cousin Terho Manner in Töysa in 1923, a summer villa for the Jyväskylä chief constable in 1923 and the Alatalo farmhouse in Tarvaala in 1924. During this period he also completed his first public buildings, the Jyväskylä Workers' Club in 1925, the Jyväskylä Defence Corps building in 1926 and the Seinäjoki Defence Corp building in 1924–29. He entered several architectural competitions for prestigious state public buildings, both in Finland and abroad, including the two competitions for the Finnish Parliament building in 1923 and 1924, the extension to the University of Helsinki in 1931, and the building to house the League of Nations in Geneva, Switzerland, in 1926–27. 

Furthermore, this was the period when Aalto was most prolific in his writings, with articles for professional journals and newspapers. Among his most well-known essays from this period are "Urban culture" (1924), "Temple baths on Jyväskylä ridge" (1925), "Abbé Coignard's sermon" (1925), and "From doorstep to living room" (1926).

The shift in Aalto's design approach from classicism to modernism is epitomised by the Viipuri Library in Vyborg (1927–35), which went through a transformation from an originally classical competition entry proposal to the completed high-modernist building. Yet his humanistic approach is in full evidence in the library: the interior displays natural materials, warm colours, and undulating lines. Due to problems over financing and a change of site, the Viipuri Library project lasted eight years, and during that same time he also designed the Standard Apartment Building (1928–29) in Turku, Turun Sanomat Building (1929–30) and Paimio Sanatorium (1929–32). A number of factors heralded Aalto's shift towards modernism: on a personal level, Aalto's increased familiarization of international trends especially after travelling throughout Europe, but in terms of completed projects it was the client of the Standard Apartment Building giving Aalto the opportunity to experiment with concrete prefabrication, the cutting-edge Corbusian form language of the Turun Sanomat Building, and these were then carried forward both in the Paimio Sanatorium and in the ongoing design for the library. Although the Turun Sanomat Building and Paimio Sanatorium are comparatively pure modernist works, they too carried the seeds of his questioning of such an orthodox modernist approach and a move to a more daring, synthetic attitude. It has been pointed out that the planning principle for Paimio Sanatorium - the splayed wings - was indebted to the Zonnestraal Sanatorium (1925–31) by Jan Duiker, which Aalto visited while it was still under construction. But while these early Functionalist works by Aalto bear hallmarks of influences from Le Corbusier, Walter Gropius and other key modernist figures of central Europe, in all these buildings Aalto nevertheless started to show his individuality in a departure from such norms with the introduction of organic references.

Through Sven Markelius, Aalto became a member of the Congres Internationaux d'Architecture Moderne (CIAM), attending the second congress in Frankfurt in 1929 and the fourth congress in Athens in 1933, where he established a close friendship with László Moholy-Nagy, Sigfried Giedion and Philip Morton Shand. It was during this time that he followed closely the work of the main driving force behind the new modernism, Le Corbusier, and visited him in his Paris office several times in the following years.

It was not until the completion of the Paimio Sanatorium (1932) and Viipuri Library (1935) that Aalto first achieved world attention in architecture. His reputation grew in the USA following the invitation to hold a retrospective exhibition of his works at the MOMA in New York in 1938, which was also the first time he visited the US. The significance of the exhibition - which afterwards went on a 12-city tour of the country - lies in the fact that he was only the second ever architect - after Le Corbusier - to have a solo exhibition at the museum. His reputation grew in the USA following the critical reception of his design for the Finnish Pavilion at the 1939 New York World's Fair, described by Frank Lloyd Wright as a "work of genius". It could be said that Aalto's international reputation was sealed with his inclusion in the second edition of Sigfried Giedion's influential book on Modernist architecture, "Space, Time and Architecture: The growth of a new tradition" (1949), in which Aalto received more attention than any other Modernist architect, including Le Corbusier. In his analysis of Aalto, Giedion gave primacy to qualities that depart from direct functionality, such as mood, atmosphere, intensity of life and even national characteristics, declaring that "Finland is with Aalto wherever he goes".

During the 1930s Alvar spent some time experimenting with laminated wood, making sculptures, and abstract reliefs, characterized by irregular curved forms. Utilizing this knowledge he was able to solve technical problems concerning the flexibility of wood and also of working out spatial issues in his designs. Aalto's early experiments with wood and his move away from a purist modernism would be tested in built form with the commission to design Villa Mairea (1939) in Noormarkku, the luxury home of the young industrialist couple Harry and Maire Gullichsen. It was Maire Gullichsen who acted as the main client, and she worked closely not only with Alvar but also Aino Aalto on the design, inspiring them to be more daring in their work. The original design was to include a private art gallery, but this was never built. The building forms a U-shape around a central inner "garden" the central feature of which is a kidney-shaped swimming pool. Adjacent to the pool is a sauna executed in a rustic style, alluding to both Finnish and Japanese precedents. The design of the house is a synthesis of numerous stylistic influences, from traditional Finnish vernacular to purist modernism, as well as influences from English and Japanese architecture. While the house is clearly intended for a wealthy family, Aalto nevertheless argued that it was also an experiment that would prove useful in the design of mass housing.

His increased fame led to offers and commissions outside Finland. In 1941 he accepted an invitation as a visiting professor to Massachusetts Institute of Technology in the USA. Because of the Second World War, he returned to Finland to direct the Reconstruction Office. After the war, he returned to MIT, where he designed the student dormitory Baker House, completed in 1949. The dormitory lay along the Charles River and its undulating form provided maximum view and ventilation for each resident. This building was the first building of Aalto's redbrick period. Originally used in Baker House to signify the Ivy League university tradition, on his return to Finland Aalto used it in a number of key buildings, in particular, in several of the buildings in the new Helsinki University of Technology campus (starting in 1950), Säynätsalo Town Hall (1952), Helsinki Pensions Institute (1954), Helsinki House of Culture (1958), as well as in his own summer house, the so-called Experimental House in Muuratsalo (1957).

In the fifties Aalto immersed himself in his sculpting, be it with wood, bronze, marble, or mixed media. Among the notable works from this period is the memorial to the Battle of Suomussalmi (1960); located on the battlefield, it consists of a leaning bronze pillar on a pedestal.

The early 1960s and 1970s (up until his death in 1976) were marked by key works in Helsinki, in particular the huge town plan for the void in centre of Helsinki adjacent to Töölö Bay and the vast railway yards, and marked on the edges by significant buildings such as the National Museum and the main railway station, both by Eliel Saarinen. In his town plan Aalto proposed a line of separate marble-clad buildings fronting the bay which would house various cultural institutions, including a concert hall, opera, museum of architecture and headquarters for the Finnish Academy. The scheme also extended into the Kamppi district with a series of tall office blocks. Aalto first presented his scheme in 1961, but it went through various modifications during the early 1960s. Only two fragments of the overall plan were ever realized: the Finlandia Hall concert hall (1976) fronting Töölö Bay, and an office building in the Kamppi district for the Helsinki Electricity Company (1975). The Miesian formal language of geometric grids employed in the buildings was also used by Aalto for other sites in Helsinki, including the Enso-Gutzeit building (1962), the Academic Bookstore (1962) and the SYP Bank building (1969).

Following Aalto's death in 1976 his office continued to operate under the direction of his widow, Elissa, completing works already to some extent designed. These works include the Jyväskylä City Theatre and Essen opera house. Since the death of Elissa Aalto the office has continued to operate as the Alvar Aalto Academy, giving advice on the restoration of Aalto buildings and organising the vast archive material.

Whereas Aalto was famous for his architecture, his furniture designs were well thought of and are still popular today. He studied Josef Hoffmann and the Wiener Werkstätte, and for a period of time, worked under Eliel Saarinen. He also gained inspiration from Gebrüder Thonet. During the late 1920s and 1930s he, working closely with Aino Aalto, also focused a lot of his energy on furniture design, partly due to the decision to design much of the individual furniture pieces and lamps for the Paimio Sanatorium. Of particular significance was the experimentation in bent plywood chairs, most notably the so-called Paimio chair, which had been designed for the sitting tuberculosis patient, and the Model 60 stacking stool. The Aaltos, together with visual arts promoter Maire Gullichsen and art historian Nils-Gustav Hahl founded the Artek company in 1935, ostensibly to sell Aalto products but also other imported products. He became the first furniture designer to use the cantilever principle in chair design using wood.

Aalto's awards included the Prince Eugen Medal in 1954, the Royal Gold Medal for Architecture from the Royal Institute of British Architects in 1957 and the Gold Medal from the American Institute of Architects in 1963. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1957. He also was a member of the Academy of Finland, and was its president from 1963 to 1968. From 1925 to 1956 he was a member of the Congrès International d'Architecture Moderne. In 1960 he received an honorary doctorate at the Norwegian University of Science and Technology (NTNU).

Aalto's career spans the changes in style from (Nordic Classicism) to purist International Style Modernism to a more personal, synthetic and idiosyncratic Modernism. Aalto's wide field of design activity ranges from the large scale of city planning and architecture to interior design, furniture and glassware design and painting. It has been estimated that during his entire career Aalto designed over 500 individual buildings, approximately 300 of which were built, the vast majority of which are in Finland. He also has a few buildings in France, Germany, Italy and the USA.

Aalto's work with wood, was influenced by early Scandinavian architects; however, his experiments and departure from the norm brought attention to his ability to make wood do things not previously done. His techniques in the way he cut the beech tree, for example, and also his ability to use plywood as structural and aesthetic. Other examples include the rough-hewn vertical placement of logs at his pavilion at the Lapua expo, looking similar to a medieval barricade, at the orchestra platform at turku and the Paris expo at the World Fair, he used varying sizes and shapes of planks. Also at Paris and at Villa Mairea he utilized birch boarding in a vertical arrangement. Also his famous undulating walls and ceilings made of red pine. In his roofing, he created massive spans (155-foot at the covered statium at Otaniemi) all without tie rods. His stairway at Villa Mairea, he evokes feelings of a natural forest by binding beech wood with withes into columns.

Aalto claimed that his paintings were not made as individual artworks but as part of his process of architectural design, and many of his small-scale "sculptural" experiments with wood led to later larger architectural details and forms. These experiments also led to a number of patents: for example, he invented a new form of laminated bent-plywood furniture in 1932 (which was patented in 1933). His experimental method had been influenced by his meetings with various members of the Bauhaus design school, especially László Moholy-Nagy, whom he first met in 1930. Aalto's furniture was exhibited in London in 1935, to great critical acclaim, and to cope with the consumer demand Aalto, together with his wife Aino, Maire Gullichsen and Nils-Gustav Hahl founded the company Artek that same year. Aalto glassware (Aino as well as Alvar) is manufactured by Iittala.

Aalto's 'High Stool' and 'Stool E60' (manufactured by Artek) are currently used in Apple Stores across the world to serve as seating for customers. Finished in black lacquer, the stools are used to seat customers at the 'Genius Bar' and also in other areas of the store at times when seating is required for a product workshop or special event. Aalto was also influential in bringing modern art to the knowledge of the Finnish people, in particular the work of his friends, Alexander Milne Calder and Fernand Léger.




As already mentioned, Aalto's international reputation was sealed with his inclusion in the second edition of Sigfried Giedion's influential book on Modernist architecture, "Space, Time and Architecture: The growth of a new tradition" (1949), in which Aalto received more attention than any other Modernist architect, including Le Corbusier. In his analysis of Aalto, Giedion gave primacy to qualities that depart from direct functionality, such as mood, atmosphere, intensity of life and even national characteristics, declaring that "Finland is with Aalto wherever he goes". However, a few more recent architecture critics and historians have questioned Aalto's position of influence in the canonic history. Italian Marxist architecture historians Manfredo Tafuri and Francesco Dal Co put forward the viewpoint that Aalto's "historical significance has perhaps been rather exaggerated; with Aalto we are outside of the great themes that have made the course of contemporary architecture so dramatic. The qualities of his works have a meaning only as masterful distractions, not subject to reproduction outside the remote reality in which they have their roots." Their viewpoint was propounded by their own priority given to urbanism, seeing Aalto as an anti-urban, and thus consequently disparaging what they regarded as peripheral non-urban areas of the world: "Essentially his architecture is not appropriate to urban typologies." Similarly concerned with the appropriateness of Aalto's form language, at the other end of the political spectrum, American postmodernist critic Charles Jencks made a claim for the need for buildings to signify meaning; however, he then lifted out Aalto's Pensions Institute building as an example of what he termed Aalto's 'soft paternalism': "Conceived as a fragmented mass to break up the feeling of bureaucracy, it succeeds all too well in being humane and killing the pensioner with kindness. The forms are familiar red brick and ribbon-strip windows broken by copper and bronze elements – all carried through with a literal-mindedness that borders on the soporific." But also during Aalto's lifetime he faced critique from his fellow architects in Finland, most notably Kirmo Mikkola and Juhani Pallasmaa; by the last decade of his life Aalto's work was seen as idiosyncratic and individualistic, when the opposing tendencies of rationalism and constructivism – often championed under left-wing politics – argued for anonymous virtually non-aesthetic architecture. Mikkola wrote of Aalto's late works: "Aalto has moved to his present baroque line..."

Aalto has been commemorated in a number of ways:



Göran Schildt has written and edited many books on Aalto, the most well-known being the three-volume biography, usually referred to as the definitive biography on Aalto.








</doc>
