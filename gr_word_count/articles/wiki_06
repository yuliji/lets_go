<doc id="1144" url="https://en.wikipedia.org/wiki?curid=1144" title="Ardipithecus">
Ardipithecus

Ardipithecus is a genus of an extinct hominine that lived during the Late Miocene and Early Pliocene epochs in the Afar Depression, Ethiopia. Originally described as one of the earliest ancestors of humans after they diverged from the chimpanzees, the relation of this genus to human ancestors and whether it is a hominin is now a matter of debate. Two fossil species are described in the literature: "A. ramidus", which lived about 4.4 million years ago during the early Pliocene, and "A. kadabba", dated to approximately 5.6 million years ago (late Miocene). Behavioral analysis showed that "Ardipithecus" could be very similar to chimpanzees, indicating that the early human ancestors were very chimpanzee-like in behavior.

"A. ramidus" was named in September 1994. The first fossil found was dated to 4.4 million years ago on the basis of its stratigraphic position between two volcanic strata: the basal Gaala Tuff Complex (G.A.T.C.) and the Daam Aatu Basaltic Tuff (D.A.B.T.). The name "Ardipithecus ramidus" stems mostly from the Afar language, in which "Ardi" means "ground/floor" and "ramid" means "root". The "pithecus" portion of the name is from the Greek word for "ape".

Like most hominids, but unlike all previously recognized hominins, it had a grasping hallux or big toe adapted for locomotion in the trees. It is not confirmed how much other features of its skeleton reflect adaptation to bipedalism on the ground as well. Like later hominins, "Ardipithecus" had reduced canine teeth.

In 1992–1993 a research team headed by Tim White discovered the first "A. ramidus" fossils—seventeen fragments including skull, mandible, teeth and arm bones—from the Afar Depression in the Middle Awash river valley of Ethiopia. More fragments were recovered in 1994, amounting to 45% of the total skeleton. This fossil was originally described as a species of "Australopithecus", but White and his colleagues later published a note in the same journal renaming the fossil under a new genus, "Ardipithecus". Between 1999 and 2003, a multidisciplinary team led by Sileshi Semaw discovered bones and teeth of nine "A. ramidus" individuals at As Duma in the Gona Western Margin of Ethiopia's Afar Region. The fossils were dated to between 4.35 and 4.45 million years old.

"Ardipithecus ramidus" had a small brain, measuring between 300 and 350 cm. This is slightly smaller than a modern bonobo or female common chimpanzee brain, but much smaller than the brain of australopithecines like Lucy (~400 to 550 cm) and roughly 20% the size of the modern "Homo sapiens" brain. Like common chimpanzees, "A. ramidus" was much more prognathic than modern humans.

The teeth of "A. ramidus" lacked the specialization of other apes, and suggest that it was a generalized omnivore and frugivore (fruit eater) with a diet that did not depend heavily on foliage, fibrous plant material (roots, tubers, etc.), or hard and or abrasive food. The size of the upper canine tooth in "A. ramidus" males was not distinctly different from that of females. Their upper canines were less sharp than those of modern common chimpanzees in part because of this decreased upper canine size, as larger upper canines can be honed through wear against teeth in the lower mouth. The features of the upper canine in "A. ramidus" contrast with the sexual dimorphism observed in common chimpanzees, where males have significantly larger and sharper upper canine teeth than females.

The less pronounced nature of the upper canine teeth in "A. ramidus" has been used to infer aspects of the social behavior of the species and more ancestral hominids. In particular, it has been used to suggest that the last common ancestor of hominids and African apes was characterized by relatively little aggression between males and between groups. This is markedly different from social patterns in common chimpanzees, among which intermale and intergroup aggression are typically high. Researchers in a 2009 study said that this condition "compromises the living chimpanzee as a behavioral model for the ancestral hominid condition."

"A. ramidus" existed more recently than the most recent common ancestor of humans and chimpanzees (CLCA or "Pan"-"Homo" LCA) and thus is not fully representative of that common ancestor. Nevertheless, it is in some ways unlike chimpanzees, suggesting that the common ancestor differs from the modern chimpanzee. After the chimpanzee and human lineages diverged, both underwent substantial evolutionary change. Chimp feet are specialized for grasping trees; "A. ramidus" feet are better suited for walking. The canine teeth of "A. ramidus" are smaller, and equal in size between males and females, which suggests reduced male-to-male conflict, increased pair-bonding, and increased parental investment. "Thus, fundamental reproductive and social behavioral changes probably occurred in hominids long before they had enlarged brains and began to use stone tools," the research team concluded.

On October 1, 2009, paleontologists formally announced the discovery of the relatively complete "A. ramidus" fossil skeleton first unearthed in 1994. The fossil is the remains of a small-brained 50-kilogram (110 lb) female, nicknamed "Ardi", and includes most of the skull and teeth, as well as the pelvis, hands, and feet. It was discovered in Ethiopia's harsh Afar desert at a site called Aramis in the Middle Awash region. Radiometric dating of the layers of volcanic ash encasing the deposits suggest that Ardi lived about 4.3-4.5 million years ago. This date, however, has been questioned by others. Fleagle and Kappelman suggest that the region in which Ardi was found is difficult to date radiometrically, and they argue that Ardi should be dated at 3.9 million years.<ref name="10.1038/nature09709"></ref>

The fossil is regarded by its describers as shedding light on a stage of human evolution about which little was known, more than a million years before Lucy ("Australopithecus afarensis"), the iconic early human ancestor candidate who lived 3.2 million years ago, and was discovered in 1974 just away from Ardi's discovery site. However, because the "Ardi" skeleton is no more than 200,000 years older than the earliest fossils of "Australopithecus", and may in fact be younger than they are, some researchers doubt that it can represent a direct ancestor of "Australopithecus".

Some researchers infer from the form of her pelvis and limbs and the presence of her abductable hallux, that "Ardi" was a facultative biped: bipedal when moving on the ground, but quadrupedal when moving about in tree branches. "A. ramidus" had a more primitive walking ability than later hominids, and could not walk or run for long distances. The teeth suggest omnivory, and are more generalised than those of modern apes.

"Ardipithecus kadabba" is "known only from teeth and bits and pieces of skeletal bones", and is dated to approximately 5.6 million years ago. It has been described as a "probable chronospecies" (i.e. ancestor) of "A. ramidus". Although originally considered a subspecies of "A. ramidus", in 2004 anthropologists Yohannes Haile-Selassie, Gen Suwa, and Tim D. White published an article elevating "A. kadabba" to species level on the basis of newly discovered teeth from Ethiopia. These teeth show "primitive morphology and wear pattern" which demonstrate that "A. kadabba" is a distinct species from "A. ramidus".

The specific name comes from the Afar word for "basal family ancestor".

The toe and pelvic structure of "A. ramidus" suggest to some researchers that the organism walked erect.

According to Scott Simpson, the Gona Project's physical anthropologist, the fossil evidence from the Middle Awash indicates that both "A. kadabba" and "A. ramidus" lived in "a mosaic of woodland and grasslands with lakes, swamps and springs nearby," but further research is needed to determine which habitat "Ardipithecus" at Gona preferred.

Due to several shared characteristics with chimpanzees, its closeness to ape divergence period, and due to its fossil incompleteness, the exact position of "Ardipithecus" in the fossil record is a subject of controversy. Independent researcher such as Esteban E. Sarmiento of the Human Evolution Foundation in New Jersey, had systematically compared in 2010 the identifying characteristics of apes and human ancestral fossils in relation to "Ardipithecus", and concluded that the comparison data is not sufficient to support an exclusive human lineage. Sarmiento noted that "Ardipithecus" does not share any characteristics exclusive to humans and some of its characteristics (those in the wrist and basicranium) suggest it diverged from the common human/African ape stock prior to the human, chimpanzee and gorilla divergence. His comparative (narrow allometry) study in 2011 on the molar and body segment lengths (which included living primates of similar body size) noted that some dimensions including short upper limbs, and metacarpals are reminiscent of humans, but other dimensions such as long toes and relative molar surface area are great ape-like. Sarmiento concluded that such length measures can change back and forth during evolution and are not very good indicators of relatedness. The "Ardipithecus" length measures, however, are good indicators of function and together with dental isotope data and the fauna and flora from the fossil site indicate "Ardipithecus" was mainly a terrestrial quadruped collecting a large portion of its food on the ground. Its arboreal behaviors would have been limited and suspension from branches solely from the upper limbs rare.

However, some later studies still argue for its classification in the human lineage. A comparative study in 2013 on carbon and oxygen stable isotopes within modern and fossil tooth enamel revealed that "Ardipithecus" fed both arboreally (on trees) and on the ground in a more open habitat, unlike chimpanzees and extinct ape "Sivapithecus", thereby differentiating them from other apes. In 2014 it was reported that the hand bones of "Ardipithecus", "Australopithecus sediba" and "A. afarensis" consist of distinct human-lineage feature (which is the presence of third metacarpal styloid process, that is absent in other ape lineages). Unique brain organisations (such as lateral shift of the carotid foramina, mediolateral abbreviation of the lateral tympanic, and a shortened, trapezoidal basioccipital element) in "Ardipithecus" are also found only in the "Australopithecus" and "Homo" clade. Comparison of the tooth root morphology with those of "Sahelanthropus tchadensis" also indicated strong resemblance, implying its correct inclusion in human lineage.

In a study that assumes the hominin status of "Ardipithecus ramidus", it has been argued the species represents a heterochronic alteration of the more general great ape body plan. In this study the resemblance of the species' craniofacial morphology with that of subadult chimpanzees is attributed to dissociation of craniofacial growth from brain growth and associated life history trajectories such as eruption of the first molar and age of first birth. Consequently, it is argued the species represents a unique ontogeny unlike any extant ape. The reduced growth in the sub-nasal alveolar region of the face, which houses the projecting canine complex in chimpanzees, suggests the species had rates of growth and reproductive biology unlike any living primate species. In this sense the species may show the first trend towards human social, parenting and sexual psychology. Consequently, the authors argue it is no longer tenable to extrapolate from chimpanzees in reconstructions of early hominin social and mating behaviour, providing further evidence against the so-called 'chimpanzee referential model'. As the authors write when discussing the species unusual pattern of cranio-dental growth and the light it may throw on the origins of human sociality:

'The contrast [of humans] with chimpanzees is instructive, for when humans start developing broader social bonds after the permanent dentition begins erupting, at the same developmental milestone, chimpanzee facial projection increases. In other words, humans seem to have replaced craniofacial growth with an extended and intensified period of socio-emotional development. As "A. ramidus" no longer has an ontogeny that results in the development of a prognathic jaw with a C/P3 complex (which is one of the most important means by which males vie for status within the mating hierarchies of other primate species), young and sub-adult members of the species must have pursued other avenues by which to become reproductively successful members of the social group. The implication of these interspecific differences is that "A. ramidus" would have most likely had a period of infant and juvenile socialisation different from that of chimpanzees. Consequently, it is possible that in "A.ramidus" we see the first, albeit incipient trend toward human forms of child socialisation and social organisation'.

This view has yet to be corroborated by more detailed studies of the ontogeny of "A.ramidus". The study also provides support for Stephen Jay Gould's theory in "Ontogeny and Phylogeny" that the paedomorphic form of early hominin craniofacial morphology results from heterochronic dissociation of growth trajectories.

A study published in "Homo: Journal of Comparative Human Biology" in 2017 claims that "A.ramidus" possessed an ontogeny and idiosyncratic skull morphology more conducive to the production of modulated vocalisations than any other species of extant great ape. This paper argued that erect posture, significant cervical lordosis, reduced facial projection as well as "flexed" cranial base architecture indicate this species possessed greater facility to modulate vocalisations than both chimpanzees and bonobos. This is a controversial finding as it pushes language origins back some 4.5Ma into the late Miocene and early Pliocene suggesting that human vocal capability may have much deeper roots in the hominin lineage than traditionally supposed. In integrating data on anatomical correlates of primate mating and social systems with studies of skull and vocal tract architecture that facilitate speech production, the authors argue that paleoanthropologists to date have failed to grasp the important relationship between early hominin social evolution and language capacity. As they write:

While the skull of "A.ramidus", according to the authors, lacks the anatomical impediments to speech evident in chimpanzees, it is unclear what the vocal capabilities of this early hominin were. While they suggest "A.ramidus" - based on similar vocal tract ratios - may have had vocal capabilities equivalent to a modern human infant or very young child, they concede this is obviously a debatable and speculative hypothesis. However, they do claim that changes in skull architecture through processes of social selection were a necessary prerequisite for language evolution. As they write:




</doc>
<doc id="1146" url="https://en.wikipedia.org/wiki?curid=1146" title="Assembly line">
Assembly line

An assembly line is a manufacturing process (often called a "progressive assembly") in which parts (usually interchangeable parts) are added as the semi-finished assembly moves from workstation to workstation where the parts are added in sequence until the final assembly is produced. By mechanically moving the parts to the assembly work and moving the semi-finished assembly from work station to work station, a finished product can be assembled faster and with less labor than by having workers carry parts to a stationary piece for assembly.

Assembly lines are common methods of assembling complex items such as automobiles and other transportation equipment, household appliances and electronic goods.

Assembly lines are designed for the sequential organization of workers, tools or machines, and parts. The motion of workers is minimized to the extent possible. All parts or assemblies are handled either by conveyors or motorized vehicles such as fork lifts, or gravity, with no manual trucking. Heavy lifting is done by machines such as overhead cranes or fork lifts. Each worker typically performs one simple operation.

According to Henry Ford:

Consider the assembly of a car: assume that certain steps in the assembly line are to install the engine, install the hood, and install the wheels (in that order, with arbitrary interstitial steps); only one of these steps can be done at a time. In traditional production, only one car would be assembled at a time. If engine installation takes 20 minutes, hood installation takes five minutes, and wheels installation takes 10 minutes, then a car can be produced every 35 minutes.

In an assembly line, car assembly is split between several stations, all working simultaneously. When one station is finished with a car, it passes it on to the next. By having three stations, a total of three different cars can be operated on at the same time, each one at a different stage of its assembly.

After finishing its work on the first car, the engine installation crew can begin working on the second car. While the engine installation crew works on the second car, the first car can be moved to the hood station and fitted with a hood, then to the wheels station and be fitted with wheels. After the engine has been installed on the second car, the second car moves to the hood assembly. At the same time, the third car moves to the engine assembly. When the third car's engine has been mounted, it then can be moved to the hood station; meanwhile, subsequent cars (if any) can be moved to the engine installation station.

Assuming no loss of time when moving a car from one station to another, the longest stage on the assembly line determines the throughput (20 minutes for the engine installation) so a car can be produced every 20 minutes, once the first car taking 35 minutes has been produced.

Before the Industrial Revolution, most manufactured products were made individually by hand. A single craftsman or team of craftsmen would create each part of a product. They would use their skills and tools such as files and knives to create the individual parts. They would then assemble them into the final product, making cut-and-try changes in the parts until they fit and could work together (craft production).

Division of labor was practiced in China where state run monopolies mass-produced metal agricultural implements, china, armor, and weapons centuries before it appeared in Europe on the eve of the Industrial Revolution. Adam Smith discussed the division of labour in the manufacture of pins at length in his book "The Wealth of Nations" (published in 1776).

The Venetian Arsenal, dating to about 1104, operated similar to a production line. Ships moved down a canal and were fitted by the various shops they passed. At the peak of its efficiency in the early 16th century, the Arsenal employed some 16,000 people who could apparently produce nearly one ship each day, and could fit out, arm, and provision a newly built galley with standardized parts on an assembly-line basis. Although the Arsenal lasted until the early Industrial Revolution, production line methods did not become common even then.

The Industrial Revolution led to a proliferation of manufacturing and invention. Many industries, notably textiles, firearms, clocks and watches, horse-drawn vehicles, railway locomotives, sewing machines, and bicycles, saw expeditious improvement in materials handling, machining, and assembly during the 19th century, although modern concepts such as industrial engineering and logistics had not yet been named.

The automatic flour mill built by Oliver Evans in 1785 was called the beginning of modern bulk material handling by Roe (1916). Evans's mill used a leather belt bucket elevator, screw conveyors, canvas belt conveyors, and other mechanical devices to completely automate the process of making flour. The innovation spread to other mills and breweries.

Probably the earliest industrial example of a linear and continuous assembly process is the Portsmouth Block Mills, built between 1801 and 1803. Marc Isambard Brunel (father of Isambard Kingdom Brunel), with the help of Henry Maudslay and others, designed 22 types of machine tools to make the parts for the rigging blocks used by the Royal Navy. This factory was so successful that it remained in use until the 1960s, with the workshop still visible at HM Dockyard in Portsmouth, and still containing some of the original machinery.

One of the earliest examples of an almost modern factory layout, designed for easy material handling, was the Bridgewater Foundry. The factory grounds were bordered by the Bridgewater Canal and the Liverpool and Manchester Railway. The buildings were arranged in a line with a railway for carrying the work going through the buildings. Cranes were used for lifting the heavy work, which sometimes weighed in the tens of tons. The work passed sequentially through to erection of framework and final assembly.

The first flow assembly line was initiated at the factory of Richard Garrett & Sons, Leiston Works in Leiston in the English county of Suffolk for the manufacture of portable steam engines. The assembly line area was called 'The Long Shop' on account of its length and was fully operational by early 1853. The boiler was brought up from the foundry and put at the start of the line, and as it progressed through the building it would stop at various stages where new parts would be added. From the upper level, where other parts were made, the lighter parts would be lowered over a balcony and then fixed onto the machine on the ground level. When the machine reached the end of the shop, it would be completed.

During the early 19th century, the development of machine tools such as the screw-cutting lathe, metal planer, and milling machine, and of toolpath control via jigs and fixtures, provided the prerequisites for the modern assembly line by making interchangeable parts a practical reality.

Steam powered conveyor lifts began being used for loading and unloading ships some time in the last quarter of the 19th century. Hounshell (1984) shows a sketch of an electric powered conveyor moving cans through a filling line in a canning factory.

The meatpacking industry of Chicago is believed to be one of the first industrial assembly lines (or dis-assembly lines) to be utilized in the United States starting in 1867. Workers would stand at fixed stations and a pulley system would bring the meat to each worker and they would complete one task. Henry Ford and others have written about the influence of this slaughterhouse practice on the later developments at Ford Motor Company.

According to Domm, the implementation of mass production of an automobile via an assembly line may be credited to Ransom Olds, who used it to build the first mass-produced automobile, the Oldsmobile Curved Dash. Olds patented the assembly line concept, which he put to work in his Olds Motor Vehicle Company factory in 1901.

At Ford Motor Company, the assembly line was introduced by William "Pa" Klann upon his return from visiting Swift & Company's slaughterhouse in Chicago and viewing what was referred to as the "disassembly line", where carcasses were butchered as they moved along a conveyor. The efficiency of one person removing the same piece over and over without himself moving caught his attention. He reported the idea to Peter E. Martin, soon to be head of Ford production, who was doubtful at the time but encouraged him to proceed. Others at Ford have claimed to have put the idea forth to Henry Ford, but Pa Klann's slaughterhouse revelation is well documented in the archives at the Henry Ford Museum and elsewhere, making him an important contributor to the modern automated assembly line concept. Ford was appreciative, having visited the highly automated 40-acre Sears mail order handling facility around 1906. At Ford, the process was an evolution by trial and error of a team consisting primarily of Peter E. Martin, the factory superintendent; Charles E. Sorensen, Martin's assistant; Clarence W. Avery; C. Harold Wills, draftsman and toolmaker; Charles Ebender; and József Galamb. Some of the groundwork for such development had recently been laid by the intelligent layout of machine tool placement that Walter Flanders had been doing at Ford up to 1908.

The moving assembly line was developed for the Ford Model T and began operation on October 7, 1913, at the Highland Park Ford Plant, and continued to evolve after that, using time and motion study. The assembly line, driven by conveyor belts, reduced production time for a Model T to just 93 minutes by dividing the process into 45 steps. Producing cars quicker than paint of the day could dry, it had an immense influence on the world.

In 1922, Ford (through his ghostwriter Crowther) said of his 1913 assembly line:

Charles E. Sorensen, in his 1956 memoir "My Forty Years with Ford", presented a different version of development that was not so much about individual "inventors" as a gradual, logical development of industrial engineering:

As a result of these developments in method, Ford's cars came off the line in three-minute intervals, or six feet per minute. This was much faster than previous methods, increasing production by eight to one (requiring 12.5 man-hours before, 1 hour 33 minutes after), while using less manpower. It was so successful, paint became a bottleneck. Only japan black would dry fast enough, forcing the company to drop the variety of colors available before 1914, until fast-drying Duco lacquer was developed in 1926.

The assembly line technique was an integral part of the diffusion of the automobile into American society. Decreased costs of production allowed the cost of the Model T to fall within the budget of the American middle class. In 1908, the price of a Model T was around $825, and by 1912 it had decreased to around $575. This price reduction is comparable to a reduction from $15,000 to $10,000 in dollar terms from the year 2000. In 1914, an assembly line worker could buy a Model T with four months' pay.

Ford's complex safety procedures—especially assigning each worker to a specific location instead of allowing them to roam about—dramatically reduced the rate of injury. The combination of high wages and high efficiency is called "Fordism", and was copied by most major industries. The efficiency gains from the assembly line also coincided with the take-off of the United States. The assembly line forced workers to work at a certain pace with very repetitive motions which led to more output per worker while other countries were using less productive methods.

In the automotive industry, its success was dominating, and quickly spread worldwide. Ford France and Ford Britain in 1911, Ford Denmark 1923, Ford Germany and Ford Japan 1925; in 1919, Vulcan (Southport, Lancashire) was the first native European manufacturer to adopt it. Soon, companies had to have assembly lines, or risk going broke by not being able to compete; by 1930, 250 companies which did not had disappeared.

The massive demand for military hardware in World War II prompted assembly-line techniques in shipbuilding and aircraft production. Thousands of Liberty Ships were built making extensive use of prefabrication, enabling ship assembly to be completed in weeks or even days. After having produced fewer than 3,000 planes for the United States Military in 1939, American aircraft manufacturers built over 300,000 planes in World War II. Vultee pioneered the use of the powered assembly line for aircraft manufacturing. Other companies quickly followed. As William S. Knudsen (having worked at Ford, GM and the National Defense Advisory Commission) observed, "We won because we smothered the enemy in an avalanche of production, the like of which he had never seen, nor dreamed possible."

In his 1922 autobiography, Henry Ford mentions several benefits of the assembly line including:

The gains in productivity allowed Ford to increase worker pay from $1.50 per day to $5.00 per day once employees reached three years of service on the assembly line. Ford continued on to reduce the hourly work week while continuously lowering the Model T price. These goals appear altruistic; however, it has been argued that they were implemented by Ford in order to reduce high employee turnover: when the assembly line was introduced in 1913, it was discovered that "every time the company wanted to add 100 men to its factory personnel, it was necessary to hire 963" in order to counteract the natural distaste the assembly line seems to have inspired.

Sociological work has explored the social alienation and boredom that many workers feel because of the repetition of doing the same specialized task all day long.

One of capitalism's most famous critics, Karl Marx, expressed in his "Entfremdung" theory the belief that in order to achieve job satisfaction workers need to see themselves in the objects they have created, that products should be "mirrors in which workers see their reflected essential nature." Marx viewed labour as a chance for us to externalize facets of our personality. Marxists argue that specialization makes it very difficult for any worker to feel they may be contributing to the real needs of humanity. The repetitive nature of specialized tasks causes, they say, a feeling of disconnection between what a worker does all day, who they really are, and what they would ideally be able to contribute to society. Marx also argued that specialised jobs are insecure, since the worker is expendable as soon as costs rise and technology can replace more expensive human labour.

Since workers have to stand in the same place for hours and repeat the same motion hundreds of times per day repetitive stress injuries are a possible pathology of occupational safety. Industrial noise also proved dangerous. When it was not too high, workers were often prohibited from talking. Charles Piaget, a skilled worker at the LIP factory, recalled that beside being prohibited from speaking, the semi-skilled workers had only 25 centimeters in which to move. Industrial ergonomics later tried to minimize physical trauma.





</doc>
<doc id="1148" url="https://en.wikipedia.org/wiki?curid=1148" title="Adelaide">
Adelaide

Adelaide ( ) is the capital city of the state of South Australia, and the fifth-most populous city of Australia. Adelaide is home to 77 percent of the South Australian population, making it the most centralised population of any state in Australia.

Adelaide is north of the Fleurieu Peninsula, on the Adelaide Plains between the Gulf St Vincent in the west and the low-lying Mount Lofty Ranges in the east. Adelaide stretches from the coast to the foothills, and from Gawler at its northern extent to Sellicks Beach in the south.

Named in honour of Adelaide of Saxe-Meiningen, queen consort to King William IV, the city was founded in 1836 as the planned capital for a freely-settled British province in Australia. Colonel William Light, one of Adelaide's founding fathers, designed the city centre and chose its location close to the River Torrens, in the area originally inhabited by the Kaurna people and known as "Tarntanya" or "Tarndanyangga" ("place of the red kangaroo"). Light's design set out the city centre in a grid layout, interspaced by wide boulevards and large public squares, and entirely surrounded by parklands.

Early colonial Adelaide was shaped by prosperity and wealth, and was one of the few Australian cities without a convict history. Until the post-war era, it was Australia's third-largest city. It has been noted for early examples of religious freedom, a commitment to political progressivism and civil liberties. It has been known as the "City of Churches" since the mid-19th century, referring to its diversity of faiths. As South Australia's government and commercial centre, Adelaide is the site of many governmental and financial institutions. Most of these are concentrated in the city centre along the cultural boulevard of North Terrace, King William Street and in various districts of the metropolitan area.

Adelaide is noted for and sporting events, its food and wine, its long beachfronts, and its large defence and manufacturing sectors. Its quality of life has ranked highly in various measures through the 2010s. The demonym "Adelaidean" is used in reference to the city and its residents.

Before its proclamation as a British settlement in 1836, the area around Adelaide was inhabited by the indigenous Kaurna people, one of many Aboriginal nations in South Australia. The city and parklands area was known as Tarntanya, or Tarndanyangga in the Kaurna language. The surrounding area was an open grassy plain with patches of trees and shrub which had been managed by hundreds of generations. Kaurna country encompassed the plains which stretched north and south of Tarntanya as well as the wooded foothills of the Mt Lofty Ranges. The River Torrens was known as the Karrawirra Pari (red gum forest river). About 300 Kaurna populated the Adelaide area, and were referred to by the settlers as the Cowandilla.

The Kaurna language was a complex one, reflecting their sophisticated culture and deep environmental knowledge. Within a few decades of European settlement of South Australia, Kaurna culture and language were almost completely destroyed. Extensive documentation by early missionaries and other researchers has enabled a modern revival of both, which has included a commitment by local and state governments to rename or include Kaurna names for many local places.

South Australia was officially proclaimed a British colony on 28 December 1836, near The Old Gum Tree in what is now the suburb of Glenelg North. The event is commemorated in South Australia as Proclamation Day. The site of the colony's capital was surveyed and laid out by Colonel William Light, the first Surveyor-General of South Australia, through the design made by the architect George Strickland Kingston. The city was named after Adelaide of Saxe-Meiningen, queen consort to King William IV at the time.

Adelaide was established as a planned colony of free immigrants, promising civil liberties and freedom from religious persecution, based upon the ideas of Edward Gibbon Wakefield. Wakefield had read accounts of Australian settlement while in prison in London for attempting to abduct an heiress, and realised that the eastern colonies suffered from a lack of available labour, due to the practice of giving land grants to all arrivals. Wakefield's idea was for the Government to survey and sell the land at a rate that would maintain land values high enough to be unaffordable for labourers and journeymen. Funds raised from the sale of land were to be used to bring out working-class emigrants, who would have to work hard for the monied settlers to ever afford their own land. As a result of this policy, Adelaide does not share the convict settlement history of other Australian cities like Sydney, Brisbane and Hobart.

As it was believed that in a colony of free settlers there would be little crime, no provision was made for a gaol in Colonel Light's 1837 plan. But by mid-1837 the "South Australian Register" was warning of escaped convicts from New South Wales and tenders for a temporary gaol were sought. Following a burglary, a murder, and two attempted murders in Adelaide during March 1838, Governor Hindmarsh created the South Australian Police Force (now the South Australia Police) in April 1838 under 21-year-old Henry Inman. The first sheriff, Samuel Smart, was wounded during a robbery, and on 2 May 1838 one of the offenders, Michael Magee, became the first person to be hanged in South Australia. William Baker Ashton was appointed governor of the temporary gaol in 1839, and in 1840 George Strickland Kingston was commissioned to design Adelaide's new gaol. Construction of Adelaide Gaol commenced in 1841.

Adelaide's early history was marked by economic uncertainty and questionable leadership. The first governor of South Australia, John Hindmarsh, clashed frequently with others, in particular the Resident Commissioner, James Hurtle Fisher. The rural area surrounding Adelaide was surveyed by Light in preparation to sell a total of over of land. Adelaide's early economy started to get on its feet in 1838 with the arrival of livestock from Victoria, New South Wales and Tasmania. Wool production provided an early basis for the South Australian economy. By 1860, wheat farms had been established from Encounter Bay in the south to Clare in the north.

George Gawler took over from Hindmarsh in late 1838 and, despite being under orders from the "Select Committee on South Australia" in Britain not to undertake any public works, promptly oversaw construction of a governor's house, the Adelaide Gaol, police barracks, a hospital, a customs house and a wharf at Port Adelaide. Gawler was recalled and replaced by George Edward Grey in 1841. Grey slashed public expenditure against heavy opposition, although its impact was negligible at this point: silver was discovered in Glen Osmond that year, agriculture was well underway, and other mines sprung up all over the state, aiding Adelaide's commercial development. The city exported meat, wool, wine, fruit and wheat by the time Grey left in 1845, contrasting with a low point in 1842 when one-third of Adelaide houses were abandoned.

Trade links with the rest of the Australian states were established after the Murray River was successfully navigated in 1853 by Francis Cadell, an Adelaide resident. South Australia became a self-governing colony in 1856 with the ratification of a new constitution by the British parliament. Secret ballots were introduced, and a bicameral parliament was elected on 9 March 1857, by which time 109,917 people lived in the province.

In 1860 the Thorndon Park reservoir was opened, finally providing an alternative water source to the now turbid River Torrens. Gas street lighting was implemented in 1867, the University of Adelaide was founded in 1874, the South Australian Art Gallery opened in 1881 and the Happy Valley Reservoir opened in 1896. In the 1890s Australia was affected by a severe economic depression, ending a hectic era of land booms and tumultuous expansionism. Financial institutions in Melbourne and banks in Sydney closed. The national fertility rate fell and immigration was reduced to a trickle. The value of South Australia's exports nearly halved. Drought and poor harvests from 1884 compounded the problems, with some families leaving for Western Australia. Adelaide was not as badly hit as the larger gold-rush cities of Sydney and Melbourne, and silver and lead discoveries at Broken Hill provided some relief. Only one year of deficit was recorded, but the price paid was retrenchments and lean public spending. Wine and copper were the only industries not to suffer a downturn.

Adelaide was Australia's third largest city for most of the 20th century. Electric street lighting was introduced in 1900 and electric trams were transporting passengers in 1909. 28,000 men were sent to fight in World War I. Historian F. W. Crowley examined the reports of visitors in the early 20th century, noting that "many visitors to Adelaide admired the foresighted planning of its founders", as well as pondering the riches of the young city. Adelaide enjoyed a postwar boom, entering a time of relative prosperity. Its population grew, and it became the third most populous metropolitan area in the country, after Sydney and Melbourne. Its prosperity was short-lived, with the return of droughts and the Great Depression of the 1930s. It later returned to fortune under strong government leadership.Secondary industries helped reduce the state's dependence on primary industries. World War II brought industrial stimulus and diversification to Adelaide under the Playford Government, which advocated Adelaide as a safe place for manufacturing due to its less vulnerable location. Shipbuilding was expanded at the nearby port of Whyalla.

The South Australian Government in this period built on former wartime manufacturing industries but neglected cultural facilities which meant South Australia's economy lagged behind. International manufacturers like General Motors Holden and Chrysler made use of these factories around the Adelaide area in suburbs like Elizabeth, completing its transformation from an agricultural service centre to a 20th-century city. The Mannum–Adelaide pipeline brought River Murray water to Adelaide in 1955 and an airport opened at West Beach in 1955. Flinders University and the Flinders Medical Centre were established in the 1960s at Bedford Park, south of the city. Today, Flinders Medical Centre is one of the largest teaching hospitals in South Australia. In the post-war years around the early 1960s Adelaide was surpassed by Brisbane as Australia's third largest city.

The Dunstan Governments of the 1970s saw something of an Adelaide 'cultural revival', establishing a wide array of social reforms. The city became noted for its progressivism as South Australia became the first Australian state or territory to decriminalise homosexuality between consenting adults in 1975. It also became a centre for the arts, building upon the biennial "Adelaide Festival of Arts" that commenced in 1960. Adelaide hosted the Formula One Australian Grand Prix between 1985 and 1996 on a street circuit in the city's east parklands; it moved to Melbourne in 1996. The State Bank collapsed in 1991 during an economic recession; the effects lasted until 2004, when Standard & Poor's reinstated South Australia's AAA credit rating. Since 1999, the Adelaide 500 Supercars race has made use of sections of the former Formula One circuit. Adelaide's tallest building, built in 1988, was originally known as the State Bank Building. In 1991 it was renamed the Santos Building and in 2006 it was renamed Westpac House, and it is currently the 160th tallest building in Australia.

In the early years of the 21st century, a significant increase in the state government's spending on Adelaide's infrastructure occurred. The Rann government invested A$535 million in a major upgrade of the Adelaide Oval to enable Australian Football League to be played in the city centre and more than A$2 billion to build a new Royal Adelaide Hospital on land adjacent to the Adelaide Railway Station. The Glenelg tramline was extended through the city to Hindmarsh and the suburban railway line extended south to Seaford.

Following a period of stagnation in the 1990s and 2000s, Adelaide began several major developments and redevelopments. The Adelaide Convention Centre was redeveloped and expanded at a cost of A$350 million beginning in 2012. Three historic buildings were adapted for modern use: the Torrens Building in Victoria Square as the Adelaide campus for Carnegie Mellon University, University College London, and Torrens University; the Stock Exchange building as the Science Exchange of the Royal Institution Australia; and the Glenside Psychiatric Hospital as the Adelaide Studios of the SA Film Corporation. The government also invested more than A$2 billion to build a desalination plant, powered by renewable energy, as an 'insurance policy' against droughts affecting Adelaide's water supply. The Adelaide Festival, Fringe, and Womadelaide became annual events.
Adelaide is north of the Fleurieu Peninsula, on the Adelaide Plains between the Gulf St Vincent and the low-lying Mount Lofty Ranges. The city stretches from the coast to the foothills, and from Gawler at its northern extent to Sellicks Beach in the south. According to the Regional Development Australia, an Australian government planning initiative, the "Adelaide Metropolitan Region" has a total land area of , while a more expansive definition by the Australian Bureau of Statistics defines a "Greater Adelaide" statistical area totalling . The city sits at an average elevation of above sea level. Mount Lofty, east of the Adelaide metropolitan region in the Adelaide Hills at an elevation of , is the tallest point of the city and in the state south of Burra.
Much of Adelaide was bushland before British settlement, with some variation – sandhills, swamps and marshlands were prevalent around the coast. The loss of the sandhills to urban development had a particularly destructive effect on the coastline due to erosion. Where practical, the government has implemented programs to rebuild and vegetate sandhills at several of Adelaide's beachside suburbs. Much of the original vegetation has been cleared with what is left to be found in reserves such as the Cleland Conservation Park and Belair National Park. A number of creeks and rivers flow through the Adelaide region. The largest are the Torrens and Onkaparinga catchments. Adelaide relies on its many reservoirs for water supply with the Happy Valley Reservoir supplying around 40% and the much larger Mount Bold Reservoir 10% of Adelaide's domestic requirements respectively.

Adelaide and its surrounding area is one of the most seismically active regions in Australia. On 1 March 1954 at 3:40 am Adelaide experienced its largest recorded earthquake to date, with the epicentre 12 km from the city centre at Darlington, and a reported magnitude of 5.6. There have been smaller earthquakes in 2010, 2011, 2014 and 2017.

Adelaide is a planned city, designed by the first Surveyor-General of South Australia, Colonel William Light. His plan, now known as Light's Vision, arranged Adelaide in a grid, with in the Adelaide city centre and a ring of parks, known as the Adelaide Parklands, surrounding it. Light's selection of the location for the city was initially unpopular with the early settlers, as well as South Australia's first governor, John Hindmarsh, due to its distance from the harbour at Port Adelaide, and the lack of fresh water there. Light successfully persisted with his choice of location against this initial opposition.

The benefits of Light's design are numerous: Adelaide has had wide multi-lane roads from its beginning, an easily navigable cardinal direction grid layout and an expansive green ring around the city centre. There are two sets of ring roads in Adelaide that have resulted from the original design. The inner ring route (A21) borders the parklands, and the outer route (A3/A13/A16/A17) completely bypasses the inner city via (in clockwise order) Grand Junction Road, Hampstead Road, Ascot Avenue, Portrush Road, Cross Road and South Road.

Suburban expansion has to some extent outgrown Light's original plan. Numerous former outlying villages and "country towns", as well as the satellite city of Elizabeth, have been enveloped by its suburban sprawl. Expanding developments in the Adelaide Hills region led to the construction of the South Eastern Freeway to cope with growth, which has subsequently led to new developments and further improvements to that transport corridor. Similarly, the booming development in Adelaide's South led to the construction of the Southern Expressway.

New roads are not the only transport infrastructure developed to cope with the urban growth. The O-Bahn Busway is an example of a unique solution to Tea Tree Gully's transport woes in the 1980s. The development of the nearby suburb of Golden Grove in the late 1980s is an example of well-thought-out urban planning.

In the 1960s, a Metropolitan Adelaide Transport Study Plan was proposed in order to cater for the future growth of the city. The plan involved the construction of freeways, expressways and the upgrade of certain aspects of the public transport system. The then premier Steele Hall approved many parts of the plan and the government went as far as purchasing land for the project. The later Labor government elected under Don Dunstan shelved the plan, but allowed the purchased land to remain vacant, should the future need for freeways arise. In 1980, the Liberal party won government and premier David Tonkin committed his government to selling off the land acquired for the MATS plan, ensuring that even when needs changed, the construction of most MATS-proposed freeways would be impractical. Some parts of this land have been used for transport, (e.g. the O-Bahn Busway and Southern Expressway), while most has been progressively subdivided for residential use.

In 2008, the SA Government announced plans for a network of transport-oriented developments across the Adelaide metropolitan area and purchased a 10 hectare industrial site at Bowden for $52.5 million as the first of these developments. The site covers 102,478 square metres, or about 10 hectares, and is bounded by Park Terrace to the south, the Adelaide to Outer Harbour railway line to the west, Drayton Street to the north and Sixth and Seventh Streets to the east.

Historically, Adelaide's suburban residential areas have been characterised by single-storey detached houses built on blocks. A relative lack of suitable, locally-available timber for construction purposes led to the early development of a brick-making industry, as well as the use of stone, for houses and other buildings. By 1891 68% of houses were built of stone, 15% of timber, and 10% of brick, with brick also being widely used in stone houses for quoins, door and window surrounds, and chimneys and fireplaces.

There is a wide variety in the styles of these predominately brick, and to a lesser degree, stone, and/or stone-faced, single-storey detached houses. After both of the World Wars, the use of red bricks was popular. In the 1960s, cream bricks became popular, and in the 1970s, deep red and brown bricks became popular. Until the 1970s, roofs tended to be clad with corrugated (iron) steel or clay tiles (usually red clay). Since then, cement tiles and Colorbond(R) corrugated (and other types of) steel have also become popular. Most roofs are pitched; flat roofs are not common. Up to the 1970s, the majority of houses were of "double brick" construction on concrete footings, with timber floors laid on joists supported by "dwarf walls". Due to Adelaide's reactive soils (particularly Keswick Clay, black earth and some red-brown earth soils), since then houses have mainly been constructed of "brick veneer" over a timber frame (and more recently, over a light steel frame) on a concrete slab foundation. The use of precast concrete panels for floor and wall construction has also increased. In addition to this, a significant factor in Adelaide's suburban history is the role of the South Australian Housing Trust.

Adelaide has a Hot-summer mediterranean climate (Köppen climate classification: "Csa") in Kent Town, and has a cold semi-arid climate (Köppen climate classification: "BSk") in Adelaide Airport. with warm to hot dry summers and cool to mild winters and with most precipitation falling in the winter months, leading to the suggestion that the climate be classified as a "cold monsoon". Adelaide receives enough annual precipitation to avoid Köppen's BSk (semi-arid climate) classification. Rainfall is unreliable, light and infrequent throughout summer. In contrast, the winter has fairly reliable rainfall with June being the wettest month of the year, averaging around 80 mm. Frosts are occasional, with the most notable occurrences in July 1908 and July 1982. Hail is also common in winter. Adelaide is a windy city with significant wind chill in winter, which makes the temperature seem colder than it actually is. Snowfall in the metropolitan area is extremely uncommon, although light and sporadic falls in the nearby hills and at Mount Lofty occur during winter. Dewpoints in the summer typically range from . There are usually two to three days in summer where the temperature reaches or above, although the frequency of these temperatures has been increasing in recent years.

The average sea temperature ranges from in August to in February.

Adelaide has been consistently listed in the world's top 10 most liveable cities through the 2010s by The Economist Intelligence Unit, although dropping to tenth place in 2018 after holding fifth position in the previous three years. It was ranked the most liveable city in Australia by the Property Council of Australia, based on surveys of residents’ views of their own city, between 2010 and 2013, dropping to second place in 2014.

Adelaide, as the capital of South Australia, is the seat of the Government of South Australia. As Adelaide is South Australia's capital and most populous city, the State Government co-operates extensively with the City of Adelaide. In 2006, the Ministry for the City of Adelaide was created to facilitate the State Government's collaboration with the Adelaide City Council and the Lord Mayor to improve Adelaide's image. The State Parliament's Capital City Committee is also involved in the governance of the City of Adelaide, being primarily concerned with the planning of Adelaide's urban development and growth.

Reflecting South Australia's status as Australia's most centralised state, Adelaide elects a substantial majority of the South Australian House of Assembly. Of the 47 seats in the chamber, 34 seats (three-quarters of the legislature) are based in Adelaide, and two rural seats include Adelaide suburbs.

The Adelaide metropolitan area is divided between nineteen local government areas. At its centre, the City of Adelaide administers the Adelaide city centre, North Adelaide, and the surrounding Adelaide Parklands. It is the oldest municipal authority in Australia and was established in 1840, when Adelaide and Australia's first mayor, James Hurtle Fisher, was elected. From 1919 onwards, the City has had a Lord Mayor, the current being Lord Mayor "The Right Honourable" Sandy Verschoor.

Adelaide's inhabitants are known as Adelaideans.

Compared with Australia's four other major state capitals, Adelaide is growing at a much slower rate. In 2017, it had a metropolitan population (including suburbs) of more than 1,333,927, making it Australia's fifth-largest city. Some 77% of the population of South Australia are residents of the Adelaide metropolitan area, making South Australia one of the most centralised states.

Major areas of population growth in recent years have been in outer suburbs such as Mawson Lakes and Golden Grove. Adelaide's inhabitants occupy 366,912 houses, 57,695 semi-detached, row terrace or town houses and 49,413 flats, units or apartments.

About one sixth (17.1%) of the population had university qualifications. The number of Adelaideans with vocational qualifications (such as tradespersons) fell from 62.1% of the labour force in the 1991 census to 52.4% in the 2001 census.

Adelaide is ageing more rapidly than other Australian capital cities. More than a quarter (27.5%) of Adelaide's population is aged 55 years or older, in comparison to the national average of 25.6%. Adelaide has the lowest number of children (under-15-year-olds), who comprised 17.7% of the population, compared to the national average of 19.3%.

At the 2016 census, the most commonly nominated ancestries were: 
Overseas-born Adelaideans composed 31.8% of the total population at the 2016 census. The five largest groups of overseas-born were from England (6.2%), India (2%), China (1.8%), Italy (1.3%) and Vietnam (1.1%).

Suburbs such as Para Hills, Salisbury, Ingle Farm and Blair Athol in the north and Findon, West Croydon and Seaton in the West are experiencing large migration from Afghanistan and Iran. Chinese migrants favour settling in the eastern and north eastern suburbs including Kensington Gardens, Greenacres, Modbury and Golden Grove. Mawson Lakes has a large international student population, due to its proximity to the University of South Australia campus.

1.4% of the population, or 18,403 people, identified as Indigenous Australians (Aboriginal Australians and Torres Strait Islanders) in 2016.

At the 2016 census, 75.4% of the population spoke English at home. The other languages most commonly spoken at home were Italian (2.1%), Standard Mandarin (2.1%), Greek (1.7%) Vietnamese (1.4%), and Cantonese (0.7%).

Adelaide was founded on a vision of religious tolerance that attracted a wide variety of religious practitioners. This led to it being known as "The City of Churches". But approximately 28% of the population expressed no religious affiliation in the 2011 Census, compared with the national average of 22.3%, making Adelaide one of Australia's least religious cities. Over half of the population of Adelaide identifies as Christian, with the largest denominations being Catholic (21.3%), Anglican (12.6%), Uniting Church (7.6%) and Eastern Orthodox (3.5%).

The Jewish community of the city dates back to 1840. Eight years later, 58 Jews lived in the city. A synagogue was built in 1871, when 435 Jews lived in the city. Many took part in the city councils, such as Judah Moss Solomon (1852–66) and others after him. Three Jews have been elected to the position of city mayor. In 1968, the Jewish population of Adelaide numbered about 1,200; in 2001, according to the Australian census, 979 persons declared themselves to be Jewish by religion. In 2011, over 1,000 Jews were living in the city, operating an orthodox and a reform school, in addition to a virtual Jewish museum.

The "Afghan" community in Australia first became established in the 1860s when camels and their Pathan, Punjabi, Baluchi and Sindhi handlers began to be used to open up settlement in the continent's arid interior. Until eventually superseded by the advent of the railways and motor vehicles, camels played an invaluable economic and social role in transporting heavy loads of goods to and from isolated settlements and mines. This is acknowledged by the name of The Ghan, the passenger train operating between Adelaide, Alice Springs, and Darwin. The Central Adelaide Mosque is regarded as Australia's oldest permanent mosque; an earlier mosque at Marree in northern South Australia, dating from 1861–62 and subsequently abandoned or demolished, has now been rebuilt.

South Australia's largest employment sectors are health care and social assistance, surpassing manufacturing in SA as the largest employer since 2006–07. In 2009–10, manufacturing in SA had average annual employment of 83,700 persons compared with 103,300 for health care and social assistance. Health care and social assistance represented nearly 13% of the state average annual employment. The Adelaide Hills wine region is an iconic and viable economic region for both the state and country in terms of wine production and sale. The 2014 vintage is reported as consisting of red grapes crushed valued at A$8,196,142 and white grapes crushed valued at $14,777,631.

The retail trade is the second largest employer in SA (2009–10), with 91,900 jobs, and 12 per cent of the state workforce.

Manufacturing, defence technology, high-tech electronic systems and research, commodity export and corresponding service industries all play a role in the SA economy. Almost half of all cars produced in Australia were made in Adelaide at the General Motors Holden plant in Elizabeth. The site ceased operating in November 2017.

The collapse of the State Bank in 1992 resulted in large levels of state public debt (as much as A$4 billion). The collapse meant that successive governments enacted lean budgets, cutting spending, which was a setback to the further economic development of the city and state. The debt has more recently been reduced with the State Government once again receiving a AAA+ Credit Rating.

The global media conglomerate News Corporation was founded in, and until 2004 incorporated in, Adelaide and it is still considered its 'spiritual' home by Rupert Murdoch. Australia's largest oil company, Santos, prominent South Australian brewery, Coopers, and national retailer Harris Scarfe also call Adelaide their home.

Adelaide is home to a large proportion of Australia's defence industries, which contribute over A$1 billion to South Australia's Gross State Product. The principal government military research institution, the Defence Science and Technology Organisation, and other defence technology organisations such as BAE Systems Australia and Lockheed Martin Australia, are north of Salisbury and west of Elizabeth in an area now called "Edinburgh Parks", adjacent to RAAF Base Edinburgh.

Others, such as Saab Systems and Raytheon, are in or near Technology Park. ASC Pty Ltd, based in the industrial suburb of Osborne. South Australia was charged with constructing Australia's "Collins" class submarines and more recently the A$6 billion contract to construct the Royal Australian Navy's new air-warfare destroyers.

, Greater Adelaide had an unemployment rate of 7.4% with a youth unemployment rate of 15%.

The median weekly individual income for people aged 15 years and over was $447 per week in 2006, compared with $466 nationally. The median family income was $1,137 per week, compared with $1,171 nationally. Adelaide's housing and living costs are substantially lower than that of other Australian cities, with housing being notably cheaper. The median Adelaide house price is half that of Sydney and two-thirds that of Melbourne. The three-month trend unemployment rate to March 2007 was 6.2%. The Northern suburbs' unemployment rate is disproportionately higher than the other regions of Adelaide at 8.3%, while the East and South are lower than the Adelaide average at 4.9% and 5.0% respectively.

Over the decade March 2001 – March 2010, Metropolitan Adelaide median house prices approximately tripled. (approx. 285% – approx. 11%p.a. compounding)
In the five years March 2007 – March 2012, prices increased by approx. 27% – approx. 5%p.a. compounding. March 2012 – March 2017 saw a further increase of 19% – approx. 3.5%p.a. compounding.

In summary:
Each quarter, The Alternative and Direct Investment Securities Association (ADISA) publishes a list of median house sale prices by suburb and Local Government Area. (Previously, this was done by REISA) Due to the small sizes of many of Adelaide's suburbs, the low volumes of sales in these suburbs, and (over time) the huge variations in the numbers of sales in a suburb in a quarter, statistical analysis of "the most expensive suburb" is unreliable; the suburbs appearing in the "top 10 most expensive suburbs this quarter" list is constantly varying. Quarterly Reports for the last two years can be found on the REISA website.

Education forms an increasingly important part of the city's economy, with the South Australian Government and educational institutions attempting to position Adelaide as "Australia's education hub" and marketing it as a "Learning City." The number of international students studying in Adelaide has increased rapidly in recent years to 30,726 in 2015, of which 1,824 were secondary school students. In addition to the city's existing institutions, foreign institutions have been attracted to set up campuses in order to increase its attractiveness as an education hub. Adelaide is the birthplace of three Nobel laureates, more than any other Australian city: physicist William Lawrence Bragg and pathologists Howard Florey and Robin Warren, all of whom completed secondary and tertiary education at St Peter's College and the University of Adelaide.

At the level of primary and secondary education, there are two systems of school education. There is a public system operated by the South Australian Government and a private system of independent and Catholic schools. All schools provide education under the South Australian Certificate of Education (SACE) or, to a lesser extent, the International Baccalaureate (IB), with Adelaide having the highest number of IB schools in Australia.

There are three public universities local to Adelaide, as well as one private university and three constituent colleges of foreign universities. Flinders University of South Australia, the University of Adelaide, the University of South Australia and Torrens University Australia—part of the Laureate International Universities are based in Adelaide. The University of Adelaide was ranked in the top 150 universities worldwide. Flinders ranked in the top 250 and Uni SA in the top 300. Torrens University Australia is part of an international network of over 70 higher education institutions in more than 30 countries worldwide. The historic Torrens Building in Victoria Square houses Carnegie Mellon University's Heinz College Australia, and University College London's School of Energy and Resources (Australia), and constitute the city's international university precinct.

The University of Adelaide, with 25,000 students, is Australia's third-oldest university and a member of the leading "Group of Eight". It has five campuses throughout the state, including two in the city-centre, and a campus in Singapore. The University of South Australia, with 37,000 students, has two North Terrace campuses, three other campuses in the metropolitan area and campuses at Whyalla and Mount Gambier. Flinders University, with 25,184 domestic and international students, is in the southern suburb of Bedford Park, alongside the Flinders Medical Centre, another campus in neighbouring Tonsley, and maintains a small city campus in Victoria Square. The plaza on the Bedford Park campus was revamped in 2014 and officially re-opened in 2016.

There are several South Australian TAFE (Technical and Further Education) campuses in the metropolitan area that provide a range of vocational education and training. The Adelaide College of the Arts, as a school of TAFE SA, provides nationally recognised training in visual and performing arts.

In addition to the universities, Adelaide is home to a number of research institutes, including the Royal Institution of Australia, established in 2009 as a counterpart to the two-hundred-year-old Royal Institution of Great Britain. Many of the organisations involved in research tend to be geographically clustered throughout the Adelaide metropolitan area:
While established as a British province, and very much English in terms of its culture, Adelaide attracted immigrants from other parts of Europe early on, including German and other European non-conformists escaping religious persecution. The first German Lutherans arrived in 1838 bringing with them the vine cuttings that they used to found the acclaimed wineries of the Barossa Valley.

Adelaide's arts scene flourished in the 1960s and 1970s with the support of successive premiers from both major political parties. The renowned Adelaide Festival of Arts and Fringe Festival were established in 1960 under Thomas Playford. Construction of the Adelaide Festival Centre began under Steele Hall in 1970 and was completed under the subsequent government of Don Dunstan, who also established the South Australian Film Corporation and, in 1976, the State Opera of South Australia.

Over time, the Adelaide Festival has expanded to include the Adelaide Cabaret Festival, Adelaide Film Festival, Adelaide Festival of Ideas, Adelaide Writers' Week, and WOMADelaide, all held predominantly in the autumnal month of March (sometimes jocularly called 'mad March' by locals due to the hectic clustering of these events). Other festivals include FEAST (a queer culture celebration), Tasting Australia (a biennial food and wine affair), and the Royal Adelaide Show (an annual agricultural show and state fair).

There are many international cultural fairs, most notably the German Schützenfest and Greek Glendi. Adelaide is home to the Adelaide Christmas Pageant, the world's largest Christmas parade. As the state capital, Adelaide is home to a great number of cultural institutions with many along the boulevard of North Terrace. The Art Gallery of South Australia, with around 35,000 works, holds Australia's second largest state-based collection. Adjacent are the South Australian Museum and State Library of South Australia, while the Adelaide Botanic Garden, National Wine Centre and Tandanya National Aboriginal Cultural Institute are nearby in the East End of the city. In the back of the State Library lies the Migration Museum, Australia's oldest museum of its kind. Contemporary art scenes include the Contemporary Art Centre of South Australia. Adelaide Festival Centre, on the banks of the Torrens, is the focal point for much of the cultural activity in the city and home to the State Theatre Company of South Australia, with other venues including the Adelaide Entertainment Centre and the city's many smaller theatres, pubs and cabaret bars.

The music of Adelaide has produced musical groups and individuals who have achieved national and international fame. This includes the Adelaide Symphony Orchestra, the Adelaide Youth Orchestra, rock bands The Angels, Cold Chisel, The Superjesus, Wolf & Cub, roots/blues group The Audreys, internationally acclaimed metal acts I Killed The Prom Queen and Double Dragon, popular Australian hip-hop outfit Hilltop Hoods, pop acts like Sia, Orianthi, Guy Sebastian, and Wes Carr, as well as internationally successful tribute act, The Australian Pink Floyd Show.

Noted rocker Jimmy Barnes spent most of his youth in the northern suburb of Elizabeth. Paul Kelly grew up in Adelaide and was head prefect at Rostrevor College. The first "Australian Idol" winner, Guy Sebastian, hails from the north-eastern suburb of Golden Grove. American musician Ben Folds used to base himself in Adelaide when he was married to Australian Frally Hynes. Folds recorded a song about Adelaide before he moved away. In addition to its own WOMADelaide, Adelaide attracts several touring music festivals, including Big Day Out, Creamfields, Future Music, Laneway, Parklife, Soundwave, Stereosonic and Summadayze

Adelaide plays host to two of Australia's leading contemporary dance companies. The Australian Dance Theatre and Leigh Warren & Dancers contribute to state festivals and perform nationally and internationally. Restless Dance Theatre is also based in Adelaide and is nationally recognised for working with disabled and non-disabled dancers to use movement as a means of expression.

Adelaide has been recognised as a "City of Music" by the UNESCO Creative Cities Network.

In 2014, Ghil'ad Zuckermann founded the Adelaide Language Festival.

Adelaide pop-concert venues (past and present) include Adelaide Entertainment Centre; Adelaide Festival Theatre; Adelaide Oval; Apollo Stadium; Memorial Drive Park; Thebarton Theatre. Other concert and live theatre venues include Adelaide Town Hall; Dunstan Playhouse; Hopgood Theatre; Her Majesty's Theatre.

Newspapers in Adelaide are dominated by News Corporation publications—Adelaide being the birthplace of News Corporation itself. The only South Australian daily newspaper is "The Advertiser", published by News Corporation six days a week. The same group publishes a Sunday paper, the "Sunday Mail".

There are eleven suburban community newspapers published weekly, known collectively as the "Messenger Newspapers", also published by a subsidiary of News Corporation. "The Independent Weekly" was a small independent newspaper providing an alternative view, but ceased publishing its print edition in November 2010 and now exists as a digital daily newsletter only. "The Adelaide Review" is a free paper published fortnightly, and other independent magazine-style papers are published, but are not as widely available.

Adelaide is served by numerous digital free-to-air television channels:


All of the five Australian national television networks broadcast both high-definition digital and standard-definition digital television services in Adelaide. They share three transmission towers on the ridge near the summit of Mount Lofty. There are two other transmission sites at 25 Grenfell Street, Adelaide and Elizabeth Downs. The two government-funded stations are run by the Australian Broadcasting Corporation (ABC South Australia) and the Special Broadcasting Service (SBS). The Seven Network and Network Ten both own their Adelaide stations (SAS-7 and ADS-10 respectively). Adelaide's NWS-9 is part of the Nine Network. Adelaide also has a community television station, Channel 44.

As part of a nationwide phase-out of analogue television in Australia, Adelaide's analogue television service was shut down on 2 April 2013.

The Foxtel pay TV service is also available via cable or satellite to the entire metropolitan area.

All the major broadcasting networks also operate online on-demand television services, alongside internet-only services such as Stan, Fetch TV, Netflix, YouTube, and Kayo Sports.

There are 20 radio stations that serve the metropolitan area, as well as four stations that serve only parts of the metropolitan area; six commercial stations, six community stations, six national stations and two narrowcast stations.

DAB+ digital radio has been broadcasting in metropolitan Adelaide since 20 May 2009, and currently includes a choice of 41 stations, all operated by the existing radio broadcasters, which includes simulcast of all AM and FM stations.

See List of radio stations in Adelaide.

The main sports played professionally in Adelaide are Australian Rules football, association football (soccer), cricket, netball, and basketball. Adelaide is the home of two Australian Football League teams: the Adelaide Football Club and Port Adelaide Football Club, and one A-League soccer team, Adelaide United. A local Australian rules football league, the SANFL, is made up of 10 teams from around Adelaide. The SANFL has been in operation since 1877 when it began as the South Australian Football Association (SAFL) before changing its name to the SANFL in 1927. The SANFL is the oldest surviving football league of any code played in Australia.
Adelaide has developed a strong culture of attracting crowds to major sporting events. Until the completion of the 2012–14 renovation and upgrade of the Adelaide Oval, most large sporting events took place at either AAMI Stadium (the then home base of the Adelaide Crows, and the then Port Adelaide's home game venue), or the historic Adelaide Oval, home of the Southern Redbacks and the Adelaide Strikers cricket teams. Since completion of the upgrade, home games for Adelaide Crows and Port Adelaide now take place at Adelaide Oval.

Since 1884, Adelaide Oval has also hosted an international cricket test every summer, along with a number of One Day International cricket matches. Memorial Drive Park, adjacent to the Adelaide Oval, used to host Davis Cup and other major tennis events, including the Australian Open and (until 2009) the Adelaide International (now known as the Brisbane International). Adelaide's professional association football team, Adelaide United, play in the A-League. Founded in 2003, their home ground is Hindmarsh Stadium, which has a capacity of 17,000 and is one of the few purpose-built soccer stadia in Australia. Prior to United's foundation, Adelaide City and West Adelaide represented the city in the National Soccer League. The two sides, which contest the Adelaide derby against one another, now play in the National Premier Leagues South Australia.

For two years, 1997 and 1998, Adelaide was represented in Australia's top level rugby league, after the New South Wales Rugby League had played a single game per season at the Adelaide Oval for five years starting in 1991. The Adelaide Rams were formed and played in the breakaway Super League (SL) competition in 1997 before moving to the new National Rugby League in 1998. Initially playing at the Adelaide Oval, the club moved to the more suitable Hindmarsh Stadium late in the 1998 season. As part of a peace deal with the Australian Rugby League to end the Super League war, the club's owners News Limited (who were also owners of the SL) suddenly closed the club only weeks before the start of the 1999 season.

Adelaide has two professional basketball teams, the men's team being the Adelaide 36ers which plays in the National Basketball League (NBL) and the women's team, the Adelaide Lightning which plays in the Women's National Basketball League (WNBL). Both teams play their home games at the Titanium Security Arena. Adelaide has a professional netball team, the Adelaide Thunderbirds, which plays in the national netball competition, the Suncorp Super Netball championship, with home games played at Priceline Stadium. The Thunderbirds occasionally play games or finals at the Titanium Security Arena, while international netball matches are usually played at the 10,500 seat Adelaide Entertainment Centre. The Titanium Security Arena has a capacity of 8,000 and is the largest purpose-built basketball stadium in Australia.

Since 1999 Adelaide and its surrounding areas have hosted the Tour Down Under bicycle race, organised and directed by Adelaide-based Mike Turtur. Turtur won an Olympic gold medal for Australia in the 4000m Team pursuit at the 1984 Los Angeles Olympics. The Tour Down Under is the largest cycling event outside Europe and was the first event outside Europe to be granted UCI ProTour status. Adelaide maintains a franchise in the Australian Baseball League, the Adelaide Bite. They have been playing since 2009, and their home stadium (until 2016) was Norwood Oval. From 2016 the team moved to the Diamond Sports Stadium located near the Adelaide International Airport due to renovations at Norwood. Its name stems from the local Great Australian Bight, and from the abundance of local Great White Sharks. Adelaide also has an Ice Hockey team, Adelaide Adrenaline in the Australian Ice Hockey League (AIHL). It was national champions in 2009 and plays its games at the IceArenA.

The Australian Grand Prix for World Championship Formula One racing was hosted by Adelaide from 1985 to 1995 on the Adelaide Street Circuit which was laid out in the city's East End as well as the eastern parklands including the Victoria Park Racecourse. The Grand Prix became a source of pride, and losing the event to Melbourne in a surprise announcement in mid-1993 left a void that has since been filled with the highly successful Clipsal 500 for V8 Supercar racing, held on a modified version of the same street circuit. The Classic Adelaide, a rally of classic sporting vehicles, is also held in the city and its surrounds.

Adelaide formerly had three horse racing venues. Victoria Park, Cheltenham Park Racecourse, both of which have now closed, and Morphettville Racecourse that remains the home of the South Australian Jockey Club. It also has Globe Derby Park for Harness racing that opened in 1969, and by 1973 had become Adelaide's premier harness racing venue taking over from the Wayville Showgrounds, as well as Greyhound Park for greyhound racing that opened in 1972.

The World Solar Challenge race attracts teams from around the world, most of which are fielded by universities or corporations, although some are fielded by high schools. The race has a 20-years' history spanning nine races, with the inaugural event taking place in 1987. Adelaide hosted the 2012 World Bowls Championships at Lockleys Bowling Club, becoming the third city in the world to have held the championships twice, having previously hosted the event in 1996.

Dirt track speedway is also popular in Adelaide with three operating speedways. Adelaide Motorsport Park, located adjacent to the Adelaide International Raceway road racing circuit at Virginia ( north of the city centre) has been in continuous operation since 1979 after the closure of the popular Rowley Park Speedway. Gillman Speedway located in the semi-industrial suburb of Gillman, has been in operation since 1998 and caters to Motorcycle speedway and Sidecars, while the Sidewinders Speedway located in Wingfield is also a motorcycle speedway dedicated to Under-16 riders and has been in operation since 1978. In 2016 backed my South Australia's Peregrine Group owners of OTR (On the run service stations and 24/7 hour convienent stores) opened up a multi-purpose facility; a state-of-the-art motorsporting park and a hotel alongside its newer OTR service station outside a small township of Tailem Bend currently named The Bend Motorsport Park. Design for thrill seekers and rev-heads the facility currently host South Australia's second V8 Supercars motoring event during a round in August and hopes to bring in other major international motoring events such as SBK Superbikes and other well established FIA motoring events.

Adelaide is home to the Great Southern Slam, the world's largest roller derby tournament. The tournament has been held biennially over Australia's Queen's Birthday holiday weekend since 2010. In 2014 and 2016 the tournament featured 45 teams playing in two divisions. In 2018 the tournament has expanded to 48 teams competing in three divisions.

Adelaide's two largest tertiary hospitals in the city are the Royal Adelaide Hospital (RAH), a teaching hospital of the University of Adelaide (705 beds), and the Flinders Medical Centre (580 beds) in Bedford Park, a teaching hospital of Flinders University. Other major public hospitals in the Adelaide area are the Women's and Children's Hospital (305 beds), on King William Road in North Adelaide; the Queen Elizabeth Hospital (340 beds) in Woodville and the Lyell McEwin Hospital (198 beds) in Elizabeth. These hospitals are all teaching hospitals. Additional RAH campuses which specialise in specific patient services are in the suburbs of Adelaide – the Hampstead Rehabilitation Centre in Northfield, and the Glenside Campus Mental Health Service. Adelaide also hosts numerous private hospitals in the city centre and suburbs.

In June 2007 the State Government announced a series of overhauls to the health sector that would see a new hospital constructed on railyards at the west end of the city, to replace the Royal Adelaide Hospital at the east end of the city. The new 800-bed hospital has a cost of A$1.85 billion and was planned to be named the "Marjorie Jackson-Nelson Hospital" after the former Governor of South Australia. However, in 2009, at the former governor's request, the state government chose to drop this name and instead transfer the Royal Adelaide Hospital name to the proposed facility. Construction started in June 2011 and finished in 2017.

In addition, major upgrades were announced to see the Flinders Medical Centre become the primary centre for health care for the southern suburbs, and the Lyell McEwin Hospital in Elizabeth become the centre for the northern suburbs. The trio of the Queen Elizabeth Hospital, the Modbury Hospital and the Noarlunga Hospital were to become specialist elective surgery centres. The Repatriation General Hospital was also to expand its range of speciality areas beyond veterans' health to incorporate stroke, orthopaedic rehabilitation and aged care. With the "Global Financial Crisis" of 2008, it remains to be seen if and how these initiatives will proceed.

The largest not-for-profit provider of community health care within Adelaide is the Royal District Nursing Service (South Australia) which provides out of hospital care and hospital avoidance care, easing pressure on the South Australia public hospital system.

Being centrally located on the Australian mainland, Adelaide forms a strategic transport hub for east-west and north-south routes. The city itself has a metropolitan-wide public transport system, which is managed by and known as the Adelaide Metro. The Adelaide Metro consists of a contracted bus system including the O-Bahn Busway, metropolitan railways (with diesel and electric lines), and the Adelaide-Glenelg Tram, which was extended as a metropolitan tram in 2010 through the city centre to the inner north-west suburb of Hindmarsh. There are further plans to extend the tram to Port Adelaide and Semaphore. A CBD tram loop too, is being considered and the latest Adelaide Airport master plan has also revealed a tram extension to the airport in the near future.

Road transport in Adelaide has historically been comparatively easier than many of the other Australian cities, with a well-defined city layout and wide multiple-lane roads from the beginning of its development. Historically, Adelaide was known as a "twenty-minute city", with commuters having been able to travel from metropolitan outskirts to the city proper in roughly twenty minutes. However, these roads are now often considered inadequate to cope with Adelaide's growing road traffic, and often experience traffic congestion.

The Adelaide metropolitan area has one freeway and three expressways. In order of construction, they are:

The Adelaide metropolitan area has two commercial airports, Adelaide Airport and Parafield Airport. Adelaide Airport, in Adelaide's western suburbs, serves in excess of 8 million passengers annually. Parafield Airport, Adelaide's second airport north of the city centre, is used for small aircraft, pilot training and recreational aviation purposes. Parafield Airport served as Adelaide's main aerodrome until the opening of the Adelaide Airport in February 1955. Adelaide airport serves 9 international destinations and all state capital cities.

Adelaide's energy requirements were originally met by the Adelaide Electric Supply Company, which was nationalised by the Playford government in 1946, becoming the Electricity Trust of South Australia (ETSA), now known as SA Power Networks. Despite significant public opposition and the Labor party's anti-privatisation stance which left the Liberal party one vote short of the numbers needed to pass the legislation, ETSA was privatised by the Olsen Government in 1999 by way of a 200-year lease for the distribution network and the outright purchase of ETSA Power by the Cheung Kong Holdings for $3.5 billion (11 times ETSA's annual earnings) after Labor MP Trevor Crothers resigned from the party and voted with the government.

The electricity retail market was opened to competition in 2003 and although competition was expected to result in lower retail costs, prices increased by 23.7% in the market's first year. In 2004 the privatisation was deemed to be a failure with consumers paying 60% more for their power and with the state government estimated to lose $3 billion in power generation net income in the first ten years of privatisation. In 2012, the industry came under scrutiny for allegedly reducing supply by shutting down generators during periods of peak demand to force prices up. Increased media attention also revealed that in 2009 the state government had approved a 46% increase in retail prices to cover expected increases in the costs of generation while generation costs had in fact fallen 35% by 2012. These price increases and large subsidies have led to South Australia paying the highest retail price for electricity in the country.

SA Power Networks now distributes electricity from transmission companies to end users. Privatisation led to competition from a variety of companies who now separately provide for the generation, transmission, distribution and retail sales of gas and electricity. Some of the major companies are: TRUenergy, which generates electricity; ElectraNet, which transmits electricity from the generators to the distribution network, Lumo Energy and AGL Energy, which retails gas and electricity. Substantial investment has been made in maintenance and reinforcement of the electricity supply network to provide continued reliability of supply.

Adelaide derives most of its electricity from the Torrens Island Power Station gas-fired plant operated by AGL Energy and the Pelican Point Power Station, along with wind power and connections to the national grid. Gas is supplied from the Moomba Gas Processing Plant in the Cooper Basin via the Moomba Adelaide Pipeline System and the SEAGas pipeline from Victoria. South Australia generates 18% of its electricity from wind power, and has 51% of the installed capacity of wind generators in Australia.

Adelaide's water supply is gained from its reservoirs: Mount Bold, Happy Valley, Myponga, Millbrook, Hope Valley, Little Para and South Para. The yield from these reservoir catchments can be as little as 10% of the city's requirements in drought years and about 60% in average years. The remaining demand is met by the pumping of water from the River Murray. A sea water desalination plant capable of supplying half of Adelaide's water requirements (100GL per annum) was commissioned in 2013. The provision of water services is by the government-owned SA Water.





</doc>
<doc id="1152" url="https://en.wikipedia.org/wiki?curid=1152" title="Alan Garner">
Alan Garner

Alan Garner (born 17 October 1934) is an English novelist best known for his children's fantasy novels and his retellings of traditional British folk tales. Much of his work is rooted in the landscape, history and folklore of his native county of Cheshire, North West England, being set in the region and making use of the native Cheshire dialect.

Born in Congleton, Garner grew up around the nearby town of Alderley Edge, and spent much of his youth in the wooded area known locally as "The Edge", where he gained an early interest in the folklore of the region. Studying at Manchester Grammar School and then briefly at Oxford University, in 1957 he moved to the nearby village of Blackden, where he bought and renovated an Early Modern building known as Toad Hall. His first novel, "The Weirdstone of Brisingamen", was published in 1960. A children's fantasy novel set on the Edge, it incorporated elements of local folklore in its plot and characters. Garner completed a sequel, "The Moon of Gomrath" (1963), but left the third book of the trilogy he had envisioned. Instead he wrote several fantasy novels, "Elidor" (1965), "The Owl Service" (1967) and "Red Shift" (1973).

Turning away from fantasy as a genre, Garner produced "The Stone Book Quartet" (1979), a series of four short novellas detailing a day in the life of four generations of his family. He also published a series of British folk tales which he had rewritten in a series of books entitled "Alan Garner's Fairy Tales of Gold" (1979), "Alan Garner's Book of British Fairy Tales" (1984) and "A Bag of Moonshine" (1986). In his subsequent novels, "Strandloper" (1996) and "Thursbitch" (2003), he continued writing tales revolving around Cheshire, although without the fantasy elements which had characterised his earlier work. In 2012, he finally published a third book in the Weirdstone trilogy, "Boneland".

Garner was born in the front room of his grandmother's house in Congleton, Cheshire, on 17 October 1934. He was raised in nearby Alderley Edge, a well-to-do village that had effectively become a suburb of Manchester. His "rural working-class family", had been connected to Alderley Edge since at least the sixteenth century, and could be traced back to the death of William Garner in 1592. Garner has stated that his family had passed on "a genuine oral tradition" involving folk tales about The Edge, which included a description of a king and his army of knights who slept under it, guarded by a wizard. In the mid-nineteenth century Alan's great-great grandfather Robert had carved the face of a bearded wizard onto the face of a cliff next to a well, known locally at that time as the Wizard's Well.

Robert Garner and his other relatives had all been craftsmen, and, according to Garner, each successive generation had tried to "improve on, or do something different from, the previous generation". Garner's grandfather, Joseph Garner, "could read, but didn't and so was virtually unlettered". Instead he taught his grandson the folk tales he knew about The Edge. Garner later remarked that as a result he was "aware of [the Edge's] magic" as a child, and he and his friends often played there. The story of the king and the wizard living under the hill played an important part in his life, becoming, he explained, "deeply embedded in my psyche" and heavily influencing his later novels.

Garner faced several life-threatening childhood illnesses, which left him bed ridden for much of the time. He attended a local village school, where he found that, despite being praised for his intelligence, he was punished for speaking in his native Cheshire dialect; for instance, when he was six his primary school teacher washed his mouth out with soapy water. Garner then won a place at Manchester Grammar School, where he received his secondary education; entry was means-tested, resulting in his school fees being waived. Rather than focusing his interest on creative writing, it was here that he excelled at sprinting. He used to go jogging along the highway, and later claimed that in doing so he was sometimes accompanied by the mathematician Alan Turing, who shared his fascination with the Disney film "Snow White and the Seven Dwarfs". Garner was then conscripted into national service, serving for a time with the Royal Artillery while posted to Woolwich in Southeast London.

At school, Garner had developed a keen interest in the work of Aeschylus and Homer, as well as the Ancient Greek language. Thus, he decided to pursue the study of Classics at Magdalen College, Oxford, passing his entrance exams in January 1953; at the time he had thoughts of becoming a professional academic. He was the first member of his family to receive anything more than a basic education, and he noted that this removed him from his "cultural background" and led to something of a schism with other members of his family, who "could not cope with me, and I could not cope with" them. Looking back, he remarked, "I soon learned that it was not a good idea to come home excited over irregular verbs". In 1955, he joined the university theatrical society, playing the role of Mark Antony in a performance of William Shakespeare's "Antony and Cleopatra" where he co-starred alongside Dudley Moore and where Kenneth Baker was the stage manager. In August 1956, he decided that he wished to devote himself to novel writing, and decided to abandon his university education without taking a degree; he left Oxford in late 1956. He nevertheless felt that the academic rigour which he learned during his university studies has remained "a permanent strength through all my life".

Aged 22, Garner was out cycling when he came across a hand-painted sign announcing that an agricultural cottage in Toad Hall – a Late Medieval building situated in Blackden, seven miles from Alderley Edge – was on sale for £510. Although he personally could not afford it, he was lent the money by the local Oddfellow lodge, enabling him to purchase and move into the cottage in June 1957. In the late nineteenth century the Hall had been divided into two agricultural labourers' cottages, but Garner was able to purchase the second for £150 about a year later; he proceeded to knock down the dividing walls and convert both halves back into a single home.

Garner had begun writing his first novel, "The Weirdstone of Brisingamen: A Tale of Alderley", in September 1956. However it was while at Toad Hall that he finished the book. Set in Alderley Edge, it revolved around two children, Susan and Colin, who are sent to live in the area with their mother's old nurse maid, Bess, and her husband, Gowther Mossock. Setting about to explore the Edge, they discover a race of malevolent creatures, the "svart alfar", who dwell in the Edge's abandoned mines and who seem intent on capturing them, until they are rescued by the wizard Cadellin who reveals that the forces of darkness are massing at the Edge in search of the eponymous "weirdstone of Brisingamen". Whilst engaged in writing in his spare time, Garner attempted to gain employment as a teacher, but soon gave that up, believing that "I couldn't write and teach; the energies were too similar", and so began working as a general labourer for four years, remaining unemployed for much of that time.

Garner sent his debut novel to the publishing company Collins, where it was picked up by the company's head, Sir William Collins, who was on the look out for new fantasy novels following on from the recent commercial and critical success of J. R. R. Tolkien's "The Lord of the Rings" (1954–55). Garner, who went on to become a personal friend of Collins, would later relate that "Billy Collins saw a title with funny-looking words in it on the stockpile, and he decided to publish it." On its release in 1960, "The Weirdstone of Brisingamen" proved to be a critical and commercial success, later being described as "a tour de force of the imagination, a novel that showed almost every writer who came afterwards what it was possible to achieve in novels ostensibly published for children." Garner himself however would later denounce this novel as "a fairly bad book" in 1968.

With his first book published, Garner abandoned his work as a labourer and gained a job as a freelance television reporter, living a "hand to mouth" lifestyle on a "shoestring" budget. He also worked on a sequel to "The Weirdstone of Brisingamen", which would be known as "The Moon of Gomrath". "The Moon of Gomrath" also revolves around the adventures of Colin and Susan, with the latter being possessed by a malevolent creature called the Brollachan who has recently entered the world. With the help of the wizard Cadellin, the Brollachan is exorcised, but Susan's soul also leaves her body, being sent to another dimension, leading Colin to find a way to bring it back. Critic Neil Philip characterised it as "an artistic advance" but "a less satisfying story". In a 1989 interview, Garner stated that he had left scope for a third book following the adventures of Colin and Susan, envisioning a trilogy, but that he had intentionally decided not to write it, instead moving on to write something different. However "Boneland", the conclusion to the sequence, was belatedly published in August 2012.

In 1962 Garner began work on a radio play named "Elidor", which would result in the completion of a novel of the same name. Set in contemporary Manchester, "Elidor" tells the story of four children who enter into a derelict Victorian church, in which they find a portal to the magical realm of Elidor. Here, they are entrusted by King Malebron to help rescue four treasures which have been stolen by the forces of evil who are attempting to take control of the kingdom. Successfully doing so, the children return to Manchester with the treasures, but are pursued by the malevolent forces who need them to seal their victory.

Before writing "Elidor", Garner had seen a dinner service set which could be arranged to make pictures of either flowers or owls. Inspired by this design, he produced his fourth novel, "The Owl Service". The story was also heavily influenced by the Medieval Welsh tale of Math fab Mathonwy from, the "Mabinogion". "The Owl Service" was critically acclaimed, winning both the Carnegie Medal and Guardian Children's Fiction Prize. It also sparked discussions among critics as to whether Garner should properly be considered a children's writer, given that this book in particular was deemed equally suitable for an adult readership.

It took Garner six years to write his next novel, "Red Shift". In this, he provided three intertwined love stories, one set in the present, another during the English Civil War, and the third in the second century CE. Philip referred to it as "a complex book but not a complicated one: the bare lines of story and emotion stand clear".
Academic specialist in children's literature Maria Nikolajeva characterised "Red Shift" as "a difficult book" for an unprepared reader, identifying its main themes as those of "loneliness and failure to communicate". Ultimately, she thought that repeated re-readings of the novel bring about the realisation that "it is a perfectly realistic story with much more depth and psychologically more credible than the most so-called "realistic" juvenile novels."

From 1976 to 1978, Garner published a series of four novellas, which have come to be collectively known as "The Stone Book" quartet: "The Stone Book", "Granny Reardun", "The Aimer Gate", and "Tom Fobble's Day". Each focused on a day in the life of a child in the Garner family, each from a different generation.
In a 1989 interview, Garner noted that although writing "The Stone Book Quartet" had been "exhausting", it had been "the most rewarding of everything" he'd done to date. Philip described the quartet as "a complete command of the material he had been working and reworking since the start of his career".
Garner pays particular attention to language, and strives to render the cadence of the Cheshire tongue in modern English. This he explains by the sense of anger he felt on reading "Sir Gawain and the Green Knight": the footnotes would not have been needed by his father.

In 1981, the literary critic Neil Philip published an analysis of Garner's novels as "A Fine Anger", which was based on his doctoral thesis, produced for the University of London in 1980. In this study he noted that ""The Stone Book" quartet marks a watershed in Garner's writing career, and provides a suitable moment for an evaluation of his work thus far."

In 1996, Garner's novel "Strandloper" was published. His collection of essays and public talks, "The Voice That Thunders", contains much autobiographical material (including an account of his life with bipolar disorder), as well as critical reflection upon folklore and language, literature and education, the nature of myth and time. In "The Voice That Thunders" he reveals the commercial pressure placed upon him during the decade-long drought which preceded "Strandloper" to 'forsake "literature", and become instead a "popular" writer, cashing in on my established name by producing sequels to, and making series of, the earlier books'. Garner feared that "making series ... would render sterile the existing work, the life that produced it, and bring about my artistic and spiritual death" and felt unable to comply.

Garner's novel "Thursbitch" was published in 2003. Garner's novel, "Boneland", was published in 2012, nominally completing a trilogy begun some 50 years earlier with "The Weirdstone of Brisingamen".

In August 2018 Garner published his only set of memoirs, "Where Shall We Run To?", which describes his childhood during the Second World War.

With his first wife Anne Cook he had three children. In 1972 he married for a second time, this time to Griselda Greaves, a teacher and critic with whom he had two children. In a 2014 interview conducted with Mike Pitts for "British Archaeology" magazine, Garner stated that "I don't have anything to do with the literary world. I avoid writers. I don't like them. Most of my close personal friends are professional archaeologists."

Although Garner's early work is often labelled as "children's literature", Garner himself rejects such a description, informing one interviewer that "I certainly have never written for children" but that instead he has always written purely for himself. Neil Philip, in his critical study of Garner's work (1981), commented that up till that point, "Everything Alan Garner has published has been published for children", although he went on to relate that "It may be that Garner's is a case" where the division between children's and adult's literature is "meaningless" and that his fiction is instead "enjoyed by a type of person, no matter what their age."

Philip offered the opinion that the "essence of his work" was "the struggle to render the complex in simple, bare terms; to couch the abstract in the concrete and communicate it directly to the reader". He added that Garner's work is "intensely autobiographical, in both obvious and subtle ways". Highlighting Garner's use of mythological and folkloric sources, Philip stated that his work explores "the disjointed and troubled psychological and emotional landscape of the twentieth century through the symbolism of myth and folklore." He also expressed the opinion that "Time is Garner's most consistent theme".

The English author and academic Charles Butler noted that Garner was attentive to the "geological, archaeological and cultural history of his settings, and careful to integrate his fiction with the physical reality beyond the page." As a part of this, Garner had included maps of Alderley Edge in both "The Weirdstone of Brisingamen" and "The Moon of Gomrath". Garner has spent much time investigating the areas that he deals with in his books; writing in the "Times Literary Supplement" in 1968, Garner commented that in preparation for writing his book "Elidor":

In a paper published in the "Children's Literature Association Quarterly", Maria Nikolajeva characterised Garner as "one of the most controversial" authors of modern children's literature.

In the fiftieth anniversary edition of "The Weirdstone of Brisingamen", published by HarperCollins in 2010, several notable British fantasy novelists praised Garner and his work. Susan Cooper related that "The power and range of Alan Garner's astounding talent has grown with every book he's written", whilst David Almond called him one of Britain's "greatest writers" whose works "really matter". Philip Pullman, the author of the "His Dark Materials" trilogy, went further when he remarked that:

Another British fantasy writer, Neil Gaiman, claimed that "Garner's fiction is something special" in that it was "smart and challenging, based in the here and the now, in which real English places emerged from the shadows of folklore, and in which people found themselves walking, living and battling their way through the dreams and patterns of myth." Praise also came from Nick Lake, the editorial director of HarperCollins Children's Books, who proclaimed that "Garner is, quite simply, one of the greatest and most influential writers this country has ever produced."

The biennial Hans Christian Andersen Award conferred by the International Board on Books for Young People is the highest recognition available to a writer or illustrator of children's books. Garner was the sole runner-up for the writing award in 1978.

Garner was appointed Officer of the Order of the British Empire (OBE) for services to literature in the 2001 New Year's Honours list. He received the British Fantasy Society's occasional Karl Edward Wagner Award in 2003 and the World Fantasy Award for Life Achievement in 2012. In January 2011, the University of Warwick awarded the degree of Doctor of Letters (honoris causa). On that occasion he gave a half-hour interview about his work.. He has also been awarded honorary doctorates from the University of Salford (2011) and the University of Huddersfield in (2012).

He has been recognised several times for particular works.




</doc>
<doc id="1154" url="https://en.wikipedia.org/wiki?curid=1154" title="August 2">
August 2





</doc>
<doc id="1155" url="https://en.wikipedia.org/wiki?curid=1155" title="Atlantic (disambiguation)">
Atlantic (disambiguation)

The Atlantic Ocean is the second largest of the world's oceans, that separates the old world from the new world.

Atlantic may also refer to:

















</doc>
<doc id="1158" url="https://en.wikipedia.org/wiki?curid=1158" title="Algebraic number">
Algebraic number

An algebraic number is any complex number (including real numbers) that is a root of a non-zero polynomial (that is, a value which causes the polynomial to equal 0) in one variable with rational coefficients (or equivalently – by clearing denominators – with integer coefficients). All integers and rational numbers are algebraic, as are all roots of integers. The same is not true for all real numbers or all complex numbers. Those real and complex numbers which are not algebraic are called transcendental numbers. They include and . While the set of complex numbers is uncountable, the set of algebraic numbers is countable and has measure zero in the Lebesgue measure as a subset of the complex numbers, and in this sense almost all complex numbers are transcendental.



The sum, difference, product and quotient (if the denominator is nonzero) of two algebraic numbers is again algebraic (this fact can be demonstrated using the resultant), and the algebraic numbers therefore form a field (sometimes denoted by , though this usually denotes the adele ring). Every root of a polynomial equation whose coefficients are "algebraic numbers" is again algebraic. This can be rephrased by saying that the field of algebraic numbers is algebraically closed. In fact, it is the smallest algebraically closed field containing the rationals, and is therefore called the algebraic closure of the rationals.

The set of "real" algebraic numbers itself forms a field.

All numbers that can be obtained from the integers using a finite number of integer additions, subtractions, multiplications, divisions, and taking th roots where is a positive integer (radical expressions) are algebraic. The converse, however, is not true: there are algebraic numbers that cannot be obtained in this manner. Such a number requires the polynomial it is a root of to be of a degree 5 or more. This is a result of Galois theory (see Quintic equations and the Abel–Ruffini theorem). An example of such a number is the unique real root of the polynomial (which is approximately ).

Algebraic numbers are all numbers that can be defined explicitly or implicitly in terms of polynomials, starting from the rational numbers. One may generalize this to "closed-form numbers", which may be defined in various ways. Most broadly, all numbers that can be defined explicitly or implicitly in terms of polynomials, exponentials, and logarithms are called "elementary numbers", and these include the algebraic numbers, plus some transcendental numbers. Most narrowly, one may consider numbers "explicitly" defined in terms of polynomials, exponentials, and logarithms – this does not include all algebraic numbers, but does include some simple transcendental numbers such as or ln 2.

An algebraic integer is an algebraic number that is a root of a polynomial with integer coefficients with leading coefficient 1 (a monic polynomial). Examples of algebraic integers are , and . Note, therefore, that the algebraic integers constitute a proper superset of the integers, as the latter are the roots of monic polynomials for all In this sense, algebraic integers are to algebraic numbers what integers are to rational numbers.

The sum, difference and product of algebraic integers are again algebraic integers, which means that the algebraic integers form a ring. The name "algebraic integer" comes from the fact that the only rational numbers that are algebraic integers are the integers, and because the algebraic integers in any number field are in many ways analogous to the integers. If is a number field, its ring of integers is the subring of algebraic integers in , and is frequently denoted as . These are the prototypical examples of Dedekind domains.




</doc>
<doc id="1160" url="https://en.wikipedia.org/wiki?curid=1160" title="Automorphism">
Automorphism

In mathematics, an automorphism is an isomorphism from a mathematical object to itself. It is, in some sense, a symmetry of the object, and a way of mapping the object to itself while preserving all of its structure. The set of all automorphisms of an object forms a group, called the automorphism group. It is, loosely speaking, the symmetry group of the object.

In the context of abstract algebra, a mathematical object is an algebraic structure such as a group, ring, or vector space. An automorphism is simply a bijective homomorphism of an object with itself. (The definition of a homomorphism depends on the type of algebraic structure; see, for example, group homomorphism, ring homomorphism, and linear operator).

The identity morphism (identity mapping) is called the trivial automorphism in some contexts. Respectively, other (non-identity) automorphisms are called nontrivial automorphisms.

The exact definition of an automorphism depends on the type of "mathematical object" in question and what, precisely, constitutes an "isomorphism" of that object. The most general setting in which these words have meaning is an abstract branch of mathematics called category theory. Category theory deals with abstract objects and morphisms between those objects.

In category theory, an automorphism is an endomorphism (i.e., a morphism from an object to itself) which is also an isomorphism (in the categorical sense of the word).

This is a very abstract definition since, in category theory, morphisms aren't necessarily functions and objects aren't necessarily sets. In most concrete settings, however, the objects will be sets with some additional structure and the morphisms will be functions preserving that structure.

If the automorphisms of an object form a set (instead of a proper class), then they form a group under composition of morphisms. This group is called the automorphism group of .

The automorphism group of an object "X" in a category "C" is denoted Aut("X"), or simply Aut("X") if the category is clear from context.


One of the earliest group automorphisms (automorphism of a group, not simply a group of automorphisms of points) was given by the Irish mathematician William Rowan Hamilton in 1856, in his icosian calculus, where he discovered an order two automorphism, writing:
so that formula_1 is a new fifth root of unity, connected with the former fifth root formula_2 by relations of perfect reciprocity.

In some categories—notably groups, rings, and Lie algebras—it is possible to separate automorphisms into two types, called "inner" and "outer" automorphisms.

In the case of groups, the inner automorphisms are the conjugations by the elements of the group itself. For each element "a" of a group "G", conjugation by "a" is the operation given by (or "a""ga"; usage varies). One can easily check that conjugation by "a" is a group automorphism. The inner automorphisms form a normal subgroup of Aut("G"), denoted by Inn("G"); this is called Goursat's lemma.

The other automorphisms are called outer automorphisms. The quotient group is usually denoted by Out("G"); the non-trivial elements are the cosets that contain the outer automorphisms.

The same definition holds in any unital ring or algebra where "a" is any invertible element. For Lie algebras the definition is slightly different.




</doc>
<doc id="1162" url="https://en.wikipedia.org/wiki?curid=1162" title="Accordion">
Accordion

Accordions (from 19th-century German "Akkordeon", from "Akkord"—"musical chord, concord of sounds") are a family of box-shaped musical instruments of the bellows-driven free-reed aerophone type, colloquially referred to as a squeezebox. A person who plays the accordion is called an "accordionist". The concertina and bandoneón are related; the harmonium and American reed organ are in the same family.

The instrument is played by compressing or expanding the bellows while pressing buttons or keys, causing "pallets" to open, which allow air to flow across strips of brass or steel, called "reeds". These vibrate to produce sound inside the body. Valves on opposing reeds of each note are used to make the instrument's reeds sound louder without air leaking from each reed block. The performer normally plays the melody on buttons or keys on the right-hand manual, and the accompaniment, consisting of bass and pre-set chord buttons, on the left-hand manual.

The accordion is widely spread across the world. In some countries (for example Brazil, Colombia, Dominican Republic, Mexico and Panama) it is used in popular music (for example Gaucho, Forró and Sertanejo in Brazil, Vallenato in Colombia, and norteño in Mexico), whereas in other regions (such as Europe, North America and other countries in South America) it tends to be more used for dance-pop and folk music and is often used in folk music in Europe, North America and South America. In Europe and North America, some popular music acts also make use of the instrument. Additionally, the accordion is used in cajun, zydeco, jazz music and in both solo and orchestral performances of classical music.
The piano accordion is the official city instrument of San Francisco, California. Many conservatories in Europe have classical accordion departments. The oldest name for this group of instruments is "harmonika", from the Greek "harmonikos", meaning "harmonic, musical". Today, native versions of the name "accordion" are more common. These names refer to the type of accordion patented by Cyrill Demian, which concerned "automatically coupled chords on the bass side".

Accordions have many configurations and types. What may be technically possible to do with one accordion could be impossible with another:

The bellows is the most recognizable part of the instrument, and the primary means of articulation. Similar to a violin's bow, the production of sound in an accordion is in direct proportion to the motion of the player. The bellows is located between the right- and left-hand manuals, and is made from pleated layers of cloth and cardboard, with added leather and metal. It is used to create pressure and vacuum, driving air across the internal reeds and producing sound by their vibrations, applied pressure increases the volume.

The keyboard touch is not expressive and does not affect dynamics: all expression is effected through the bellows. Bellows effects include:

The accordion's body consists of two wooden boxes joined together by the bellows. These boxes house reed chambers for the right- and left-hand manuals. Each side has grilles in order to facilitate the transmission of air in and out of the instrument, and to allow the sound to project better. The grille for the right-hand manual is usually larger and is often shaped for decorative purposes. The right-hand manual is normally used for playing the melody and the left-hand manual for playing the accompaniment; however, skilled players can reverse these roles.

The size and weight of an accordion varies depending on its type, layout and playing range, which can be as small as to have only one or two rows of basses and a single octave on the right-hand manual, to the standard 120-bass accordion and through to large and heavy 160-bass free-bass converter models.

The accordion is an aerophone. The manual mechanism of the instrument either enables the air flow, or disables it:

The term "accordion" covers a wide range of instruments, with varying components. All instruments have reed ranks of some format. Not all have switches. The most typical accordion is the piano accordion, which is used for many musical genres. Another type of accordion is the button accordion, which is used in several musical traditions, including Cajun, Conjunto and Tejano music, Swiss and Austro-German Alpine music, and Argentinian tango music.

Different systems exist for the right-hand manual of an accordion, which is normally used for playing the melody. Some use a button layout arranged in one way or another, while others use a piano-style keyboard. Each system has different claimed benefits by those who prefer it. They are also used to define one accordion or another as a different "type":

Different systems are also in use for the left-hand manual, which is normally used for playing the accompaniment. These almost always use distinct bass buttons and often have buttons with concavities or studs to help the player navigate the layout despite not being able to see the buttons while playing. There are three general categories:

Inside the accordion are the reeds that generate the instrument tones. These are organized in different sounding "banks", which can be further combined into "registers" producing differing "timbres". All but the smaller accordions are equipped with switches that control which combination of reed banks operate, organized from high to low registers. Each register stop produces a separate sound timbre. See the accordion reed ranks and switches article for further explanation and audio samples.

All but the smallest accordions usually have treble switches. The larger and more expensive accordions often also have bass switches.

In describing or pricing an accordion, the first factor is size, expressed in number of keys on either side. For a piano type, this could for one example be 37/96, meaning 37 keys (three octaves plus one note) on the treble side and 96 bass keys. After size, the price and weight of an accordion is largely dependent on the number of reed ranks on either side, either on a cassotto or not, and to a lesser degree on the number of combinations available through register switches. Typically, these could be announced as "Reeds: 5 + 3", meaning five reeds on the treble side and three on the bass, and "Registers: 13 + M, 7", meaning 13 register buttons on the treble side plus a special "master" that activates all ranks, like the "tutti" on an organ, and seven register switches on the bass side.
The larger piano and chromatic button accordions are usually heavier than other smaller squeezeboxes, and are equipped with two shoulder straps to make it easier to balance the weight and increase bellows control while sitting, and avoid dropping the instrument while standing.

Other accordions, such as the diatonic button accordion, have only a single shoulder strap and a right hand thumb strap. All accordions have a (mostly adjustable) leather strap on the left-hand manual to keep the player's hand in position while drawing the bellows. There are also straps above and below the bellows to keep it securely closed when the instrument is not playing.

Various hybrid accordions have been created between instruments of different buttonboards and actions. Many remain curiosities — only a few have remained in use:

The accordion's basic form is believed to have been invented in Berlin, in 1822, by Christian Friedrich Ludwig Buschmann, although one instrument has been recently discovered that appears to have been built earlier.

The earliest history of the accordion in Russia is poorly documented. Nevertheless, according to Russian researchers, the earliest known simple accordions were made in Tula, Russia, by from 1820, and from 1830. By the late 1840s, the instrument was already very widespread; together the factories of the two masters were producing 10,000 instruments a year. By 1866, over 50,000 instruments were being produced yearly by Tula and neighbouring villages, and by 1874 the yearly production rate was over 700,000. By the 1860s, Novgorod, Vyatka and Saratov governorates also had significant accordion production. By the 1880s, the list included Oryol, Ryazan, Moscow, Tver, Vologda, Kostroma, Nizhny Novgorod and Simbirsk, and many of these places created their own varieties of the instrument.

The accordion is one of several European inventions of the early 19th century that use free reeds driven by a bellows. An instrument called "accordion" was first patented in 1829 by Cyrill Demian, of Armenian origin, in Vienna. Demian's instrument bore little resemblance to modern instruments. It only had a left hand buttonboard, with the right hand simply operating the bellows. One key feature for which Demian sought the patent was the sounding of an entire chord by depressing one key. His instrument also could sound two different chords with the same key, one for each bellows direction (a "bisonoric" action). At that time in Vienna, mouth harmonicas with "Kanzellen" (chambers) had already been available for many years, along with bigger instruments driven by hand bellows. The diatonic key arrangement was also already in use on mouth-blown instruments. Demian's patent thus covered an accompanying instrument: an accordion played with the left hand, opposite to the way that contemporary chromatic hand harmonicas were played, small and light enough for travelers to take with them and used to accompany singing. The patent also described instruments with both bass and treble sections, although Demian preferred the bass-only instrument owing to its cost and weight advantages.

The accordion was introduced from Germany into Britain in about the year 1828. The instrument was noted in "The Times" in 1831 as one new to British audiences and was not favourably reviewed, but nevertheless it soon became popular. It had also become popular with New Yorkers by the mid-1840s.

After Demian's invention, other accordions appeared, some featuring only the right-handed keyboard for playing melodies. It took English inventor Charles Wheatstone to bring both chords and keyboard together in one squeezebox. His 1844 patent for what he called a "concertina" also featured the ability to easily tune the reeds from the outside with a simple tool.
The musician Adolph Müller described a great variety of instruments in his 1833 book "Schule für Accordion". At the time, Vienna and London had a close musical relationship, with musicians often performing in both cities in the same year, so it is possible that Wheatstone was aware of this type of instrument and may have used them to put his key-arrangement ideas into practice.

Jeune's "flutina" resembles Wheatstone's concertina in internal construction and tone colour, but it appears to complement Demian's accordion functionally. The flutina is a one-sided bisonoric melody-only instrument whose keys are operated with the right hand while the bellows is operated with the left. When the two instruments are combined, the result is quite similar to diatonic button accordions still manufactured today.

Further innovations followed and continue to the present. Various buttonboard and keyboard systems have been developed, as well as voicings (the combination of multiple tones at different octaves), with mechanisms to switch between different voices during performance, and different methods of internal construction to improve tone, stability and durability.

The accordion has traditionally been used to perform folk or ethnic music, popular music, and transcriptions from the operatic and light-classical music repertoire. Today the instrument is sometimes heard in contemporary pop styles, such as rock and pop-rock, and occasionally even in serious classical music concerts, as well as advertisements.

The accordion's popularity spread rapidly: it has mostly been associated with the common people, and was propagated by Europeans who emigrated around the world. The accordion in both button and piano forms became a favorite of folk musicians and has been integrated into traditional music styles all over the world: see the list of music styles that incorporate the accordion.

The accordion appeared in popular music from the 1900s to the 1960s. This half-century is often called the "golden age of the accordion". Five players, Pietro Frosini, the two brothers Count Guido Deiro and Pietro Deiro and Slovenian brothers Vilko Ovsenik and Slavko Avsenik, Charles Magnante were major influences at this time.

Most vaudeville theaters closed during the Great Depression, but accordionists during the 1930s–1950s taught and performed for radio. Included among this group was the concert virtuoso John Serry, Sr. During the 1950s through the 1980s the accordion received significant exposure on television with performances by Myron Floren on "The Lawrence Welk Show". In the late 1950s and early 1960s, the accordion declined in popularity due to the rise of rock and roll. The first accordionist to appear and perform at the Newport Jazz Festival was Angelo DiPippo. He can be seen playing his accordion in the motion picture "The Godfather". He also composed and performed with his accordion on part of the soundtrack of Woody Allen's movie "To Rome With Love". He was featured twice on "The Tonight Show" with Johnny Carson. 
Richard Galliano is an internationally known jazz accordionist. Some popular acts use the instrument in their distinctive sounds. A notable example is Grammy Award-winning parodist "Weird Al" Yankovic, who plays the accordion on many of his musical tracks, particularly his polkas. Yankovic was trained in the accordion as a child.

The accordion has also been used in the rock genre, most notably by John Linnell of They Might Be Giants, featuring more prominently in the band's earlier works. The instrument is still frequently used during live performances, and continues to make appearances in their studio albums.

Although best known as a folk instrument, it has grown in popularity among classical composers. The earliest surviving concert piece is "", written in 1836 by Louise Reisner of Paris. Other composers, including the Russian Pyotr Ilyich Tchaikovsky, the Italian Umberto Giordano, and the American Charles Ives, wrote works for the diatonic button accordion.

The first composer to write specifically for the chromatic accordion was Paul Hindemith. In 1922, the Austrian Alban Berg included an accordion in "Wozzeck", Op. 7. In 1937 the first accordion concerto was composed in Russia. Other notable composers have written for the accordion during the first half of the 20th century. Included among this group was the Italian-American John Serry Sr., whose "Concerto for Free Bass Accordion" was completed in 1964. In addition, the american accordionist Robert Davine composed his "Divertimento for Flute, Clarinet, Bassoon and Accordion" as a work for chamber orchestra. American composer William P. Perry featured the accordion in his orchestral suite "Six Title Themes in Search of a Movie" (2008). The experimental composer Howard Skempton began his musical career as an accordionist, and has written numerous solo works for it. In his work "Drang" (1999), British composer John Palmer pushed the expressive possibilities of the accordion/bayan. Luciano Berio wrote "Sequenza XIII" (1995) for accordionist Teodoro Anzellotti. Accordionists like Mogens Ellegaard, Joseph Macerollo, Friedrich Lips, Hugo Noth, Stefan Hussong, Italo Salizzato, Teodoro Anzellotti, Mie Miki, and Geir Draugsvoll, encouraged composers to write new music for the accordion (solo and chamber music) and also started playing baroque music on the free bass accordion.

French composer Henri Dutilleux used an accordion in both his late song cycles "Correspondances" (2003) and "Le Temps l'Horloge" (2009). Russian-born composer Sofia Gubaidulina has composed solos, concertos, and chamber works for accordion. Astor Piazzolla's concert tangos are performed widely. Piazzolla performed on the bandoneon, but his works are performed on either bandoneon or accordion.

The earliest mention of the novel accordion instrument in Australian music occurs in the 1830s. 
The accordion initially competed against cheaper and more convenient reed instruments such as mouth organ, concertina and melodeon.
Frank Fracchia was an Australian accordion composer and copies of his works "My dear, can you come out tonight" and "Dancing with you" are preserved in Australian libraries.
Other Australian composers who arranged music for accordion include Reginald Stoneham.
The popularity of the accordion peaked in the late 1930s and continued until the 1950s.
The accordion was particularly favoured by buskers.

The accordion is a traditional instrument in Bosnia and Herzegovina. It is the dominant instrument used in sevdalinka, a traditional genre of folk music from Bosnia-Herzegovina. It is also considered a national instrument of the country.

The accordion was brought to Brazil by settlers and immigrants from Europe, specially Italians and German immigrants, where mainly settled at the south (Rio Grande do Sul, Santa Catarina and Parana). The first instrument brought had a name of "Concertina" (a 120 button Chromatic accordion).

The instrument was very popular at 1950, where was common to find 2 accordions in the same house. There are many different configurations and tunes which adapted perfectly to the culture that came from Europe.

Accordion is the official symbol instrument of the Rio Grande do Sul state, where was voted by unanimity in the deputy chamber.
In the boom of accordion there were around 65 factories in Brazil, where most of them (52) was settled in the south, at Rio Grande do Sul state, with only 7 outside the south. One of the most famous and genuinely Brazilian brand was Acordeões Todeschini from Bento Gonçalves-RS, closed in 1973. Todeschini accordion is very appreciated today and survive with very few maintainers.

The most notable musicians of button accordion are Renato Borghetti, Adelar Bertussi, Albino Manique and Edson Dutra.

Compared to many other countries, the instrument is very popular in mainstream pop music. In some parts of the country, such as the north-east it is the most popular melodic instrument. As opposed to most European folk accordion, a very dry tuning is usually used in Brazil.

Outside the south, the accordion (predominantly the piano accordion) is used in almost all styles of Forró (in particular in the subgenres of Xote and Baião) as principal instrument, Luiz Gonzaga (the "King of the Baião") and Dominguinhos being among the notable musicians in this style from northeast. In this musical style the typical combination is a trio of accordion, triangle and zabumba (a type of drum). This style has gained popularity recently, in particular among the student population of the south-east of the country (in the Forró Universitário genre, with important exponents today being Falamansa, and trios such as Trio Dona Zefa, Trio Virgulino and Trio Alvorada). Moreover, the accordion is the principal instrument in Junina music (music of the São João Festival), with Mario Zan having been a very important exponent of this music.

It is an important instrument in Sertanejo (and Caipira) music, which originated in the centre-west and south-east of Brazil and subsequently has gained popularity throughout the country.

The accordion is also a traditional instrument in Colombia, commonly associated with the vallenato and cumbia genres. The accordion has been used by tropipop musicians such as Carlos Vives, Andrés Cabas, Fonseca (singer) and Bacilos, as well as rock musicians such as Juanes and pop musicians as Shakira. Vallenato, who emerged in the early twentieth century in a city known as Valledupar, and have come to symbolize the folk music of Colombia.

Every year in April, Colombia holds one of the most important musical festivals in the country: the Vallenato Legend Festival. The festival holds contests for best accordion player. Once every decade, the "King of Kings" accordion competition takes place, where winners of the previous festivals compete for the highest possible award for a vallenato accordion player: the "Pilonera Mayor" prize. This is the world's largest competitive accordion festival.

Norteño heavily relies on the accordion, it is a genre related to polka. Ramón Ayala known in Mexico as the "King of the Accordion" is a norteño musician. Cumbia which features the accordion is also popular with musicians such as Celso Piña creating a more contemporary style.

U.S. born Mexican musician Julieta Venegas incorporates the sound of the instrument into rock, pop and folk. She was influenced by her fellow Chicanos Los Lobos who also use the music of the accordion.

According to Barbara Demick in Nothing to Envy, the accordion is known as "the people's instrument" and all North Korean teachers were expected to learn the accordion.

Accordionists in heavy metal music make their most extensive appearances in the folk metal subgenre, and are otherwise generally rare. Full-time accordionists in folk metal seem even rarer, but they are still utilized for studio work, as flexible keyboardists are usually more accessible for live performances.

Notably, the Finnish symphonic folk-metal band Turisas used to have a full-time accordionist, employing classical and polka sensibilities alongside a violinist. One of their accordionists, Netta Skog, is now a member of Ensiferum, another folk-metal band. Another Finnish metal band, Korpiklaani, invokes a type of Finnish polka called humppa, and also has a full-time accordionist. Sarah Kiener, the former hurdy-gurdy player for the Swiss melodic-death-folk metal band Eluveitie, played a Helvetic accordion known as a "zugerörgeli".

The most expensive accordions are always fully hand-made, particularly the reeds; completely hand-made reeds have a far better tonal quality than even the best automatically-manufactured ones. Some accordions have been modified by individuals striving to bring a more pure sound out of low-end instruments, such as the ones improved by Yutaka Usui, a Japanese-born craftsman.

The manufacture of an accordion is only a partly automated process. In a sense, all accordions are handmade, since there is always some hand assembly of the small parts required. The general process involves making the individual parts, assembling the subsections, assembling the entire instrument, and final decorating and packaging.

Famous centres of production are the Italian cities of Stradella and Castelfidardo, with many small and medium size manufacturers especially at the latter. Castelfidardo honours the memory of Paolo Soprani who was one of the first large-scale producers. The French town of Tulle has hosted Maugein Freres since 1919, and the company is now the last complete-process manufacturer of accordions in France. German companies such as Hohner and Weltmeister made large numbers of accordions, but production diminished by the end of the 20th century. Hohner still manufactures its top-end models in Germany, and "Weltmeister" instruments are still handmade by HARMONA Akkordeon GmbH in Klingenthal. Cheaper student models are often made in China.




</doc>
<doc id="1164" url="https://en.wikipedia.org/wiki?curid=1164" title="Artificial intelligence">
Artificial intelligence

In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans. Colloquially, the term "artificial intelligence" is often used to describe machines (or computers) that mimic "cognitive" functions that humans associate with the human mind, such as "learning" and "problem solving".

As machines become increasingly capable, tasks considered to require "intelligence" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says "AI is whatever hasn't been done yet." For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology. Modern machine capabilities generally classified as AI include successfully understanding human speech, competing at the highest level in strategic game systems (such as chess and Go), autonomously operating cars, intelligent routing in content delivery networks, and military simulations.

Artificial intelligence can be classified into three different types of systems: analytical, human-inspired, and humanized artificial intelligence. Analytical AI has only characteristics consistent with cognitive intelligence; generating cognitive representation of the world and using learning based on past experience to inform future decisions. Human-inspired AI has elements from cognitive and emotional intelligence; understanding human emotions, in addition to cognitive elements, and considering them in their decision making. Humanized AI shows characteristics of all types of competencies (i.e., cognitive, emotional, and social intelligence), is able to be self-conscious and is self-aware in interactions with others.
Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an "AI winter"), followed by new approaches, success and renewed funding. For most of its history, AI research has been divided into subfields that often fail to communicate with each other. These sub-fields are based on technical considerations, such as particular goals (e.g. "robotics" or "machine learning"), the use of particular tools ("logic" or artificial neural networks), or deep philosophical differences. Subfields have also been based on social factors (particular institutions or the work of particular researchers).
The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects. General intelligence is among the field's long-term goals. Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many other fields.
The field was founded on the claim that human intelligence "can be so precisely described that a machine can be made to simulate it". This raises philosophical arguments about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence which are issues that have been explored by myth, fiction and philosophy since antiquity. Some people also consider AI to be a danger to humanity if it progresses unabated. Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.
In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.

Thought-capable artificial beings appeared as storytelling devices in antiquity, and have been common in fiction, as in Mary Shelley's "Frankenstein" or Karel Čapek's "R.U.R. (Rossum's Universal Robots)". These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.
The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the Church–Turing thesis. Along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain. Turing proposed that "if a human could not distinguish between responses from a machine and a human, the machine could be considered "intelligent". The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons".
The field of AI research was born at a workshop at Dartmouth College in 1956. Attendees Allen Newell (CMU), Herbert Simon (CMU), John McCarthy (MIT), Marvin Minsky (MIT) and Arthur Samuel (IBM) became the founders and leaders of AI research. They and their students produced programs that the press described as "astonishing": computers were learning checkers strategies (c. 1954) (and by 1959 were reportedly playing better than the average human), solving word problems in algebra, proving logical theorems (Logic Theorist, first run c. 1956) and speaking English. By the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense and laboratories had been established around the world. AI's founders were optimistic about the future: Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do". Marvin Minsky agreed, writing, "within a generation ... the problem of creating 'artificial intelligence' will substantially be solved".
They failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an "AI winter", a period when obtaining funding for AI projects was difficult.
In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting hiatus began.
In the late 1990s and early 21st century, AI began to be used for logistics, data mining, medical diagnosis and other areas. The success was due to increasing computational power (see Moore's law), greater emphasis on solving specific problems, new ties between AI and other fields (such as statistics, economics and mathematics), and a commitment by researchers to mathematical methods and scientific standards. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.
In 2011, a "Jeopardy!" quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest "Jeopardy!" champions, Brad Rutter and Ken Jennings, by a significant margin. Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012. The Kinect, which provides a 3D body–motion interface for the Xbox 360 and the Xbox One, uses algorithms that emerged from lengthy AI research as do intelligent personal assistants in smartphones. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. In the 2017 Future of Go Summit, AlphaGo won a three-game match with Ke Jie, who at the time continuously held the world No. 1 ranking for two years. This marked the completion of a significant milestone in the development of Artificial Intelligence as Go is a relatively complex game, more so than Chess.

According to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI Google increased from a "sporadic usage" in 2012 to more than 2,700 projects. Clark also presents factual data indicating the improvements of AI since 2012 supported by lower error rates in image processing tasks. He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets. Other cited examples include Microsoft's development of a Skype system that can automatically translate from one language to another and Facebook's system that can describe images to blind people. In a 2017 survey, one in five companies reported they had "incorporated AI in some offerings or processes". Around 2016, China greatly accelerated its government funding; given its large supply of data and its rapidly increasing research output, some observers believe it may be on track to becoming an "AI superpower".

Computer science defines AI research as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. A more elaborate definition characterizes AI as “a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.”

A typical AI analyzes its environment and takes actions that maximize its chance of success. An AI's intended utility function (or goal) can be simple ("1 if the AI wins a game of Go, 0 otherwise") or complex ("Do mathematically similar actions to the ones succeeded in the past"). Goals can be explicitly defined, or induced. If the AI is programmed for "reinforcement learning", goals can be implicitly induced by rewarding some types of behavior or punishing others. Alternatively, an evolutionary system can induce goals by using a "fitness function" to mutate and preferentially replicate high-scoring AI systems, similarly to how animals evolved to innately desire certain goals such as finding food. Some AI systems, such as nearest-neighbor, instead of reason by analogy, these systems are not generally given goals, except to the degree that goals are implicit in their training data. Such systems can still be benchmarked if the non-goal system is framed as a system whose "goal" is to successfully accomplish its narrow classification task.

AI often revolves around the use of algorithms. An algorithm is a set of unambiguous instructions that a mechanical computer can execute. A complex algorithm is often built on top of other, simpler, algorithms. A simple example of an algorithm is the following (optimal for first player) recipe for play at tic-tac-toe:


Many AI algorithms are capable of learning from data; they can enhance themselves by learning new heuristics (strategies, or "rules of thumb", that have worked well in the past), or can themselves write other algorithms. Some of the "learners" described below, including Bayesian networks, decision trees, and nearest-neighbor, could theoretically, (given infinite data, time, and memory) learn to approximate any function, including which combination of mathematical functions would best describe the world. These learners could therefore, derive all possible knowledge, by considering every possible hypothesis and matching them against the data. In practice, it is almost never possible to consider every possibility, because of the phenomenon of "combinatorial explosion", where the amount of time needed to solve a problem grows exponentially. Much of AI research involves figuring out how to identify and avoid considering broad range of possibilities that are unlikely to be beneficial. For example, when viewing a map and looking for the shortest driving route from Denver to New York in the East, one can in most cases skip looking at any path through San Francisco or other areas far to the West; thus, an AI wielding a pathfinding algorithm like A* can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered in turn.

The earliest (and easiest to understand) approach to AI was symbolism (such as formal logic): "If an otherwise healthy adult has a fever, then they may have influenza". A second, more general, approach is Bayesian inference: "If the current patient has a fever, adjust the probability they have influenza in such-and-such way". The third major approach, extremely popular in routine business AI applications, are analogizers such as SVM and nearest-neighbor: "After examining the records of known past patients whose temperature, symptoms, age, and other factors mostly match the current patient, X% of those patients turned out to have influenza". A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the artificial neural network approach uses artificial "neurons" that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to "reinforce" connections that seemed to be useful. These four main approaches can overlap with each other and with evolutionary systems; for example, neural nets can learn to make inferences, to generalize, and to make analogies. Some systems implicitly or explicitly use multiple of these approaches, alongside many other AI and non-AI algorithms; the best approach is often different depending on the problem.

Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as "since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well". They can be nuanced, such as "X% of families have geographically separate species with color variants, so there is an Y% chance that undiscovered black swans exist". Learners also work on the basis of "Occam's razor": The simplest theory that explains the data is the likeliest. Therefore, according to Occam's razor principle, a learner must be designed such that it prefers simpler theories to complex theories, except in cases where the complex theory is proven substantially better.
Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is. Besides classic overfitting, learners can also disappoint by "learning the wrong lesson". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses. A real-world example is that, unlike humans, current image classifiers don't determine the spatial relationship between components of the picture; instead, they learn abstract patterns of pixels that humans are oblivious to, but that linearly correlate with images of certain types of real objects. Faintly superimposing such a pattern on a legitimate image results in an "adversarial" image that the system misclassifies.
Compared with humans, existing AI lacks several features of human "commonsense reasoning"; most notably, humans have powerful mechanisms for reasoning about "naïve physics" such as space, time, and physical interactions. This enables even young children to easily make inferences like "If I roll this pen off a table, it will fall on the floor". Humans also have a powerful mechanism of "folk psychology" that helps them to interpret natural-language sentences such as "The city councilmen refused the demonstrators a permit because they advocated violence". (A generic AI has difficulty discerning whether the ones alleged to be advocating violence are the councilmen or the demonstrators.) This lack of "common knowledge" means that AI often makes different mistakes than humans make, in ways that can seem incomprehensible. For example, existing self-driving cars cannot reason about the location nor the intentions of pedestrians in the exact way that humans do, and instead must use non-human modes of reasoning to avoid accidents.

The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.

Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.

These algorithms proved to be insufficient for solving large reasoning problems, because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger. In fact, even humans rarely use the step-by-step deduction that early AI research was able to model. They solve most of their problems using fast, intuitive judgements.

Knowledge representation and knowledge engineering are central to classical AI research. Some "expert systems" attempt to gather together explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects; situations, events, states and time; causes and effects; knowledge about knowledge (what we know about what other people know); and many other, less well researched domains. A representation of "what exists" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The semantics of these are captured as description logic concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the Web Ontology Language. The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge by acting as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining "interesting" and actionable inferences from large databases), and other areas.

Among the most difficult problems in knowledge representation are:

Intelligent agents must be able to set goals and achieve them. They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the utility (or "value") of available choices.

In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions. However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions, but also evaluate its predictions and adapt based on its assessment.

Multi-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.

Machine learning (ML), a fundamental concept of AI research since the field's inception, is the study of computer algorithms that improve automatically through experience.

Unsupervised learning is the ability to find patterns in a stream of input, without requiring a human to label the inputs first. Supervised learning includes both classification and numerical regression, which requires a human to label the input data first. Classification is used to determine what category something belongs in, and occurs after a program sees a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam". Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization. In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.

Natural language processing (NLP) gives machines the ability to read and understand human language. A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include information retrieval, text mining, question answering and machine translation. Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. "Keyword spotting" strategies for search are popular and scalable but dumb; a search query for "dog" might only match documents with the literal word "dog" and miss a document with the word "poodle". "Lexical affinity" strategies use the occurrence of words such as "accident" to assess the sentiment of a document. Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level, but continue to lack the semantic understanding required to classify isolated sentences well. Besides the usual difficulties with encoding semantic commonsense knowledge, existing semantic NLP sometimes scales too poorly to be viable in business applications. Beyond semantic NLP, the ultimate goal of "narrative" NLP is to embody a full understanding of commonsense reasoning.

Machine perception is the ability to use input from sensors (such as cameras (visible spectrum or infrared), microphones, wireless signals, and active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Applications include speech recognition, facial recognition, and object recognition. Computer vision is the ability to analyze visual input. Such input is usually ambiguous; a giant, fifty-meter-tall pedestrian far away may produce exactly the same pixels as a nearby normal-sized pedestrian, requiring the AI to judge the relative likelihood and reasonableness of different interpretations, for example by using its "object model" to assess that fifty-meter pedestrians do not exist.

AI is heavily used in robotics. Advanced robotic arms and other industrial robots, widely used in modern factories, can learn from experience how to move efficiently despite the presence of friction and gear slippage. A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and map its environment; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge. Motion planning is the process of breaking down a movement task into "primitives" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object. Moravec's paradox generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after Hans Moravec, who stated in 1988 that "it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility". This is attributed to the fact that, unlike checkers, physical dexterity has been a direct target of natural selection for millions of years.

Moravec's paradox can be extended to many forms of social intelligence. Distributed multi-agent coordination of autonomous vehicles remains a difficult problem. Affective computing is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human affects. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal affect analysis (see multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject.

In the long run, social skills and an understanding of human emotion and game theory would be valuable to a social agent. Being able to predict the actions of others by understanding their motives and emotional states would allow an agent to make better decisions. Some computer systems mimic human emotion and expressions to appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction. Similarly, some virtual assistants are programmed to speak conversationally or even to banter humorously; this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.

Historically, projects such as the Cyc knowledge base (1984–) and the massive Japanese Fifth Generation Computer Systems initiative (1982–1992) attempted to cover the breadth of human cognition. These early projects failed to escape the limitations of non-quantitative symbolic logic models and, in retrospect, greatly underestimated the difficulty of cross-domain AI. Nowadays, the vast majority of current AI researchers work instead on tractable "narrow AI" applications (such as medical diagnosis or automobile navigation). Many researchers predict that such "narrow AI" work in different individual domains will eventually be incorporated into a machine with artificial general intelligence (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas. Many advances have general, cross-domain significance. One high-profile example is that DeepMind in the 2010s developed a "generalized artificial intelligence" that could learn many diverse Atari games on its own, and later developed a variant of the system which succeeds at . Besides transfer learning, hypothetical AGI breakthroughs could include the development of reflective architectures that can engage in decision-theoretic metareasoning, and figuring out how to "slurp up" a comprehensive knowledge base from the entire unstructured Web. Some argue that some kind of (currently-undiscovered) conceptually straightforward, but mathematically difficult, "Master Algorithm" could lead to AGI. Finally, a few "emergent" approaches look to simulating human intelligence extremely closely, and believe that anthropomorphic features like an artificial brain or simulated child development may someday reach a critical point where general intelligence emerges.

Many of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do. For example, even specific straightforward tasks, like machine translation, require that a machine read and write in both languages (NLP), follow the author's argument (reason), know what is being talked about (knowledge), and faithfully reproduce the author's original intent (social intelligence). A problem like machine translation is considered "AI-complete", because all of these problems need to be solved simultaneously in order to reach human-level machine performance.

There is no established unifying theory or paradigm that guides AI research. Researchers disagree about many issues. A few of the most long standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying psychology or neurobiology? Or is human biology as irrelevant to AI research as bird biology is to aeronautical engineering?
Can intelligent behavior be described using simple, elegant principles (such as logic or optimization)? Or does it necessarily require solving a large number of completely unrelated problems?

In the 1940s and 1950s, a number of researchers explored the connection between neurobiology, information theory, and cybernetics. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as W. Grey Walter's turtles and the Johns Hopkins Beast. Many of these researchers gathered for meetings of the Teleological Society at Princeton University and the Ratio Club in England. By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.

When access to digital computers became possible in the middle 1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions: Carnegie Mellon University, Stanford and MIT, and as described below, each one developed its own style of research. John Haugeland named these symbolic approaches to AI "good old fashioned AI" or "GOFAI". During the 1960s, symbolic approaches had achieved great success at simulating high-level thinking in small demonstration programs. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.
Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.

Economist Herbert Simon and Allen Newell studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as cognitive science, operations research and management science. Their research team used the results of psychological experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s.

Unlike Simon and Newell, John McCarthy felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem-solving, regardless whether people used the same algorithms. His laboratory at Stanford (SAIL) focused on using formal logic to solve a wide variety of problems, including knowledge representation, planning and learning. Logic was also the focus of the work at the University of Edinburgh and elsewhere in Europe which led to the development of the programming language Prolog and the science of logic programming.

Researchers at MIT (such as Marvin Minsky and Seymour Papert) found that solving difficult problems in vision and natural language processing required ad-hoc solutions—they argued that there was no simple and general principle (like logic) that would capture all the aspects of intelligent behavior. Roger Schank described their "anti-logic" approaches as "scruffy" (as opposed to the "neat" paradigms at CMU and Stanford). Commonsense knowledge bases (such as Doug Lenat's Cyc) are an example of "scruffy" AI, since they must be built by hand, one complicated concept at a time.

When computers with large memories became available around 1970, researchers from all three traditions began to build knowledge into AI applications. This "knowledge revolution" led to the development and deployment of expert systems (introduced by Edward Feigenbaum), the first truly successful form of AI software. A key component of the system architecture for all expert systems is the knowledge base, which stores facts and rules that illustrate AI. The knowledge revolution was also driven by the realization that enormous amounts of knowledge would be required by many simple AI applications.

By the 1980s, progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into "sub-symbolic" approaches to specific AI problems. Sub-symbolic methods manage to approach intelligence without specific representations of knowledge.

This includes embodied, situated, behavior-based, and nouvelle AI. Researchers from the related field of robotics, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move and survive. Their work revived the non-symbolic point of view of the early cybernetics researchers of the 1950s and reintroduced the use of control theory in AI. This coincided with the development of the embodied mind thesis in the related field of cognitive science: the idea that aspects of the body (such as movement, perception and visualization) are required for higher intelligence.

Within developmental robotics, developmental learning approaches are elaborated upon to allow robots to accumulate repertoires of novel skills through autonomous self-exploration, social interaction with human teachers, and the use of guidance mechanisms (active learning, maturation, motor synergies, etc.).

Interest in neural networks and "connectionism" was revived by David Rumelhart and others in the middle of the 1980s. Artificial neural networks are an example of soft computing—they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often sufficient. Other soft computing approaches to AI include fuzzy systems, Grey system theory, evolutionary computation and many statistical tools. The application of soft computing to AI is studied collectively by the emerging discipline of computational intelligence.

Much of traditional GOFAI got bogged down on "ad hoc" patches to symbolic computation that worked on their own toy models but failed to generalize to real-world results. However, around the 1990s, AI researchers adopted sophisticated mathematical tools, such as hidden Markov models (HMM), information theory, and normative Bayesian decision theory to compare or to unify competing architectures. The shared mathematical language permitted a high level of collaboration with more established fields (like mathematics, economics or operations research). Compared with GOFAI, new "statistical learning" techniques such as HMM and neural networks were gaining higher levels of accuracy in many practical domains such as data mining, without necessarily acquiring semantic understanding of the datasets. The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more scientific. Nowadays results of experiments are often rigorously measurable, and are sometimes (with difficulty) reproducible. Different statistical learning techniques have different limitations; for example, basic HMM cannot model the infinite possible combinations of natural language. Critics note that the shift from GOFAI to statistical learning is often also a shift away from Explainable AI. In AGI research, some scholars caution against over-reliance on statistical learning, and argue that continuing research into GOFAI will still be necessary to attain general intelligence.



AI has developed a large number of tools to solve the most difficult problems in computer science. A few of the most general of these methods are discussed below.

Many problems in AI can be solved in theory by intelligently searching through many possible solutions: Reasoning can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an inference rule. Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis. Robotics algorithms for moving limbs and grasping objects use local searches in configuration space. Many learning algorithms use search algorithms based on optimization.

Simple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use "heuristics" or "rules of thumb" that prioritize choices in favor of those that are more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies heuristics can also serve to entirely eliminate some choices that are unlikely to lead to a goal (called "pruning the search tree"). Heuristics supply the program with a "best guess" for the path on which the solution lies. Heuristics limit the search for solutions into a smaller sample size.

A very different kind of search came to prominence in the 1990s, based on the mathematical theory of optimization. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are simulated annealing, beam search and random optimization.
Evolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses). Classic evolutionary algorithms include genetic algorithms, gene expression programming, and genetic programming. Alternatively, distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).

Logic is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the satplan algorithm uses logic for planning and inductive logic programming is a method for learning.

Several different forms of logic are used in AI research. Propositional logic involves truth functions such as "or" and "not". First-order logic adds quantifiers and predicates, and can express facts about objects, their properties, and their relations with each other. Fuzzy set theory assigns a "degree of truth" (between 0 and 1) to vague statements such as "Alice is old" (or rich, or tall, or hungry) that are too linguistically imprecise to be completely true or false. Fuzzy logic is successfully used in control systems to allow experts to contribute vague rules such as "if you are close to the destination station and moving fast, increase the train's brake pressure"; these vague rules can then be numerically refined within the system. Fuzzy logic fails to scale well in knowledge bases; many AI researchers question the validity of chaining fuzzy-logic inferences.

Default logics, non-monotonic logics and circumscription are forms of logic designed to help with default reasoning and the qualification problem. Several extensions of logic have been designed to handle specific domains of knowledge, such as: description logics; situation calculus, event calculus and fluent calculus (for representing events and time); causal calculus; belief calculus; and modal logics.

Overall, qualitative symbolic logic is brittle and scales poorly in the presence of noise or other uncertainty. Exceptions to rules are numerous, and it is difficult for logical systems to function in the presence of contradictory rules.

Many problems in AI (in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from probability theory and economics.

Bayesian networks are a very general tool that can be used for a large number of problems: reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks). Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters). Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. Complicated graphs with diamonds or other "loops" (undirected cycles) can require a sophisticated method such as Markov chain Monte Carlo, which spreads an ensemble of random walkers throughout the Bayesian network and attempts to converge to an assessment of the conditional probabilities. Bayesian networks are used on Xbox Live to rate and match players; wins and losses are "evidence" of how good a player is. AdSense uses a Bayesian network with over 300 million edges to learn which ads to serve.

A key concept from the science of economics is "utility": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.

The simplest AI applications can be divided into two types: classifiers ("if shiny then diamond") and controllers ("if shiny then pick up"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems. Classifiers are functions that use pattern matching to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class can be seen as a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.

A classifier can be trained in various ways; there are many statistical and machine learning approaches. The decision tree is perhaps the most widely used machine learning algorithm. Other widely used classifiers are the neural network,
k-nearest neighbor algorithm,
kernel methods such as the support vector machine (SVM),
Gaussian mixture model, and the extremely popular naive Bayes classifier. Classifier performance depends greatly on the characteristics of the data to be classified, such as the dataset size, distribution of samples across classes, the dimensionality, and the level of noise. Model-based classifiers perform well if the assumed model is an extremely good fit for the actual data. Otherwise, if no matching model is available, and if accuracy (rather than speed or scalability) is the sole concern, conventional wisdom is that discriminative classifiers (especially SVM) tend to be more accurate than model-based classifiers such as "naive Bayes" on most practical data sets.

Neural networks, or neural nets, were inspired by the architecture of neurons in the human brain. A simple "neuron" "N" accepts input from multiple other neurons, each of which, when activated (or "fired"), cast a weighted "vote" for or against whether neuron "N" should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed "fire together, wire together") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The net forms "concepts" that are distributed among a subnetwork of shared neurons that tend to fire together; a concept meaning "leg" might be coupled with a subnetwork meaning "foot" that includes the sound for "foot". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural nets can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car. In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related M&A in 2017 was over 25 times as large as in 2015.

The study of non-learning artificial neural networks began in the decade before the field of AI research was founded, in the work of Walter Pitts and Warren McCullouch. Frank Rosenblatt invented the perceptron, a learning network with a single layer, similar to the old concept of linear regression. Early pioneers also include Alexey Grigorevich Ivakhnenko, Teuvo Kohonen, Stephen Grossberg, Kunihiko Fukushima, Christoph von der Malsburg, David Willshaw, Shun-Ichi Amari, Bernard Widrow, John Hopfield, Eduardo R. Caianiello, and others.

The main categories of networks are acyclic or feedforward neural networks (where the signal passes in only one direction) and recurrent neural networks (which allow feedback and short-term memories of previous input events). Among the most popular feedforward networks are perceptrons, multi-layer perceptrons and radial basis networks. Neural networks can be applied to the problem of intelligent control (for robotics) or learning, using such techniques as Hebbian learning ("fire together, wire together"), GMDH or competitive learning.

Today, neural networks are often trained by the backpropagation algorithm, which had been around since 1970 as the reverse mode of automatic differentiation published by Seppo Linnainmaa, and was introduced to neural networks by Paul Werbos.

Hierarchical temporal memory is an approach that models some of the structural and algorithmic properties of the neocortex.

To summarize, most neural networks use some form of gradient descent on a hand-created neural topology. However, some research groups, such as Uber, argue that simple neuroevolution to mutate new neural network topologies and weights may be competitive with sophisticated gradient descent approaches. One advantage of neuroevolution is that it may be less prone to get caught in "dead ends".

Deep learning is any artificial neural network that can learn a long chain of causal links. For example, a feedforward network with six hidden layers can learn a seven-link causal chain (six hidden layers + output layer) and has a "credit assignment path" (CAP) depth of seven. Many deep learning systems need to be able to learn chains ten or more causal links in length. Deep learning has transformed many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing and others.

According to one overview, the expression "Deep Learning" was introduced to the machine learning community by Rina Dechter in 1986 and gained traction after
Igor Aizenberg and colleagues introduced it to artificial neural networks in 2000. The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965. These networks are trained one layer at a time. Ivakhnenko's 1971 paper describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.

Deep learning often uses convolutional neural networks (CNNs), whose origins can be traced back to the Neocognitron introduced by Kunihiko Fukushima in 1980. In 1989, Yann LeCun and colleagues applied backpropagation to such an architecture. In the early 2000s, in an industrial application CNNs already processed an estimated 10% to 20% of all the checks written in the US.
Since 2011, fast implementations of CNNs on GPUs have
won many visual pattern recognition competitions.

CNNs with 12 convolutional layers were used in conjunction with reinforcement learning by Deepmind's "AlphaGo Lee", the program that beat a top Go champion in 2016.

Early on, deep learning was also applied to sequence learning with recurrent neural networks (RNNs) which are in theory Turing complete and can run arbitrary programs to process arbitrary sequences of inputs. The depth of an RNN is unlimited and depends on the length of its input sequence; thus, an RNN is an example of deep learning. RNNs can be trained by gradient descent but suffer from the vanishing gradient problem. In 1992, it was shown that unsupervised pre-training of a stack of recurrent neural networks can speed up subsequent supervised learning of deep sequential problems.

Numerous researchers now use variants of a deep learning recurrent NN called the long short-term memory (LSTM) network published by Hochreiter & Schmidhuber in 1997. LSTM is often trained by Connectionist Temporal Classification (CTC). At Google, Microsoft and Baidu this approach has revolutionised speech recognition. For example, in 2015, Google's speech recognition experienced a dramatic performance jump of 49% through CTC-trained LSTM, which is now available through Google Voice to billions of smartphone users. Google also used LSTM to improve machine translation, Language Modeling and Multilingual Language Processing. LSTM combined with CNNs also improved automatic image captioning and a plethora of other applications.

AI, like electricity or the steam engine, is a general purpose technology. There is no consensus on how to characterize which tasks AI tends to excel at. While projects such as AlphaZero have succeeded in generating their own knowledge from scratch, many other machine learning projects require large training datasets. Researcher Andrew Ng has suggested, as a "highly imperfect rule of thumb", that "almost anything a typical human can do with less than one second of mental thought, we can probably now or in the near future automate using AI." Moravec's paradox suggests that AI lags humans at many tasks that the human brain has specifically evolved to perform well.

Games provide a well-publicized benchmark for assessing rates of progress. AlphaGo around 2016 brought the era of classical board-game benchmarks to a close. Games of imperfect knowledge provide new challenges to AI in the area of game theory. E-sports such as StarCraft continue to provide additional public benchmarks. There are many competitions and prizes, such as the Imagenet Challenge, to promote research in artificial intelligence. The most common areas of competition include general machine intelligence, conversational behavior, data-mining, robotic cars, and robot soccer as well as conventional games.

The "imitation game" (an interpretation of the 1950 Turing test that assesses whether a computer can imitate a human) is nowadays considered too exploitable to be a meaningful benchmark. A derivative of the Turing test is the Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). As the name implies, this helps to determine that a user is an actual person and not a computer posing as a human. In contrast to the standard Turing test, CAPTCHA is administered by a machine and targeted to a human as opposed to being administered by a human and targeted to a machine. A computer asks a user to complete a simple test then generates a grade for that test. Computers are unable to solve the problem, so correct solutions are deemed to be the result of a person taking the test. A common type of CAPTCHA is the test that requires the typing of distorted letters, numbers or symbols that appear in an image undecipherable by a computer.

Proposed "universal intelligence" tests aim to compare how well machines, humans, and even non-human animals perform on problem sets that are generic as possible. At an extreme, the test suite can contain every possible problem, weighted by Kolmogorov complexity; unfortunately, these problem sets tend to be dominated by impoverished pattern-matching exercises where a tuned AI can easily exceed human performance levels.

AI is relevant to any intellectual task. Modern artificial intelligence techniques are pervasive and are too numerous to list here. Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.

High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google search), online assistants (such as Siri), image recognition in photographs, spam filtering, predicting flight delays, prediction of judicial decisions and targeting online advertisements.

With social media sites overtaking TV as a source for news for young people and news organizations increasingly reliant on social media platforms for generating distribution, major publishers now use artificial intelligence (AI) technology to post stories more effectively and generate higher volumes of traffic.

AI is being applied to the high cost problem of dosage issues—where findings suggested that AI could save $16 billion. In 2016, a ground breaking study in California found that a mathematical formula developed with the help of AI correctly determined the accurate dose of immunosuppressant drugs to give to organ patients. 
Artificial intelligence is breaking into the healthcare industry by assisting doctors. According to Bloomberg Technology, Microsoft has developed AI to help doctors find the right treatments for cancer. There is a great amount of research and drugs developed relating to cancer. In detail, there are more than 800 medicines and vaccines to treat cancer. This negatively affects the doctors, because there are too many options to choose from, making it more difficult to choose the right drugs for the patients. Microsoft is working on a project to develop a machine called "Hanover". Its goal is to memorize all the papers necessary to cancer and help predict which combinations of drugs will be most effective for each patient. One project that is being worked on at the moment is fighting myeloid leukemia, a fatal cancer where the treatment has not improved in decades. Another study was reported to have found that artificial intelligence was as good as trained doctors in identifying skin cancers. Another study is using artificial intelligence to try and monitor multiple high-risk patients, and this is done by asking each patient numerous questions based on data acquired from live doctor to patient interactions. One study was done with transfer learning, the machine performed a diagnosis similarly to a well-trained ophthalmologist, and could generate a decision within 30 seconds on whether or not the patient should be referred for treatment, with more than 95% accuracy.

According to CNN, a recent study by surgeons at the Children's National Medical Center in Washington successfully demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel during open surgery, and doing so better than a human surgeon, the team claimed. IBM has created its own artificial intelligence computer, the IBM Watson, which has beaten human intelligence (at some levels). Watson not only won at the game show "Jeopardy!" against former champions, but was declared a hero after successfully diagnosing a woman who was suffering from leukemia.

Advancements in AI have contributed to the growth of the automotive industry through the creation and evolution of self-driving vehicles. , there are over 30 companies utilizing AI into the creation of driverless cars. A few companies involved with AI include Tesla, Google, and Apple.

Many components contribute to the functioning of self-driving cars. These vehicles incorporate systems such as braking, lane changing, collision prevention, navigation and mapping. Together, these systems, as well as high performance computers, are integrated into one complex vehicle.

Recent developments in autonomous automobiles have made the innovation of self-driving trucks possible, though they are still in the testing phase. The UK government has passed legislation to begin testing of self-driving truck platoons in 2018. Self-driving truck platoons are a fleet of self-driving trucks following the lead of one non-self-driving truck, so the truck platoons aren't entirely autonomous yet. Meanwhile, the Daimler, a German automobile corporation, is testing the Freightliner Inspiration which is a semi-autonomous truck that will only be used on the highway.

One main factor that influences the ability for a driver-less automobile to function is mapping. In general, the vehicle would be pre-programmed with a map of the area being driven. This map would include data on the approximations of street light and curb heights in order for the vehicle to be aware of its surroundings. However, Google has been working on an algorithm with the purpose of eliminating the need for pre-programmed maps and instead, creating a device that would be able to adjust to a variety of new surroundings. Some self-driving cars are not equipped with steering wheels or brake pedals, so there has also been research focused on creating an algorithm that is capable of maintaining a safe environment for the passengers in the vehicle through awareness of speed and driving conditions.

Another factor that is influencing the ability for a driver-less automobile is the safety of the passenger. To make a driver-less automobile, engineers must program it to handle high-risk situations. These situations could include a head-on collision with pedestrians. The car's main goal should be to make a decision that would avoid hitting the pedestrians and saving the passengers in the car. But there is a possibility the car would need to make a decision that would put someone in danger. In other words, the car would need to decide to save the pedestrians or the passengers. The programming of the car in these situations is crucial to a successful driver-less automobile.

Financial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking can be traced back to 1987 when Security Pacific National Bank in US set-up a Fraud Prevention Task force to counter the unauthorized use of debit cards. Programs like Kasisto and Moneystream are using AI in financial services.

Banks use artificial intelligence systems today to organize operations, maintain book-keeping, invest in stocks, and manage properties. AI can react to changes overnight or when business is not taking place. In August 2001, robots beat humans in a simulated financial trading competition. AI has also reduced fraud and financial crimes by monitoring behavioral patterns of users for any abnormal changes or anomalies.

The use of AI machines in the market in applications such as online trading and decision making has changed major economic theories. For example, AI based buying and selling platforms have changed the law of supply and demand in that it is now possible to easily estimate individualized demand and supply curves and thus individualized pricing. Furthermore, AI machines reduce information asymmetry in the market and thus making markets more efficient while reducing the volume of trades. Furthermore, AI in the markets limits the consequences of behavior in the markets again making markets more efficient. Other theories where AI has had impact include in rational choice, rational expectations, game theory, Lewis turning point, portfolio optimization and counterfactual thinking.

In video games, artificial intelligence is routinely used to generate dynamic purposeful behavior in non-player characters (NPCs). In addition, well-understood AI techniques are routinely used for pathfinding. Some researchers consider NPC AI in games to be a "solved problem" for most production tasks. Games with more atypical AI include the AI director of "Left 4 Dead" (2008) and the neuroevolutionary training of platoons in "Supreme Commander 2" (2010).

Worldwide annual military spending on robotics rose from US$5.1 billion in 2010 to US$7.5 billion in 2015. Military drones capable of autonomous action are widely considered a useful asset. Many artificial intelligence researchers seek to distance themselves from military applications of AI.

For financial statements audit, AI makes continuous audit possible. AI tools could analyze many sets of different information immediately. The potential benefit would be the overall audit risk will be reduced, the level of assurance will be increased and the time duration of audit will be reduced.

It is possible to use AI to predict or generalize the behavior of customers from their digital footprints in order to target them with personalized promotions or build customer personas automatically. A documented case reports that online gambling companies were using AI to improve customer targeting.

Moreover, the application of Personality computing AI models can help reducing the cost of advertising campaigns by adding psychological targeting to more traditional sociodemographic or behavioral targeting.

Artificial Intelligence has inspired numerous creative applications including its usage to produce visual art. The exhibition "Thinking Machines: Art and Design in the Computer Age, 1959–1989" at MoMA provides a good overview of the historical applications of AI for art, architecture, and design. Recent exhibitions showcasing the usage of AI to produce art include the Google-sponsored benefit and auction at the Gray Area Foundation in San Francisco, where artists experimented with the deepdream algorithm and the exhibition "Unhuman: Art in the Age of AI," which took place in Los Angeles and Frankfurt in the fall of 2017. In the spring of 2018, the Association of Computing Machinery dedicated a special magazine issue to the subject of computers and art highlighting the role of machine learning in the arts.

There are three philosophical questions related to AI:

Can a machine be intelligent? Can it "think"?







Widespread use of artificial intelligence could have unintended consequences that are dangerous or undesirable. Scientists from the Future of Life Institute, among others, described some short-term research goals to see how AI influences the economy, the laws and ethics that are involved with AI and how to minimize AI security risks. In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies.

The potential negative effects of AI and automation are a major issue for Andrew Yang's presidential campaign.

Physicist Stephen Hawking, Microsoft founder Bill Gates, and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could evolve to the point that humans could not control it, with Hawking theorizing that this could "spell the end of the human race".

In his book "", Nick Bostrom provides an argument that artificial intelligence will pose a threat to humankind. He argues that sufficiently intelligent AI, if it chooses actions based on achieving some goal, will exhibit convergent behavior such as acquiring resources or protecting itself from being shut down. If this AI's goals do not reflect humanity's—one example is an AI told to compute as many digits of pi as possible—it might harm humanity in order to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal.

Concern over risk from artificial intelligence has led to some high-profile donations and investments. A group of prominent tech titans including Peter Thiel, Amazon Web Services and Musk have committed $1billion to OpenAI, a nonprofit company aimed at championing responsible AI development. The opinion of experts within the field of artificial intelligence is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI. Other technology industry leaders believe that artificial intelligence is helpful in its current form and will continue to assist humans. Oracle CEO Mark Hurd has stated that AI "will actually create more jobs, not less jobs" as humans will be needed to manage AI systems. Facebook CEO Mark Zuckerberg believes AI will "unlock a huge amount of positive things," such as curing disease and increasing the safety of autonomous cars.

In January 2015, Elon Musk donated ten million dollars to the Future of Life Institute to fund research on understanding AI decision making. The goal of the institute is to "grow wisdom with which we manage" the growing power of technology. Musk also funds companies developing artificial intelligence such as Google DeepMind and Vicarious to "just keep an eye on what's going on with artificial intelligence. I think there is potentially a dangerous outcome there."

For this danger to be realized, the hypothetical AI would have to overpower or out-think all of humanity, which a minority of experts argue is a possibility far enough in the future to not be worth researching. Other counterarguments revolve around humans being either intrinsically or convergently valuable from the perspective of an artificial intelligence.

Joseph Weizenbaum wrote that AI applications cannot, by definition, successfully simulate genuine human empathy and that the use of AI technology in fields such as customer service or psychotherapy was deeply misguided. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position is now known as computationalism). To Weizenbaum these points suggest that AI research devalues human life.

One concern is that AI programs may be programmed to be biased against certain groups, such as women and minorities, because most of the developers are wealthy Caucasian men. Support for artificial intelligence is higher among men (with 47% approving) than women (35% approving).

Algorithms have a host of applications in today’s legal system already, assisting officials ranging from judges to parole officers and public defenders in gauging the predicted likelihood of recidivism of defendants. COMPAS (an acronym for Correctional Offender Management Profiling for Alternative Sanctions) counts among the most widely utilized commercially available solutions. It has been suggested that COMPAS assigns an exceptionally elevated risk of recidivism to black defendants while, conversely, ascribing a statistically unexpectedly frequent low risk estimate to white defendants.

The relationship between automation and employment is complicated. While automation eliminates old jobs, it also creates new jobs through micro-economic and macro-economic effects. Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; "The Economist" states that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously". Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. Author Martin Ford and others go further and argue that a large number of jobs are routine, repetitive and (to an AI) predictable; Ford warns that these jobs may be automated in the next couple of decades, and that many of the new jobs may not be "accessible to people with average capability", even with retraining. Economists point out that in the past technology has tended to increase rather than reduce total employment, but acknowledge that "we're in uncharted territory" with AI.

Currently, 50+ countries are researching battlefield robots, including the United States, China, Russia, and the United Kingdom. Many people concerned about risk from superintelligent AI also want to limit the use of artificial soldiers and drones.

Machines with intelligence have the potential to use their intelligence to prevent harm and minimize the risks; they may have the ability to use ethical reasoning to better choose their actions in the world. Research in this area includes machine ethics, artificial moral agents, and friendly AI.

Wendell Wallach introduced the concept of artificial moral agents (AMA) in his book "Moral Machines" For Wallach, AMAs have become a part of the research landscape of artificial intelligence as guided by its two central questions which he identifies as "Does Humanity Want Computers Making Moral Decisions" and "Can (Ro)bots Really Be Moral". For Wallach the question is not centered on the issue of "whether" machines can demonstrate the equivalent of moral behavior in contrast to the "constraints" which society may place on the development of AMAs.

The field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making. The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: "Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In all cases, only human beings have engaged in ethical reasoning. The time has come for adding an ethical dimension to at least some machines. Recognition of the ethical ramifications of behavior involving machines, as well as recent and potential developments in machine autonomy, necessitate this. In contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics, machine ethics is concerned with the behavior of machines towards human users and other machines. Research in machine ethics is key to alleviating concerns with autonomous systems—it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine intelligence. Further, investigation of machine ethics could enable the discovery of problems with current ethical theories, advancing our thinking about Ethics." Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. A variety of perspectives of this nascent field can be found in the collected edition "Machine Ethics" that stems from the AAAI Fall 2005 Symposium on Machine Ethics.

Political scientist Charles T. Rubin believes that AI can be neither designed nor guaranteed to be benevolent. He argues that "any sufficiently advanced benevolence may be indistinguishable from malevolence." Humans should not assume machines or robots would treat us favorably because there is no "a priori" reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share). Hyper-intelligent software may not necessarily decide to support the continued existence of humanity and would be extremely difficult to stop. This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.

One proposal to deal with this is to ensure that the first generally intelligent AI is 'Friendly AI' and will be able to control subsequently developed AIs. Some question whether this kind of check could actually remain in place.

Leading AI researcher Rodney Brooks writes, "I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI, and the enormity and complexity of building sentient volitional intelligence."

If an AI system replicates all key aspects of human intelligence, will that system also be sentient—will it have a mind which has conscious experiences? This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the hard problem of consciousness.

David Chalmers identified two problems in understanding the mind, which he named the "hard" and "easy" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this "feels" or why it should feel like anything at all. Human information processing is easy to explain, however human subjective experience is difficult to explain.

For example, consider what happens when a person is shown a color swatch and identifies it, saying "it's red". The easy problem only requires understanding the machinery in the brain that makes it possible for a person to know that the color swatch is red. The hard problem is that people also know something else—they also know "what red looks like". (Consider that a person born blind can know that something is red without knowing what red looks like.) Everyone knows subjective experience exists, because they do it every day (e.g., all sighted people know what red looks like). The hard problem is explaining how the brain creates it, why it exists, and how it is different from knowledge and other aspects of the brain.

Computationalism is the position in the philosophy of mind that the human mind or the human brain (or both) is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind-body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.

The philosophical position that John Searle has named "strong AI" states: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds." Searle counters this assertion with his Chinese room argument, which asks us to look "inside" the computer and try to find where the "mind" might be.

If a machine can be created that has intelligence, could it also "feel"? If it can feel, does it have the same rights as a human? This issue, now known as "robot rights", is currently being considered by, for example, California's Institute for the Future, although many critics believe that the discussion is premature. Some critics of transhumanism argue that any hypothetical robot rights would lie on a spectrum with animal rights and human rights. The subject is profoundly discussed in the 2010 documentary film "Plug & Pray", and many sci fi media such as Star Trek Next Generation, with the character of Commander Data, who fought being disassembled for research, and wanted to "become human", and the robotic holograms in Voyager.

Are there limits to how intelligent machines—or human-machine hybrids—can be? A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. "Superintelligence" may also refer to the form or degree of intelligence possessed by such an agent.

If research into Strong AI produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to recursive self-improvement. The new intelligence could thus increase exponentially and dramatically surpass humans. Science fiction writer Vernor Vinge named this scenario "singularity". Technological singularity is when accelerating progress in technologies will cause a runaway effect wherein artificial intelligence will exceed human intellectual capacity and control, thus radically changing or even ending civilization. Because the capabilities of such an intelligence may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.

Ray Kurzweil has used Moore's law (which describes the relentless exponential improvement in digital technology) to calculate that desktop computers will have the same processing power as human brains by the year 2029, and predicts that the singularity will occur in 2045.

Robot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, which has roots in Aldous Huxley and Robert Ettinger.

Edward Fredkin argues that "artificial intelligence is the next stage in evolution", an idea first proposed by Samuel Butler's "Darwin among the Machines" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.

The long-term economic effects of AI are uncertain. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit, if productivity gains are redistributed.

Thought-capable artificial beings appeared as storytelling devices since antiquity,
and have been a persistent theme in science fiction.

A common trope in these works began with Mary Shelley's "Frankenstein", where a human creation becomes a threat to its masters. This includes such works as and "" (both 1968), with HAL 9000, the murderous computer in charge of the "Discovery One" spaceship, as well as "The Terminator" (1984) and "The Matrix" (1999). In contrast, the rare loyal robots such as Gort from "The Day the Earth Stood Still" (1951) and Bishop from "Aliens" (1986) are less prominent in popular culture.

Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the "Multivac" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.

Transhumanism (the merging of humans and machines) is explored in the manga "Ghost in the Shell" and the science-fiction series "Dune". In the 1980s, artist Hajime Sorayama's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later "the Gynoids" book followed that was used by or influenced movie makers including George Lucas and other creatives. Sorayama never considered these organic robots to be real part of nature but always unnatural product of the human mind, a fantasy existing in the mind even when realized in actual form.

Several works use AI to force us to confront the fundamental of question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's "R.U.R.", the films "A.I. Artificial Intelligence" and "Ex Machina", as well as the novel "Do Androids Dream of Electric Sheep?", by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.




</doc>
<doc id="1166" url="https://en.wikipedia.org/wiki?curid=1166" title="Afro Celt Sound System">
Afro Celt Sound System

Their albums have been released through Peter Gabriel's Real World Records, and they have frequently performed at WOMAD festivals worldwide. Their sales on the label are exceeded only by Gabriel himself. Their recording contract with Real World was for five albums, of which "Volume 5: Anatomic" was the last.

After a number of festival dates in 2007, the band went on hiatus. In 2010, they regrouped to play a number of shows (including a return to WOMAD), releasing a re-mastered retrospective titled "Capture."

On 20 May 2014 Afro Celt Sound System announced the upcoming release of a new album, "Born". In January 2016, a posting to that website revealed that due to a dispute with Emmerson, who announced his departure from the band in 2015, there were two active versions of the band, a version led by Emmerson and a separate line-up headed by James McNally and Martin Russell. Emmerson's version of the band released the album "The Source" in 2016. The dispute ended on 21 December 2016, with an announcement on social media.

The inspiration behind the project dates back to 1991, when Simon Emmerson, a Grammy Award-nominated British producer and guitarist, collaborated with Afro-pop star Baaba Maal. While making an album with Maal in Senegal, Emmerson was struck by the similarity between one African melody and a traditional Irish air. Back in London, Irish musician Davy Spillane told Emmerson about a belief that nomadic Celts lived in Africa or India before they migrated to Western Europe. Whether or not the theory was true, Emmerson was intrigued by the two countries' musical affinities.

In an experiment that would prove successful, Emmerson brought two members of Baaba Maal's band together with traditional Irish musicians to see what kind of music the two groups would create. Adding a dash of modern sound, Emmerson also brought in English dance mixers for an electronic beat. "People thought I was mad when I touted the idea," Emmerson told Jim Carroll of "The Irish Times". "At the time, I was out of favour with the London club scene. I was broke and on income support but the success was extraordinary".

Jamming in the studios at Real World, musician Peter Gabriel's recording facilities in Wiltshire, England, the diverse group of musicians recorded the basis of their first album in one week. This album, "", was released by Real World Records in 1996, and marked the debut of the Afro Celt Sound System.

"Prior to that first album being made, none of us knew if it would work," musician James McNally told Larry Katz of the Boston Herald. "We were strangers who didn't even speak the same language. But we were bowled over by this communication that took place beyond language." McNally, who grew up second-generation Irish in London, played whistles, keyboards, piano, bodhran, and bamboo flute.

"Sound Magic" has now sold over 300,000 copies. The band performed at festivals, raves, and dance clubs and regularly included two African musicians, Moussa Sissokho on talking drum and djembe and N'Faly Kouyate on vocals, kora and balafon.

Just as the second album was getting off the ground, one of the group's core musicians, 27-year-old keyboardist Jo Bruce (son of Cream bass player Jack Bruce), died suddenly of an asthma attack. The band was devastated, and the album was put on hold. Then Irish pop star Sinéad O'Connor came to the rescue, collaborating with the band and helping them cope with their loss. "[O'Connor] blew into the studio on a windy November night and blew away again leaving us something incredibly emotional and powerful," McNally told Katz. "We had this track we didn't know what to do with. Sinéad scribbled a few lyrics and bang! She left us completely choked up." So taken was the band with O'Connor's song, "Release," that they used the name for the title of their album. "" hit the music stores in 1999, and by the spring of 2000 it had sold more than half a million copies worldwide.

In 2000 the group was nominated for a Grammy Award in the Best World Music category. The band, composed at the time of eight members from six countries (England, Senegal, Guinea, Ireland, France and Kenya), took pride in its ability to bring people together through music. "We can communicate anywhere at any corner of the planet and feel that we're at home," McNally told Patrick MacDonald of The Seattle Times". "We're breaking down categories of world music and rock music and black music. We leave a door open to communicate with each other's traditions. And it's changed our lives".

In 2001 the group released "", which climbed to number one on Billboard's Top World Music Albums chart. Featuring guest spots by Peter Gabriel and Robert Plant, the album also incorporated a heightened African sound. "On the first two records, the pendulum swung more toward the Celtic, London club side of the equation," Emmerson told the Irish Times's Carroll. "For this one, we wanted to have more African vocals and input than we'd done before." Again the Afro Celt Sound System met with success. Chuck Taylor of Billboard magazine praised the album as "a cultural phenomenon that bursts past the traditional boundaries of contemporary music." The single "When You're Falling", with vocals by Gabriel, became a radio hit in the United States.

In 2003, for the "Seed" album, they changed their name to Afrocelts. They reverted to the longer band name for their subsequent albums, "Pod", a compilation of new mixes of songs from the first four albums, "" (their fifth studio album), and "Capture - Afro Celt Sound System 1995-2010".

They played a number of shows to promote "Volume 5: Anatomic" in 2006 and summer 2007, ending with a gig in Korea, before taking an extended break to work on side projects, amongst them "The Imagined Village" featuring Simon Emmerson and Johnny Kalsi. Starting in the summer of 2010, the band performed a series of live shows to promote a new 2-CD album, "Capture - Afro Celt Sound System 1995-2010", released on 6 September 2010 on Real World Records. Further performances continue to the present day, and a new album-in-progress titled "Born" was announced on their website in 2014. Following the split (see below), Emmerson's version of the band released the album The Source in 2016.

During 2015, the band had split into two formations, one of them including Simon Emmerson, N'Faly Kouyate and Johnny Kalsi, the other one James McNally and Martin Russell. The split was announced on the band's website in January 2016. The dispute officially ended with an announcement on social media on December 21, 2016. "Simon Emmerson, James McNally and Martin Russell are pleased to announce that they have been able to set aside their differences and come to an amicable agreement to bring their dispute to an end. Going forward, McNally, Russell and Emmerson have agreed that Emmerson will continue to perform as Afro Celt Sound System and McNally and Russell will work under a new name to be announced in due course.
While McNally, Russell and Emmerson will no longer be performing or working together they recognise, and are grateful for each other's contribution to Afro Celt Sound System over the past two decades and will be working with the extensive community of musicians that make up the long standing Afro Celt Sound System family." Emmerson's version of the band released the album The Source in 2016.

When Afro Celt Sound System formed in the mid-1990s during the Real World Recording Week, the difference between a guest artist and a band member was virtually non-existent. However, over time, a combination of people became most often associated with the name Afro Celt Sound System (while "Volume 5: Anatomic" only lists Emmerson, McNally, Ó Lionáird and Russell as regulars). The divided grouping of the band into two versions, both operating under the name Afro Celt Sound System, began in January 2016 and was resolved in December 2016 after McNally and Russell agreed to work under a different name from Emmerson.

Russell/McNally version

Other musicians who have performed or recorded with Afro Celt Sound System include: Jimmy Mahon, Demba Barry, Babara Bangoura, Iarla Ó Lionáird, Peter Gabriel, Robert Plant, Pete Lockett, Sinéad O'Connor, Pina Kollar, Dorothee Munyaneza, Sevara Nazarkhan, Simon Massey, Jesse Cook, Martin Hayes, Eileen Ivers, Mundy, Mairéad Ní Mhaonaigh and Ciarán Tourish of Altan, Ronan Browne, Michael McGoldrick, Myrdhin, Shooglenifty, Mairead Nesbitt, Nigel Eaton, Davy Spillane, Jonas Bruce, Heather Nova, Julie Murphy and Ayub Ogada, Ross Ainslie.


They also recorded the soundtrack for the PC game "Magic and Mayhem", released in 1998.



</doc>
<doc id="1167" url="https://en.wikipedia.org/wiki?curid=1167" title="Ancient philosophy">
Ancient philosophy

This page lists some links to ancient philosophy. In Western philosophy, the spread of Christianity in the Roman Empire marked the ending of Hellenistic philosophy and ushered in the beginnings of Medieval philosophy, whereas in Eastern philosophy, the spread of Islam through the Arab Empire marked the end of Old Iranian philosophy and ushered in the beginnings of early Islamic philosophy.

Genuine philosophical thought, depending upon original individual insights, arose in many cultures roughly contemporaneously. Karl Jaspers termed the intense period of philosophical development beginning around the 7th century and concluding around the 3rd century BCE an Axial Age in human thought.

Chinese philosophy is the dominant philosophical thought in China and other countries within the East Asian cultural sphere that share a common language, including Japan, Korea, and Vietnam.

The Hundred Schools of Thought were philosophers and schools that flourished from the 6th century to 221 BCE, an era of great cultural and intellectual expansion in China. Even though this period – known in its earlier part as the Spring and Autumn period and the Warring States period – in its latter part was fraught with chaos and bloody battles, it is also known as the Golden Age of Chinese philosophy because a broad range of thoughts and ideas were developed and discussed freely. The thoughts and ideas discussed and refined during this period have profoundly influenced lifestyles and social consciousness up to the present day in East Asian countries. The intellectual society of this era was characterized by itinerant scholars, who were often employed by various state rulers as advisers on the methods of government, war, and diplomacy. This period ended with the rise of the Qin Dynasty and the subsequent purge of dissent. The Book of Han lists ten major schools, they are:

The founder of the Qin Dynasty, who implemented Legalism as the official philosophy, quashed Mohist and Confucianist schools. Legalism remained influential until the emperors of the Han Dynasty adopted Daoism and later Confucianism as official doctrine. These latter two became the determining forces of Chinese thought until the introduction of Buddhism.

Confucianism was particularly strong during the Han Dynasty, whose greatest thinker was Dong Zhongshu, who integrated Confucianism with the thoughts of the Zhongshu School and the theory of the Five Elements. He also was a promoter of the New Text school, which considered Confucius as a divine figure and a spiritual ruler of China, who foresaw and started the evolution of the world towards the Universal Peace. In contrast, there was an Old Text school that advocated the use of Confucian works written in ancient language (from this comes the denomination "Old Text") that were so much more reliable. In particular, they refuted the assumption of Confucius as a godlike figure and considered him as the greatest sage, but simply a human and mortal.

The 3rd and 4th centuries saw the rise of the "Xuanxue" (mysterious learning), also called "Neo-Taoism". The most important philosophers of this movement were Wang Bi, Xiang Xiu and Guo Xiang. The main question of this school was whether Being came before Not-Being (in Chinese, "ming" and "wuming"). A peculiar feature of these Taoist thinkers, like the Seven Sages of the Bamboo Grove, was the concept of "feng liu" (lit. wind and flow), a sort of romantic spirit which encouraged following the natural and instinctive impulse.

Buddhism arrived in China around the 1st century AD, but it was not until the Northern and Southern, Sui and Tang Dynasties that it gained considerable influence and acknowledgement. At the beginning, it was considered a sort of Taoist sect, and there was even a theory about Laozi, founder of Taoism, who went to India and taught his philosophy to Buddha. Mahayana Buddhism was far more successful in China than its rival Hinayana, and both Indian schools and local Chinese sects arose from the 5th century. Two chiefly important monk philosophers were Sengzhao and Daosheng. But probably the most influential and original of these schools was the Chan sect, which had an even stronger impact in Japan as the Zen sect.






See also: "Christian philosophy"


The ancient Indian philosophy is a fusion of two ancient traditions: the Vedic tradition and the Sramana tradition.

Indian philosophy begins with the "Vedas" wherein questions pertaining to laws of nature, the origin of the universe and the place of man in it are asked. In the famous Rigvedic "Hymn of Creation" (Nasadiya Sukta) the poet asks:

In the Vedic view, creation is ascribed to the self-consciousness of the primeval being ("Purusha"). This leads to the inquiry into "the one being" that underlies the diversity of empirical phenomena and the origin of all things. Cosmic order is termed "rta" and causal law by "karma". Nature ("prakriti") is taken to have three qualities ("sattva", "rajas", and "tamas").

Jainism and Buddhism are continuation of the Sramana school of thought. The Sramanas cultivated a pessimistic worldview of the samsara as full of suffering and advocated renunciation and austerities. They laid stress on philosophical concepts like Ahimsa, Karma, Jnana, Samsara and Moksa. Cārvāka (Sanskrit: चार्वाक) (atheist) philosophy, also known as Lokāyata, it is a system of Hindu philosophy that assumes various forms of philosophical skepticism and religious indifference. It is named after its founder, Cārvāka, author of the Bārhaspatya-sūtras.

In classical times, these inquiries were systematized in six schools of philosophy. Some of the questions asked were:

The six schools of Indian philosophy are:






See also: "Dualism, Dualism (philosophy of mind)"

While there are ancient relations between the Indian Vedas and the Iranian Avesta, the two main families of the Indo-Iranian philosophical traditions were characterized by fundamental differences in their implications for the human being's position in society and their view of man's role in the universe. The first charter of human rights by Cyrus the Great as understood in the Cyrus cylinder is often seen as a reflection of the questions and thoughts expressed by Zarathustra and developed in Zoroastrian schools of thought of the Achaemenid Era of Iranian history.

Ideas and tenets of Zoroastrian schools of Early Persian philosophy are part of many works written in Middle Persian and of the extant scriptures of the zoroastrian religion in Avestan language. Among these are treatises such as the Shikand-gumanic Vichar by Mardan-Farrux Ohrmazddadan, selections of Denkard, Wizidagīhā-ī Zātspram ("Selections of Zātspram") as well as older passages of the book Avesta, the Gathas which are attributed to Zarathustra himself and regarded as his "direct teachings".

Anacharsis







See also: "Jewish philosophy"








</doc>
<doc id="1168" url="https://en.wikipedia.org/wiki?curid=1168" title="Anaximander">
Anaximander

Anaximander (; "Anaximandros"; ), was a pre-Socratic Greek philosopher who lived in Miletus, a city of Ionia (in modern-day Turkey). He belonged to the Milesian school and learned the teachings of his master Thales. He succeeded Thales and became the second master of that school where he counted Anaximenes and, arguably, Pythagoras amongst his pupils.

Little of his life and work is known today. According to available historical documents, he is the first philosopher known to have written down his studies, although only one fragment of his work remains. Fragmentary testimonies found in documents after his death provide a portrait of the man.

Anaximander was an early proponent of science and tried to observe and explain different aspects of the universe, with a particular interest in its origins, claiming that nature is ruled by laws, just like human societies, and anything that disturbs the balance of nature does not last long. Like many thinkers of his time, Anaximander's philosophy included contributions to many disciplines. In astronomy, he attempted to describe the mechanics of celestial bodies in relation to the Earth. In physics, his postulation that the indefinite (or apeiron) was the source of all things led Greek philosophy to a new level of conceptual abstraction. His knowledge of geometry allowed him to introduce the gnomon in Greece. He created a map of the world that contributed greatly to the advancement of geography. He was also involved in the politics of Miletus and was sent as a leader to one of its colonies.

Anaximander, son of Praxiades, was born in the third year of the 42nd Olympiad (610 BC). According to Apollodorus of Athens, Greek grammarian of the 2nd century BC, he was sixty-four years old during the second year of the 58th Olympiad (547–546 BC), and died shortly afterwards.

Establishing a timeline of his work is now impossible, since no document provides chronological references. Themistius, a 4th-century Byzantine rhetorician, mentions that he was the "first of the known Greeks to publish a written document on nature." Therefore, his texts would be amongst the earliest written in prose, at least in the Western world. By the time of Plato, his philosophy was almost forgotten, and Aristotle, his successor Theophrastus and a few doxographers provide us with the little information that remains. However, we know from Aristotle that Thales, also from Miletus, precedes Anaximander. It is debatable whether Thales actually was the teacher of Anaximander, but there is no doubt that Anaximander was influenced by Thales' theory that everything is derived from water. One thing that is not debatable is that even the ancient Greeks considered Anaximander to be from the Monist school which began in Miletus, with Thales followed by Anaximander and finished with Anaximenes. 3rd-century Roman rhetorician Aelian depicts him as leader of the Milesian colony to Apollonia on the Black Sea coast, and hence some have inferred that he was a prominent citizen. Indeed, "Various History" (III, 17) explains that philosophers sometimes also dealt with political matters. It is very likely that leaders of Miletus sent him there as a legislator to create a constitution or simply to maintain the colony's allegiance.

Anaximander lived the final few years of his life as a subject of the Persian Achaemenid Empire.

Anaximander's theories were influenced by the Greek mythical tradition, and by some ideas of Thales – the father of philosophy – as well as by observations made by older civilizations in the East (especially by the Babylonian astrologers). All these were elaborated rationally. In his desire to find some universal principle, he assumed, like traditional religion, the existence of a cosmic order; and in elaborating his ideas on this he used the old mythical language which ascribed divine control to various spheres of reality. This was a common practice for the Greek philosophers in a society which saw gods everywhere, and therefore could fit their ideas into a tolerably elastic system.

Some scholars see a gap between the existing mythical and the new rational way of thought which is the main characteristic of the archaic period (8th to 6th century BC) in the Greek city-states. This has given rise to the phrase "Greek miracle". But if we follow carefully the course of Anaximander's ideas, we will notice that there was not such an abrupt break as initially appears. The basic elements of nature (water, air, fire, earth) which the first Greek philosophers believed constituted the universe represent in fact the primordial forces of previous thought. Their collision produced what the mythical tradition had called cosmic harmony. In the old cosmogonies – Hesiod (8th – 7th century BC) and Pherecydes (6th century BC) – Zeus establishes his order in the world by destroying the powers which were threatening this harmony (the Titans). Anaximander claimed that the cosmic order is not monarchic but geometric, and that this causes the equilibrium of the earth, which is lying in the centre of the universe. This is the projection on nature of a new political order and a new space organized around a centre which is the static point of the system in the society as in nature. In this space there is "isonomy" (equal rights) and all the forces are symmetrical and transferrable. The decisions are now taken by the assembly of "demos" in the "agora" which is lying in the middle of the city.

The same "rational" way of thought led him to introduce the abstract "apeiron" (indefinite, infinite, boundless, unlimited) as an origin of the universe, a concept that is probably influenced by the original Chaos (gaping void, abyss, formless state) of the mythical Greek cosmogony from which everything else appeared. It also takes notice of the mutual changes between the four elements. Origin, then, must be something else unlimited in its source, that could create without experiencing decay, so that genesis would never stop.

The "Refutation" attributed to Hippolytus of Rome (I, 5), and the later 6th century Byzantine philosopher Simplicius of Cilicia, attribute to Anaximander the earliest use of the word "apeiron" ( "infinite" or "limitless") to designate the original principle. He was the first philosopher to employ, in a philosophical context, the term "archē" (), which until then had meant beginning or origin.

"That Anaximander called this something by the name of is the natural interpretation of what Theophrastos says; the current statement that the term was introduced by him appears to be due to a misunderstanding."

And "Hippolytos, however, is not an independent authority, and the only question is what Theophrastos wrote."

For him, it became no longer a mere point in time, but a source that could perpetually give birth to whatever will be. The indefiniteness is spatial in early usages as in Homer (indefinite sea) and as in Xenophanes (6th century BC) who said that the earth went down indefinitely (to "apeiron") i.e. beyond the imagination or concept of men.

Burnet (1930) in "Early Greek Philosophy" says:

"Nearly all we know of Anaximander’s system is derived in the last resort from Theophrastos, who certainly knew his book. He seems once at least to have quoted Anaximander's own words, and he criticised his style. Here are the remains of what he said of him in the First Book:

"Anaximander of Miletos, son of Praxiades, a fellow-citizen and associate of Thales, said that the material cause and first element of things was the Infinite, he being the first to introduce this name of the material cause. He says it is neither water nor any other of the so-called elements, but a substance different from them which is infinite" [apeiron, or ] "from which arise all the heavens and the worlds within them.—Phys, Op. fr. 2 {Dox. p. 476 ; R. P. 16)."

Burnet's quote from the "First Book" is his translation of Theophrastos' "Physic Opinion" fragment 2 as it appears in p. 476 of "Historia Philosophiae Graecae" (1898) by Ritter and Preller and section 16 of "Doxographi Graeci" (1879) by Diels.

By ascribing the "Infinite" with a "material cause", Theophrastos is following the Aristotelian tradition of "nearly always discussing the facts from the point of view of his own system".

Aristotle writes ("Metaphysics", I.III 3–4) that the Pre-Socratics were searching for the element that constitutes all things. While each pre-Socratic philosopher gave a different answer as to the identity of this element (water for Thales and air for Anaximenes), Anaximander understood the beginning or first principle to be an endless, unlimited primordial mass ("apeiron"), subject to neither old age nor decay, that perpetually yielded fresh materials from which everything we perceive is derived. He proposed the theory of the "apeiron" in direct response to the earlier theory of his teacher, Thales, who had claimed that the primary substance was water. The notion of temporal infinity was familiar to the Greek mind from remote antiquity in the religious concept of immortality, and Anaximander's description was in terms appropriate to this conception. This "archē" is called "eternal and ageless". (Hippolytus (?), "Refutation", I,6,I;DK B2)""Aristotle puts things in his own way regardless of historical considerations, and it is difficult to see that it is more of an anachronism to call the Boundless “ intermediate between the elements ” than to say that it is " distinct from the elements.” Indeed, if once we introduce the elements at all, the former description is the more adequate of the two. At any rate, if we refuse to understand these passages as referring to Anaximander, we shall have to say that Aristotle paid a great deal of attention to some one whose very name has been lost, and who not only agreed with some of Anaximander’s views, but also used some of his most characteristic expressions. We may add that in one or two places Aristotle certainly seems to identify the “ intermediate ” with the something “ distinct from ” the elements".""It is certain that he [Anaximander] cannot have said anything about elements, which no one thought of before Empedokles, and no one could think of before Parmenides. The question has only been mentioned because it has given rise to a lengthy controversy, and because it throws light on the historical value of Aristotle’s statements. From the point of view of his own system, these may be justified; but we shall have to remember in other cases that, when he seems to attribute an idea to some earlier thinker, we are not bound to take what he says in an historical sense."For Anaximander, the principle of things, the constituent of all substances, is nothing determined and not an element such as water in Thales' view. Neither is it something halfway between air and water, or between air and fire, thicker than air and fire, or more subtle than water and earth. Anaximander argues that water cannot embrace all of the opposites found in nature — for example, water can only be wet, never dry — and therefore cannot be the one primary substance; nor could any of the other candidates. He postulated the "apeiron" as a substance that, although not directly perceptible to us, could explain the opposites he saw around him."If Thales had been right in saying that water was the fundamental reality, it would not be easy to see how anything else could ever have existed. One side of the opposition, the cold and moist, would have had its way unchecked, and the warm and dry would have been driven from the field long ago. We must, then, have something not itself one of the warring opposites, something more primitive, out of which they arise, and into which they once more pass away."Anaximander explains how the four elements of ancient physics (air, earth, water and fire) are formed, and how Earth and terrestrial beings are formed through their interactions. Unlike other Pre-Socratics, he never defines this principle precisely, and it has generally been understood (e.g., by Aristotle and by Saint Augustine) as a sort of primal chaos. According to him, the Universe originates in the separation of opposites in the primordial matter. It embraces the opposites of hot and cold, wet and dry, and directs the movement of things; an entire host of shapes and differences then grow that are found in "all the worlds" (for he believed there were many)."Anaximander taught, then, that there was an eternal. The indestructible something out of which everything arises, and into which everything returns; a boundless stock from which the waste of existence is continually made good, “elements.”. That is only the natural development of the thought we have ascribed to Thales, and there can be no doubt that Anaximander at least formulated it distinctly. Indeed, we can still follow to some extent the reasoning which led him to do so. Thales had regarded water as the most likely thing to be that of which all others are forms; Anaximander appears to have asked how the primary substance could be one of these particular things. His argument seems to be preserved by Aristotle, who has the following passage in his discussion of the Infinite: ""Further, there cannot be a single, simple body which is infinite, either, as some hold, one distinct from the elements, which they then derive from it, or without this qualification. For there are some who make this. (i.e. a body distinct from the elements). the infinite, and not air or water, in order that the other things may not be destroyed by their infinity. They are in opposition one to another. air is cold, water moist, and fire hot. and therefore, if any one of them were infinite, the rest would have ceased to he hy this time. Accordingly they say that what is infinite is something other than the elements, and from it the elements arise.'⁠—Aristotle Physics. F, 5 204 b 22 (Ritter and Preller (1898) Historia Philosophiae Graecae, section 16 b).""Anaximander maintains that all dying things are returning to the element from which they came ("apeiron"). The one surviving fragment of Anaximander's writing deals with this matter. Simplicius transmitted it as a quotation, which describes the balanced and mutual changes of the elements:
Whence things have their origin,
Thence also their destruction happens,
According to necessity;
For they give to each other justice and recompense
For their injustice
In conformity with the ordinance of Time.
Simplicius mentions that Anaximander said all these "in poetic terms", meaning that he used the old mythical language. The goddess Justice (Dike) keeps the cosmic order. This concept of returning to the element of origin was often revisited afterwards, notably by Aristotle, and by the Greek tragedian Euripides: "what comes from earth must return to earth." Friedrich Nietzsche, in his "Philosophy in the Tragic Age of the Greeks", stated that Anaximander viewed "... all coming-to-be as though it were an illegitimate emancipation from eternal being, a wrong for which destruction is the only penance." Physicist Max Born, in commenting upon Werner Heisenberg's arriving at the idea that the elementary particles of quantum mechanics are to be seen as different manifestations, different quantum states, of one and the same “primordial substance,”' proposed that this primordial substance be called "apeiron".

Anaximander's bold use of non-mythological explanatory hypotheses considerably distinguishes him from previous cosmology writers such as Hesiod. It confirms that pre-Socratic philosophers were making an early effort to demystify physical processes. His major contribution to history was writing the oldest prose document about the Universe and the origins of life; for this he is often called the "Father of Cosmology" and founder of astronomy. However, pseudo-Plutarch states that he still viewed celestial bodies as deities.

Anaximander was the first to conceive a mechanical model of the world. In his model, the Earth floats very still in the centre of the infinite, not supported by anything. It remains "in the same place because of its indifference", a point of view that Aristotle considered ingenious, but false, in "On the Heavens". Its curious shape is that of a cylinder with a height one-third of its diameter. The flat top forms the inhabited world, which is surrounded by a circular oceanic mass.

Anaximander's realization that the Earth floats free without falling and does not need to be resting on something has been indicated by many as the first cosmological revolution and the starting point of scientific thinking. Karl Popper calls this idea "one of the boldest, most revolutionary, and most portentous ideas in the whole history of human thinking." Such a model allowed the concept that celestial bodies could pass under the Earth, opening the way to Greek astronomy.

At the origin, after the separation of hot and cold, a ball of flame appeared that surrounded Earth like bark on a tree. This ball broke apart to form the rest of the Universe. It resembled a system of hollow concentric wheels, filled with fire, with the rims pierced by holes like those of a flute. Consequently, the Sun was the fire that one could see through a hole the same size as the Earth on the farthest wheel, and an eclipse corresponded with the occlusion of that hole. The diameter of the solar wheel was twenty-seven times that of the Earth (or twenty-eight, depending on the sources) and the lunar wheel, whose fire was less intense, eighteen (or nineteen) times. Its hole could change shape, thus explaining lunar phases. The stars and the planets, located closer, followed the same model.

Anaximander was the first astronomer to consider the Sun as a huge mass, and consequently, to realize how far from Earth it might be, and the first to present a system where the celestial bodies turned at different distances. Furthermore, according to Diogenes Laertius (II, 2), he built a celestial sphere. This invention undoubtedly made him the first to realize the obliquity of the Zodiac as the Roman philosopher Pliny the Elder reports in "Natural History" (II, 8). It is a little early to use the term ecliptic, but his knowledge and work on astronomy confirm that he must have observed the inclination of the celestial sphere in relation to the plane of the Earth to explain the seasons. The doxographer and theologian Aetius attributes to Pythagoras the exact measurement of the obliquity.

According to Simplicius, Anaximander already speculated on the plurality of worlds, similar to atomists Leucippus and Democritus, and later philosopher Epicurus. These thinkers supposed that worlds appeared and disappeared for a while, and that some were born when others perished. They claimed that this movement was eternal, "for without movement, there can be no generation, no destruction".

In addition to Simplicius, Hippolytus reports Anaximander's claim that from the infinite comes the principle of beings, which themselves come from the heavens and the worlds (several doxographers use the plural when this philosopher is referring to the worlds within, which are often infinite in quantity). Cicero writes that he attributes different gods to the countless worlds.

This theory places Anaximander close to the Atomists and the Epicureans who, more than a century later, also claimed that an infinity of worlds appeared and disappeared. In the timeline of the Greek history of thought, some thinkers conceptualized a single world (Plato, Aristotle, Anaxagoras and Archelaus), while others instead speculated on the existence of a series of worlds, continuous or non-continuous (Anaximenes, Heraclitus, Empedocles and Diogenes).

Anaximander attributed some phenomena, such as thunder and lightning, to the intervention of elements, rather than to divine causes. In his system, thunder results from the shock of clouds hitting each other; the loudness of the sound is proportionate with that of the shock. Thunder without lightning is the result of the wind being too weak to emit any flame, but strong enough to produce a sound. A flash of lightning without thunder is a jolt of the air that disperses and falls, allowing a less active fire to break free. Thunderbolts are the result of a thicker and more violent air flow.

He saw the sea as a remnant of the mass of humidity that once surrounded Earth. A part of that mass evaporated under the sun's action, thus causing the winds and even the rotation of the celestial bodies, which he believed were attracted to places where water is more abundant. He explained rain as a product of the humidity pumped up from Earth by the sun. For him, the Earth was slowly drying up and water only remained in the deepest regions, which someday would go dry as well. According to Aristotle's "Meteorology" (II, 3), Democritus also shared this opinion.

Anaximander speculated about the beginnings and origin of animal life. Taking into account the existence of fossils , he claimed that animals sprang out of the sea long ago. The first animals were born trapped in a spiny bark, but as they got older, the bark would dry up and break. As the early humidity evaporated, dry land emerged and, in time, humankind had to adapt. The 3rd century Roman writer Censorinus reports:

Anaximander put forward the idea that humans had to spend part of this transition inside the mouths of big fish to protect themselves from the Earth's climate until they could come out in open air and lose their scales. He thought that, considering humans' extended infancy, we could not have survived in the primeval world in the same manner we do presently.

Both Strabo and Agathemerus (later Greek geographers) claim that, according to the geographer Eratosthenes, Anaximander was the first to publish a map of the world. The map probably inspired the Greek historian Hecataeus of Miletus to draw a more accurate version. Strabo viewed both as the first geographers after Homer.

Maps were produced in ancient times, also notably in Egypt, Lydia, the Middle East, and Babylon. Only some small examples survived until today. The unique example of a world map comes from late Babylonian tablet BM 92687 later than 9th century BC but is based probably on a much older map. These maps indicated directions, roads, towns, borders, and geological features. Anaximander's innovation was to represent the entire inhabited land known to the ancient Greeks.

Such an accomplishment is more significant than it at first appears. Anaximander most likely drew this map for three reasons. First, it could be used to improve navigation and trade between Miletus's colonies and other colonies around the Mediterranean Sea and Black Sea. Second, Thales would probably have found it easier to convince the Ionian city-states to join in a federation in order to push the Median threat away if he possessed such a tool. Finally, the philosophical idea of a global representation of the world simply for the sake of knowledge was reason enough to design one.

Surely aware of the sea's convexity, he may have designed his map on a slightly rounded metal surface. The centre or “navel” of the world ( "omphalós gẽs") could have been Delphi, but is more likely in Anaximander's time to have been located near Miletus. The Aegean Sea was near the map's centre and enclosed by three continents, themselves located in the middle of the ocean and isolated like islands by sea and rivers. Europe was bordered on the south by the Mediterranean Sea and was separated from Asia by the Black Sea, the Lake Maeotis, and, further east, either by the Phasis River (now called the Rioni) or the Tanais. The Nile flowed south into the ocean, separating Libya (which was the name for the part of the then-known African continent) from Asia.

The "Suda" relates that Anaximander explained some basic notions of geometry. It also mentions his interest in the measurement of time and associates him with the introduction in Greece of the gnomon. In Lacedaemon, he participated in the construction, or at least in the adjustment, of sundials to indicate solstices and equinoxes. Indeed, a gnomon required adjustments from a place to another because of the difference in latitude.

In his time, the gnomon was simply a vertical pillar or rod mounted on a horizontal plane. The position of its shadow on the plane indicated the time of day. As it moves through its apparent course, the Sun draws a curve with the tip of the projected shadow, which is shortest at noon, when pointing due south. The variation in the tip's position at noon indicates the solar time and the seasons; the shadow is longest on the winter solstice and shortest on the summer solstice.

The invention of the gnomon itself cannot be attributed to Anaximander because its use, as well as the division of days into twelve parts, came from the Babylonians. It is they, according to Herodotus' Histories (II, 109), who gave the Greeks the art of time measurement. It is likely that he was not the first to determine the solstices, because no calculation is necessary. On the other hand, equinoxes do not correspond to the middle point between the positions during solstices, as the Babylonians thought. As the "Suda" seems to suggest, it is very likely that with his knowledge of geometry, he became the first Greek to accurately determine the equinoxes.

In his philosophical work De Divinatione (I, 50, 112), Cicero states that Anaximander convinced the inhabitants of Lacedaemon to abandon their city and spend the night in the country with their weapons because an earthquake was near. The city collapsed when the top of the Taygetus split like the stern of a ship. Pliny the Elder also mentions this anecdote (II, 81), suggesting that it came from an "admirable inspiration", as opposed to Cicero, who did not associate the prediction with divination.

Bertrand Russell in the "History of Western Philosophy" interprets Anaximander's theories as an assertion of the necessity of an appropriate balance between earth, fire, and water, all of which may be independently seeking to aggrandize their proportions relative to the others. Anaximander seems to express his belief that a natural order ensures balance between these elements, that where there was fire, ashes (earth) now exist. His Greek peers echoed this sentiment with their belief in natural boundaries beyond which not even the gods could operate.

Friedrich Nietzsche, in "Philosophy in the Tragic Age of the Greeks", claimed that Anaximander was a pessimist who asserted that the primal being of the world was a state of indefiniteness. In accordance with this, anything definite has to eventually pass back into indefiniteness. In other words, Anaximander viewed "...all coming-to-be as though it were an illegitimate emancipation from eternal being, a wrong for which destruction is the only penance". ("Ibid.", § 4) The world of individual objects, in this way of thinking, has no worth and should perish.

Martin Heidegger lectured extensively on Anaximander, and delivered a lecture entitled "Anaximander's Saying" which was subsequently included in "Off the Beaten Track". The lecture examines the ontological difference and the oblivion of Being or "Dasein" in the context of the Anaximander fragment. Heidegger's lecture is, in turn, an important influence on the French philosopher Jacques Derrida.

According to the "Suda":







</doc>
<doc id="1169" url="https://en.wikipedia.org/wiki?curid=1169" title="APL">
APL

APL is an abbreviation, acronym, or initialism that may refer to:







</doc>
<doc id="1170" url="https://en.wikipedia.org/wiki?curid=1170" title="Architect">
Architect

An architect is a person who plans, designs and reviews the construction of buildings. To "practice architecture" means to provide services in connection with the design of buildings and the space within the site surrounding the buildings that have human occupancy or use as their principal purpose. Etymologically, "architect" derives from the Latin "architectus", which derives from the Greek ("arkhi-", chief + "tekton", builder), i.e., chief builder.

Professionally, an architect's decisions affect public safety, and thus an architect must undergo specialized training consisting of advanced education and a "practicum" (or "internship") for practical experience to earn a license to practice architecture. Practical, technical, and academic requirements for becoming an architect vary by jurisdiction.

Throughout ancient and medieval history, most of the architectural design and construction was carried out by artisans—such as stone masons and carpenters, rising to the role of master builder. Until modern times, there was no clear distinction between architect and engineer. In Europe, the titles "architect" and "engineer" were primarily geographical variations that referred to the same person, often used interchangeably.It is suggested that various developments in technology and mathematics allowed the development of the professional 'gentleman' architect, separate from the hands-on craftsman. Paper was not used in Europe for drawing until the 15th century but became increasingly available after 1500. Pencils were used more often for drawing by 1600. The availability of both allowed pre-construction drawings to be made by professionals. Concurrently, the introduction of linear perspective and innovations such as the use of different projections to describe a three-dimensional building in two dimensions, together with an increased understanding of dimensional accuracy, helped building designers communicate their ideas. However, the development was gradual. Until the 18th-century, buildings continued to be designed and set out by craftsmen with the exception of high-status projects.

In most developed countries, only those qualified with an appropriate license, certification or registration with a relevant body (often governmental) may legally practice architecture. Such licensure usually requires a university degree, successful completion of exams, as well as a training period. Representation of oneself as an architect through the use of terms and titles is restricted to licensed individuals by law, although in general, derivatives such as "architectural designer" are often not legally protected.

To practice architecture implies the ability to practice independently of supervision. The term "building design professional" (or "Design professional)", by contrast, is a much broader term that includes professionals who practice independently under an alternate profession, such as engineering professionals, or those who assist in the practice architecture under the supervision of a licensed architect such as "intern architects". In many places, independent, non-licensed individuals may perform design services outside the professional restrictions, such design houses and other smaller structures.

In the architectural profession, technical and environmental knowledge, design and construction management, and an understanding of business are as important as design. However, the design is the driving force throughout the project and beyond. An architect accepts a commission from a client. The commission might involve preparing feasibility reports, building audits, the design of a building or of several buildings, structures, and the spaces among them. The architect participates in developing the requirements the client wants in the building. Throughout the project (planning to occupancy), the architect co-ordinates a design team. Structural, mechanical, and electrical engineers and other specialists, are hired by the client or the architect, who must ensure that the work is co-ordinated to construct the design.

The architect, once hired by a client, is responsible for creating a design concept that both meets the requirements of that client and provides a facility suitable to the required use. The architect must meet with, and question, the client in order to ascertain all the requirements (and nuances) of the planned project.

Often the full brief is not entirely clear at the beginning: entailing a degree of risk in the design undertaking. The architect may make early proposals to the client, which may rework the very terms of the brief. The "program" (or brief) is essential to producing a project that meets all the needs of the owner. This then is a guide for the architect in creating the design concept.

Design proposal(s) are generally expected to be both imaginative and pragmatic. Depending on the place, time, finance, culture, and available crafts and technology in which the design takes place, the precise extent and nature of these expectations will vary.

Foresight is a prerequisite as designing buildings is a very complex and demanding undertaking. 

Any design concept must at a very early stage in its generation take into account a great number of issues and variables which include qualities of space(s), the end-use and life-cycle of these proposed spaces, connections, relations, and aspects between spaces including how they are put together as well as the impact of proposals on the immediate and wider locality. Selection of appropriate materials and technology must be considered, tested and reviewed at an early stage in the design to ensure there are no setbacks (such as higher-than-expected costs) which may occur later. The site and its environs, as well as the culture and history of the place, will also influence the design. The design must also countenance increasing concerns with environmental sustainability. The architect may introduce (intentionally or not), to greater or lesser degrees, aspects of mathematics and architecture, new or current architectural theory, or references to architectural history.

A key part of the design is that the architect often consults with engineers, surveyors and other specialists throughout the design, ensuring that aspects such as the structural supports and air conditioning elements are coordinated in the scheme as a whole. The control and planning of construction costs are also a part of these consultations. Coordination of the different aspects involves a high degree of specialized communication, including advanced computer technology such as BIM (Building Information Management), CAD, and cloud-based technologies.

At all times in the design, the architect reports back to the client who may have reservations or recommendations, introducing a further variable into the design.

Architects deal with local and federal jurisdictions about regulations and building codes. The architect might need to comply with local planning and zoning laws, such as required setbacks, height limitations, parking requirements, transparency requirements (windows), and land use. Some established jurisdictions require adherence to design and historic preservation guidelines. Health and safety risks form a vital part of the current design, and in many jurisdictions, design reports and records are required which include ongoing considerations such as materials and contaminants, waste management and recycling, traffic control and fire safety.

Previously, architects employed drawings to illustrate and generate design proposals. While conceptual sketches are still widely used by architects, computer technology has now become the industry standard. However, design may include the use of photos, collages, prints, linocuts, 3D scanning technology and other media in design production. 
Increasingly, computer software such as BIM is shaping how architects work. BIM technology allows for the creation of a virtual building that serves as an information database for the sharing of design and building information throughout the life-cycle of the building's design, construction and maintenance.

As current buildings are now known to be high emitters of carbon into the atmosphere, increasing controls are being placed on buildings and associated technology to reduce emissions, increase energy efficiency, and make use of renewable energy sources. Renewable energy sources may be developed within the proposed building or via local or national renewable energy providers. As a result, the architect is required to remain abreast of current regulations which are continually tightening. Some new developments exhibit extremely low energy use.
However, the architect is also increasingly required to provide initiatives in a wider environmental sense, such as making provision for low-energy transport, natural daylighting instead of artificial lighting, natural ventilation instead of air conditioning, pollution, and waste management, use of recycled materials and employment of materials which can be easily recycled in the future.

As the design becomes more advanced and detailed, specifications and detail designs are made of all the elements and components of the building. Techniques in the production of a building are continually advancing which places a demand on the architect to ensure that he or she remains up to date with these advances.

Depending on the client's needs and the jurisdiction's requirements, the spectrum of the architect's services during construction stages may be extensive (detailed document preparation and construction review) or less involved (such as allowing a contractor to exercise considerable design-build functions).

Architects typically put projects to tender on behalf of their clients, advise on the award of the project to a general contractor, facilitate and then administer a contract of agreement which is often between the client and the contractor. This contract is legally binding and covers a very wide range of aspects including the insurances and commitments of all stakeholders, the status of the design documents, provisions for the architect's access, and procedures for the control of the works as they proceed. Depending on the type of contract utilized, provisions for further sub-contract tenders may be required. The architect may require that some elements are covered by a warranty which specifies the expected life and other aspects of the material, product or work.

In most jurisdictions, prior notification to the relevant local authority must be given before commencement on site, thus giving the local authority notice to carry out independent inspections. The architect will then review and inspect the progress of the work in coordination with the local authority.

The architect will typically review contractor shop drawings and other submittals, prepare and issue site instructions, and provide Certificates for Payment to the contractor (see also Design-bid-build) which is based on the work done to date as well as any materials and other goods purchased or hired. In the United Kingdom and other countries, a quantity surveyor is often part of the team to provide cost consulting. With very large, complex projects, an independent construction manager is sometimes hired to assist in the design and to manage construction.

In many jurisdictions, mandatory certification or assurance of the completed work or part of works is required. This demand for certification entails a high degree of risk - therefore, regular inspections of the work as it progresses on site is required to ensure that is in compliance with the design itself as well as with all relevant statutes and permissions.

Recent decades have seen the rise of specializations within the profession. Many architects and architectural firms focus on certain project types (for example, healthcare, retail, public housing, event management), technological expertise or project delivery methods. Some architects specialize as building code, building envelope, sustainable design, technical writing, historic preservation(US) or conservation (UK), accessibility and other forms of specialist consultants.

Many architects elect to move into real estate (property) development, corporate facilities planning, project management, construction management, interior design, city planning, or other related fields.

Although there are variations from place to place, most of the world's architects are required to register with the appropriate jurisdiction. To do so, architects are typically required to meet three common requirements: education, experience, and examination.

Educational requirements generally consist of a university degree in architecture. The experience requirement for degree candidates is usually satisfied by a practicum or internship (usually two to three years, depending on jurisdiction). Finally, a Registration Examination or a series of exams is required prior to licensure.

Professionals engaged in the design and supervision of construction projects prior to the late 19th century were not necessarily trained in a separate architecture program in an academic setting. Instead, they often trained under established architects. Prior to modern times, there was no distinction between architects, engineers and often artists, and the title used varied depending on geographical location. They often carried the title of master builder or surveyor after serving a number of years as an apprentice (such as Sir Christopher Wren). The formal study of architecture in academic institutions played a pivotal role in the development of the profession as a whole, serving as a focal point for advances in architectural technology and theory.

Architects' fee structures are typically based on a percentage of construction value, as a rate per unit area of the proposed construction, hourly rates or a fixed lump sum fee. Combinations of these structures are also common. Fixed fees are usually based on a project's allocated construction cost and can range between 4 and 12% of new construction cost, for commercial and institutional projects, depending on a project's size and complexity. Residential projects range from 12 to 20%. Renovation projects typically command higher percentages, as high as 15-20%.

Overall billings for architectural firms range widely, depending on location and economic climate. Billings have traditionally been dependent on the local economic conditions but, with rapid globalization, this is becoming less of a factor for larger international firms. Salaries also vary, depending on experience, position within the firm (staff architect, partner, or shareholder, etc.), and the size and location of the firm.

A number of national professional organizations exist to promote career and business development in architecture.

The American Institute of Architects (AIA) USA

Royal Institute of British Architects (RIBA) UK

Architects Registration Board (ARB) UK

The Australian Institute of Architects (AIA) Australia

Association of Licensed Architects
(ALA) USA

A wide variety of prizes is awarded by national professional associations and other bodies, recognizing accomplished architects, their buildings, structures, and professional careers.

The most lucrative award an architect can receive is the Pritzker Prize, sometimes termed the "Nobel Prize for architecture." Other prestigious architectural awards are the Royal Gold Medal, the AIA Gold Medal (USA), AIA Gold Medal (Australia), and the Praemium Imperiale.

Architects in the UK, who have made contributions to the profession through design excellence or architectural education, or have in some other way advanced the profession, might until 1971 be elected Fellows of the Royal Institute of British Architects and can write FRIBA after their name if they feel so inclined. Those elected to chartered membership of the RIBA after 1971 may use the initials RIBA but cannot use the old ARIBA and FRIBA. An Honorary Fellow may use the initials Hon. FRIBA. and an International Fellow may use the initials Int. FRIBA. Architects in the US, who have made contributions to the profession through design excellence or architectural education, or have in some other way advanced the profession, are elected Fellows of the American Institute of Architects and can write FAIA after their name. Architects in Canada, who have made outstanding contributions to the profession through contribution to research, scholarship, public service, or professional standing to the good of architecture in Canada, or elsewhere, may be recognized as a Fellow of the Royal Architectural Institute of Canada and can write FRAIC after their name. In Hong Kong, those elected to chartered membership may use the initial HKIA, and those who have made a special contribution after nomination and election by The Hong Kong Institute of Architects (HKIA), may be elected as fellow members of HKIA and may use FHKIA after their name.

Architects in the Philippines and Filipino communities overseas (whether they are Filipinos or not), especially those who also profess other jobs at the same time, are addressed and introduced as "Architect", rather than "Sir/Madam" in speech or "Mr./Mrs./Ms." ("G./Gng./Bb." in Filipino) before surnames. That word is used either in itself or before the given name or surname.


</doc>
<doc id="1171" url="https://en.wikipedia.org/wiki?curid=1171" title="Abbreviation">
Abbreviation

An abbreviation (from Latin "brevis", meaning "short" ) is a shortened form of a word or phrase. It consists of a group of letters taken from the word or phrase. For example, the word "abbreviation" can itself be represented by the abbreviation "abbr.", "abbrv.", or "abbrev."

In strict analysis, abbreviations should not be confused with contractions, crasis, acronyms, or initialisms, with which they share some semantic and phonetic functions, though all four are connected by the term "abbreviation" in loose parlance.An abbreviation is a shortening by any method; a contraction is a reduction of size by the drawing together of the parts. A contraction of a word is made by omitting certain letters or syllables and bringing together the first and last letters or elements; an abbreviation may be made by omitting certain portions from the interior or by cutting off a part. A contraction is an abbreviation, but an abbreviation is not necessarily a contraction. Acronyms and initialisms are regarded as subsets of abbreviations (e.g. by the Council of Science Editors). They are abbreviations that consist of the initial letters or parts of words.

Abbreviations have a long history, created so that spelling out a whole word could be avoided. This might be done to save time and space, and also to provide secrecy. Shortened words were used and initial letters were commonly used to represent words in specific applications. In classical Greece and Rome, the reduction of words to single letters was common. In Roman inscriptions, "Words were commonly abbreviated by using the initial letter or letters of words, and most inscriptions have at least one abbreviation." However, "some could have more than one meaning, depending on their context. (For example, "A" can be an abbreviation for many words, such as "ager", "amicus", "annus", "as", "Aulus", "Aurelius", "aurum" and "avus".)"

Abbreviations in English were frequently used from its earliest days. Manuscripts of copies of the old English poem "Beowulf" used many abbreviations, for example "7" or "&" for "and", and "y" for "since", so that "not much space is wasted". The standardisation of English in the 15th through 17th centuries included such a growth in the use of abbreviations. At first, abbreviations were sometimes represented with various suspension signs, not only periods. For example, sequences like ‹er› were replaced with ‹ɔ›, as in ‹mastɔ› for "master" and ‹exacɔbate› for "exacerbate". While this may seem trivial, it was symptomatic of an attempt by people manually reproducing academic texts to reduce the copy time. An example from the Oxford University Register, 1503:

The Early Modern English period, between the 15th and 17th centuries, had abbreviations like "y" for "Þ", used for the word "the": "hence, by later misunderstanding, Ye Olde Tea Shoppe."

During the growth of philological linguistic theory in academic Britain, abbreviating became very fashionable. The use of abbreviation for the names of J. R. R. Tolkien and his friend C. S. Lewis, and other members of the Oxford literary group known as the Inklings, are sometimes cited as symptomatic of this. Likewise, a century earlier in Boston, a fad of abbreviation started that swept the United States, with the globally popular term OK generally credited as a remnant of its influence.

After World War II, the British greatly reduced the use of the full stop and other punctuation points after abbreviations in at least semi-formal writing, while the Americans more readily kept such use until more recently, and still maintain it more than Britons. The classic example, considered by their American counterparts quite curious, was the maintenance of the internal comma in a British organisation of secret agents called the "Special Operations, Executive"—"S.O., E"—which is not found in histories written after about 1960.

But before that, many Britons were more scrupulous at maintaining the French form. In French, the period only follows an abbreviation if the last letter in the abbreviation is "not" the last letter of its antecedent: "M." is the abbreviation for "monsieur" while "Mme" is that for "madame". Like many other cross-channel linguistic acquisitions, many Britons readily took this up and followed this rule themselves, while the Americans took a simpler rule and applied it rigorously.

Over the years, however, the lack of convention in some style guides has made it difficult to determine which two-word abbreviations should be abbreviated with periods and which should not. The U.S. media tend to use periods in two-word abbreviations like United States (U.S.), but not personal computer (PC) or television (TV). Many British publications have gradually done away with the use of periods in abbreviations.

Minimization of punctuation in typewritten material became economically desirable in the 1960s and 1970s for the many users of carbon-film ribbons since a period or comma consumed the same length of non-reusable expensive ribbon as did a capital letter.

Widespread use of electronic communication through mobile phones and the Internet during the 1990s allowed for a marked rise in colloquial abbreviation. This was due largely to increasing popularity of textual communication services such as instant- and text messaging. SMS, for instance, supports message lengths of 160 characters at most (using the GSM 03.38 character set). This brevity gave rise to an informal abbreviation scheme sometimes called Textese, with which 10% or more of the words in a typical SMS message are abbreviated. More recently Twitter, a popular social networking service, began driving abbreviation use with 140 character message limits.

In modern English, there are several conventions for abbreviations, and the choice may be confusing. The only rule universally accepted is that one should be "consistent", and to make this easier, publishers express their preferences in a style guide. Questions which arise include those in the following subsections.

If the original word was capitalized then the first letter of its abbreviation should retain the capital, for example Lev. for "Leviticus". When a word is abbreviated to more than a single letter and was originally spelled with lower case letters then there is no need for capitalization. However, when abbreviating a phrase where only the first letter of each word is taken, then all letters should be capitalized, as in YTD for "year-to-date", PCB for "printed circuit board" and FYI for "for your information". However, see the following section regarding abbreviations that have become common vocabulary: these are no longer written with capital letters.

A period (full stop) is often used to signify an abbreviation, but opinion is divided as to when and if this should happen.

According to Hart's Rules, the traditional rule is that abbreviations (in the narrow sense that includes only words with the ending, and not the middle, dropped) terminate with a full stop, whereas contractions (in the sense of words missing a middle part) do not, but there are exceptions. Fowler's Modern English Usage says full stops are used to mark both abbreviations and contractions, but recommends against this practice: advising them only for abbreviations and lower-case initialisms and not for upper-case initialisms and contractions.

In American English, the period is usually included regardless of whether or not it is a contraction, e.g. "Dr." or "Mrs.". In some cases, periods are optional, as in either "US" or "U.S." for "United States", "EU" or "E.U." for "European Union", and "UN" or "U.N." for "United Nations". There are some house styles, however—American ones included—that remove the periods from almost all abbreviations. For example:

Acronyms that were originally capitalized (with or without periods) but have since entered the vocabulary as generic words are no longer written with capital letters nor with any periods. Examples are sonar, radar, lidar, laser, snafu, and scuba.

Today, spaces are generally not used between single-letter abbreviations of words in the same phrase, so one almost never encounters "U. S."

When an abbreviation appears at the end of a sentence, only one period is used: "The capital of the United States is Washington, D.C".

There is a question about how to pluralize abbreviations, particularly acronyms. Often a writer will add an 's' following an apostrophe, as in "PC's". However, this style is not preferred by many style guides. For instance, Kate Turabian, writing about style in academic writings, allows for an apostrophe to form plural acronyms "only when an abbreviation contains internal periods or both capital and lowercase letters". Turabian would therefore prefer "DVDs" and "URLs" and "Ph.D.'s", while the Modern Language Association explicitly says, "do not use an apostrophe to form the plural of an abbreviation". Also, the American Psychological Association specifically says, "without an apostrophe".

However, the 1999 style guide for "The New York Times" states that the addition of an apostrophe is necessary when pluralizing all abbreviations, preferring "PC's, TV's and VCR's".

Following those who would generally omit the apostrophe, to form the plural of run batted in, simply add an s to the end of RBI.


For all other rules, see below:

To form the plural of an abbreviation, a number, or a capital letter used as a noun, simply add a lowercase "s" to the end. Apostrophes following decades and single letters are also common.

To indicate the plural of the abbreviation or symbol of a unit of measure, the same form is used as in the singular.

When an abbreviation contains more than one full point, "Hart's Rules" recommends putting the "s" after the final one.
However, subject to any house style or consistency requirement, the same plurals may be rendered less formally as:

According to "Hart's Rules", an apostrophe may be used in rare cases where clarity calls for it, for example when letters or symbols are referred to as objects.
However, the apostrophe can be dispensed with if the items are set in italics or quotes:

In Latin, and continuing to the derivative forms in European languages as well as English, single-letter abbreviations had the plural being a doubling of the letter for note-taking. Most of these deal with writing and publishing. A few longer abbreviations use this as well.

Publications based in the U.S. tend to follow the style guides of "The Chicago Manual of Style" and the Associated Press. The U.S. Government follows a style guide published by the U.S. Government Printing Office. The National Institute of Standards and Technology sets the style for abbreviations of units.

Many British publications follow some of these guidelines in abbreviation:


Writers often use shorthand to denote units of measure. Such shorthand can be an abbreviation, such as "in" for "inch" or can be a symbol such as "km" for "kilometre/kilometer".

The shorthand "in" applies to English only—in Afrikaans for example, the shorthand "dm" is used for the equivalent Afrikaans word "duim". Since both "in" and "dm" are contractions of the same word, but in different languages, they are abbreviations. A symbol on the other hand, defined as "Mark or character taken as the conventional sign of some object or idea or process" applies the appropriate shorthand by "substitution" rather than by "contraction". Since the shorthand for kilometre/kilometer ("" in Portuguese or "" in Greek) is "km" in both languages and the letter "k" does not appear in the expansion of either translation, "km" is a symbol as it is a substitution rather than a contraction. It is a logogram rather than an abbreviation.

In the International System of Units (SI) manual the word "symbol" is used consistently to define the shorthand used to represent the various SI units of measure. The manual also defines the way in which units should be written, the principal rules being:

A syllabic abbreviation is usually formed from the initial syllables of several words, such as "Interpol" = International" + police". It is a variant of the acronym. Syllabic abbreviations are usually written using lower case, sometimes starting with a capital letter, and are always pronounced as words rather than letter by letter. Syllabic abbreviations should be distinguished from portmanteaus, which combine two words without necessarily taking whole syllables from each.

Syllabic abbreviations are not widely used in English. Some UK government ministries such as Ofcom (Office of Communications") and Oftel (Office of Telecommunications") use this style.

New York City has various neighborhoods named by syllabic abbreviation, such as Tribeca (Triangle below Canal Street") and SoHo (South of Houston Street"). This usage has spread into other American cities, giving SoMa, San Francisco (South of Market") and LoDo, Denver (Lower Downtown"), among others.

Partially syllabic abbreviations are preferred by the US Navy, as it increases readability amidst the large number of initialisms that would otherwise have to fit into the same acronyms. Hence "DESRON 6" is used (in the full capital form) to mean "Destroyer Squadron 6", while "COMNAVAIRLANT" would be "Commander, Naval Air Force (in the) Atlantic."

Syllabic abbreviations prevailed in Nazi Germany and the Soviet Union for naming the plethora of new bureaucratic organisations. For example, "Gestapo" stands for Geheime Staats-Polizei", or "secret state police". Similarly, Leninist organisations such as the "Comintern" ("Communist International") and "Komsomol" (Kommunisticheskii Soyuz Molodyozhi", or "Communist youth union") used Russian language syllabic abbreviations. This has given syllabic abbreviations negative connotations in some countries, (as in Orwell's Newspeak), notwithstanding that such abbreviations were used in Germany even before the Nazis came to power, e.g., "" for "Schutzpolizei", and are still used, e.g. "" for "".

In the modern Russian language words like "Minoborony" (from Ministerstvo oborony — Ministry of Defence) and "Minobrnauki" (from Ministerstvo obrazovaniya i nauki — Ministry of Education and Science) are still commonly used.

Syllabic abbreviations were also typical for the German language used in the German Democratic Republic, e.g. "Stasi" for Staatssicherheit" ("state security", the secret police) or "Vopo" for "Volkspolizist" ("people's policeman"). Other uses are in company or product names such as Aldi, from the name of the founder, Theo Albrecht, and the German word Diskont" (discount) or Haribo, from the name of the founder and the headquarters of the company, Hans Riegl Bonn.

Syllabic abbreviations are more commenin Spanish; examples abound in organization names such as Pemex for Petróleos Mexicanos" ("Mexican Petroleums") or Fonafifo for Fondo Nacional de Financimiento Forestal" (National Forestry Financing Fund).

In Southeast Asian languages, especially in Malay languages, syllabic abbreviations are also common; examples include Petronas (for Petroliam Nasional", "National Petroleum"), its Indonesian equivalent Pertamina (from its original name Perusahaan Pertambangan Minyak dan Gas Bumi Negara", "State Oil and Natural Gas Mining Company"), and Kemenhub (from "Kementerian Perhubungan", "Ministry of Transportation")

East Asian languages whose writing systems use Chinese characters form abbreviations similarly by using key Chinese characters from a term or phrase. For example, in Japanese the term for the United Nations, "kokusai rengō" (国際連合) is often abbreviated to "kokuren" (国連). (Such abbreviations are called (略語) in Japanese; see also Japanese abbreviated and contracted words). The syllabic abbreviation is frequently used for universities: for instance, "Tōdai" (東大) for "Tōkyō daigaku" (東京大学, University of Tokyo) and is used similarly in Chinese: "Běidà" (北大) for "Běijīng Dàxué" (北京大学, Peking University). The English phrase "Gung ho" originated as a Chinese abbreviation.




</doc>
<doc id="1174" url="https://en.wikipedia.org/wiki?curid=1174" title="Aphrodite">
Aphrodite

Aphrodite is an ancient Greek goddess associated with love, beauty, pleasure, passion and procreation. She is identified with the planet Venus, which is named after the Roman goddess , with whom Aphrodite was extensively syncretized. Aphrodite's major symbols include myrtles, roses, doves, sparrows, and swans.

The cult of Aphrodite was largely derived from that of the Phoenician goddess Astarte, a cognate of the East Semitic goddess Ishtar, whose cult was based on the Sumerian cult of Inanna. Aphrodite's main cult centers were Cythera, Cyprus, Corinth, and Athens. Her main festival was the Aphrodisia, which was celebrated annually in midsummer. In Laconia, Aphrodite was worshipped as a warrior goddess. She was also the patron goddess of prostitutes, an association which led early scholars to propose the concept of "sacred prostitution", an idea which is now generally seen as erroneous.

In Hesiod's "Theogony", Aphrodite is born off the coast of Cythera from the foam (') produced by Uranus's genitals, which his son Cronus has severed and thrown into the sea. In Homer's "Iliad", however, she is the daughter of Zeus and Dione. Plato, in his "Symposium" 180e, asserts that these two origins actually belong to separate entities: Aphrodite Ourania (a transcendent, "Heavenly" Aphrodite) and Aphrodite Pandemos (Aphrodite common to "all the people"). Aphrodite had many other epithets, each emphasizing a different aspect of the same goddess, or used by a different local cult. Thus she was also known as Cytherea ("Lady of Cythera") and Cypris"' ("Lady of Cyprus"), because both locations claimed to be the place of her birth.

In Greek mythology, Aphrodite was married to Hephaestus, the god of blacksmiths and metalworking. Despite this, Aphrodite was frequently unfaithful to him and had many lovers; in the "Odyssey", she is caught in the act of adultery with Ares, the god of war. In the "First Homeric Hymn to Aphrodite", she seduces the mortal shepherd Anchises. Aphrodite was also the surrogate mother and lover of the mortal shepherd Adonis, who was killed by a wild boar. Along with Athena and Hera, Aphrodite was one of the three goddesses whose feud resulted in the beginning of the Trojan War and she plays a major role throughout the "Iliad". Aphrodite has been featured in western art as a symbol of female beauty and has appeared in numerous works of western literature. She is a major deity in modern Neopagan religions, including the Church of Aphrodite, Wicca, and Hellenismos.

Hesiod derives "Aphrodite" from () "sea-foam", interpreting the name as "risen from the foam", but most modern scholars regard this as a spurious folk etymology. Early modern scholars of classical mythology attempted to argue that Aphrodite's name was of Greek or Indo-European origin, but these efforts have now been mostly abandoned. Aphrodite's name is generally accepted to be of non-Greek, probably Semitic, origin, but its exact derivation cannot be determined.

Scholars in the late nineteenth and early twentieth centuries, accepting Hesiod's "foam" etymology as genuine, analyzed the second part of Aphrodite's name as *"-odítē" "wanderer" or *"-dítē" "bright". Michael Janda, also accepting Hesiod's etymology, has argued in favor of the latter of these interpretations and claims the story of a birth from the foam as an Indo-European mytheme. Similarly, Witczak proposes an Indo-European compound ' "very" and ' "to shine", also referring to Eos. Other scholars have argued that these hypotheses are unlikely since Aphrodite's attributes are entirely different from those of both Eos and the Vedic deity Ushas.

A number of improbable non-Greek etymologies have also been suggested. One Semitic etymology compares Aphrodite to the Assyrian "barīrītu", the name of a female demon that appears in Middle Babylonian and Late Babylonian texts. Hammarström looks to Etruscan, comparing "(e)prϑni" "lord", an Etruscan honorific loaned into Greek as πρύτανις. This would make the theonym in origin an honorific, "the lady". Most scholars reject this etymology as implausible, especially since Aphrodite actually appears in Etruscan in the borrowed form "Apru" (from Greek , clipped form of "Aphrodite"). The medieval "Etymologicum Magnum" (c. 1150) offers a highly contrived etymology, deriving "Aphrodite" from the compound "habrodíaitos" (), "she who lives delicately", from "habrós" and "díaita". The alteration from "b" to "ph" is explained as a "familiar" characteristic of Greek "obvious from the Macedonians".

The cult of Aphrodite in Greece was imported from, or at least influenced by, the cult of Astarte in Phoenicia, which, in turn, was influenced by the cult of the Mesopotamian goddess known as "Ishtar" to the East Semitic peoples and as "Inanna" to the Sumerians. Pausanias states that the first to establish a cult of Aphrodite were the Assyrians, followed by the Paphians of Cyprus and then the Phoenicians at Ascalon. The Phoenicians, in turn, taught her worship to the people of Cythera.

Aphrodite took on Inanna-Ishtar's associations with sexuality and procreation. Furthermore, she was known as Ourania (Οὐρανία), which means "heavenly", a title corresponding to Inanna's role as the Queen of Heaven. Early artistic and literary portrayals of Aphrodite are extremely similar on Inanna-Ishtar. Like Inanna-Ishtar, Aphrodite was also a warrior goddess; the second-century AD Greek geographer Pausanias records that, in Sparta, Aphrodite was worshipped as "Aphrodite Areia", which means "warlike". He also mentions that Aphrodite's most ancient cult statues in Sparta and on Cythera showed her bearing arms. Modern scholars note that Aphrodite's warrior-goddess aspects appear in the oldest strata of her worship and see it as an indication of her Near Eastern origins.

Nineteenth century classical scholars had a general aversion to the idea that ancient Greek religion was at all influenced by the cultures of the Near East, but, even Friedrich Gottlieb Welcker, who argued that Near Eastern influence on Greek culture was largely confined to material culture, admitted that Aphrodite was clearly of Phoenician origin. The significant influence of Near Eastern culture on early Greek religion in general, and on the cult of Aphrodite in particular, is now widely recognized as dating to a period of orientalization during the eighth century BC, when archaic Greece was on the fringes of the Neo-Assyrian Empire.

Some early comparative mythologists opposed to the idea of a Near Eastern origin argued that Aphrodite originated as an aspect of the Greek dawn goddess Eos and that she was therefore ultimately derived from the Proto-Indo-European dawn goddess *"Héusōs" (properly Greek Eos, Latin Aurora, Sanskrit Ushas). Most modern scholars have now rejected the notion of a purely Indo-European Aphrodite, but it is possible that Aphrodite, originally a Semitic deity, may have been influenced by the Indo-European dawn goddess. Both Aphrodite and Eos were known for their erotic beauty and aggressive sexuality and both had relationships with mortal lovers. Both goddesses were associated with the colors red, white, and gold. Michael Janda etymologizes Aphrodite's name as an epithet of Eos meaning "she who rises from the foam [of the ocean]" and points to Hesiod's "Theogony" account of Aphrodite's birth as an archaic reflex of Indo-European myth. Aphrodite rising out of the waters after Cronus defeats Uranus as a mytheme would then be directly cognate to the Rigvedic myth of Indra defeating Vrtra, liberating Ushas. Another key similarity between Aphrodite and the Indo-European dawn goddess is her close kinship to the Greek sky deity, since both of the main claimants to her paternity (Zeus and Uranus) are sky deities.

Aphrodite's most common cultic epithet was "Ourania", meaning "heavenly", but this epithet almost never occurs in literary texts, indicating a purely cultic significance. Another common name for Aphrodite was "Pandemos" ("For All the Folk"). In her role as Aphrodite Pandemos, Aphrodite was associated with "Peithō" (), meaning "persuasion", and could be prayed to for aid in seduction. The character of Pausanias in Plato's "Symposium", takes differing cult-practices associated with different epithets of the Goddess to claim that Ourania and Pandemos are, in fact, separate goddesses. He asserts that "Aphrodite Ourania" is the celestial Aphrodite, born from the sea foam after Cronus castrated Uranus, and the older of the two goddesses. According to the "Symposium", "Aphrodite Ourania" is the inspiration of male homosexual desire, specifically the ephebic eros, and pederasty. "Aphrodite Pandemos", by contrast, is the younger of the two goddesses: the common Aphrodite, born from the union of Zeus and Dione, and the inspiration of heterosexual desire and sexual promiscuity, the "lesser" of the two loves.

Among the Neoplatonists and, later, their Christian interpreters, Ourania is associated with spiritual love, and Pandemos with physical love (desire). A representation of Ourania with her foot resting on a tortoise came to be seen as emblematic of discretion in conjugal love; it was the subject of a chryselephantine sculpture by Phidias for Elis, known only from a parenthetical comment by the geographer Pausanias.

One of Aphrodite's most common literary epithets is "Philommeidḗs" (), which means "smile-loving", but is sometimes mistranslated as "laughter-loving". This epithet occurs throughout both of the Homeric epics and the "First Homeric Hymn to Aphrodite". Hesiod references it once in his "Theogony" in the context of Aphrodite's birth, but interprets it as "genital-loving" rather than "smile-loving". Monica Cyrino notes that the epithet may relate to the fact that, in many artistic depictions of Aphrodite, she is shown smiling. Other common literary epithets are "Cypris" and "Cythereia", which derive from her associations with the islands of Cyprus and Cythera respectively.

On Cyprus, Aphrodite was sometimes called "Eleemon" ("the merciful"). In Athens, she was known as "Aphrodite en kopois" ("Aphrodite of the Gardens"). At Cape Colias, a town along the Attic coast, she was venerated as "Genetyllis" "Mother". The Spartans worshipped her as "Potnia" "Mistress", "Enoplios" "Armed", "Morpho" "Shapely", "Ambologera" "She who Postpones Old Age". Across the Greek world, she was known under epithets such as "Melainis" "Black One", "Skotia" "Dark One", "Androphonos" "Killer of Men", "Anosia" "Unholy", and "Tymborychos" "Gravedigger", all of which indicate her darker, more violent nature.

A male version of Aphrodite known as Aphroditus was worshipped in the city of Amathus on Cyprus. Aphroditus was depicted with the figure and dress of a woman, but had a beard, and was shown lifting his dress to reveal an erect phallus. This gesture was believed to be an apotropaic symbol, and was thought to convey good fortune upon the viewer. Eventually, the popularity of Aphroditus waned as the mainstream, fully feminine version of Aphrodite became more popular, but traces of his cult are preserved in the later legends of Hermaphroditus.

Aphrodite's main festival, the Aphrodisia, was celebrated across Greece, but particularly in Athens and Corinth. In Athens, the Aphrodisia was celebrated on the fourth day of the month of Hekatombaion in honor of Aphrodite's role in the unification of Attica. During this festival, the priests of Aphrodite would purify the temple of Aphrodite Pandemos on the southwestern slope of the Acropolis with the blood of a sacrificed dove. Next, the altars would be anointed and the cult statues of Aphrodite Pandemos and Peitho would be escorted in a majestic procession to a place where they would be ritually bathed. Aphrodite was also honored in Athens as part of the Arrhephoria festival. The fourth day of every month was sacred to Aphrodite.

Pausanias records that, in Sparta, Aphrodite was worshipped as "Aphrodite Areia", which means "warlike". This epithet stresses Aphrodite's connections to Ares, with whom she had extramarital relations. Pausanias also records that, in Sparta and on Cythera, a number of extremely ancient cult statues of Aphrodite portrayed her bearing arms. Other cult statues showed her bound in chains.

Aphrodite was the patron goddess of prostitutes of all varieties, ranging from "pornai" (cheap street prostitutes typically owned as slaves by wealthy pimps) to "hetairai" (expensive, well-educated hired companions, who were usually self-employed and sometimes provided sex to their customers). The city of Corinth was renowned throughout the ancient world for its many "hetairai", who had a widespread reputation for being among the most skilled, but also the most expensive, prostitutes in the Greek world. Corinth also had a major temple to Aphrodite located on the Acrocorinth and was one of the main centers of her cult. Records of numerous dedications to Aphrodite made by successful courtesans have survived in poems and in pottery inscriptions. References to Aphrodite in association with prostitution are found in Corinth as well as on the islands of Cyprus, Cythera, and Sicily. Aphrodite's Mesopotamian precursor Inanna-Ishtar was also closely associated with prostitution.

Scholars in the nineteenth and twentieth centuries believed that the cult of Aphrodite may have involved ritual prostitution, an assumption based on ambiguous passages in certain ancient texts, particularly a fragment of a "skolion" by the Boeotian poet Pindar, which mentions prostitutes in Corinth in association with Aphrodite. Modern scholars now dismiss the notion of ritual prostitution in Greece as a "historiographic myth" with no factual basis.

During the Hellenistic period, the Greeks identified Aphrodite with the ancient Egyptian goddesses Hathor and Isis. Aphrodite was the patron goddess of the Lagid queens and Queen Arsinoe II was identified as her mortal incarnation. Aphrodite was worshipped in Alexandria and had numerous temples in and around the city. Arsinoe II introduced the cult of Adonis to Alexandria and many of the women there partook in it. The Tessarakonteres, a gigantic catamaran galley designed by Archimedes for Ptolemy IV Philopator, had a circular temple to Aphrodite on it with a marble statue of the goddess herself. In the second century BC, Ptolemy VIII Physcon and his wives Cleopatra II and Cleopatra III dedicated a temple to Aphrodite Hathor at Philae. Statuettes of Aphrodite for personal devotion became common in Egypt starting in the early Ptolemaic times and extending until long after Egypt became a Roman province.

The ancient Romans identified Aphrodite with their goddess Venus, who was originally a goddess of agricultural fertility, vegetation, and springtime. According to the Roman historian Livy, Aphrodite and Venus were officially identified in the third century BC when the cult of "Venus Erycina" was introduced to Rome from the Greek sanctuary of Aphrodite on Mount Eryx in Sicily. After this point, Romans adopted Aphrodite's iconography and myths and applied them to Venus. Because Aphrodite was the mother of the Trojan hero Aeneas in Greek mythology and Roman tradition claimed Aeneas as the founder of Rome, Venus became venerated as "Venus Genetrix", the mother of the entire Roman nation. Julius Caesar claimed to be directly descended from Aeneas's son Iulus and became a strong proponent of the cult of Venus. This precedent was later followed by his nephew Augustus and the later emperors claiming succession from him.

This syncretism greatly impacted Greek worship of Aphrodite. During the Roman era, the cults of Aphrodite in many Greek cities began to emphasize her relationship with Troy and Aeneas. They also began to adopt distinctively Roman elements, portraying Aphrodite as more maternal, more militaristic, and more concerned with administrative bureaucracy. She was claimed as a divine guardian by many political magistrates. Appearances of Aphrodite in Greek literature also vastly proliferated, usually showing Aphrodite in a characteristically Roman manner.

Aphrodite is usually said to have been born near her chief center of worship, Paphos, on the island of Cyprus, which is why she is sometimes called "Cyprian", especially in the poetic works of Sappho. The Sanctuary of Aphrodite Paphia, marking her birthplace, was a place of pilgrimage in the ancient world for centuries. Other versions of her myth have her born near the island of Cythera, hence another of her names, "Cytherea". Cythera was a stopping place for trade and culture between Crete and the Peloponesus, so these stories may preserve traces of the migration of Aphrodite's cult from the Middle East to mainland Greece.

According to the version of her birth recounted by Hesiod in his "Theogony", Cronus severed Uranus' genitals and threw them behind him into the sea. The foam from his genitals gave rise to Aphrodite (hence her name, which Hesiod interprets as "foam-arisen"), while the Giants, the Erinyes (furies), and the Meliae emerged from the drops of his blood. Hesiod states that the genitals "were carried over the sea a long time, and white foam arose from the immortal flesh; with it a girl grew." Hesiod's account of Aphrodite's birth following Uranus's castration is probably derived from "The Song of Kumarbi", an ancient Hittite epic poem in which the god Kumarbi overthrows his father Anu, the god of the sky, and bites off his genitals, causing him to become pregnant and give birth to Anu's children, which include Ishtar and her brother Teshub, the Hittite storm god.

In the "Iliad", Aphrodite is described as the daughter of Zeus and Dione. Dione's name appears to be a feminine cognate to "Dios" and "Dion", which are oblique forms of the name "Zeus". Zeus and Dione shared a cult at Dodona in northwestern Greece. In "Theogony", Hesiod describes Dione as an Oceanid.

Aphrodite is consistently portrayed as a nubile, infinitely desirable adult, having had no childhood. She is often depicted nude. In the "Iliad", Aphrodite is the apparently unmarried consort of Ares, the god of war, and the wife of Hephaestus is a different goddess named Charis. Likewise, in Hesiod's "Theogony", Aphrodite is unmarried and the wife of Hephaestus is Aglaea, the youngest of the three Charites.

In Book Eight of the "Odyssey", however, the blind singer Demodocus describes Aphrodite as the wife of Hephaestus and tells how she committed adultery with Ares during the Trojan War. The sun-god Helios saw Aphrodite and Ares having sex in Hephaestus's bed and warned Hephaestus, who fashioned a net of gold. The next time Ares and Aphrodite had sex together, the net trapped them both. Hephaestus brought all the gods into the bedchamber to laugh at the captured adulterers, but Apollo, Hermes, and Poseidon had sympathy for Ares and Poseidon agreed to pay Hephaestus for Ares's release. Humiliated, Aphrodite returned to Cyprus, where she was attended by the Charites. This narrative probably originated as a Greek folk tale, originally independent of the "Odyssey".

Later stories were invented to explain Aphrodite's marriage to Hephaestus. In the most famous story, Zeus hastily married Aphrodite to Hephaestus in order to prevent the other gods from fighting over her. In another version of the myth, Hephaestus gave his mother Hera a golden throne, but when she sat on it, she became trapped and he refused to let her go until she agreed to give him Aphrodite's hand in marriage. Hephaestus was overjoyed to be married to the goddess of beauty, and forged her beautiful jewelry, including a "strophion" () known as the (), a saltire-shaped undergarment (usually translated as "girdle"), which accentuated her breasts and made her even more irresistible to men. Such "strophia" were commonly used in depictions of the Near Eastern goddesses Ishtar and Atargatis.

Aphrodite is almost always accompanied by Eros, the god of lust and sexual desire. In his "Theogony", Hesiod describes Eros as one of the four original primeval forces born at the beginning of time, but, after the birth of Aphrodite from the sea foam, he is joined by Himeros and, together, they become Aphrodite's constant companions. In early Greek art, Eros and Himeros are both shown as idealized handsome youths with wings. The Greek lyric poets regarded the power of Eros and Himeros as dangerous, compulsive, and impossible for anyone to resist. In modern times, Eros is often seen as Aphrodite's son, but this is actually a comparatively late innovation. A "scholion" on Theocritus's "Idylls" remarks that the sixth-century BC poet Sappho had described Eros as the son of Aphrodite and Uranus, but the first surviving reference to Eros as Aphrodite's son comes from Apollonius of Rhodes's "Argonautica", written in the third century BC, which makes him the son of Aphrodite and Ares. Later, the Romans, who saw Venus as a mother goddess, seized on this idea of Eros as Aphrodite's son and popularized it, making it the predominant portrayal in works on mythology until the present day.

Aphrodite's main attendants were the three Charites, whom Hesiod identifies as the daughters of Zeus and Eurynome and names as Aglaea ("Splendor"), Euphrosyne ("Good Cheer"), and Thalia ("Abundance"). The Charites had been worshipped as goddesses in Greece since the beginning of Greek history, long before Aphrodite was introduced to the pantheon. Aphrodite's other set of attendants was the three Horae (the "Hours"), whom Hesiod identifies as the daughters of Zeus and Themis and names as Eunomia (“Good Order”), Dike (“Justice”), and Eirene (“Peace”). Aphrodite was also sometimes accompanied by Harmonia, her daughter by Ares, and Hebe, the daughter of Zeus and Hera.

The fertility god Priapus was usually considered to be Aphrodite's son by Dionysus, but he was sometimes also described as her son by Hermes, Adonis, or even Zeus. A "scholion" on Apollonius of Rhodes's "Argonautica" states that, while Aphrodite was pregnant with Priapus, Hera envied her and applied an evil potion to her belly while she was sleeping to ensure that the child would be hideous. When Aphrodite gave birth, she was horrified to see that the child had a massive, permanently erect penis, a potbelly, and a huge tongue. Aphrodite abandoned the infant to die in the wilderness, but a herdsman found him and raised him, later discovering that Priapus could use his massive penis to aid in the growth of plants.

The "First Homeric Hymn to Aphrodite" (Hymn 5), which was probably composed sometime in the mid-seventh century BC, describes how Zeus once became annoyed with Aphrodite for causing deities to fall in love with mortals, so he caused her to fall in love with Anchises, a handsome mortal shepherd who lived in the foothills beneath Mount Ida near the city of Troy. Aphrodite appears to Anchises in the form of a tall, beautiful, mortal virgin while he is alone in his home. Anchises sees her dressed in bright clothing and gleaming jewelry, with her breasts shining with divine radiance. He asks her if she is Aphrodite and promises to build her an altar on top of the mountain if she will bless him and his family.

Aphrodite lies and tells him that she is not a goddess, but the daughter of one of the noble families of Phrygia. She claims to be able to understand the Trojan language because she had a Trojan nurse as a child and says that she found herself on the mountainside after she was snatched up by Hermes while dancing in a celebration in honor of Artemis, the goddess of virginity. Aphrodite tells Anchises that she is still a virgin and begs him to take her to his parents. Anchises immediately becomes overcome with mad lust for Aphrodite and swears that he will have sex with her. Anchises takes Aphrodite, with her eyes cast downwards, to his bed, which is covered in the furs of lions and bears. He then strips her naked and makes love to her.

After the lovemaking is complete, Aphrodite reveals her true divine form. Anchises is terrified, but Aphrodite consoles him and promises that she will bear him a son. She prophesies that their son will be the demigod Aeneas, who will be raised by the nymphs of the wilderness for five years before going to Troy to become a nobleman like his father. The story of Aeneas's conception is also mentioned in Hesiod's "Theogony" and in Book II of Homer's "Iliad".

The myth of Aphrodite and Adonis is probably derived from the ancient Sumerian legend of Inanna and Dumuzid. The Greek name ("Adōnis", ) is derived from the Canaanite word "ʼadōn", meaning "lord". The earliest known Greek reference to Adonis comes from a fragment of a poem by the Lesbian poetess Sappho (c. 630 – c. 570 BC), in which a chorus of young girls asks Aphrodite what they can do to mourn Adonis's death. Aphrodite replies that they must beat their breasts and tear their tunics. Later references flesh out the story with more details. According to the retelling of the story found in the poem "Metamorphoses" by the Roman poet Ovid (43 BC – 17/18 AD), Adonis was the son of Myrrha, who was cursed by Aphrodite with insatiable lust for her own father, King Cinyras of Cyprus, after Myrrha's mother bragged that her daughter was more beautiful than the goddess. Driven out after becoming pregnant, Myrrha was changed into a myrrh tree, but still gave birth to Adonis.

Aphrodite found the baby, and took him to the underworld to be fostered by Persephone. She returned for him once he was grown and discovered him to be strikingly handsome. Persephone wanted to keep Adonis, resulting in a custody battle between the two goddesses over whom should rightly possess Adonis. Zeus settled the dispute by decreeing that Adonis would spend one third of the year with Aphrodite, one third with Persephone, and one third with whomever he chose. Adonis chose to spend that time with Aphrodite. Then, one day, while Adonis was hunting, he was wounded by a wild boar and bled to death in Aphrodite's arms.

In different versions of the story, the boar was either sent by Ares, who was jealous that Aphrodite was spending so much time with Adonis, or by Artemis, who wanted revenge against Aphrodite for having killed her devoted follower Hippolytus. The story also provides an etiology for Aphrodite's associations with certain flowers. Reportedly, as she mourned Adonis's death, she caused anemones to grow wherever his blood fell, and declared a festival on the anniversary of his death. In one version of the story, Aphrodite injured herself on a thorn from a rose bush and the rose, which had previously been white, was stained red by her blood. According to Lucian's "On the Syrian Goddess", each year during the festival of Adonis, the Adonis River in Lebanon (now known as the Abraham River) ran red with blood.

The myth of Adonis is associated with the festival of the Adonia, which was celebrated by Greek women every year in midsummer. The festival, which was evidently already celebrated in Lesbos by Sappho's time, seems to have first become popular in Athens in the mid-fifth century BC. At the start of the festival, the women would plant a "garden of Adonis", a small garden planted inside a small basket or a shallow piece of broken pottery containing a variety of quick-growing plants, such as lettuce and fennel, or even quick-sprouting grains such as wheat and barley. The women would then climb ladders to the roofs of their houses, where they would place the gardens out under the heat of the summer sun. The plants would sprout in the sunlight, but wither quickly in the heat. Then the women would mourn and lament loudly over the death of Adonis, tearing their clothes and beating their breasts in a public display of grief.

In Hesiod's "Works and Days", Zeus orders Aphrodite to make Pandora, the first woman, physically beautiful and sexually attractive, so that she may become "an evil men will love to embrace". Aphrodite "spills grace" over Pandora's head and equips her with "painful desire and knee-weakening anguish", thus making her the perfect vessel for evil to enter the world. Aphrodite's attendants, Peitho, the Charites, and the Horae, adorn Pandora with gold and jewelry.

According to one myth, Aphrodite aided Hippomenes, a noble youth who wished to marry Atalanta, a maiden who was renowned throughout the land for her beauty, but who refused to marry any man unless he could outrun her in a footrace. Atalanta was an exceedingly swift runner and she beheaded all of the men who lost to her. Aphrodite gave Hippomenes three golden apples from the Garden of the Hesperides and instructed him to toss them in front of Atalanta as he raced her. Hippomenes obeyed Aphrodite's order and Atalanta, seeing the beautiful, golden fruits, bent down to pick up each one, allowing Hippomenes to outrun her. In the version of the story from Ovid's "Metamorphoses", Hippomenes forgets to repay Aphrodite for her aid, so she causes the couple to become inflamed with lust while they are staying at the temple of Cybele. The couple desecrate the temple by having sex in it, leading Cybele to turn them into lions as punishment.

The myth of Pygmalion is first mentioned by the third-century BC Greek writer Philostephanus of Cyrene, but is first recounted in detail in Ovid's "Metamorphoses". According to Ovid, Pygmalion was an exceedingly handsome sculptor from the island of Cyprus, who was so sickened by the immorality of women that he refused to marry. He fell madly and passionately in love with the ivory cult statue he was carving of Aphrodite and longed to marry it. Because Pygmalion was extremely pious and devoted to Aphrodite, the goddess brought the statue to life. Pygmalion married the girl the statue became and they had a son named Paphos, after whom the capital of Cyprus received its name. Pseudo-Apollodorus later mentions "Metharme, daughter of Pygmalion, king of Cyprus".

Aphrodite generously rewarded those who honored her, but also punished those who disrespected her, often quite brutally. A myth described in Apollonius of Rhodes's "Argonautica" and later summarized in the "Bibliotheca" of Pseudo-Apollodorus tells how, when the women of the island of Lemnos refused to sacrifice to Aphrodite, the goddess cursed them to stink horribly so that their husbands would never have sex with them. Instead, their husbands started having sex with their Thracian slave-girls. In anger, the women of Lemnos murdered the entire male population of the island, as well as all the Thracian slaves. When Jason and his crew of Argonauts arrived on Lemnos, they mated with the sex-starved women under Aphrodite's approval and repopulated the island. From then on, the women of Lemnos never disrespected Aphrodite again.

In Euripides's tragedy "Hippolytus", which was first performed at the City Dionysia in 428 BC, Theseus's son Hippolytus worships only Artemis, the goddess of virginity, and refuses to engage in any form of sexual contact. Aphrodite is infuriated by his prideful behavior and, in the prologue to the play, she declares that, by honoring only Artemis and refusing to venerate her, Hippolytus has directly challenged her authority. Aphrodite therefore causes Hippolytus's stepmother, Phaedra, to fall in love with him, knowing Hippolytus will reject her. After being rejected, Phaedra commits suicide and leaves a suicide note to Theseus telling him that she killed herself because Hippolytus attempted to rape her. Theseus prays to Poseidon to kill Hippolytus for his transgression. Poseidon sends a wild bull to scare Hippolytus's horses as he is riding by the sea in his chariot, causing the horses to bolt and smash the chariot against the cliffs, dragging Hippolytus to a bloody death across the rocky shoreline. The play concludes with Artemis vowing to kill Aphrodite's own mortal beloved (presumably Adonis) in revenge.

Glaucus of Corinth angered Aphrodite by refusing to let his horses for chariot racing mate, since doing so would hinder their speed. During the chariot race at the funeral games of King Pelias, Aphrodite drove his horses mad and they tore him apart. Polyphonte was a young woman who chose a virginal life with Artemis instead of marriage and children, as favoured by Aphrodite. Aphrodite cursed her, causing her to have children by a bear. The resulting offspring, Agrius and Oreius, were wild cannibals who incurred the hatred of Zeus. Ultimately, he transformed all the members of the family into birds of ill omen.

The myth of the Judgement of Paris is mentioned briefly in the "Iliad", but is described in depth in an epitome of the "Cypria", a lost poem of the Epic Cycle, which records that all the gods and goddesses as well as various mortals were invited to the marriage of Peleus and Thetis (the eventual parents of Achilles). Only Eris, goddess of discord, was not invited. She was annoyed at this, so she arrived with a golden apple inscribed with the word καλλίστῃ (kallistēi, "for the fairest"), which she threw among the goddesses. Aphrodite, Hera, and Athena all claimed to be the fairest, and thus the rightful owner of the apple.

The goddesses chose to place the matter before Zeus, who, not wanting to favor one of the goddesses, put the choice into the hands of Paris, a Trojan prince. After bathing in the spring of Mount Ida where Troy was situated, the goddesses appeared before Paris for his decision. In the extant ancient depictions of the Judgement of Paris, Aphrodite is only occasionally represented nude, and Athena and Hera are always fully clothed. Since the Renaissance, however, western paintings have typically portrayed all three goddesses as completely naked.

All three goddesses were ideally beautiful and Paris could not decide between them, so they resorted to bribes. Hera tried to bribe Paris with power over all Asia and Europe, and Athena offered wisdom, fame and glory in battle, but Aphrodite promised Paris that, if he were to choose her as the fairest, she would let him marry the most beautiful woman on earth. This woman was Helen, who was already married to King Menelaus of Sparta. Paris selected Aphrodite and awarded her the apple. The other two goddesses were enraged and, as a direct result, sided with the Greeks in the Trojan War.

Aphrodite plays an important and active role throughout the entirety of Homer's "Iliad". In Book III, she rescues Paris from Menelaus after he foolishly challenges him to a one-on-one duel. She then appears to Helen in the form of an old woman and attempts to persuade her to have sex with Paris, reminding her of his physical beauty and athletic prowess. Helen immediately recognizes Aphrodite by her beautiful neck, perfect breasts, and flashing eyes and chides the goddess, addressing her as her equal. Aphrodite sharply rebukes Helen, reminding her that, if she vexes her, she will punish her just as much as she has favored her already. Helen demurely obeys Aphrodite's command.

In Book V, Aphrodite charges into battle to rescue her son Aeneas from the Greek hero Diomedes. Diomedes recognizes Aphrodite as a "weakling" goddess and, thrusting his spear, nicks her wrist through her "ambrosial robe". Aphrodite borrows Ares's chariot to ride back to Mount Olympus. Zeus chides her for putting herself in danger, reminding her that "her specialty is love, not war." According to Walter Burkert, this scene directly parallels a scene from Tablet VI of the "Epic of Gilgamesh" in which Ishtar, Aphrodite's Akkadian precursor, cries to her mother Antu after the hero Gilgamesh rejects her sexual advances, but is mildly rebuked by her father Anu. In Book XIV of the "Iliad", during the "Dios Apate" episode, Aphrodite lends her "kestos himas" to Hera for the purpose of seducing Zeus and distracting him from the combat while Poseidon aids the Greek forces on the beach. In the "Theomachia" in Book XXI, Aphrodite again enters the battlefield to carry Ares away after he is wounded.

Aphrodite's most prominent avian symbol was the dove, which was originally an important symbol of her Near Eastern precursor Inanna-Ishtar. (In fact, the ancient Greek word for "dove", "peristerá", may be derived from a Semitic phrase "peraḥ Ištar", meaning "bird of Ishtar".) Aphrodite frequently appears with doves in ancient Greek pottery and the temple of Aphrodite Pandemos on the southwest slope of the Athenian Acropolis was decorated with relief sculptures of doves with knotted fillets in their beaks. Votive offerings of small, white, marble doves were also discovered in the temple of Aphrodite at Daphni. In addition to her associations with doves, Aphrodite was also closely linked with sparrows and she is described riding in a chariot pulled by sparrows in Sappho's "Ode to Aphrodite".

Because of her connections to the sea, Aphrodite was associated with a number of different types of water fowl, including swans, geese, and ducks. Aphrodite's other symbols included the sea, conch shells, and roses. The rose and myrtle flowers were both sacred to Aphrodite. Her most important fruit emblem was the apple, but she was also associated with pomegranates, possibly because the red seeds suggested sexuality or because Greek women sometimes used pomegranates as a method of birth control. In Greek art, Aphrodite is often also accompanied by dolphins and Nereids.

A scene of Aphrodite rising from the sea appears on the back of the Ludovisi Throne ( 460 BC), which was probably originally part of a massive altar that was constructed as part of the Ionic temple to Aphrodite in the Greek polis of Locri Epizephyrii in Magna Graecia in southern Italy. The throne shows Aphrodite rising from the sea, clad in a diaphanous garment, which is drenched with seawater and clinging to her body, revealing her upturned breasts and the outline of her navel. Her hair hangs dripping as she reaches to two attendants standing barefoot on the rocky shore on either side of her, lifting her out of the water. Scenes with Aphrodite appear in works of classical Greek pottery, including a famous white-ground "kylix" by the Pistoxenos Painter dating the between 470 and 460 BC, showing her riding on a swan or goose.

In BC, the Athenian sculptor Praxiteles carved the marble statue "Aphrodite of Knidos", which Pliny the Elder later praised as the greatest sculpture ever made. The statue showed a nude Aphrodite modestly covering her pubic region while resting against a water pot with her robe draped over it for support. The "Aphrodite of Knidos" was the first full-sized statue to depict Aphrodite completely naked and one of the first sculptures that was intended to be viewed from all sides. The statue was purchased by the people of Knidos in around 350 BC and proved to be tremendously influential on later depictions of Aphrodite. The original sculpture has been lost, but written descriptions of it as well several depictions of it on coins are still extant and over sixty copies, small-scale models, and fragments of it have been identified.

The Greek painter Apelles of Kos, a contemporary of Praxiteles, produced the panel painting "Aphrodite Anadyomene" ("Aphrodite Rising from the Sea"). According to Athenaeus, Apelles was inspired to paint the painting after watching the courtesan Phryne take off her clothes, untie her hair, and bathe naked in the sea at Eleusis. The painting was displayed in the Asclepeion on the island of Kos. The "Aphrodite Anadyomene" went unnoticed for centuries, but Pliny the Elder records that, in his own time, it was regarded as Apelles's most famous work.

During the Hellenistic and Roman periods, statues depicting Aphrodite proliferated; many of these statues were modeled at least to some extent on Praxiteles's "Aphrodite of Knidos". Some statues show Aphrodite crouching naked; others show her wringing water out of her hair as she rises from the sea. Another common type of statue is known as "Aphrodite Kallipygos", the name of which is Greek for "Aphrodite of the Beautiful Buttocks"; this type of sculpture shows Aphrodite lifting her "peplos" to display her buttocks to the viewer while looking back at them from over her shoulder. The ancient Romans produced massive numbers of copies of Greek sculptures of Aphrodite and more sculptures of Aphrodite have survived from antiquity than of any other deity.

Early Christians frequently adapted pagan iconography to suit Christian purposes. In the Early Middle Ages, Christians adapted elements of Aphrodite/Venus's iconography and applied them to Eve and prostitutes, but also female saints and even the Virgin Mary. Christians in the east reinterpreted the story of Aphrodite's birth as a metaphor for baptism; in a Coptic stele from the sixth century AD, a female orant is shown wearing Aphrodite's conch shell as a sign that she is newly baptized. Throughout the Middle Ages, villages and communities across Europe still maintained folk tales and traditions about Aphrodite/Venus and travelers reported a wide variety of stories. Numerous Roman mosaics of Venus survived in Britain, preserving memory of the pagan past. In North Africa in the late fifth century AD, Fulgentius of Ruspe encountered mosaics of Aphrodite and reinterpreted her as a symbol of the sin of Lust, arguing that she was shown naked because "the sin of lust is never cloaked" and that she was often shown "swimming" because "all lust suffers shipwreck of its affairs." He also argued that she was associated with doves and conchs because these are symbols of copulation, and that she was associated with roses because "as the rose gives pleasure, but is swept away by the swift movement of the seasons, so lust is pleasant for a moment, but is swept away forever."

While Fulgentius had appropriated Aphrodite as a symbol of Lust, Isidore of Seville ( 560–636) interpreted her as a symbol of marital procreative sex and declared that the moral of the story of Aphrodite's birth is that sex can only be holy in the presence of semen, blood, and heat, which he regarded as all being necessary for procreation. Meanwhile, Isidore denigrated Aphrodite/Venus's son Eros/Cupid as a "demon of fornication" ("daemon fornicationis"). Aphrodite/Venus was best known to Western European scholars through her appearances in Virgil's "Aeneid" and Ovid's "Metamorphoses". Venus is mentioned in the Latin poem "Pervigilium Veneris" ("The Eve of Saint Venus"), written in the third or fourth century AD, and in Giovanni Boccaccio's "Genealogia Deorum Gentilium".

Aphrodite is the central figure in Sandro Botticelli's painting "Primavera", which has been described as "one of the most written about, and most controversial paintings in the world", and "one of the most popular paintings in Western art". The story of Aphrodite's birth from the foam was a popular subject matter for painters during the Italian Renaissance, who were attempting to consciously reconstruct Apelles of Kos's lost masterpiece "Aphrodite Anadyomene" based on the literary "ekphrasis" of it preserved by Cicero and Pliny the Elder. Artists also drew inspiration from Ovid's description of the birth of Venus in his "Metamorphoses". Sandro Botticelli's "The Birth of Venus" ( 1485) was also partially inspired by a description by Poliziano of a relief on the subject. Later Italian renditions of the same scene include Titian's "Venus Anadyomene" ( 1525) and Raphael's painting in the "Stufetta del cardinal Bibbiena" (1516). Titian's biographer Giorgio Vasari identified all of Titian's paintings of naked women as paintings of "Venus", including an erotic painting from 1534, which he called the "Venus of Urbino", even though the painting does not contain any of Aphrodite/Venus's traditional iconography and the woman in it is clearly shown in a contemporary setting, not a classical one.
Jacques-Louis David's final work was his 1824 "magnum opus", "Mars Being Disarmed by Venus", which combines elements of classical, Renaissance, traditional French art, and contemporary artistic styles. While he was working on the painting, David described it, saying, "This is the last picture I want to paint, but I want to surpass myself in it. I will put the date of my seventy-five years on it and afterwards I will never again pick up my brush." The painting was exhibited first in Brussels and then in Paris, where over 10,000 people came to see it. Jean-Auguste-Dominique Ingres's painting "Venus Anadyomene" was one of his major works. Louis Geofroy described it as a "dream of youth realized with the power of maturity, a happiness that few obtain, artists or others." Théophile Gautier declared: "Nothing remains of the marvelous painting of the Greeks, but surely if anything could give the idea of antique painting as it was conceived following the statues of Phidias and the poems of Homer, it is M. Ingres's painting: the "Venus Anadyomene" of Apelles has been found." Other critics dismissed it as a piece of unimaginative, sentimental kitsch, but Ingres himself considered it to be among his greatest works and used the same figure as the model for his later 1856 painting "La Source".

Paintings of Venus were favorites of the late nineteenth-century Academic artists in France. In 1863, Alexandre Cabanel won widespread critical acclaim at the Paris Salon for his painting "The Birth of Venus", which the French emperor Napoleon III immediately purchased for his own personal art collection. Édouard Manet's 1865 painting "Olympia" parodied the nude Venuses of the Academic painters, particularly Cabanel's "Birth of Venus". In 1867, the English Academic painter Frederic Leighton displayed his "Venus Disrobing for the Bath" at the Academy. The art critic J. B. Atkinson praised it, declaring that "Mr Leighton, instead of adopting corrupt Roman notions regarding Venus such as Rubens embodied, has wisely reverted to the Greek idea of Aphrodite, a goddess worshipped, and by artists painted, as the perfection of female grace and beauty." A year later, the English painter Dante Gabriel Rossetti, a founding member of the Pre-Raphaelite Brotherhood, painted "Venus Verticordia" (Latin for "Aphrodite, the Changer of Hearts"), showing Aphrodite as a nude red-headed woman in a garden of roses. Though he was reproached for his "outré" subject matter, Rossetti refused to alter the painting and it was soon purchased by J. Mitchell of Bradford. In 1879, William Adolphe Bouguereau exhibited at the Paris Salon his own "Birth of Venus", which imitated the classical tradition of "contrapposto" and was met with widespread critical acclaim, rivalling the popularity of Cabanel's version from nearly two decades prior.
William Shakespeare's erotic narrative poem "Venus and Adonis" (1593), a retelling of the courtship of Aphrodite and Adonis from Ovid's "Metamorphoses", was the most popular of all his works published within his own lifetime. Six editions of it were published before Shakespeare's death (more than any of his other works) and it enjoyed particularly strong popularity among young adults. In 1605, Richard Barnfield lauded it, declaring that the poem had placed Shakespeare's name "in fames immortall Booke". Despite this, the poem has received mixed reception from modern critics; Samuel Taylor Coleridge defended it, but Samuel Butler complained that it bored him and C. S. Lewis described an attempted reading of it as "suffocating".

Aphrodite appears in Richard Garnett's short story collection "The Twilight of the Gods and Other Tales" (1888), in which the gods' temples have been destroyed by Christians. Stories revolving around sculptures of Aphrodite were common in the late nineteenth and early twentieth centuries. Examples of such works of literature include the novel "The Tinted Venus: A Farcical Romance" (1885) by Thomas Anstey Guthrie and the short story "The Venus of Ille" (1887) by Prosper Mérimée, both of which are about statues of Aphrodite that come to life. Another noteworthy example is "Aphrodite in Aulis" by the Anglo-Irish writer George Moore, which revolves around an ancient Greek family who moves to Aulis. The French writer Pierre Louÿs titled his erotic historical novel "" (1896) after the Greek goddess. The novel enjoyed widespread commercial success, but scandalized French audiences due to its sensuality and its decadent portrayal of Greek society.

In the early twentieth century, stories of Aphrodite were used by feminist poets, such as Amy Lowell and Alicia Ostriker. Many of these poems dealt with Aphrodite's legendary birth from the foam of the sea. Other feminist writers, including Claude Cahun, Thit Jensen, and Anaïs Nin also made use of the myth of Aphrodite in their writings. Ever since the publication of Isabel Allende's book "Aphrodite: A Memoir of the Senses" in 1998, the name "Aphrodite" has been used as a title for dozens of books dealing with all topics even superficially connected to her domain. Frequently these books do not even mention Aphrodite, or mention her only briefly, but make use of her name as a selling point.

In 1938, Gleb Botkin, a Russian immigrant to the United States, founded the Church of Aphrodite, a Neopagan religion centered around the worship of a Mother Goddess, whom its practitioners identified as Aphrodite. The Church of Aphrodite's theology was laid out in the book "In Search of Reality", published in 1969, two years before Botkin's death. The book portrayed Aphrodite in a drastically different light than the one in which the Greeks envisioned her, instead casting her as "the sole Goddess of a somewhat Neoplatonic Pagan monotheism". It claimed that the worship of Aphrodite had been brought to Greece by the mystic teacher Orpheus, but that the Greeks had misunderstood Orpheus's teachings and had not realized the importance of worshipping Aphrodite alone.

Aphrodite is a major deity in Wicca, a contemporary nature-based syncretic Neopagan religion. Wiccans regard Aphrodite as one aspect of the Goddess and she is frequently invoked by name during enchantments dealing with love and romance. Wiccans regard Aphrodite as the ruler of human emotions, erotic spirituality, creativity, and art. As one of the twelve Olympians, Aphrodite is a major deity within Hellenismos (Hellenic Polytheistic Reconstructionism), a Neopagan religion which seeks to authentically revive and recreate the religion of ancient Greece in the modern world. Unlike Wiccans, Hellenists are usually strictly polytheistic or pantheistic. Hellenists venerate Aphrodite primarily as the goddess of romantic love, but also as a goddess of sexuality, the sea, and war. Her many epithets include "Sea Born", "Killer of Men", "She upon the Graves", "Fair Sailing", and "Ally in War".





</doc>
<doc id="1175" url="https://en.wikipedia.org/wiki?curid=1175" title="April 1">
April 1

It is not only the first day of the second quarter of the year, but it is also the midway point of the first half of the year.





</doc>
<doc id="1176" url="https://en.wikipedia.org/wiki?curid=1176" title="Antisymmetric relation">
Antisymmetric relation

In mathematics, a binary relation "R" on a set "X" is antisymmetric if there is no pair of "distinct" elements of "X" each of which is related by "R" to the other. More formally, "R" is antisymmetric precisely if for all "a" and "b" in "X"
or, equivalently,

The divisibility relation on the natural numbers is an important example of an antisymmetric relation. In this context, antisymmetry means that the only way each of two numbers can be divisible by the other is if the two are, in fact, the same number; equivalently, if "n" and "m" are distinct and "n" is a factor of "m", then "m" cannot be a factor of "n". For example, 12 is divisible by 4, but 4 is not divisible by 12.

The usual order relation ≤ on the real numbers is antisymmetric: if for two real numbers "x" and "y" both inequalities "x" ≤ "y" and "y" ≤ "x" hold then "x" and "y" must be equal. Similarly, the subset order ⊆ on the subsets of any given set is antisymmetric: given two sets "A" and "B", if every element in "A" also is in "B" and every element in "B" is also in "A", then "A" and "B" must contain all the same elements and therefore be equal:

Partial and total orders are antisymmetric by definition. A relation can be both symmetric and antisymmetric (e.g., the equality relation), and there are relations which are neither symmetric nor antisymmetric (e.g., the "preys on" relation on biological species).

Antisymmetry is different from asymmetry, which requires both antisymmetry and irreflexivity. Thus, every asymmetric relation is antisymmetric, but the reverse is false.




</doc>
<doc id="1177" url="https://en.wikipedia.org/wiki?curid=1177" title="Aleister Crowley">
Aleister Crowley

Aleister Crowley (; born Edward Alexander Crowley; 12 October 1875 – 1 December 1947) was an English occultist, ceremonial magician, poet, painter, novelist, and mountaineer. He founded the religion of Thelema, identifying himself as the prophet entrusted with guiding humanity into the Æon of Horus in the early 20th century. A prolific writer, he published widely over the course of his life.

Born to a wealthy family in Royal Leamington Spa, Warwickshire, Crowley rejected his parent's fundamentalist Christian Plymouth Brethren faith to pursue an interest in Western esotericism. He was educated at Trinity College at the University of Cambridge, where he focused his attentions on mountaineering and poetry, resulting in several publications. Some biographers allege that here he was recruited into a British intelligence agency, further suggesting that he remained a spy throughout his life. In 1898 he joined the esoteric Hermetic Order of the Golden Dawn, where he was trained in ceremonial magic by Samuel Liddell MacGregor Mathers and Allan Bennett. Moving to Boleskine House by Loch Ness in Scotland, he went mountaineering in Mexico with Oscar Eckenstein, before studying Hindu and Buddhist practices in India. He married Rose Edith Kelly and in 1904 they honeymooned in Cairo, Egypt, where Crowley claimed to have been contacted by a supernatural entity named Aiwass, who provided him with "The Book of the Law", a sacred text that served as the basis for Thelema. Announcing the start of the Æon of Horus, "The Book" declared that its followers should "Do what thou wilt" and seek to align themselves with their True Will through the practice of magick.

After an unsuccessful attempt to climb Kanchenjunga and a visit to India and China, Crowley returned to Britain, where he attracted attention as a prolific author of poetry, novels, and occult literature. In 1907, he and George Cecil Jones co-founded an esoteric order, the A∴A∴, through which they propagated Thelema. After spending time in Algeria, in 1912 he was initiated into another esoteric order, the German-based Ordo Templi Orientis (O.T.O.), rising to become the leader of its British branch, which he reformulated in accordance with his Thelemite beliefs. Through the O.T.O., Thelemite groups were established in Britain, Australia, and North America. Crowley spent the First World War in the United States, where he took up painting and campaigned for the German war effort against Britain, later revealing that he had infiltrated the pro-German movement to assist the British intelligence services. In 1920 he established the Abbey of Thelema, a religious commune in Cefalù, Sicily where he lived with various followers. His libertine lifestyle led to denunciations in the British press, and the Italian government evicted him in 1923. He divided the following two decades between France, Germany, and England, and continued to promote Thelema until his death.

Crowley gained widespread notoriety during his lifetime, being a recreational drug experimenter, bisexual and an individualist social critic. He was denounced in the popular press as "the wickedest man in the world" and a Satanist. Crowley has remained a highly influential figure over Western esotericism and the counterculture, and continues to be considered a prophet in Thelema. He is the subject of various biographies and academic studies.

Crowley was born as Edward Alexander Crowley at 30 Clarendon Square in Royal Leamington Spa, Warwickshire, on 12 October 1875. His father, Edward Crowley (1829–87), was trained as an engineer, but his share in a lucrative family brewing business, Crowley's Alton Ales, had allowed him to retire before his son was born. His mother, Emily Bertha Bishop (1848–1917), came from a Devonshire-Somerset family and had a strained relationship with her son; she described him as "the Beast", a name that he revelled in. The couple had been married at London's Kensington Registry Office in November 1874, and were evangelical Christians. Crowley's father had been born a Quaker, but had converted to the Exclusive Brethren, a faction of a Christian fundamentalist group known as the Plymouth Brethren, with Emily joining him upon marriage. Crowley's father was particularly devout, spending his time as a travelling preacher for the sect and reading a chapter from the Bible to his wife and son after breakfast every day. Following the death of their baby daughter in 1880, in 1881 the Crowleys moved to Redhill, Surrey. At the age of 8, Crowley was sent to H.T. Habershon's evangelical Christian boarding school in Hastings, and then to Ebor preparatory school in Cambridge, run by the Reverend Henry d'Arcy Champney, whom Crowley considered a sadist.

In March 1887, when Crowley was 11, his father died of tongue cancer. Crowley described this as a turning point in his life, and he always maintained an admiration of his father, describing him as "my hero and my friend". Inheriting a third of his father's wealth, he began misbehaving at school and was harshly punished by Champney; Crowley's family removed him from the school when he developed albuminuria. He then attended Malvern College and Tonbridge School, both of which he despised and left after a few terms. He became increasingly skeptical regarding Christianity, pointing out inconsistencies in the Bible to his religious teachers, and went against the Christian morality of his upbringing by smoking, masturbating, and having sex with prostitutes from whom he contracted gonorrhea. Sent to live with a Brethren tutor in Eastbourne, he undertook chemistry courses at Eastbourne College. Crowley developed interests in chess, poetry, and mountain climbing, and in 1894 climbed Beachy Head before visiting the Alps and joining the Scottish Mountaineering Club. The following year he returned to the Bernese Alps, climbing the Eiger, Trift, Jungfrau, Mönch, and Wetterhorn.

Having adopted the name of Aleister over Edward, in October 1895 Crowley began a three-year course at Trinity College, Cambridge, where he was entered for the Moral Science Tripos studying philosophy. With approval from his personal tutor, he changed to English literature, which was not then part of the curriculum offered. Crowley spent much of his time at university engaged in his pastimes, becoming president of the chess club and practising the game for two hours a day; he briefly considered a professional career as a chess player. Crowley also embraced his love of literature and poetry, particularly the works of Richard Francis Burton and Percy Bysshe Shelley. Many of his own poems appeared in student publications such as "The Granta", "Cambridge Magazine", and "Cantab". He continued his mountaineering, going on holiday to the Alps to climb every year from 1894 to 1898, often with his friend Oscar Eckenstein, and in 1897 he made the first ascent of the Mönch without a guide. These feats led to his recognition in the Alpine mountaineering community.

Crowley had his first significant mystical experience while on holiday in Stockholm in December 1896. Several biographers, including Lawrence Sutin, Richard Kaczynski, and Tobias Churton, believed that this was the result of Crowley's first same-sex sexual experience, which enabled him to recognise his bisexuality. At Cambridge, Crowley maintained a vigorous sex life with women—largely with female prostitutes, from one of whom he caught syphilis—but eventually he took part in same-sex activities, despite their illegality. In October 1897, Crowley met Herbert Charles Pollitt, president of the Cambridge University Footlights Dramatic Club, and the two entered into a relationship. They broke apart because Pollitt did not share Crowley's increasing interest in Western esotericism, a break-up that Crowley would regret for many years.

In 1897, Crowley travelled to Saint Petersburg in Russia, later claiming that he was trying to learn Russian as he was considering a future diplomatic career there. Biographers Richard Spence and Tobias Churton suggested that Crowley had done so as an intelligence agent under the employ of the British secret service, speculating that he had been enlisted while at Cambridge.

In October 1897, a brief illness triggered considerations of mortality and "the futility of all human endeavour", and Crowley abandoned all thoughts of a diplomatic career in favour of pursuing an interest in the occult. In March 1898, he obtained A.E. Waite's "The Book of Black Magic and of Pacts" (1898), and then Karl von Eckartshausen's "The Cloud Upon the Sanctuary" (1896), furthering his occult interests.
In 1898 Crowley privately published 100 copies of his poem "Aceldama: A Place to Bury Strangers In", but it was not a particular success. That same year he published a string of other poems, including "White Stains", a Decadent collection of erotic poetry that was printed abroad lest its publication be prohibited by the British authorities. In July 1898, he left Cambridge, not having taken any degree at all despite a "first class" showing in his 1897 exams and consistent "second class honours" results before that.

In August 1898, Crowley was in Zermatt, Switzerland, where he met the chemist Julian L. Baker, and the two began discussing their common interest in alchemy. Back in London, Baker introduced Crowley to George Cecil Jones, Baker's brother in-law, and a fellow member of the occult society known as the Hermetic Order of the Golden Dawn, which had been founded in 1888. Crowley was initiated into the Outer Order of the Golden Dawn on 18 November 1898 by the group's leader, Samuel Liddell MacGregor Mathers. The ceremony took place in the Golden Dawn's Isis-Urania Temple held at London's Mark Masons Hall, where Crowley took the magical motto and name "Frater Perdurabo", which he interpreted as "I shall endure to the end". Biographers Richard Spence and Tobias Churton have suggested that Crowley joined the Order under the command of the British secret services to monitor the activities of Mathers, who was known to be a Carlist.

Crowley moved into his own luxury flat at 67–69 Chancery Lane and soon invited a senior Golden Dawn member, Allan Bennett, to live with him as his personal magical tutor. Bennett taught Crowley more about ceremonial magic and the ritual use of drugs, and together they performed the rituals of the "Goetia", until Bennett left for South Asia to study Buddhism. In November 1899, Crowley purchased Boleskine House in Foyers on the shore of Loch Ness in Scotland. He developed a love of Scottish culture, describing himself as the "Laird of Boleskine", and took to wearing traditional highland dress, even during visits to London. He continued writing poetry, publishing "Jezebel and Other Tragic Poems", "Tales of Archais", "Songs of the Spirit", "Appeal to the American Republic", and "Jephthah" in 1898–99; most gained mixed reviews from literary critics, although "Jephthah" was considered a particular critical success.

Crowley soon progressed through the lower grades of the Golden Dawn, and was ready to enter the group's inner Second Order. He was unpopular in the group; his bisexuality and libertine lifestyle had gained him a bad reputation, and he had developed feuds with some of the members, including W. B. Yeats. When the Golden Dawn's London lodge refused to initiate Crowley into the Second Order, he visited Mathers in Paris, who personally admitted him into the Adeptus Minor Grade. A schism had developed between Mathers and the London members of the Golden Dawn, who were unhappy with his autocratic rule. Acting under Mathers' orders, Crowley – with the help of his mistress and fellow initiate Elaine Simpson – attempted to seize the Vault of the Adepts, a temple space at 36 Blythe Road in West Kensington, from the London lodge members. When the case was taken to court, the judge ruled in favour of the London lodge, as they had paid for the space's rent, leaving both Crowley and Mathers isolated from the group. Spence suggested that the entire scenario was part of an intelligence operation to undermine Mathers' authority.

In 1900, Crowley travelled to Mexico via the United States, settling in Mexico City and starting a relationship with a local woman. Developing a love of the country, he continued experimenting with ceremonial magic, working with John Dee's Enochian invocations. He later claimed to have been initiated into Freemasonry while there, and he wrote a play based on Richard Wagner's "Tannhäuser" as well as a series of poems, published as "Oracles" (1905). Eckenstein joined him later that year, and together they climbed several mountains, including Iztaccihuatl, Popocatepetl, and Colima, the latter of which they had to abandon owing to a volcanic eruption. Spence has suggested that the purpose of the trip might have been to explore Mexican oil prospects for British intelligence. Leaving Mexico, Crowley headed to San Francisco before sailing for Hawaii aboard the "Nippon Maru". On the ship he had a brief affair with a married woman named Mary Alice Rogers; saying he had fallen in love with her, he wrote a series of poems about the romance, published as "Alice: An Adultery" (1903).
Briefly stopping in Japan and Hong Kong, Crowley reached Ceylon, where he met with Allan Bennett, who was there studying Shaivism. The pair spent some time in Kandy before Bennett decided to become a Buddhist monk in the Theravada tradition, travelling to Burma to do so. Crowley decided to tour India, devoting himself to the Hindu practice of "Rāja yoga", from which he claimed to have achieved the spiritual state of "dhyana". He spent much of this time studying at the Meenakshi Temple in Madura. At this time he also composed and also wrote poetry which was published as "The Sword of Song" (1904). He contracted malaria, and had to recuperate from the disease in Calcutta and Rangoon. In 1902, he was joined in India by Eckenstein and several other mountaineers: Guy Knowles, H. Pfannl, V. Wesseley, and Jules Jacot-Guillarmod. Together the Eckenstein-Crowley expedition attempted K2, which had never been climbed. On the journey, Crowley was afflicted with influenza, malaria, and snow blindness, and other expedition members were also struck with illness. They reached an altitude of before turning back.

Having arrived in Paris in November 1902 he socialised with friend and future brother-in-law, the painter Gerald Kelly, and through him became a fixture of the Parisian arts scene. Whilst there, Crowley wrote a series of poems on the work of an acquaintance, the sculptor Auguste Rodin. These poems were later published as "Rodin in Rime" (1907). One of those frequenting this milieu was W. Somerset Maugham, who after briefly meeting Crowley later used him as a model for the character of Oliver Haddo in his novel "The Magician" (1908). Returning to Boleskine in April 1903, in August Crowley wed Gerald's sister Rose Edith Kelly in a "marriage of convenience" to prevent her entering an arranged marriage; the marriage appalled the Kelly family and damaged his friendship with Gerald. Heading on a honeymoon to Paris, Cairo, and then Ceylon, Crowley fell in love with Rose and worked to prove his affections. While on his honeymoon, he wrote her a series of love poems, published as "Rosa Mundi and other Love Songs" (1906), as well as authoring the religious satire "Why Jesus Wept" (1904).

In February 1904, Crowley and Rose arrived in Cairo. Claiming to be a prince and princess, they rented an apartment in which Crowley set up a temple room and began invoking ancient Egyptian deities, while studying Islamic mysticism and Arabic. According to Crowley's later account, Rose regularly became delirious and informed him "they are waiting for you." On 18 March, she explained that "they" were the god Horus, and on 20 March proclaimed that "the Equinox of the Gods has come". She led him to a nearby museum, where she showed him a seventh-century BCE mortuary stele known as the Stele of Ankh-ef-en-Khonsu; Crowley thought it important that the exhibit's number was 666, the Number of the Beast in Christian belief, and in later years termed the artefact the "Stele of Revealing."

According to Crowley's later statements, on 8 April he heard a disembodied voice that claimed to be that of Aiwass, the messenger of Horus, or Hoor-Paar-Kraat. Crowley said that he wrote down everything the voice told him over the course of the next three days, and titled it "Liber AL vel Legis" or "The Book of the Law". The book proclaimed that humanity was entering a new Aeon, and that Crowley would serve as its prophet. It stated that a supreme moral law was to be introduced in this Aeon, "Do what thou wilt shall be the whole of the Law," and that people should learn to live in tune with their Will. This book, and the philosophy that it espoused, became the cornerstone of Crowley's religion, Thelema. Crowley said that at the time he had been unsure what to do with "The Book of the Law". Often resenting it, he said that he ignored the instructions which the text commanded him to perform, which included taking the Stele of Revealing from the museum, fortifying his own island, and translating the book into all the world's languages. According to his account, he instead sent typescripts of the work to several occultists he knew, putting the manuscript away and ignoring it.

Returning to Boleskine, Crowley came to believe that Mathers had begun using magic against him, and the relationship between the two broke down. On 28 July 1905, Rose gave birth to Crowley's first child, a daughter named Lilith, with Crowley writing the pornographic "Snowdrops From a Curate's Garden" to entertain his recuperating wife. He also founded a publishing company through which to publish his poetry, naming it the Society for the Propagation of Religious Truth in parody of the Society for Promoting Christian Knowledge. Among its first publications were Crowley's "Collected Works", edited by Ivor Back. His poetry often received strong reviews (either positive or negative), but never sold well. In an attempt to gain more publicity, he issued a reward of £100 for the best essay on his work. The winner of this was J. F. C. Fuller, a British Army officer and military historian, whose essay, "The Star in the West" (1907), heralded Crowley's poetry as some of the greatest ever written.

Crowley decided to climb Kanchenjunga in the Himalayas of Nepal, widely recognised as the world's most treacherous mountain. Assembling a team consisting of Jacot-Guillarmod, Charles Adolphe Reymond, Alexis Pache, and Alcesti C. Rigo de Righi, the expedition was marred by much argument between Crowley and the others, who thought that he was reckless. They eventually mutinied against Crowley's control, with the other climbers heading back down the mountain as nightfall approached despite Crowley's warnings that it was too dangerous. Subsequently, Pache and several porters were killed in an accident, something for which Crowley was widely blamed by the mountaineering community.

Spending time in Moharbhanj, where he took part in big-game hunting and wrote the homoerotic work "The Scented Garden", Crowley met up with Rose and Lilith in Calcutta before being forced to leave India after non-lethally shooting two men who tried to mug him. Briefly visiting Bennett in Burma, Crowley and his family decided to tour Southern China, hiring porters and a nanny for the purpose. Spence has suggested that this trip to China was orchestrated as part of a British intelligence scheme to monitor the region's opium trade. Crowley smoked opium throughout the journey, which took the family from Tengyueh through to Yungchang, Tali, Yunnanfu, and then Hanoi. On the way he spent much time on spiritual and magical work, reciting the "Bornless Ritual", an invocation to his Holy Guardian Angel, on a daily basis.

While Rose and Lilith returned to Europe, Crowley headed to Shanghai to meet old friend Elaine Simpson, who was fascinated by "The Book of the Law"; together they performed rituals in an attempt to contact Aiwass. Crowley then sailed to Japan and Canada, before continuing to New York City, where he unsuccessfully solicited support for a second expedition up Kanchenjunga. Upon arrival in Britain, Crowley learned that his daughter Lilith had died of typhoid in Rangoon, something he later blamed on Rose's increasing alcoholism. Under emotional distress, his health began to suffer, and he underwent a series of surgical operations. He began short-lived romances with actress Vera "Lola" Neville (née Snepp) and author Ada Leverson, while Rose gave birth to Crowley's second daughter, Lola Zaza, in February 1907.

With his old mentor George Cecil Jones, Crowley continued performing the Abramelin rituals at the Ashdown Park Hotel in Coulsdon, Surrey. Crowley claimed that in doing so he attained "samadhi", or union with Godhead, thereby marking a turning point in his life. Making heavy use of hashish during these rituals, he wrote an essay on "The Psychology of Hashish" (1909) in which he championed the drug as an aid to mysticism. He also claimed to have been contacted once again by Aiwass in late October and November 1907, adding that Aiwass dictated two further texts to him, "Liber VII" and "Liber Cordis Cincti Serpente", both of which were later classified in the corpus of The Holy Books of Thelema. Crowley wrote down more Thelemic Holy Books during the last two months of the year, including "Liber LXVI", "Liber Arcanorum", "Liber Porta Lucis, Sub Figura X", "Liber Tau", "Liber Trigrammaton" and "Liber DCCCXIII vel Ararita", which he again claimed to have received from a preternatural source. Crowley stated that in June 1909, when the manuscript of "The Book of the Law" was rediscovered at Boleskine, he developed the opinion that Thelema represented objective truth.

Crowley's inheritance was running out. Trying to earn money, he was hired by George Montagu Bennett, the Earl of Tankerville, to help protect him from witchcraft; recognising Bennett's paranoia as being based in his cocaine addiction, Crowley took him on holiday to France and Morocco to recuperate. In 1907, he also began taking in paying students, whom he instructed in occult and magical practice. Victor Neuburg, whom Crowley met in February 1907, became his sexual partner and closest disciple; in 1908 the pair toured northern Spain before heading to Tangier, Morocco. The following year Neuburg stayed at Boleskine, where he and Crowley engaged in sadomasochism. Crowley continued to write prolifically, producing such works of poetry as "Ambergris", "Clouds Without Water", and "Konx Om Pax", as well as his first attempt at an autobiography, "The World's Tragedy". Recognising the popularity of short horror stories, Crowley wrote his own, some of which were published, and he also published several articles in "Vanity Fair", a magazine edited by his friend Frank Harris. He also wrote "Liber 777", a book of magical and Qabalistic correspondences that borrowed from Mathers and Bennett.

In November 1907, Crowley and Jones decided to found an occult order to act as a successor to the Hermetic Order of the Golden Dawn, being aided in doing so by Fuller. The result was the A∴A∴. The group's headquarters and temple were situated at 124 Victoria Street in central London, and their rites borrowed much from those of the Golden Dawn, but with an added Thelemic basis. Its earliest members included solicitor Richard Noel Warren, artist Austin Osman Spare, Horace Sheridan-Bickers, author George Raffalovich, Francis Henry Everard Joseph Feilding, engineer Herbert Edward Inman, Kenneth Ward, and Charles Stansfeld Jones. In March 1909, Crowley began production of a biannual periodical titled "The Equinox". He billed this periodical, which was to become the "Official Organ" of the A∴A∴, as "The Review of Scientific Illuminism".

Crowley had become increasingly frustrated with Rose's alcoholism, and in November 1909 he divorced her on the grounds of his own adultery. Lola was entrusted to Rose's care; the couple remained friends and Rose continued to live at Boleskine. Her alcoholism worsened, and as a result she was institutionalised in September 1911.

In November 1909, Crowley and Neuburg travelled to Algeria, touring the desert from El Arba to Aumale, Bou Saâda, and then Dā'leh Addin, with Crowley reciting the Quran on a daily basis. During the trip he invoked the thirty aethyrs of Enochian magic, with Neuburg recording the results, later published in "The Equinox" as "The Vision and the Voice". Following a mountaintop sex magic ritual, Crowley also performed an invocation to the demon Choronzon involving blood sacrifice, considering the results to be a watershed in his magical career. Returning to London in January 1910, Crowley found that Mathers was suing him for publishing Golden Dawn secrets in "The Equinox"; the court found in favour of Crowley. The case was widely reported in the press, with Crowley gaining wider fame. Crowley enjoyed this, and played up to the sensationalist stereotype of being a Satanist and advocate of human sacrifice, despite being neither.

The publicity attracted new members to the A∴A∴, among them Frank Bennett, James Bayley, Herbert Close, and James Windram. The Australian violinist Leila Waddell soon became Crowley's lover. Deciding to expand his teachings to a wider audience, Crowley developed the Rites of Artemis, a public performance of magic and symbolism featuring A∴A∴ members personifying various deities. It was first performed at the A∴A∴ headquarters, with attendees given a fruit punch containing peyote to enhance their experience. Various members of the press attended, and reported largely positively on it. In October and November 1910, Crowley decided to stage something similar, the Rites of Eleusis, at Caxton Hall, Westminster; this time press reviews were mixed. Crowley came under particular criticism from West de Wend Fenton, editor of "The Looking Glass" newspaper, who called him "one of the most blasphemous and cold-blooded villains of modern times". Fenton's articles suggested that Crowley and Jones were involved in homosexual activity; Crowley did not mind, but Jones unsuccessfully sued for libel. Fuller broke off his friendship and involvement with Crowley over the scandal, and Crowley and Neuburg returned to Algeria for further magical workings.

"The Equinox" continued publishing, and various books of literature and poetry were also published under its imprint, like Crowley's "Ambergris", "The Winged Beetle", and "The Scented Garden", as well as Neuburg's "The Triumph of Pan" and Ethel Archer's "The Whirlpool". In 1911, Crowley and Waddell holidayed in Montigny-sur-Loing, where he wrote prolifically, producing poems, short stories, plays, and 19 works on magic and mysticism, including the two final Holy Books of Thelema. In Paris, he met Mary Desti, who became his next "Scarlet Woman", with the two undertaking magical workings in St. Moritz; Crowley believed that one of the Secret Chiefs, Ab-ul-Diz, was speaking through her. Based on Desti's statements when in trance, Crowley wrote the two-volume "Book 4" (1912–13) and at the time developed the spelling "magick" in reference to the paranormal phenomenon as a means of distinguishing it from the stage magic of illusionists.

In early 1912, Crowley published "The Book of Lies", a work of mysticism that biographer Lawrence Sutin described as "his greatest success in merging his talents as poet, scholar, and magus". The German occultist Theodor Reuss later accused him of publishing some of the secrets of his own occult order, the Ordo Templi Orientis (O.T.O.), within "The Book". Crowley convinced Reuss that the similarities were coincidental, and the two became friends. Reuss appointed Crowley as head of the O.T.O's British branch, the Mysteria Mystica Maxima (MMM), and at a ceremony in Berlin Crowley adopted the magical name of Baphomet and was proclaimed "X° Supreme Rex and Sovereign Grand Master General of Ireland, Iona, and all the Britons". With Reuss' permission, Crowley set about advertising the MMM and re-writing many O.T.O. rituals, which were then based largely on Freemasonry; his incorporation of Thelemite elements proved controversial in the group. Fascinated by the O.T.O's emphasis on sex magic, Crowley devised a magical working based on anal sex and incorporated it into the syllabus for those O.T.O. members who had been initiated into the eleventh degree.

In March 1913 Crowley acted as producer for "The Ragged Ragtime Girls", a group of female violinists led by Waddell, as they performed at London's Old Tivoli theatre. They subsequently performed in Moscow for six weeks, where Crowley had a sadomasochistic relationship with the Hungarian Anny Ringler. In Moscow, Crowley continued to write plays and poetry, including "Hymn to Pan", and the Gnostic Mass, a Thelemic ritual that became a key part of O.T.O. liturgy. Churton suggested that Crowley had travelled to Moscow on the orders of British intelligence to spy on revolutionary elements in the city. In January 1914 Crowley and Neuburg settled into an apartment in Paris, where the former was involved in the controversy surrounding Jacob Epstein's new monument to Oscar Wilde. Together Crowley and Neuburg performed the six-week "Paris Working", a period of intense ritual involving strong drug use in which they invoked the gods Mercury and Jupiter. As part of the ritual, the couple performed acts of sex magic together, at times being joined by journalist Walter Duranty. Inspired by the results of the Working, Crowley wrote "Liber Agapé", a treatise on sex magic. Following the Paris Working, Neuburg began to distance himself from Crowley, resulting in an argument in which Crowley cursed him.

By 1914 Crowley was living a hand-to-mouth existence, relying largely on donations from A∴A∴ members and dues payments made to O.T.O. In May he transferred ownership of Boleskine House to the MMM for financial reasons, and in July he went mountaineering in the Swiss Alps. During this time the First World War broke out.
After recuperating from a bout of phlebitis, Crowley set sail for the United States aboard the RMS "Lusitania" in October 1914. Arriving in New York City, he moved into a hotel and began earning money writing for the American edition of "Vanity Fair" and undertaking freelance work for the famed astrologer Evangeline Adams. In the city, he continued experimenting with sex magic, through the use of masturbation, female prostitutes, and male clients of a Turkish bathhouse; all of these encounters were documented in his diaries.

Professing to be of Irish ancestry and a supporter of Irish independence from Great Britain, Crowley began to espouse support for Germany in their war against Britain. He became involved in New York's pro-German movement, and in January 1915 German spy George Sylvester Viereck employed him as a writer for his propagandist paper, "The Fatherland", which was dedicated to keeping the US neutral in the conflict. In later years, detractors denounced Crowley as a traitor to Britain for this action. In reality, Crowley was a double agent, working for the British intelligence services to infiltrate and undermine Germany's operation in New York. Many of his articles in "The Fatherland" were hyperbolic, for instance comparing Wilhelm II to Jesus Christ; in July 1915 he orchestrated a publicity stunt – reported on by "The New York Times" – in which he declared independence for Ireland in front of the Statue of Liberty; the real intention was to make the German lobby appear ridiculous in the eyes of the American public. It has been argued that he encouraged the German Navy to destroy the "Lusitania", informing them that it would ensure the US stayed out of the war, while in reality hoping that it would bring the US into the war on Britain's side.

Crowley entered into a relationship with Jeanne Robert Foster, with whom he toured the West Coast. In Vancouver, headquarters of the North American O.T.O., he met with Charles Stansfeld Jones and Wilfred Talbot Smith to discuss the propagation of Thelema on the continent. In Detroit he experimented with Peyote at Parke-Davis, then visited Seattle, San Francisco, Santa Cruz, Los Angeles, San Diego, Tijuana, and the Grand Canyon, before returning to New York. There he befriended Ananda Coomaraswamy and his wife Alice Richardson; Crowley and Richardson performed sex magic in April 1916, following which she became pregnant and then miscarried. Later that year he took a "magical retirement" to a cabin by Lake Pasquaney owned by Evangeline Adams. There, he made heavy use of drugs and undertook a ritual after which he proclaimed himself "Master Therion". He also wrote several short stories based on J.G. Frazer's "The Golden Bough" and a work of literary criticism, "The Gospel According to Bernard Shaw".

In December he moved to New Orleans, his favourite US city, before spending February 1917 with evangelical Christian relatives in Titusville, Florida. Returning to New York City, he moved in with artist and A∴A∴ member Leon Engers Kennedy in May, learning of his mother's death. After the collapse of "The Fatherland", Crowley continued his association with Viereck, who appointed him contributing editor of arts journal "The International". Crowley used it to promote Thelema, but it soon ceased publication. He then moved to the studio apartment of Roddie Minor, who became his partner and Scarlet Woman. Through their rituals, which Crowley called "The Amalantrah Workings", he believed that they were contacted by a preternatural entity named Lam. The relationship soon ended.

In 1918, Crowley went on a magical retreat in the wilderness of Esopus Island on the Hudson River. Here, he began a translation of the "Tao Te Ching", painted Thelemic slogans on the riverside cliffs, and – he later claimed – experienced past life memories of being Ge Xuan, Pope Alexander VI, Alessandro Cagliostro, and Eliphas Levi. Back in New York City, he moved to Greenwich Village, where he took Leah Hirsig as his lover and next Scarlet Woman. He took up painting as a hobby, exhibiting his work at the Greenwich Village Liberal Club and attracting the attention of the "New York Evening World". With the financial assistance of sympathetic Freemasons, Crowley revived "The Equinox" with the first issue of volume III, known as "The Blue Equinox". He spent mid-1919 on a climbing holiday in Montauk before returning to London in December.

Now destitute and back in London, Crowley came under attack from the tabloid "John Bull", which labelled him traitorous "scum" for his work with the German war effort; several friends aware of his intelligence work urged him to sue, but he decided not to. When he was suffering from asthma, a doctor prescribed him heroin, to which he soon became addicted. In January 1920, he moved to Paris, renting a house in Fontainebleau with Leah Hirsig; they were soon joined in a "ménage à trois" by Ninette Shumway, and also (in living arrangement) by Leah's newborn daughter Anne "Poupée" Leah. Crowley had ideas of forming a community of Thelemites, which he called the Abbey of Thelema after the Abbaye de Thélème in François Rabelais' satire "Gargantua and Pantagruel". After consulting the "I Ching", he chose Cefalù (on Sicily, Italy) as a location, and after arriving there, began renting the old Villa Santa Barbara as his Abbey on 2 April.
Moving to the commune with Hirsig, Shumway, and their children Hansi, Howard, and Poupée, Crowley described the scenario as "perfectly happy ... my idea of heaven." They wore robes, and performed rituals to the sun god Ra at set times during the day, also occasionally performing the Gnostic Mass; the rest of the day they were left to follow their own interests. Undertaking widespread correspondences, Crowley continued to paint, wrote a commentary on "The Book of the Law", and revised the third part of "Book 4". He offered a libertine education for the children, allowing them to play all day and witness acts of sex magic. He occasionally travelled to Palermo to visit rent boys and buy supplies, including drugs; his heroin addiction came to dominate his life, and cocaine began to erode his nasal cavity. There was no cleaning rota, and wild dogs and cats wandered throughout the building, which soon became unsanitary. Poupée died in October 1920, and Ninette gave birth to a daughter, Astarte Lulu Panthea, soon afterwards.

New followers continued to arrive at the Abbey to be taught by Crowley. Among them was film star Jane Wolfe, who arrived in July 1920, where she was initiated into the A∴A∴ and became Crowley's secretary. Another was Cecil Frederick Russell, who often argued with Crowley, disliking the same-sex sexual magic that he was required to perform, and left after a year. More conducive was the Australian Thelemite Frank Bennett, who also spent several months at the Abbey. In February 1922, Crowley returned to Paris for a retreat in an unsuccessful attempt to kick his heroin addiction. He then went to London in search of money, where he published articles in "The English Review" criticising the Dangerous Drugs Act 1920 and wrote a novel, "Diary of a Drug Fiend", completed in July. On publication, it received mixed reviews; he was lambasted by the "Sunday Express", which called for its burning and used its influence to prevent further reprints.

Subsequently, a young Thelemite named Raoul Loveday moved to the Abbey with his wife Betty May; while Loveday was devoted to Crowley, May detested him and life at the commune. She later said that Loveday was made to drink the blood of a sacrificed cat, and that they were required to cut themselves with razors every time they used the pronoun "I". Loveday drank from a local polluted stream, soon developing a liver infection resulting in his death in February 1923. Returning to London, May told her story to the press. "John Bull" proclaimed Crowley "the wickedest man in the world" and "a man we'd like to hang", and although Crowley deemed many of their accusations against him to be slanderous, he was unable to afford the legal fees to sue them. As a result, "John Bull" continued its attack, with its stories being repeated in newspapers throughout Europe and in North America. The Fascist government of Benito Mussolini learned of Crowley's activities and in April 1923 he was given a deportation notice forcing him to leave Italy; without him, the Abbey closed.

Crowley and Hirsig went to Tunis, where, dogged by continuing poor health, he unsuccessfully tried again to give up heroin, and began writing what he termed his "autohagiography", "The Confessions of Aleister Crowley". They were joined in Tunis by the Thelemite Norman Mudd, who became Crowley's public relations consultant. Employing a local boy, Mohammad ben Brahim, as his servant, Crowley went with him on a retreat to Nefta, where they performed sex magic together. In January 1924, Crowley travelled to Nice, France, where he met with Frank Harris, underwent a series of nasal operations, and visited the Institute for the Harmonious Development of Man and had a positive opinion of its founder, George Gurdjieff. Destitute, he took on a wealthy student, Alexander Zu Zolar, before taking on another American follower, Dorothy Olsen. Crowley took Olsen back to Tunisia for a magical retreat in Nefta, where he also wrote "To Man" (1924), a declaration of his own status as a prophet entrusted with bringing Thelema to humanity. After spending the winter in Paris, in early 1925 Crowley and Olsen returned to Tunis, where he wrote "The Heart of the Master" (1938) as an account of a vision he experienced in a trance. In March Olsen became pregnant, and Hirsig was called to take care of her; she miscarried, following which Crowley took Olsen back to France. Hirsig later distanced herself from Crowley, who then denounced her.

According to Crowley, Reuss had named him head of the O.T.O. upon his death, but this was challenged by a leader of the German O.T.O., Heinrich Tränker. Tränker called the Hohenleuben Conference in Thuringia, Germany, which Crowley attended. There, prominent members like Karl Germer and Martha Küntzel championed Crowley's leadership, but other key figures like Albin Grau, Oskar Hopfer, and Henri Birven backed Tränker by opposing it, resulting in a split in the O.T.O. Moving to Paris, where he broke with Olsen in 1926, Crowley went through a large number of lovers over the following years, with whom he experimented in sex magic. Throughout, he was dogged by poor health, largely caused by his heroin and cocaine addictions. In 1928, Crowley was introduced to young Englishman Israel Regardie, who embraced Thelema and became Crowley's secretary for the next three years. That year, Crowley also met Gerald Yorke, who began organising Crowley's finances but never became a Thelemite. He also befriended the homosexual journalist Tom Driberg; Driberg did not accept Thelema either. It was here that Crowley also published one of his most significant works, "Magick in Theory and Practice", which received little attention at the time.

In December 1928 Crowley met the Nicaraguan Maria Teresa Sanchez. Crowley was deported from France by the authorities, who disliked his reputation and feared that he was a German agent. So that she could join him in Britain, Crowley married Sanchez in August 1929. Now based in London, Mandrake Press agreed to publish his autobiography in a limited edition six-volume set, also publishing his novel "Moonchild" and book of short stories "The Stratagem". Mandrake went into liquidation in November 1930, before the entirety of Crowley's "Confessions" could be published. Mandrake's owner P.R. Stephenson meanwhile wrote "The Legend of Aleister Crowley", an analysis of the media coverage surrounding him.

In April 1930, Crowley moved to Berlin, where he took Hanni Jaegar as his magical partner; the relationship was troubled. In September he went to Lisbon in Portugal to meet the poet Fernando Pessoa. There, he decided to fake his own death, doing so with Pessoa's help at the Boca do Inferno rock formation. He then returned to Berlin, where he reappeared three weeks later at the opening of his art exhibition at the Gallery Neumann-Nierendorf. Crowley's paintings fitted with the fashion for German Expressionism; few of them sold, but the press reports were largely favourable. In August 1931, he took Bertha Busch as his new lover; they had a violent relationship, and often physically assaulted one another. He continued to have affairs with both men and women while in the city, and met with famous people like Aldous Huxley and Alfred Adler. After befriending him, in January 1932 he took the communist Gerald Hamilton as a lodger, through whom he was introduced to many figures within the Berlin far left; it is possible that he was operating as a spy for British intelligence at this time, monitoring the communist movement.

Crowley left Busch and returned to London, where he took Pearl Brooksmith as his new Scarlet Woman. Undergoing further nasal surgery, it was here in 1932 that he was invited to be guest of honour at Foyles' Literary Luncheon, also being invited by Harry Price to speak at the National Laboratory of Psychical Research. In need of money, he launched a series of court cases against people whom he believed had libelled him, some of which proved successful. He gained much publicity for his lawsuit against Constable and Co for publishing Nina Hamnett's "Laughing Torso" (1932) – a book he thought libelled him – but lost the case. The court case added to Crowley's financial problems, and in February 1935 he was declared bankrupt. During the hearing, it was revealed that Crowley had been spending three times his income for several years.

Crowley developed a friendship with Deidre Patricia Doherty; she offered to bear his child, who was born in May 1937. Named Randall Gair, Crowley nicknamed him Aleister Atatürk. Crowley continued to socialise with friends, holding curry parties in which he cooked particularly spicy food for them. In 1936, he published his first book in six years, "The Equinox of the Gods", which contained a facsimile of "The Book of the Law" and was considered to be volume III, number 3, of "The Equinox" periodical. The work sold well, resulting in a second print run. In 1937 he gave a series of public lectures on yoga in Soho. Crowley was now living largely off contributions supplied by the O.T.O.'s Agape Lodge in California, led by rocket scientist John Whiteside "Jack" Parsons. Crowley was intrigued by the rise of Nazism in Germany, and influenced by his friend Martha Küntzel believed that Adolf Hitler might convert to Thelema; when the Nazis abolished the German O.T.O. and imprisoned Germer, who fled to the US, Crowley then lambasted Hitler as a black magician.

When the Second World War broke out, Crowley wrote to the Naval Intelligence Division offering his services, but they declined. He associated with a variety of figures in Britain's intelligence community at the time, including Dennis Wheatley, Roald Dahl, Ian Fleming, and Maxwell Knight, and claimed to have been behind the "V for Victory" sign first used by the BBC; this has never been proven.
In 1940, his asthma worsened, and with his German-produced medication unavailable, he returned to using heroin, once again becoming addicted. As the Blitz hit London, Crowley relocated to Torquay, where he was briefly hospitalised with asthma, and entertained himself with visits to the local chess club. Tiring of Torquay, he returned to London, where he was visited by American Thelemite Grady McMurtry, to whom Crowley awarded the title of "Hymenaeus Alpha". He stipulated that though Germer would be his immediate successor, McMurty should succeed Germer as head of the O.T.O. after the latter's death. With O.T.O. initiate Lady Frieda Harris, Crowley developed plans to produce a tarot card set, designed by him and painted by Harris. Accompanying this was a book, published in a limited edition as "The Book of Thoth" by Chiswick Press in 1944. To aid the war effort, he wrote a proclamation on the rights of humanity, "Liber Oz", and a poem for the liberation of France, "Le Gauloise". Crowley's final publication during his lifetime was a book of poetry, "Olla: An Anthology of Sixty Years of Song". Another of his projects, "Aleister Explains Everything", was posthumously published as "Magick Without Tears".

In April 1944 Crowley briefly moved to Aston Clinton in Buckinghamshire, where he was visited by the poet Nancy Cunard, before relocating to Hastings in Sussex, where he took up residence at the Netherwood boarding house. He took a young man named Kenneth Grant as his secretary, paying him in magical teaching rather than wages. He was also introduced to John Symonds, whom he appointed to be his literary executor; Symonds thought little of Crowley, later publishing negative biographies of him. Corresponding with the illusionist Arnold Crowther, it was through him that Crowley was introduced to Gerald Gardner, the future founder of Gardnerian Wicca. They became friends, with Crowley authorising Gardner to revive Britain's ailing O.T.O. Another visitor was Eliza Marian Butler, who interviewed Crowley for her book "The Myth of the Magus". Other friends and family also spent time with him, among them Doherty and Crowley's son Aleister Atatürk. On 1 December 1947, Crowley died at Netherwood of chronic bronchitis aggravated by pleurisy and myocardial degeneration, aged 72. His funeral was held at a Brighton crematorium on 5 December; about a dozen people attended, and Louis Wilkinson read excerpts from the Gnostic Mass, "The Book of the Law", and "Hymn to Pan". The funeral generated press controversy, and was labelled a Black Mass by the tabloids. Crowley's ashes were sent to Karl Germer in the US, who buried them in his garden in Hampton, New Jersey.

Crowley's belief system, Thelema, has been described by scholars as a religion, and more specifically as both a new religious movement, and as a "magico-religious doctrine". It has also been characterised as a form of esotericism and modern Paganism. Although holding "The Book of the Law"—which was composed in 1904—as its central text, Thelema took shape as a complete system in the years after 1904.

In his autobiography, Crowley claimed that his purpose in life had been to "bring oriental wisdom to Europe and to restore paganism in a purer form", although what he meant by "paganism" was unclear.
Crowley's thought was not always cohesive, and was influenced by a variety of sources, ranging from eastern religious movements and practices like Hindu yoga and Buddhism, scientific naturalism, and various currents within Western esotericism, among them ceremonial magic, alchemy, astrology, Rosicrucianism, Kabbalah, and the Tarot. He was steeped in the esoteric teachings he had learned from the Hermetic Order of the Golden Dawn, although pushed further with his own interpretations and strategies than the Golden Dawn had done. Crowley incorporated concepts and terminology from South Asian religious traditions like yoga and Tantra into his Thelemic system, believing that there was a fundamental underlying resemblance between Western and Eastern spiritual systems.
The historian Alex Owen noted that Crowley adhered to the "modus operandi" of the Decadent movement throughout his life.

Crowley believed that the twentieth century marked humanity's entry to the Aeon of Horus, a new era in which humans would take increasing control of their destiny. He believed that this Aeon follows on from the Aeon of Osiris, in which paternalistic religions like Christianity, Islam, and Buddhism dominated the world, and that this in turn had followed the Aeon of Isis, which had been maternalistic and dominated by goddess worship. He believed that Thelema was the proper religion of the Aeon of Horus, and also deemed himself to be the prophet of this new Aeon. Thelema revolves around the idea that human beings each have their own True Will that they should discover and pursue, and that this exists in harmony with the Cosmic Will that pervades the universe. Crowley referred to this process of searching and discovery of one's True Will to be "the Great Work" or the attaining of the "knowledge and conversation of the Holy Guardian Angel". His favoured method of doing so was through the performance of the Abramelin operation, a ceremonial magic ritual obtained from a 17th-century grimoire. The moral code of "Do What Thou Wilt" is believed by Thelemites to be the religion's ethical law, although the historian of religion Marco Pasi noted that this was not anarchistic or libertarian in structure, as Crowley saw individuals as part of a wider societal organism.

Crowley believed in the objective existence of magic, which he chose to spell "Magick", an older archaic spelling of the word. He provided various different definitions of this term over his career. In his book "Magick in Theory and Practice", Crowley defined Magick as "the Science and Art of causing change to occur in conformity with Will". He also told his disciple Karl Germer that "Magick is getting into communication with individuals who exist on a higher plane than ours. Mysticism is the raising of oneself to their level." Crowley saw Magick as a third way between religion and science, giving "The Equinox" the subtitle of "The Method of Science; the Aim of Religion". Within that journal he expressed positive sentiments toward science and the scientific method, and urged magicians to keep detailed records of their magical experiments, "The more scientific the record is, the better." His understanding of magic was also influenced by the work of the anthropologist James Frazer, in particular the view that magic was a precursor to science in a cultural evolutionary framework. Unlike Frazer, however, Crowley did not see magic as a survival from the past that required eradication, but rather he believed that magic had to be adapted to suit the new age of science. In Crowley's alternative schema, old systems of "magic" had to decline (per Frazer's framework) so that science and magic could synthesize into "magick", which would simultaneously accept the existence of the supernatural and an experimental method. Crowley deliberately adopted an exceptionally broad definition of magick that included almost all forms of technology as magick, adopting an instrumentalist interpretation of magic, science, and technology.

Sexuality played an important role in Crowley's ideas about magick and his practice of it, and has been described as being central to Thelema. He outlined three forms of sex magick—the autoerotic, homosexual, and heterosexual—and argued that such acts could be used to focus the magician's will onto a specific goal such as financial gain or personal creative success. For Crowley, sex was treated as a sacrament, with the consumption of sexual fluids interpreted as a Eucharist. This was often manifested as the Cakes of Light, a biscuit containing either menstrual blood or a mixture of semen and vaginal fluids. The Gnostic Mass is the central religious ceremony within Thelema.

Crowley's theological beliefs were not clear. The historian Ronald Hutton noted that some of Crowley's writings could be used to argue that he was an atheist, while some support the idea that he was a polytheist, and others would bolster the idea that he was a mystical monotheist. On the basis of the teachings in "The Book of the Law", Crowley described a pantheon of three deities taken from the ancient Egyptian pantheon: Nuit, Hadit, and Ra-Hoor-Khuit. In 1928, he made the claim that all "true" deities were "derived" from this trinity. Jason Josephson-Storm has argued that Crowley built on 19th-century attempts to link early Christianity to Paganism, such as Frazer's "Golden Bough", to synthesize Christian theology and Neopaganism while remaining critical of institutional and traditional Christianity.

Both during his life and after it, Crowley has been widely described as a Satanist, usually by detractors. Crowley stated he did not consider himself a Satanist, nor did he worship Satan, as he did not accept the Christian world view in which Satan was believed to exist. He nevertheless used Satanic imagery, for instance by describing himself as "the Beast 666" and referring to the Whore of Babylon in his work, while in later life he sent "Antichristmas cards" to his friends. In his writings, Crowley occasionally identified Aiwass as Satan and designated him as "Our Lord God the Devil" at one occasion. The scholar of religion Gordan Djurdjevic stated that Crowley "was emphatically not" a Satanist, "if for no other reason than simply because he did not identify himself as such". Crowley nevertheless expressed anti-Christian sentiment, stating that he hated Christianity "as Socialists hate soap", an animosity likely stemming from his experiences among the Plymouth Brethren. He was also accused of advocating human sacrifice, largely because of a passage in "Book 4" in which he stated that "A male child of perfect innocence and high intelligence is the most satisfactory victim" and added that he had sacrificed about 150 every year. This was a tongue-in-cheek reference to ejaculation, something not realised by his critics, thus reflecting their own "ignorance and prejudice" toward Crowley.

Crowley considered himself to be one of the outstanding figures of his time. The historian Ronald Hutton stated that in Crowley's youth, he was "a self-indulgent and flamboyant young man" who "set about a deliberate flouting and provocation of social and religious norms", while being shielded from an "outraged public opinion" by his inherited wealth. Hutton also described Crowley as having both an "unappeasable desire" to take control of any organisation that he belonged to, and "a tendency to quarrel savagely" with those who challenged him. Crowley biographer Martin Booth asserted that Crowley was "self-confident, brash, eccentric, egotistic, highly intelligent, arrogant, witty, wealthy, and, when it suited him, cruel". Similarly, Richard Spence noted that Crowley was "capable of immense physical and emotional cruelty". Biographer Lawrence Sutin noted that Crowley exhibited "courage, skill, dauntless energy, and remarkable focus of will" while at the same time showing a "blind arrogance, petty fits of bile, [and] contempt for the abilities of his fellow men". The Thelemite Lon Milo DuQuette noted that Crowley "was by no means perfect" and "often alienated those who loved him dearest."
Crowley enjoyed being outrageous and flouting conventional morality, with John Symonds noting that he "was in revolt against the moral and religious values of his time". Crowley's political thought was studied by academic Marco Pasi, who noted that for Crowley, socio-political concerns were subordinate to metaphysical and spiritual ones. He was neither on the political left nor right but perhaps best categorised as a "conservative revolutionary" despite not being affiliated with the German-based conservative revolutionary movement. Pasi described Crowley's affinity to the extreme ideologies of Nazism and Marxism–Leninism, which aimed to violently overturn society: "What Crowley liked about Nazism and communism, or at least what made him curious about them, was the anti-Christian position and the revolutionary and socially subversive implications of these two movements. In their subversive powers, he saw the possibility of an annihilation of old religious traditions, and the creation of a void that Thelema, subsequently, would be able to fill." Crowley described democracy as an "imbecile and nauseating cult of weakness", and commented that "The Book of the Law" proclaimed that "there is the master and there is the slave; the noble and the serf; the 'lone wolf' and the herd". In this attitude he was influenced by the work of Friedrich Nietzsche and by Social Darwinism. Although he had contempt for most of the British aristocracy, he regarded himself as an aristocrat and styled himself as Laird Boleskine, once describing his ideology as "aristocratic communism".

Crowley was bisexual, and exhibited a sexual preference for women, with his homosexual relationships being fewer and clustered in the early part of his life. In particular he had an attraction toward "exotic women", and claimed to have fallen in love on multiple occasions; Kaczynski stated that "when he loved, he did so with his whole being, but the passion was typically short-lived". Even in later life, Crowley was able to attract young bohemian women to be his lovers, largely due to his charisma. During homosexual anal intercourse, he usually played the passive role, which Booth believed "appealed to his masochistic side". Crowley argued that homosexual and bisexual people should not suppress their sexual orientation, commenting that a person "must not be ashamed or afraid of being homosexual if he happens to be so at heart; he must not attempt to violate his own true nature because of public opinion, or medieval morality, or religious prejudice which would wish he were otherwise." On other issues he adopted a more conservative attitude; he opposed abortion on moral grounds, believing that no woman following her True Will would ever desire one.

Biographer Lawrence Sutin stated that "blatant bigotry is a persistent minor element in Crowley's writings". Sutin thought Crowley "a spoiled scion of a wealthy Victorian family who embodied many of the worst John Bull racial and social prejudices of his upper-class contemporaries", noting that he "embodied the contradiction that writhed within many Western intellectuals of the time: deeply held racist viewpoints courtesy of society, coupled with a fascination with people of colour". Crowley insulted his close Jewish friend Victor Neuburg using anti-Semitic slurs and he had mixed opinions about Jews as a group. Although he praised their "sublime" poetry and stated that they exhibited "imagination, romance, loyalty, probity and humanity", he also thought that centuries of persecution had led some Jews to exhibit "avarice, servility, falseness, cunning and the rest". He was also known to praise various ethnic and cultural groups, for instance he thought that the Chinese people exhibited a "spiritual superiority" to the English, and praised Muslims for exhibiting "manliness, straightforwardness, subtlety, and self-respect".

Crowley also exhibited a "general misogyny" that Booth believed arose from his bad relationship with his mother. Sutin noted that Crowley "largely accepted the notion, implicitly embodied in Victorian sexology, of women as secondary social beings in terms of intellect and sensibility". Crowley described women as "moral inferiors" who had to be treated with "firmness, kindness and justice".

Crowley has remained an influential figure, both amongst occultists and in popular culture, particularly that of Britain, but also of other parts of the world. In 2002, a BBC poll placed Crowley seventy-third in a list of the 100 Greatest Britons. Richard Cavendish has written of him that "In native talent, penetrating intelligence and determination, Aleister Crowley was the best-equipped magician to emerge since the seventeenth century." The scholar of esotericism Egil Asprem described him as "one of the most well-known figures in modern occultism". The scholar of esotericism Wouter Hanegraaff asserted that Crowley was an extreme representation of "the dark side of the occult", adding that he was "the most notorious occultist magician of the twentieth century". The philosopher John Moore opined that Crowley stood out as a "Modern Master" when compared with other prominent occult figures like George Gurdjieff, P. D. Ouspensky, Rudolf Steiner, or Helena Blavatsky, also describing him as a "living embodiment" of Oswald Spengler's "Faustian Man".
Biographer Tobias Churton considered Crowley "a pioneer of consciousness research". Hutton noted that Crowley had "an important place in the history of modern Western responses to Oriental spiritual traditions", while Sutin thought that he had made "distinctly original contributions" to the study of yoga in the West.

Thelema continued to develop and spread following Crowley's death. In 1969, the O.T.O. was reactivated in California under the leadership of Grady Louis McMurtry; in 1985 its right to the title was unsuccessfully challenged in court by a rival group, the Society Ordo Templi Orientis, led by Brazilian Thelemite Marcelo Ramos Motta.
Another American Thelemite is the filmmaker Kenneth Anger, who had been influenced by Crowley's writings from a young age. In the United Kingdom, Kenneth Grant propagated a tradition known as Typhonian Thelema through his organisation, the Typhonian O.T.O., later renamed the Typhonian Order.
Also in Britain, an occultist known as Amado Crowley claimed to be Crowley's son; this has been refuted by academic investigation. Amado argued that Thelema was a false religion created by Crowley to hide his true esoteric teachings, which Amado claimed to be propagating.

Several Western esoteric traditions other than Thelema were also influenced by Crowley, with Djurdjevic observing that "Crowley's influence on twentieth-century and contemporary esotericism has been enormous". Gerald Gardner, founder of Gardnerian Wicca, made use of much of Crowley's published material when composing the Gardnerian ritual liturgy, and the Australian witch Rosaleen Norton was also heavily influenced by Crowley's ideas. More widely, Crowley became "a dominant figure" in the modern Pagan community. L. Ron Hubbard, the American founder of Scientology, was involved in Thelema in the early 1940s (with Jack Parsons), and it has been argued that Crowley's ideas influenced some of Hubbard's work. The scholars of religion Asbjørn Dyrendel, James R. Lewis, and Jesper Petersen noted that despite the fact that Crowley was not a Satanist, he "in many ways embodies the pre-Satanist esoteric discourse on Satan and Satanism through his lifestyle and his philosophy", with his "image and ought" becoming an "important influence" on the later development of religious Satanism. For instance, two prominent figures in religious Satanism, Anton LaVey and Michael Aquino, were influenced by Crowley's work.

Crowley also had a wider influence in British popular culture. After his time in Cefalù which had brought him to public attention in Britain, various "literary Crowleys" appeared; characters in fiction based upon him. One of the earliest was the character of the poet Shelley Arabin in John Buchan's 1926 novel "The Dancing Floor". In his novel "The Devil Rides Out", the writer Dennis Wheatley used Crowley as a partial basis for the character of Damien Morcata, a portly bald defrocked priest who engages in black magic. The occultist Dion Fortune used Crowley as a basis for characters in her books "The Secrets of Doctor Taverner" (1926) and "The Winged Bull" (1935). He was included as one of the figures on the cover art of The Beatles' album "Sgt. Pepper's Lonely Hearts Club Band" (1967), and his motto of "Do What Thou Wilt" was inscribed on the vinyl of Led Zeppelin's album "Led Zeppelin III" (1970). Led Zeppelin co-founder Jimmy Page bought Boleskine in 1971, and part of the band's film "The Song Remains the Same" was filmed in the grounds. He sold it in 1992. David Bowie made reference to Crowley in the lyrics of his song "Quicksand" (1971), while Ozzy Osbourne and his lyricist Bob Daisley wrote a song titled "Mr. Crowley" (1980). Crowley began to receive scholarly attention from academics in the late 1990s.




</doc>
<doc id="1178" url="https://en.wikipedia.org/wiki?curid=1178" title="Afterlife">
Afterlife

The afterlife (also referred to as life after death) is the belief that the essential part of an individual's identity or the stream of consciousness continues after the death of the physical body. According to various ideas about the afterlife, the essential aspect of the individual that lives on after death may be some partial element, or the entire soul or spirit, of an individual, which carries with it and may confer personal identity or, on the contrary, may not, as in Indian nirvana. Belief in an afterlife is in contrast to the belief in oblivion after death.

In some views, this continued existence often takes place in a spiritual realm, and in other popular views, the individual may be reborn into this world and begin the life cycle over again, likely with no memory of what they have done in the past. In this latter view, such rebirths and deaths may take place over and over again continuously until the individual gains entry to a spiritual realm or Otherworld. Major views on the afterlife derive from religion, esotericism and metaphysics.

Some belief systems, such as those in the Abrahamic tradition, hold that the dead go to a specific plane of existence after death, as determined by God, or other divine judgment, based on their actions or beliefs during life. In contrast, in systems of reincarnation, such as those in the Indian religions, the nature of the continued existence is determined directly by the actions of the individual in the ended life, rather than through the decision of a different being.
Theists generally believe some type of afterlife awaits people when they die. Members of some generally non-theistic religions tend to believe in an afterlife, but without reference to a deity. The Sadducees were an ancient Jewish sect that generally believed that there was a God but no afterlife.

Many religions, whether they believe in the soul's existence in another world like Christianity, Islam and many pagan belief systems, or in reincarnation like many forms of Hinduism and Buddhism, believe that one's status in the afterlife is a reward or punishment for their conduct during life.

Reincarnation is the philosophical or religious concept that an aspect of a living being starts a new life in a different physical body or form after each biological death. It is also called rebirth or transmigration, and is a part of the Saṃsāra doctrine of cyclic existence. It is a central tenet of all major Indian religions, namely Buddhism, Hinduism, Jainism, and Sikhism. The idea of reincarnation is found in many ancient cultures, and a belief in rebirth/metempsychosis was held by Greek historic figures, such as Pythagoras, Socrates, and Plato. It is also a common belief of various ancient and modern religions such as Spiritism, Theosophy, and Eckankar and is found as well in many tribal societies around the world, in places such as Australia, East Asia, Siberia, and South America.

Although the majority of denominations within the Abrahamic religions of Judaism, Christianity, and Islam do not believe that individuals reincarnate, particular groups within these religions do refer to reincarnation; these groups include the mainstream historical and contemporary followers of Kabbalah, the Cathars, Alawites, the Druze, and the Rosicrucians. The historical relations between these sects and the beliefs about reincarnation that were characteristic of Neoplatonism, Orphism, Hermeticism, Manicheanism, and Gnosticism of the Roman era as well as the Indian religions have been the subject of recent scholarly research. Unity Church and its founder Charles Fillmore teach reincarnation.

Rosicrucians speak of a life review period occurring immediately after death and before entering the afterlife's planes of existence (before the silver cord is broken), followed by a judgment, more akin to a final review or end report over one's life.

Heaven, the heavens, seven heavens, pure lands, Tian, Jannah, Valhalla, or the Summerland, is a common religious, cosmological, or transcendent place where beings such as gods, angels, jinn, saints, or venerated ancestors are said to originate, be enthroned, or live. According to the beliefs of some religions, heavenly beings can descend to earth or incarnate, and earthly beings can ascend to heaven in the afterlife, or in exceptional cases enter heaven alive.

Heaven is often described as a "higher place", the holiest place, a paradise, in contrast to hell or the underworld or the "low places", and universally or conditionally accessible by earthly beings according to various standards of divinity, goodness, piety, faith or other virtues or right beliefs or simply the will of God. Some believe in the possibility of a heaven on Earth in a world to come.

In Indian religions, heaven is considered as "Svarga loka". There are seven positive regions the soul can go to after death and seven negative regions. After completing its stay in the respective region, the soul is subjected to rebirth in different living forms according to its "karma". This cycle can be broken after a soul achieves "Moksha" or "Nirvana". Any place of existence, either of humans, souls or deities, outside the tangible world (heaven, hell, or other) is referred to as otherworld.

Hell, in many religious and folkloric traditions, is a place of torment and punishment in the afterlife. Religions with a linear divine history often depict hell as an eternal destination, while religions with a cyclic history often depict a hell as an intermediary period between incarnations. Typically, these traditions locate hell in another dimension or under the earth's surface and often include entrances to hell from the land of the living. Other afterlife destinations include purgatory and limbo.

Traditions that do not conceive of the afterlife as a place of punishment or reward merely describe hell as an abode of the dead, the grave, a neutral place (for example, sheol or Hades) located under the surface of earth.

The afterlife played an important role in Ancient Egyptian religion, and its belief system is one of the earliest known in recorded history. When the body died, parts of its soul known as "ka" (body double) and the "ba" (personality) would go to the Kingdom of the Dead. While the soul dwelt in the Fields of Aaru, Osiris demanded work as restitution for the protection he provided. Statues were placed in the tombs to serve as substitutes for the deceased.

Arriving at one's reward in afterlife was a demanding ordeal, requiring a sin-free heart and the ability to recite the spells, passwords and formulae of the Book of the Dead. In the Hall of Two Truths, the deceased's heart was weighed against the "Shu" feather of truth and justice taken from the headdress of the goddess Ma'at. If the heart was lighter than the feather, they could pass on, but if it were heavier they would be devoured by the demon Ammit.

Egyptians also believed that being mummified and put in a sarcophagus (an ancient Egyptian "coffin" carved with complex symbols and designs, as well as pictures and hieroglyphs) was the only way to have an afterlife. Only if the corpse had been properly embalmed and entombed in a mastaba, could the dead live again in the Fields of Yalu and accompany the Sun on its daily ride. Due to the dangers the afterlife posed, the Book of the Dead was placed in the tomb with the body as well as food, jewellery, and 'curses'. They also used the "opening of the mouth".

Ancient Egyptian civilization was based on religion; their belief in the rebirth after death became the driving force behind their funeral practices. Death was simply a temporary interruption, rather than complete cessation, of life, and that eternal life could be ensured by means like piety to the gods, preservation of the physical form through mummification, and the provision of statuary and other funerary equipment. Each human consisted of the physical body, the "ka", the "ba", and the "akh". The Name and Shadow were also living entities. To enjoy the afterlife, all these elements had to be sustained and protected from harm.

On March 30, 2010, a spokesman for the Egyptian Culture Ministry claimed it had unearthed a large red granite door in Luxor with inscriptions by User, a powerful adviser to the 18th dynasty Queen Hatshepsut who ruled between 1479 BC and 1458 BC, the longest of any woman. It believes the false door is a 'door to the Afterlife'. According to the archaeologists, the door was reused in a structure in Roman Egypt.

The Greek god Hades is known in Greek mythology as the king of the underworld, a place where souls live after death. The Greek god Hermes, the messenger of the gods, would take the dead soul of a person to the underworld (sometimes called Hades or the House of Hades). Hermes would leave the soul on the banks of the River Styx, the river between life and death.

Charon, also known as the ferry-man, would take the soul across the river to Hades, if the soul had gold: Upon burial, the family of the dead soul would put coins under the deceased's tongue. Once crossed, the soul would be judged by Aeacus, Rhadamanthus and King Minos. The soul would be sent to Elysium, Tartarus, Asphodel Fields, or the Fields of Punishment. The Elysian Fields were for the ones that lived pure lives. It consisted of green fields, valleys and mountains, everyone there was peaceful and contented, and the Sun always shone there. Tartarus was for the people that blasphemed against the gods, or were simply rebellious and consciously evil.

The Asphodel Fields were for a varied selection of human souls: Those whose sins equalled their goodness, were indecisive in their lives, or were not judged. The Fields of Punishment were for people that had sinned often, but not so much as to be deserving of Tartarus. In Tartarus, the soul would be punished by being burned in lava, or stretched on racks. Some heroes of Greek legend are allowed to visit the underworld. The Romans had a similar belief system about the afterlife, with Hades becoming known as Pluto. In the ancient Greek myth about the Labours of Heracles, the hero Heracles had to travel to the underworld to capture Cerberus, the three-headed guard dog, as one of his tasks.

In "Dream of Scipio", Cicero describes what seems to be an out of body experience, of the soul traveling high above the Earth, looking down at the small planet, from far away.

In Book VI of Virgil's "Aeneid", the hero, Aeneas, travels to the underworld to see his father. By the River Styx, he sees the souls of those not given a proper burial, forced to wait by the river until someone buries them. While down there, along with the dead, he is shown the place where the wrongly convicted reside, the fields of sorrow where those who committed suicide and now regret it reside, including Aeneas' former lover, the warriors and shades, Tartarus (where the titans and powerful non-mortal enemies of the Olympians reside) where he can hear the groans of the imprisoned, the palace of Pluto, and the fields of Elysium where the descendants of the divine and bravest heroes reside. He sees the river of forgetfulness, Lethe, which the dead must drink to forget their life and begin anew. Lastly, his father shows him all of the future heroes of Rome who will live if Aeneas fulfills his destiny in founding the city.

The Poetic and Prose Eddas, the oldest sources for information on the Norse concept of the afterlife, vary in their description of the several realms that are described as falling under this topic. The most well-known are:

The teachings of the Bahá'í Faith state that the nature of the afterlife is beyond the understanding of those living, just as an unborn fetus cannot understand the nature of the world outside of the womb. The Bahá'í writings state that the soul is immortal and after death it will continue to progress until it attains God's presence. In Bahá'í belief, souls in the afterlife will continue to retain their individuality and consciousness and will be able to recognize and communicate spiritually with other souls whom they have made deep profound friendships with, such as their spouses.

The Bahá'í scriptures also state there are distinctions between souls in the afterlife, and that souls will recognize the worth of their own deeds and understand the consequences of their actions. It is explained that those souls that have turned toward God will experience gladness, while those who have lived in error will become aware of the opportunities they have lost. Also, in the Baha'i view, souls will be able to recognize the accomplishments of the souls that have reached the same level as themselves, but not those that have achieved a rank higher than them.

Mainstream Christianity professes belief in the Nicene Creed, and English versions of the Nicene Creed in current use include the phrase: "We look for the resurrection of the dead, and the life of the world to come." Although punishments are made part of certain Christian conceptions of the afterlife, the prevalent concept of "eternal damnation" is a tenet of the Christian afterlife.

When questioned by the Sadducees about the resurrection of the dead (in a context relating to who one's spouse would be if one had been married several times in life), Jesus said that marriage will be irrelevant after the resurrection as the resurrected will be like the angels in heaven.

Jesus also maintained that the time would come when the dead would hear the voice of the Son of God, and all who were in the tombs would come out, who have done good deeds to the resurrection of life, but those who have done wicked deeds to the resurrection of condemnation.

The Book of Enoch describes Sheol as divided into four compartments for four types of the dead: the faithful saints who await resurrection in Paradise, the merely virtuous who await their reward, the wicked who await punishment, and the wicked who have already been punished and will not be resurrected on Judgment Day. The Book of Enoch is considered apocryphal by most denominations of Christianity and all denominations of Judaism.

The book of 2 Maccabees gives a clear account of the dead awaiting a future resurrection and judgment, plus prayers and offerings for the dead to remove the burden of sin.
The author of Luke recounts the story of Lazarus and the rich man, which shows people in Hades awaiting the resurrection either in comfort or torment. The author of the Book of Revelation writes about God and the angels versus Satan and demons in an epic battle at the end of times when all souls are judged. There is mention of ghostly bodies of past prophets, and the transfiguration.

The non-canonical Acts of Paul and Thecla speak of the efficacy of prayer for the dead, so that they might be "translated to a state of happiness".

Hippolytus of Rome pictures the underworld (Hades) as a place where the righteous dead, awaiting in the bosom of Abraham their resurrection, rejoice at their future prospect, while the unrighteous are tormented at the sight of the "lake of unquenchable fire" into which they are destined to be cast.

Gregory of Nyssa discusses the long-before believed possibility of purification of souls after death.

Pope Gregory I repeats the concept, articulated over a century earlier by Gregory of Nyssa that the saved suffer purification after death, in connection with which he wrote of "purgatorial flames".

The noun "purgatorium" (Latin: place of cleansing) is used for the first time to describe a state of painful purification of the saved after life. The same word in adjectival form ("purgatorius -a -um", cleansing), which appears also in non-religious writing, was already used by Christians such as Augustine of Hippo and Pope Gregory I to refer to an after-death cleansing.

During the Age of Enlightenment, theologians and philosophers presented various philosophies and beliefs. A notable example is Emanuel Swedenborg who wrote some 18 theological works which describe in detail the nature of the afterlife according to his claimed spiritual experiences, the most famous of which is "Heaven and Hell". His report of life there covers a wide range of topics, such as marriage in heaven (where all angels are married), children in heaven (where they are raised by angel parents), time and space in heaven (there are none), the after-death awakening process in the World of Spirits (a place halfway between Heaven and Hell and where people first wake up after death), the allowance of a free will choice between Heaven or Hell (as opposed to being sent to either one by God), the eternity of Hell (one could leave but would never want to), and that all angels or devils were once people on earth.

The "Spiritual Combat", a written work by Lorenzo Scupoli, states that four assaults are attempted by the "evil one" at the hour of death. The Catholic conception of the afterlife teaches that after the body dies, the soul is judged, the righteous and free of sin enter Heaven. However, those who die in unrepented mortal sin go to hell. In the 1990s, the Catechism of the Catholic Church defined hell not as punishment imposed on the sinner but rather as the sinner's self-exclusion from God. Unlike other Christian groups, the Catholic Church teaches that those who die in a state of grace, but still carry venial sin go to a place called Purgatory where they undergo purification to enter Heaven.

Despite popular opinion, Limbo, which was elaborated upon by theologians beginning in the Middle Ages, was never recognized as a dogma of the Catholic Church, yet, at times, it has been a very popular theological theory within the Church. Limbo is a theory that unbaptized but innocent souls, such as those of infants, virtuous individuals who lived before Jesus Christ was born on earth, or those that die before baptism exist in neither Heaven or Hell proper. Therefore, these souls neither merit the beatific vision, nor are subjected to any punishment, because they are not guilty of any personal sin although they have not received baptism, so still bear original sin. So they are generally seen as existing in a state of natural, but not supernatural, happiness, until the end of time.

In other Christian denominations it has been described as an intermediate place or state of confinement in oblivion and neglect.

The notion of purgatory is associated particularly with the Catholic Church. In the Catholic Church, all those who die in God's grace and friendship, but still imperfectly purified, are indeed assured of their eternal salvation; but after death they undergo purification, so as to achieve the holiness necessary to enter the joy of heaven or the final purification of the elect, which is entirely different from the punishment of the damned. The tradition of the church, by reference to certain texts of scripture, speaks of a "cleansing fire" although it is not always called purgatory.

Anglicans of the Anglo-Catholic tradition generally also hold to the belief. John Wesley, the founder of Methodism, believed in an intermediate state between death and the resurrection of the dead and in the possibility of "continuing to grow in holiness there", but Methodism does not officially affirm this belief and denies the possibility of helping by prayer any who may be in that state.

The Orthodox Church is intentionally reticent on the afterlife, as it acknowledges the mystery especially of things that have not yet occurred. Beyond the second coming of Jesus, bodily resurrection, and final judgment, all of which is affirmed in the Nicene Creed (325 CE), Orthodoxy does not teach much else in any definitive manner. Unlike Western forms of Christianity, however, Orthodoxy is traditionally non-dualist and does not teach that there are two separate literal locations of heaven and hell, but instead acknowledges that "the 'location' of one's final destiny—heaven or hell—as being figurative." Instead, Orthodoxy teaches that the final judgment is simply one's uniform encounter with divine love and mercy, but this encounter is experienced multifariously depending on the extent to which one has been transformed, partaken of divinity, and is therefore compatible or incompatible with God. "The monadic, immutable, and ceaseless object of eschatological encounter is therefore the love and mercy of God, his glory which infuses the heavenly temple, and it is the subjective human reaction which engenders multiplicity or any division of experience." For instance, St. Isaac the Syrian observes that "those who are punished in Gehenna, are scourged by the scourge of love. ... The power of love works in two ways: it torments sinners ... [as] bitter regret. But love inebriates the souls of the sons of Heaven by its delectability." In this sense, the divine action is always, immutably, and uniformly love and if one experiences this love negatively, the experience is then one of self-condemnation because of free will rather than condemnation by God. Orthodoxy therefore uses the description of Jesus' judgment in John 3:19–21 as their model: "19 And this is the judgment: the light has come into the world, and people loved the darkness rather than the light because their works were evil. 20 For everyone who does wicked things hates the light and does not come to the light, lest his works should be exposed. 21 But whoever does what is true comes to the light, so that it may be clearly seen that his works have been carried out in God." As a characteristically Orthodox understanding, then, Fr. Thomas Hopko writes, "[I]t is precisely the presence of God's mercy and love which cause the torment of the wicked. God does not punish; he forgives... . In a word, God has mercy on all, whether all like it or not. If we like it, it is paradise; if we do not, it is hell. Every knee will bend before the Lord. Everything will be subject to Him. God in Christ will indeed be "all and in all," with boundless mercy and unconditional pardon. But not all will rejoice in God's gift of forgiveness, and that choice will be judgment, the self-inflicted source of their sorrow and pain."

Moreover, Orthodoxy includes a prevalent tradition of "apokatastasis", or the restoration of all things in the end. This has been taught most notably by Origen, but also many other Church fathers and Saints, including Gregory of Nyssa. The Second Council of Constantinople (553 CE) affirmed the orthodoxy of Gregory of Nyssa while simultaneously condemning Origen's brand of universalism because it taught the restoration back to our pre-existent state, which Orthodoxy doesn't teach. It is also a teaching of such eminent Orthodox theologians as Olivier Clément, Metropolitan Kallistos Ware, and Bishop Hilarion Alfeyev. Although apokatastasis is not a dogma of the church but instead a theologoumena, it is no less a teaching of the Orthodox Church than its rejection. As Met. Kallistos Ware explains, "It is heretical to say that all must be saved, for this is to deny free will; but, it is legitimate to hope that all may be saved," as insisting on torment without end also denies free will.

Joseph F. Smith of The Church of Jesus Christ of Latter-day Saints presents an elaborate vision of the afterlife. It is revealed as the scene of an extensive missionary effort by righteous spirits in paradise to redeem those still in darkness—a spirit prison or "hell" where the spirits of the dead remain until judgment. It is divided into two parts: Spirit Prison and Paradise. Together these are also known as the Spirit World (also Abraham's Bosom; see Luke 16:19–25). They believe that Christ visited spirit prison (1 Peter 3:18–20) and opened the gate for those who repent to cross over to Paradise. This is similar to the Harrowing of Hell doctrine of some mainstream Christian faiths. Both Spirit Prison and Paradise are temporary according to Latter-day Saint beliefs. After the resurrection, spirits are assigned "permanently" to three degrees of heavenly glory, determined by how they lived – Celestial, Terrestrial, and Telestial. (1 Cor 15:44–42; Doctrine and Covenants, Section 76) Sons of Perdition, or those who have known and seen God and deny it, will be sent to the realm of Satan, which is called Outer Darkness, where they shall live in misery and agony forever.

The Celestial Kingdom is believed to be a place where the righteous can live eternally with their families. Progression does not end once one has entered the Celestial Kingdom, but it extends eternally. According to "True to the Faith" (a handbook on doctrines in the LDS faith), "The celestial kingdom is the place prepared for those who have "received the testimony of Jesus" and been "made perfect through Jesus the mediator of the new covenant, who wrought out this perfect atonement through the shedding of his own blood" (D&C 76:51, 69). To inherit this gift, we must receive the ordinances of salvation, keep the commandments, and repent of our sins."

Jehovah's Witnesses occasionally use terms such as "afterlife" to refer to any hope for the dead, but they understand Ecclesiastes 9:5 to preclude belief in an immortal soul. Individuals judged by God to be wicked, such as in the Great Flood or at Armageddon, are given no hope of an afterlife. However, they believe that after Armageddon there will be a bodily resurrection of "both righteous and unrighteous" dead (but not the "wicked"). Survivors of Armageddon and those who are resurrected are then to gradually restore earth to a paradise. After Armageddon, unrepentant sinners are punished with eternal death (non-existence).

The Seventh-day Adventist Church, teaches that the first death, or death brought about by living on a planet with sinful conditions (sickness, old age, accident, etc.) is a sleep of the soul. Adventists believe that the body + the breath of God = a living soul. Like Jehovah's Witnesses, Adventists use key phrases from the Bible, such as "For the living know that they shall die: but the dead know not any thing, neither have they any more a reward; for the memory of them is forgotten." (Eccl. 9:5 KJV). Adventists also point to the fact that the wage of sin is death and God alone is immortal. Adventists believe God will grant eternal life to the redeemed who are resurrected at Jesus' second coming. Until then, all those who have died are "asleep". When Jesus the Christ, who is the Word and the Bread of Life, comes a second time, the righteous will be raised incorruptible and will be taken in the clouds to meet their Lord. The righteous will live in heaven for a thousand years (the millennium) where they will sit with God in judgment over the unredeemed and the fallen angels. During the time the redeemed are in heaven, the Earth will be devoid of human and animal inhabitation. Only the fallen angels will be left alive. The second resurrection is of the unrighteous, when Jesus brings the New Jerusalem down from heaven to relocate to Earth. Jesus will call to life all those who are unrighteous. Satan and his angels will convince the unrighteous to surround the city, but hell fire and brimstone will fall from heaven and consume them, thus cleansing Earth of all sin. The universe will be then free from sin forever. This is called the second death. On the new earth God will provide an eternal home for all the redeemed and a perfect environment for everlasting life, where Eden will be restored. The great controversy will be ended and sin will be no more. God will reign in perfect harmony forever. (Rom. 6:23; 1 Tim. 6:15, 16; Eccl. 9:5, 6; Ps. 146:3, 4; John 11:11–14; Col. 3:4; 1 Cor. 15:51–54; 1 Thess. 4:13–17; John 5:28, 29; Rev. 20:1–10; Rev. 20; 1 Cor. 6:2, 3; Jer. 4:23–26; Rev. 21:1–5; Mal. 4:1; Eze. 28:18, 19; 2 Peter 3:13; Isa. 35; 65:17–25; Matt. 5:5; Rev. 21:1–7; 22:1–5; 11:15.)

The Islamic belief in the afterlife as stated in the Quran is descriptive. The Arabic word for Paradise is "Jannah" and Hell is "Jahannam". Their level of comfort while in the grave (according to some commentators) depends wholly on their level of "iman" or faith in the one almighty creator or supreme being (God or Allah). In order for one to achieve proper, firm and healthy "iman" one must practice righteous deeds or else his level of "iman" chokes and shrinks and eventually can wither away if one does not practice Islam long enough, hence the depth of practicing Islam is good deeds. One may also acquire "tasbih" and recite the names of Allah in such manner as "Subahann Allah" or "Glory be to Allah" over and over again to acquire good deeds, all for the cause to reach absolute beliefe to elevate the spiritual entity that will find its creator (source). This ultimate goal is recited in one of the most prominent verses in Quraan, the first Sura in the Quraan, named Alfateha in the 5th verse "Ehdina al serata al mostaqeem" meaning "guide us to the straight path", and the following verses follows describing this path as "The way of those on whom you have bestowed your grace, not the way of those who earned your anger, nor of those who went astray".

In the Quran, God gives warning about grievous punishment to those who do not believe in the afterlife ("Akhirah"), and admonishes mankind that Hell is prepared for those who deny the meeting with Him.

Islam teaches that the purpose of Man's entire creation is to worship God alone, which includes being kind to other human beings and life, including animals, and to trees, by not oppressing them. Islam teaches that the life we live on Earth is nothing but a test for us and to determine each individual's ultimate abode, be it Hell or Paradise in the afterlife, which is eternal and everlasting.

"Jannah" and "Jahannam" both have different levels. "Jannah" has eight gates and seven levels. The higher the level the better it is and the happier you are. "Jahannam" possess 7 deep terrible layers. The lower the layer the worse it is. Individuals will arrive at both everlasting places during Judgment Day, which commences after the Angel Israfil blows the trumpet the second time. Islam teaches the continued existence of the soul and a transformed physical existence after death. Muslims believe there will be a day of judgment when all humans will be judged by God and assigned between the eternal destinations of Paradise and Hell.

In the 20th century, discussions about the afterlife address the interconnection between human action and divine judgment, the need for moral rectitude, and the eternal consequences of human action in this life and world.

A central doctrine of the Quran is the Last Day, on which the world will come to an end and God will raise all people and jinn from the dead to be judged. The Last Day is also called the Day of Standing Up, Day of Separation, Day of Reckoning, Day of Awakening, Day of Judgment, The Encompassing Day or The Hour.

Until the Day of Judgment, deceased souls remain in their graves awaiting the resurrection. However, they begin to feel immediately a taste of their destiny to come. Those bound for hell will suffer in their graves, while those bound for heaven will be in peace until that time.

The resurrection that will take place on the Last Day is physical, and is explained by suggesting that God will re-create the decayed body (17:100: "Could they not see that God who created the heavens and the earth is able to create the like of them?").

On the Last Day, resurrected humans and jinn will be judged by God according to their deeds. One's eternal destination depends on balance of good to bad deeds in life. They are either granted admission to Paradise, where they will enjoy spiritual and physical pleasures forever, or condemned to Hell to suffer spiritual and physical torment for eternity. The day of judgment is described as passing over Hell on a narrow bridge (as thin as human hair and sharper than a razor) in order to enter Paradise. Those who fall, weighted by their bad deeds, will remain in Hell forever.

Ahmadi believe that the afterlife is not material but of a spiritual nature. According to Mirza Ghulam Ahmad, the founder of Ahmadiyya religion, the soul will give birth to another rarer entity and will resemble the life on this earth in the sense that this entity will bear a similar relationship to the soul as the soul bears relationship with the human existence on earth. On earth, if a person leads a righteous life and submits to the will of God, his or her tastes become attuned to enjoying spiritual pleasures as opposed to carnal desires. With this, an "embryonic soul" begins to take shape. Different tastes are said to be born which a person given to carnal passions finds no enjoyment. For example, sacrifice of one's own rights over that of others becomes enjoyable, or that forgiveness becomes second nature. In such a state a person finds contentment and peace at heart and at this stage, according to Ahmadiyya beliefs, it can be said that a soul within the soul has begun to take shape.

The Sufi scholar Ibn 'Arabi defined Barzakh as the intermediate realm or "isthmus." It is between the world of corporeal bodies and the world of spirits, and is a means of contact between the two worlds. Without it, there would be no contact between the two and both would cease to exist. He described it as simple and luminous, like the world of spirits, but also able to take on many different forms just like the world of corporeal bodies can. In broader terms Barzakh, "is anything that separates two things". It has been called the dream world in which the dreamer is in both life and death.

She'ol, in the Hebrew Bible, is a place of darkness to which all the dead go, both the righteous and the unrighteous, regardless of the moral choices made in life, a place of stillness and darkness cut off from life and from God.

The inhabitants of Sheol are the "shades" ("rephaim"), entities without personality or strength. Under some circumstances they are thought to be able to be contacted by the living, as the Witch of Endor contacts the shade of Samuel for Saul, but such practices are forbidden (Deuteronomy 18:10).

While the Hebrew Bible appears to describe Sheol as the permanent place of the dead, in the Second Temple period (roughly 500 BC – 70 AD) a more diverse set of ideas developed. In some texts, Sheol is considered to be the home of both the righteous and the wicked, separated into respective compartments; in others, it was considered a place of punishment, meant for the wicked dead alone. When the Hebrew scriptures were translated into Greek in ancient Alexandria around 200 BC, the word "Hades" (the Greek underworld) was substituted for Sheol. This is reflected in the New Testament where Hades is both the underworld of the dead and the personification of the evil it represents.

The Talmud offers a number of thoughts relating to the afterlife. After death, the soul is brought for judgment. Those who have led pristine lives enter immediately into the "Olam Haba" or world to come. Most do not enter the world to come immediately, but now experience a period of review of their earthly actions and they are made aware of what they have done wrong. Some view this period as being a "re-schooling", with the soul gaining wisdom as one's errors are reviewed. Others view this period to include spiritual discomfort for past wrongs. At the end of this period, not longer than one year, the soul then takes its place in the world to come. Although discomforts are made part of certain Jewish conceptions of the afterlife, the concept of "eternal damnation", so prevalent in other religions, is not a tenet of the Jewish afterlife. According to the Talmud, extinction of the soul is reserved for a far smaller group of malicious and evil leaders, either whose very evil deeds go way beyond norms, or who lead large groups of people to utmost evil.

Maimonides describes the "Olam Haba" in spiritual terms, relegating the prophesied physical resurrection to the status of a future miracle, unrelated to the afterlife or the Messianic era. According to Maimonides, an afterlife continues for the soul of every human being, a soul now separated from the body in which it was "housed" during its earthly existence.

The Zohar describes Gehenna not as a place of punishment for the wicked but as a place of spiritual purification for souls.

Although there is no reference to reincarnation in the Talmud or any prior writings, according to rabbis such as Avraham Arieh Trugman, reincarnation is recognized as being part and parcel of Jewish tradition. Trugman explains that it is through oral tradition that the meanings of the Torah, its commandments and stories, are known and understood. The classic work of Jewish mysticism, the Zohar, is quoted liberally in all Jewish learning; in the Zohar the idea of reincarnation is mentioned repeatedly. Trugman states that in the last five centuries the concept of reincarnation, which until then had been a much hidden tradition within Judaism, was given open exposure.

Shraga Simmons commented that within the Bible itself, the idea [of reincarnation] is intimated in Deut. 25:5–10, Deut. 33:6 and Isaiah 22:14, 65:6.

Yirmiyahu Ullman wrote that reincarnation is an "ancient, mainstream belief in Judaism". The Zohar makes frequent and lengthy references to reincarnation. Onkelos, a righteous convert and authoritative commentator of the same period, explained the verse, "Let Reuben live and not die ..." (Deuteronomy 33:6) to mean that Reuben should merit the World to Come directly, and not have to die again as a result of being reincarnated. Torah scholar, commentator and kabbalist, Nachmanides (Ramban 1195–1270), attributed Job's suffering to reincarnation, as hinted in Job's saying "God does all these things twice or three times with a man, to bring back his soul from the pit to ... the light of the living' (Job 33:29, 30)."

Reincarnation, called "gilgul", became popular in folk belief, and is found in much Yiddish literature among Ashkenazi Jews. Among a few kabbalists, it was posited that some human souls could end up being reincarnated into non-human bodies. These ideas were found in a number of Kabbalistic works from the 13th century, and also among many mystics in the late 16th century. Martin Buber's early collection of stories of the Baal Shem Tov's life includes several that refer to people reincarnating in successive lives.

Among well known (generally non-kabbalist or anti-kabbalist) rabbis who rejected the idea of reincarnation are Saadia Gaon, David Kimhi, Hasdai Crescas, Yedayah Bedershi (early 14th century), Joseph Albo, Abraham ibn Daud, the Rosh and Leon de Modena. Saadia Gaon, in Emunoth ve-Deoth (Hebrew: "beliefs and opinions") concludes Section VI with a refutation of the doctrine of metempsychosis (reincarnation). While rebutting reincarnation, Saadia Gaon further states that Jews who hold to reincarnation have adopted non-Jewish beliefs. By no means do all Jews today believe in reincarnation, but belief in reincarnation is not uncommon among many Jews, including Orthodox.

Other well-known rabbis who are reincarnationists include Yonassan Gershom, Abraham Isaac Kook, Talmud scholar Adin Steinsaltz, DovBer Pinson, David M. Wexelman, Zalman Schachter, and many others. Reincarnation is cited by authoritative biblical commentators, including Ramban (Nachmanides), Menachem Recanti and Rabbenu Bachya.

Among the many volumes of Yitzchak Luria, most of which come down from the pen of his primary disciple, Chaim Vital, are insights explaining issues related to reincarnation. His "Shaar HaGilgulim", "The Gates of Reincarnation", is a book devoted exclusively to the subject of reincarnation in Judaism.

Rabbi Naftali Silberberg of The Rohr Jewish Learning Institute notes that "Many ideas that originate in other religions and belief systems have been popularized in the media and are taken for granted by unassuming Jews."

Buddhists maintain that rebirth takes place without an unchanging self or soul passing from one form to another. The type of rebirth will be conditioned by the moral tone of the person's actions (kamma or karma). For example, if a person has committed harmful actions of body, speech and mind based on greed, hatred and delusion, rebirth in a lower realm, i.e. an animal, a hungry ghost or a hell realm, is to be expected. On the other hand, where a person has performed skillful actions based on generosity, loving-kindness (metta), compassion and wisdom, rebirth in a happy realm, i.e. human or one of the many heavenly realms, can be expected.

Yet the mechanism of rebirth with kamma is not deterministic. It depends on various levels of kamma. The most important moment that determines where a person is reborn into is the last thought moment. At that moment, heavy kamma would ripen if there were performed, if not then near death kamma, if not then habitual kamma, finally if none of the above happened, then residual kamma from previous actions can ripen. According to Theravada Buddhism, there are 31 realms of existence that one can be reborn into.

Pure Land Buddhism of Mahayana believes in a special place apart from the 31 planes of existence called Pure Land. It is believed that each Buddha has their own pure land, created out of their merits for the sake of sentient beings who recall them mindfully to be able to be reborn in their pure land and train to become a Buddha there. Thus the main practice of pure land Buddhism is to chant a Buddha's name.

In Tibetan Buddhism the Tibetan Book of the Dead explains the intermediate state of humans between death and reincarnation. The deceased will find the bright light of wisdom, which shows a straightforward path to move upward and leave the cycle of reincarnation. There are various reasons why the deceased do not follow that light. Some had no briefing about the intermediate state in the former life. Others only used to follow their basic instincts like animals. And some have fear, which results from foul deeds in the former life or from insistent haughtiness. In the intermediate state the awareness is very flexible, so it is important to be virtuous, adopt a positive attitude, and avoid negative ideas. Ideas which are rising from subconsciousness can cause extreme tempers and cowing visions. In this situation they have to understand, that these manifestations are just reflections of the inner thoughts. No one can really hurt them, because they have no more material body. The deceased get help from different Buddhas who show them the path to the bright light. The ones who do not follow the path after all will get hints for a better reincarnation. They have to release the things and beings on which or whom they still hang from the life before. It is recommended to choose a family where the parents trust in the Dharma and to reincarnate with the will to care for the welfare of all beings.

"Life is cosmic energy of the universe and after death it merges in universe again and as the time comes to find the suitable place for the entity died in the life condition it gets born. There are 10 life states of any life: Hell, hunger, anger, animality, rapture, humanity, learning, realization, bodhisatva and buddhahood. The life dies in which life condition it reborn in the same life condition."

The Upanishads describe reincarnation ("punarjanma") (see also: samsara). The Bhagavad Gita, an important Hindu script, talks extensively about the afterlife. Here, Krishna says that just as a man discards his old clothes and wears new ones; similarly the soul discards the old body and takes on a new one. In Hinduism, the belief is that the body is nothing but a shell, the soul inside is immutable and indestructible and takes on different lives in a cycle of birth and death. The end of this cycle is called "mukti" (Sanskrit: मुक्ति) and staying finally with supreme God forever; is "moksha" (Sanskrit: मोक्ष) or salvation.

The Garuda Purana deals solely with what happens to a person after death. The God of Death Yama sends his representatives to collect the soul from a person's body whenever he is due for death and they take the soul to Yama. A record of each person's timings & deeds performed by him is kept in a ledger by Yama's assistant, Chitragupta.

According to the Garuda Purana, a soul after leaving the body travels through a very long and dark tunnel towards the South. This is why an oil lamp is lit and kept beside the head of the corpse, to light the dark tunnel and allow the soul to travel comfortably.

The soul, called "atman" leaves the body and reincarnates itself according to the deeds or "karma" performed by one in last birth. Rebirth would be in form of animals or other lower creatures if one performed bad karmas and in human form in a good family with joyous lifetime if the person was good in last birth. In between the two births a human is also required to either face punishments for bad karmas in "naraka" or hell or enjoy for the good karmas in "swarga" or heaven for good deeds. Whenever his or her punishments or rewards are over he or she is sent back to earth, also known as "Mrutyulok" or human world. A person stays with the God or ultimate power when he discharges only & only "yajna karma" (means work done for satisfaction of supreme lord only) in last birth and the same is called as "moksha" or "nirvana", which is the ultimate goal of a self realised soul. "Atma" moves with "Parmatma" or the greatest soul. According to Bhagavad Gita an "Atma" or soul never dies, what dies is the body only made of five elements—Earth, Water, Fire, Air, and Sky. Soul is believed to be indestructible. None of the five elements can harm or influence it. Hinduism through Garuda Purana also describes in detail various types of "narkas" or Hells where a person after death is punished for his bad "karmas" and dealt with accordingly.

Hindus also believe in "karma". "Karma" is the accumulated sums of one's good or bad deeds. "Satkarma" means good deeds, "vikarma" means bad deeds. According to Hinduism the basic concept of karma is 'As you sow, you shall reap'. So, if a person has lived a good life, they will be rewarded in the afterlife. Similarly their sum of bad deeds will be mirrored in their next life. Good karma brings good rewards and bad karmas lead to bad results. There is no judgment here. People accumulate karma through their actions and even thoughts. In Bhagavad Gita when Arjuna hesitates to kill his kith and kin the lord reprimands him saying thus "Do you believe that you are the doer of the action. No. You are merely an instrument in MY hands. Do you believe that the people in front of you are living? Dear Arjuna, they are already dead. As a "kshatriya" (warrior) it is your duty to protect your people and land. If you fail to do your duty, then you are not adhering to dharmic principles."

Jainism also believes in the afterlife. They believe that the soul takes on a body form based on previous karmas or actions performed by that soul through eternity. Jains believe the soul is eternal and that the freedom from the cycle of reincarnation is the means to attain eternal bliss.

Sikhism may have a belief in the afterlife. They believe that the soul belongs to the spiritual universe which has its origins in God. However it's been a matter of great debate amongst the Sikhs about Sikhism's belief in afterlife. Many believe that Sikhism endorses the afterlife and the concept of reward and punishment as there are verses given in "Guru Granth Sahib", but a large number of Sikhs believe otherwise and treat those verses as metaphorical or poetic.

Also it has been noted by many scholars that the Guru Granth Sahib includes poetic renditions from multiple saints and religious traditions like that of Kabir, Farid and Ramananda. The essential doctrine is to experience the divine through simple living, meditation and contemplation while being alive. Sikhism also has the belief of being in union with God while living. Accounts of afterlife are considered to be aimed at the popular prevailing views of the time so as to provide a referential framework without necessarily establishing a belief in the afterlife. Thus while it is also acknowledged that living the life of a householder is above the metaphysical truth, Sikhism can be considered agnostic to the question of an afterlife. Some scholars also interpret the mention of reincarnation to be naturalistic akin to the biogeochemical cycles.

But if one analyses the Sikh Scriptures carefully, one may find that on many occasions the afterlife and the existence of heaven and hell are mentioned in "Guru Granth Sahib" and in "Dasam granth", so from that it can be concluded that Sikhism does believe in the existence of heaven and hell; however, heaven and hell are created to temporarily reward and punish, and one will then take birth again until one merges in God. According to the Sikh scriptures, the human form is the closet form to God and the best opportunity for a human being to attain salvation and merge back with God. Sikh Gurus said that nothing dies, nothing is born, everything is ever present, and it just changes forms. Like standing in front of a wardrobe, you pick up a dress and wear it and then you discard it. You wear another one. Thus, in the view of Sikhism, your soul is never born and never dies. Your soul is a part of God and hence lives forever.

Traditional African religions are diverse in their beliefs in an afterlife. Hunter-gatherer societies such as the Hadza have no particular belief in an afterlife, and the death of an individual is a straightforward end to their existence. Ancestor cults are found throughout Sub-Saharan Africa, including cultures like the Yombe, Beng, Yoruba and Ewe, "[T]he belief that the dead come back into life and are reborn into their families is given concrete expression in the personal names that are given to children...What is reincarnated are some of the dominant characteristics of the ancestor and not his soul. For each soul remains distinct and each birth represents a new soul." The Yoruba, Dogon and LoDagoa have eschatological ideas similar to Abrahamic religions, "but in most African societies, there is a marked absence of such clear-cut notions of heaven and hell, although there are notions of God judging the soul after death." In some societies like the Mende, multiple beliefs coexist. The Mende believe that people die twice: once during the process of joining the secret society, and again during biological death after which they become ancestors. However, some Mende also believe that after people are created by God they live ten consecutive lives, each in progressively descending worlds. One cross-cultural theme is that the ancestors are part of the world of the living, interacting with it regularly.

It is common for families to participate in ceremonies for children at a shrine, yet have a Buddhist funeral at the time of death. In old Japanese legends, it is often claimed that the dead go to a place called "yomi" (黄泉), a gloomy underground realm with a river separating the living from the dead mentioned in the legend of Izanami and Izanagi. This "yomi" very closely resembles the Greek Hades; however, later myths include notions of resurrection and even Elysium-like descriptions such as in the legend of Okuninushi and Susanoo. Shinto tends to hold negative views on death and corpses as a source of pollution called "kegare". However, death is also viewed as a path towards apotheosis in Shintoism as can be evidenced by how legendary individuals become enshrined after death. Perhaps the most famous would be Emperor Ojin who was enshrined as Hachiman the God of War after his death.

Some Unitarian Universalists believe in universalism: that all souls will ultimately be saved and that there are no torments of hell. Unitarian Universalists differ widely in their theology hence there is no exact same stance on the issue. Although Unitarians historically believed in a literal hell, and Universalists historically believed that everyone goes to heaven, modern Unitarian Universalists can be categorized into those believing in a heaven, reincarnation and oblivion. Most Unitarian Universalists believe that heaven and hell are symbolic places of consciousness and the faith is largely focused on the worldly life rather than any possible afterlife.

According to Edgar Cayce, the afterlife consisted of nine realms equated with the nine planets of astrology. The first, symbolized by Saturn, was a level for the purification of the souls. The second, Mercury's realm, gives us the ability to consider problems as a whole. The third of the nine soul realms is ruled by Earth and is associated with the Earthly pleasures. The fourth realm is where we find out about love and is ruled by Venus. The fifth realm is where we meet our limitations and is ruled by Mars. The sixth realm is ruled by Neptune, and is where we begin to use our creative powers and free ourselves from the material world. The seventh realm is symbolized by Jupiter, which strengthens the soul's ability to depict situations, to analyze people and places, things, and conditions. The eighth afterlife realm is ruled by Uranus and develops psychic ability. The ninth afterlife realm is symbolized by Pluto, the astrological realm of the unconscious. This afterlife realm is a transient place where souls can choose to travel to other realms or other solar systems, it is the souls liberation into eternity, and is the realm that opens the doorway from our solar system into the cosmos.

Mainstream Spiritualists postulate a series of seven realms that are not unlike Edgar Cayce's nine realms ruled by the planets. As it evolves, the soul moves higher and higher until it reaches the ultimate realm of spiritual oneness. The first realm, equated with hell, is the place where troubled souls spend a long time before they are compelled to move up to the next level. The second realm, where most souls move directly, is thought of as an intermediate transition between the lower planes of life and hell and the higher perfect realms of the universe. The third level is for those who have worked with their karmic inheritance. The fourth level is that from which evolved souls teach and direct those on Earth. The fifth level is where the soul leaves human consciousness behind. At the sixth plane, the soul is finally aligned with the cosmic consciousness and has no sense of separateness or individuality. Finally, the seventh level, the goal of each soul, is where the soul transcends its own sense of "soulfulness" and reunites with the World Soul and the universe.

The Wiccan afterlife is most commonly described as The Summerland. Here, souls rest, recuperate from life, and reflect on the experiences they had during their lives. After a period of rest, the souls are reincarnated, and the memory of their previous lives is erased. Many Wiccans see The Summerland as a place to reflect on their life actions. It is not a place of reward, but rather the end of a life journey at an end point of incarnations.

Zoroastrianism states that the "urvan", the disembodied spirit, lingers on earth for three days before departing downward to the kingdom of the dead that is ruled by Yima. For the three days that it rests on Earth, righteous souls sit at the head of their body, chanting the Ustavaiti Gathas with joy, while a wicked person sits at the feet of the corpse, wails and recites the Yasna. Zoroastrianism states that for the righteous souls, a beautiful maiden, which is the personification of the soul's good thoughts, words and deeds, appears. For a wicked person, a very old, ugly, naked hag appears. After three nights, the soul of the wicked is taken by the demon Vizaresa (Vīzarəša), to Chinvat bridge, and is made to go to darkness (hell).

Yima is believed to have been the first king on earth to rule, as well as the first man to die. Inside of Yima's realm, the spirits live a shadowy existence, and are dependent on their own descendants which are still living on Earth. Their descendants are to satisfy their hunger and clothe them, through rituals done on earth.

Rituals which are done on the first three days are vital and important, as they protect the soul from evil powers and give it strength to reach the underworld. After three days, the soul crosses Chinvat bridge which is the Final Judgment of the soul. Rashnu and Sraosha are present at the final judgment. The list is expanded sometimes, and include Vahman and Ormazd. Rashnu is the yazata who holds the scales of justice. If the good deeds of the person outweigh the bad, the soul is worthy of paradise. If the bad deeds outweigh the good, the bridge narrows down to the width of a blade-edge, and a horrid hag pulls the soul in her arms, and takes it down to hell with her.

Misvan Gatu is the "place of the mixed ones" where the souls lead a gray existence, lacking both joy and sorrow. A soul goes here if his/her good deeds and bad deeds are equal, and Rashnu's scale is equal.

The Society for Psychical Research was founded in 1882 with the express intention of investigating phenomena relating to Spiritualism and the afterlife. Its members continue to conduct scientific research on the paranormal to this day. Some of the earliest attempts to apply scientific methods to the study of phenomena relating to an afterlife were conducted by this organization. Its earliest members included noted scientists like William Crookes, and philosophers such as Henry Sidgwick and William James.

Parapsychological investigation of the afterlife includes the study of haunting, apparitions of the deceased, instrumental trans-communication, electronic voice phenomena, and mediumship. But also the study of the near death experience. Scientists who have worked in this area include Raymond Moody, Susan Blackmore, Charles Tart, William James, Ian Stevenson, Michael Persinger, Pim van Lommel and Penny Sartori among others.

A study conducted in 1901 by physician Duncan MacDougall sought to measure the weight lost by a human when the soul "departed the body" upon death. MacDougall weighed dying patients in an attempt to prove that the soul was material, tangible and thus measurable. Although MacDougall's results varied considerably from "21 grams", for some people this figure has become synonymous with the measure of a soul's mass. The title of the 2003 movie "21 Grams" is a reference to MacDougall's findings. His results have never been reproduced, and are generally regarded either as meaningless or considered to have had little if any scientific merit.

Frank Tipler has argued that physics can explain immortality, though such arguments are not falsifiable and thus do not qualify, in Karl Popper's views, as science.

After 25 years of parapsychological research, Susan Blackmore came to the conclusion according to her experiences there is not enough empirical evidence for many of these cases ., despite the contrary affirm other parapsychologists specialized in the subject.

There is a view based on the philosophical question of personal identity, termed open individualism by Daniel Kolak. It concludes that individual conscious experience is illusory, and because consciousness continues after death in all conscious beings, "you" do not die. This position has been supported by notable physicists such as Erwin Schrödinger and Freeman Dyson.

Certain problems arise with the idea of a particular person continuing after death. Peter van Inwagen, in his argument regarding resurrection, notes that the materialist must have some sort of physical continuity. John Hick also raises some questions regarding personal identity in his book, "Death and Eternal Life" using an example of a person ceasing to exist in one place while an exact replica appears in another. If the replica had all the same experiences, traits, and physical appearances of the first person, we would all attribute the same identity to the second, according to Hick.

In the panentheistic model of process philosophy and theology the writers Alfred North Whitehead and Charles Hartshorne rejected that the universe was made of substance, instead reality is composed of living experiences (occasions of experience). According to Hartshorne people do not experience subjective (or personal) immortality in the afterlife, but they do have objective immortality because their experiences live on forever in God, who contains all that was. However other process philosophers such as David Ray Griffin have written that people may have subjective experience after death.

Regarding the mind–body problem, some neuroscientists take a physicalist position according to which consciousness derives from and/or is reducible to physical phenomena such as neuronal activity occurring in the brain. The implication of this premise is that once the brain stops functioning at brain death, consciousness fails to survive and ceases to exist. Theoretical physicist Stephen Hawking rejected the concept of an afterlife, saying, "I regard the brain as a computer which will stop working when its components fail. There is no heaven or afterlife for broken down computers; that is a fairy story for people afraid of the dark".

Psychological proposals for the origin of a belief in an afterlife include cognitive disposition, cultural learning, and as an intuitive religious idea. In one study, children were able to recognize the ending of physical, mental, and perceptual activity in death, but were hesitant to conclude the ending of will, self, or emotion in death.

In 2008, a large-scale study conducted by the University of Southhampton involving 2060 patients from 15 hospitals in the United Kingdom, United States and Austria was launched. The AWARE (AWAreness during REsuscitation) study examined the broad range of mental experiences in relation to death. In a large study, researchers also tested the validity of conscious experiences for the first time using objective markers, to determine whether claims of awareness compatible with out-of-body experiences correspond with real or hallucinatory events. The results revealed that 40% of those who survived a cardiac arrest were aware during the time that they were clinically dead and before their hearts were restarted. Dr. Parnia, in the interview stated: “The evidence thus far suggests that in the first few minutes after death, consciousness is not annihilated.


 



</doc>
<doc id="1181" url="https://en.wikipedia.org/wiki?curid=1181" title="Astrometry">
Astrometry

Astrometry is the branch of astronomy that involves precise measurements of the positions and movements of stars and other celestial bodies. The information obtained by astrometric measurements provides information on the kinematics and physical origin of the Solar System and our galaxy, the Milky Way.

The history of astrometry is linked to the history of star catalogues, which gave astronomers reference points for objects in the sky so they could track their movements. This can be dated back to Hipparchus, who around 190 BC used the catalogue of his predecessors Timocharis and Aristillus to discover Earth's precession. In doing so, he also developed the brightness scale still in use today. Hipparchus compiled a catalogue with at least 850 stars and their positions. Hipparchus's successor, Ptolemy, included a catalogue of 1,022 stars in his work the "Almagest", giving their location, coordinates, and brightness.

In the 10th century, Abd al-Rahman al-Sufi carried out observations on the stars and described their positions, magnitudes and star color; furthermore, he provided drawings for each constellation, which are depicted in his "Book of Fixed Stars". Ibn Yunus observed more than 10,000 entries for the Sun's position for many years using a large astrolabe with a diameter of nearly 1.4 metres. His observations on eclipses were still used centuries later in Simon Newcomb's investigations on the motion of the Moon, while his other observations of the motions of the planets Jupiter and Saturn inspired Laplace's "Obliquity of the Ecliptic" and "Inequalities of Jupiter and Saturn". In the 15th century, the Timurid astronomer Ulugh Beg compiled the "Zij-i-Sultani", in which he catalogued 1,019 stars. Like the earlier catalogs of Hipparchus and Ptolemy, Ulugh Beg's catalogue is estimated to have been precise to within approximately 20 minutes of arc.

In the 16th century, Tycho Brahe used improved instruments, including large mural instruments, to measure star positions more accurately than previously, with a precision of 15–35 arcsec. Taqi al-Din measured the right ascension of the stars at the Constantinople Observatory of Taqi ad-Din using the "observational clock" he invented. When telescopes became commonplace, setting circles sped measurements

James Bradley first tried to measure stellar parallaxes in 1729. The stellar movement proved too insignificant for his telescope, but he instead discovered the aberration of light and the nutation of the Earth's axis. His cataloguing of 3222 stars was refined in 1807 by Friedrich Bessel, the father of modern astrometry. He made the first measurement of stellar parallax: 0.3 arcsec for the binary star 61 Cygni.

Being very difficult to measure, only about 60 stellar parallaxes had been obtained by the end of the 19th century, mostly by use of the filar micrometer. Astrographs using astronomical photographic plates sped the process in the early 20th century. Automated plate-measuring machines and more sophisticated computer technology of the 1960s allowed more efficient compilation of star catalogues. In the 1980s, charge-coupled devices (CCDs) replaced photographic plates and reduced optical uncertainties to one milliarcsecond. This technology made astrometry less expensive, opening the field to an amateur audience.

In 1989, the European Space Agency's Hipparcos satellite took astrometry into orbit, where it could be less affected by mechanical forces of the Earth and optical distortions from its atmosphere. Operated from 1989 to 1993, Hipparcos measured large and small angles on the sky with much greater precision than any previous optical telescopes. During its 4-year run, the positions, parallaxes, and proper motions of 118,218 stars were determined with an unprecedented degree of accuracy. A new "Tycho catalog" drew together a database of 1,058,332 to within 20-30 mas (milliarcseconds). Additional catalogues were compiled for the 23,882 double/multiple stars and 11,597 variable stars also analyzed during the Hipparcos mission.

Today, the catalogue most often used is USNO-B1.0, an all-sky catalogue that tracks proper motions, positions, magnitudes and other characteristics for over one billion stellar objects. During the past 50 years, 7,435 Schmidt camera plates were used to complete several sky surveys that make the data in USNO-B1.0 accurate to within 0.2 arcsec.

Apart from the fundamental function of providing astronomers with a reference frame to report their observations in, astrometry is also fundamental for fields like celestial mechanics, stellar dynamics and galactic astronomy. In observational astronomy, astrometric techniques help identify stellar objects by their unique motions. It is instrumental for keeping time, in that UTC is essentially the atomic time synchronized to Earth's rotation by means of exact astronomical observations. Astrometry is an important step in the cosmic distance ladder because it establishes parallax distance estimates for stars in the Milky Way.

Astrometry has also been used to support claims of extrasolar planet detection by measuring the displacement the proposed planets cause in their parent star's apparent position on the sky, due to their mutual orbit around the center of mass of the system. Astrometry is more accurate in space missions that are not affected by the distorting effects of the Earth's atmosphere. NASA's planned Space Interferometry Mission (SIM PlanetQuest) (now cancelled) was to utilize astrometric techniques to detect terrestrial planets orbiting 200 or so of the nearest solar-type stars. The European Space Agency's Gaia Mission, launched in 2013, applies astrometric techniques in its stellar census. In addition to the detection of exoplanets, it can also be used to determine their mass.

Astrometric measurements are used by astrophysicists to constrain certain models in celestial mechanics. By measuring the velocities of pulsars, it is possible to put a limit on the asymmetry of supernova explosions. Also, astrometric results are used to determine the distribution of dark matter in the galaxy.

Astronomers use astrometric techniques for the tracking of near-Earth objects. Astrometry is responsible for the detection of many record-breaking Solar System objects. To find such objects astrometrically, astronomers use telescopes to survey the sky and large-area cameras to take pictures at various determined intervals. By studying these images, they can detect Solar System objects by their movements relative to the background stars, which remain fixed. Once a movement per unit time is observed, astronomers compensate for the parallax caused by Earth's motion during this time and the heliocentric distance to this object is calculated. Using this distance and other photographs, more information about the object, including its orbital elements, can be obtained.

50000 Quaoar and 90377 Sedna are two Solar System objects discovered in this way by Michael E. Brown and others at Caltech using the Palomar Observatory's Samuel Oschin telescope of and the Palomar-Quest large-area CCD camera. The ability of astronomers to track the positions and movements of such celestial bodies is crucial to the understanding of the Solar System and its interrelated past, present, and future with others in the Universe.

A fundamental aspect of astrometry is error correction. Various factors introduce errors into the measurement of stellar positions, including atmospheric conditions, imperfections in the instruments and errors by the observer or the measuring instruments. Many of these errors can be reduced by various techniques, such as through instrument improvements and compensations to the data. The results are then analyzed using statistical methods to compute data estimates and error ranges.







</doc>
<doc id="1182" url="https://en.wikipedia.org/wiki?curid=1182" title="Athena">
Athena

Athena or Athene, often given the epithet Pallas, is an ancient Greek goddess associated with wisdom, handicraft, and warfare, who was later syncretized with the Roman goddess Minerva. Athena was regarded as the patron and protectress of various cities across Greece, particularly the city of Athens, from which she most likely received her name. She is usually shown in art wearing a helmet and holding a spear. Her major symbols include owls, olive trees, snakes, and the Gorgoneion.

From her origin as an Aegean palace goddess, Athena was closely associated with the city. She was known as "Polias" and "Poliouchos" (both derived from "polis", meaning "city-state"), and her temples were usually located atop the fortified acropolis in the central part of the city. The Parthenon on the Athenian Acropolis is dedicated to her, along with numerous other temples and monuments. As the patron of craft and weaving, Athena was known as "Ergane". She was also a warrior goddess, and was believed to lead soldiers into battle as "Athena Promachos". Her main festival in Athens was the Panathenaia, which was celebrated during the month of Hekatombaion in midsummer and was the most important festival on the Athenian calendar.

In Greek mythology, Athena was believed to have been born from the head of her father Zeus. In the founding myth of Athens, Athena bested Poseidon in a competition over patronage of the city by creating the first olive tree. She was known as "Athena Parthenos" ("Athena the Virgin"), but, in one archaic Attic myth, the god Hephaestus tried and failed to rape her, resulting in Gaia giving birth to Erichthonius, an important Athenian founding hero. Athena was the patron goddess of heroic endeavor; she was believed to have also aided the heroes Perseus, Heracles, Bellerophon, and Jason. Along with Aphrodite and Hera, Athena was one of the three goddesses whose feud resulted in the beginning of the Trojan War. She plays an active role in the "Iliad", in which she assists the Achaeans and, in the "Odyssey", she is the divine counselor to Odysseus.

In the later writings of the Roman poet Ovid, Athena was said to have competed against the mortal Arachne in a weaving competition, afterwards transforming Arachne into the first spider; Ovid also describes how she transformed Medusa into a Gorgon after witnessing her being raped by Poseidon in her temple. Since the Renaissance, Athena has become an international symbol of wisdom, the arts, and classical learning. Western artists and allegorists have often used Athena as a symbol of freedom and democracy.

Athena is associated with the city of Athens. The name of the city in ancient Greek is "Ἀθῆναι" ("Athenai"), a plural toponym, designating the place where—according to myth—she presided over the "Athenai", a sisterhood devoted to her worship. In ancient times, scholars argued whether Athena was named after Athens or Athens after Athena. Now scholars generally agree that the goddess takes her name from the city; the ending -"ene" is common in names of locations, but rare for personal names. Testimonies from different cities in ancient Greece attest that similar city goddesses were worshipped in other cities and, like Athena, took their names from the cities where they were worshipped. For example, in Mycenae there was a goddess called Mykene, whose sisterhood was known as "Mykenai", whereas at Thebes an analogous deity was called Thebe, and the city was known under the plural form "Thebai" (or Thebes, in English, where the 's' is the plural formation). The name "Athenai" is likely of Pre-Greek origin because it contains the presumably Pre-Greek morpheme "*-ān-".

In his dialogue "Cratylus", the ancient Greek philosopher Plato (428–347 BC) gives some rather imaginative etymologies of Athena's name, based on the theories of the ancient Athenians and his own etymological speculations:

Thus, Plato believed that Athena's name was derived from Greek , "Atheonóa"—which the later Greeks rationalised as from the deity's (θεός, "theós") mind (νοῦς, "noũs"). The second-century AD orator Aelius Aristides attempted to derive natural symbols from the etymological roots of Athena's names to be "aether", "air", "earth", and "moon".

Athena was originally the Aegean goddess of the palace, who presided over household crafts and protected the king. A single Mycenaean Greek inscription "a-ta-na po-ti-ni-ja" /Athana potnia/ appears at Knossos in the Linear B tablets from the Late Minoan II-era "Room of the Chariot Tablets"; these comprise the earliest Linear B archive anywhere. Although "Athana potnia" is often translated "Mistress Athena", it could also mean "the "Potnia" of Athana", or "the Lady of Athens". However, any connection to the city of Athens in the Knossos inscription is uncertain. A sign series "a-ta-no-dju-wa-ja" appears in the still undeciphered corpus of Linear A tablets, written in the unclassified Minoan language. This could be connected with the Linear B Mycenaean expressions "a-ta-na po-ti-ni-ja" and "di-u-ja" or "di-wi-ja" ("Diwia", "of Zeus" or, possibly, related to a homonymous goddess), resulting in a translation "Athena of Zeus" or "divine Athena". Similarly, in the Greek mythology and epic tradition, Athena figures as a daughter of Zeus (Διός θυγάτηρ; "cfr." Dyeus). However, the inscription quoted seems to be very similar to "a-ta-nū-tī wa-ya", quoted as SY Za 1 by Jan Best. Best translates the initial "a-ta-nū-tī", which is recurrent in line beginnings, as "I have given".

A Mycenean fresco depicts two women extending their hands towards a central figure, who is covered by an enormous figure-eight shield; this may depict the warrior-goddess with her "palladion", or her palladion in an aniconic representation. In the "Procession Fresco" at Knossos, which was reconstructed by the Mycenaeans, two rows of figures carrying vessels seem to meet in front of a central figure, which is probably the Minoan precursor to Athena. The early twentieth-century scholar Martin Persson Nilsson argued that the Minoan snake goddess figurines are early representations of Athena.

Nilsson and others have claimed that, in early times, Athena was either an owl herself or a bird goddess in general. In the third book of the "Odyssey", she takes the form of a sea-eagle. Proponents of this view argue that she dropped her prophylactic owl-mask before she lost her wings. "Athena, by the time she appears in art," Jane Ellen Harrison remarks, "has completely shed her animal form, has reduced the shapes she once wore of snake and bird to attributes, but occasionally in black-figure vase-paintings she still appears with wings."

It is generally agreed that the cult of Athena preserves some aspects of the Proto-Indo-European transfunctional goddess. The cult of Athena may have also been influenced by those of Near Eastern warrior goddesses such as the East Semitic Ishtar and the Ugaritic Anat, both of whom were often portrayed bearing arms. Classical scholar Charles Penglase notes that Athena closely resembles Inanna in her role as a "terrifying warrior goddess" and that both goddesses were closely linked with creation. Athena's birth from the head of Zeus may be derived from the earlier Sumerian myth of Inanna's descent into and return from the Underworld.

Plato notes that the citizens of Sais in Egypt worshipped a goddess known as Neith, whom he identifies with Athena. Neith was the ancient Egyptian goddess of war and hunting, who was also associated with weaving; her worship began during the Egyptian Pre-Dynastic period. In Greek mythology, Athena was reported to have visited mythological sites in North Africa, including Libya's Triton River and the Phlegraean plain. Based on these similarities, the Sinologist Martin Bernal created the "Black Athena" hypothesis, which claimed that Neith was brought to Greece from Egypt, along with "an enormous number of features of civilization and culture in the third and second millennia". The "Black Athena" hypothesis stirred up widespread controversy near the end of the twentieth century, but it has now been widely rejected by modern scholars.

In her aspect of "Athena Polias", Athena was venerated as the goddess of the city and the protectress of the citadel. In Athens, the Plynteria, or "Feast of the Bath", was observed every year at the end of the month of Thargelion. The festival lasted for five days. During this period, the priestesses of Athena, or "plyntrídes", performed a cleansing ritual within the Erechtheion, a sanctuary devoted to Athena and Poseidon. Here Athena's statue was undressed, her clothes washed, and body purified. Athena was worshipped at festivals such as Chalceia as "Athena Ergane", the patroness of various crafts, especially weaving. She was also the patron of metalworkers and was believed to aid in the forging of armor and weapons. During the late fifth century BC, the role of goddess of philosophy became a major aspect of Athena's cult.

As "Athena Promachos", she was believed to lead soldiers into battle. Athena represented the disciplined, strategic side of war, in contrast to her brother Ares, the patron of violence, bloodlust, and slaughter—"the raw force of war". Athena was believed to only support those fighting for a just cause and was thought to view war primarily as a means to resolve conflict. The Greeks regarded Athena with much higher esteem than Ares. Athena was especially worshipped in this role during the festivals of the Panathenaea and Pamboeotia, both of which prominently featured displays of athletic and military prowess. As the patroness of heroes and warriors, Athena was believed to favor those who used cunning and intelligence rather than brute strength.

In her aspect as a warrior maiden, Athena was known as "Parthenos" ( "virgin"), because, like her fellow goddesses Artemis and Hestia, she was believed to remain perpetually a virgin. Athena's most famous temple, the Parthenon on the Athenian Acropolis, takes its name from this title. According to Karl Kerényi, a scholar of Greek mythology, the name "Parthenos" is not merely an observation of Athena's virginity, but also a recognition of her role as enforcer of rules of sexual modesty and ritual mystery. Even beyond recognition, the Athenians allotted the goddess value based on this pureness of virginity, which they upheld as a rudiment of female behavior. Kerényi's study and theory of Athena explains her virginal epithet as a result of her relationship to her father Zeus and a vital, cohesive piece of her character throughout the ages. This role is expressed in a number of stories about Athena. Marinus of Neapolis reports that when Christians removed the statue of the goddess from the Parthenon, a beautiful woman appeared in a dream to Proclus, a devotee of Athena, and announced that the ""Athenian Lady"" wished to dwell with him.

Athena was not only the patron goddess of Athens, but also other cities, including Argos, Sparta, Gortyn, Lindos, and Larisa. The various cults of Athena were all branches of her panhellenic cult and often proctored various initiation rites of Grecian youth, such as the passage into citizenship by young men or the passage of young women into marriage. These cults were portals of a uniform socialization, even beyond mainland Greece. Athena was frequently equated with Aphaea, a local goddess of the island of Aegina, originally from Crete and also associated with Artemis and the nymph Britomartis. In Arcadia, she was assimilated with the ancient goddess Alea and worshiped as Athena Alea. Sanctuaries dedicated to Athena Alea were located in the Laconian towns of Mantineia and Tegea. The temple of Athena Alea in Tegea was an important religious center of ancient Greece. The geographer Pausanias was informed that the "temenos" had been founded by Aleus.

Athena had a major temple on the Spartan Acropolis, where she was venerated as Poliouchos and "Khalkíoikos" ("of the Brazen House", often latinized as "Chalcioecus"). This epithet may refer to the fact that cult statue held there may have been made of bronze, that the walls of the temple itself may have been made of bronze, or that Athena was the patron of metal-workers. Bells made of terracotta and bronze were used in Sparta as part of Athena's cult. An Ionic-style temple to Athena Polias was built at Priene in the fourth century BC. It was designed by Pytheos of Priene, the same architect who designed the Mausoleum at Halicarnassus. The temple was dedicated by Alexander the Great and an inscription from the temple declaring his dedication is now held in the British Museum.

Athena was known as "Atrytone" ( "the Unwearying"), "Parthenos" ( "Virgin"), and "Promachos" ( "she who fights in front"). The epithet "Polias" (Πολιάς "of the city"), refers to Athena's role as protectress of the city. The epithet "Ergane" (Εργάνη "the Industrious") pointed her out as the patron of craftsmen and artisans. Burkert notes that the Athenians sometimes simply called Athena "the Goddess", "hē theós" (ἡ θεός), certainly an ancient title. After serving as the judge at the trial of Orestes in which he was acquitted of having murdered his mother Clytemnestra, Athena won the epithet "Areia" (Αρεία).

Athena was sometimes given the epithet "Hippia" (Ἵππια "of the horses", "equestrian"), referring to her invention of the bit, bridle, chariot, and wagon. The Greek geographer Pausanias mentions in his "Guide to Greece" that the temple of Athena "Chalinitis" ("the bridler") in Corinth was located near the tomb of Medea's children. Other epithets include Ageleia, Itonia and "Aethyia", under which she was worshiped in Megara. The word "aíthyia" () signifies a "diver", also some diving bird species (possibly the shearwater) and figuratively, a "ship", so the name must reference Athena teaching the art of shipbuilding or navigation. In a temple at Phrixa in Elis, reportedly built by Clymenus, she was known as "Cydonia" (Κυδωνία).

The Greek biographer Plutarch (46–120 AD) refers to an instance during the Parthenon's construction of her being called "Athena Hygieia" (Ὑγίεια, i. e. personified "Health") after inspiring a physician to a successful course of treatment.

In Homer's epic works, Athena's most common epithet is "Glaukopis" (), which usually is translated as, "bright-eyed" or "with gleaming eyes". The word is a combination of "glaukós" (, meaning "gleaming, silvery", and later, "bluish-green" or "gray") and "ṓps" (, "eye, face"). The word "glaúx" (, "little owl") is from the same root, presumably according to some, because of the bird's own distinctive eyes. Athena was clearly associated with the owl from very early on; in archaic images, she is frequently depicted with an owl perched on her hand. Through its association with Athena, the owl evolved into the national mascot of the Athenians and eventually became a symbol of wisdom.

In the "Iliad" (4.514), the "Odyssey" (3.378), the "Homeric Hymns", and in Hesiod's "Theogony", Athena is also given the curious epithet "Tritogeneia" (Τριτογένεια), whose significance remains unclear. It could mean various things, including "Triton-born", perhaps indicating that the homonymous sea-deity was her parent according to some early myths. One myth relates the foster father relationship of this Triton towards the half-orphan Athena, whom he raised alongside his own daughter Pallas. Kerényi suggests that "Tritogeneia did not mean that she came into the world on any particular river or lake, but that she was born of the water itself; for the name Triton seems to be associated with water generally." In Ovid's "Metamorphoses", Athena is occasionally referred to as "Tritonia".

Another possible meaning may be "triple-born" or "third-born", which may refer to a triad or to her status as the third daughter of Zeus or the fact she was born from Metis, Zeus, and herself; various legends list her as being the first child after Artemis and Apollo, though other legends identify her as Zeus' first child. Several scholars have suggested a connection to the Rigvedic god Trita, who was sometimes grouped in a body of three mythological poets. Michael Janda has connected the myth of Trita to the scene in the "Iliad" in which the "three brothers" Zeus, Poseidon, and Hades divide the world between them, receiving the "broad sky", the sea, and the underworld respectively. Janda further connects the myth of Athena being born of the head (i. e. the uppermost part) of Zeus, understanding "Trito-" (which perhaps originally meant "the third") as another word for "the sky". In Janda's analysis of Indo-European mythology, this heavenly sphere is also associated with the mythological body of water surrounding the inhabited world ("cfr." Triton's mother, Amphitrite).

Yet another possible meaning is mentioned in Diogenes Laertius' biography of Democritus, that Athena was called "Tritogeneia" because three things, on which all mortal life depends, come from her.

In the classical Olympian pantheon, Athena was regarded as the favorite daughter of Zeus, born fully armed from his forehead. The story of her birth comes in several versions. The earliest mention is in Book V of the "Iliad", when Ares accuses Zeus of being biased in favor of Athena because ""autos egeinao"" (literally "you fathered her", but probably intended as "you gave birth to her"). In the version recounted by Hesiod in his "Theogony", Zeus married the goddess Metis, who is described as the "wisest among gods and mortal men", and engaged in sexual intercourse with her. After learning that Metis was pregnant, however, he became afraid that the unborn offspring would try to overthrow him, because Gaia and Ouranos had prophesied that Metis would bear children wiser than their father. In order to prevent this, Zeus tricked Metis into letting him swallow her, but it was too late because Metis had already conceived. A later account of the story from the "Bibliotheca" of Pseudo-Apollodorus, written in the second century AD, makes Metis Zeus's unwilling sexual partner, rather than his wife. According to this version of the story, Metis transformed into many different shapes in effort to escape Zeus, but Zeus successfully raped her and swallowed her.

After swallowing Metis, Zeus took six more wives in succession until he married his seventh and present wife, Hera. Then Zeus experienced an enormous headache. He was in such pain that he ordered someone (either Prometheus, Hephaestus, Hermes, Ares, or Palaemon, depending on the sources examined) to cleave his head open with the "labrys", the double-headed Minoan axe. Athena leaped from Zeus's head, fully grown and armed. The "First Homeric Hymn to Athena" states in lines 9–16 that the gods were awestruck by Athena's appearance and even Helios, the god of the sun, stopped his chariot in the sky. Pindar, in his "Seventh Olympian Ode", states that she "cried aloud with a mighty shout" and that "the Sky and mother Earth shuddered before her."

Hesiod states that Hera was so annoyed at Zeus for having given birth to a child on his own that she conceived and bore Hephaestus by herself, but in "Imagines" 2. 27 (trans. Fairbanks), the third-century AD Greek rhetorician Philostratus the Elder writes that Hera "rejoices" at Athena's birth "as though Athena were her daughter also." The second-century AD Christian apologist Justin Martyr takes issue with those pagans who erect at springs images of Kore, whom he interprets as Athena: "They said that Athena was the daughter of Zeus not from intercourse, but when the god had in mind the making of a world through a word ("logos") his first thought was Athena." A "scholium" on the "Iliad" makes Athena the daughter of Brontes the Cyclops, who seduced Metis and impregnated her, prompting Zeus to swallow her. The "Etymologicum Magnum" instead deems Athena the daughter of the Daktyl Itonos. Fragments attributed by the Christian Eusebius of Caesarea to the semi-legendary Phoenician historian Sanchuniathon, which Eusebius thought had been written before the Trojan war, make Athena instead the daughter of Cronus, a king of Byblos who visited "the inhabitable world" and bequeathed Attica to Athena.

Athena's epithet "Pallas" is derived either from , meaning "to brandish [as a weapon]", or, more likely, from and related words, meaning "youth, young woman". On this topic, Walter Burkert says "she is the Pallas of Athens, "Pallas Athenaie", just as Hera of Argos is "Here Argeie"." In later times, after the original meaning of the name had been forgotten, the Greeks invented myths to explain its origin, such as those reported by the Epicurean philosopher Philodemus and the "Bibliotheca" of Pseudo-Apollodorus, which claim that "Pallas" was originally a separate entity, whom Athena had slain in combat.

In one version of the myth, Pallas was the daughter of the sea-god Triton; she and Athena were childhood friends, but Athena accidentally killed her during a friendly sparring match. Distraught over what she had done, Athena took the name Pallas for herself as a sign of her grief. In another version of the story, Pallas was a Gigante; Athena slew him during the Gigantomachy and flayed off his skin to make her cloak, which she wore as a victory trophy. In an alternative variation of the same myth, Pallas was instead Athena's father, who attempted to assault his own daughter, causing Athena to kill him and take his skin as a trophy.

The "palladion" was a statue of Athena that was said to have stood in her temple on the Trojan Acropolis. Athena was said to have carved the statue herself in the likeness of her dead friend Pallas. The statue had special talisman-like properties and it was thought that, as long as it was in the city, Troy could never fall. When the Greeks captured Troy, Cassandra, the daughter of Priam, clung to the palladion for protection, but Ajax the Lesser violently tore her away from it and dragged her over to the other captives. Athena was infuriated by this violation of her protection. Although Agamemnon attempted to placate her anger with sacrifices, Athena sent a storm at Cape Kaphereos to destroy almost the entire Greek fleet and scatter all of the surviving ships across the Aegean.

In a founding myth reported by Pseudo-Apollodorus, Athena competed with Poseidon for the patronage of Athens. They agreed that each would give the Athenians one gift and that Cecrops, the king of Athens, would determine which gift was better. Poseidon struck the ground with his trident and a salt water spring sprang up; this gave the Athenians access to trade and water. Athens at its height was a significant sea power, defeating the Persian fleet at the Battle of Salamis—but the water was salty and undrinkable. In an alternative version of the myth from Vergil's "Georgics", Poseidon instead gave the Athenians the first horse. Athena offered the first domesticated olive tree. Cecrops accepted this gift and declared Athena the patron goddess of Athens. The olive tree brought wood, oil, and food, and became a symbol of Athenian economic prosperity. Robert Graves was of the opinion that "Poseidon's attempts to take possession of certain cities are political myths", which reflect the conflict between matriarchal and patriarchal religions.

Pseudo-Apollodorus records an archaic legend, which claims that Hephaestus once attempted to rape Athena, but she pushed him away, causing him to ejaculate on her thigh. Athena wiped the semen off using a tuft of wool, which she tossed into the dust, impregnating Gaia and causing her to give birth to Erichthonius. Athena adopted Erichthonius as her son and raised him. The Roman mythographer Hyginus records a similar story in which Hephaestus demanded Zeus to let him marry Athena since he was the one who had smashed open Zeus's skull, allowing Athena to be born. Zeus agreed to this and Hephaestus and Athena were married, but, when Hephaestus was about to consummate the union, Athena vanished from the bridal bed, causing him to ejaculate on the floor, thus impregnating Gaia with Erichthonius.

The geographer Pausanias records that Athena placed the infant Erichthonius into a small chest ("cista"), which she entrusted to the care of the three daughters of Cecrops: Herse, Pandrosos, and Aglauros of Athens. She warned the three sisters not to open the chest, but did not explain to them why or what was in it. Aglauros, and possibly one of the other sisters, opened the chest. Differing reports say that they either found that the child itself was a serpent, that it was guarded by a serpent, that it was guarded by two serpents, or that it had the legs of a serpent. In Pausanias's story, the two sisters were driven mad by the sight of the chest's contents and hurled themselves off the Acropolis, dying instantly, but an Attic vase painting shows them being chased by the serpent off the edge of the cliff instead.

Erichthonius was one of the most important founding heroes of Athens and the legend of the daughters of Cecrops was a cult myth linked to the rituals of the Arrhephoria festival. Pausanias records that, during the Arrhephoria, two young girls known as the "Arrhephoroi", who lived near the temple of Athena Polias, would be given hidden objects by the priestess of Athena, which they would carry on their heads down a natural underground passage. They would leave the objects they had been given at the bottom of the passage and take another set of hidden objects, which they would carry on their heads back up to the temple. The ritual was performed in the dead of night and no one, not even the priestess, knew what the objects were. The serpent in the story may be the same one depicted coiled at Athena's feet in Pheidias's famous statue of the "Athena Parthenos" in the Parthenon. Many of the surviving sculptures of Athena show this serpent.

Herodotus records that a serpent lived in a crevice on the north side of the summit of the Athenian Acropolis and that the Athenians left a honey cake for it each month as an offering. On the eve of the Second Persian invasion of Greece in 480 BC, the serpent did not eat the honey cake and the Athenians interpreted it as a sign that Athena herself had abandoned them. Another version of the myth of the Athenian maidens is told in "Metamorphoses" by the Roman poet Ovid (43 BC17 AD); in this late variant Hermes falls in love with Herse. Herse, Aglaulus, and Pandrosus go to the temple to offer sacrifices to Athena. Hermes demands help from Aglaulus to seduce Herse. Aglaulus demands money in exchange. Hermes gives her the money the sisters have already offered to Athena. As punishment for Aglaulus's greed, Athena asks the goddess Envy to make Aglaulus jealous of Herse. When Hermes arrives to seduce Herse, Aglaulus stands in his way instead of helping him as she had agreed. He turns her to stone.

According to Pseudo-Apollodorus's "Bibliotheca", Athena advised Argos, the builder of the "Argo", the ship on which the hero Jason and his band of Argonauts sailed, and aided in the ship's construction. Pseudo-Apollodorus also records that Athena guided the hero Perseus in his quest to behead Medusa. She and Hermes, the god of travelers, appeared to Perseus after he set off on his quest and gifted him with tools he would need to kill the Gorgon. Athena gave Perseus a polished bronze shield to view Medusa's reflection rather than looking at her directly and thereby avoid being turned to stone. Hermes gave him an adamantine scythe to cut off Medusa's head. When Perseus swung his blade to behead Medusa, Athena guided it, allowing his scythe to cut it clean off. According to Pindar's "Thirteenth Olympian Ode", Athena helped the hero Bellerophon tame the winged horse Pegasus by giving him a bit.

In ancient Greek art, Athena is frequently shown aiding the hero Heracles. She appears in four of the twelve metopes on the Temple of Zeus at Olympia depicting Heracles's Twelve Labors, including the first, in which she passively watches him slay the Nemean lion, and the tenth, in which she is shown actively helping him hold up the sky. She is presented as his "stern ally", but also the "gentle... acknowledger of his achievements." Artistic depictions of Heracles's apotheosis show Athena driving him to Mount Olympus in her chariot and presenting him to Zeus for his deification. In Aeschylus's tragedy "Orestes", Athena intervenes to save Orestes from the wrath of the Erinyes and presides over his trial for the murder of his mother Clytemnestra. When half the jury votes to acquit and the other half votes to convict, Athena casts the deciding vote to acquit Orestes and declares that, from then on, whenever a jury is tied, the defendant shall always be acquitted.

In "The Odyssey", Odysseus' cunning and shrewd nature quickly wins Athena's favour. For the first part of the poem, however, she largely is confined to aiding him only from "afar", mainly by implanting thoughts in his head during his journey home from Troy. Her guiding actions reinforce her role as the "protectress of heroes," or, as mythologian Walter Friedrich Otto dubbed her, the "goddess of nearness," due to her mentoring and motherly probing. It is not until he washes up on the shore of the island of the Phaeacians, where Nausicaa is washing her clothes that Athena arrives personally to provide more tangible assistance. She appears in Nausicaa's dreams to ensure that the princess rescues Odysseus and plays a role in his eventual escort to Ithaca. Athena appears to Odysseus upon his arrival, disguised as a herdsman; she initially lies and tells him that Penelope, his wife, has remarried and that he is believed to be dead, but Odysseus lies back to her, employing skillful prevarications to protect himself. Impressed by his resolve and shrewdness, she reveals herself and tells him what he needs to know in order to win back his kingdom. She disguises him as an elderly beggar so that he will not be recognized by the suitors or Penelope, and helps him to defeat the suitors. Athena also appears to Odysseus's son Telemachus. Her actions lead him to travel around to Odysseus's comrades and ask about his father. He hears stories about some of Odysseus's journey. Athena's push for Telemachos's journey helps him grow into the man role, that his father once held. She also plays a role in ending the resultant feud against the suitors' relatives. She instructs Laertes to throw his spear and to kill Eupeithes, the father of Antinous.

The Gorgoneion appears to have originated as an apotropaic symbol intended to ward off evil. In a late myth invented to explain the origins of the Gorgon, Medusa is described as having been a young priestess who served in the temple of Athena in Athens. Poseidon lusted after Medusa, and raped her in the temple of Athena, refusing to allow her vow of chastity to stand in his way. Upon discovering the desecration of her temple, Athena transformed Medusa into a hideous monster with serpents for hair whose gaze would turn any mortal to stone.

In his "Twelfth Pythian Ode", Pindar recounts the story of how Athena invented the "aulos", a kind of flute, in imitation of the lamentations of Medusa's sisters, the Gorgons, after she was beheaded by the hero Perseus. According to Pindar, Athena gave the aulos to mortals as a gift. Later, the comic playwright Melanippides of Melos ( 480-430 BC) embellished the story in his comedy "Marsyas", claiming that Athena looked in the mirror while she was playing the aulos and saw how blowing into it puffed up her cheeks and made her look silly, so she threw the aulos away and cursed it so that whoever picked it up would meet an awful death. The aulos was picked up by the satyr Marsyas, who was later killed by Apollo for his hubris. Later, this version of the story became accepted as canonical and the Athenian sculptor Myron created a group of bronze sculptures based on it, which was installed before the western front of the Parthenon in around 440 BC.

A myth told by the early third-century BC Hellenistic poet Callimachus in his "Hymn" 5 begins with Athena bathing in a spring on Mount Helicon at midday with one of her favorite companions, the nymph Chariclo. Chariclo's son Tiresias happened to be hunting on the same mountain and came to the spring searching for water. He inadvertently saw Athena naked, so she struck him blind to ensure he would never again see what man was not intended to see. Chariclo intervened on her son's behalf and begged Athena to have mercy. Athena replied that she could not restore Tiresias's eyesight, so, instead, she gave him the ability to understand the language of the birds and thus foretell the future.

The fable of Arachne appears in Ovid's "Metamorphoses" (8 AD) (vi.5–54 and 129–145), which is nearly the only extant source for the legend. The story does not appear to have been well known prior to Ovid's rendition of it and the only earlier reference to it is a brief allusion in Virgil's "Georgics", (29 BC) (iv, 246) that does not mention Arachne by name. According to Ovid, Arachne (whose name means "spider" in ancient Greek) was the daughter of a famous dyer in Tyrian purple in Hypaipa of Lydia, and a weaving student of Athena. She became so conceited of her skill as a weaver that she began claiming that her skill was greater than that of Athena herself. Athena gave Arachne a chance to redeem herself by assuming the form of an old woman and warning Arachne not to offend the deities. Arachne scoffed and wished for a weaving contest, so she could prove her skill.

Athena wove the scene of her victory over Poseidon in the contest for the patronage of Athens. Arachne's tapestry featured twenty-one episodes of the deities' infidelity, including Zeus being unfaithful with Leda, with Europa, and with Danaë. Athena admitted that Arachne's work was flawless, but was outraged at Arachne's offensive choice of subject, which displayed the failings and transgressions of the deities. Finally, losing her temper, Athena destroyed Arachne's tapestry and loom, striking it with her shuttle. Athena then struck Arachne across the face with her staff four times. Arachne hanged herself in despair, but Athena took pity on her and brought her back from the dead in the form of a spider.

The myth of the Judgement of Paris is mentioned briefly in the "Iliad", but is described in depth in an epitome of the "Cypria", a lost poem of the Epic Cycle, which records that all the gods and goddesses as well as various mortals were invited to the marriage of Peleus and Thetis (the eventual parents of Achilles). Only Eris, goddess of discord, was not invited. She was annoyed at this, so she arrived with a golden apple inscribed with the word καλλίστῃ (kallistēi, "for the fairest"), which she threw among the goddesses. Aphrodite, Hera, and Athena all claimed to be the fairest, and thus the rightful owner of the apple.

The goddesses chose to place the matter before Zeus, who, not wanting to favor one of the goddesses, put the choice into the hands of Paris, a Trojan prince. After bathing in the spring of Mount Ida where Troy was situated, the goddesses appeared before Paris for his decision. In the extant ancient depictions of the Judgement of Paris, Aphrodite is only occasionally represented nude, and Athena and Hera are always fully clothed. Since the Renaissance, however, western paintings have typically portrayed all three goddesses as completely naked.

All three goddesses were ideally beautiful and Paris could not decide between them, so they resorted to bribes. Hera tried to bribe Paris with power over all Asia and Europe, and Athena offered fame and glory in battle, but Aphrodite promised Paris that, if he were to choose her as the fairest, she would let him marry the most beautiful woman on earth. This woman was Helen, who was already married to King Menelaus of Sparta. Paris selected Aphrodite and awarded her the apple. The other two goddesses were enraged and, as a direct result, sided with the Greeks in the Trojan War.

In Books V–VI of the "Iliad", Athena aids the hero Diomedes, who, in the absence of Achilles, proves himself to be the most effective Greek warrior. Several artistic representations from the early sixth century BC may show Athena and Diomedes, including an early sixth-century BC shield band depicting Athena and an unidentified warrior riding on a chariot, a vase painting of a warrior with his charioteer facing Athena, and an inscribed clay plaque showing Diomedes and Athena riding in a chariot. Numerous passages in the "Iliad" also mention Athena having previously served as the patron of Diomedes's father Tydeus. When the Trojan women go to the temple of Athena on the Acropolis to plead her for protection from Diomedes, Athena ignores them.

In Book XXII of the "Iliad", while Achilles is chasing Hector around the walls of Troy, Athena appears to Hector disguised as his brother Deiphobus and persuades him to hold his ground so that they can fight Achilles together. Then, Hector throws his spear at Achilles and misses, expecting Deiphobus to hand him another, but Athena disappears instead, leaving Hector to face Achilles alone without his spear. In Sophocles's tragedy "Ajax", she punishes Odysseus's rival Ajax the Great, driving him insane and causing him to massacre the Achaeans' cattle, thinking that he is slaughtering the Achaeans themselves. Even after Odysseus himself expresses pity for Ajax, Athena declares, "To laugh at your enemies - what sweeter laughter can there be than that?" (lines 78–9). Ajax later commits suicide as a result of his humiliation.

Athena appears frequently in classical Greek art, including on coins and in paintings on ceramics. She is especially prominent in works produced in Athens. In classical depictions, Athena is usually portrayed standing upright, wearing a full-length chiton. She is most often represented dressed in armor like a male soldier and wearing a Corinthian helmet raised high atop her forehead. Her shield bears at its centre the aegis with the head of the gorgon ("gorgoneion") in the center and snakes around the edge. Sometimes she is shown wearing the aegis as a cloak. As Athena Promachos, she is shown brandishing a spear. Scenes in which Athena was represented include her birth from the head of Zeus, her battle with the Gigantes, the birth of Erichthonius, and the Judgement of Paris.

The "Mourning Athena" or "Athena Meditating" is a famous relief sculpture dating to around 470-460 BC that has been interpreted to represent Athena Polias. The most famous classical depiction of Athena was the "Athena Parthenos", a now-lost gold and ivory statue of her in the Parthenon created by the Athenian sculptor Phidias. Copies reveal that this statue depicted Athena holding her shield in her left hand with Nike, the winged goddess of victory, standing in her right. Athena Polias is also represented in a Neo-Attic relief now held in the Virginia Museum of Fine Arts, which depicts her holding an owl in her hand and wearing her characteristic Corinthian helmet while resting her shield against a nearby "herma". The Roman goddess Minerva adopted most of Athena's Greek iconographical associations, but was also integrated into the Capitoline Triad.

Early Christian writers, such as Clement of Alexandria and Firmicus, denigrated Athena as representative of all the things that were detestable about paganism; they condemned her as "immodest and immoral". During the Middle Ages, however, many attributes of Athena were given to the Virgin Mary, who, in fourth century portrayals, was often depicted wearing the Gorgoneion. Some even viewed the Virgin Mary as a warrior maiden, much like Athena Parthenos; one anecdote tells that the Virgin Mary once appeared upon the walls of Constantinople when it was under siege by the Avars, clutching a spear and urging the people to fight. During the Middle Ages, Athena became widely used as a Christian symbol and allegory, and she appeared on the family crests of certain noble houses.

During the Renaissance, Athena donned the mantle of patron of the arts and human endeavor; allegorical paintings involving Athena were a favorite of the Italian Renaissance painters. In Sandro Botticelli's painting "Pallas and the Centaur", probably painted sometime in the 1480s, Athena is the personification of chastity, who is shown grasping the forelock of a centaur, who represents lust. Andrea Mantegna's 1502 painting "Minerva Expelling the Vices from the Garden of Virtue" uses Athena as the personification of Graeco-Roman learning chasing the vices of medievalism from the garden of modern scholarship. Athena is also used as the personification of wisdom in Bartholomeus Spranger's 1591 painting "The Triumph of Wisdom" or "Minerva Victorious over Ignorance".

During the sixteenth and seventeenth centuries, Athena was used as a symbol for female rulers. In his book "A Revelation of the True Minerva" (1582), Thomas Blennerhassett portrays Queen Elizabeth I of England as a "new Minerva" and "the greatest goddesse nowe on earth". A series of paintings by Peter Paul Rubens depict Athena as Marie de' Medici's patron and mentor; the final painting in the series goes even further and shows Marie de' Medici with Athena's iconography, as the mortal incarnation of the goddess herself. The German sculptor Jean-Pierre-Antoine Tassaert later portrayed Catherine II of Russia as Athena in a marble bust in 1774. During the French Revolution, statues of pagan gods were torn down all throughout France, but statues of Athena were not. Instead, Athena was transformed into the personification of freedom and the republic and a statue of the goddess stood in the center of the Place de la Revolution in Paris. In the years following the Revolution, artistic representations of Athena proliferated.

A statue of Athena stands directly in front of the Austrian Parliament Building in Vienna, and depictions of Athena have influenced other symbols of western freedom, including the Statue of Liberty and Britannia. For over a century, a full-scale replica of the Parthenon has stood in Nashville, Tennessee. In 1990, the curators added a gilded forty-two foot (12.5 m) tall replica of Phidias's "Athena Parthenos", built from concrete and fiberglass. The state seal of California bears the image of Athena kneeling next to a brown grizzly bear. Athena has occasionally appeared on modern coins, as she did on the ancient Athenian drachma. Her head appears on the $50 1915-S Panama-Pacific commemorative coin.

One of Sigmund Freud's most treasured possessions was a small, bronze sculpture of Athena, which sat on his desk. Freud once described Athena as "a woman who is unapproachable and repels all sexual desires - since she displays the terrifying genitals of the Mother." Feminist views on Athena are sharply divided; some feminists regard her as a symbol of female empowerment, while others regard her as "the ultimate patriarchal sell out... who uses her powers to promote and advance men rather than others of her sex." In contemporary Wicca, Athena is venerated as an aspect of the Goddess and some Wiccans believe that she may bestow the "Owl Gift" ("the ability to write and communicate clearly") upon her worshippers. Due to her status as one of the twelve Olympians, Athena is a major deity in Hellenismos, a Neopagan religion which seeks to authentically revive and recreate the religion of ancient Greece in the modern world.

Athena is a natural patron of universities: At Bryn Mawr College in Pennsylvania a statue of Athena (a replica of the original bronze one in the arts and archaeology library) resides in the Great Hall. It is traditional at exam time for students to leave offerings to the goddess with a note asking for good luck, or to repent for accidentally breaking any of the college's numerous other traditions. Pallas Athena is the tutelary goddess of the international social fraternity Phi Delta Theta. Her owl is also a symbol of the fraternity.




</doc>
<doc id="1183" url="https://en.wikipedia.org/wiki?curid=1183" title="Amber Diceless Roleplaying Game">
Amber Diceless Roleplaying Game

The Amber Diceless Roleplaying Game is a role-playing game created and written by Erick Wujcik, set in the fictional universe created by author Roger Zelazny for his "Chronicles of Amber". The game is unusual in that no dice are used in resolving conflicts or player actions; instead a simple diceless system of comparative ability, and narrative description of the action by the players and gamemaster, is used to determine how situations are resolved.

"Amber DRPG" was created in the 1980s, and is much more focused on relationships and roleplaying than most of the roleplaying games of that era. Most "Amber" characters are members of the two ruling classes in the "Amber" multiverse, and are much more advanced in matters of strength, endurance, psyche, warfare and sorcery than ordinary beings. This often means that the only individuals who are capable of opposing a character are from his or her family, a fact that leads to much suspicion and intrigue.

The original 256-page game book was published in 1991 by Phage Press, covering material from the first five novels (the "Corwin Cycle") and some details – sorcery and the Logrus – from the remaining five novels (the "Merlin Cycle"), in order to allow players to roleplay characters from the Courts of Chaos. Some details were changed slightly to allow more player choice – for example, players can be full Trump Artists without having walked the Pattern or the Logrus, which Merlin says is impossible; and players' psychic abilities are far greater than those shown in the books.
A 256-page companion volume, "Shadow Knight", was published in 1993. This supplemental rule book includes the remaining elements from the Merlin novels, such as Broken Patterns, and allows players to create Constructs such as Merlin's Ghostwheel. The book presents the second series of novels not as additions to the series' continuity but as an example of a roleplaying campaign with Merlin, Luke, Julia, Jurt and Coral as the PCs. The remainder of the book is a collection of essays on the game, statistics for the new characters and an update of the older ones in light of their appearance in the second series, and (perhaps most usefully for GMs) plot summaries of each of the ten books. The book includes some material from the short story "The Salesman's Tale," and some unpublished material cut from "Prince of Chaos", notably Coral's pregnancy by Merlin.

Both books were translated into French and published by Jeux Descartes in 1994 and 1995.

A third book, "Rebma", was promised. Cover art was commissioned and pre-orders were taken, but it never arrived. Wujcik also expressed a desire to create a book giving greater detail to the Courts of Chaos. The publishing rights to the "Amber DRPG" games were acquired in 2004 by Guardians of Order, who took over sales of the game and announced their intention to release a new edition of the game. However, no new edition was released before Guardians of Order went out of business in 2006. The two existing books are now out-of-print, but they have been made available as PDF downloads.

In June 2007 a new publishing company, headed by Edwin Voskamp and Eric Todd, was formed with the express purpose of bringing "Amber DRPG" back into print. The new company is named "Diceless by Design".

In May 2010, "Rite Publishing" secured a license from Diceless by Design to use the rules system with a new setting in the creation of a new product to be written by industry and system veteran Jason Durall. The project Lords of Gossamer & Shadow (Diceless) was funded via Kickstarter in May 2013. In Sept 2013 the project was completed, and on in Nov 2013 Lords of Gossamer and Shadow (Diceless) was released publicly in full-color Print and PDF, along with additional supplements and continued support.

The game is set in the multiverse described in Zelazny's "Chronicles of Amber". The first book assumes that gamemasters will set their campaigns after the Patternfall war; that is, after the end of the fifth book in the series, "The Courts of Chaos", but uses material from the following books to describe those parts of Zelazny's cosmology that were featured there in more detail. The "Amber" multiverse consists of Amber, a city at one pole of the universe wherein is found the Pattern, the symbol of Order; The Courts of Chaos, an assembly of worlds at the other pole where can be found the Logrus, the manifestation of Chaos, and the Abyss, the source or end of all reality; and Shadow, the collection of all possible universes (shadows) between and around them. Inhabitants of either pole can use one or both of the Pattern and the Logrus to travel through Shadow.

It is assumed that players will portray the children of the main characters from the books – the ruling family of Amber, known as the Elder Amberites – or a resident of the Courts. However, since some feel that being the children of the main characters is too limiting, it is fairly common to either start with King Oberon's death "before" the book begins and roleplay the Elder Amberites as they vie for the throne; or to populate Amber from scratch with a different set of Elder Amberites. The former option is one presented in the book; the latter is known in the Amber community as an "Amethyst" game. A third option is to have the players portray Corwin's children, in an Amber-like city built around Corwin's pattern; this is sometimes called an "Argent" game, since one of Corwin's heraldic colours is Silver.

Characters in "Amber DRPG" are represented by four attributes: "Psyche", "Strength", "Endurance" and "Warfare".
The attributes run from −25 (normal human level), through −10 (normal level for a denizen of the Courts of Chaos) and 0 (normal level for an inhabitant of Amber), upwards without limit. Scores above 0 are "ranked", with the highest score being ranked 1st, the next-highest 2nd, and so on. The character with 1st rank in each attribute is considered "superior" in that attribute, being considered to be substantially better than the character with 2nd rank even if the difference in scores is small. All else being equal, a character with a higher rank in an attribute will always win a contest based on that attribute.

A character's ability scores are purchased during character creation in an auction; players get 100 character points, and bid on each attribute in turn. The character who bids the most for an attribute is "ranked" first and is considered superior to all other characters in that attribute. Unlike conventional auctions, bids are non-refundable; if one player bids 65 for psyche and another wins with a bid of 66, then the character with 66 is "superior" to the character with 65 even though there is only one bid difference. Instead, lower bidding characters are ranked in ascending order according to how much they have bid, the characters becoming progressively weaker in that attribute as they pay less for it. After the auction, players can secretly pay extra points to raise their ranks, but they can only pay to raise their scores to an existing rank. Further, a character with a bid-for rank is considered to have a slight advantage over character with a bought-up rank.

The Auction simulates a 'history' of competition between the descendants of Oberon for player characters who have not had dozens of decades to get to know each other. Through the competitive Auction, characters may begin the game vying for standings. The auction serves to introduce some unpredictability into character creation without the need to resort to dice, cards, or other randomizing devices. A player may intend, for example, to create a character who is a strong, mighty warrior, but being "outplayed" in the auction may result in lower attribute scores than anticipated, therefore necessitating a change of character concept. Since a player cannot control another player's bids, and since all bids are non-refundable, the auction involves a considerable amount of strategizing and prioritization by players. A willingness to spend as many points as possible on an attribute may improve your chances of a high ranking, but too reckless a spending strategy could leave a player with few points to spend on powers and objects. In a hotly contested auction, such as for the important attribute of warfare, the most valuable skill is the ability to force one's opponents to back down. With two or more equally determined players, this can result in a "bidding war" where the attribute is driven up by increments to large sums. An alternative strategy is to try to cow other players into submission with a high opening bid. Most players bid low amounts between one and ten points in an initial bid in order to feel out the competition and to save points for other uses. A high enough opening bid could signal a player's determination to be first ranked in that attribute, thereby dissuading others from competing.

Characters with high psyche are presented as having strong telepathic abilities, being able to hypnotise and even mentally dominate any character with lesser psyche with whom they can make eye-contact. This is likely due to three scenes in the "Chronicles": first, when Eric paralyzes Corwin with an attack across the Trump and refuses to desist because one or the other would be dominated; second, when Corwin faces the demon Strygalldwir, it is able to wrestle mentally with him when their gazes meet; and third, when Fiona is able to keep Brand immobile in the final battle at the Courts of Chaos. However, in general, the books only feature mental battles when there is some reason for mind-to-mind contact (for example, Trump contact) and magic or Trump is involved in all three of the above conflicts, so it is not clear whether Zelazny intended his characters to have such a power; the combination of Brand's "living trump" powers and his high Psyche (as presented in the roleplaying game) would have guaranteed him victory over Corwin. "Shadow Knight" does address this inconsistency somewhat, by presenting the "living trump" abilities as somewhat limited.

Characters in "Amber DRPG" have access to the powers seen in the "Chronicles of Amber": "Pattern", "Logrus", "Shape-shifting", "Trump", and "magic".


Each of the first four powers is available in an advanced form.

While a character with Pattern, Logrus or Conjuration can acquire virtually any object, players can choose to spend character points to obtain objects with particular virtues – unbreakability, or a mind of their own. Since they have paid points for the items, they are a part of the character's legend, and cannot lightly be destroyed. Similarly, a character can find any possible universe, but they can spend character points to know of or inhabit shadows which are (in some sense) "real" and therefore useful. The expansion, "Shadow Knight", adds Constructs – artifacts with connections to shadows.

Unspent character points become good stuff – a good luck for the character. Players are also allowed to overspend (in moderation), with the points becoming bad stuff – bad luck which the Gamemaster should inflict on the character. Stuff governs how non-player characters perceive and respond to the character: characters with good stuff will often receive friendly or helpful reactions, while characters with bad stuff are often treated with suspicion or hostility.

As well as representing luck, stuff can be seen as representing a character's outlook on the universe: characters with good stuff seeing the multiverse as a cheerful place, while characters with bad stuff see it as hostile.

In any given fair conflict between two characters, the character with the higher score in the relevant attribute will eventually win. The key words here are "fair" and "eventually" – if characters' ranks are close, and the weaker character has obtained some advantage, then the weaker character can escape defeat or perhaps prevail. Close ranks result in longer contests while greater difference between ranks result in fast resolution. Alternatively, if characters' attribute ranks are close, the weaker character can try to change the relevant attribute by changing the nature of the conflict. For example, if two characters are wrestling the relevant attribute is Strength; a character could reveal a weapon, changing it to Warfare; they could try to overcome the other character's mind using a power, changing it to Psyche; or they could concentrate their strength on defense, changing it to Endurance. If there is a substantial difference between characters' ranks, the conflict is generally over before the weaker character can react.

"Amber DRPG" advises gamemasters to change rules as they see fit – even to the point of adding or removing powers or attributes.

Despite the game's out-of-print status, a thriving convention scene exists supporting the game. Amber conventions, known as "Ambercons", are held yearly in Massachusetts, Michigan, Portland (United States), Milton Keynes (England), Belfast (Northern Ireland) and Modena, Italy. Additionally, Phage Press published 12 volumes of a dedicated "Amber DRPG" magazine called "Amberzine". Some "Amberzine" issues are still available from Phage Press.




</doc>
<doc id="1184" url="https://en.wikipedia.org/wiki?curid=1184" title="Athene (disambiguation)">
Athene (disambiguation)

Athene or Athena is the shrewd companion of heroes and the goddess of heroic endeavour in Greek mythology.

Athene may also refer to:




</doc>
<doc id="1187" url="https://en.wikipedia.org/wiki?curid=1187" title="Alloy">
Alloy

An alloy is a combination of metals or a combination of one or more metals with other non-metallic elements. For example, combining the metallic elements gold and copper produces red gold, gold and silver becomes white gold, and silver combined with copper produces sterling silver. Elemental iron, combined with non-metallic carbon or silicon, produces alloys called steel or silicon steel. The resulting mixture forms a substance with properties that often differ from those of the pure metals, such as increased strength or hardness. Unlike other substances that may contain metallic bases but do not behave as metals, such as aluminium oxide (sapphire), beryllium aluminium silicate (emerald) or sodium chloride (salt), an alloy will retain all the properties of a metal in the resulting material, such as electrical conductivity, ductility, opaqueness, and luster. Alloys are used in a wide variety of applications, from the steel alloys, used in everything from buildings to automobiles to surgical tools, to exotic titanium-alloys used in the aerospace industry, to beryllium-copper alloys for non-sparking tools. In some cases, a combination of metals may reduce the overall cost of the material while preserving important properties. In other cases, the combination of metals imparts synergistic properties to the constituent metal elements such as corrosion resistance or mechanical strength. Examples of alloys are steel, solder, brass, pewter, duralumin, bronze and amalgams.

An alloy may be a solid solution of metal elements (a single phase, where all metallic grains (crystals) are of the same composition) or a mixture of metallic phases (two or more solutions, forming a microstructure of different crystals within the metal). Intermetallic compounds are alloys with a defined stoichiometry and crystal structure. Zintl phases are also sometimes considered alloys depending on bond types (see also: Van Arkel–Ketelaar triangle for information on classifying bonding in binary compounds).

Alloys are defined by a metallic bonding character. The alloy constituents are usually measured by mass percentage for practical applications, and in atomic fraction for basic science studies. Alloys are usually classified as substitutional or interstitial alloys, depending on the atomic arrangement that forms the alloy. They can be further classified as homogeneous (consisting of a single phase), or heterogeneous (consisting of two or more phases) or intermetallic.

An alloy is a mixture of chemical elements, which forms an impure substance (admixture) that retains the characteristics of a metal. An alloy is distinct from an impure metal in that, with an alloy, t primary metal or the base metal, and the name of this metal may also be the name of the alloy. The other constituents may or may not be metals but, when mixed with the molten base, they will be soluble and dissolve into the mixture.
The mechanical properties of alloys will often be quite different from those of its individual constituents. A metal that is normally very soft (malleable), such as aluminium, can be altered by alloying it with another soft metal, such as copper. Although both metals are very soft and ductile, the resulting aluminium alloy will have much greater strength. Adding a small amount of non-metallic carbon to iron trades its great ductility for the greater strength of an alloy called steel. Due to its very-high strength, but still substantial toughness, and its ability to be greatly altered by heat treatment, steel is one of the most useful and common alloys in modern use. By adding chromium to steel, its resistance to corrosion can be enhanced, creating stainless steel, while adding silicon will alter its electrical characteristics, producing silicon steel.

Like oil and water, a molten metal may not always mix with another element. For example, pure iron is almost completely insoluble with copper. Even when the constituents are soluble, each will usually have a saturation point, beyond which no more of the constituent can be added. Iron, for example, can hold a maximum of 6.67% carbon. Although the elements of an alloy usually must be soluble in the liquid state, they may not always be soluble in the solid state. If the metals remain soluble when solid, the alloy forms a solid solution, becoming a homogeneous structure consisting of identical crystals, called a phase. If as the mixture cools the constituents become insoluble, they may separate to form two or more different types of crystals, creating a heterogeneous microstructure of different phases, some with more of one constituent than the other phase has. However, in other alloys, the insoluble elements may not separate until after crystallization occurs. If cooled very quickly, they first crystallize as a homogeneous phase, but they are supersaturated with the secondary constituents. As time passes, the atoms of these supersaturated alloys can separate from the crystal lattice, becoming more stable, and form a second phase that serve to reinforce the crystals internally.

Some alloys, such as electrum which is an alloy consisting of silver and gold, occur naturally. Meteorites are sometimes made of naturally occurring alloys of iron and nickel, but are not native to the Earth. One of the first alloys made by humans was bronze, which is a mixture of the metals tin and copper. Bronze was an extremely useful alloy to the ancients, because it is much stronger and harder than either of its components. Steel was another common alloy. However, in ancient times, it could only be created as an accidental byproduct from the heating of iron ore in fires (smelting) during the manufacture of iron. Other ancient alloys include pewter, brass and pig iron. In the modern age, steel can be created in many forms. Carbon steel can be made by varying only the carbon content, producing soft alloys like mild steel or hard alloys like spring steel. Alloy steels can be made by adding other elements, such as chromium, molybdenum, vanadium or nickel, resulting in alloys such as high-speed steel or tool steel. Small amounts of manganese are usually alloyed with most modern steels because of its ability to remove unwanted impurities, like phosphorus, sulfur and oxygen, which can have detrimental effects on the alloy. However, most alloys were not created until the 1900s, such as various aluminium, titanium, nickel, and magnesium alloys. Some modern superalloys, such as incoloy, inconel, and hastelloy, may consist of a multitude of different elements.

As a noun, the term alloy is used to describe a mixture of atoms in which the primary constituent is a metal. When used as a verb, the term refers to the act of mixing a metal with other elements. The primary metal is called the "base", the "matrix", or the "solvent". The secondary constituents are often called "solutes". If there is a mixture of only two types of atoms (not counting impurities) such as a copper-nickel alloy, then it is called a "binary alloy." If there are three types of atoms forming the mixture, such as iron, nickel and chromium, then it is called a "ternary alloy." An alloy with four constituents is a "quaternary alloy," while a five-part alloy is termed a "quinary alloy." Because the percentage of each constituent can be varied, with any mixture the entire range of possible variations is called a "system". In this respect, all of the various forms of an alloy containing only two constituents, like iron and carbon, is called a "binary system," while all of the alloy combinations possible with a ternary alloy, such as alloys of iron, carbon and chromium, is called a "ternary system".

Although an alloy is technically an impure metal, when referring to alloys, the term "impurities" usually denotes those elements which are not desired. Such impurities are introduced from the base metals and alloying elements, but are removed during processing. For instance, sulfur is a common impurity in steel. Sulfur combines readily with iron to form iron sulfide, which is very brittle, creating weak spots in the steel. Lithium, sodium and calcium are common impurities in aluminium alloys, which can have adverse effects on the structural integrity of castings. Conversely, otherwise pure-metals that simply contain unwanted impurities are often called "impure metals" and are not usually referred to as alloys. Oxygen, present in the air, readily combines with most metals to form metal oxides; especially at higher temperatures encountered during alloying. Great care is often taken during the alloying process to remove excess impurities, using fluxes, chemical additives, or other methods of extractive metallurgy.

In practice, some alloys are used so predominantly with respect to their base metals that the name of the primary constituent is also used as the name of the alloy. For example, 14 karat gold is an alloy of gold with other elements. Similarly, the silver used in jewelry and the aluminium used as a structural building material are also alloys.

The term "alloy" is sometimes used in everyday speech as a synonym for a particular alloy. For example, automobile wheels made of an aluminium alloy are commonly referred to as simply "alloy wheels", although in point of fact steels and most other metals in practical use are also alloys. Steel is such a common alloy that many items made from it, like wheels, barrels, or girders, are simply referred to by the name of the item, assuming it is made of steel. When made from other materials, they are typically specified as such, (i.e.: "bronze wheel", "plastic barrel", or "wood girder").

Alloying a metal is done by combining it with one or more other elements. The most common and oldest alloying process is performed by heating the base metal beyond its melting point and then dissolving the solutes into the molten liquid, which may be possible even if the melting point of the solute is far greater than that of the base. For example, in its liquid state, titanium is a very strong solvent capable of dissolving most metals and elements. In addition, it readily absorbs gases like oxygen and burns in the presence of nitrogen, increasing the chances of contamination from any contacting surface, thus requires vacuum induction-heating and special, water-cooled, copper crucibles in order to melt it. However, some metals and solutes, such as iron and carbon, have very high melting-points and were impossible for ancient people to melt. Thus, alloying (in particular, interstitial alloying) may also be performed with one or more constituents in a gaseous state, such as found in a blast furnace to make pig iron (liquid-gas), nitriding, carbonitriding or other forms of case hardening (solid-gas), or the cementation process used to make blister steel (solid-gas). It may also be done with one, more, or all of the constituents in the solid state, such as found in ancient methods of pattern welding (solid-solid), shear steel (solid-solid), or crucible steel production (solid-liquid), mixing the elements via solid-state diffusion.

By adding another element to a metal, differences in the size of the atoms create internal stresses in the lattice of the metallic crystals; stresses that often enhance its properties. For example, the combination of carbon with iron produces steel, which is stronger than iron, its primary element. The electrical and thermal conductivity of alloys is usually lower than that of the pure metals. The physical properties, such as density, reactivity, Young's modulus of an alloy may not differ greatly from those of its base element, but engineering properties such as tensile strength, ductility, and shear strength may be substantially different from those of the constituent materials. This is sometimes a result of the sizes of the atoms in the alloy, because larger atoms exert a compressive force on neighboring atoms, and smaller atoms exert a tensile force on their neighbors, helping the alloy resist deformation. Sometimes alloys may exhibit marked differences in behavior even when small amounts of one element are present. For example, impurities in semiconducting ferromagnetic alloys lead to different properties, as first predicted by White, Hogan, Suhl, Tian Abrie and Nakamura.
Some alloys are made by melting and mixing two or more metals. Bronze, an alloy of copper and tin, was the first alloy discovered, during the prehistoric period now known as the Bronze Age. It was harder than pure copper and originally used to make tools and weapons, but was later superseded by metals and alloys with better properties. In later times bronze has been used for ornaments, bells, statues, and bearings. Brass is an alloy made from copper and zinc.

Unlike pure metals, most alloys do not have a single melting point, but a melting range during which the material is a mixture of solid and liquid phases (a slush). The temperature at which melting begins is called the solidus, and the temperature when melting is just complete is called the liquidus. For many alloys there is a particular alloy proportion (in some cases more than one), called either a eutectic mixture or a peritectic composition, which gives the alloy a unique and low melting point, and no liquid/solid slush transition.

Alloying elements are added to a base metal, to induce hardness, toughness, ductility, or other desired properties. Most metals and alloys can be work hardened by creating defects in their crystal structure. These defects are created during plastic deformation by hammering, bending, extruding, etcetera, and are permanent unless the metal is recrystallized. Otherwise, some alloys can also have their properties altered by heat treatment. Nearly all metals can be softened by annealing, which recrystallizes the alloy and repairs the defects, but not as many can be hardened by controlled heating and cooling. Many alloys of aluminium, copper, magnesium, titanium, and nickel can be strengthened to some degree by some method of heat treatment, but few respond to this to the same degree as does steel.

The base metal iron of the iron-carbon alloy known as steel, undergoes a change in the arrangement (allotropy) of the atoms of its crystal matrix at a certain temperature (usually between and , depending on carbon content). This allows the smaller carbon atoms to enter the interstices of the iron crystal. When this diffusion happens, the carbon atoms are said to be in "solution" in the iron, forming a particular single, homogeneous, crystalline phase called austenite. If the steel is cooled slowly, the carbon can diffuse out of the iron and it will gradually revert to its low temperature allotrope. During slow cooling, the carbon atoms will no longer be as soluble with the iron, and will be forced to precipitate out of solution, nucleating into a more concentrated form of iron carbide (FeC) in the spaces between the pure iron crystals. The steel then becomes heterogeneous, as it is formed of two phases, the iron-carbon phase called cementite (or carbide), and pure iron ferrite. Such a heat treatment produces a steel that is rather soft. If the steel is cooled quickly, however, the carbon atoms will not have time to diffuse and precipitate out as carbide, but will be trapped within the iron crystals. When rapidly cooled, a diffusionless (martensite) transformation occurs, in which the carbon atoms become trapped in solution. This causes the iron crystals to deform as the crystal structure tries to change to its low temperature state, leaving those crystals very hard but much less ductile (more brittle).

While the high strength of steel results when diffusion and precipitation is prevented (forming martensite), most heat-treatable alloys are precipitation hardening alloys, that depend on the diffusion of alloying elements to achieve their strength. When heated to form a solution and then cooled quickly, these alloys become much softer than normal, during the diffusionless transformation, but then harden as they age. The solutes in these alloys will precipitate over time, forming intermetallic phases, which are difficult to discern from the base metal. Unlike steel, in which the solid solution separates into different crystal phases (carbide and ferrite), precipitation hardening alloys form different phases within the same crystal. These intermetallic alloys appear homogeneous in crystal structure, but tend to behave heterogeneously, becoming hard and somewhat brittle.

When a molten metal is mixed with another substance, there are two mechanisms that can cause an alloy to form, called "atom exchange" and the "interstitial mechanism". The relative size of each element in the mix plays a primary role in determining which mechanism will occur. When the atoms are relatively similar in size, the atom exchange method usually happens, where some of the atoms composing the metallic crystals are substituted with atoms of the other constituent. This is called a "substitutional alloy". Examples of substitutional alloys include bronze and brass, in which some of the copper atoms are substituted with either tin or zinc atoms respectively. In the case of the interstitial mechanism, one atom is usually much smaller than the other and can not successfully substitute for the other type of atom in the crystals of the base metal. Instead, the smaller atoms become trapped in the spaces between the atoms of the crystal matrix, called the "interstices". This is referred to as an "interstitial alloy". Steel is an example of an interstitial alloy, because the very small carbon atoms fit into interstices of the iron matrix. Stainless steel is an example of a combination of interstitial and substitutional alloys, because the carbon atoms fit into the interstices, but some of the iron atoms are substituted by nickel and chromium atoms.

The use of alloys by humans started with the use of meteoric iron, a naturally occurring alloy of nickel and iron. It is the main constituent of iron meteorites which occasionally fall down on Earth from outer space. As no metallurgic processes were used to separate iron from nickel, the alloy was used as it was. Meteoric iron could be forged from a red heat to make objects such as tools, weapons, and nails. In many cultures it was shaped by cold hammering into knives and arrowheads. They were often used as anvils. Meteoric iron was very rare and valuable, and difficult for ancient people to work.

Iron is usually found as iron ore on Earth, except for one deposit of native iron in Greenland, which was used by the Inuit people. Native copper, however, was found worldwide, along with silver, gold, and platinum, which were also used to make tools, jewelry, and other objects since Neolithic times. Copper was the hardest of these metals, and the most widely distributed. It became one of the most important metals to the ancients. Around 10,000 years ago in the highlands of Anatolia (Turkey}, humans learned to smelt metals such as copper and tin from ore. Around 2500 BC, people began alloying the two metals to form bronze, which was much harder than its ingredients. Tin was rare, however, being found mostly in Great Britain. In the Middle East, people began alloying copper with zinc to form brass. Ancient civilizations took into account the mixture and the various properties it produced, such as hardness, toughness and melting point, under various conditions of temperature and work hardening, developing much of the information contained in modern alloy phase diagrams. For example, arrowheads from the Chinese Qin dynasty (around 200 BC) were often constructed with a hard bronze-head, but a softer bronze-tang, combining the alloys to prevent both dulling and breaking during use.

Mercury has been smelted from cinnabar for thousands of years. Mercury dissolves many metals, such as gold, silver, and tin, to form amalgams (an alloy in a soft paste or liquid form at ambient temperature). Amalgams have been used since 200 BC in China for gilding objects such as armor and mirrors with precious metals. The ancient Romans often used mercury-tin amalgams for gilding their armor. The amalgam was applied as a paste and then heated until the mercury vaporized, leaving the gold, silver, or tin behind. Mercury was often used in mining, to extract precious metals like gold and silver from their ores.

Many ancient civilizations alloyed metals for purely aesthetic purposes. In ancient Egypt and Mycenae, gold was often alloyed with copper to produce red-gold, or iron to produce a bright burgundy-gold. Gold was often found alloyed with silver or other metals to produce various types of colored gold. These metals were also used to strengthen each other, for more practical purposes. Copper was often added to silver to make sterling silver, increasing its strength for use in dishes, silverware, and other practical items. Quite often, precious metals were alloyed with less valuable substances as a means to deceive buyers. Around 250 BC, Archimedes was commissioned by the King of Syracuse to find a way to check the purity of the gold in a crown, leading to the famous bath-house shouting of "Eureka!" upon the discovery of Archimedes' principle.

The term pewter covers a variety of alloys consisting primarily of tin. As a pure metal, tin is much too soft to be used for any practical purpose. However, during the Bronze Age, tin was a rare metal in many parts of Europe and the Mediterranean; due to this it was often valued higher than gold. To make jewellery, cutlery, or other objects from tin, it was usually alloyed with other metals to increase its strength and hardness. These metals were typically lead, antimony, bismuth or copper. These solutes were sometimes added individually in varying amounts, or added together, making a wide variety of objects, ranging from practical items such as dishes, surgical tools, candlesticks or funnels, to decorative items like ear rings and hair clips.

The earliest examples of pewter come from ancient Egypt, around 1450 BC. The use of pewter was widespread across Europe, from France to Norway and Britain (where most of the ancient tin was mined) to the Near East. The alloy was also used in China and the Far East, arriving in Japan around 800 AD, where it was used for making objects like ceremonial vessels, tea canisters, or chalices used in shinto shrines.

The first known smelting of iron began in Anatolia, around 1800 BC. Called the bloomery process, it produced very soft but ductile wrought iron. By 800 BC, iron-making technology had spread to Europe, arriving in Japan around 700 AD. Pig iron, a very hard but brittle alloy of iron and carbon, was being produced in China as early as 1200 BC, but did not arrive in Europe until the Middle Ages. Pig iron has a lower melting point than iron, and was used for making cast-iron. However, these metals found little practical use until the introduction of crucible steel around 300 BC. These steels were of poor quality, and the introduction of pattern welding, around the 1st century AD, sought to balance the extreme properties of the alloys by laminating them, to create a tougher metal. Around 700 AD, the Japanese began folding bloomery-steel and cast-iron in alternating layers to increase the strength of their swords, using clay fluxes to remove slag and impurities. This method of Japanese swordsmithing produced one of the purest steel-alloys of the ancient world.

While the use of iron started to become more widespread around 1200 BC, mainly because of interruptions in the trade routes for tin, the metal was much softer than bronze. However, very small amounts of steel, (an alloy of iron and around 1% carbon), was always a byproduct of the bloomery process. The ability to modify the hardness of steel by heat treatment had been known since 1100 BC, and the rare material was valued for the manufacture of tools and weapons. Because the ancients could not produce temperatures high enough to melt iron fully, the production of steel in decent quantities did not occur until the introduction of blister steel during the Middle Ages. This method introduced carbon by heating wrought iron in charcoal for long periods of time, but the absorption of carbon in this manner is extremely slow thus the penetration was not very deep, so the alloy was not homogeneous. In 1740, Benjamin Huntsman began melting blister steel in a crucible to even out the carbon content, creating the first process for the mass production of tool steel. Huntsman's process was used for manufacturing tool steel until the early 1900s.

With the introduction of the blast furnace to Europe in the Middle Ages, pig iron was able to be produced in much higher volumes than wrought iron. Because pig iron could be melted, people began to develop processes of reducing the carbon in the liquid pig iron to create steel. Puddling had been used in China since the first century, and was introduced in Europe during the 1700s, where molten pig iron was stirred while exposed to the air, to remove the carbon by oxidation. In 1858, Henry Bessemer developed a process of steel-making by blowing hot air through liquid pig iron to reduce the carbon content. The Bessemer process was able to produce the first large scale manufacture of steel.

Although steel is an alloy of iron and carbon, the term "alloy steel" usually only refers to those steels which contain other elements like vanadium, molybdenum, or cobalt in amounts sufficient to alter the properties of the base steel. Since ancient times when steel was used primarily for tools and weapons, the methods of producing and working the metal were often closely guarded secrets. Even long after the Age of reason, the steel industry was very competitive and manufacturers went through great lengths to keep their processes confidential, resisting any attempts to scientifically analyze the material for fear it would reveal their methods. For example, the people of Sheffield, a center of steel production in England, were known to routinely bar visitors and tourists from entering town to deter industrial espionage. Thus, almost no metallurgical information existed about steel until 1860. Because of this lack of understanding, steel was not generally considered an alloy until the decades between 1930 and 1970 (primarily due to the work of scientists like William Chandler Roberts-Austen, Adolph Martens, and Edgar Bain), so "alloy steel" became the popular term for ternary and quaternary steel-alloys.

After Benjamin Huntsman developed his crucible steel in 1740, he began experimenting with the addition of elements like manganese (in the form of a high-manganese pig-iron called "spiegeleisen"), which helped remove impurities such as phosphorus and oxygen; a process adopted by Bessemer and still used in modern steels (albeit in concentrations low enough to still be considered carbon steel). Afterward, many people began experimenting with various alloys of steel without much success. However, in 1882, Robert Hadfield, being a pioneer in steel metallurgy, took an interest and produced a steel alloy containing around 12% manganese. Called mangalloy, it exhibited extreme hardness and toughness, becoming the first commercially viable alloy-steel. Afterward, he created silicon steel, launching the search for other possible alloys of steel.

Robert Forester Mushet found that by adding tungsten to steel it could produce a very hard edge that would resist losing its hardness at high temperatures. "R. Mushet's special steel" (RMS) became the first high-speed steel. Mushet's steel was quickly replaced by tungsten carbide steel, developed by Taylor and White in 1900, in which they doubled the tungsten content and added small amounts of chromium and vanadium, producing a superior steel for use is lathes and machining tools. In 1903 the Wright brothers used a chromium-nickel steel to make the crankshaft for their airplane engine, while in 1908 Henry Ford began using vanadium steels for parts like crankshafts and valves in his Model T Ford, due to their higher strength and resistance to high temperatures. In 1912, the Krupp Ironworks in Germany developed a rust-resistant steel by adding 21% chromium and 7% nickel, producing the first stainless steel.

Nonferrous alloys are those which contain no appreciable amounts of iron. Although the first alloys, bronze and brass, were used for thousands of years, along with lead alloys, pewter and others, these were all made from metals that were fairly non-reactive and could be smelted over open flames. In the 18th century, Antoine Lavoisier helped to establish the oxygen theory of combustion, displacing the defunct phlogiston theory that had ruled since the late Middle Ages. The oxygen theory helped correctly explain the phenomenon of things like oxidation of metals (i.e.: rust) and how rocky ores transform into metals when heated. Lavoisier predicted that many of the earths, salts, and alkalis contained metallic bases that were too reactive to oxygen to be smelted in the usual methods; for example in alum, a salt that had been used since antiquity. His work eventually led to the periodic table of elements, which helped confirm the existence of these "missing metals."

Due to their high reactivity, most metals were not discovered until the 19th century. A method for extracting aluminium from bauxite was proposed by Humphry Davy in 1807, using an electric arc. Although his attempts were unsuccessful, by 1855 the first sales of pure aluminium reached the market. However, as extractive metallurgy was still in its infancy, most aluminium extraction-processes produced unintended alloys contaminated with other elements found in the ore; the most abundant of which was copper. These aluminium-copper alloys (at the time termed "aluminum bronze") preceded pure aluminium, offering greater strength and hardness over the soft, pure metal, and to a slight degree were found to be heat treatable. However, due to their softness and limited hardenability these alloys found little practical use, and were more of a novelty, until the Wright brothers used an aluminium alloy to construct the first airplane engine in 1903. During the time between 1865 and 1910, processes for extracting many other metals were discovered, such as chromium, vanadium, tungsten, iridium, cobalt, and molybdenum, and various alloys were developed.

Prior to 1910, research mainly consisted of private individuals tinkering in their own laboratories. However, as the aircraft and automotive industries began growing, research into alloys became an industrial effort in the years following 1910, as new magnesium alloys were developed for pistons and wheels in cars, and pot metal for levers and knobs, and aluminium alloys developed for airframes and aircraft skins were put into use.

In 1906, precipitation hardening alloys were discovered by Alfred Wilm. Precipitation hardening alloys, such as certain alloys of aluminium, titanium, and copper, are heat-treatable alloys that soften when quenched (cooled quickly), and then harden over time. Wilm had been searching for a way to harden aluminium alloys for use in machine-gun cartridge cases. Knowing that aluminium-copper alloys were heat-treatable to some degree, Wilm tried quenching a ternary alloy of aluminium, copper, and the addition of magnesium, but was initially disappointed with the results. However, when Wilm retested it the next day he discovered that the alloy increased in hardness when left to age at room temperature, and far exceeded his expectations. Although an explanation for the phenomenon was not provided until 1919, duralumin was one of the first "age hardening" alloys to be used, becoming the primary building material for the first Zeppelins, and was soon followed by many others. Because they often exhibit a combination of high strength and low weight, these alloys became widely used in many forms of industry, including the construction of modern aircraft.




</doc>
<doc id="1192" url="https://en.wikipedia.org/wiki?curid=1192" title="Artistic revolution">
Artistic revolution

Throughout history, forms of art have gone through periodic abrupt changes called artistic revolutions. Movements have come to an end to be replaced by a new movement markedly different in striking ways. See also cultural movements.

The role of fine art has been to simultaneously express values of the current culture while also offering criticism, balance, or alternatives to any such values that are proving no longer useful. So as times change, art changes. If changes were abrupt they were deemed revolutions. The best artists have predated society's changes due not to any prescience, but because sensitive perceptivity is part of their talent of seeing.

Artists who succeeded enough to portray visions that future generations could live to see, often had to navigate an often treacherous path between their own capacity to see and execute what lesser artists could not, while still appealing to powerful patrons who could finance their visions. For example, paintings glorified aristocracy in the early 17th century when leadership was needed to nationalize small political groupings, but later as leadership became oppressive, satirization increased and subjects were less concerned with leaders and more with more common plights of mankind.

No art owes quite as much to state power as French painting does. It was in the age of absolute monarchy launched by Louix XIV in the 17th century that the likes of Poussin and Le Brun put France in the forefront of European art. Versailles found its stately mirror in the powerful idea of classicism – a painting style, enduring in later artists like Ingres, whose austerity and grandeur express the authority of a world where Jove is very much in his throne.

Examples of revolutionary art in conjunction with cultural and political movements:


Here is an example of an Artistic Revolution Pieces

Not all artistic revolutions were political. Sometimes, science and technological innovations have brought about unforeseen transformations in the works of artists. The stylistic revolution known as Impressionism, by painters eager to more accurately capture the changing colors of light and shadow, is inseparable from discoveries and inventions in the mid-19th century in which the style was born.

Eugene Chevreul, a French chemist hired as director of dyes at a French tapestry works, began to investigate the optical nature of color in order to improve color in fabrics. Chevreul realized It was the eye, and not the dye, that had the greatest influence on color, and from this, he revolutionized color theory by grasping what came to be called the law of simultaneous contrast: that colors mutually influence one another when juxtaposed, each imposing its own complementary color on the other. The French painter Eugène Delacroix, who had been experimenting with what he called broken tones, embraced Chevreul's book, "The Law of Contrast of Color (1839) with its explanations of how juxtaposed colors can enhance or diminish each other, and his exploration of all the visible colors of the spectrum. Inspired by Chevreul’s 1839 treatise, Delacroix passed his enthusiasm on to the young artists who were inspired by him. It was Chevreul who led the Impressionists to grasp that they should apply separate brushstrokes of pure color to a canvas and allow the viewer’s eye to combine them optically.

They were aided greatly in this by innovations in oil paint itself. Since the Renaissance, painters had to grind pigment, add oil and thus create their own paints; these time-consuming paints also quickly dried out, making studio painting a necessity for large works, and limiting painters to mix one or two colors at a time and fill in an entire area using just that one color before it dried out. in 1841, a little-known American painter named John G. Rand invented a simple improvement without which the Impressionist movement could not have occurred: the small, flexible tin tube with removable cap in which oil paints could be stored. Oil paints kept in such tubes stayed moist and usable -- and quite portable. For the first time since the Renaissance, painters were not trapped by the time frame of how quickly oil paint dried.

Paints in tubes could be easily loaded up and carried out into the real world, to directly observe the play of color and natural light, in shadow and movement, to paint in the moment. Selling the oil paint in tubes also brought about the arrival of dazzling new pigments - chrome yellow, cadmium blue - invented by 19th century industrial chemists. The tubes freed the Impressionists to paint quickly, and across an entire canvas, rather than carefully delineated single-color sections at a time; in short, to sketch directly in oil - racing across the canvas in every color that came to hand and thus inspiring their name of "impressionists" - since such speedy, bold brushwork and dabs of separate colors made contemporary critics think their paintings were mere impressions, not finished paintings, which were to have no visible brush marks at all, seamless under layers of varnish.

Pierre-Auguste Renoir said, “Without colors in tubes, there would be no Cézanne, no Monet, no Pissarro, and no Impressionism.”

Finally, the careful, hyper-realistic techniques of French neo-classicism were seen as stiff and lifeless when compared to the remarkable new vision of the world as seen through the new invention of photography by the mid-1850s. It was not merely that the increasing ability of this new invention, particularly by the French inventor Daguerre, made the realism of the painted image redundant as he deliberately competed in the Paris diorama with large-scale historical paintings. The neo-classical subject matter, limited by Academic tradition to Greek and Roman legends, historical battles and Biblical stories, seemed oppressively cliched and limited to artists eager to explore the actual world in front of their own eyes revealed by the camera - daily life, candid groupings of everyday people doing simple things, Paris itself, rural landscapes and most particularly the play of captured light - not the imaginary lionizing of unseen past events. Early photographs influenced Impressionist style by its use of asymmetry, cropping and most obviously the blurring of motion, as inadvertently captured in the very slow speeds of early photography.

Their initial break with realism into an exploration of light, color and the nature of paint was brought to an ultimate conclusion by the Abstract Expressionists who broke away from recognizable content of any kind into works of pure shape, color and painterliness which emerged at the end of the second world war. At first thought of as primitive, inept works - as in "my four year old could do that"—these works were misunderstood and neglected until given critical and support by the rise of art journalists and critics who championed their work in the 1940s and 50's, expressing the power of such work in aesthetic terms the artists themselves seldom used, or even understood. Jackson Pollock who pioneered splatter painting, dispensing with a paint brush altogether, soon became lionized as the angry young man in a large spread in Life Magazine.

In fact, in a deliberate, secret and successful effort to separate artistic revolutions from political ones, abstract expressionists like Pollack, Robert Motherwell, Willem de Kooning and Mark Rothko, while seemingly difficult, pathbreaking artists, were in fact secretly supported for twenty years by the C.I.A. in a Cold War policy begun in 1947 to prove that the United States could foster more artistic freedom than the Soviet bloc. "It was recognized that Abstract Expressionism was the kind of art that made Socialist Realism look even more stylized and rigid and confined than it was, " said former C.I.A. case worker Donald Jameson, who finally broke the silence on this program in 1995. Ironically, the covert C.I.A. support for these radical works was required because an attempt to use government funds for a European tour of these works during the Truman administration led to a public uproar in conservative McCarthy-era America, with Truman famously remarking, "If that's art, I'm a Hottentot." Thus the program was hidden under the guise of fabricated foundations and the support of wealthy patrons who were actually using C.I.A. funds, not their own, to sponsor traveling exhibitions of American abstract expressionists all over the world, publish books and articles praising them and to purchase and exhibit Abstract Expressionist works in major American and British museums. Thomas Braden, in charge of these cultural programs for the C.I.A.. in the early years of the Cold War, had formerly been executive secretary of the Museum of Modern Art, America's leading institution for 20th Century art and the charges of collusion between the two echoed for many years after this program was revealed, though most of the artists involved had no idea they were being used in this way and were furious when they found out.

Key dates: 15000 BCE / 400 BCE-200CE / 350 CE-450CE
Ancient - There are few remaining examples with early art often favouring drawing over colour. Work has been found recently in tombs, Egyptian frescoes, pottery and metalwork.
Classical - Relating to or from ancient Roman or Greek architecture and art. Mainly concerned with geometry and symmetry rather than individual expression.
Byzantine - A religious art characterised by large domes, rounded arches and mosaics from the eastern Roman Empire in the 4th Century.

Key dates: 400CE
Medieval - A highly religious art beginning in the 5th Century in Western Europe. It was characterised by iconographic paintings illustrating scenes from the bible.
Gothic - This style prevailed between the 12th century and the 16th century in Europe. Mainly an architectural movement, Gothic was characterised by its detailed ornamentation most noticeably the pointed archways and elaborate rib vaulting.
First developed in France, Gothic was intended as a solution to the inadequacies of Romanesque architecture. It allowed for cathedrals to be built with thinner walls and it became possible to introduce stained glass windows instead of traditional mosaic decorations. Some of the finest examples of the style include the cathedrals of Chartres, Reims and Amiens. The term was also used to describe sculpture and painting that demonstrated a greater degree of naturalism.

Key dates: 14th century
This movement began in Italy in the 14th century and the term, literally meaning rebirth, describes the revival of interest in the artistic achievements of the Classical world. Initially in a literary revival Renaissance was determined to move away from the religion-dominated Middle Ages and to turn its attention to the plight of the individual man in society. It was a time when individual expression and worldly experience became two of the main themes of Renaissance art. The movement owed a lot to the increasing sophistication of society, characterised by political stability, economic growth and cosmopolitanism. Education blossomed at this time, with libraries and academies allowing more thorough research to be conducted into the culture of the antique world. In addition, the arts benefited from the patronage of such influential groups as the Medici family of Florence, the Sforza family of Milan and Popes Julius II and Leo X. The works of Petrarch first displayed the new interest in the intellectual values of the Classical world in the early 14th century and the romance of this era as rediscovered in the Renaissance period can be seen expressed by Boccaccio. Leonardo da Vinci was the archetypal Renaissance man representing the humanistic values of the period in his art, science and writing. Michelangelo and Raphael were also vital figures in this movement, producing works regarded for centuries as embodying the classical notion of perfection. Renaissance architects included Alberti, Brunelleschi and Bramante. Many of these artists came from Florence and it remained an important centre for the Renaissance into the 16th century eventually to be overtaken by Rome and Venice. Some of the ideas of the Italian Renaissance did spread to other parts of Europe, for example to the German artist Albrecht Dürer of the 'Northern Renaissance'. But by the 16th century Mannerism had overtaken the Renaissance and it was this style that caught on in Europe. 
Representative artists:
Leonardo da Vinci, Sandro Botticelli, Filippo Brunelleschi, Raphael da Urbino, Titian, Michelangelo Buonarroti, and Donatello Bardi.

Key dates: 1520-1600
Artists of the Early Renaissance and the High Renaissance developed their characteristic styles from the observation of nature and the formulation of a pictorial science. When Mannerism matured after 1520(The year Raphael died), all the representational problems had been solved. A body of knowledge was there to be learned. Instead of nature as their teacher, Mannerist artists took art. While Renaissance artists sought nature to find their style, the Mannerists looked first for a style and found a manner. In Mannerist paintings, compositions can have no focal point, space can be ambiguous, figures can be characterized by an athletic bending and twisting with distortions, exaggerations, an elastic elongation of the limbs, bizarre posturing on one hand, graceful posturing on the other hand, and a rendering of the heads as uniformly small and oval. The composition is jammed by clashing colors, which is unlike what we've seen in the balanced, natural, and dramatic colors of the High Renaissance. Mannerist artwork seeks instability and restlessness. There is also a fondness for allegories that have lascivious undertones. 
Representative artists:
Andrea del Sarto, Jacopo da Pontormo, Correggio

Key dates: 17th century
Baroque Art emerged in Europe around 1600, as a reaction against the intricate and formulaic Mannerist style which dominated the Late Renaissance. Baroque Art is less complex, more realistic and more emotionally affecting than Mannerism.
This movement was encouraged by the Catholic Church, the most important patron of the arts at that time, as a return to tradition and spirituality.
One of the great periods of art history, Baroque Art was developed by Caravaggio, Annibale Carracci, and Gianlorenzo Bernini, among others. This was also the age of Rubens, Rembrandt, Velázquez, and Vermeer.
In the 18th century, Baroque Art was replaced by the more elegant and elaborate Rococo style.
Representative artists:
Caravaggio, Annibale Carracci, Gianlorenzo Bernini, Rubens, Rembrandt, Nicolas Poussin

Key dates: 18th century
Throughout the 18th century in France, a new wealthy and influential middle-class was beginning to rise, even though the royalty and nobility continued to be patrons of the arts. Upon the death of Louis XIV and the abandonment of Versailles, the Paris high society became the purveyors of style. This style, primarily used in interior decoration, came to be called Rococo. The term Rococo was derived from the French word "rocaille", which means pebbles and refers to the stones and shells used to decorate the interiors of caves. Therefore, shell forms became the principal motif in Rococo. The society women competed for the best and most elaborate decorations for their houses. Hence the Rococo style was highly dominated by the feminine taste and influence.
François Boucher was the 18th century painter and engraver whose works are regarded as the perfect expression of French taste in the Rococo period. Trained by his father who was a lace designer, Boucher won fame with his sensuous and light-hearted mythological paintings and landscapes. He executed important works for both the Queen of France and Mme. de Pompadour, Louis XV's mistress, who was considered the most powerful woman in France at the time. Boucher was Mme. de Pompadour's favorite artist and was commissioned by her for numerous paintings and decorations. Boucher also became the principal designer for the royal porcelain factory and the director of the Gobelins tapestry factory. The Vulcan Presenting Venus with Arms for Aeneas is a template for a tapestry made by this factory. 
Characterized by elegant and refined yet playful subject matters, Boucher's style became the epitome of the court of Louis XV. His style consisted of delicate colors and gentle forms painted within a frivolous subject matter. His works typically utilized delightful and decorative designs to illustrate graceful stories with Arcadian shepherds, goddesses and cupids playing against a pink and blue sky. These works mirrored the frolicsome, artificial and ornamented decadence of the French aristocracy of the time.
The Rococo is sometimes considered a final phase of the Baroque period.
Representative artists:
François Boucher, William Hogarth, Giovanni Battista Tiepolo, Angelica Kauffman, Giovanni Antonio Canaletto, Velázquez Vermeer

Key dates: 1750-1880
A nineteenth-century French art style and movement that originated as a reaction to the Baroque. It sought to revive the ideals of ancient Greek and Roman art. Neoclassic artists used classical forms to express their ideas about courage, sacrifice, and love of country. David and Canova are examples of neo-classicists.
Representative artists:
Jacques-Louis David, Sir Henry Raeburn, Sir Joshua Reynolds, Jean-Auguste-Dominique Ingres, Thomas Gainsborough, Antonio Canova, Arnold Bocklin

Key dates: 1800-1880
Romanticism was basically a reaction against Neoclassicism, it is a deeply felt style which is individualistic, beautiful, exotic, and emotionally wrought.
Although Romanticism and Neoclassicism were philosophically opposed, they were the dominant European styles for generations, and many artists were affected to a greater or lesser degree by both. Artists might work in both styles at different times or even mix the styles, creating an intellectually Romantic work using a Neoclassical visual style, for example.
Great artists closely associated with Romanticism include J.M.W. Turner, Caspar David Friedrich, John Constable, and William Blake.
In the United States, the leading Romantic movement was the Hudson River School of dramatic landscape painting.
Obvious successors of Romanticism include the Pre-Raphaelite movement and the Symbolists. But Impressionism, and through it almost all of 20th-century art, is also firmly rooted in the Romantic tradition. 
Representative artists:
George Stubbs, William Blake, John Martin, Francisco Goya, Sir Thomas Lawrence, John Constable, Eugène Delacroix, Sir Edwin landseer, Caspar David Friedrich, JMW Turner


</doc>
<doc id="1193" url="https://en.wikipedia.org/wiki?curid=1193" title="Agrarianism">
Agrarianism

Agrarianism is a social philosophy or political philosophy which values rural society as superior to urban society and the independent farmer as superior to the paid worker, and sees farming as a way of life that can shape the ideal social values. It stresses the superiority of a simpler rural life as opposed to the complexity of city life.

M. Thomas Inge defines agrarianism by the following basic tenets:

The philosophical roots of agrarianism include European and Chinese philosophers. The Chinese school of Agriculturalism (农家/農家) was a philosophy that advocated peasant utopian communalism and egalitarianism. In societies influenced by Confucianism, the farmer was considered an esteemed productive member of society, but merchants who made money were looked down upon. That influenced European intellectuals like François Quesnay, an avid Confucianist and advocate of China's agrarian policies, in forming the French agrarian philosophy of physiocracy. The physiocrats, along with the ideas of John Locke and the Romantic Era, formed the basis of modern European and American agrarianism.

United States president (1801–1809) Thomas Jefferson was a representative agrarian who built Jeffersonian democracy around the notion that farmers are “the most valuable citizens” and the truest republicans.

Peasant parties first appeared across Eastern Europe between 1860 and 1910, when commercialized agriculture and world market forces disrupted traditional rural society, and the railway and growing literacy facilitated the work of roving organizers. Agrarian parties advocated land reforms to redistribute land on large estates among those who work it. They also wanted village cooperatives to keep the profit from crop sales in local hands and credit institutions to underwrite needed improvements. Many peasant parties were also nationalist parties because peasants often worked their land for the benefit of landlords of different ethnicity.

Peasant parties rarely had any power before World War I but some became influential in the interwar era, especially in Bulgaria and Czechoslovakia. For a while, in the 1920s and the 1930s, there was a Green International (International Agrarian Bureau) based on the peasant parties in Bulgaria, Czechoslovakia, Poland, and Serbia. It functioned primarily as an information center that spread the ideas of agrarianism and combating socialism on the left and landlords on the right and never launched any significant activities.

The Farmers' Voice Party won a seat in the district of Jendouba after the parliamentary election of 2014.

In Bulgaria, the Bulgarian Agrarian National Union (BZNS) was organized in 1899 to resist taxes and build cooperatives. BZNS came to power in 1919 and introduced many economic, social, and legal reforms. However, conservative forces crushed BZNS in a 1923 coup and assassinated its leader, Aleksandar Stamboliyski (1879–1923). BZNS was made into a communist puppet group until 1989, when it reorganized as a genuine party.

In Czechoslovakia, the Republican Party of Agricultural and Smallholder People often shared power in parliament as a partner in the five-party pětka coalition. The party's leader, Antonin Svehla (1873–1933), was prime minister several times. It was consistently the strongest party, forming and dominating coalitions. It moved beyond its original agrarian base to reach middle-class voters. The party was banned by the National Front after the Second World War.

In France, the Hunting, Fishing, Nature, Tradition party is a moderate conservative, agrarianist party, reaching a peak of 4.23% in the 2002 French presidential election. It would later on become affiliated to France's main conservative party, Union for a Popular Movement.

In the late 19th century, the Irish National Land League aimed to abolish landlordism in Ireland and enable tenant farmers to own the land they worked on. The "Land War" of 1878–1909 led to the Irish Land Acts, ending absentee landlords and ground rent and redistributing land among peasant farmers.

Post-independence, the Farmers' Party operated in the Irish Free State from 1922, folding into the National Centre Party in 1932. It was mostly supported by wealthy farmers in the east of Ireland.

Clann na Talmhan (Family of the Land; also called the "National Agricultural Party") was founded in 1938. They focused more on the poor smallholders of the west, supporting land reclamation, afforestation, social democracy and rates reform. They formed part of the governing coalition of the Government of the 13th Dáil and Government of the 15th Dáil. Economic improvement in the 1960s saw farmers vote for other parties and Clann na Talmhan disbanded in 1965.

In Latvia, the Union of Greens and Farmers is supportive of traditional small farms and perceives them as more environmentally friendly than large-scale farming: Nature is threatened by development, while small farms are threatened by large industrial-scale farms.

In Lithuania, as of 2017, the government is led by the Lithuanian Farmers and Greens Union, under the leadership of industrial farmer Ramūnas Karbauskis.

In Poland, the Polish People's Party traces its tradition to an agrarian party in Austro-Hungarian-controlled Galician Poland. After the fall of the communist regime, PPP's biggest success came in 1993 elections, where it won 132 out of 460 parliamentary seats. Since then, PPP's support has steadily declined.

In Romania, older parties from Transylvania, Moldavia, and Wallachia merged to become the National Peasants' Party in 1926. Iuliu Maniu (1873–1953) was a prime minister with an agrarian cabinet from 1928–1930 and briefly in 1932–1933, but the Great Depression made proposed reforms impossible. The communist regime dissolved the party in 1947, but it reformed in 1989 after they fell from power.

The reformed party, which also incorporated elements of Christian democracy in its ideology, governed Romania as part of the Romanian Democratic Convention between 1996–2000.

In Serbia, Nikola Pašić (1845–1926) and his People's Radical Party dominated Serbian politics after 1903. The party also monopolized power in Yugoslavia from 1918 to 1929. During the dictatorship of the 1930s, the prime minister was from that party.

In Ukraine, the Radical Party of Oleh Lyashko has promised to purify the country of oligarchs "with a pitchfork". The party advocates a number of traditional left-wing positions (lower salary taxes, a ban on agricultural land sale and eliminating the illegal land market, a tenfold increase in budget spending on health, setting up primary health centres in every village
), and mixes them with strong nationalist sentiments.

Historian F.K. Crowley finds that:

The National Party of Australia (formerly called the Country Party), from the 1920s to the 1970s, promulgated its version of agrarianism, which it called "countrymindedness". The goal was to enhance the status of the graziers (operators of big sheep ranches) and small farmers and justified subsidies for them.

The New Zealand Liberal Party aggressively promoted agrarianism in its heyday (1891–1912). The landed gentry and aristocracy ruled Britain at this time. New Zealand never had an aristocracy but its wealthy landowners largely controlled politics before 1891. The Liberal Party set out to change that by a policy it called "populism." Richard Seddon had proclaimed the goal as early as 1884: "It is the rich and the poor; it is the wealthy and the landowners against the middle and labouring classes. That, Sir, shows the real political position of New Zealand." The Liberal strategy was to create a large class of small landowning farmers who supported Liberal ideals. The Liberal government also established the basis of the later welfare state such as old age pensions and developed a system for settling industrial disputes, which was accepted by both employers and trade unions. In 1893, it extended voting rights to women, making New Zealand the first country in the world to do so.

To obtain land for farmers, the Liberal government from 1891 to 1911 purchased of Maori land. The government also purchased from large estate holders for subdivision and closer settlement by small farmers. The Advances to Settlers Act (1894) provided low-interest mortgages, and the agriculture department disseminated information on the best farming methods. The Liberals proclaimed success in forging an egalitarian, anti-monopoly land policy. The policy built up support for the Liberal Party in rural North Island electorates. By 1903, the Liberals were so dominant that there was no longer an organized opposition in Parliament.

Agrarianism is similar to but not identical with the back-to-the-land movement. Agrarianism concentrates on the fundamental goods of the earth, on communities of more limited economic and political scale than in modern society, and on simple living, even when the shift involves questioning the "progressive" character of some recent social and economic developments. Thus, agrarianism is not industrial farming, with its specialization on products and industrial scale.








</doc>
<doc id="1194" url="https://en.wikipedia.org/wiki?curid=1194" title="Atomic">
Atomic

Atomic may refer to:






</doc>
<doc id="1196" url="https://en.wikipedia.org/wiki?curid=1196" title="Angle">
Angle

In plane geometry, an angle is the figure formed by two rays, called the "sides" of the angle, sharing a common endpoint, called the "vertex" of the angle.
Angles formed by two rays lie in a plane, but this plane does not have to be a Euclidean plane. Angles are also formed by the intersection of two planes in Euclidean and other spaces. These are called dihedral angles. Angles formed by the intersection of two curves in a plane are defined as the angle determined by the tangent rays at the point of intersection. Similar statements hold in space, for example, the spherical angle formed by two great circles on a sphere is the dihedral angle between the planes determined by the great circles.

"Angle" is also used to designate the measure of an angle or of a rotation. This measure is the ratio of the length of a circular arc to its radius. In the case of a geometric angle, the arc is centered at the vertex and delimited by the sides. In the case of a rotation, the arc is centered at the center of the rotation and delimited by any other point and its image by the rotation.

The word "angle" comes from the Latin word "angulus", meaning "corner"; cognate words are the Greek "(ankylοs)", meaning "crooked, curved," and the English word "ankle". Both are connected with the Proto-Indo-European root "*ank-", meaning "to bend" or "bow".
Euclid defines a plane angle as the inclination to each other, in a plane, of two lines which meet each other, and do not lie straight with respect to each other. According to Proclus an angle must be either a quality or a quantity, or a relationship. The first concept was used by Eudemus, who regarded an angle as a deviation from a straight line; the second by Carpus of Antioch, who regarded it as the interval or space between the intersecting lines; Euclid adopted the third concept, although his definitions of right, acute, and obtuse angles are certainly quantitative.

In mathematical expressions, it is common to use Greek letters (α, β, γ, θ, φ, . . . ) to serve as variables standing for the size of some angle. (To avoid confusion with its other meaning, the symbol is typically not used for this purpose.) Lower case Roman letters ("a", "b", "c", . . . ) are also used, as are upper case Roman letters in the context of polygons. See the figures in this article for examples.

In geometric figures, angles may also be identified by the labels attached to the three points that define them. For example, the angle at vertex A enclosed by the rays AB and AC (i.e. the lines from point A to point B and point A to point C) is denoted ∠BAC (in Unicode ) or formula_1. Sometimes, where there is no risk of confusion, the angle may be referred to simply by its vertex ("angle A").

Potentially, an angle denoted, say, ∠BAC might refer to any of four angles: the clockwise angle from B to C, the anticlockwise angle from B to C, the clockwise angle from C to B, or the anticlockwise angle from C to B, where the direction in which the angle is measured determines its sign (see Positive and negative angles). However, in many geometrical situations it is obvious from context that the positive angle less than or equal to 180 degrees is meant, and no ambiguity arises. Otherwise, a convention may be adopted so that ∠BAC always refers to the anticlockwise (positive) angle from B to C, and ∠CAB to the anticlockwise (positive) angle from C to B.


The names, intervals, and measured units are shown in a table below:


When two straight lines intersect at a point, four angles are formed. Pairwise these angles are named according to their location relative to each other.


A transversal is a line that intersects a pair of (often parallel) lines and is associated with "alternate interior angles", "corresponding angles", "interior angles", and "exterior angles".

There are three special angle pairs which involve the summation of angles:



The size of a geometric angle is usually characterized by the magnitude of the smallest rotation that maps one of the rays into the other. Angles that have the same size are said to be "equal" or "congruent" or "equal in measure".

In some contexts, such as identifying a point on a circle or describing the "orientation" of an object in two dimensions relative to a reference orientation, angles that differ by an exact multiple of a full turn are effectively equivalent. In other contexts, such as identifying a point on a spiral curve or describing the "cumulative rotation" of an object in two dimensions relative to a reference orientation, angles that differ by a non-zero multiple of a full turn are not equivalent.

In order to measure an angle θ, a circular arc centered at the vertex of the angle is drawn, e.g. with a pair of compasses. The ratio of the length s of the arc by the radius r of the circle is the measure of the angle in radians.

The measure of the angle in another angular unit is then obtained by multiplying its measure in radians by the scaling factor , where "k" is the measure of a complete turn in the chosen unit (for example 360 for degrees or 400 for gradians):

The value of θ thus defined is independent of the size of the circle: if the length of the radius is changed then the arc length changes in the same proportion, so the ratio "s"/"r" is unaltered. (Proof. The formula above can be rewritten as One turn, for which units, corresponds to an arc equal in length to the circle's circumference, which is 2"r", so . Substituting "n" for "θ" and 2"r" for "s" in the formula, results in ) 

The angle addition postulate states that if "B" is in the interior of angle "AOC", then

The measure of the angle "AOC" is the sum of the measure of angle AOB and the measure of angle "BOC". In this postulate it does not matter in which unit the angle is measured as long as each angle is measured in the same unit.

Units used to represent angles are listed below in descending magnitude order. Of these units, the "degree" and the "radian" are by far the most commonly used. Angles expressed in radians are dimensionless for the purposes of dimensional analysis.

Most units of angular measurement are defined such that one "turn" (i.e. one full circle) is equal to "n" units, for some whole number "n". The two exceptions are the radian and the diameter part.

















Although the definition of the measurement of an angle does not support the concept of a negative angle, it is frequently useful to impose a convention that allows positive and negative angular values to represent orientations and/or rotations in opposite directions relative to some reference.

In a two-dimensional Cartesian coordinate system, an angle is typically defined by its two sides, with its vertex at the origin. The "initial side" is on the positive x-axis, while the other side or "terminal side" is defined by the measure from the initial side in radians, degrees, or turns. With "positive angles" representing rotations toward the positive y-axis and "negative angles" representing rotations toward the negative "y"-axis. When Cartesian coordinates are represented by "standard position", defined by the "x"-axis rightward and the "y"-axis upward, positive rotations are anticlockwise and negative rotations are clockwise.

In many contexts, an angle of −"θ" is effectively equivalent to an angle of "one full turn minus "θ"". For example, an orientation represented as  −45° is effectively equivalent to an orientation represented as 360° − 45° or 315°. Although the final position is the same, a physical rotation (movement) of  −45° is not the same as a rotation of 315° (for example, the rotation of a person holding a broom resting on a dusty floor would leave visually different traces of swept regions on the floor).

In three-dimensional geometry, "clockwise" and "anticlockwise" have no absolute meaning, so the direction of positive and negative angles must be defined relative to some reference, which is typically a vector passing through the angle's vertex and perpendicular to the plane in which the rays of the angle lie.

In navigation, bearings or azimuth are measured relative to north. By convention, viewed from above, bearing angles are positive clockwise, so a bearing of 45° corresponds to a north-east orientation. Negative bearings are not used in navigation, so a north-west orientation corresponds to a bearing of 315°.

There are several alternatives to measuring the size of an angle by the angle of rotation.
The "grade of a slope", or "gradient" is equal to the tangent of the angle, or sometimes (rarely) the sine. A gradient is often expressed as a percentage. For very small values (less than 5%), the grade of a slope is approximately the measure of the angle in radians.

In rational geometry the "spread" between two lines is defined as the square of the sine of the angle between the lines. As the sine of an angle and the sine of its supplementary angle are the same, any angle of rotation that maps one of the lines into the other leads to the same value for the spread between the lines.

Astronomers measure angular separation of objects in degrees from their point of observation.

These measurements clearly depend on the individual subject, and the above should be treated as rough rule of thumb approximations only.

The angle between a line and a curve (mixed angle) or between two intersecting curves (curvilinear angle) is defined to be the angle between the tangents at the point of intersection. Various names (now rarely, if ever, used) have been given to particular cases:—"amphicyrtic" (Gr. , on both sides, κυρτός, convex) or "cissoidal" (Gr. κισσός, ivy), biconvex; "xystroidal" or "sistroidal" (Gr. ξυστρίς, a tool for scraping), concavo-convex; "amphicoelic" (Gr. κοίλη, a hollow) or "angulus lunularis", biconcave.

The ancient Greek mathematicians knew how to bisect an angle (divide it into two angles of equal measure) using only a compass and straightedge, but could only trisect certain angles. In 1837 Pierre Wantzel showed that for most angles this construction cannot be performed.

In the Euclidean space, the angle "θ" between two Euclidean vectors u and v is related to their dot product and their lengths by the formula

This formula supplies an easy method to find the angle between two planes (or curved surfaces) from their normal vectors and between skew lines from their vector equations.

To define angles in an abstract real inner product space, we replace the Euclidean dot product ( · ) by the inner product formula_6, i.e.

In a complex inner product space, the expression for the cosine above may give non-real values, so it is replaced with

or, more commonly, using the absolute value, with

The latter definition ignores the direction of the vectors and thus describes the angle between one-dimensional subspaces formula_10 and formula_11 spanned by the vectors formula_12 and formula_13 correspondingly.

The definition of the angle between one-dimensional subspaces formula_10 and formula_11 given by

in a Hilbert space can be extended to subspaces of any finite dimensions. Given two subspaces formula_17, formula_18 with formula_19, this leads to a definition of formula_20 angles called canonical or principal angles between subspaces.

In Riemannian geometry, the metric tensor is used to define the angle between two tangents. Where "U" and "V" are tangent vectors and "g" are the components of the metric tensor "G",

A hyperbolic angle is an argument of a hyperbolic function just as the "circular angle" is the argument of a circular function. The comparison can be visualized as the size of the openings of a hyperbolic sector and a circular sector since the areas of these sectors correspond to the angle magnitudes in each case. Unlike the circular angle, the hyperbolic angle is unbounded. When the circular and hyperbolic functions are viewed as infinite series in their angle argument, the circular ones are just alternating series forms of the hyperbolic functions. This weaving of the two types of angle and function was explained by Leonhard Euler in "Introduction to the Analysis of the Infinite".

In geography, the location of any point on the Earth can be identified using a "geographic coordinate system". This system specifies the latitude and longitude of any location in terms of angles subtended at the centre of the Earth, using the equator and (usually) the Greenwich meridian as references.

In astronomy, a given point on the celestial sphere (that is, the apparent position of an astronomical object) can be identified using any of several "astronomical coordinate systems", where the references vary according to the particular system. Astronomers measure the "angular separation" of two stars by imagining two lines through the centre of the Earth, each intersecting one of the stars. The angle between those lines can be measured, and is the angular separation between the two stars.

In both geography and astronomy, a sighting direction can be specified in terms of a vertical angle such as altitude /elevation with respect to the horizon as well as the azimuth with respect to north.

Astronomers also measure the "apparent size" of objects as an angular diameter. For example, the full moon has an angular diameter of approximately 0.5°, when viewed from Earth. One could say, "The Moon's diameter subtends an angle of half a degree." The small-angle formula can be used to convert such an angular measurement into a distance/size ratio.


Attribution



</doc>
<doc id="1197" url="https://en.wikipedia.org/wiki?curid=1197" title="Asa">
Asa

Asa may refer to:





</doc>
<doc id="1198" url="https://en.wikipedia.org/wiki?curid=1198" title="Acoustics">
Acoustics

Acoustics is the branch of physics that deals with the study of all mechanical waves in gases, liquids, and solids including topics such as vibration, sound, ultrasound and infrasound. A scientist who works in the field of acoustics is an acoustician while someone working in the field of acoustics technology may be called an acoustical engineer. The application of acoustics is present in almost all aspects of modern society with the most obvious being the audio and noise control industries.

Hearing is one of the most crucial means of survival in the animal world, and speech is one of the most distinctive characteristics of human development and culture. Accordingly, the science of acoustics spreads across many facets of human society—music, medicine, architecture, industrial production, warfare and more. Likewise, animal species such as songbirds and frogs use sound and hearing as a key element of mating rituals or marking territories. Art, craft, science and technology have provoked one another to advance the whole, as in many other fields of knowledge. Robert Bruce Lindsay's 'Wheel of Acoustics' is a well accepted overview of the various fields in acoustics. Acoustic music is a genre of music using instruments that produce sound solely through acoustic means, without electronic amplification. 

The word "acoustic" is derived from the Greek word ἀκουστικός ("akoustikos"), meaning "of or for hearing, ready to hear"and that from ἀκουστός ("akoustos"), "heard, audible", which in turn derives from the verb ἀκούω("akouo"), "I hear".

The Latin synonym is "sonic", after which the term sonics used to be a synonym for acoustics and later a branch of acoustics. Frequenciesabove and below the audible range are called "ultrasonic" and "infrasonic", respectively.

In the 6th century BC, the ancient Greek philosopher Pythagoras wanted to know why some combinations of musical sounds seemed more beautiful than others, and he found answers in terms of numerical ratios representing the harmonic overtone series on a string. He is reputed to have observed that when the lengths of vibrating strings are expressible as ratios of integers (e.g. 2 to 3, 3 to 4), the tones produced will be harmonious, and the smaller the integers the more harmonious the sounds. If, for example, a string of a certain length would sound particularly harmonious with a string of twice the length (other factors being equal). In modern parlance, if a string sounds the note C when plucked, a string twice as long will sound a C an octave lower. In one system of musical tuning, the tones in between are then given by 16:9 for D, 8:5 for E, 3:2 for F, 4:3 for G, 6:5 for A, and 16:15 for B, in ascending order.

Aristotle (384–322 BC) understood that sound consisted of compressions and rarefactions of air which "falls upon and strikes the air which is next to it...", a very good expression of the nature of wave motion.

In about 20 BC, the Roman architect and engineer Vitruvius wrote a treatise on the acoustic properties of theaters including discussion of interference, echoes, and reverberation—the beginnings of architectural acoustics. In Book V of his "De architectura" ("The Ten Books of Architecture") Vitruvius describes sound as a wave comparable to a water wave extended to three dimensions, which, when interrupted by obstructions, would flow back and break up following waves. He described the ascending seats in ancient theaters as designed to prevent this deterioration of sound and also recommended bronze vessels of appropriate sizes be placed in theaters to resonate with the fourth, fifth and so on, up to the double octave, in order to resonate with the more desirable, harmonious notes. 

During the Islamic golden age, Abū Rayhān al-Bīrūnī (973-1048) is believed to postulated that the speed of sound was much slower than the speed of light.

The physical understanding of acoustical processes advanced rapidly during and after the Scientific Revolution. Mainly Galileo Galilei (1564–1642) but also Marin Mersenne (1588–1648), independently, discovered the complete laws of vibrating strings (completing what Pythagoras and Pythagoreans had started 2000 years earlier). Galileo wrote "Waves are produced by the vibrations of a sonorous body, which spread through the air, bringing to the tympanum of the ear a stimulus which the mind interprets as sound", a remarkable statement that points to the beginnings of physiological and psychological acoustics. Experimental measurements of the speed of sound in air were carried out successfully between 1630 and 1680 by a number of investigators, prominently Mersenne. Meanwhile, Newton (1642–1727) derived the relationship for wave velocity in solids, a cornerstone of physical acoustics (Principia, 1687).

The eighteenth century saw major advances in acoustics as mathematicians applied the new techniques of calculus to elaborate theories of sound wave propagation. In the nineteenth century the major figures of mathematical acoustics were Helmholtz in Germany, who consolidated the field of physiological acoustics, and Lord Rayleigh in England, who combined the previous knowledge with his own copious contributions to the field in his monumental work "The Theory of Sound" (1877). Also in the 19th century, Wheatstone, Ohm, and Henry developed the analogy between electricity and acoustics.

The twentieth century saw a burgeoning of technological applications of the large body of scientific knowledge that was by then in place. The first such application was Sabine’s groundbreaking work in architectural acoustics, and many others followed. Underwater acoustics was used for detecting submarines in the first World War. Sound recording and the telephone played important roles in a global transformation of society. Sound measurement and analysis reached new levels of accuracy and sophistication through the use of electronics and computing. The ultrasonic frequency range enabled wholly new kinds of application in medicine and industry. New kinds of transducers (generators and receivers of acoustic energy) were invented and put to use.

Acoustics is defined by ANSI/ASA S1.1-2013 as "(a) Science of sound, including its production, transmission, and effects, including biological and psychological effects. (b) Those qualities of a room that, together, determine its character with respect to auditory effects."

The study of acoustics revolves around the generation, propagation and reception of mechanical waves and vibrations.

The steps shown in the above diagram can be found in any acoustical event or process. There are many kinds of cause, both natural and volitional. There are many kinds of transduction process that convert energy from some other form into sonic energy, producing a sound wave. There is one fundamental equation that describes sound wave propagation, the acoustic wave equation, but the phenomena that emerge from it are varied and often complex. The wave carries energy throughout the propagating medium. Eventually this energy is transduced again into other forms, in ways that again may be natural and/or volitionally contrived. The final effect may be purely physical or it may reach far into the biological or volitional domains. The five basic steps are found equally well whether we are talking about an earthquake, a submarine using sonar to locate its foe, or a band playing in a rock concert.

The central stage in the acoustical process is wave propagation. This falls within the domain of physical acoustics. In fluids, sound propagates primarily as a pressure wave. In solids, mechanical waves can take many forms including longitudinal waves, transverse waves and surface waves.

Acoustics looks first at the pressure levels and frequencies in the sound wave and how the wave interacts with the environment. This interaction can be described as either a diffraction, interference or a reflection or a mix of the three. If several media are present, a refraction can also occur. Transduction processes are also of special importance to acoustics.

In fluids such as air and water, sound waves propagate as disturbances in the ambient pressure level. While this disturbance is usually small, it is still noticeable to the human ear. The smallest sound that a person can hear, known as the threshold of hearing, is nine orders of magnitude smaller than the ambient pressure. The loudness of these disturbances is related to the sound pressure level (SPL) which is measured on a logarithmic scale in decibels.

Physicists and acoustic engineers tend to discuss sound pressure levels in terms of frequencies, partly because this is how our ears interpret sound. What we experience as "higher pitched" or "lower pitched" sounds are pressure vibrations having a higher or lower number of cycles per second. In a common technique of acoustic measurement, acoustic signals are sampled in time, and then presented in more meaningful forms such as octave bands or time frequency plots. Both of these popular methods are used to analyze sound and better understand the acoustic phenomenon.

The entire spectrum can be divided into three sections: audio, ultrasonic, and infrasonic. The audio range falls between 20 Hz and 20,000 Hz. This range is important because its frequencies can be detected by the human ear. This range has a number of applications, including speech communication and music. The ultrasonic range refers to the very high frequencies: 20,000 Hz and higher. This range has shorter wavelengths which allow better resolution in imaging technologies. Medical applications such as ultrasonography and elastography rely on the ultrasonic frequency range. On the other end of the spectrum, the lowest frequencies are known as the infrasonic range. These frequencies can be used to study geological phenomena such as earthquakes.

Analytic instruments such as the spectrum analyzer facilitate visualization and measurement of acoustic signals and their properties. The spectrogram produced by such an instrument is a graphical display of the time varying pressure level and frequency profiles which give a specific acoustic signal its defining character.

A transducer is a device for converting one form of energy into another. In an electroacoustic context, this means converting sound energy into electrical energy (or vice versa). Electroacoustic transducers include loudspeakers, microphones, hydrophones and sonar projectors. These devices convert a sound pressure wave to or from an electric signal. The most widely used transduction principles are electromagnetism, electrostatics and piezoelectricity.

The transducers in most common loudspeakers (e.g. woofers and tweeters), are electromagnetic devices that generate waves using a suspended diaphragm driven by an electromagnetic voice coil, sending off pressure waves. Electret microphones and condenser microphones employ electrostatics—as the sound wave strikes the microphone's diaphragm, it moves and induces a voltage change. The ultrasonic systems used in medical ultrasonography employ piezoelectric transducers. These are made from special ceramics in which mechanical vibrations and electrical fields are interlinked through a property of the material itself.

An acoustician is an expert in the science of sound.

There are many types of acoustician, but they usually have a Bachelor's degree or higher qualification. Some possess a degree in acoustics, while others enter the discipline via studies in fields such as physics or engineering. Much work in acoustics requires a good grounding in Mathematics and science. Many acoustic scientists work in research and development. Some conduct basic research to advance our knowledge of the perception (e.g. hearing, psychoacoustics or neurophysiology) of speech, music and noise. Other acoustic scientists advance understanding of how sound is affected as it moves through environments, e.g. Underwater acoustics, Architectural acoustics or Structural acoustics. Other areas of work are listed under subdisciplines below. Acoustic scientists work in government, university and private industry laboratories. Many go on to work in Acoustical Engineering. Some positions, such as Faculty (academic staff) require a Doctor of Philosophy.

These subdisciplines are a slightly modified list from the PACS (Physics and Astronomy Classification Scheme) coding used by the Acoustical Society of America.

Archaeoacoustics, also known as the archaeology of sound, is one of the only ways to experience the past with senses other than our eyes.Archaeoacoustics is studied by testing the acoustic properties of prehistoric sites, including caves. Iegor Rezkinoff, a sound archaeologist, studies the acoustic properties of caves through natural sounds like humming and whistling.Archaeological theories of acoustics are focused around ritualistic purposes as well as a way of echolocation in the caves. In archaeology, acoustic sounds and rituals directly correlate as specific sounds were meant to bring ritual participants closer to a spiritual awakening.Parallels can also be drawn between cave wall paintings and the acoustic properties of the cave; they are both dynamic.Because archaeoacoustics is a fairly new archaeological subject, acoustic sound is still being tested in these prehistoric sites today. 

Aeroacoustics is the study of noise generated by air movement, for instance via turbulence, and the movement of sound through the fluid air. This knowledge is applied in acoustical engineering to study how to quieten aircraft. Aeroacoustics is important to understanding how wind musical instruments work.

Acoustic signal processing is the electronic manipulation of acoustic signals. Applications include: active noise control; design for hearing aids or cochlear implants; echo cancellation; music information retrieval, and perceptual coding (e.g. MP3 or Opus).

Architectural acoustics (also known as building acoustics) involves the scientific understanding of how to achieve good sound within a building. It typically involves the study of speech intelligibility, speech privacy, music quality, and vibration reduction in the built environment.

Bioacoustics is the scientific study of the hearing and calls of animal calls, as well as how animals are affected by the acoustic and sounds of their habitat.

This subdiscipline is concerned with the recording, manipulation and reproduction of audio using electronics. This might include products such as mobile phones, large scale public address systems or virtual reality systems in research laboratories.

Environmental acoustics is concerned with noise and vibration caused by railways, road traffic, aircraft, industrial equipment and recreational activities. The main aim of these studies is to reduce levels of environmental noise and vibration. Research work now also has a focus on the positive use of sound in urban environments: soundscapes and tranquility.

Musical acoustics is the study of the physics of acoustic instruments; the audio signal processing used in electronic music; the computer analysis of music and composition, and the perception and cognitive neuroscience of music.

Many studies have been conducted to identify the relationship between acoustics and cognition, or more commonly known as psychoacoustics, in which what one hears is a combination of perception and biological aspects. The information intercepted by the passage of sound waves through the ear is understood and interpreted through the brain, emphasizing the connection between the mind and acoustics. Psychological changes have been seen as brain waves slow down or speed up as a result of varying auditory stimulus which can in turn affect the way one thinks, feels, or even behaves. This correlation can be viewed in normal, everyday situations in which listening to an upbeat or uptempo song can cause one's foot to start tapping or a slower song can leave one feeling calm and serene. In a deeper biological look at the phenomenon of psychoacoustics, it was discovered that the central nervous system is activated by basic acoustical characteristics of music. By observing how the central nervous system, which includes the brain and spine, is influenced by acoustics, the pathway in which acoustic affects the mind, and essentially the body, is evident.

Acousticians study the production, processing and perception of speech. Speech recognition and Speech synthesis are two important areas of speech processing using computers. The subject also overlaps with the disciplines of physics, physiology, psychology, and linguistics.

Ultrasonics deals with sounds at frequencies too high to be heard by humans. Specialisms include medical ultrasonics (including medical ultrasonography), sonochemistry, material characterisation and underwater acoustics (Sonar).

Underwater acoustics is the scientific study of natural and man-made sounds underwater. Applications include sonar to locate submarines, underwater communication by whales, climate change monitoring by measuring sea temperatures acoustically, sonic weapons, and marine bioacoustics.

This is the study of how mechanical systems vibrate and interact with their surroundings. Applications might include: ground vibrations from railways; vibration isolation to reduce vibration in operating theatres; studying how vibration can damage health (vibration white finger); vibration control to protect a building from earthquakes, or measuring how structure-borne sound moves through buildings.






</doc>
<doc id="1200" url="https://en.wikipedia.org/wiki?curid=1200" title="Atomic physics">
Atomic physics

Atomic physics is the field of physics that studies atoms as an isolated system of electrons and an atomic nucleus. It is primarily concerned with the arrangement of electrons around the nucleus and
the processes by which these arrangements change. This comprises ions, neutral atoms and, unless otherwise stated, it can be assumed that the term "atom" includes ions.

The term "atomic physics" can be associated with nuclear power and nuclear weapons, due to the synonymous use of "atomic" and "nuclear" in standard English. Physicists distinguish between atomic physics—which deals with the atom as a system consisting of a nucleus and electrons—and nuclear physics, which studies nuclear reactions and special properties of atomic nuclei.

As with many scientific fields, strict delineation can be highly contrived and atomic physics is often considered in the wider context of "atomic, molecular, and optical physics". Physics research groups are usually so classified.

Atomic physics primarily considers atoms in isolation. Atomic models will consist of a single nucleus that may be surrounded by one or more bound electrons. It is not concerned with the formation of molecules (although much of the physics is identical), nor does it examine atoms in a solid state as condensed matter. It is concerned with processes such as ionization and excitation by photons or collisions with atomic particles.

While modelling atoms in isolation may not seem realistic, if one considers atoms in a gas or plasma then the time-scales for atom-atom interactions are huge in comparison to the atomic processes that are generally considered. This means that the individual atoms can be treated as if each were in isolation, as the vast majority of the time they are. By this consideration atomic physics provides the underlying theory in plasma physics and atmospheric physics, even though both deal with very large numbers of atoms.

Electrons form notional shells around the nucleus. These are normally in a ground state but can be excited by the absorption of energy from light (photons), magnetic fields, or interaction with a colliding particle (typically ions or other electrons).

If the electron absorbs a quantity of energy less than the binding energy, it will be transferred to an excited state. After a certain time, the electron in an excited state will "jump" (undergo a transition) to a lower state. In a neutral atom, the system will emit a photon of the difference in energy, since energy is conserved.

If an inner electron has absorbed more than the binding energy (so that the atom ionizes), then a more outer electron may undergo a transition to fill the inner orbital. In this case, a visible photon or a characteristic x-ray is emitted, or a phenomenon known as the Auger effect may take place, where the released energy is transferred to another bound electron, causing it to go into the continuum. The Auger effect allows one to multiply ionize an atom with a single photon.

There are rather strict selection rules as to the electronic configurations that can be reached by excitation by light — however there are no such rules for excitation by collision processes.

One of the earliest steps towards atomic physics was the recognition that matter was composed
of "atoms". It forms a part of the texts written in 6th century BC to 2nd century BC such as those of Democritus or Vaisheshika Sutra written by Kanad. This theory was later developed in the modern sense of the basic unit of a chemical element by the British chemist and physicist John Dalton in the 18th century. At this stage, it wasn't clear what atoms were although they could be described and classified by their properties (in bulk). The invention of the periodic system of elements by Mendeleev was another great step forward.

The true beginning of atomic physics is marked by the discovery of spectral lines and attempts to describe the phenomenon, most notably by Joseph von Fraunhofer. The study of these lines led to the Bohr atom model and to the birth of quantum mechanics. In seeking to explain atomic spectra an entirely new mathematical model of matter was revealed. As far as atoms and their electron shells were concerned, not only did this yield a better overall description, i.e. the atomic orbital model, but it also provided a new theoretical basis for chemistry
(quantum chemistry) and spectroscopy.

Since the Second World War, both theoretical and experimental fields have advanced at a rapid pace. This can be attributed to progress in computing technology, which has allowed larger and more sophisticated models of atomic structure and associated collision processes. Similar technological advances in accelerators, detectors, magnetic field generation and lasers have greatly assisted experimental work.




</doc>
<doc id="1201" url="https://en.wikipedia.org/wiki?curid=1201" title="American Sign Language">
American Sign Language

American Sign Language (ASL) is a natural language that serves as the predominant sign language of Deaf communities in the United States and most of Anglophone Canada. Besides North America, dialects of ASL and ASL-based creoles are used in many countries around the world, including much of West Africa and parts of Southeast Asia. ASL is also widely learned as a second language, serving as a lingua franca. ASL is most closely related to French Sign Language (LSF). It has been proposed that ASL is a creole language of LSF, although ASL shows features atypical of creole languages, such as agglutinative morphology.

ASL originated in the early 19th century in the American School for the Deaf (ASD) in West Hartford, Connecticut, from a situation of language contact. Since then, ASL use has propagated widely via schools for the deaf and Deaf community organizations. Despite its wide use, no accurate count of ASL users has been taken, though reliable estimates for American ASL users range from 250,000 to 500,000 persons, including a number of children of deaf adults. ASL users face stigma due to beliefs in the superiority of oral language to sign language, compounded by the fact that ASL is often glossed in English due to the lack of a standard writing system.

ASL signs have a number of phonemic components, including movement of the face and torso as well as the hands. ASL is not a form of pantomime, but iconicity does play a larger role in ASL than in spoken languages. English loan words are often borrowed through fingerspelling, although ASL grammar is unrelated to that of English. ASL has verbal agreement and aspectual marking and has a productive system of forming agglutinative classifiers. Many linguists believe ASL to be a subject–verb–object (SVO) language, but there are several alternative proposals to account for ASL word order.

ASL emerged as a language in the American School for the Deaf (ASD), founded in 1817. This school brought together Old French Sign Language, various village sign languages, and home sign systems; ASL was created in this situation of language contact. ASL was influenced by its forerunners but distinct from all of them.

The influence of French Sign Language (LSF) on ASL is readily apparent; for example, it has been found that about 58% of signs in modern ASL are cognate to Old French Sign Language signs. However, this is far less than the standard 80% measure used to determine whether related languages are actually dialects. This suggests that nascent ASL was highly affected by the other signing systems brought by the ASD students, despite the fact that the school's original director Laurent Clerc taught in LSF. In fact, Clerc reported that he often learned the students' signs rather than conveying LSF:
It has been proposed that ASL is a creole with LSF as the superstrate language and with the native village sign languages as substrate languages. However, more recent research has shown that modern ASL does not share many of the structural features that characterize creole languages. ASL may have begun as a creole and then undergone structural change over time, but it is also possible that it was never a creole-type language. There are modality-specific reasons that sign languages tend towards agglutination, for example the ability to simultaneously convey information via the face, head, torso, and other body parts. This might override creole characteristics such as the tendency towards isolating morphology. Additionally, Clerc and Thomas Hopkins Gallaudet may have used an artificially constructed form of manually coded language in instruction rather than true LSF.

Although the United States, the United Kingdom, and Australia share English as a common oral and written language, ASL is not mutually intelligible with British Sign Language (BSL) nor Auslan. All three languages show degrees of borrowing from English, but this alone is not sufficient for cross-language comprehension. It has been found that a relatively high percentage (37–44%) of ASL signs have similar translations in Auslan, which for oral languages would suggest that they belong to the same language family. However, this does not seem justified historically for ASL and Auslan, and it is likely that this resemblance is due to the higher degree of iconicity in sign languages in general, as well as contact with English.

American Sign Language is growing in popularity among many states. Many people in high school and colleges desire to take it as a foreign language, but until recently, it was not a creditable foreign language elective. The issue was that many didn't consider it a foreign language. ASL users, however, have a very distinct culture and way they interact when talking. Their facial expressions and hand movements reflect what they are conveying. They also have their own sentence structure which sets the language apart.

American sign language is now being accepted by many colleges as a foreign language credit; many states are making it mandatory to accept it.

Prior to the birth of ASL, sign language had been used by various communities in the United States. In the United States, as elsewhere in the world, hearing families with deaf children have historically employed ad-hoc home sign, which often reaches much higher levels of sophistication than gestures used by hearing people in spoken conversation. As early as 1541 at first contact by Francisco Vásquez de Coronado, there were reports that the Plains Indians had developed a sign language to communicate between tribes of different languages.

In the 19th century, a "triangle" of village sign languages developed in New England: one in Martha's Vineyard, Massachusetts; one in Henniker, New Hampshire, and one in Sandy River Valley, Maine. Martha's Vineyard Sign Language (MVSL), which was particularly important for the history of ASL, was used mainly in Chilmark, Massachusetts. Due to intermarriage in the original community of English settlers of the 1690s, and the recessive nature of genetic deafness, Chilmark had a high 4% rate of genetic deafness. MVSL was used even by hearing residents whenever a deaf person was present, and also in some situations where spoken language would be ineffective or inappropriate, such as during church sermons or between boats at sea.

ASL is thought to have originated in the American School for the Deaf (ASD), founded in Hartford, Connecticut in 1817. Originally known as "The American Asylum, At Hartford, For The Education And Instruction Of The Deaf And Dumb", the school was founded by the Yale graduate and divinity student Thomas Hopkins Gallaudet. Gallaudet, inspired by his success in demonstrating the learning abilities of a young deaf girl Alice Cogswell, traveled to Europe in order to learn deaf pedagogy from European institutions. Ultimately, Gallaudet chose to adopt the methods of the French Institut National de Jeunes Sourds de Paris, and convinced Laurent Clerc, an assistant to the school's founder Charles-Michel de l'Épée, to accompany him back to the United States. Upon his return, Gallaudet founded the ASD on April 15, 1817.

The largest group of students during the first seven decades of the school were from Martha's Vineyard, and they brought MVSL with them. There were also 44 students from around Henniker, New Hampshire, and 27 from the Sandy River valley in Maine, each of which had their own village sign language. Other students brought knowledge of their own home signs. Laurent Clerc, the first teacher at ASD, taught using French Sign Language (LSF), which itself had developed in the Parisian school for the deaf established in 1755. From this situation of language contact, a new language emerged, now known as ASL.
More schools for the deaf were founded after ASD, and knowledge of ASL spread to these schools. In addition, the rise of Deaf community organizations bolstered the continued use of ASL. Societies such as the National Association of the Deaf and the National Fraternal Society of the Deaf held national conventions that attracted signers from across the country. This all contributed to ASL's wide use over a large geographical area, atypical of a sign language.

Up to the 1950s, the predominant method in deaf education was oralism – acquiring oral language comprehension and production. Linguists did not consider sign language to be true "language", but rather something inferior. Recognition of the legitimacy of ASL was achieved by William Stokoe, a linguist who arrived at Gallaudet University in 1955 when this was still the dominant assumption. Aided by the civil rights movement of the 1960s, Stokoe argued for manualism, the use of sign language in deaf education. Stokoe noted that sign language shares the important features that oral languages have as a means of communication, and even devised a transcription system for ASL. In doing so, Stokoe revolutionized both deaf education and linguistics. In the 1960s, ASL was sometimes referred to as "Ameslan", but this term is now considered obsolete.

Counting the number of ASL signers is difficult because ASL users have never been counted by the American census. The ultimate source for current estimates of the number of ASL users in the United States is a report for the National Census of the Deaf Population (NCDP) by Schein and Delk (1974). Based on a 1972 survey of the NCDP, Schein and Delk provided estimates consistent with a signing population between 250,000 and 500,000. The survey did not distinguish between ASL and other forms of signing; in fact, the name "ASL" was not yet in widespread use.

Incorrect figures are sometimes cited for the population of ASL users in the United States based on misunderstandings of known statistics. Demographics of the deaf population have been confused with those of ASL use, since adults who become deaf late in life rarely use ASL in the home. This accounts for currently cited estimations which are greater than 500,000; such mistaken estimations can reach as high as 15,000,000. A 100,000-person lower bound has been cited for ASL users; the source of this figure is unclear, but it may be an estimate of prelingual deafness, which is correlated with but not equivalent to signing.

ASL is sometimes incorrectly cited as the third- or fourth-most-spoken language in the United States. These figures misquote Schein and Delk (1974), who actually concluded that ASL speakers constituted the third-largest population "requiring an interpreter in court". Although this would make ASL the third-most used language among monolinguals other than English, it does not imply that it is the fourth-most-spoken language in the United States, since speakers of other languages may also speak English.

ASL is used throughout Anglo-America. This contrasts with Europe, where a variety of sign languages are used within the same continent. The unique situation of ASL seems to have been caused by the proliferation of ASL through schools influenced by the American School for the Deaf, wherein ASL originated, and the rise of community organizations for the Deaf.

Throughout West Africa, ASL-based sign languages are spoken by educated Deaf adults. These languages, imported by boarding schools, are often considered by associations to be the official sign languages of their countries, and are named accordingly, e.g. Nigerian Sign Language, Ghanaian Sign Language. Such signing systems are found in Benin, Burkina Faso, Ivory Coast, Ghana, Liberia, Mauritania, Mali, Nigeria, and Togo. Due to lack of data, it is still an open question how similar these sign languages are to the variety of ASL used in America.

In addition to the aforementioned West African countries, ASL is reported to be used as a first language in Barbados, Bolivia, Cambodia, the Central African Republic, Chad, China (Hong Kong), the Democratic Republic of the Congo, Gabon, Jamaica, Kenya, Madagascar, the Philippines, Singapore, and Zimbabwe. ASL is also used as a lingua franca throughout the deaf world, widely learned as a second language.

Sign production can often vary according to location. Signers from the South tend to sign with more flow and ease. Native signers from New York have been reported as signing comparatively more quickly and sharply. Sign production of native Californian signers has also been reported as being fast as well. Research on this phenomenon often concludes this fast-paced production for signers from the coast could be due to the fast-paced nature of living in large metropolitan areas. This conclusion also supports how the ease with which Southern sign could be due to the easy going environment of the South in comparison to that of the East and West coast.

Sign production can also vary depending on age and native language. For example, sign production of letters may vary in older signers. Slight differences in finger spelling production can be a signal of age. Additionally, signers who learned American Sign Language as a second language vary in production. For Deaf signers who learned a different sign language before learning American Sign Language, qualities of their native language may show in their ASL production. Some examples of this varied production are finger spelling towards the body instead of away from, and signing certain movement from bottom to top instead of top to bottom. Hearing people that learn American Sign Language also have noticeable differences in signing production. The most notable production difference of hearing people learning American Sign Language is their rhythm and arm posture.

Most popularly there are variants of the signs for English words such as "birthday", "pizza", "Halloween", "early", and "soon". These are just a sample of the most commonly recognized signs with variant based on regional change. The sign for "school" is commonly varied between black and white signers. The variation between sign produced by black and white signers is sometimes referred to as Black American Sign Language.

The prevalence of residential Deaf schools can account for much of the regional variance of signs and sign productions across the United States. Deaf schools often serve students of the state in which the school resides. This limited access to signers from other regions, combined with the residential quality of Deaf Schools promoted specific use of certain sign variants. Native signers did not have much access to signers from other regions during the beginning years of their education. It is hypothesized that because of this seclusion, certain variants of a sign prevailed over others due to the choice of variant used by the student of the school/signers in the community.

However, American Sign Language does not appear to be vastly varied when compared to other signed languages. This is because when Deaf education was beginning in the United States, many educators flocked to the American School for the Deaf in Hartford, Connecticut. This central location for the first generation of educators in Deaf education to learn American Sign Language allows ASL to be more standardized than it is variant.

Varieties of ASL are found throughout the world. There is little difficulty in comprehension among the varieties of the United States and Canada.

Mutual intelligibility among these ASL varieties is high, and the variation is primarily lexical. For example, there are three different words for English "about" in Canadian ASL; the standard way, and two regional variations (Atlantic and Ontario), as shown in the videos on the right. Variation may also be phonological, meaning that the same sign may be signed in a different way depending on the region. For example, an extremely common type of variation is between the handshapes /1/, /L/, and /5/ in signs with one handshape.

There is also a distinct variety of ASL used by the Black Deaf community. Black ASL evolved as a result of racially segregated schools in some states, which included the residential schools for the deaf. Black ASL differs from standard ASL in vocabulary, phonology, and some grammatical structure. While African American English (AAE) is generally viewed as more innovating than standard English, Black ASL is more conservative than standard ASL, preserving older forms of many signs. Black sign language speakers use more two-handed signs than in mainstream ASL, are less likely to show assimilatory lowering of signs produced on the forehead (e.g. KNOW) and use a wider signing space. Modern Black ASL borrows a number of idioms from AAE; for instance, the AAE idiom "I feel you" is calqued into Black ASL.

ASL is used internationally as a lingua franca, and a number of closely related sign languages derived from ASL are used in many different countries. Even so, there have been varying degrees of divergence from standard ASL in these imported ASL varieties. Bolivian Sign Language is reported to be a dialect of ASL, no more divergent than other acknowledged dialects. On the other hand, it is also known that some imported ASL varieties have diverged to the extent of being separate languages. For example, Malaysian Sign Language, which has ASL origins, is no longer mutually comprehensible with ASL and must be considered its own language. For some imported ASL varieties, such as those used in West Africa, it is still an open question how similar they are to American ASL.

When communicating with hearing English speakers, ASL-speakers often use what is commonly called Pidgin Signed English (PSE) or 'contact signing', a blend of English structure with ASL. Various types of PSE exist, ranging from highly English-influenced PSE (practically relexified English) to PSE which is quite close to ASL lexically and grammatically, but may alter some subtle features of ASL grammar. Fingerspelling may be used more often in PSE than it is normally used in ASL. There have been some constructed sign languages, known as Manually Coded English (MCE), which match English grammar exactly and simply replace spoken words with signs; these systems are not considered to be varieties of ASL.

Tactile ASL (TASL) is a variety of ASL used throughout the United States by and with the deaf-blind. It is particularly common among those with Usher's syndrome. This syndrome results in deafness from birth followed by loss of vision later in life; consequently, those with Usher's syndrome often grow up in the Deaf community using ASL, and later transition to TASL. TASL differs from ASL in that signs are produced by touching the palms, and there are some grammatical differences from standard ASL in order to compensate for the lack of non-manual signing.

In 2013 the White House published a response to a petition that gained over 37,000 signatures to "officially recognize American Sign Language as a community language and a language of instruction in schools". The response is titled "there shouldn't be any stigma about American Sign Language" and addressed that ASL is a vital language for the Deaf and hard of hearing. Stigmas associated with sign languages and the use of sign for educating children often lead to the absence of sign during periods in children's lives when they can access languages most effectively. Scholars such as Beth S. Benedict advocate not only for bilingualism (using ASL and English training) but also for early childhood intervention for children who are deaf. York University psychologist Ellen Bialystok has also campaigned for bilingualism, arguing that those who are bilingual acquire cognitive skills that may help to prevent dementia later in life.

The majority of children born to deaf parents are hearing. These children, known as CODAs ("Children Of Deaf Adults") are often more culturally Deaf than deaf children, the majority of whom are born to hearing parents. Unlike many deaf children, CODAs acquire ASL as well as Deaf cultural values and behaviors from birth. These bilingual hearing children may be mistakenly labeled as being "slow learners" or as having "language difficulties" due to preferential attitudes towards spoken language.

Although there is no well-established writing system for ASL, written sign language dates back almost two centuries. The first systematic writing system for a sign language seems to be that of Roch-Ambroise Auguste Bébian, developed in 1825. However, written sign language remained marginal among the public. In the 1960s, linguist William Stokoe created Stokoe notation specifically for ASL. It is alphabetic, with a letter or diacritic for every phonemic (distinctive) hand shape, orientation, motion, and position, though it lacks any representation of facial expression, and is better suited for individual words than for extended passages of text. Stokoe used this system for his 1965 "A Dictionary of American Sign Language on Linguistic Principles".

SignWriting, proposed in 1974 by Valerie Sutton, is the first writing system to gain use among the public and the first writing system for sign languages to be included in the Unicode Standard. SignWriting consists of more than 5000 distinct iconic graphs/glyphs. Currently, it is in use in many schools for the Deaf, particularly in Brazil, and has been used in International Sign forums with speakers and researchers in more than 40 countries, including Brazil, Ethiopia, France, Germany, Italy, Portugal, Saudi Arabia, Slovenia, Tunisia, and the United States. Sutton SignWriting has both a printed and an electronically produced form so that persons can use the system anywhere that oral languages are written (personal letters, newspapers, and media, academic research). The systematic examination of the International Sign Writing Alphabet (ISWA) as an equivalent usage structure to the International Phonetic Alphabet for spoken languages has been proposed. According to some researchers, SignWriting is not a phonemic orthography and does not have a one-to-one map from phonological forms to written forms. This assertion has been disputed and the process for each country to look at the ISWA and create a phonemic/morphemic assignment of features of each sign language was proposed by researchers Msc. Roberto Cesar Reis da Costa and Madson Barreto in a thesis forum on June 23, 2014. The SignWriting community has an open project on Wikimedia Labs to support the various Wikimedia projects on Wikimedia Incubator and elsewhere involving SignWriting. The ASL Wikipedia request was marked as eligible in 2008 and the test ASL Wikipedia has 50 articles written in ASL using SignWriting.

The most widely used transcription system among academics is HamNoSys, developed at the University of Hamburg. Based on Stokoe Notation, HamNoSys was expanded to about 200 graphs in order to allow transcription of any sign language. Phonological features are usually indicated with single symbols, though the group of features that make up a handshape is indicated collectively with a symbol.

Several additional candidates for written ASL have appeared over the years, including SignFont, ASL-phabet, and Si5s.

For English-speaking audiences, ASL is often glossed using English words. These glosses are typically all-capitalized and are arranged in ASL order. For example, the ASL sentence DOG NOW CHASE>IX=3 CAT, meaning "the dog is chasing the cat", uses NOW to mark ASL progressive aspect and shows ASL verbal inflection for the third person (written with >IX=3). However, glossing is not used to write the language for speakers of ASL.

Each sign in ASL is composed of a number of distinctive components, generally referred to as parameters. A sign may use one hand or both. All signs can be described using the five parameters involved in signed languages, which are handshape, movement, palm orientation, location and non-manual markers. Just as phonemes of sound distinguish meaning in spoken languages, these parameters are the phonemes that distinguish meaning in signed languages like ASL. Changing any one of these may change the meaning of a sign, as illustrated by the ASL signs THINK and DISAPPOINTED:
There are also meaningful non-manual signals in ASL. This may include movement of the eyebrows, the cheeks, the nose, the head, the torso, and the eyes.

William Stokoe proposed that these components are analogous to the phonemes of spoken languages. There has also been a proposal that these are analogous to classes like place and manner of articulation. As in spoken languages, these phonological units can be split into distinctive features. For instance, the handshapes /2/ and /3/ are distinguished by the presence or absence of the feature [± closed thumb], as illustrated to the right. ASL has processes of allophony and phonotactic restrictions. There is ongoing research into whether ASL has an analog of syllables in spoken language.

ASL has a rich system of verbal inflection. This involves both grammatical aspect—how the action of verbs flows in time—and agreement marking. Aspect can be marked by changing the manner of movement of the verb; for example, continuous aspect is marked by incorporating rhythmic, circular movement, while punctual aspect is achieved by modifying the sign so that it has a stationary hand position. Verbs may agree with both the subject and the object, and are marked for number and reciprocity. Reciprocity is indicated by using two one-handed signs; for example, the sign SHOOT, made with an L-shaped handshape with inward movement of the thumb, inflects to SHOOT, articulated by having two L-shaped hands "shooting" at each other.

ASL has a productive system of classifiers, which are used to classify objects and their movement in space. For example, a rabbit running downhill would use a classifier consisting of a bent V classifier handshape with a downhill-directed path; if the rabbit is hopping, the path is executed with a bouncy manner. In general, classifiers are composed of a "classifier handshape" bound to a "movement root". The classifier handshape represents the object as a whole, incorporating such attributes as surface, depth, and shape, and is usually very iconic. The movement root consists of a path, a direction and a manner.

ASL possesses a set of 26 signs known as the American manual alphabet, which can be used to spell out words from the English language. These signs make use of the 19 handshapes of ASL. For example, the signs for 'p' and 'k' use the same handshape but different orientations. A common misconception is that ASL consists only of fingerspelling; although such a method (Rochester Method) has been used, it is not ASL.

Fingerspelling is a form of borrowing, a linguistic process wherein words from one language are incorporated into another. In ASL, fingerspelling is used for proper nouns and for technical terms with no native ASL equivalent. There are also some other loan words which are fingerspelled, either very short English words or abbreviations of longer English words, e.g. "O-N" from English 'on', and "A-P-T" from English 'apartment'. Fingerspelling may also be used to emphasize a word that would normally be signed otherwise.

ASL is a subject–verb–object (SVO) language with various phenomena affecting this basic word order. Basic SVO sentences are signed without any pauses:

However, other word orders may also occur, as ASL allows the topic of a sentence to be moved to sentence-initial position, a phenomenon known as topicalization. In object-subject-verb (OSV) sentences, the object is topicalized, marked by a forward head-tilt and a pause:
Even more, word orders can be obtained through the phenomenon of subject copy. In subject copy, the subject is repeated at the end of the sentence, accompanied by head nodding, either for clarification or emphasis:

ASL also allows null subject sentences, where the subject is implied rather than stated explicitly. Subjects can be copied even in a null subject sentence, in which the subject is omitted from its original position, yielding a verb–object–subject (VOS) construction:

Topicalization, accompanied with a null subject and a subject copy, can produce yet another word order, object–verb–subject (OVS).

These properties of ASL allow it a variety of word orders, leading many to question which is the true, underlying, "basic" order. There are several other proposals that attempt to account for the flexibility of word order in ASL. One proposal is that languages like ASL are best described with a topic–comment structure, where words are ordered by their importance in the sentence rather than by their syntactic properties. Another hypothesis is that ASL exhibits free word order, in which syntax is not encoded in word order whatsoever, but can be encoded by other means (e.g. head nods, eyebrow movement, body position).

A common misconception is that signs are iconically self-explanatory, that they are a transparent imitation of what they mean, or even that they are pantomime. In fact, many signs bear no resemblance to their referent, either because they were originally arbitrary symbols or because their iconicity has been obscured over time. Even so, in ASL iconicity plays a significant role; a high percentage of signs resemble their referents in some way. This may be due to the fact that the medium of sign—three-dimensional space—naturally allows more iconicity than oral language.

In the era of the influential linguist Ferdinand de Saussure, it was assumed that the mapping between form and meaning in language must be completely arbitrary. Although onomatopoeia is a clear exception, since words like 'choo-choo' bear clear resemblance to the sounds that they mimic, the Saussurean approach was to treat these as marginal exceptions. ASL, with its significant inventory of iconic signs, directly challenges this theory.

Research on acquisition of pronouns in ASL has shown that children do not always take advantage of the iconic properties of signs when interpreting their meaning. It has been found that when children acquire the pronoun "you", the iconicity of the point (at the child) is often confused, being treated more like a name. This is a similar finding to research in oral languages on pronoun acquisition. It has also been found that iconicity of signs does not affect immediate memory and recall; less iconic signs are remembered just as well as highly iconic signs.




</doc>
<doc id="1202" url="https://en.wikipedia.org/wiki?curid=1202" title="Applet">
Applet

In computing, an applet is any small application that performs one specific task that runs within the scope of a dedicated widget engine or a larger program, often as a plug-in. The term is frequently used to refer to a Java applet, a program written in the Java programming language that is designed to be placed on a web page. Applets are typical examples of transient and auxiliary applications that don't monopolize the user's attention. Applets are not full-featured application programs, and are intended to be easily accessible.

The word "applet" was first used in 1990 in PC Magazine. However, the concept of an applet, or more broadly a small interpreted program downloaded and executed by the user, dates at least to RFC 5 (1969) by Jeff Rulifson, which described the Decode-Encode Language (DEL), which was designed to allow remote use of the oN-Line System (NLS) over ARPANET, by downloading small programs to enhance the interaction. This has been specifically credited as a forerunner of Java's downloadable programs in RFC 2555.
Applet is an event driven program .

In some cases, an applet does not run independently. These applets must run either in a container provided by a host program, through a plugin, or a variety of other applications including mobile devices that support the applet programming model.

Applets were used to provide interactive features to web applications that historically could not be provided by HTML alone. They could capture mouse input and also had controls like buttons or check boxes. In response to the user action an applet could change the provided graphic content. This made applets well suitable for demonstration, visualization, and teaching. There were online applet collections for studying various subjects, from physics to heart physiology. Applets were also used to create online game collections that allowed players to compete against live opponents in real-time.

An applet could also be a text area only, providing, for instance, a cross platform command-line interface to some remote system. If needed, an applet could leave the dedicated area and run as a separate window. However, applets had very little control over web page content outside the applet dedicated area, so they were less useful for improving the site appearance in general (while applets like news tickers or WYSIWYG editors are also known). Applets could also play media in formats that are not natively supported by the browser.

HTML pages could embed parameters that were passed to the applet. Hence the same applet could appear differently depending on the parameters that were passed.

Examples of Web-based Applets include:


A larger application distinguishes its applets through several features:


A Java Applet is a java program that is launched from HTML and run in a web browser. It can provide web applications with interactive features that cannot be provided by HTML. Since Java's bytecode is platform-independent, Java applets can be executed by browsers running under many platforms, including Windows, Unix, macOS, and Linux. When a Java technology-enabled web browser processes a page that contains an applet, the applet's code is transferred to the client's system and executed by the browser's Java Virtual Machine (JVM). An HTML page references an applet either via the deprecated <applet> tag or via its replacement, the <object> tag.

Recent developments in the coding of applications including mobile and embedded systems have led to the awareness of the security of applets.

Applets in an open platform environment should provide secure interactions between different applications. A compositional approach can be used to provide security for open platform applets. Advanced compositional verification methods have been developed for secure applet interactions.

A Java applet contains different security models: unsigned Java applet security, signed Java applet security, and self signed Java applet security.

In an applet-enabled web browser, many methods can be used to provide applet security for malicious applets. A malicious applet can infect a computer system in many ways, including denial of service, invasion of privacy, and annoyance. A typical solution for malicious applets is to make the web browser to monitor applets' activities. This will result in a web browser that will enable the manual or automatic stopping of malicious applets. To illustrate this method, AppletGuard was used to observe and control any applet in a browser successfully.



</doc>
<doc id="1203" url="https://en.wikipedia.org/wiki?curid=1203" title="Alternate history">
Alternate history

Alternate history or alternative history (Commonwealth English) (AH) is a genre of speculative fiction consisting of stories in which one or more historical events occur differently. These stories usually contain "what if" scenarios at crucial points in history and present outcomes other than those in the historical record. The stories are conjectural but are sometimes based on fact. Alternate history has been seen as a subgenre of literary fiction, science fiction, or historical fiction; alternate history works may use tropes from any or all of these genres. Another term occasionally used for the genre is "allohistory" (literally "other history").

Since the 1950s, this type of fiction has, to a large extent, merged with science fiction tropes involving time travel between alternate histories, psychic awareness of the existence of one universe by the people in another, or time travel that results in history splitting into two or more timelines. Cross-time, time-splitting, and alternate history themes have become so closely interwoven that it is impossible to discuss them fully apart from one another.

In Spanish, French, German, Portuguese, Italian, Catalan and Galician, the genre of alternate history is called "uchronie / ucronia / ucronía / Uchronie", which has given rise to the term "Uchronia" in English. This neologism is based on the prefix (which in Ancient Greek means "not/not any/no") and the Greek (), meaning "time". A "uchronia" means literally "(in) no time". This term apparently also inspired the name of the alternate history book list, "".

The Collins English Dictionary defines alternative history as "a genre of fiction in which the author speculates on how the course of history might have been altered if a particular historical event had had a different outcome." According to Steven H Silver, an American science fiction editor, alternate history requires three things: a point of divergence from the history of our world prior to the time at which the author is writing, a change that would alter history as it is known, and an examination of the ramifications of that change.

Several genres of fiction have been misidentified as alternate history. Science fiction set in what was the future but is now the past, like Arthur C. Clarke's "" or George Orwell's "Nineteen Eighty-Four", is not alternate history because the author did not make the choice to change the past at the time of writing. Secret history, which can take the form of fiction or nonfiction, documents events that may or may not have happened historically but did not have an effect on the overall outcome of history, and so is not to be confused with alternate history. 

Alternate history is related to, but distinct from, counterfactual history. This term is used by some professional historians to describe the practice of using thoroughly researched and carefully reasoned speculations on "what might have happened if..." as a tool of academic historical research, as opposed to a literary device.

The earliest example of alternate (or counterfactual) history is found in Livy's "Ab Urbe Condita Libri" (book IX, sections 17–19). Livy contemplated an alternative 4th century BC in which Alexander the Great had survived to attack Europe as he had planned; asking, "What would have been the results for Rome if she had been engaged in a war with Alexander?" Livy concluded that the Romans would likely have defeated Alexander.

Another example of counterfactual was posited by cardinal and Doctor of the Church Peter Damian in the 11th century. In his famous work "De Divina Omnipotentia", a long letter in which he discusses God's omnipotence, he treats questions related to the limits of divine power, including the question of whether God can change the past, for example, bringing about that Rome was never founded:I see I must respond finally to what many people, on the basis of your holiness’s [own] judgment, raise as an objection on the topic of this dispute. For they say: If, as you assert, God is omnipotent in all things, can he manage this, that things that have been made were not made? He can certainly destroy all things that have been made, so that they do not exist now. But it cannot be seen how he can bring it about that things that have been made were not made. To be sure, it can come about that from now on and hereafter Rome does not exist; for it can be destroyed. But no opinion can grasp how it can come about that it was not founded long ago...One early work of fiction detailing an alternate history is Joanot Martorell's 1490 epic romance "Tirant lo Blanch", which was written when the loss of Constantinople to the Turks was still a recent and traumatic memory for Christian Europe. It tells the story of the knight Tirant the White from Brittany who travels to the embattled remnants of the Byzantine Empire. He becomes a Megaduke and commander of its armies and manages to fight off the invading Ottoman armies of . He saves the city from Islamic conquest, and even chases the Turks deeper into lands they had previously conquered.

One of the earliest works of alternate history published in large quantities for the reception of a large audience may be Louis Geoffroy's "Histoire de la Monarchie universelle: Napoléon et la conquête du monde (1812–1832)" (History of the Universal Monarchy: Napoleon and the Conquest of the World) (1836), which imagines Napoleon's First French Empire emerging victorious in the French invasion of Russia in 1811 and in an invasion of England in 1814, later unifying the world under Bonaparte's rule.

In the English language, the first known complete alternate history is Nathaniel Hawthorne's short story "P.'s Correspondence", published in 1845. It recounts the tale of a man who is considered "a madman" due to his perceptions of a different 1845, a reality in which long-dead famous people, such as the poets Robert Burns, Lord Byron, Percy Bysshe Shelley and John Keats, the actor Edmund Kean, the British politician George Canning, and even Napoleon Bonaparte, are still alive.

The first novel-length alternate history in English would seem to be Castello Holford's "Aristopia" (1895). While not as nationalistic as Louis Geoffroy's "Napoléon et la conquête du monde, 1812–1823", "Aristopia" is another attempt to portray a Utopian society. In "Aristopia", the earliest settlers in Virginia discover a reef made of solid gold and are able to build a Utopian society in North America.

A number of alternate history stories and novels appeared in the late 19th and early 20th centuries (see, for example, Charles Petrie's "If: A Jacobite Fantasy" [1926]). In 1931, British historian Sir John Squire collected a series of essays from some of the leading historians of the period for his anthology "If It Had Happened Otherwise". In this work, scholars from major universities (as well as important non-academic authors) turned their attention to such questions as "If the Moors in Spain Had Won" and "If Louis XVI Had Had an Atom of Firmness". The essays range from serious scholarly efforts to Hendrik Willem van Loon's fanciful and satiric portrayal of an independent 20th century Dutch city state on the island of Manhattan. Among the authors included were Hilaire Belloc, André Maurois, and Winston Churchill.
One of the entries in Squire's volume was Churchill's "If Lee Had Not the Battle of Gettysburg", written from the viewpoint of a historian in a world where the Confederate States of America had won the American Civil War. The entry considers what would have happened if the North had been victorious (in other words, a character from an alternate world imagines a world more like the real one we live in, although not identical in every detail). Speculative work that narrates from the point of view of an alternate history is variously known as "recursive alternate history", a "double-blind what-if", or an "alternate-alternate history". Churchill's essay was one of the influences behind Ward Moore's alternate history novel "Bring the Jubilee", in which General Robert E. Lee won the Battle of Gettysburg, paving the way for the eventual victory of the Confederacy in the American Civil War (named the "War of Southron Independence" in this timeline). The protagonist, autodidact Hodgins Backmaker, travels back to the aforementioned battle and inadvertently changes history, resulting in the emergence of our own timeline and the consequent victory of the Union instead.

American humorist author James Thurber parodied alternate history stories about the American Civil War in his 1930 story "If Grant Had Been Drinking at Appomattox", which he accompanied with this very brief introduction: ""Scribner's" magazine is publishing a series of three articles: 'If Booth Had Missed Lincoln', 'If Lee Had Won the Battle of Gettysburg', and 'If Napoleon Had Escaped to America'. This is the fourth."

Another example of alternate history from this period (and arguably the first to explicitly posit cross-time travel from one universe to another as anything more than a visionary experience) is H.G. Wells' "Men Like Gods" (1923), in which several Englishmen are transferred via an accidental encounter with a cross-time machine into an alternate universe featuring a seemingly pacifistic and utopian Britain. When the Englishmen, led by a satiric figure based on Winston Churchill, try to seize power, the utopians simply point a ray gun at them and send them on to someone else's universe. Wells describes a multiverse of alternative worlds, complete with the paratime travel machines that would later become popular with US pulp writers. However, since his hero experiences only a single alternate world, this story is not very different from conventional alternate history.

In the 1930s, alternate history moved into a new arena. The December 1933 issue of "Astounding" published Nat Schachner's "Ancestral Voices", which was quickly followed by Murray Leinster's "Sidewise in Time". While earlier alternate histories examined reasonably straightforward divergences, Leinster attempted something completely different. In his "World gone mad", pieces of Earth traded places with their analogs from different timelines. The story follows Professor Minott and his students from a fictitious Robinson College as they wander through analogues of worlds that followed a different history.

A somewhat similar approach was taken by Robert A. Heinlein in his 1941 novelette "Elsewhen", in which a professor trains his mind to move his body across timelines. He then hypnotizes his students so they can explore more of them. Eventually each settles into the reality most suitable for him or her. Some of the worlds they visit are mundane, some very odd; others follow science fiction or fantasy conventions.

World War II produced alternate history for propaganda: both British and American authors wrote works depicting Nazi invasions of their respective countries as cautionary tales.

The period around World War II also saw the publication of the time travel novel "Lest Darkness Fall" by L. Sprague de Camp, in which an American academic travels to Italy at the time of the Byzantine invasion of the Ostrogoths. De Camp's time traveler, Martin Padway, is depicted as making permanent historical changes and implicitly forming a new time branch, thereby making the work an alternate history.

Time travel as the cause of a point of divergence (POD), which can denote either the bifurcation of a historical timeline or a simple replacement of the future that existed before the time traveling event, has continued to be a popular theme. In Ward Moore's "Bring the Jubilee", the protagonist lives in an alternate history in which the Confederacy has won the American Civil War; he travels backward through time, and brings about a Union victory in the Battle of Gettysburg.

When a story's assumptions about the nature of time travel lead to the complete replacement of the visited time's future rather than just the creation of an additional time line, the device of a "time patrol" is often used, most notably in Poul Anderson's "Time Patrol" collection—where guardians race uptime and downtime to preserve the "correct" history. In the most celebrated of this series, "Delenda Est", the interference of time traveling outlaws causes Carthage to win the Second Punic War and destroy Rome with massive consequences for the present day.

A more recent example is "Making History" by Stephen Fry, in which a time machine is used to alter history so that Adolf Hitler was never born. This ironically results in a more competent leader of the Third Reich, resulting in the country's ascendancy and longevity in this altered timeline.

H.G. Wells' "cross-time" or "many universes" variant (see above) was fully developed by Murray Leinster in his 1934 short story "Sidewise in Time", in which sections of the Earth's surface begin changing places with their counterparts in alternate timelines.

Fredric Brown employed this subgenre to satirize the science fiction pulps and their adolescent readers—and fears of foreign invasion—in the classic "What Mad Universe" (1949). In Clifford D. Simak's "Ring Around the Sun" (1953), the hero ends up in an alternate earth of thick forests in which humanity never developed but a band of mutants is establishing a colony; the story line appears to frame the author's anxieties regarding McCarthyism and the Cold War.

In the late 1940s and the 1950s, however, writers such as H. Beam Piper, Sam Merwin, Jr. and Andre Norton wrote stories set in a multiverse in which all alternate histories are co-existent and travel between them occurs via a technology involving portals and/or paratime transporter machinery. These authors established the convention of a secret paratime trading empire that exploits and/or protects worlds lacking the paratime technology via a network of secret agents (Piper called them the "paratime police").

This concept provided a convenient framing for packing a smörgåsbord of historical alternatives (and even of timeline "branches") into a single novel, either via the hero chasing or being chased by the villain(s) through multiple worlds or (less artfully) via discussions between the paratime cops and their superiors (or between paratime agents and new recruits) regarding the histories of such worlds.

The paratime theme is sometimes used without the police; for example, Poul Anderson had the Old Phoenix tavern as a nexus between alternate histories. A character from a modern American alternate history "Operation Chaos" can thus appear in the English Civil War setting of "A Midsummer's Tempest". In this context, the distinction between an alternate history and a parallel universe with some points in common but no common history may not be feasible, as the writer may not provide enough information to distinguish between them.

Paratime stories published in recent decades often cite the many-worlds interpretation of quantum mechanics (first formulated by Hugh Everett III in 1957) to account for the differing worlds. Some science fiction writers interpret the splitting of worlds to depend on human decision-making and free will, while others rely on the butterfly effect from chaos theory to amplify random differences at the atomic or subatomic level into a macroscopic divergence at some specific point in history; either way, science fiction writers usually have all changes flow from a particular historical point of divergence (often abbreviated 'POD' by fans of the genre). Prior to Everett, science-fiction writers drew on higher dimensions and the speculations of P. D. Ouspensky to explain their characters' cross-time journeys.

While many justifications for alternate histories involve a multiverse, the "many world" theory would naturally involve many worlds, in fact a continually exploding array of universes. In quantum theory, new worlds would proliferate with every quantum event, and even if the writer uses human decisions, every decision that could be made differently would result in a different timeline. A writer's fictional multiverse may, in fact, preclude some decisions as humanly impossible, as when, in "Night Watch", Terry Pratchett depicts a character informing Vimes that while anything that can happen, has happened, nevertheless there is no history whatsoever in which Vimes has ever murdered his wife. When the writer explicitly maintains that "all" possible decisions are made in all possible ways, one possible conclusion is that the characters were neither brave, nor clever, nor skilled, but simply lucky enough to happen on the universe in which they did not choose the cowardly route, take the stupid action, fumble the crucial activity, etc.; few writers focus on this idea, although it has been explored in stories such as Larry Niven's story "All the Myriad Ways", where the reality of all possible universes leads to an epidemic of suicide and crime because people conclude their choices have no moral import.

In any case, even if it is true that every possible outcome occurs in some world, it can still be argued that traits such as bravery and intelligence might still affect the relative frequency of worlds in which better or worse outcomes occurred (even if the total number of worlds with each type of outcome is infinite, it is still possible to assign a different measure to different infinite sets). The physicist David Deutsch, a strong advocate of the many-worlds interpretation of quantum mechanics, has argued along these lines, saying that "By making good choices, doing the right thing, we thicken the stack of universes in which versions of us live reasonable lives. When you succeed, all the copies of you who made the same decision succeed too. What you do for the better increases the portion of the multiverse where good things happen." This view is perhaps somewhat too abstract to be explored directly in science fiction stories, but a few writers have tried, such as Greg Egan in his short story "The Infinite Assassin", where an agent is trying to contain reality-scrambling "whirlpools" that form around users of a certain drug, and the agent is constantly trying to maximize the consistency of behavior among his alternate selves, attempting to compensate for events and thoughts he experiences, he guesses are of low measure relative to those experienced by most of his other selves.

Many writers—perhaps the majority—avoid the discussion entirely. In one novel of this type, H. Beam Piper's "Lord Kalvan of Otherwhen", a Pennsylvania State Police officer, who knows how to make gunpowder, is transported from our world to an alternate universe where the recipe for gunpowder is a tightly held secret and saves a country that is about to be conquered by its neighbors. The paratime patrol members are warned against going into the timelines immediately surrounding it, where the country "will" be overrun, but the book never depicts the slaughter of the innocent thus entailed, remaining solely in the timeline where the country is saved.

The cross-time theme was further developed in the 1960s by Keith Laumer in the first three volumes of his "Imperium" sequence, which would be completed in "Zone Yellow" (1990). Piper's politically more sophisticated variant was adopted and adapted by Michael Kurland and Jack Chalker in the 1980s; Chalker's "G.O.D. Inc" trilogy (1987–89), featuring paratime detectives Sam and Brandy Horowitz, marks the first attempt at merging the paratime thriller with the police procedural. Kurland's "Perchance" (1988), the first volume of the never-completed "Chronicles of Elsewhen", presents a multiverse of secretive cross-time societies that utilize a variety of means for cross-time travel, ranging from high-tech capsules to mutant powers. Harry Turtledove has launched the Crosstime Traffic series for teenagers featuring a variant of H. Beam Piper's paratime trading empire.

The concept of a cross-time version of a world war, involving rival paratime empires, was developed in Fritz Leiber's Change War series, starting with the Hugo Award winning "The Big Time" (1958); followed by Richard C. Meredith's "Timeliner" trilogy in the 1970s, Michael McCollum's "A Greater Infinity" (1982) and John Barnes' "Timeline Wars" trilogy in the 1990s.

Such "paratime" stories may include speculation that the laws of nature can vary from one universe to the next, providing a science fictional explanation—or veneer—for what is normally fantasy. Aaron Allston's "Doc Sidhe" and "Sidhe Devil" take place between our world, the "grim world" and an alternate "fair world" where the Sidhe retreated to. Although technology is clearly present in both worlds, and the "fair world" parallels our history, about fifty years out of step, there is functional magic in the fair world. Even with such explanation, the more explicitly the alternate world resembles a normal fantasy world, the more likely the story is to be labelled fantasy, as in Poul Anderson's "House Rule" and "Loser's Night". In both science fiction and fantasy, whether a given parallel universe is an alternate history may not be clear. The writer might allude to a POD only to explain the existence and make no use of the concept, or may present the universe without explanation of its existence.

Isaac Asimov's short story "What If—" (1952) is about a couple who can explore alternate realities by means of a television-like device. This idea can also be found in Asimov's novel "The End of Eternity" (1955), in which the "Eternals" can change the realities of the world, without people being aware of it. Poul Anderson's "Time Patrol" stories feature conflicts between forces intent on changing history and the Patrol who work to preserve it. One story describes a world in which Carthage triumphed over the Roman Republic. "The Big Time", by Fritz Leiber, describes a Change War ranging across all of history.

Keith Laumer's "Worlds of the Imperium" is one of the earliest alternate history novels; it was published by "Fantastic Stories of the Imagination" in 1961, in magazine form, and reprinted by Ace Books in 1962 as one half of an Ace Double. Besides our world, Laumer describes a world ruled by an Imperial aristocracy formed by the merger of European empires, in which the American Revolution never happened, and a third world in post-war chaos ruled by the protagonist's doppelganger.

Philip K. Dick's novel, "The Man in the High Castle" (1962), is an alternate history in which Nazi Germany and Imperial Japan won World War II. This book contains an example of "alternate-alternate" history, in that one of its characters authored a book depicting a reality in which the Allies won the war, itself divergent from real-world history in several aspects. One character is transported into a version of San Francisco that closely resembles the real-world city. He is horrified by its ugliness and chaos, compared to the vibrancy and order of the Japanese-dominated city in his world.

Vladimir Nabokov's novel, "" (1969), is a story of incest that takes place within an alternate North America settled in part by Czarist Russia and that borrows from Dick's idea of "alternate-alternate" history (the world of Nabokov's hero is wracked by rumors of a "counter-earth" that apparently is ours). Some critics believe that the references to a counter-earth suggest that the world portrayed in "Ada" is a delusion in the mind of the hero (another favorite theme of Dick's novels). Strikingly, the characters in "Ada" seem to acknowledge their own world as the copy or negative version, calling it "Anti-Terra", while its mythical twin is the real "Terra". Like history, science has followed a divergent path on Anti-Terra: it boasts all the same technology as our world, but all based on water instead of electricity; e.g., when a character in "Ada" makes a long-distance call, all the toilets in the house flush at once to provide hydraulic power.

Guido Morselli described the defeat of Italy (and subsequently France) in World War I in his novel, "Past Conditional" (1975; ), wherein the static Alpine front line which divided Italy from Austria during that war collapses when the Germans and the Austrians forsake trench warfare and adopt blitzkrieg twenty years in advance.

Kingsley Amis set his novel, "The Alteration" (1976), in the 20th century, but major events in the Reformation did not take place, and Protestantism is limited to the breakaway Republic of New England. Martin Luther was reconciled to the Roman Catholic Church and later became Pope Germanian I.

Kim Stanley Robinson's novel, "The Years of Rice and Salt" (2002), starts at the point of divergence with Timur turning his army away from Europe, and the Black Death has killed 99% of Europe's population, instead of only a third. Robinson explores world history from that point in AD 1405 (807 AH) to about AD 2045 (1467 AH). Rather than following the great man theory of history, focusing on leaders, wars, and major events, Robinson writes more about social history, similar to the Annales School of history theory and Marxist historiography, focusing on the lives of ordinary people living in their time and place.

Philip Roth's novel, "The Plot Against America" (2004), looks at an America where Franklin D. Roosevelt is defeated in 1940 in his bid for a third term as President of the United States, and Charles Lindbergh is elected, leading to a US that features increasing fascism and anti-Semitism.

Michael Chabon, occasionally an author of speculative fiction, contributed to the genre with his novel "The Yiddish Policemen's Union" (2007), which explores a world in which the State of Israel was destroyed in its infancy and many of the world's Jews instead live in a small strip of Alaska set aside by the US government for Jewish settlement. The story follows a Jewish detective solving a murder case in the Yiddish-speaking semi-autonomous city state of Sitka. Stylistically, Chabon borrows heavily from the noir and detective fiction genres, while exploring social issues related to Jewish history and culture. Apart from the alternate history of the Jews and Israel, Chabon also plays with other common tropes of alternate history fiction; in the book, Germany actually loses the war even "harder" than they did in reality, getting hit with a nuclear bomb instead of just simply losing a ground war (subverting the common "what if Germany won WWII?" trope).

The late 1980s and the 1990s saw a boom in popular-fiction versions of alternate history, fueled by the emergence of the prolific alternate history author Harry Turtledove, as well as the development of the steampunk genre and two series of anthologies—the "What Might Have Been" series edited by Gregory Benford and the "Alternate ..." series edited by Mike Resnick. This period also saw alternate history works by S. M. Stirling, Kim Stanley Robinson, Harry Harrison, Howard Waldrop, and others.

Since the late 1990s, Harry Turtledove has been the most prolific practitioner of alternate history and has been given the title "Master of Alternate History" by some. His books include those of Timeline 191 (a.k.a. Southern Victory, also known as TL-191), in which, while the Confederate States of America won the American Civil War, the Union and Imperial Germany defeat the Entente Powers in the two "Great War"s of the 1910s and 1940s (with a Nazi-esque Confederate government attempting to exterminate its Black population), and the Worldwar series, in which aliens invaded Earth during World War II. Other stories by Turtledove include "A Different Flesh", in which America was not colonized from Asia during the last ice age; "In the Presence of Mine Enemies", in which the Nazis won World War II; and "Ruled Britannia", in which the Spanish Armada succeeded in conquering Britain in the Elizabethan era, with William Shakespeare being given the task of writing the play that will motivate the Britons to rise up against their Spanish conquerors. He also co-authored a book with actor Richard Dreyfuss, "The Two Georges", in which the United Kingdom retained the American colonies, with George Washington and King George III making peace. He did a two-volume series in which the Japanese not only bombed Pearl Harbor but also invaded and occupied the Hawaiian Islands.

Perhaps the most incessantly explored theme in popular alternate history focuses on worlds in which the Nazis won World War Two. In some versions, the Nazis and/or Axis Powers conquer the entire world; in others, they conquer most of the world but a "Fortress America" exists under siege; while in others, there is a Nazi/Japanese Cold War comparable to the US/Soviet equivalent in 'our' timeline. "Fatherland" (1992), by Robert Harris, is set in Europe following the Nazi victory. Several writers have posited points of departure for such a world but then have injected time splitters from the future or paratime travel, for instance James P. Hogan's "The Proteus Operation". Norman Spinrad wrote "The Iron Dream" in 1972, which is intended to be a science fiction novel written by Adolf Hitler after fleeing from Europe to North America in the 1920s.

In Jo Walton's "Small Change" series, the United Kingdom made peace with Hitler before the involvement of the United States in World War II, and fascism slowly strangled the UK. Former House Speaker Newt Gingrich and William R. Forstchen have written a novel, "1945", in which the US defeated Japan but not Germany in World War II, resulting in a Cold War with Germany rather than the Soviet Union. Gingrich and Forstchen neglected to write the promised sequel; instead, they wrote a trilogy about the American Civil War, starting with "", in which the Confederates win a victory at the Battle of Gettysburg - however, after Lincoln responds by bringing Grant and his forces to the eastern theater, the Army of Northern Virginia is soon trapped and destroyed in Maryland, and the war ends within weeks. Also from that general era, Martin Cruz Smith, in his first novel, posited an independent American Indian nation following the defeat of Custer in "The Indians Won" (1970).

Beginning with "The Probability Broach" in 1980, L. Neil Smith wrote several novels that postulated the disintegration of the US Federal Government after Albert Gallatin joins the Whiskey Rebellion in 1794 and eventually leads to the creation of a libertarian utopia.

A recent time traveling splitter variant involves entire communities being shifted elsewhere to become the unwitting creators of new time branches. These communities are transported from the present (or the near-future) to the past or to another time-line via a natural disaster, the action of technologically advanced aliens, or a human experiment gone wrong. S. M. Stirling wrote the "Island in the Sea of Time" trilogy, in which Nantucket Island and all its modern inhabitants are transported to Bronze Age times to become the world's first superpower. In Eric Flint's 1632 series, a small town in West Virginia is transported to 17th century central Europe and drastically changes the course of the Thirty Years' War, which was then underway. John Birmingham's "Axis of Time" trilogy deals with the culture shock when a United Nations naval task force from 2021 finds itself back in 1942 helping the Allies against the Empire of Japan and the Germans (and doing almost as much harm as good in spite of its advanced weapons). Similarly, Robert Charles Wilson's "Mysterium" depicts a failed US government experiment which transports a small American town into an alternative version of the US run by believers in a form of Christianity known as Gnosticism, who are engaged in a bitter war with the "Spanish" in Mexico (the chief scientist at the laboratory where the experiment occurred is described as a Gnostic, and references to Christian Gnosticism appear repeatedly in the book).

Many fantasies and science fantasies are set in a world that has a history somewhat similar to our own world, but with magic added. Some posit points of divergence, but some also feature magic altering history all along. One example of a universe that is in part historically recognizable but also obeys different physical laws is Poul Anderson's "Three Hearts and Three Lions" in which the Matter of France is history, and the fairy folk are real and powerful. A partly familiar European history for which the author provides a point of divergence is Randall Garrett's "Lord Darcy" series: a monk systemizing magic rather than science, so the use of foxglove to treat heart disease is called superstition. The other great point of divergence in this timeline occurs in 1199, when Richard the Lionheart survives the Siege of Chaluz and returns to England, making the Angevin Empire so strong it survives into the 20th century.

"Jonathan Strange & Mr Norrell" takes place in an alternative version of England where a separate Kingdom ruled by the Raven King and founded on magic existed in Northumbria for over 300 years. In Patricia Wrede's Regency fantasies, Great Britain has a Royal Society of Wizards, and in Poul Anderson's "A Midsummer Tempest" William Shakespeare is remembered as the Great Historian, with the novel itself taking place in the era of Oliver Cromwell and Charles I, with an alternate outcome for the English Civil War and an earlier Industrial Revolution.

"The Tales of Alvin Maker" series by Orson Scott Card (a parallel to the life of Joseph Smith, founder of the Latter Day Saint movement) takes place in an alternate America, beginning in the early 19th century. Prior to that time, a POD occurred: England, under the control of Oliver Cromwell, had banished "makers", or anyone else demonstrating "knacks" (an ability to perform seemingly supernatural feats) to the North American continent. Thus the early American colonists embraced as perfectly ordinary these gifts, and counted on them as a part of their daily lives. The political division of the continent is considerably altered, with two large English colonies bookending a smaller "American" nation, one aligned with England, and the other governed by exiled Cavaliers. Actual historical figures are seen in a much different light: Ben Franklin is revered as the continent's finest "maker", George Washington was executed at the hands of an English army, and "Tom" Jefferson is the first president of "Appalachia", the result of a compromise between the Continentals and the British.

On the other hand, when the "Old Ones" still manifest themselves in England in Keith Roberts's "Pavane", which takes place in a technologically backward world after a Spanish assassination of Elizabeth I allowed the Spanish Armada to conquer England, the possibility that the fairies were real but retreated from modern advances makes the POD possible: the fairies really were present all along, in a secret history. Again, in the English Renaissance fantasy "Armor of Light" by Melissa Scott and Lisa A. Barnett, the magic used in the book, by Dr. John Dee and others, actually was practiced in the Renaissance; positing a secret history of effective magic makes this an alternate history with a POD, Sir Philip Sidney's surviving the Battle of Zutphen in 1586, and shortly thereafter saving the life of Christopher Marlowe.

Many works of fantasy posit a world in which known practitioners of magic were able to make it function, and where the consequences of such reality would not, in fact, disturb history to such an extent as to make it plainly alternate history. Many ambiguous alternate/secret histories are set in Renaissance or pre-Renaissance times, and may explicitly include a "retreat" from the world, which would explain the current absence of such phenomena.

When the magical version of our world's history is set in contemporary times, the distinction becomes clear between alternate history on the one hand and contemporary fantasy, using in effect a form of secret history (as when Josepha Sherman's "Son of Darkness" has an elf living in New York City, in disguise) on the other. In works such as Robert A. Heinlein's "Magic, Incorporated" where a construction company can use magic to rig up stands at a sporting event and Poul Anderson's "Operation Chaos" and its sequel "Operation Luna", where djinns are serious weapons of war—with atomic bombs—the use of magic throughout the United States and other modern countries makes it clear that this is not secret history—although references in "Operation Chaos" to degaussing the effects of cold iron make it possible that it is the result of a POD. The sequel clarifies this as the result of a collaboration of Einstein and Planck in 1901, resulting in the theory of "rhea tics". Henry Moseley applies this theory to "degauss the effects of cold iron and release the goetic forces." This results in the suppression of ferromagnetism and the re-emergence of magic and magical creatures.

Alternate history shades off into other fantasy subgenres when the use of actual, though altered, history and geography decreases, although a culture may still be clearly the original source; Barry Hughart's "Bridge of Birds" and its sequels take place in a fantasy world, albeit one clearly based on China, and with allusions to actual Chinese history, such as the Empress Wu. Richard Garfinkle's "Celestial Matters" incorporates ancient Chinese physics and Greek Aristotelian physics, using them as if factual.

A fantasy version of the paratime police was developed by children's writer Diana Wynne Jones in her "Chrestomanci" quartet (1977–1988), with wizards taking the place of high tech secret agents. Among the novels in this series, "Witch Week" stands out for its vivid depiction of a history alternate to that of Chrestomanci's own world rather than our own (and yet with a specific POD that turned it away from the "normal" history of most worlds visited by the wizard).

Terry Pratchett's works include several references to alternate histories of Discworld. "Men At Arms" observes that in millions of universes, Edward d'Eath became an obsessive recluse rather than the instigator of the plot that he is in the novel. In "Jingo", Vimes accidentally picks up a pocket organizer that should have gone down another leg of the Trousers of Time, and so can hear the organizer reporting on the deaths that would have occurred had his decision gone otherwise. Indeed, Discworld contains an equivalent of the Time Patrol in its History Monks. "Night Watch" revolves around a repair of history after a time traveller's murder of an important figure in Vimes's past. "Thief of Time" presents them functioning as a full-scale Time Patrol, ensuring that history occurs at all.

Alternate history has long been a staple of Japanese speculative fiction with such authors as Futaro Yamada and Ryō Hanmura writing novels set in recognizable historical settings with supernatural or science fiction elements present. In 1973, Ryō Hanmura wrote "Musubi no Yama Hiroku" which recreated 400 years of Japan's history from the perspective of a secret magical family with psychic abilities. The novel has since come to be recognized as a masterpiece of Japanese speculative fiction. Twelve years later, author Hiroshi Aramata wrote the groundbreaking "Teito Monogatari" which reimagined the history of Tokyo across the 20th century in a world heavily influenced by the supernatural.

The TV show "Sliders" explores different possible alternate realities by having the protagonist "slide" into different parallel dimensions of the same planet Earth.

The two-part play "Harry Potter and the Cursed Child" contains alternate timelines set within the world of Harry Potter.

In "World of Winx," the seven fairies- Bloom, Stella, Musa, Tecna, Flora, Aisha and Roxy- live on Earth, where humans are ignorant of the existence of fairies or belief in magic; much unlike the fourth season of "Winx Club", where they had brought all magic back to Earth by releasing its terrestrial fairies.

For the same reasons that this genre is explored by role-playing games, alternate history is also an intriguing backdrop for the storylines of many video games. A famous example of an alternate history game is "". Released in 1996, the game presents a point of divergence in 1946 where Albert Einstein goes back in time to prevent World War II from ever taking place by erasing Adolf Hitler from time after he is released from Landsberg Prison in 1924. He is successful in his mission, but in the process allows Joseph Stalin and the Soviet Union to become powerful enough to launch a massive campaign to conquer Europe.

In the "Civilization" series, the player guides a civilization from prehistory to the present day, creating radically altered versions of history on a long time-scale. Several scenarios recreate a particular period which becomes the "point of divergence" in an alternate history shaped by the player's actions. Popular examples in "Sid Meier's Civilization IV" include "Desert War", set in the Mediterranean theatre of World War II and featuring scripted events tied to possible outcomes of battles; "Broken Star", set in a hypothetical Russian civil war in 2010; and "Rhye's and Fall of Civilization", an 'Earth simulator' designed to mirror a history as closely as possible but incorporating unpredictable elements to provide realistic alternate settings.

In some games such as the "Metal Gear" and "Resident Evil" series, events that were originally intended to represent the near future at the time the games were originally released later ended up becoming alternate histories in later entries in those franchises. For example, "" (1990), set in 1999, depicted a near future that ended up becoming an alternate history in "Metal Gear Solid" (1998). Likewise, "Resident Evil" (1996) and "Resident Evil 2" (1998), both set in 1998, depicted near-future events that had later become an alternative history by the time "Resident Evil 4" (2005) was released.

In the 2009 steampunk shooter, "Damnation" is set on an alternate version of planet Earth, in the early part of the 20th century after the American Civil War, which had spanned over several decades, where steam engines replace combustion engines. The game sees the protagonists fighting off a rich industrialist who wants to do away with both the Union and Confederacy in one swift movement and turn the United States of America into a country called the "American Empire" with a totalitarian dictatorship.
"Crimson Skies" is one example of an alternate history spawning multiple interpretations in multiple genres. The stories and games in "Crimson Skies" take place in an alternate 1930s United States, where the nation crumbled into many hostile states following the effects of the Great Depression, the Great War, and Prohibition. With the road and railway system destroyed, commerce took to the skies, which led to the emergence of air pirate gangs who plunder the aerial commerce.

The game "Freedom Fighters" portrays a situation similar to that of the movie "Red Dawn" and "Red Alert 2", though less comically than the latter. The point of divergence is during World War II, where the Soviet Union develops an atomic bomb first and uses it on Berlin. With the balance of power and influence tipped in Russia's favor, history diverges; brief summaries at the beginning of the game inform the player of the Communist bloc's complete takeover of Europe by 1953, a different ending to the Cuban Missile Crisis, and the spread of Soviet influence into South America and Mexico.

Similarly, the 2007 video game "World in Conflict" is set in 1989, with the Soviet Union on the verge of collapse. The point of divergence is several months before the opening of the game, when Warsaw Pact forces staged a desperate invasion of Western Europe. As the game begins, a Soviet invasion force lands in Seattle, taking advantage of the fact that most of the US military is in Europe.

The game "", released in 2008, offered in alternate history campaign for the Imperial Japanese Navy, wherein Japan destroys all three carriers in the Battle of Midway, which follows with a successful invasion of the island. Because of this, the United States lacked any sort of aerial power to fight the Japanese, and is continuously forced into the defense.

"", released in February 2008, is an alternate history first person shooter where Winston Churchill died in 1931 from being hit by a taxi cab. Because of this, Great Britain lacks the charismatic leader needed to keep the country together and Nazi Germany successfully conquers Great Britain via Operation Sea Lion in 1940. Germany later conquers the rest of Europe, North Africa and the Middle East while mass-producing their wunderwaffe. The Axis launch a surprise invasion of an isolationist United States' Eastern Seaboard in 1953, which forces the country to surrender and submit to a puppet government.
Another alternate history game involving Nazis is "" in which Hitler died during the early days of World War II and thus, a much more effective leadership rose to power. Under the command of a new Führer (who is referred to as "Chancellor", and his real name is never revealed), Operation Sealion succeeds and the Nazis successfully conquer Britain, sparking a cold war between the Allied Powers and Germany.

The "Fallout" series of computer role-playing games is set in a divergent America, where history after World War II diverges from the real world to follow a retro-futuristic timeline. For example, fusion power was invented quite soon after the end of the war, but the transistor was never developed. The result was a future that has a 1950s 'World of Tomorrow' feel to it, with extremely high technology such as artificial intelligence implemented with thermionic valves and other technologies now considered obsolete.

Many game series by Swedish developer Paradox Interactive start off at a concise point in history, allowing the player to immerse in the role of a contemporary leader and alter the course of in-game history. The most prominent game with this setting is "Crusader Kings II".

"S.T.A.L.K.E.R." games have an alternate history at the Chernobyl Exclusion Zone, where a special area called "The Zone" is formed.

"" is set in an alternate 1960 in which the Nazis won the Second World War, also thanks to their acquisition of high technology. The sequel "" continues this, although being set in the conquered United States of America.

Fans of alternate history have made use of the internet from a very early point to showcase their own works and provide useful tools for those fans searching for anything alternate history, first in mailing lists and usenet groups, later in web databases and forums. There are even YouTube channels about alternate history, including AlternateHistoryHub. The "Usenet Alternate History List" was first posted on April 11, 1991, to the Usenet newsgroup rec.arts.sf-lovers. In May 1995, the dedicated newsgroup "soc.history.what-if" was created for showcasing and discussing alternate histories. Its prominence declined with the general migration from unmoderated usenet to moderated web forums, most prominently AlternateHistory.com, the self-described "largest gathering of alternate history fans on the internet" with over 10,000 active members.

In addition to these discussion forums, in 1997 was created as an online repository, now containing over 2,900 alternate history novels, stories, essays, and other printed materials in several different languages. Uchronia was selected as the Sci Fi Channel's "Sci Fi Site of the Week" twice.

Collaborative attempts by several amateur writers have led to notable accomplishments. The contributors at Ill Bethisad have made two constructed languages: Brithenig and Wenedyk.





</doc>
<doc id="1206" url="https://en.wikipedia.org/wiki?curid=1206" title="Atomic orbital">
Atomic orbital

In atomic theory and quantum mechanics, an atomic orbital is a mathematical function that describes the wave-like behavior of either one electron or a pair of electrons in an atom. This function can be used to calculate the probability of finding any electron of an atom in any specific region around the atom's nucleus. The term "atomic orbital" may also refer to the physical region or space where the electron can be calculated to be present, as defined by the particular mathematical form of the orbital.

Each orbital in an atom is characterized by a unique set of values of the three quantum numbers , , and , which respectively correspond to the electron's energy, angular momentum, and an angular momentum vector component (the magnetic quantum number). Each such orbital can be occupied by a maximum of two electrons, each with its own spin quantum number . The simple names s orbital, p orbital, d orbital and f orbital refer to orbitals with angular momentum quantum number and respectively. These names, together with the value of , are used to describe the electron configurations of atoms. They are derived from the description by early spectroscopists of certain series of alkali metal spectroscopic lines as sharp, principal, diffuse, and fundamental. Orbitals for > 3 continue alphabetically, omitting j (g, h, i, k, ...) because some languages do not distinguish between the letters "i" and "j".

Atomic orbitals are the basic building blocks of the atomic orbital model (alternatively known as the electron cloud or wave mechanics model), a modern framework for visualizing the submicroscopic behavior of electrons in matter. In this model the electron cloud of a multi-electron atom may be seen as being built up (in approximation) in an electron configuration that is a product of simpler hydrogen-like atomic orbitals. The repeating "periodicity" of the blocks of 2, 6, 10, and 14 elements within sections of the periodic table arises naturally from the total number of electrons that occupy a complete set of s, p, d and f atomic orbitals, respectively, although for higher values of the quantum number , particularly when the atom in question bears a positive charge, the energies of certain sub-shells become very similar and so the order in which they are said to be populated by electrons (e.g. Cr = [Ar]4s3d and Cr = [Ar]3d) can only be rationalized somewhat arbitrarily.

With the development of quantum mechanics and experimental findings (such as the two slit diffraction of electrons), it was found that the orbiting electrons around a nucleus could not be fully described as particles, but needed to be explained by the wave-particle duality. In this sense, the electrons have the following properties:

Wave-like properties:

Particle-like properties:

Thus, despite the popular analogy to planets revolving around the Sun, electrons cannot be described simply as solid particles. In addition, atomic orbitals do not closely resemble a planet's elliptical path in ordinary atoms. A more accurate analogy might be that of a large and often oddly shaped "atmosphere" (the electron), distributed around a relatively tiny planet (the atomic nucleus). Atomic orbitals exactly describe the shape of this "atmosphere" only when a single electron is present in an atom. When more electrons are added to a single atom, the additional electrons tend to more evenly fill in a volume of space around the nucleus so that the resulting collection (sometimes termed the atom's "electron cloud") tends toward a generally spherical zone of probability describing the electron's location, because of the uncertainty principle.

Atomic orbitals may be defined more precisely in formal quantum mechanical language. Specifically, in quantum mechanics, the state of an atom, i.e., an eigenstate of the atomic Hamiltonian, is approximated by an expansion (see configuration interaction expansion and basis set) into linear combinations of anti-symmetrized products (Slater determinants) of one-electron functions. The spatial components of these one-electron functions are called atomic orbitals. (When one considers also their spin component, one speaks of atomic spin orbitals.) A state is actually a function of the coordinates of all the electrons, so that their motion is correlated, but this is often approximated by this independent-particle model of products of single electron wave functions. (The London dispersion force, for example, depends on the correlations of the motion of the electrons.)

In atomic physics, the atomic spectral lines correspond to transitions (quantum leaps) between quantum states of an atom. These states are labeled by a set of quantum numbers summarized in the term symbol and usually associated with particular electron configurations, i.e., by occupation schemes of atomic orbitals (for example, 1s 2s 2p for the ground state of neon—term symbol: S).

This notation means that the corresponding Slater determinants have a clear higher weight in the configuration interaction expansion. The atomic orbital concept is therefore a key concept for visualizing the excitation process associated with a given transition. For example, one can say for a given transition that it corresponds to the excitation of an electron from an occupied orbital to a given unoccupied orbital. Nevertheless, one has to keep in mind that electrons are fermions ruled by the Pauli exclusion principle and cannot be distinguished from the other electrons in the atom. Moreover, it sometimes happens that the configuration interaction expansion converges very slowly and that one cannot speak about simple one-determinant wave function at all. This is the case when electron correlation is large.

Fundamentally, an atomic orbital is a one-electron wave function, even though most electrons do not exist in one-electron atoms, and so the one-electron view is an approximation. When thinking about orbitals, we are often given an orbital visualization heavily influenced by the Hartree–Fock approximation, which is one way to reduce the complexities of molecular orbital theory.

Atomic orbitals can be the hydrogen-like "orbitals" which are exact solutions to the Schrödinger equation for a hydrogen-like "atom" (i.e., an atom with one electron). Alternatively, atomic orbitals refer to functions that depend on the coordinates of one electron (i.e., orbitals) but are used as starting points for approximating wave functions that depend on the simultaneous coordinates of all the electrons in an atom or molecule. The coordinate systems chosen for atomic orbitals are usually spherical coordinates in atoms and cartesians in polyatomic molecules. The advantage of spherical coordinates (for atoms) is that an orbital wave function is a product of three factors each dependent on a single coordinate: . The angular factors of atomic orbitals generate s, p, d, etc. functions as real combinations of spherical harmonics (where and are quantum numbers). There are typically three mathematical forms for the radial functions  which can be chosen as a starting point for the calculation of the properties of atoms and molecules with many electrons:


Although hydrogen-like orbitals are still used as pedagogical tools, the advent of computers has made STOs preferable for atoms and diatomic molecules since combinations of STOs can replace the nodes in hydrogen-like atomic orbital. Gaussians are typically used in molecules with three or more atoms. Although not as accurate by themselves as STOs, combinations of many Gaussians can attain the accuracy of hydrogen-like orbitals.

The term "orbital" was coined by Robert Mulliken in 1932 as an abbreviation for "one-electron orbital wave function". However, the idea that electrons might revolve around a compact nucleus with definite angular momentum was convincingly argued at least 19 years earlier by Niels Bohr, and the Japanese physicist Hantaro Nagaoka published an orbit-based hypothesis for electronic behavior as early as 1904. Explaining the behavior of these electron "orbits" was one of the driving forces behind the development of quantum mechanics.

With J. J. Thomson's discovery of the electron in 1897, it became clear that atoms were not the smallest building blocks of nature, but were rather composite particles. The newly discovered structure within atoms tempted many to imagine how the atom's constituent parts might interact with each other. Thomson theorized that multiple electrons revolved in orbit-like rings within a positively charged jelly-like substance, and between the electron's discovery and 1909, this "plum pudding model" was the most widely accepted explanation of atomic structure.

Shortly after Thomson's discovery, Hantaro Nagaoka predicted a different model for electronic structure. Unlike the plum pudding model, the positive charge in Nagaoka's "Saturnian Model" was concentrated into a central core, pulling the electrons into circular orbits reminiscent of Saturn's rings. Few people took notice of Nagaoka's work at the time, and Nagaoka himself recognized a fundamental defect in the theory even at its conception, namely that a classical charged object cannot sustain orbital motion because it is accelerating and therefore loses energy due to electromagnetic radiation. Nevertheless, the Saturnian model turned out to have more in common with modern theory than any of its contemporaries.

In 1909, Ernest Rutherford discovered that the bulk of the atomic mass was tightly condensed into a nucleus, which was also found to be positively charged. It became clear from his analysis in 1911 that the plum pudding model could not explain atomic structure. In 1913 as Rutherford's post-doctoral student, Niels Bohr proposed a new model of the atom, wherein electrons orbited the nucleus with classical periods, but were only permitted to have discrete values of angular momentum, quantized in units "h"/2π. This constraint automatically permitted only certain values of electron energies. The Bohr model of the atom fixed the problem of energy loss from radiation from a ground state (by declaring that there was no state below this), and more importantly explained the origin of spectral lines.
After Bohr's use of Einstein's explanation of the photoelectric effect to relate energy levels in atoms with the wavelength of emitted light, the connection between the structure of electrons in atoms and the emission and absorption spectra of atoms became an increasingly useful tool in the understanding of electrons in atoms. The most prominent feature of emission and absorption spectra (known experimentally since the middle of the 19th century), was that these atomic spectra contained discrete lines. The significance of the Bohr model was that it related the lines in emission and absorption spectra to the energy differences between the orbits that electrons could take around an atom. This was, however, "not" achieved by Bohr through giving the electrons some kind of wave-like properties, since the idea that electrons could behave as matter waves was not suggested until eleven years later. Still, the Bohr model's use of quantized angular momenta and therefore quantized energy levels was a significant step towards the understanding of electrons in atoms, and also a significant step towards the development of quantum mechanics in suggesting that quantized restraints must account for all discontinuous energy levels and spectra in atoms.

With de Broglie's suggestion of the existence of electron matter waves in 1924, and for a short time before the full 1926 Schrödinger equation treatment of hydrogen-like atom, a Bohr electron "wavelength" could be seen to be a function of its momentum, and thus a Bohr orbiting electron was seen to orbit in a circle at a multiple of its half-wavelength (this physically incorrect Bohr model is still often taught to beginning students). The Bohr model for a short time could be seen as a classical model with an additional constraint provided by the 'wavelength' argument. However, this period was immediately superseded by the full three-dimensional wave mechanics of 1926. In our current understanding of physics, the Bohr model is called a semi-classical model because of its quantization of angular momentum, not primarily because of its relationship with electron wavelength, which appeared in hindsight a dozen years after the Bohr model was proposed.

The Bohr model was able to explain the emission and absorption spectra of hydrogen. The energies of electrons in the "n" = 1, 2, 3, etc. states in the Bohr model match those of current physics. However, this did not explain similarities between different atoms, as expressed by the periodic table, such as the fact that helium (two electrons), neon (10 electrons), and argon (18 electrons) exhibit similar chemical inertness. Modern quantum mechanics explains this in terms of electron shells and subshells which can each hold a number of electrons determined by the Pauli exclusion principle. Thus the "n" = 1 state can hold one or two electrons, while the "n" = 2 state can hold up to eight electrons in 2s and 2p subshells. In helium, all "n" = 1 states are fully occupied; the same for "n" = 1 and "n" = 2 in neon. In argon the 3s and 3p subshells are similarly fully occupied by eight electrons; quantum mechanics also allows a 3d subshell but this is at higher energy than the 3s and 3p in argon (contrary to the situation in the hydrogen atom) and remains empty.

Immediately after Heisenberg discovered his uncertainty principle, Bohr noted that the existence of any sort of wave packet implies uncertainty in the wave frequency and wavelength, since a spread of frequencies is needed to create the packet itself. In quantum mechanics, where all particle momenta are associated with waves, it is the formation of such a wave packet which localizes the wave, and thus the particle, in space. In states where a quantum mechanical particle is bound, it must be localized as a wave packet, and the existence of the packet and its minimum size implies a spread and minimal value in particle wavelength, and thus also momentum and energy. In quantum mechanics, as a particle is localized to a smaller region in space, the associated compressed wave packet requires a larger and larger range of momenta, and thus larger kinetic energy. Thus the binding energy to contain or trap a particle in a smaller region of space increases without bound as the region of space grows smaller. Particles cannot be restricted to a geometric point in space, since this would require an infinite particle momentum.

In chemistry, Schrödinger, Pauling, Mulliken and others noted that the consequence of Heisenberg's relation was that the electron, as a wave packet, could not be considered to have an exact location in its orbital. Max Born suggested that the electron's position needed to be described by a probability distribution which was connected with finding the electron at some point in the wave-function which described its associated wave packet. The new quantum mechanics did not give exact results, but only the probabilities for the occurrence of a variety of possible such results. Heisenberg held that the path of a moving particle has no meaning if we cannot observe it, as we cannot with electrons in an atom.

In the quantum picture of Heisenberg, Schrödinger and others, the Bohr atom number "n" for each orbital became known as an "n-sphere" in a three dimensional atom and was pictured as the mean energy of the probability cloud of the electron's wave packet which surrounded the atom.

Orbitals have been given names, which are usually given in the form:
where "X" is the energy level corresponding to the principal quantum number ; type is a lower-case letter denoting the shape or subshell of the orbital, corresponding to the angular quantum number ; and is the number of electrons in that orbital.

For example, the orbital 1s (pronounced as the individual numbers and letters: "one ess two") has two electrons and is the lowest energy level () and has an angular quantum number of , denoted as s.

There is also another, less common system still used in X-ray science known as X-ray notation, which is a continuation of the notations used before orbital theory was well understood. In this system, the principal quantum number is given a letter associated with it. For , the letters associated with those numbers are K, L, M, N, O, ... respectively.

The simplest atomic orbitals are those that are calculated for systems with a single electron, such as the hydrogen atom. An atom of any other element ionized down to a single electron is very similar to hydrogen, and the orbitals take the same form. In the Schrödinger equation for this system of one negative and one positive particle, the atomic orbitals are the eigenstates of the Hamiltonian operator for the energy. They can be obtained analytically, meaning that the resulting orbitals are products of a polynomial series, and exponential and trigonometric functions. (see hydrogen atom).

For atoms with two or more electrons, the governing equations can only be solved with the use of methods of iterative approximation. Orbitals of multi-electron atoms are "qualitatively" similar to those of hydrogen, and in the simplest models, they are taken to have the same form. For more rigorous and precise analysis, numerical approximations must be used.

A given (hydrogen-like) atomic orbital is identified by unique values of three quantum numbers: , , and . The rules restricting the values of the quantum numbers, and their energies (see below), explain the electron configuration of the atoms and the periodic table.

The stationary states (quantum states) of the hydrogen-like atoms are its atomic orbitals. However, in general, an electron's behavior is not fully described by a single orbital. Electron states are best represented by time-depending "mixtures" (linear combinations) of multiple orbitals. See Linear combination of atomic orbitals molecular orbital method.

The quantum number first appeared in the Bohr model where it determines the radius of each circular electron orbit. In modern quantum mechanics however, determines the mean distance of the electron from the nucleus; all electrons with the same value of "n" lie at the same average distance. For this reason, orbitals with the same value of "n" are said to comprise a "shell". Orbitals with the same value of "n" and also the same value of  are even more closely related, and are said to comprise a "subshell".

Because of the quantum mechanical nature of the electrons around a nucleus, atomic orbitals can be uniquely defined by a set of integers known as quantum numbers. These quantum numbers only occur in certain combinations of values, and their physical interpretation changes depending on whether real or complex versions of the atomic orbitals are employed.

In physics, the most common orbital descriptions are based on the solutions to the hydrogen atom, where orbitals are given by the product between a radial function and a pure spherical harmonic. The quantum numbers, together with the rules governing their possible values, are as follows:

The principal quantum number describes the energy of the electron and is always a positive integer. In fact, it can be any positive integer, but for reasons discussed below, large numbers are seldom encountered. Each atom has, in general, many orbitals associated with each value of "n"; these orbitals together are sometimes called "electron shells".

The azimuthal quantum number describes the orbital angular momentum of each electron and is a non-negative integer. Within a shell where is some integer , ranges across all (integer) values satisfying the relation formula_3. For instance, the  shell has only orbitals with formula_4, and the  shell has only orbitals with formula_4, and formula_6. The set of orbitals associated with a particular value of  are sometimes collectively called a "subshell".

The magnetic quantum number, formula_7, describes the magnetic moment of an electron in an arbitrary direction, and is also always an integer. Within a subshell where formula_8 is some integer formula_9, formula_7 ranges thus: formula_11.

The above results may be summarized in the following table. Each cell represents a subshell, and lists the values of formula_7 available in that subshell. Empty cells represent subshells that do not exist.

Subshells are usually identified by their formula_13- and formula_8-values. formula_13 is represented by its numerical value, but formula_8 is represented by a letter as follows: 0 is represented by 's', 1 by 'p', 2 by 'd', 3 by 'f', and 4 by 'g'. For instance, one may speak of the subshell with formula_17 and formula_4 as a '2s subshell'.

Each electron also has a spin quantum number, s, which describes the spin of each electron (spin up or spin down). The number s can be + or −.

The Pauli exclusion principle states that no two electrons in an atom can have the same values of all four quantum numbers. If there are two electrons in an orbital with given values for three quantum numbers, (n, l, m), these two electrons must differ in their spin.

The above conventions imply a preferred axis (for example, the "z" direction in Cartesian coordinates), and they also imply a preferred direction along this preferred axis. Otherwise there would be no sense in distinguishing from . As such, the model is most useful when applied to physical systems that share these symmetries. The Stern–Gerlach experiment — where an atom is exposed to a magnetic field — provides one such example.

An atom that is embedded in a crystalline solid feels multiple preferred axes, but often no preferred direction. Instead of building atomic orbitals out of the product of radial functions and a single spherical harmonic, linear combinations of spherical harmonics are typically used, designed so that the imaginary part of the spherical harmonics cancel out. These real orbitals are the building blocks most commonly shown in orbital visualizations.

In the real hydrogen-like orbitals, for example, and have the same interpretation and significance as their complex counterparts, but is no longer a good quantum number (though its absolute value is). The orbitals are given new names based on their shape with respect to a standardized Cartesian basis. The real hydrogen-like p orbitals are given by the following

where , , and , are the complex orbitals corresponding to .

The equations for the p and p orbitals depend on the phase convention used for the spherical harmonics. The above equations suppose that the spherical harmonics are defined by formula_22. However some quantum physicists include a phase factor (-1) in these definitions, which has the effect of relating the p orbital to a "difference" of spherical harmonics and the p orbital to the corresponding "sum". (For more detail, see Spherical harmonics#Conventions).

Simple pictures showing orbital shapes are intended to describe the angular forms of regions in space where the electrons occupying the orbital are likely to be found. The diagrams cannot show the entire region where an electron can be found, since according to quantum mechanics there is a non-zero probability of finding the electron (almost) anywhere in space. Instead the diagrams are approximate representations of boundary or contour surfaces where the probability density has a constant value, chosen so that there is a certain probability (for example 90%) of finding the electron within the contour. Although as the square of an absolute value is everywhere non-negative, the sign of the wave function is often indicated in each subregion of the orbital picture.

Sometimes the function will be graphed to show its phases, rather than the which shows probability density but has no phases (which have been lost in the process of taking the absolute value, since is a complex number). orbital graphs tend to have less spherical, thinner lobes than graphs, but have the same number of lobes in the same places, and otherwise are recognizable. This article, in order to show wave function phases, shows mostly graphs.

The lobes can be viewed as standing wave interference patterns between the two counter rotating, ring resonant travelling wave "" and "" modes, with the projection of the orbital onto the xy plane having a resonant "" wavelengths around the circumference. Though rarely depicted the travelling wave solutions can be viewed as rotating banded tori, with the bands representing phase information. For each there are two standing wave solutions and . For the case where the orbital is vertical, counter rotating information is unknown, and the orbital is z-axis symmetric. For the case where there are no counter rotating modes. There are only radial modes and the shape is spherically symmetric. For any given , the smaller is, the more radial nodes there are. Loosely speaking "n" is energy, is analogous to eccentricity, and is orientation. In the classical case, a ring resonant travelling wave, for example in a circular transmission line, unless actively forced, will spontaneously decay into a ring resonant standing wave because reflections will build up over time at even the smallest imperfection or discontinuity.

Generally speaking, the number determines the size and energy of the orbital for a given nucleus: as increases, the size of the orbital increases. When comparing different elements, the higher nuclear charge of heavier elements causes their orbitals to contract by comparison to lighter ones, so that the overall size of the whole atom remains very roughly constant, even as the number of electrons in heavier elements (higher ) increases.

Also in general terms, determines an orbital's shape, and its orientation. However, since some orbitals are described by equations in complex numbers, the shape sometimes depends on also. Together, the whole set of orbitals for a given and fill space as symmetrically as possible, though with increasingly complex sets of lobes and nodes.

The single s-orbitals (formula_4) are shaped like spheres. For it is roughly a solid ball (it is most dense at the center and fades exponentially outwardly), but for or more, each single s-orbital is composed of spherically symmetric surfaces which are nested shells (i.e., the "wave-structure" is radial, following a sinusoidal radial component as well). See illustration of a cross-section of these nested shells, at right. The s-orbitals for all numbers are the only orbitals with an anti-node (a region of high wave function density) at the center of the nucleus. All other orbitals (p, d, f, etc.) have angular momentum, and thus avoid the nucleus (having a wave node "at" the nucleus). Recently, there has been an effort to experimentally image the 1"s" and 2"p" orbitials in a SrTiO crystal using scanning transmission electron microscopy with energy dispersive x-ray spectroscopy. Because the imaging was conducted using an electron beam, Coulombic beam-orbital interaction that is often termed as the impact parameter effect is included in the final outcome (see the figure at right).

The shapes of p, d and f-orbitals are described verbally here and shown graphically in the "Orbitals table" below. The three p-orbitals for have the form of two ellipsoids with a point of tangency at the nucleus (the two-lobed shape is sometimes referred to as a "dumbbell"—there are two lobes pointing in opposite directions from each other). The three p-orbitals in each shell are oriented at right angles to each other, as determined by their respective linear combination of values of . The overall result is a lobe pointing along each direction of the primary axes.

Four of the five d-orbitals for look similar, each with four pear-shaped lobes, each lobe tangent at right angles to two others, and the centers of all four lying in one plane. Three of these planes are the xy-, xz-, and yz-planes—the lobes are between the pairs of primary axes—and the fourth has the centres along the x and y axes themselves. The fifth and final d-orbital consists of three regions of high probability density: a torus with two pear-shaped regions placed symmetrically on its z axis. The overall total of 18 directional lobes point in every primary axis direction and between every pair.

There are seven f-orbitals, each with shapes more complex than those of the d-orbitals.

Additionally, as is the case with the s orbitals, individual p, d, f and g orbitals with values higher than the lowest possible value, exhibit an additional radial node structure which is reminiscent of harmonic waves of the same type, as compared with the lowest (or fundamental) mode of the wave. As with s orbitals, this phenomenon provides p, d, f, and g orbitals at the next higher possible value of (for example, 3p orbitals vs. the fundamental 2p), an additional node in each lobe. Still higher values of further increase the number of radial nodes, for each type of orbital.

The shapes of atomic orbitals in one-electron atom are related to 3-dimensional spherical harmonics. These shapes are not unique, and any linear combination is valid, like a transformation to cubic harmonics, in fact it is possible to generate sets where all the d's are the same shape, just like the and are the same shape.
Although individual orbitals are most often shown independent of each other, the orbitals coexist around the nucleus at the same time. Also, in 1927, Albrecht Unsöld proved that if one sums the electron density of all orbitals of a particular azimuthal quantum number of the same shell (e.g. all three 2p orbitals, or all five 3d orbitals) where each orbital is occupied by an electron or each is occupied by an electron pair, then all angular dependence disappears; that is, the resulting total density of all the atomic orbitals in that subshell (those with the same ) is spherical. This is known as Unsöld's theorem.

This table shows all orbital configurations for the real hydrogen-like wave functions up to 7s, and therefore covers the simple electronic configuration for all elements in the periodic table up to radium. "ψ" graphs are shown with − and + wave function phases shown in two different colors (arbitrarily red and blue). The orbital is the same as the orbital, but the and are formed by taking linear
combinations of the and orbitals (which is why they are listed under the label). Also, the and are not
the same shape as the , since they are pure spherical harmonics.

The shapes of atomic orbitals can be qualitatively understood by considering the analogous case of standing waves on a circular drum. To see the analogy, the mean vibrational displacement of each bit of drum membrane from the equilibrium point over many cycles (a measure of average drum membrane velocity and momentum at that point) must be considered relative to that point's distance from the center of the drum head. If this displacement is taken as being analogous to the probability of finding an electron at a given distance from the nucleus, then it will be seen that the many modes of the vibrating disk form patterns that trace the various shapes of atomic orbitals. The basic reason for this correspondence lies in the fact that the distribution of kinetic energy and momentum in a matter-wave is predictive of where the particle associated with the wave will be. That is, the probability of finding an electron at a given place is also a function of the electron's average momentum at that point, since high electron momentum at a given position tends to "localize" the electron in that position, via the properties of electron wave-packets (see the Heisenberg uncertainty principle for details of the mechanism).

This relationship means that certain key features can be observed in both drum membrane modes and atomic orbitals. For example, in all of the modes analogous to s orbitals (the top row in the animated illustration below), it can be seen that the very center of the drum membrane vibrates most strongly, corresponding to the antinode in all s orbitals in an atom. This antinode means the electron is most likely to be at the physical position of the nucleus (which it passes straight through without scattering or striking it), since it is moving (on average) most rapidly at that point, giving it maximal momentum.

A mental "planetary orbit" picture closest to the behavior of electrons in s orbitals, all of which have no angular momentum, might perhaps be that of a Keplerian orbit with the orbital eccentricity of 1 but a finite major axis, not physically possible (because particles were to collide), but can be imagined as a limit of orbits with equal major axes but increasing eccentricity.

Below, a number of drum membrane vibration modes and the respective wave functions of the hydrogen atom are shown. A correspondence can be considered where the wave functions of a vibrating drum head are for a two-coordinate system and the wave functions for a vibrating sphere are three-coordinate .

None of the other sets of modes in a drum membrane have a central antinode, and in all of them the center of the drum does not move. These correspond to a node at the nucleus for all non-s orbitals in an atom. These orbitals all have some angular momentum, and in the planetary model, they correspond to particles in orbit with eccentricity less than 1.0, so that they do not pass straight through the center of the primary body, but keep somewhat away from it.

In addition, the drum modes analogous to p and d modes in an atom show spatial irregularity along the different radial directions from the center of the drum, whereas all of the modes analogous to s modes are perfectly symmetrical in radial direction. The non radial-symmetry properties of non-s orbitals are necessary to localize a particle with angular momentum and a wave nature in an orbital where it must tend to stay away from the central attraction force, since any particle localized at the point of central attraction could have no angular momentum. For these modes, waves in the drum head tend to avoid the central point. Such features again emphasize that the shapes of atomic orbitals are a direct consequence of the wave nature of electrons.

In atoms with a single electron (hydrogen-like atoms), the energy of an orbital (and, consequently, of any electrons in the orbital) is determined mainly by formula_13. The formula_25 orbital has the lowest possible energy in the atom. Each successively higher value of formula_13 has a higher level of energy, but the difference decreases as formula_13 increases. For high formula_13, the level of energy becomes so high that the electron can easily escape from the atom. In single electron atoms, all levels with different formula_8 within a given formula_13 are degenerate in the Schrödinger approximation, and have the same energy. This approximation is broken to a slight extent in the solution to the Dirac equation (where the energy depends on and another quantum number ), and by the effect of the magnetic field of the nucleus and quantum electrodynamics effects. The latter induce tiny binding energy differences especially for s electrons that go nearer the nucleus, since these feel a very slightly different nuclear charge, even in one-electron atoms; see Lamb shift.

In atoms with multiple electrons, the energy of an electron depends not only on the intrinsic properties of its orbital, but also on its interactions with the other electrons. These interactions depend on the detail of its spatial probability distribution, and so the energy levels of orbitals depend not only on formula_13 but also on formula_8. Higher values of formula_8 are associated with higher values of energy; for instance, the 2p state is higher than the 2s state. When formula_34, the increase in energy of the orbital becomes so large as to push the energy of orbital above the energy of the s-orbital in the next higher shell; when formula_35 the energy is pushed into the shell two steps higher. The filling of the 3d orbitals does not occur until the 4s orbitals have been filled.

The increase in energy for subshells of increasing angular momentum in larger atoms is due to electron–electron interaction effects, and it is specifically related to the ability of low angular momentum electrons to penetrate more effectively toward the nucleus, where they are subject to less screening from the charge of intervening electrons. Thus, in atoms of higher atomic number, the formula_8 of electrons becomes more and more of a determining factor in their energy, and the principal quantum numbers formula_13 of electrons becomes less and less important in their energy placement.

The energy sequence of the first 35 subshells (e.g., 1s, 2p, 3d, etc.) is given in the following table. Each cell represents a subshell with formula_13 and formula_8 given by its row and column indices, respectively. The number in the cell is the subshell's position in the sequence. For a linear listing of the subshells in terms of increasing energies in multielectron atoms, see the section below.

"Note: empty cells indicate non-existent sublevels, while numbers in italics indicate sublevels that could (potentially) exist, but which do not hold electrons in any element currently known."

Several rules govern the placement of electrons in orbitals ("electron configuration"). The first dictates that no two electrons in an atom may have the same set of values of quantum numbers (this is the Pauli exclusion principle). These quantum numbers include the three that define orbitals, as well as , or spin quantum number. Thus, two electrons may occupy a single orbital, so long as they have different values of . However, "only" two electrons, because of their spin, can be associated with each orbital.

Additionally, an electron always tends to fall to the lowest possible energy state. It is possible for it to occupy any orbital so long as it does not violate the Pauli exclusion principle, but if lower-energy orbitals are available, this condition is unstable. The electron will eventually lose energy (by releasing a photon) and drop into the lower orbital. Thus, electrons fill orbitals in the order specified by the energy sequence given above.

This behavior is responsible for the structure of the periodic table. The table may be divided into several rows (called 'periods'), numbered starting with 1 at the top. The presently known elements occupy seven periods. If a certain period has number "i", it consists of elements whose outermost electrons fall in the "i"th shell. Niels Bohr was the first to propose (1923) that the periodicity in the properties of the elements might be explained by the periodic filling of the electron energy levels, resulting in the electronic structure of the atom.

The periodic table may also be divided into several numbered rectangular 'blocks'. The elements belonging to a given block have this common feature: their highest-energy electrons all belong to the same -state (but the associated with that -state depends upon the period). For instance, the leftmost two columns constitute the 's-block'. The outermost electrons of Li and Be respectively belong to the 2s subshell, and those of Na and Mg to the 3s subshell.

The following is the order for filling the "subshell" orbitals, which also gives the order of the "blocks" in the periodic table:

The "periodic" nature of the filling of orbitals, as well as emergence of the s, p, d and f "blocks", is more obvious if this order of filling is given in matrix form, with increasing principal quantum numbers starting the new rows ("periods") in the matrix. Then, each subshell (composed of the first two quantum numbers) is repeated as many times as required for each pair of electrons it may contain. The result is a compressed periodic table, with each entry representing two successive elements:

Although this is the general order of orbital filling according to the Madelung rule, there are exceptions, and the actual electronic energies of each element are also dependent upon additional details of the atoms (see ).

The number of electrons in an electrically neutral atom increases with the atomic number. The electrons in the outermost shell, or "valence electrons", tend to be responsible for an element's chemical behavior. Elements that contain the same number of valence electrons can be grouped together and display similar chemical properties.

For elements with high atomic number , the effects of relativity become more pronounced, and especially so for s electrons, which move at relativistic velocities as they penetrate the screening electrons near the core of high- atoms. This relativistic increase in momentum for high speed electrons causes a corresponding decrease in wavelength and contraction of 6s orbitals relative to 5d orbitals (by comparison to corresponding s and d electrons in lighter elements in the same column of the periodic table); this results in 6s valence electrons becoming lowered in energy.

Examples of significant physical outcomes of this effect include the lowered melting temperature of mercury (which results from 6s electrons not being available for metal bonding) and the golden color of gold and caesium.

In the Bohr Model, an  electron has a velocity given by formula_40, where is the atomic number, formula_41 is the fine-structure constant, and is the speed of light. In non-relativistic quantum mechanics, therefore, any atom with an atomic number greater than 137 would require its 1s electrons to be traveling faster than the speed of light. Even in the Dirac equation, which accounts for relativistic effects, the wave function of the electron for atoms with formula_42 is oscillatory and unbounded. The significance of element 137, also known as untriseptium, was first pointed out by the physicist Richard Feynman. Element 137 is sometimes informally called feynmanium (symbol Fy). However, Feynman's approximation fails to predict the exact critical value of  due to the non-point-charge nature of the nucleus and very small orbital radius of inner electrons, resulting in a potential seen by inner electrons which is effectively less than . The critical  value which makes the atom unstable with regard to high-field breakdown of the vacuum and production of electron-positron pairs, does not occur until is about 173. These conditions are not seen except transiently in collisions of very heavy nuclei such as lead or uranium in accelerators, where such electron-positron production from these effects has been claimed to be observed. See Extension of the periodic table beyond the seventh period.

There are no nodes in relativistic orbital densities, although individual components of the wave function will have nodes.

Bound quantum states have discrete energy levels. When applied to atomic orbitals, this means that the energy differences between states are also discrete. A transition between these states (i.e., an electron absorbing or emitting a photon) can thus only happen if the photon has an energy corresponding with the exact energy difference between said states.

Consider two states of the hydrogen atom:

State 1) , , and 

State 2) , , and 

By quantum theory, state 1 has a fixed energy of , and state 2 has a fixed energy of . Now, what would happen if an electron in state 1 were to move to state 2? For this to happen, the electron would need to gain an energy of exactly . If the electron receives energy that is less than or greater than this value, it cannot jump from state 1 to state 2. Now, suppose we irradiate the atom with a broad-spectrum of light. Photons that reach the atom that have an energy of exactly will be absorbed by the electron in state 1, and that electron will jump to state 2. However, photons that are greater or lower in energy cannot be absorbed by the electron, because the electron can only jump to one of the orbitals, it cannot jump to a state between orbitals. The result is that only photons of a specific frequency will be absorbed by the atom. This creates a line in the spectrum, known as an absorption line, which corresponds to the energy difference between states 1 and 2.

The atomic orbital model thus predicts line spectra, which are observed experimentally. This is one of the main validations of the atomic orbital model.

The atomic orbital model is nevertheless an approximation to the full quantum theory, which only recognizes many electron states. The predictions of line spectra are qualitatively useful but are not quantitatively accurate for atoms and ions other than those containing only one electron.





</doc>
<doc id="1207" url="https://en.wikipedia.org/wiki?curid=1207" title="Amino acid">
Amino acid

Amino acids are organic compounds containing amine (-NH) and carboxyl (-COOH) functional groups, along with a side chain (R group) specific to each amino acid. The key elements of an amino acid are carbon (C), hydrogen (H), oxygen (O), and nitrogen (N), although other elements are found in the side chains of certain amino acids. About 500 naturally occurring amino acids are known (though only 20 appear in the genetic code) and can be classified in many ways. They can be classified according to the core structural functional groups' locations as alpha- (α-), beta- (β-), gamma- (γ-) or delta- (δ-) amino acids; other categories relate to polarity, pH level, and side chain group type (aliphatic, acyclic, aromatic, containing hydroxyl or sulfur, etc.). In the form of proteins, amino acid residues form the second-largest component (water is the largest) of human muscles and other tissues. Beyond their role as residues in proteins, amino acids participate in a number of processes such as neurotransmitter transport and biosynthesis.

In biochemistry, amino acids having both the amine and the carboxylic acid groups attached to the first (alpha-) carbon atom have particular importance. They are known as 2-, alpha-, or α-amino acids (generic formula HNCHRCOOH in most cases, where R is an organic substituent known as a "side chain"); often the term "amino acid" is used to refer specifically to these. They include the 22 proteinogenic ("protein-building") amino acids, which combine into peptide chains ("polypeptides") to form the building-blocks of a vast array of proteins. These are all -stereoisomers ("left-handed" isomers), although a few -amino acids ("right-handed") occur in bacterial envelopes, as a neuromodulator (-serine), and in some antibiotics.

Twenty of the proteinogenic amino acids are encoded directly by triplet codons in the genetic code and are known as "standard" amino acids. The other two ("non-standard" or "non-canonical") are selenocysteine (present in many prokaryotes as well as most eukaryotes, but not coded directly by DNA), and pyrrolysine (found only in some archaea and one bacterium). Pyrrolysine and selenocysteine are encoded via variant codons; for example, selenocysteine is encoded by stop codon and SECIS element. "N"-formylmethionine (which is often the initial amino acid of proteins in bacteria, mitochondria, and chloroplasts) is generally considered as a form of methionine rather than as a separate proteinogenic amino acid. Codon–tRNA combinations not found in nature can also be used to "expand" the genetic code and form novel proteins known as alloproteins incorporating non-proteinogenic amino acids.

Many important proteinogenic and non-proteinogenic amino acids have biological functions. For example, in the human brain, glutamate (standard glutamic acid) and gamma-amino-butyric acid ("GABA", non-standard gamma-amino acid) are, respectively, the main excitatory and inhibitory neurotransmitters. Hydroxyproline, a major component of the connective tissue collagen, is synthesised from proline. Glycine is a biosynthetic precursor to porphyrins used in red blood cells. Carnitine is used in lipid transport.

Nine proteinogenic amino acids are called "essential" for humans because they cannot be produced from other compounds by the human body and so must be taken in as food. Others may be conditionally essential for certain ages or medical conditions. Essential amino acids may also differ between species.

Because of their biological significance, amino acids are important in nutrition and are commonly used in nutritional supplements, fertilizers, feed, and food technology. Industrial uses include the production of drugs, biodegradable plastics, and chiral catalysts.

The first few amino acids were discovered in the early 19th century. In 1806, French chemists Louis-Nicolas Vauquelin and Pierre Jean Robiquet isolated a compound in asparagus that was subsequently named asparagine, the first amino acid to be discovered. Cystine was discovered in 1810, although its monomer, cysteine, remained undiscovered until 1884. Glycine and leucine were discovered in 1820. The last of the 20 common amino acids to be discovered was threonine in 1935 by William Cumming Rose, who also determined the essential amino acids and established the minimum daily requirements of all amino acids for optimal growth.

The unity of the chemical category was recognized by Wurtz in 1865, but he gave no particular name to it. First use of the term "amino acid" in the English language dates from 1898, while the German term, "Aminosäure", was used earlier. Proteins were found to yield amino acids after enzymatic digestion or acid hydrolysis. In 1902, Emil Fischer and Franz Hofmeister independently proposed that proteins are formed from many amino acids, whereby bonds are formed between the amino group of one amino acid with the carboxyl group of another, resulting in a linear structure that Fischer termed "peptide".

In the structure shown at the top of the page, R represents a side chain specific to each amino acid. The carbon atom next to the carboxyl group (which is therefore numbered 2 in the carbon chain starting from that functional group) is called the α–carbon. Amino acids containing an amino group bonded directly to the alpha carbon are referred to as "alpha amino acids". These include amino acids such as proline which contain secondary amines, which used to be often referred to as "imino acids".

The alpha amino acids are the most common form found in nature, but only when occurring in the -isomer. The alpha carbon is a chiral carbon atom, with the exception of glycine which has two indistinguishable hydrogen atoms on the alpha carbon. Therefore, all alpha amino acids but glycine can exist in either of two enantiomers, called or amino acids, which are mirror images of each other ("see also Chirality"). While -amino acids represent all of the amino acids found in proteins during translation in the ribosome, -amino acids are found in some proteins produced by enzyme posttranslational modifications after translation and translocation to the endoplasmic reticulum, as in exotic sea-dwelling organisms such as cone snails. They are also abundant components of the peptidoglycan cell walls of bacteria, and -serine may act as a neurotransmitter in the brain. -amino acids are used in racemic crystallography to create centrosymmetric crystals, which (depending on the protein) may allow for easier and more robust protein structure determination. The and convention for amino acid configuration refers not to the optical activity of the amino acid itself but rather to the optical activity of the isomer of glyceraldehyde from which that amino acid can, in theory, be synthesized (-glyceraldehyde is dextrorotatory; -glyceraldehyde is levorotatory).
In alternative fashion, the "(S)" and "(R)" designators are used to indicate the absolute stereochemistry. Almost all of the amino acids in proteins are "(S)" at the α carbon, with cysteine being "(R)" and glycine non-chiral. Cysteine has its side chain in the same geometric position as the other amino acids, but the "R/S" terminology is reversed because of the higher atomic number of sulfur compared to the carboxyl oxygen gives the side chain a higher priority, whereas the atoms in most other side chains give them lower priority.

In amino acids that have a carbon chain attached to the α–carbon (such as lysine, shown to the right) the carbons are labeled in order as α, β, γ, δ, and so on. In some amino acids, the amine group is attached to the β or γ-carbon, and these are therefore referred to as "beta" or "gamma amino acids".

Amino acids are usually classified by the properties of their side chain into four groups. The side chain can make an amino acid a weak acid or a weak base, and a hydrophile if the side chain is polar or a hydrophobe if it is nonpolar. The chemical structures of the 22 standard amino acids, along with their chemical properties, are described more fully in the article on these proteinogenic amino acids.

The phrase "branched-chain amino acids" or BCAA refers to the amino acids having aliphatic side chains that are non-linear; these are leucine, isoleucine, and valine. Proline is the only proteinogenic amino acid whose side-group links to the α-amino group and, thus, is also the only proteinogenic amino acid containing a secondary amine at this position. In chemical terms, proline is, therefore, an imino acid, since it lacks a primary amino group, although it is still classed as an amino acid in the current biochemical nomenclature, and may also be called an "N-alkylated alpha-amino acid".

The α-carboxylic acid group of amino acids is a weak acid, meaning that it releases a hydron (such as a proton) at moderate pH values. In other words, carboxylic acid groups (−COH) can be deprotonated to become negatively charged carboxylates (−CO ). The negatively charged carboxylate ion predominates at pH values greater than the pKa of the carboxylic acid group (typically around 2.2 for the 20 common amino acids; see the table of amino acid structures above). In a complementary fashion, the α-amine of amino acids is a weak base, meaning that it accepts a proton at moderate pH values. In other words, α-amino groups (NH−) can be protonated to become positively charged α-ammonium groups (HN−). The positively charged α-ammonium group predominates at pH values less than the pKa of the α-ammonium group (mean for the 20 common α-amino acids is about 9.4).

Because all amino acids contain amine and carboxylic acid functional groups, they share amphiprotic properties. Below pH 2.2, the predominant form will have a neutral carboxylic acid group and a positive α-ammonium ion (net charge +1), and above pH 9.4, a negative carboxylate and neutral α-amino group (net charge −1). At a pH between 2.2 and 9.4, an amino acid typically contains both a negative carboxylate and a positive α-ammonium group, as shown in structure (2) on the right and exhibits a net zero charge. This molecular state is known as a zwitterion, from the German "" meaning "hermaphrodite" or "hybrid". The fully neutral form (structure (1) on the left) is a very minor species in aqueous solution throughout the pH range (less than 1 part in 10). Altogether, amino acids exist as zwitterions in the solid phase and crystallize with salt-like properties unlike typical organic acids or amines.

The variation in titration curves when the amino acids can be grouped by category. With the exception of tyrosine, using titration to distinguish among hydrophobic amino acids is problematic.

At pH values between the two pKa values, the zwitterion predominates, but coexists in dynamic equilibrium with small amounts of net negative and net positive ions. At the exact midpoint between the two pKa values, the trace amount of net negative and trace of net positive ions exactly balance, so that average net charge of all forms present is zero. This pH is known as the isoelectric point pI, so pI = ½(pKa + pKa). The individual amino acids all have slightly different pKa values and therefore have different isoelectric points. For amino acids with charged side chains, the pKa of the side chain is involved. Thus for Asp or Glu with negative side chains, pI = ½(pKa + pKa), where pKa is the side chain pKa. Cysteine also has potentially negative side chain with pKa = 8.14, so pI should be calculated as for Asp and Glu, even though the side chain is not significantly charged at physiological pH. For His, Lys, and Arg with positive side chains, pI = ½(pKa + pKa). Amino acids have zero mobility in electrophoresis at their isoelectric point, although this behaviour is more usually exploited for peptides and proteins than single amino acids. Zwitterions have minimum solubility at their isoelectric point, and some amino acids (in particular, with non-polar side chains) can be isolated by precipitation from water by adjusting the pH to the required isoelectric point.

Amino acids are the structural units (monomers) that make up proteins. They join together to form short polymer chains called peptides or longer chains called either polypeptides or proteins. These polymers are linear and unbranched, with each amino acid within the chain attached to two neighboring amino acids. The process of making proteins encoded by DNA/RNA genetic material is called "translation" and involves the step-by-step addition of amino acids to a growing protein chain by a ribozyme that is called a ribosome. The order in which the amino acids are added is read through the genetic code from an mRNA template, which is an RNA copy of one of the organism's genes.

Twenty-two amino acids are naturally incorporated into polypeptides and are called proteinogenic or natural amino acids. Of these, 20 are encoded by the universal genetic code. The remaining 2, selenocysteine and pyrrolysine, are incorporated into proteins by unique synthetic mechanisms. Selenocysteine is incorporated when the mRNA being translated includes a SECIS element, which causes the UGA codon to encode selenocysteine instead of a stop codon. Pyrrolysine is used by some methanogenic archaea in enzymes that they use to produce methane. It is coded for with the codon UAG, which is normally a stop codon in other organisms. This UAG codon is followed by a PYLIS downstream sequence.

Aside from the 22 proteinogenic amino acids, many "non-proteinogenic" amino acids are known. Those either are not found in proteins (for example carnitine, GABA, levothyroxine) or are not produced directly and in isolation by standard cellular machinery (for example, hydroxyproline and selenomethionine).

Non-proteinogenic amino acids that are found in proteins are formed by post-translational modification, which is modification after translation during protein synthesis. These modifications are often essential for the function or regulation of a protein. For example, the carboxylation of glutamate allows for better binding of calcium cations, and collagen contains hydroxyproline, generated by hydroxylation of proline. Another example is the formation of hypusine in the translation initiation factor EIF5A, through modification of a lysine residue. Such modifications can also determine the localization of the protein, e.g., the addition of long hydrophobic groups can cause a protein to bind to a phospholipid membrane.

Some non-proteinogenic amino acids are not found in proteins. Examples include 2-aminoisobutyric acid and the neurotransmitter gamma-aminobutyric acid. Non-proteinogenic amino acids often occur as intermediates in the metabolic pathways for standard amino acids – for example, ornithine and citrulline occur in the urea cycle, part of amino acid catabolism (see below). A rare exception to the dominance of α-amino acids in biology is the β-amino acid beta alanine (3-aminopropanoic acid), which is used in plants and microorganisms in the synthesis of pantothenic acid (vitamin B), a component of coenzyme A.

-isomers are uncommon in live organisms, gramicidin is a polypeptide made up from mixture of - and -amino acids. Other compounds containing -amino acid are tyrocidine and valinomycin. These compounds disrupt bacterial cell walls, particularly in Gram-positive bacteria. Only 837 -amino acids were found in Swiss-Prot database (187 million amino acids analysed).

The 20 amino acids that are encoded directly by the codons of the universal genetic code are called "standard" or "canonical" amino acids. A modified form of methionine ("N"-formylmethionine) is often incorporated in place of methionine as the initial amino acid of proteins in bacteria, mitochondria and chloroplasts. Other amino acids are called "non-standard" or "non-canonical". Most of the non-standard amino acids are also non-proteinogenic (i.e. they cannot be incorporated into proteins during translation), but two of them are proteinogenic, as they can be incorporated translationally into proteins by exploiting information not encoded in the universal genetic code.

The two non-standard proteinogenic amino acids are selenocysteine (present in many non-eukaryotes as well as most eukaryotes, but not coded directly by DNA) and pyrrolysine (found only in some archaea and one bacterium). The incorporation of these non-standard amino acids is rare. For example, 25 human proteins include selenocysteine (Sec) in their primary structure, and the structurally characterized enzymes (selenoenzymes) employ Sec as the catalytic moiety in their active sites. Pyrrolysine and selenocysteine are encoded via variant codons. For example, selenocysteine is encoded by stop codon and SECIS element.

When taken up into the human body from the diet, the 20 standard amino acids either are used to synthesize proteins, other biomolecules, or are oxidized to urea and carbon dioxide as a source of energy. The oxidation pathway starts with the removal of the amino group by a transaminase; the amino group is then fed into the urea cycle. The other product of transamidation is a keto acid that enters the citric acid cycle. Glucogenic amino acids can also be converted into glucose, through gluconeogenesis. Of the 20 standard amino acids, nine (His, Ile, Leu, Lys, Met, Phe, Thr, Trp and Val) are called essential amino acids because the human body cannot synthesize them from other compounds at the level needed for normal growth, so they must be obtained from food. In addition, cysteine, taurine, tyrosine, and arginine are considered semiessential amino-acids in children (though taurine is not technically an amino acid), because the metabolic pathways that synthesize these amino acids are not fully developed. The amounts required also depend on the age and health of the individual, so it is hard to make general statements about the dietary requirement for some amino acids. Dietary exposure to the non-standard amino acid BMAA has been linked to human neurodegenerative diseases, including ALS.

In humans, non-protein amino acids also have important roles as metabolic intermediates, such as in the biosynthesis of the neurotransmitter gamma-amino-butyric acid (GABA). Many amino acids are used to synthesize other molecules, for example:

Some non-standard amino acids are used as defenses against herbivores in plants. For example, canavanine is an analogue of arginine that is found in many legumes, and in particularly large amounts in "Canavalia gladiata" (sword bean). This amino acid protects the plants from predators such as insects and can cause illness in people if some types of legumes are eaten without processing. The non-protein amino acid mimosine is found in other species of legume, in particular "Leucaena leucocephala". This compound is an analogue of tyrosine and can poison animals that graze on these plants.

Amino acids are used for a variety of applications in industry, but their main use is as additives to animal feed. This is necessary, since many of the bulk components of these feeds, such as soybeans, either have low levels or lack some of the essential amino acids: lysine, methionine, threonine, and tryptophan are most important in the production of these feeds. In this industry, amino acids are also used to chelate metal cations in order to improve the absorption of minerals from supplements, which may be required to improve the health or production of these animals.

The food industry is also a major consumer of amino acids, in particular, glutamic acid, which is used as a flavor enhancer, and aspartame (aspartyl-phenylalanine-1-methyl ester) as a low-calorie artificial sweetener. Similar technology to that used for animal nutrition is employed in the human nutrition industry to alleviate symptoms of mineral deficiencies, such as anemia, by improving mineral absorption and reducing negative side effects from inorganic mineral supplementation.

The chelating ability of amino acids has been used in fertilizers for agriculture to facilitate the delivery of minerals to plants in order to correct mineral deficiencies, such as iron chlorosis. These fertilizers are also used to prevent deficiencies from occurring and improving the overall health of the plants. The remaining production of amino acids is used in the synthesis of drugs and cosmetics.

Similarly, some amino acids derivatives are used in pharmaceutical industry. They include 5-HTP (5-hydroxytryptophan) used for experimental treatment of depression, -DOPA (-dihydroxyphenylalanine) for Parkinson's treatment, and eflornithine drug that inhibits ornithine decarboxylase and used in the treatment of sleeping sickness.

Since 2001, 40 non-natural amino acids have been added into protein by creating a unique codon (recoding) and a corresponding transfer-RNA:aminoacyl – tRNA-synthetase pair to encode it with diverse physicochemical and biological properties in order to be used as a tool to exploring protein structure and function or to create novel or enhanced proteins.

Nullomers are codons that in theory code for an amino acid, however in nature there is a selective bias against using this codon in favor of another, for example bacteria prefer to use CGA instead of AGA to code for arginine. This creates some sequences that do not appear in the genome. This characteristic can be taken advantage of and used to create new selective cancer-fighting drugs and to prevent cross-contamination of DNA samples from crime-scene investigations.

Amino acids are important as low-cost feedstocks. These compounds are used in chiral pool synthesis as enantiomerically pure building-blocks.

Amino acids have been investigated as precursors chiral catalysts, e.g., for asymmetric hydrogenation reactions, although no commercial applications exist.

Amino acids are under development as components of a range of biodegradable polymers. These materials have applications as environmentally friendly packaging and in medicine in drug delivery and the construction of prosthetic implants. These polymers include polypeptides, polyamides, polyesters, polysulfides, and polyurethanes with amino acids either forming part of their main chains or bonded as side chains. These modifications alter the physical properties and reactivities of the polymers. An interesting example of such materials is polyaspartate, a water-soluble biodegradable polymer that may have applications in disposable diapers and agriculture. Due to its solubility and ability to chelate metal ions, polyaspartate is also being used as a biodegradeable anti-scaling agent and a corrosion inhibitor. In addition, the aromatic amino acid tyrosine is being developed as a possible replacement for toxic phenols such as bisphenol A in the manufacture of polycarbonates.

The commercial production of amino acids usually relies on mutant bacteria that overproduce individual amino acids using glucose as a carbon source. Some amino acids are produced by enzymatic conversions of synthetic intermediates. 2-Aminothiazoline-4-carboxylic acid is an intermediate in one industrial synthesis of L-cysteine for example. Aspartic acid is produced by the addition of ammonia to fumarate using a lyase.

In plants, nitrogen is first assimilated into organic compounds in the form of glutamate, formed from alpha-ketoglutarate and ammonia in the mitochondrion. For other amino acids, plants use transaminases to move the amino group from glutamate to another alpha-keto acids. For example, aspartate aminotransferase converts glutamate and oxaloacetate to alpha-ketoglutarate and aspartate. Other organisms use transaminases for amino acid synthesis, too.

Nonstandard amino acids are usually formed through modifications to standard amino acids. For example, homocysteine is formed through the transsulfuration pathway or by the demethylation of methionine via the intermediate metabolite S-adenosyl methionine, while hydroxyproline is made by a posttranslational modification of proline.

Microorganisms and plants synthesize many uncommon amino acids. For example, some microbes make 2-aminoisobutyric acid and lanthionine, which is a sulfide-bridged derivative of alanine. Both of these amino acids are found in peptidic lantibiotics such as alamethicin. However, in plants, 1-aminocyclopropane-1-carboxylic acid is a small disubstituted cyclic amino acid that is a key intermediate in the production of the plant hormone ethylene.

Amino acids undergo the reactions expected of the constituent functional groups. The types of these reactions are determined by the groups on these side chains and are, therefore, different between the various types of amino acid.

As both the amine and carboxylic acid groups of amino acids can react to form amide bonds, one amino acid molecule can react with another and become joined through an amide linkage. This polymerization of amino acids is what creates proteins. This condensation reaction yields the newly formed peptide bond and a molecule of water. In cells, this reaction does not occur directly; instead, the amino acid is first activated by attachment to a transfer RNA molecule through an ester bond. This aminoacyl-tRNA is produced in an ATP-dependent reaction carried out by an aminoacyl tRNA synthetase. This aminoacyl-tRNA is then a substrate for the ribosome, which catalyzes the attack of the amino group of the elongating protein chain on the ester bond. As a result of this mechanism, all proteins made by ribosomes are synthesized starting at their N-terminus and moving toward their C-terminus.

However, not all peptide bonds are formed in this way. In a few cases, peptides are synthesized by specific enzymes. For example, the tripeptide glutathione is an essential part of the defenses of cells against oxidative stress. This peptide is synthesized in two steps from free amino acids. In the first step, gamma-glutamylcysteine synthetase condenses cysteine and glutamic acid through a peptide bond formed between the side chain carboxyl of the glutamate (the gamma carbon of this side chain) and the amino group of the cysteine. This dipeptide is then condensed with glycine by glutathione synthetase to form glutathione.

In chemistry, peptides are synthesized by a variety of reactions. One of the most-used in solid-phase peptide synthesis uses the aromatic oxime derivatives of amino acids as activated units. These are added in sequence onto the growing peptide chain, which is attached to a solid resin support. The ability to easily synthesize vast numbers of different peptides by varying the types and order of amino acids (using combinatorial chemistry) has made peptide synthesis particularly important in creating libraries of peptides for use in drug discovery through high-throughput screening.

The combination of functional groups allow amino acids to be effective polydentate ligands for metal-amino acid chelates.
The multiple side chains of amino acids can also undergo chemical reactions.

Amino acids must first pass out of organelles and cells into blood circulation via amino acid transporters, since the amine and carboxylic acid groups are typically ionized. Degradation of an amino acid, occurring in the liver and kidneys, often involves deamination by moving its amino group to alpha-ketoglutarate, forming glutamate. This process involves transaminases, often the same as those used in amination during synthesis. In many vertebrates, the amino group is then removed through the urea cycle and is excreted in the form of urea. However, amino acid degradation can produce uric acid or ammonia instead. For example, serine dehydratase converts serine to pyruvate and ammonia. After removal of one or more amino groups, the remainder of the molecule can sometimes be used to synthesize new amino acids, or it can be used for energy by entering glycolysis or the citric acid cycle, as detailed in image at right.

Amino acids are bidentate ligands, forming transition metal amino acid complexes. 

The 20 amino acids encoded directly by the genetic code can be divided into several groups based on their properties. Important factors are charge, hydrophilicity or hydrophobicity, size, and functional groups. These properties are important for protein structure and protein–protein interactions. The water-soluble proteins tend to have their hydrophobic residues (Leu, Ile, Val, Phe, and Trp) buried in the middle of the protein, whereas hydrophilic side chains are exposed to the aqueous solvent. (Note that in biochemistry, a residue refers to a specific monomer within the polymeric chain of a polysaccharide, protein or nucleic acid.) The integral membrane proteins tend to have outer rings of exposed hydrophobic amino acids that anchor them into the lipid bilayer. In the case part-way between these two extremes, some peripheral membrane proteins have a patch of hydrophobic amino acids on their surface that locks onto the membrane. In similar fashion, proteins that have to bind to positively charged molecules have surfaces rich with negatively charged amino acids like glutamate and aspartate, while proteins binding to negatively charged molecules have surfaces rich with positively charged chains like lysine and arginine. There are different hydrophobicity scales of amino acid residues.

Some amino acids have special properties such as cysteine, that can form covalent disulfide bonds to other cysteine residues, proline that forms a cycle to the polypeptide backbone, and glycine that is more flexible than other amino acids.

Many proteins undergo a range of posttranslational modifications, when additional chemical groups are attached to the amino acids in proteins. Some modifications can produce hydrophobic lipoproteins, or hydrophilic glycoproteins. These type of modification allow the reversible targeting of a protein to a membrane. For example, the addition and removal of the fatty acid palmitic acid to cysteine residues in some signaling proteins causes the proteins to attach and then detach from cell membranes.

Two additional amino acids are in some species coded for by codons that are usually interpreted as stop codons:

In addition to the specific amino acid codes, placeholders are used in cases where chemical or crystallographic analysis of a peptide or protein cannot conclusively determine the identity of a residue. They are also used to summarise conserved protein sequence motifs. The use of single letters to indicate sets of similar residues is similar to the use of abbreviation codes for degenerate bases.

Unk is sometimes used instead of Xaa, but is less standard.

In addition, many non-standard amino acids have a specific code. For example, several peptide drugs, such as Bortezomib and MG132, are artificially synthesized and retain their protecting groups, which have specific codes. Bortezomib is Pyz-Phe-boroLeu, and MG132 is Z-Leu-Leu-Leu-al. To aid in the analysis of protein structure, photo-reactive amino acid analogs are available. These include photoleucine (pLeu) and photomethionine (pMet).


</doc>
<doc id="1208" url="https://en.wikipedia.org/wiki?curid=1208" title="Alan Turing">
Alan Turing

Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science and artificial intelligence. Despite these accomplishments, he was never fully recognised in his home country during his lifetime, due to his homosexuality, which was then a crime in the UK.

During the Second World War, Turing worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. For a time he led Hut 8, the section that was responsible for German naval cryptanalysis. Here, he devised a number of techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bombe method, an electromechanical machine that could find settings for the Enigma machine.

Turing played a pivotal role in cracking intercepted coded messages that enabled the Allies to defeat the Nazis in many crucial engagements, including the Battle of the Atlantic, and in so doing helped win the war. Counterfactual history is difficult with respect to the effect Ultra intelligence had on the length of the war, but at the upper end it has been estimated that this work shortened the war in Europe by more than two years and saved over 14 million lives.

After the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, which was one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory at the Victoria University of Manchester, where he helped develop the Manchester computers and became interested in mathematical biology. He wrote a paper on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov–Zhabotinsky reaction, first observed in the 1960s.

Turing was prosecuted in 1952 for homosexual acts; the Labouchere Amendment had mandated that "gross indecency" was a criminal offence in the UK. He accepted chemical castration treatment, with DES, as an alternative to prison. Turing died in 1954, 16 days before his 42nd birthday, from cyanide poisoning. An inquest determined his death as a suicide, but it has been noted that the known evidence is also consistent with accidental poisoning.

In 2009, following an Internet campaign, British Prime Minister Gordon Brown made an official public apology on behalf of the British government for "the appalling way he was treated". Queen Elizabeth II granted Turing a posthumous pardon in 2013. The Alan Turing law is now an informal term for a 2017 law in the United Kingdom that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.

Turing was born in Maida Vale, London, while his father, Julius Mathison Turing (1873–1947), was on leave from his position with the Indian Civil Service (ICS) at Chatrapur, then in the Madras Presidency and presently in Odisha state, in India. Turing's father was the son of a clergyman, the Rev. John Robert Turing, from a Scottish family of merchants that had been based in the Netherlands and included a baronet. Turing's mother, Julius' wife, was Ethel Sara Turing (née Stoney 1881–1976), daughter of Edward Waller Stoney, chief engineer of the Madras Railways. The Stoneys were a Protestant Anglo-Irish gentry family from both County Tipperary and County Longford, while Ethel herself had spent much of her childhood in County Clare.

Julius' work with the ICS brought the family to British India, where his grandfather had been a general in the Bengal Army. However, both Julius and Ethel wanted their children to be brought up in Britain, so they moved to Maida Vale, London, where Alan Turing was born on 23 June 1912, as recorded by a blue plaque on the outside of the house of his birth, later the Colonnade Hotel. Turing had an elder brother, John (the father of Sir John Dermot Turing, 12th Baronet of the Turing baronets).

Turing's father's civil service commission was still active and during Turing's childhood years Turing's parents travelled between Hastings in England and India, leaving their two sons to stay with a retired Army couple. At Hastings, Turing stayed at Baston Lodge, Upper Maze Hill, St Leonards-on-Sea, now marked with a blue plaque. The plaque was unveiled on 23 June 2012, the centenary of Turing's birth.

Very early in life, Turing showed signs of the genius that he was later to display prominently. His parents purchased a house in Guildford in 1927, and Turing lived there during school holidays. The location is also marked with a blue plaque.

Turing's parents enrolled him at St Michael's, a day school at 20 Charles Road, St Leonards-on-Sea, at the age of six. The headmistress recognised his talent early on, as did many of his subsequent teachers.

Between January 1922 and 1926, Turing was educated at Hazelhurst Preparatory School, an independent school in the village of Frant in Sussex (now East Sussex). In 1926, at the age of 13, he went on to Sherborne School, a boarding independent school in the market town of Sherborne in Dorset. The first day of term coincided with the 1926 General Strike in Britain, but he was so determined to attend, that he rode his bicycle unaccompanied from Southampton to Sherborne, stopping overnight at an inn.

Turing's natural inclination towards mathematics and science did not earn him respect from some of the teachers at Sherborne, whose definition of education placed more emphasis on the classics. His headmaster wrote to his parents: "I hope he will not fall between two stools. If he is to stay at public school, he must aim at becoming "educated". If he is to be solely a "Scientific Specialist", he is wasting his time at a public school". Despite this, Turing continued to show remarkable ability in the studies he loved, solving advanced problems in 1927 without having studied even elementary calculus. In 1928, aged 16, Turing encountered Albert Einstein's work; not only did he grasp it, but it is possible that he managed to deduce Einstein's questioning of Newton's laws of motion from a text in which this was never made explicit.

At Sherborne, Turing formed a significant friendship with fellow pupil Christopher Morcom (1911 – 1930), who has been described as Turing's "first love". Their relationship provided inspiration in Turing's future endeavours, but it was cut short by Morcom's death, in February 1930, from complications of bovine tuberculosis, contracted after drinking infected cow's milk some years previously.

The event caused Turing great sorrow. He coped with his grief by working that much harder on the topics of science and mathematics that he had shared with Morcom. In a letter to Morcom's mother Turing said:

Turing's relationship with Morcom's mother continued long after Morcom's death, with her sending gifts to Turing, and him sending letters, typically on Morcom's birthdays. A day before the third anniversary of Morcom's death (12 February 1933), he wrote to Mrs. Morcom: 

Some have speculated that Morcom's death was the cause of Turing's atheism and materialism. Apparently, at this point in his life he still believed in such concepts as a spirit, independent of the body and surviving death. In a later letter, also written to Morcom's mother, Turing said: 

After Sherborne, Turing studied as an undergraduate from 1931 to 1934 at King's College, Cambridge, where he was awarded first-class honours in mathematics. In 1935, at the age of 22, he was elected a fellow of King's on the strength of a dissertation in which he proved the central limit theorem. Unknown to the committee, the theorem had already been proven, in 1922, by Jarl Waldemar Lindeberg. A blue plaque at the college was unveiled on the centenary of his birth on 23 June 2012 and is now installed at the college's Keynes Building on King's Parade.

In 1936, Turing published his paper "On Computable Numbers, with an Application to the Entscheidungsproblem". It was published in the "Proceedings of the London Mathematical Society" journal in two parts, the first on 30 November and the second on 23 December. In this paper, Turing reformulated Kurt Gödel's 1931 results on the limits of proof and computation, replacing Gödel's universal arithmetic-based formal language with the formal and simple hypothetical devices that became known as Turing machines. The "Entscheidungsproblem" (decision problem) was originally posed by German mathematician David Hilbert in 1928. Turing proved that his "universal computing machine" would be capable of performing any conceivable mathematical computation if it were representable as an algorithm. He went on to prove that there was no solution to the "decision problem" by first showing that the halting problem for Turing machines is undecidable: It is not possible to decide algorithmically whether a Turing machine will ever halt.
Although Turing's proof was published shortly after Alonzo Church's equivalent proof using his lambda calculus, Turing's approach is considerably more accessible and intuitive than Church's. It also included a notion of a 'Universal Machine' (now known as a universal Turing machine), with the idea that such a machine could perform the tasks of any other computation machine (as indeed could Church's lambda calculus). According to the Church–Turing thesis, Turing machines and the lambda calculus are capable of computing anything that is computable. John von Neumann acknowledged that the central concept of the modern computer was due to Turing's paper. To this day, Turing machines are a central object of study in theory of computation.

From September 1936 to July 1938, Turing spent most of his time studying under Church at Princeton University, in the second year as a Jane Eliza Procter Visiting Fellow. In addition to his purely mathematical work, he studied cryptology and also built three of four stages of an electro-mechanical binary multiplier. In June 1938, he obtained his PhD from the Department of Mathematics at Princeton; his dissertation, "Systems of Logic Based on Ordinals", introduced the concept of ordinal logic and the notion of relative computing, where Turing machines are augmented with so-called oracles, allowing the study of problems that cannot be solved by Turing machines. John von Neumann wanted to hire him as his postdoctoral assistant, but he went back to England.

When Turing returned to Cambridge, he attended lectures given in 1939 by Ludwig Wittgenstein about the foundations of mathematics. The lectures have been reconstructed verbatim, including interjections from Turing and other students, from students' notes. Turing and Wittgenstein argued and disagreed, with Turing defending formalism and Wittgenstein propounding his view that mathematics does not discover any absolute truths, but rather invents them.

During the Second World War, Turing was a leading participant in the breaking of German ciphers at Bletchley Park. The historian and wartime codebreaker Asa Briggs has said, "You needed exceptional talent, you needed genius at Bletchley and Turing's was that genius."

From September 1938, Turing had been working part-time with the Government Code and Cypher School (GC&CS), the British codebreaking organisation. He concentrated on cryptanalysis of the Enigma with Dilly Knox, a senior GC&CS codebreaker. Soon after the July 1939 Warsaw meeting at which the Polish Cipher Bureau had provided the British and French with the details of the wiring of Enigma rotors and their method of decrypting Enigma code messages, Turing and Knox started to work on a less fragile approach to the problem. The Polish method relied on an insecure indicator procedure that the Germans were likely to change, which they did in May 1940. Turing's approach was more general, using crib-based decryption for which he produced the functional specification of the bombe (an improvement of the Polish Bomba).

On 4 September 1939, the day after the UK declared war on Germany, Turing reported to Bletchley Park, the wartime station of GC&CS.
Specifying the bombe was the first of five major cryptanalytical advances that Turing made during the war. The others were: deducing the indicator procedure used by the German navy; developing a statistical procedure for making much more efficient use of the bombes dubbed "Banburismus"; developing a procedure for working out the cam settings of the wheels of the Lorenz SZ 40/42 ("Tunny") dubbed "Turingery" and, towards the end of the war, the development of a portable secure voice scrambler at Hanslope Park that was codenamed "Delilah".

By using statistical techniques to optimise the trial of different possibilities in the code breaking process, Turing made an innovative contribution to the subject. He wrote two papers discussing mathematical approaches, titled "The Applications of Probability to Cryptography" and "Paper on Statistics of Repetitions", which were of such value to GC&CS and its successor GCHQ that they were not released to the UK National Archives until April 2012, shortly before the centenary of his birth. A GCHQ mathematician, "who identified himself only as Richard," said at the time that the fact that the contents had been restricted for some 70 years demonstrated their importance, and their relevance to post-war cryptanalysis: 

Turing had a reputation for eccentricity at Bletchley Park. He was known to his colleagues as "Prof" and his treatise on Enigma was known as the "Prof's Book". According to historian Ronald Lewin, Jack Good, a cryptanalyst who worked with Turing, said of his colleague:

While working at Bletchley, Turing, who was a talented long-distance runner, occasionally ran the to London when he was needed for meetings, and he was capable of world-class marathon standards. Turing tried out for the 1948 British Olympic team but he was hampered by an injury. His tryout time for the marathon was only 11 minutes slower than British silver medallist Thomas Richards' Olympic race time of 2 hours 35 minutes. He was Walton Athletic Club's best runner, a fact discovered when he passed the group while running alone.

In 1946, Turing was appointed an Officer of the Order of the British Empire (OBE) by King George VI for his wartime services, but his work remained secret for many years.

Within weeks of arriving at Bletchley Park, Turing had specified an electromechanical machine called the bombe, which could break Enigma more effectively than the Polish "bomba kryptologiczna", from which its name was derived. The bombe, with an enhancement suggested by mathematician Gordon Welchman, became one of the primary tools, and the major automated one, used to attack Enigma-enciphered messages.

The bombe searched for possible correct settings used for an Enigma message (i.e., rotor order, rotor settings and plugboard settings) using a suitable "crib": a fragment of probable plaintext. For each possible setting of the rotors (which had on the order of 10 states, or 10 states for the four-rotor U-boat variant), the bombe performed a chain of logical deductions based on the crib, implemented electromechanically.

The bombe detected when a contradiction had occurred and ruled out that setting, moving on to the next. Most of the possible settings would cause contradictions and be discarded, leaving only a few to be investigated in detail. A contradiction would occur when an enciphered letter would be turned back into the same plaintext letter, which was impossible with the Enigma. The first bombe was installed on 18 March 1940.

By late 1941, Turing and his fellow cryptanalysts Gordon Welchman, Hugh Alexander and Stuart Milner-Barry were frustrated. Building on the work of the Poles, they had set up a good working system for decrypting Enigma signals, but their limited staff and bombes meant they could not translate all the signals. In the summer, they had considerable success, and shipping losses had fallen to under 100,000 tons a month; however, they badly needed more resources to keep abreast of German adjustments. They had tried to get more people and fund more bombes through the proper channels, but had failed.

On 28 October they wrote directly to Winston Churchill explaining their difficulties, with Turing as the first named. They emphasised how small their need was compared with the vast expenditure of men and money by the forces and compared with the level of assistance they could offer to the forces. As Andrew Hodges, biographer of Turing, later wrote, "This letter had an electric effect." Churchill wrote a memo to General Ismay, which read: "ACTION THIS DAY. Make sure they have all they want on extreme priority and report to me that this has been done." On 18 November, the chief of the secret service reported that every possible measure was being taken. The cryptographers at Bletchley Park did not know of the Prime Minister's response, but as Milner-Barry recalled, "All that we did notice was that almost from that day the rough ways began miraculously to be made smooth." More than two hundred bombes were in operation by the end of the war.

Turing decided to tackle the particularly difficult problem of German naval Enigma "because no one else was doing anything about it and I could have it to myself". In December 1939, Turing solved the essential part of the naval indicator system, which was more complex than the indicator systems used by the other services.

That same night, he also conceived of the idea of "Banburismus", a sequential statistical technique (what Abraham Wald later called sequential analysis) to assist in breaking the naval Enigma, "though I was not sure that it would work in practice, and was not, in fact, sure until some days had actually broken." For this, he invented a measure of weight of evidence that he called the "ban". "Banburismus" could rule out certain sequences of the Enigma rotors, substantially reducing the time needed to test settings on the bombes. Later this sequential process of accumulating sufficient weight of evidence using decibans (one tenth of a ban) was used in Cryptanalysis of the Lorenz cipher

Turing travelled to the United States in November 1942 and worked with US Navy cryptanalysts on the naval Enigma and bombe construction in Washington; he also visited their Computing Machine Laboratory in Dayton, Ohio.

Turing's reaction to the American bombe design was far from enthusiastic:
During this trip, he also assisted at Bell Labs with the development of secure speech devices. He returned to Bletchley Park in March 1943. During his absence, Hugh Alexander had officially assumed the position of head of Hut 8, although Alexander had been "de facto" head for some time (Turing having little interest in the day-to-day running of the section). Turing became a general consultant for cryptanalysis at Bletchley Park.

Alexander wrote of Turing's contribution:
In July 1942, Turing devised a technique termed "Turingery" (or jokingly "Turingismus") for use against the Lorenz cipher messages produced by the Germans' new "Geheimschreiber" (secret writer) machine. This was a teleprinter rotor cipher attachment codenamed "Tunny" at Bletchley Park. Turingery was a method of "wheel-breaking", i.e., a procedure for working out the cam settings of Tunny's wheels. He also introduced the Tunny team to Tommy Flowers who, under the guidance of Max Newman, went on to build the Colossus computer, the world's first programmable digital electronic computer, which replaced a simpler prior machine (the Heath Robinson), and whose superior speed allowed the statistical decryption techniques to be applied usefully to the messages. Some have mistakenly said that Turing was a key figure in the design of the Colossus computer. Turingery and the statistical approach of Banburismus undoubtedly fed into the thinking about cryptanalysis of the Lorenz cipher, but he was not directly involved in the Colossus development.

Following his work at Bell Labs in the US, Turing pursued the idea of electronic enciphering of speech in the telephone system. In the latter part of the war, he moved in order to work for the Secret Service's Radio Security Service (later HMGCC) at Hanslope Park. At the park, he further developed his knowledge of electronics with the assistance of engineer Donald Bayley. Together they undertook the design and construction of a portable secure voice communications machine codenamed "Delilah". The machine was intended for different applications, but it lacked the capability for use with long-distance radio transmissions. In any case, Delilah was completed too late to be used during the war. Though the system worked fully, with Turing demonstrating it to officials by encrypting and decrypting a recording of a Winston Churchill speech, Delilah was not adopted for use. Turing also consulted with Bell Labs on the development of SIGSALY, a secure voice system that was used in the later years of the war.

Between 1945 and 1947, Turing lived in Hampton, London, while he worked on the design of the ACE (Automatic Computing Engine) at the National Physical Laboratory (NPL). He presented a paper on 19 February 1946, which was the first detailed design of a stored-program computer. Von Neumann's incomplete "First Draft of a Report on the EDVAC" had predated Turing's paper, but it was much less detailed and, according to John R. Womersley, Superintendent of the NPL Mathematics Division, it "contains a number of ideas which are Dr. Turing's own". Although ACE was a feasible design, the secrecy surrounding the wartime work at Bletchley Park led to delays in starting the project and he became disillusioned. In late 1947 he returned to Cambridge for a sabbatical year during which he produced a seminal work on "Intelligent Machinery" that was not published in his lifetime. While he was at Cambridge, the Pilot ACE was being built in his absence. It executed its first program on 10 May 1950, and a number of later computers around the world owe much to it, including the English Electric DEUCE and the American Bendix G-15. The full version of Turing's ACE was not built until after his death.

According to the memoirs of the German computer pioneer Heinz Billing from the Max Planck Institute for Physics, published by Genscher, Düsseldorf, there was a meeting between Turing and Konrad Zuse. It took place in Göttingen in 1947. The interrogation had the form of a colloquium. Participants were Womersley, Turing, Porter from England and a few German researchers like Zuse, Walther, and Billing (for more details see Herbert Bruderer, "Konrad Zuse und die Schweiz").

In 1948, Turing was appointed reader in the Mathematics Department at the Victoria University of Manchester. A year later, he became Deputy Director of the Computing Machine Laboratory, where he worked on software for one of the earliest stored-program computers—the Manchester Mark 1. Turing wrote the first version of the Programmer's Manual for this machine, and was recruited by Ferranti as a consultant in the development of their commercialised machine, the Ferranti Mark 1. He continued to be paid consultancy fees by Ferranti until his death. During this time, he continued to do more abstract work in mathematics,<ref name="doi10.1093/qjmam/1.1.287"></ref> and in "Computing Machinery and Intelligence" ("Mind", October 1950), Turing addressed the problem of artificial intelligence, and proposed an experiment that became known as the Turing test, an attempt to define a standard for a machine to be called "intelligent". The idea was that a computer could be said to "think" if a human interrogator could not tell it apart, through conversation, from a human being. In the paper, Turing suggested that rather than building a program to simulate the adult mind, it would be better rather to produce a simpler one to simulate a child's mind and then to subject it to a course of education. A reversed form of the Turing test is widely used on the Internet; the CAPTCHA test is intended to determine whether the user is a human or a computer.

In 1948 Turing, working with his former undergraduate colleague, D.G. Champernowne, began writing a chess program for a computer that did not yet exist. By 1950, the program was completed and dubbed the Turbochamp. In 1952, he tried to implement it on a Ferranti Mark 1, but lacking enough power, the computer was unable to execute the program. Instead, Turing "ran" the program by flipping through the pages of the algorithm and carrying out its instructions on a chessboard, taking about half an hour per move. The game was recorded. According to Garry Kasparov, Turing's program "played a recognizable game of chess." The program lost to Turing's colleague Alick Glennie, although it is said that it won a game against Champernowne's wife,
Isabel.

His Turing test was a significant, characteristically provocative, and lasting contribution to the debate regarding artificial intelligence, which continues after more than half a century.

When Turing was 39 years old in 1951, he turned to mathematical biology, finally publishing his masterpiece "The Chemical Basis of Morphogenesis" in January 1952. He was interested in morphogenesis, the development of patterns and shapes in biological organisms. Among other things, he wanted to understand Fibonacci phyllotaxis, the existence of Fibonacci numbers in plant structures. He suggested that a system of chemicals reacting with each other and diffusing across space, termed a reaction-diffusion system, could account for "the main phenomena of morphogenesis". He used systems of partial differential equations to model catalytic chemical reactions. For example, if a catalyst A is required for a certain chemical reaction to take place, and if the reaction produced more of the catalyst A, then we say that the reaction is autocatalytic, and there is positive feedback that can be modelled by nonlinear differential equations. Turing discovered that patterns could be created if the chemical reaction not only produced catalyst A, but also produced an inhibitor B that slowed down the production of A. If A and B then diffused through the container at different rates, then you could have some regions where A dominated and some where B did. To calculate the extent of this, Turing would have needed a powerful computer, but these were not so freely available in 1951, so he had to use linear approximations to solve the equations by hand. These calculations gave the right qualitative results, and produced, for example, a uniform mixture that oddly enough had regularly spaced fixed red spots. The Russian biochemist Boris Belousov had performed experiments with similar results, but could not get his papers published because of the contemporary prejudice that any such thing violated the second law of thermodynamics. Belousov was not aware of Turing's paper in the "Philosophical Transactions of the Royal Society".

Although published before the structure and role of DNA was understood, Turing's work on morphogenesis remains relevant today and is considered a seminal piece of work in mathematical biology. One of the early applications of Turing's paper was the work by James Murray explaining spots and stripes on the fur of cats, large and small. Further research in the area suggests that Turing's work can partially explain the growth of "feathers, hair follicles, the branching pattern of lungs, and even the left-right asymmetry that puts the heart on the left side of the chest." In 2012, Sheth, et al. found that in mice, removal of Hox genes causes an increase in the number of digits without an increase in the overall size of the limb, suggesting that Hox genes control digit formation by tuning the wavelength of a Turing-type mechanism. Later papers were not available until "Collected Works of A. M. Turing" was published in 1992.

In 1941, Turing proposed marriage to Hut 8 colleague Joan Clarke, a fellow mathematician and cryptanalyst, but their engagement was short-lived. After admitting his homosexuality to his fiancée, who was reportedly "unfazed" by the revelation, Turing decided that he could not go through with the marriage.

In January 1952, Turing was 39 when he started a relationship with Arnold Murray, a 19-year-old unemployed man. Just before Christmas, Turing was walking along Manchester's Oxford Road when he met Murray just outside the Regal Cinema and invited him to lunch. On 23 January, Turing's house was burgled. Murray told Turing that he and the burglar were acquainted, and Turing reported the crime to the police. During the investigation, he acknowledged a sexual relationship with Murray. Homosexual acts were criminal offences in the United Kingdom at that time, and both men were charged with "gross indecency" under Section 11 of the Criminal Law Amendment Act 1885. Initial committal proceedings for the trial were held on 27 February during which Turing's solicitor "reserved his defence", i.e., did not argue or provide evidence against the allegations.

Turing was later convinced by the advice of his brother and his own solicitor, and he entered a plea of guilty. The case, "Regina v. Turing and Murray," was brought to trial on 31 March 1952. Turing was convicted and given a choice between imprisonment and probation. His probation would be conditional on his agreement to undergo hormonal physical changes designed to reduce libido. He accepted the option of injections of what was then called stilboestrol (now known as diethylstilbestrol or DES), a synthetic oestrogen; this feminization of his body was continued for the course of one year. The treatment rendered Turing impotent and caused breast tissue to form, fulfilling in the literal sense Turing's prediction that "no doubt I shall emerge from it all a different man, but quite who I've not found out". Murray was given a conditional discharge.

Turing's conviction led to the removal of his security clearance and barred him from continuing with his cryptographic consultancy for the Government Communications Headquarters (GCHQ), the British signals intelligence agency that had evolved from GC&CS in 1946, though he kept his academic job. He was denied entry into the United States after his conviction in 1952, but was free to visit other European countries. Turing was never accused of espionage but, in common with all who had worked at Bletchley Park, he was prevented by the Official Secrets Act from discussing his war work.

On 8 June 1954, Turing's housekeeper found him dead at the age of 41; he had died the previous day. Cyanide poisoning was established as the cause of death. When his body was discovered, an apple lay half-eaten beside his bed, and although the apple was not tested for cyanide, it was speculated that this was the means by which Turing had consumed a fatal dose. An inquest determined that he had committed suicide. Andrew Hodges and another biographer, David Leavitt, have both speculated that Turing was re-enacting a scene from the Walt Disney film "Snow White and the Seven Dwarfs" (1937), his favourite fairy tale. Both men noted that (in Leavitt's words) he took "an especially keen pleasure in the scene where the Wicked Queen immerses her apple in the poisonous brew." Turing's remains were cremated at Woking Crematorium on 12 June 1954 and his ashes were scattered in the gardens of the crematorium, just as his father's had been.

Philosophy professor Jack Copeland has questioned various aspects of the coroner's historical verdict. He suggested an alternative explanation for the cause of Turing's death: the accidental inhalation of cyanide fumes from an apparatus used to electroplate gold onto spoons. The potassium cyanide was used to dissolve the gold. Turing had such an apparatus set up in his tiny spare room. Copeland noted that the autopsy findings were more consistent with inhalation than with ingestion of the poison. Turing also habitually ate an apple before going to bed, and it was not unusual for the apple to be discarded half-eaten. In addition, Turing had reportedly borne his legal setbacks and hormone treatment (which had been discontinued a year previously) "with good humour" and had shown no sign of despondency prior to his death. He even set down a list of tasks that he intended to complete upon returning to his office after the holiday weekend. Turing's mother believed that the ingestion was accidental, resulting from her son's careless storage of laboratory chemicals. Biographer Andrew Hodges theorised that Turing arranged the delivery of the equipment in order to deliberately allow his mother plausible deniability in regard to any suicide claims.
Conspiracy theorists pointed out that Turing was the cause of intense anxiety to the British authorities at the time of his death. The secret services feared that communists would entrap prominent homosexuals and use them to gather intelligence. Turing was still engaged in highly classified work when he was also a practising homosexual who holidayed in European countries near the Iron Curtain. According to the conspiracy theory, it is possible that the secret services considered him too great a security risk and assassinated one of the most brilliant minds in their employ.

Turing believed in extrasensory perception, and it has been suggested that his belief in fortune-telling may have caused his depressed mood. As a youth, Turing had been told by a gypsy fortune-teller that he would be a genius. Shortly before his death, during a day-trip to St Annes-on Sea with the Greenbaum family, Turing again decided to consult a fortune-teller. According to the Greenbaums' daughter, Barbara:But it was a lovely sunny day and Alan was in a cheerful mood and off we went... Then he thought it would be a good idea to go to the Pleasure Beach at Blackpool. We found a fortune-teller's tent and Alan said he'd like to go in so we waited around for him to come back... And this sunny, cheerful visage had shrunk into a pale, shaking, horror-stricken face. Something had happened. We don't know what the fortune-teller said but he obviously was deeply unhappy. I think that was probably the last time we saw him before we heard of his suicide."

In August 2009, British programmer John Graham-Cumming started a petition urging the British government to apologise for Turing's prosecution as a homosexual. The petition received more than 30,000 signatures. The Prime Minister, Gordon Brown, acknowledged the petition, releasing a statement on 10 September 2009 apologising and describing the treatment of Turing as "appalling":
In December 2011, William Jones created an e-petition requesting that the British government pardon Turing for his conviction of "gross indecency":
The petition gathered over 37,000 signatures, and was supported by Manchester MP John Leech but the request was discouraged by Justice Minister Lord McNally, who said:
John Leech, the MP for Manchester Withington (2005–15), submitted several bills to Parliament and campaigned with Jones to secure the pardon. Leech made the case in the House of Commons that Turing's contribution to the war made him a national hero and that it was "ultimately just embarrassing" that the conviction still stood. Leech continued to take the bill through Parliament and campaigned for several years until it was passed.

At the UK premiere of a film based on Turing's life, "The Imitation Game", the producers thanked Leech for bringing the topic to public attention and securing Turing's pardon. His campaign turned to acquiring pardons for the 75,000 other men convicted of the same crime. Leech's campaign gained public support from leading scientists, including Stephen Hawking.

On 26 July 2012, a bill was introduced in the House of Lords to grant a statutory pardon to Turing for offences under section 11 of the Criminal Law Amendment Act 1885, of which he was convicted on 31 March 1952. Late in the year in a letter to "The Daily Telegraph", the physicist Stephen Hawking and 10 other signatories including the Astronomer Royal Lord Rees, President of the Royal Society Sir Paul Nurse, Lady Trumpington (who worked for Turing during the war) and Lord Sharkey (the bill's sponsor) called on Prime Minister David Cameron to act on the pardon request. The government indicated it would support the bill, and it passed its third reading in the Lords in October.

At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage. The bill was due to return to the House of Commons on 28 February 2014, but before the bill could be debated in the House of Commons, the government elected to proceed under the royal prerogative of mercy. On 24 December 2013, Queen Elizabeth II signed a pardon for Turing's conviction for "gross indecency", with immediate effect. Announcing the pardon, Lord Chancellor Chris Grayling said Turing deserved to be "remembered and recognised for his fantastic contribution to the war effort" and not for his later criminal conviction. The Queen officially pronounced Turing pardoned in August 2014. The Queen's action is only the fourth royal pardon granted since the conclusion of the Second World War. Pardons are normally granted only when the person is technically innocent, and a request has been made by the family or other interested party; neither condition was met in regard to Turing's conviction.

In a letter to the Prime Minister, David Cameron, human rights advocate Peter Tatchell criticised the decision to single out Turing due to his fame and achievements when thousands of others convicted under the same law have not received pardons. Tatchell also called for a new investigation into Turing's death:

In September 2016, the government announced its intention to expand this retroactive exoneration to other men convicted of similar historical indecency offences, in what was described as an "Alan Turing law". The Alan Turing law is now an informal term for the law in the United Kingdom, contained in the Policing and Crime Act 2017, which serves as an amnesty law to retroactively pardon men who were cautioned or convicted under historical legislation that outlawed homosexual acts. The law applies in England and Wales.

Turing was appointed an officer of the Order of the British Empire 1946. He was also elected a Fellow of the Royal Society (FRS) in 1951. Several things are named in his honour:

Various institutions have paid tribute to Turing by naming things after him including:

A biography published by the Royal Society shortly after Turing's death, while his wartime work was still subject to the Official Secrets Act, recorded:

Since 1966, the Turing Award has been given annually by the Association for Computing Machinery for technical or theoretical contributions to the computing community. It is widely considered to be the computing world's highest honour, equivalent to the Nobel Prize.

On 23 June 1998, on what would have been Turing's 86th birthday, his biographer, Andrew Hodges, unveiled an official English Heritage blue plaque at his birthplace in Warrington Crescent, London, later the Colonnade Hotel. To mark the 50th anniversary of his death, a memorial plaque was unveiled on 7 June 2004 at his former residence, Hollymeade, in Wilmslow, Cheshire.

On 13 March 2000, Saint Vincent and the Grenadines issued a set of postage stamps to celebrate the greatest achievements of the 20th century, one of which carries a portrait of Turing against a background of repeated 0s and 1s, and is captioned: "1937: Alan Turing's theory of digital computing". On 1 April 2003, Turing's work at Bletchley Park was named an IEEE Milestone. On 28 October 2004, a bronze statue of Turing sculpted by John W. Mills was unveiled at the University of Surrey in Guildford, marking the 50th anniversary of Turing's death; it portrays him carrying his books across the campus.

Turing was one of four mathematicians examined in the BBC documentary entitled "Dangerous Knowledge" (2008). The "Princeton Alumni Weekly" named Turing the second most significant alumnus in the history of Princeton University, second only to President James Madison. A 1.5-ton, life-size statue of Turing was unveiled on 19 June 2007 at Bletchley Park. Built from approximately half a million pieces of Welsh slate, it was sculpted by Stephen Kettle, having been commissioned by the American billionaire Sidney Frank.

Turing has been honoured in various ways in Manchester, the city where he worked towards the end of his life. In 1994, a stretch of the A6010 road (the Manchester city intermediate ring road) was named "Alan Turing Way". A bridge carrying this road was widened, and carries the name Alan Turing Bridge. A statue of Turing was unveiled in Manchester on 23 June 2001 in Sackville Park, between the University of Manchester building on Whitworth Street and Canal Street. The memorial statue depicts the "father of computer science" sitting on a bench at a central position in the park. Turing is shown holding an apple. The cast bronze bench carries in relief the text 'Alan Mathison Turing 1912–1954', and the motto 'Founder of Computer Science' as it could appear if encoded by an Enigma machine: 'IEKYF ROMSI ADXUO KVKZC GUBJ'. However, the meaning of the coded message is disputed, as the 'u' in 'computer' matches up with the 'u' in 'ADXUO'. As a letter encoded by an enigma machine can not appear as itself, the actual message behind the code is uncertain.

A plaque at the statue's feet reads 'Father of computer science, mathematician, logician, wartime codebreaker, victim of prejudice'. There is also a Bertrand Russell quotation: "Mathematics, rightly viewed, possesses not only truth, but supreme beauty—a beauty cold and austere, like that of sculpture." The sculptor buried his own old Amstrad computer under the plinth as a tribute to "the godfather of all modern computers".

In 1999, "Time" magazine named Turing as one of the and stated, "The fact remains that everyone who taps at a keyboard, opening a spreadsheet or a word-processing program, is working on an incarnation of a Turing machine."

In 2002, Turing was ranked twenty-first on the BBC's poll of the 100 Greatest Britons following a UK-wide vote. In 2006, British writer and mathematician Ioan James chose Turing as one of twenty people to feature in his book about famous historical figures who may have had some of the traits of Asperger syndrome. In 2010, actor/playwright Jade Esteban Estrada portrayed Turing in the solo musical, "Icons: The Lesbian and Gay History of the World, Vol. 4". In 2011, in "The Guardian"s "My hero" series, writer Alan Garner chose Turing as his hero and described how they had met while out jogging in the early 1950s. Garner remembered Turing as "funny and witty" and said that he "talked endlessly". In 2006, Turing was named with online resources as an LGBT History Month Icon. In 2006, Boston Pride named Turing their Honorary Grand Marshal.

The logo of Apple Inc. is often erroneously referred to as a tribute to Turing, with the bite mark a reference to his death. Both the designer of the logo and the company deny that there is any homage to Turing in the design. Stephen Fry has recounted asking Steve Jobs whether the design was intentional, saying that Jobs' response was, "God, we wish it were." In February 2011, Turing's papers from the Second World War were bought for the nation with an 11th-hour bid by the National Heritage Memorial Fund, allowing them to stay at Bletchley Park.

In 2012, Turing was inducted into the Legacy Walk, an outdoor public display that celebrates LGBT history and people.

The song "Alan et la Pomme", by francophone singer-songwriter Salvatore Adamo, is a tribute to Turing. Turing's life and work featured in a BBC children's programme about famous scientists, "Absolute Genius with Dick and Dom", first broadcast on 12 March 2014.

On 17 May 2014, the world's first work of public art to recognise Turing as gay was commissioned in Bletchley, close by to Bletchley Park where his war-time work was carried out. The commission was announced to mark International Day Against Homophobia and Transphobia. The work was unveiled at a ceremony on Turing's birthday, 23 June 2014, and is placed alongside busy Watling Street, the old main road to London, where Turing himself would have passed by on many occasions. On 22 October 2014, Turing was inducted into the NSA Hall of Honor.

In February 2019, in the BBC eight-part series "", Turing was voted by viewers to be the Greatest Person.

To mark the 100th anniversary of Turing's birth, the Turing Centenary Advisory Committee (TCAC) co-ordinated the Alan Turing Year, a year-long programme of events around the world honouring Turing's life and achievements. The TCAC, chaired by S. Barry Cooper with Turing's nephew Sir John Dermot Turing acting as Honorary President, worked with the University of Manchester faculty members and a broad spectrum of people from Cambridge University and Bletchley Park.

On 23 June 2012, Google featured an interactive doodle where visitors had to change the instructions of a Turing Machine, so when run, the symbols on the tape would match a provided sequence, featuring "Google" in Baudot-Murray code.

The Bletchley Park Trust collaborated with Winning Moves to publish an Alan Turing edition of the board game Monopoly. The game's squares and cards have been revised to tell the story of Turing's life, from his birthplace in Maida Vale to Hut 8 at Bletchley Park. The game also includes a replica of an original hand-drawn board created by William Newman, son of Turing's mentor, Max Newman, which Turing played on in the 1950s.

In the Philippines, the Department of Philosophy at De La Salle University-Manila hosted Turing 2012, an international conference on philosophy, artificial intelligence, and cognitive science from 27 to 28 March 2012 to commemorate the centenary birth of Turing. Madurai, India held celebrations with a programme attended by 6,000 students.
There was a three-day conference in Manchester in June, the Alan Turing Centenary Conference, a two-day conference in San Francisco, organised by the ACM, and a birthday party and Turing Centenary Conference in Cambridge organised at King's College, Cambridge, and the University of Cambridge, the latter organised by the association Computability in Europe.

The Science Museum in London launched a free exhibition devoted to Turing's life and achievements in June 2012, to run until July 2013. In February 2012, the Royal Mail issued a stamp featuring Turing as part of its "Britons of Distinction" series. The London 2012 Olympic Torch flame was passed on in front of Turing's statue in Sackville Gardens, Manchester, on the evening of 23 June 2012, the 100th anniversary of his birth.

On 22 June 2012 Manchester City Council, in partnership with the Lesbian and Gay Foundation, launched the Alan Turing Memorial Award, which will recognise individuals or groups who have made a significant contribution to the fight against homophobia in Manchester.

At the University of Oxford, a new course in Computer Science and Philosophy was established to coincide with the centenary of Turing's birth.

Previous events have included a celebration of Turing's life and achievements, at the University of Manchester, arranged by the British Logic Colloquium and the British Society for the History of Mathematics on 5 June 2004.











</doc>
<doc id="1209" url="https://en.wikipedia.org/wiki?curid=1209" title="Area">
Area

Area is the quantity that expresses the extent of a two-dimensional figure or shape, or planar lamina, in the plane. Surface area is its analog on the two-dimensional surface of a three-dimensional object. Area can be understood as the amount of material with a given thickness that would be necessary to fashion a model of the shape, or the amount of paint necessary to cover the surface with a single coat. It is the two-dimensional analog of the length of a curve (a one-dimensional concept) or the volume of a solid (a three-dimensional concept).

The area of a shape can be measured by comparing the shape to squares of a fixed size. In the International System of Units (SI), the standard unit of area is the square metre (written as m), which is the area of a square whose sides are one metre long. A shape with an area of three square metres would have the same area as three such squares. In mathematics, the unit square is defined to have area one, and the area of any other shape or surface is a dimensionless real number.

There are several well-known formulas for the areas of simple shapes such as triangles, rectangles, and circles. Using these formulas, the area of any polygon can be found by dividing the polygon into triangles. For shapes with curved boundary, calculus is usually required to compute the area. Indeed, the problem of determining the area of plane figures was a major motivation for the historical development of calculus.

For a solid shape such as a sphere, cone, or cylinder, the area of its boundary surface is called the surface area. Formulas for the surface areas of simple shapes were computed by the ancient Greeks, but computing the surface area of a more complicated shape usually requires multivariable calculus.

Area plays an important role in modern mathematics. In addition to its obvious importance in geometry and calculus, area is related to the definition of determinants in linear algebra, and is a basic property of surfaces in differential geometry. In analysis, the area of a subset of the plane is defined using Lebesgue measure, though not every subset is measurable. In general, area in higher mathematics is seen as a special case of volume for two-dimensional regions.

Area can be defined through the use of axioms, defining it as a function of a collection of certain plane figures to the set of real numbers. It can be proved that such a function exists.

An approach to defining what is meant by "area" is through axioms. "Area" can be defined as a function from a collection M of special kind of plane figures (termed measurable sets) to the set of real numbers which satisfies the following properties:

It can be proved that such an area function actually exists.

Every unit of length has a corresponding unit of area, namely the area of a square with the given side length. Thus areas can be measured in square metres (m), square centimetres (cm), square millimetres (mm), square kilometres (km), square feet (ft), square yards (yd), square miles (mi), and so forth. Algebraically, these units can be thought of as the squares of the corresponding length units.

The SI unit of area is the square metre, which is considered an SI derived unit.

Calculation of the area of a square whose length and width are 1 metre would be:

1 metre x 1 metre = 1 m

and so, a rectangle with different sides (say length of 3 metres and width of 2 metres) would have an area in square units that can be calculated as:

3 metres x 2 metres = 6 m. This is equivalent to 6 million square millimetres. Other useful conversions are:

In non-metric units, the conversion between two square units is the square of the conversion between the corresponding length units.
the relationship between square feet and square inches is
where 144 = 12 = 12 × 12. Similarly:
In addition, conversion factors include:

There are several other common units for area. The are was the original unit of area in the metric system, with:
Though the are has fallen out of use, the hectare is still commonly used to measure land:
Other uncommon metric units of area include the tetrad, the hectad, and the myriad.

The acre is also commonly used to measure land areas, where
An acre is approximately 40% of a hectare.

On the atomic scale, area is measured in units of barns, such that:
The barn is commonly used in describing the cross-sectional area of interaction in nuclear physics.

In India,

In the 5th century BCE, Hippocrates of Chios was the first to show that the area of a disk (the region enclosed by a circle) is proportional to the square of its diameter, as part of his quadrature of the lune of Hippocrates, but did not identify the constant of proportionality. Eudoxus of Cnidus, also in the 5th century BCE, also found that the area of a disk is proportional to its radius squared.

Subsequently, Book I of Euclid's "Elements" dealt with equality of areas between two-dimensional figures. The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book "Measurement of a Circle". (The circumference is 2"r", and the area of a triangle is half the base times the height, yielding the area "r" for the disk.) Archimedes approximated the value of π (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).

Swiss scientist Johann Heinrich Lambert in 1761 proved that π, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers. In 1794 French mathematician Adrien-Marie Legendre proved that π is irrational; this also proves that π is irrational. In 1882, German mathematician Ferdinand von Lindemann proved that π is transcendental (not the solution of any polynomial equation with rational coefficients), confirming a conjecture made by both Legendre and Euler.

Heron (or Hero) of Alexandria found what is known as Heron's formula for the area of a triangle in terms of its sides, and a proof can be found in his book, "Metrica", written around 60 CE. It has been suggested that Archimedes knew the formula over two centuries earlier, and since "Metrica" is a collection of the mathematical knowledge available in the ancient world, it is possible that the formula predates the reference given in that work.

In 499 Aryabhata, a great mathematician-astronomer from the classical age of Indian mathematics and Indian astronomy, expressed the area of a triangle as one-half the base times the height in the "Aryabhatiya" (section 2.6).

A formula equivalent to Heron's was discovered by the Chinese independently of the Greeks. It was published in 1247 in "Shushu Jiuzhang" ("Mathematical Treatise in Nine Sections"), written by Qin Jiushao.

In the 7th century CE, Brahmagupta developed a formula, now known as Brahmagupta's formula, for the area of a cyclic quadrilateral (a quadrilateral inscribed in a circle) in terms of its sides. In 1842 the German mathematicians Carl Anton Bretschneider and Karl Georg Christian von Staudt independently found a formula, known as Bretschneider's formula, for the area of any quadrilateral.

The development of Cartesian coordinates by René Descartes in the 17th century allowed the development of the surveyor's formula for the area of any polygon with known vertex locations by Gauss in the 19th century.

The development of integral calculus in the late 17th century provided tools that could subsequently be used for computing more complicated areas, such as the area of an ellipse and the surface areas of various curved three-dimensional objects.

For a non-self-intersecting (simple) polygon, the Cartesian coordinates formula_1 ("i"=0, 1, ..., "n"-1) of whose "n" vertices are known, the area is given by the surveyor's formula:

where when "i"="n"-1, then "i"+1 is expressed as modulus "n" and so refers to 0.

The most basic area formula is the formula for the area of a rectangle. Given a rectangle with length and width , the formula for the area is:

That is, the area of the rectangle is the length multiplied by the width. As a special case, as in the case of a square, the area of a square with side length is given by the formula:

The formula for the area of a rectangle follows directly from the basic properties of area, and is sometimes taken as a definition or axiom. On the other hand, if geometry is developed before arithmetic, this formula can be used to define multiplication of real numbers.

Most other simple formulas for area follow from the method of dissection.
This involves cutting a shape into pieces, whose areas must sum to the area of the original shape.

For an example, any parallelogram can be subdivided into a trapezoid and a right triangle, as shown in figure to the left. If the triangle is moved to the other side of the trapezoid, then the resulting figure is a rectangle. It follows that the area of the parallelogram is the same as the area of the rectangle:

However, the same parallelogram can also be cut along a diagonal into two congruent triangles, as shown in the figure to the right. It follows that the area of each triangle is half the area of the parallelogram:
Similar arguments can be used to find area formulas for the trapezoid as well as more complicated polygons.

The formula for the area of a circle (more properly called the area enclosed by a circle or the area of a disk) is based on a similar method. Given a circle of radius , it is possible to partition the circle into sectors, as shown in the figure to the right. Each sector is approximately triangular in shape, and the sectors can be rearranged to form an approximate parallelogram. The height of this parallelogram is , and the width is half the circumference of the circle, or . Thus, the total area of the circle is :
Though the dissection used in this formula is only approximate, the error becomes smaller and smaller as the circle is partitioned into more and more sectors. The limit of the areas of the approximate parallelograms is exactly , which is the area of the circle.

This argument is actually a simple application of the ideas of calculus. In ancient times, the method of exhaustion was used in a similar way to find the area of the circle, and this method is now recognized as a precursor to integral calculus. Using modern methods, the area of a circle can be computed using a definite integral:

The formula for the area enclosed by an ellipse is related to the formula of a circle; for an ellipse with semi-major and semi-minor axes and the formula is:

Most basic formulas for surface area can be obtained by cutting surfaces and flattening them out. For example, if the side surface of a cylinder (or any prism) is cut lengthwise, the surface can be flattened out into a rectangle. Similarly, if a cut is made along the side of a cone, the side surface can be flattened out into a sector of a circle, and the resulting area computed.

The formula for the surface area of a sphere is more difficult to derive: because a sphere has nonzero Gaussian curvature, it cannot be flattened out. The formula for the surface area of a sphere was first obtained by Archimedes in his work "On the Sphere and Cylinder". The formula is:


(see Green's theorem) or the "z"-component of

To find the bounded area between two quadratic functions, we subtract one from the other to write the difference as
where "f"("x") is the quadratic upper bound and "g"("x") is the quadratic lower bound. Define the discriminant of "f"("x")-"g"("x") as
By simplifying the integral formula between the graphs of two functions (as given in the section above) and using Vieta's formula, we can obtain
The above remains valid if one of the bounding functions is linear instead of quadratic.


The general formula for the surface area of the graph of a continuously differentiable function formula_35 where formula_36 and formula_37 is a region in the xy-plane with the smooth boundary:
An even more general formula for the area of the graph of a parametric surface in the vector form formula_39 where formula_40 is a continuously differentiable vector function of formula_41 is:

The above calculations show how to find the areas of many common shapes.

The areas of irregular polygons can be calculated using the "Surveyor's formula".

The isoperimetric inequality states that, for a closed curve of length "L" (so the region it encloses has perimeter "L") and for area "A" of the region that it encloses,

and equality holds if and only if the curve is a circle. Thus a circle has the largest area of any closed figure with a given perimeter.

At the other extreme, a figure with given perimeter "L" could have an arbitrarily small area, as illustrated by a rhombus that is "tipped over" arbitrarily far so that two of its angles are arbitrarily close to 0° and the other two are arbitrarily close to 180°.

For a circle, the ratio of the area to the circumference (the term for the perimeter of a circle) equals half the radius "r". This can be seen from the area formula "πr" and the circumference formula 2"πr".

The area of a regular polygon is half its perimeter times the apothem (where the apothem is the distance from the center to the nearest point on any side).

Doubling the edge lengths of a polygon multiplies its area by four, which is two (the ratio of the new to the old side length) raised to the power of two (the dimension of the space the polygon resides in). But if the one-dimensional lengths of a fractal drawn in two dimensions are all doubled, the spatial content of the fractal scales by a power of two that is not necessarily an integer. This power is called the fractal dimension of the fractal.
There are an infinitude of lines that bisect the area of a triangle. Three of them are the medians of the triangle (which connect the sides' midpoints with the opposite vertices), and these are concurrent at the triangle's centroid; indeed, they are the only area bisectors that go through the centroid. Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's incenter (the center of its incircle). There are either one, two, or three of these for any given triangle.

Any line through the midpoint of a parallelogram bisects the area.

All area bisectors of a circle or other ellipse go through the center, and any chords through the center bisect the area. In the case of a circle they are the diameters of the circle.

Given a wire contour, the surface of least area spanning ("filling") it is a minimal surface. Familiar examples include soap bubbles.

The question of the filling area of the Riemannian circle remains open.

The circle has the largest area of any two-dimensional object having the same perimeter.

A cyclic polygon (one inscribed in a circle) has the largest area of any polygon with a given number of sides of the same lengths.

A version of the isoperimetric inequality for triangles states that the triangle of greatest area among all those with a given perimeter is equilateral.

The triangle of largest area of all those inscribed in a given circle is equilateral; and the triangle of smallest area of all those circumscribed around a given circle is equilateral.

The ratio of the area of the incircle to the area of an equilateral triangle, formula_44, is larger than that of any non-equilateral triangle.

The ratio of the area to the square of the perimeter of an equilateral triangle, formula_45 is larger than that for any other triangle.



</doc>
<doc id="1210" url="https://en.wikipedia.org/wiki?curid=1210" title="Astronomical unit">
Astronomical unit

The astronomical unit (symbol: au, ua, or AU) is a unit of length, roughly the distance from Earth to the Sun. However, that distance varies as Earth orbits the Sun, from a maximum (aphelion) to a minimum (perihelion) and back again once a year. Originally conceived as the average of Earth's aphelion and perihelion, since 2012 it has been defined as exactly metres, or about . The astronomical unit is used primarily for measuring distances within the Solar System or around other stars. It is also a fundamental component in the definition of another unit of astronomical length, the parsec.

A variety of unit symbols and abbreviations have been in use for the astronomical unit. In a 1976 resolution, the International Astronomical Union (IAU) had used the symbol "A" to denote a length equal to the astronomical unit. In the astronomical literature, the symbol AU was (and remains) common. In 2006, the International Bureau of Weights and Measures (BIPM) had recommended ua as the symbol for the unit. In the non-normative Annex C to ISO 80000-3 (2006), the symbol of the astronomical unit is "ua". In 2012, the IAU, noting "that various symbols are presently in use for the astronomical unit", recommended the use of the symbol "au", as did the American Astronomical Society (AAS) in the manuscript preparation guidelines for its principal journals. In the 2014 revision and 2019 edition of the SI Brochure, the BIPM used the unit symbol "au".

Earth's orbit around the Sun is an ellipse. The semi-major axis of this elliptic orbit is defined to be half of the straight line segment that joins the perihelion and aphelion. The centre of the Sun lies on this straight line segment, but not at its midpoint. Because ellipses are well-understood shapes, measuring the points of its extremes defined the exact shape mathematically, and made possible calculations for the entire orbit as well as predictions based on observation. In addition, it mapped out exactly the largest straight-line distance that Earth traverses over the course of a year, defining times and places for observing the largest parallax (apparent shifts of position) in nearby stars. Knowing Earth's shift and a star's shift enabled the star's distance to be calculated. But all measurements are subject to some degree of error or uncertainty, and the uncertainties in the length of the astronomical unit only increased uncertainties in the stellar distances. Improvements in precision have always been a key to improving astronomical understanding. Throughout the twentieth century, measurements became increasingly precise and sophisticated, and ever more dependent on accurate observation of the effects described by Einstein's theory of relativity and upon the mathematical tools it used.

Improving measurements were continually checked and cross-checked by means of improved understanding of the laws of celestial mechanics, which govern the motions of objects in space. The expected positions and distances of objects at an established time are calculated (in AU) from these laws, and assembled into a collection of data called an ephemeris. NASA Jet Propulsion Laboratory HORIZONS System provides one of several ephemeris computation services.

In 1976, in order to establish a yet more precise measure for the astronomical unit, the IAU formally adopted a new definition. Although directly based on the then-best available observational measurements, the definition was recast in terms of the then-best mathematical derivations from celestial mechanics and planetary ephemerides. It stated that "the astronomical unit of length is that length ("A") for which the Gaussian gravitational constant ("k") takes the value when the units of measurement are the astronomical units of length, mass and time". Equivalently, by this definition, one AU is "the radius of an unperturbed circular Newtonian orbit about the sun of a particle having infinitesimal mass, moving with an angular frequency of "; or alternatively that length for which the heliocentric gravitational constant (the product "G") is equal to () AU/d, when the length is used to describe the positions of objects in the Solar System.

Subsequent explorations of the Solar System by space probes made it possible to obtain precise measurements of the relative positions of the inner planets and other objects by means of radar and telemetry. As with all radar measurements, these rely on measuring the time taken for photons to be reflected from an object. Because all photons move at the speed of light in vacuum, a fundamental constant of the universe, the distance of an object from the probe is calculated as the product of the speed of light and the measured time. However, for precision the calculations require adjustment for things such as the motions of the probe and object while the photons are transiting. In addition, the measurement of the time itself must be translated to a standard scale that accounts for relativistic time dilation. Comparison of the ephemeris positions with time measurements expressed in the TDB scale leads to a value for the speed of light in astronomical units per day (of ). By 2009, the IAU had updated its standard measures to reflect improvements, and calculated the speed of light at (TDB).

In 1983, the International Committee for Weights and Measures (CIPM) modified the International System of Units (SI, or "modern" metric system) to make the metre defined as the distance travelled in a vacuum by light in 1/299792458 second. This replaced the previous definition, valid between 1960 and 1983, which was that the metre equalled a certain number of wavelengths of a certain emission line of krypton-86. (The reason for the change was an improved method of measuring the speed of light.) The speed of light could then be expressed exactly as "c" = , a standard also adopted by the IERS numerical standards. From this definition and the 2009 IAU standard, the time for light to traverse an AU is found to be "τ" = , which is slightly more than 8 minutes 19 seconds. By multiplication, the best IAU 2009 estimate was "A" = "c""τ" = , based on a comparison of JPL and IAA–RAS ephemerides.

In 2006, the BIPM reported a value of the astronomical unit as . In the 2014 revision of the SI Brochure, the BIPM recognised the IAU's 2012 redefinition of the astronomical unit as . or an increase of 9 meters.

This estimate was still derived from observation and measurements subject to error, and based on techniques that did not yet standardize all relativistic effects, and thus were not constant for all observers. In 2012, finding that the equalization of relativity alone would make the definition overly complex, the IAU simply used the 2009 estimate to redefine the astronomical unit as a conventional unit of length directly tied to the metre (exactly ). The new definition also recognizes as a consequence that the astronomical unit is now to play a role of reduced importance, limited in its use to that of a convenience in some applications.

This definition makes the speed of light, defined as exactly , equal to exactly  ×  ÷  or about AU/d, some 60 parts per trillion less than the 2009 estimate.

With the definitions used before 2012, the astronomical unit was dependent on the heliocentric gravitational constant, that is the product of the gravitational constant "G" and the solar mass . Neither "G" nor can be measured to high accuracy separately, but the value of their product is known very precisely from observing the relative positions of planets (Kepler's Third Law expressed in terms of Newtonian gravitation). Only the product is required to calculate planetary positions for an ephemeris, so ephemerides are calculated in astronomical units and not in SI units.

The calculation of ephemerides also requires a consideration of the effects of general relativity. In particular, time intervals measured on Earth's surface (terrestrial time, TT) are not constant when compared to the motions of the planets: the terrestrial second (TT) appears to be longer during the Northern Hemisphere winter and shorter during the Northern Hemisphere summer when compared to the "planetary second" (conventionally measured in barycentric dynamical time, TDB). This is because the distance between Earth and the Sun is not fixed (it varies between and ) and, when Earth is closer to the Sun (perihelion), the Sun's gravitational field is stronger and Earth is moving faster along its orbital path. As the metre is defined in terms of the second and the speed of light is constant for all observers, the terrestrial metre appears to change in length compared to the "planetary metre" on a periodic basis.

The metre is defined to be a unit of proper length, but the SI definition does not specify the metric tensor to be used in determining it. Indeed, the International Committee for Weights and Measures (CIPM) notes that "its definition applies only within a spatial extent sufficiently small that the effects of the non-uniformity of the gravitational field can be ignored". As such, the metre is undefined for the purposes of measuring distances within the Solar System. The 1976 definition of the astronomical unit was incomplete because it did not specify the frame of reference in which time is to be measured, but proved practical for the calculation of ephemerides: a fuller definition that is consistent with general relativity was proposed, and "vigorous debate" ensued until August 2012 when the IAU adopted the current definition of 1 astronomical unit = metres.

The astronomical unit is typically used for stellar system scale distances, such as the size of a protostellar disk or the heliocentric distance of an asteroid, whereas other units are used for other distances in astronomy. The astronomical unit is too small to be convenient for interstellar distances, where the parsec and light-year are widely used. The parsec (parallax arcsecond) is defined in terms of the astronomical unit, being the distance of an object with a parallax of 1 arcsecond. The light-year is often used in popular works, but is not an approved non-SI unit and is rarely used by professional astronomers.

When simulating a numerical model of the Solar System, the astronomical unit provides an appropriate scale that minimizes (overflow, underflow and truncation) errors in floating point calculations.

The book "On the Sizes and Distances of the Sun and Moon", which has long been ascribed to Aristarchus, says that he calculated the distance to the Sun to be between 18 and 20 times the distance to the Moon, whereas the true ratio is about 389.174. The latter estimate was based on the angle between the half moon and the Sun, which he estimated as 87° (the true value being close to 89.853°). Depending on the distance that Van Helden assumes Aristarchus used for the distance to the Moon, his calculated distance to the Sun would fall between 380 and Earth radii.

According to Eusebius of Caesarea in the "Praeparatio Evangelica" (Book XV, Chapter 53), Eratosthenes found the distance to the Sun to be "σταδιων μυριαδας τετρακοσιας και οκτωκισμυριας" (literally "of "stadia" myriads 400 and ") but with the additional note that in the Greek text the grammatical agreement is between "myriads" (not "stadia") on the one hand and both "400" and "" on the other, as in Greek, unlike English, all three (or all four if one were to include "stadia") words are inflected. This has been translated either as "stadia" (1903 translation by Edwin Hamilton Gifford), or as "stadia" (edition of , dated 1974–1991). Using the Greek stadium of 185 to 190 metres, the former translation comes to to , which is far too low, whereas the second translation comes to 148.7 to 152.8 million kilometres (accurate within 2%). Hipparchus also gave an estimate of the distance of Earth from the Sun, quoted by Pappus as equal to 490 Earth radii. According to the conjectural reconstructions of Noel Swerdlow and G. J. Toomer, this was derived from his assumption of a "least perceptible" solar parallax of 7 arc minutes.

A Chinese mathematical treatise, the "Zhoubi Suanjing" (c. 1st century BCE), shows how the distance to the Sun can be computed geometrically, using the different lengths of the noontime shadows observed at three places li apart and the assumption that Earth is flat.

In the 2nd century CE, Ptolemy estimated the mean distance of the Sun as times Earth's radius. To determine this value, Ptolemy started by measuring the Moon's parallax, finding what amounted to a horizontal lunar parallax of 1° 26′, which was much too large. He then derived a maximum lunar distance of Earth radii. Because of cancelling errors in his parallax figure, his theory of the Moon's orbit, and other factors, this figure was approximately correct. He then measured the apparent sizes of the Sun and the Moon and concluded that the apparent diameter of the Sun was equal to the apparent diameter of the Moon at the Moon's greatest distance, and from records of lunar eclipses, he estimated this apparent diameter, as well as the apparent diameter of the shadow cone of Earth traversed by the Moon during a lunar eclipse. Given these data, the distance of the Sun from Earth can be trigonometrically computed to be Earth radii. This gives a ratio of solar to lunar distance of approximately 19, matching Aristarchus's figure. Although Ptolemy's procedure is theoretically workable, it is very sensitive to small changes in the data, so much so that changing a measurement by a few percent can make the solar distance infinite.

After Greek astronomy was transmitted to the medieval Islamic world, astronomers made some changes to Ptolemy's cosmological model, but did not greatly change his estimate of the Earth–Sun distance. For example, in his introduction to Ptolemaic astronomy, al-Farghānī gave a mean solar distance of Earth radii, whereas in his "zij", al-Battānī used a mean solar distance of Earth radii. Subsequent astronomers, such as al-Bīrūnī, used similar values. Later in Europe, Copernicus and Tycho Brahe also used comparable figures ( and Earth radii), and so Ptolemy's approximate Earth–Sun distance survived through the 16th century.

Johannes Kepler was the first to realize that Ptolemy's estimate must be significantly too low (according to Kepler, at least by a factor of three) in his "Rudolphine Tables" (1627). Kepler's laws of planetary motion allowed astronomers to calculate the relative distances of the planets from the Sun, and rekindled interest in measuring the absolute value for Earth (which could then be applied to the other planets). The invention of the telescope allowed far more accurate measurements of angles than is possible with the naked eye. Flemish astronomer Godefroy Wendelin repeated Aristarchus' measurements in 1635, and found that Ptolemy's value was too low by a factor of at least eleven.

A somewhat more accurate estimate can be obtained by observing the transit of Venus. By measuring the transit in two different locations, one can accurately calculate the parallax of Venus and from the relative distance of Earth and Venus from the Sun, the solar parallax "α" (which cannot be measured directly due to the brightness of the Sun). Jeremiah Horrocks had attempted to produce an estimate based on his observation of the 1639 transit (published in 1662), giving a solar parallax of 15 arcseconds, similar to Wendelin's figure. The solar parallax is related to the Earth–Sun distance as measured in Earth radii by
The smaller the solar parallax, the greater the distance between the Sun and Earth: a solar parallax of 15" is equivalent to an Earth–Sun distance of Earth radii.

Christiaan Huygens believed that the distance was even greater: by comparing the apparent sizes of Venus and Mars, he estimated a value of about Earth radii, equivalent to a solar parallax of 8.6". Although Huygens' estimate is remarkably close to modern values, it is often discounted by historians of astronomy because of the many unproven (and incorrect) assumptions he had to make for his method to work; the accuracy of his value seems to be based more on luck than good measurement, with his various errors cancelling each other out.
Jean Richer and Giovanni Domenico Cassini measured the parallax of Mars between Paris and Cayenne in French Guiana when Mars was at its closest to Earth in 1672. They arrived at a figure for the solar parallax of ", equivalent to an Earth–Sun distance of about Earth radii. They were also the first astronomers to have access to an accurate and reliable value for the radius of Earth, which had been measured by their colleague Jean Picard in 1669 as thousand "toises". Another colleague, Ole Rømer, discovered the finite speed of light in 1676: the speed was so great that it was usually quoted as the time required for light to travel from the Sun to the Earth, or "light time per unit distance", a convention that is still followed by astronomers today.

A better method for observing Venus transits was devised by James Gregory and published in his "Optica Promata" (1663). It was strongly advocated by Edmond Halley and was applied to the transits of Venus observed in 1761 and 1769, and then again in 1874 and 1882. Transits of Venus occur in pairs, but less than one pair every century, and observing the transits in 1761 and 1769 was an unprecedented international scientific operation including observations by James Cook and Charles Green from Tahiti. Despite the Seven Years' War, dozens of astronomers were dispatched to observing points around the world at great expense and personal danger: several of them died in the endeavour. The various results were collated by Jérôme Lalande to give a figure for the solar parallax of 8.6″.
Another method involved determining the constant of aberration. Simon Newcomb gave great weight to this method when deriving his widely accepted value of 8.80″ for the solar parallax (close to the modern value of ″), although Newcomb also used data from the transits of Venus. Newcomb also collaborated with A. A. Michelson to measure the speed of light with Earth-based equipment; combined with the constant of aberration (which is related to the light time per unit distance), this gave the first direct measurement of the Earth–Sun distance in kilometres. Newcomb's value for the solar parallax (and for the constant of aberration and the Gaussian gravitational constant) were incorporated into the first international system of astronomical constants in 1896, which remained in place for the calculation of ephemerides until 1964. The name "astronomical unit" appears first to have been used in 1903.

The discovery of the near-Earth asteroid 433 Eros and its passage near Earth in 1900–1901 allowed a considerable improvement in parallax measurement. Another international project to measure the parallax of 433 Eros was undertaken in 1930–1931.

Direct radar measurements of the distances to Venus and Mars became available in the early 1960s. Along with improved measurements of the speed of light, these showed that Newcomb's values for the solar parallax and the constant of aberration were inconsistent with one another.

The unit distance "A" (the value of the astronomical unit in metres) can be expressed in terms of other astronomical constants:
where "G" is the Newtonian gravitational constant, is the solar mass, "k" is the numerical value of Gaussian gravitational constant and "D" is the time period of one day.
The Sun is constantly losing mass by radiating away energy, so the orbits of the planets are steadily expanding outward from the Sun. This has led to calls to abandon the astronomical unit as a unit of measurement.

As the speed of light has an exact defined value in SI units and the Gaussian gravitational constant "k" is fixed in the astronomical system of units, measuring the light time per unit distance is exactly equivalent to measuring the product "G" in SI units. Hence, it is possible to construct ephemerides entirely in SI units, which is increasingly becoming the norm.

A 2004 analysis of radiometric measurements in the inner Solar System suggested that the secular increase in the unit distance was much larger than can be accounted for by solar radiation, + metres per century.

The measurements of the secular variations of the astronomical unit are not confirmed by other authors and are quite controversial.
Furthermore, since 2010, the astronomical unit has not been estimated by the planetary ephemerides.

The following table contains some distances given in astronomical units. It includes some examples with distances that are normally not given in astronomical units, because they are either too short or far too long. Distances normally change over time. Examples are listed by increasing distance.




</doc>
<doc id="1212" url="https://en.wikipedia.org/wiki?curid=1212" title="Artist">
Artist

An artist is a person engaged in an activity related to creating art, practicing the arts, or demonstrating an art. The common usage in both everyday speech and academic discourse is a practitioner in the visual arts only. The term is often used in the entertainment business, especially in a business context, for musicians and other performers (less often for actors). "Artiste" (the French for artist) is a variant used in English only in this context; this use is becoming rare. Use of the term to describe writers, for example, is valid, but less common, and mostly restricted to contexts like criticism.

Wiktionary defines the noun 'artist' (Singular: artist; Plural: artists) as follows:
The "Oxford English Dictionary" defines the older broad meanings of the term "artist":


The Greek word "techně", often translated as "art," implies mastery of any sort of craft. The adjectival Latin form of the word, "technicus",
became the source of the English words technique, technology, technical.

In Greek culture each of the nine Muses oversaw a different field of human creation:

No muse was identified with the visual arts of painting and sculpture. In ancient Greece sculptors and painters were held in low regard, somewhere between freemen and slaves, their work regarded as mere manual labour.

The word "art" derives from the Latin "ars" (stem "art-"), which, although literally defined means "skill method" or "technique", also conveys a connotation of beauty.

During the Middle Ages the word "artist" already existed in some countries such as Italy, but the meaning was something resembling "craftsman", while the word "artesan" was still unknown. An artist was someone able to do a work better than others, so the skilled excellency was underlined, rather than the activity field. In this period some "artisanal" products (such as textiles) were much more precious and expensive than paintings or sculptures.

The first division into major and minor arts dates back at least to the works of Leon Battista Alberti (1404–1472): "De re aedificatoria, De statua, De pictura", which focused on the importance of the intellectual skills of the artist rather than the manual skills (even if in other forms of art there was a project behind).

With the Academies in Europe (second half of 16th century) the gap between fine and applied arts was definitely set.

Many contemporary definitions of "artist" and "art" are highly contingent on culture, resisting aesthetic prescription, in much the same way that the features constituting beauty and the beautiful cannot be standardized easily without corruption into kitsch.

"Artist" is a descriptive term applied to a person who engages in an activity deemed to be an art. An artist also may be defined unofficially as "a person who expresses him- or herself through a medium". The word is also used in a qualitative sense of, a person creative in, innovative in, or adept at, an artistic practice.

Most often, the term describes those who create within a context of the fine arts or 'high culture', activities such as drawing, painting, sculpture, acting, dancing, writing, filmmaking, new media, photography, and music—people who use imagination, talent, or skill to create works that may be judged to have an aesthetic value. Art historians and critics define artists as those who produce art within a recognized or recognizable discipline. Contrasting terms for highly skilled workers in media in the applied arts or decorative arts include artisan, craftsman, and specialized terms such as potter, goldsmith or glassblower. Fine arts artists such as painters succeeded in the Renaissance in raising their status, formerly similar to these workers, to a decisively higher level.

The term may also be used loosely or metaphorically to denote highly skilled people in any non-"art" activities, as well— law, medicine, mechanics, or mathematics, for example.

Often, discussions on the subject focus on the differences among "artist" and "technician", "entertainer" and "artisan", "fine art" and "applied art", or what constitutes art and what does not. The French word "artiste" (which in French, simply means "artist") has been imported into the English language where it means a performer (frequently in Music Hall or Vaudeville). Use of the word "artiste" can also be a pejorative term.

The English word 'artiste' has thus a narrower range of meaning than the word 'artiste' in French.

In "Living with Art", Mark Getlein proposes six activities, services or functions of contemporary artists:

After looking at years of data on arts school graduates as well as policies & program outcomes regarding artists, arts, & culture, Elizabeth Lingo and Steven Tepper propose the divide between "arts for art's sake" artists and commercially successful artists is not as wide as may be perceived, and that "this bifurcation between the commercial and the noncommercial, the excellent and the base, the elite and the popular, is increasingly breaking down" (Eikhof & Haunschild, 2007). Lingo and Tepper point out:

The US Bureau of Labor Statistics classifies many visual artists as either "craft artists" or "fine artists". A craft artist makes handmade functional works of art, such as pottery or clothing. A fine artist makes paintings, illustrations (such as book illustrations or medical illustrations), sculptures, or similar artistic works primarily for their aesthetic value.

The main source of skill for both craft artists and fine artists is long-term repetition and practice. Many fine artists have studied their art form at university and some have a master's degree in fine arts. Artists may also study on their own or receive on-the-job training from an experienced artist.

The number of available jobs as an artist is increasing more slowly than other fields. About half of US artists are self-employed. Others work in a variety of industries. For example, a pottery manufacturer will employ craft artists, and book publishers will hire illustrators.

In the US, fine artists have a median income of approximately US$50,000 per year, and craft artists have a median income of approximately US$33,000 per year. This compares to US$61,000 for all art-related fields, including related jobs such as graphic designers, multimedia artists, animators, and fashion designers. Many artists work part-time as artists and hold a second job.




</doc>
<doc id="1213" url="https://en.wikipedia.org/wiki?curid=1213" title="Actaeon">
Actaeon

Actaeon (; "Aktaion"), in Greek mythology, son of the priestly herdsman Aristaeus and Autonoe in Boeotia, was a famous Theban hero. Like Achilles in a later generation, he was trained by the centaur Chiron.

He fell to the fatal wrath of Artemis, but the surviving details of his transgression vary: "the only certainty is in what Aktaion suffered, his pathos, and what Artemis did: the hunter became the hunted; he was transformed into a stag, and his raging hounds, struck with a 'wolf's frenzy' (Lyssa), tore him apart as they would a stag." This is the iconic motif by which Actaeon is recognized, both in ancient art and in Renaissance and post-Renaissance depictions.

Among others, John Heath has observed, "The unalterable kernel of the tale was a hunter's transformation into a deer and his death in the jaws of his hunting dogs. But authors were free to suggest different motives for his death." In the version that was offered by the Hellenistic poet Callimachus, which has become the standard setting, Artemis was bathing in the woods when the hunter Actaeon stumbled across her, thus seeing her naked. He stopped and stared, amazed at her ravishing beauty. Once seen, Artemis got revenge on Actaeon: she forbade him speech — if he tried to speak, he would be changed into a stag — for the unlucky profanation of her virginity's mystery. Upon hearing the call of his hunting party, he cried out to them and immediately transformed. At this he fled deep into the woods, and doing so he came upon a pond and, seeing his reflection, groaned. His own hounds then turned upon him and pursued him, not recognizing him. In an endeavour to save himself, he raised his eyes (and would have raised his arms, had he had them) toward Mount Olympus. The gods did not heed his plea, and he was torn to pieces. An element of the earlier myth made Actaeon the familiar hunting companion of Artemis, no stranger. In an embroidered extension of the myth, the hounds were so upset with their master's death, that Chiron made a statue so lifelike that the hounds thought it was Actaeon.

There are various other versions of his transgression: The Hesiodic "Catalogue of Women" and pseudo-Apollodoran "Bibliotheke" state that his offense was that he was a rival of Zeus for Semele, his mother's sister, whereas in Euripides' "Bacchae" he has boasted that he is a better hunter than Artemis:
Further materials, including fragments that belong with the Hesiodic "Catalogue of Women" and at least four Attic tragedies, including a "Toxotides" of Aeschylus, have been lost. Diodorus Siculus (4.81.4), in a variant of Actaeon's "hubris" that has been largely ignored, has it that Actaeon wanted to marry Artemis. Other authors say the hounds were Artemis' own; some lost elaborations of the myth seem to have given them all names and narrated their wanderings after his loss.

According to the Latin version of the story told by the Roman Ovid having accidentally seen Diana (Artemis) on Mount Cithaeron while she was bathing, he was changed by her into a stag, and pursued and killed by his fifty hounds. This version also appears in Callimachus' Fifth Hymn, as a mythical parallel to the blinding of Tiresias after he sees Athena bathing.

The literary testimony of Actaeon's myth is largely lost, but Lamar Ronald Lacy, deconstructing the myth elements in what survives and supplementing it by iconographic evidence in late vase-painting, made a plausible reconstruction of an ancient Actaeon myth that Greek poets may have inherited and subjected to expansion and dismemberment. His reconstruction opposes a too-pat consensus that has an archaic Actaeon aspiring to Semele, a classical Actaeon boasting of his hunting prowess and a Hellenistic Actaeon glimpsing Artemis' bath. Lacy identifies the site of Actaeon's transgression as a spring sacred to Artemis at Plataea where Actaeon was a " hero archegetes" ("hero-founder") The righteous hunter, the companion of Artemis, seeing her bathing naked in the spring, was moved to try to make himself her consort, as Diodorus Siculus noted, and was punished, in part for transgressing the hunter's "ritually enforced deference to Artemis" (Lacy 1990:42).

Notes:


In the second century AD, the traveller Pausanias was shown a spring on the road in Attica leading to Plataea from Eleutherae, just beyond Megara "and a little farther on a rock. It is called the bed of Actaeon, for it is said that he slept thereon when weary with hunting and that into this spring he looked while Artemis was bathing in it."

In the standard version of the "Epic of Gilgamesh" (tablet vi) there is a parallel, in the series of examples Gilgamesh gives Ishtar of her mistreatment of her serial lovers:
"You loved the herdsman, shepherd and chief shepherd<br> Who was always heaping up the glowing ashes for you,<br> And cooked ewe-lambs for you every day.<br> But you hit him and turned him into a wolf,<br> His own herd-boys hunt him down<br>
And his dogs tear at his haunches.<br><nowiki>"</nowiki>Actaeon, torn apart by dogs incited by Artemis, finds another Near Eastern parallel in the Ugaritic hero Aqht, torn apart by eagles incited by Anath who wanted his hunting bow.

The virginal Artemis of classical times is not directly comparable to Ishtar of the many lovers, but the mytheme of Artemis shooting Orion, was linked to her punishment of Actaeon by T.C.W. Stinton; the Greek context of the mortal's reproach to the amorous goddess is translated to the episode of Anchises and Aphrodite. Daphnis too was a herdsman loved by a goddess and punished by her: see Theocritus' First Idyll.

In Greek Mythology, Actaeon is thought by many, including Hans Biedermann, to symbolize ritual human sacrifice in attempt to please a God or Goddess. In the case of Actaeon, the dogs symbolize the sacrificers and Actaeon symbolizes the sacrifice. Actaeon also may symbolize a human curiosity or irreverence.

The myth is seen by Jungian psychologist Wolfgang Giegerich as a symbol of spiritual transformation and/or enlightenment.

The two main scenes are Actaeon surprising Artemis/Diana, and his death. In classical art Actaeon is normally shown as fully human, even as his hounds are killing him (sometimes he has small horns), but in Renaissance art he is often given a deer's head with antlers even in the scene with Diana, and by the time he is killed he has at the least this head, and has often completely transformed into the shape of a deer. 






</doc>
<doc id="1214" url="https://en.wikipedia.org/wiki?curid=1214" title="Anglicanism">
Anglicanism

Anglicanism is a Western Christian tradition which has developed from the practices, liturgy, and identity of the Church of England following the English Reformation.

Adherents of Anglicanism are called "Anglicans". The majority of Anglicans are members of national or regional ecclesiastical provinces of the international Anglican Communion, which forms the third-largest Christian communion in the world, after the Roman Catholic Church and the Eastern Orthodox Church. They are in full communion with the See of Canterbury, and thus the Archbishop of Canterbury, whom the communion refers to as its "primus inter pares" (Latin, "first among equals"). He calls the decennial Lambeth Conference, chairs the meeting of primates, and is the president of the Anglican Consultative Council. Some churches that are not part of the Anglican Communion or recognised by the Anglican Communion also call themselves Anglican, including those that are part of the Continuing Anglican movement and Anglican realignment.

Anglicans base their Christian faith on the Bible, traditions of the apostolic Church, apostolic succession ("historic episcopate"), and the writings of the Church Fathers. Anglicanism forms one of the branches of Western Christianity, having definitively declared its independence from the Holy See at the time of the Elizabethan Religious Settlement. Many of the new Anglican formularies of the mid-16th century corresponded closely to those of contemporary Protestantism. These reforms in the Church of England were understood by one of those most responsible for them, Thomas Cranmer, the Archbishop of Canterbury, and others as navigating a middle way between two of the emerging Protestant traditions, namely Lutheranism and Calvinism.

In the first half of the 17th century, the Church of England and its associated Church of Ireland were presented by some Anglican divines as comprising a distinct Christian tradition, with theologies, structures, and forms of worship representing a different kind of middle way, or "via media", between Protestantism and Roman Catholicism – a perspective that came to be highly influential in later theories of Anglican identity and expressed in the description of Anglicanism as "Catholic and Reformed". The degree of distinction between Protestant and Catholic tendencies within the Anglican tradition is routinely a matter of debate both within specific Anglican churches and throughout the Anglican Communion. Unique to Anglicanism is the Book of Common Prayer, the collection of services in one Book used for centuries. The Book is acknowledged as a principal tie that binds the Anglican Communion together as a liturgical rather than a confessional tradition or one possessing a magisterium as in the Roman Catholic Church.

After the American Revolution, Anglican congregations in the United States and British North America (which would later form the basis for the modern country of Canada) were each reconstituted into autonomous churches with their own bishops and self-governing structures; these were known as the American Episcopal Church and the Church of England in the Dominion of Canada. Through the expansion of the British Empire and the activity of Christian missions, this model was adopted as the model for many newly formed churches, especially in Africa, Australasia, and Asia-Pacific. In the 19th century, the term "Anglicanism" was coined to describe the common religious tradition of these churches; as also that of the Scottish Episcopal Church, which, though originating earlier within the Church of Scotland, had come to be recognised as sharing this common identity.

The word "Anglican" originates in , a phrase from the Magna Carta dated 15 June 1215, meaning "the Anglican Church shall be free". Adherents of Anglicanism are called "Anglicans". As an adjective, "Anglican" is used to describe the people, institutions, and churches, as well as the liturgical traditions and theological concepts developed by the Church of England.

As a noun, an Anglican is a member of a church in the Anglican Communion. The word is also used by followers of separated groups which have left the communion or have been founded separately from it, although this is considered as a misuse by the Anglican Communion. The word "Anglicanism" came into being in the 19th century. The word originally referred only to the teachings and rites of Christians throughout the world in communion with the see of Canterbury, but has come to sometimes be extended to any church following those traditions rather than actual membership in the modern Anglican Communion.

Although the term "Anglican" is found referring to the Church of England as far back as the 16th century, its use did not become general until the latter half of the 19th century. In British parliamentary legislation referring to the English Established Church, there is no need for a description; it is simply the Church of England, though the word "Protestant" is used in many legal acts specifying the succession to the Crown and qualifications for office. When the Union with Ireland Act created the United Church of England and Ireland, it is specified that it shall be one "Protestant Episcopal Church", thereby distinguishing its form of church government from the Presbyterian polity that prevails in the Church of Scotland.

The word "Episcopal" is preferred in the title of the Episcopal Church (the province of the Anglican Communion covering the United States) and the Scottish Episcopal Church, though the full name of the former is "The Protestant Episcopal Church of the United States of America". Elsewhere, however, the term "Anglican Church" came to be preferred as it distinguished these churches from others that maintain an episcopal polity.

Anglicanism, in its structures, theology, and forms of worship, is commonly understood as a distinct Christian tradition representing a middle ground between what are perceived to be the extremes of the claims of 16th-century Roman Catholicism and the Lutheran and Reformed varieties of Protestantism of that era. As such, it is often referred to as being a "via media" (or "middle way") between these traditions.

The faith of Anglicans is founded in the Scriptures and the Gospels, the traditions of the Apostolic Church, the historical episcopate, the first four ecumenical councils, and the early Church Fathers (among these councils, especially the premier four ones, and among these Fathers, especially those active during the five initial centuries of Christianity, according to the "quinquasaecularist" principle proposed by the English bishop Lancelot Andrewes and the Lutheran dissident Georg Calixtus). Anglicans understand the Old and New Testaments as "containing all things necessary for salvation" and as being the rule and ultimate standard of faith. Reason and tradition are seen as valuable means to interpret scripture (a position first formulated in detail by Richard Hooker), but there is no full mutual agreement among Anglicans about "exactly how" scripture, reason, and tradition interact (or ought to interact) with each other. Anglicans understand the Apostles' Creed as the baptismal symbol and the Nicene Creed as the sufficient statement of the Christian faith.

Anglicans believe the catholic and apostolic faith is revealed in Holy Scripture and the Catholic creeds and interpret these in light of the Christian tradition of the historic church, scholarship, reason, and experience.

Anglicans celebrate the traditional sacraments, with special emphasis being given to the Eucharist, also called Holy Communion, the Lord's Supper or the Mass. The Eucharist is central to worship for most Anglicans as a communal offering of prayer and praise in which the life, death, and resurrection of Jesus Christ are proclaimed through prayer, reading of the Bible, singing, giving God thanks over the bread and wine for the innumerable benefits obtained through the passion of Christ, the breaking of the bread, the blessing of the cup, and the partaking of the body and blood of Christ as instituted at the Last Supper, however one wished to define the Presence. The consecrated bread and wine which are the true body and blood of Christ after a spiritual manner (not in a crude physical way) are outward symbols of an inner grace given by Christ, which to the repentant conveys forgiveness and cleaning from sin. While many Anglicans celebrate the Eucharist in similar ways to the predominant western Catholic tradition, a considerable degree of liturgical freedom is permitted, and worship styles range from the simple to elaborate.

Unique to Anglicanism is the "Book of Common Prayer" (BCP), the collection of services that worshippers in most Anglican churches have used for centuries. It was called "common prayer" originally because it was intended for use in all Church of England churches, which had previously followed differing local liturgies. The term was kept when the church became international, because all Anglicans used to share in its use around the world.

In 1549, the first "Book of Common Prayer" was compiled by Thomas Cranmer, who was then Archbishop of Canterbury. While it has since undergone many revisions and Anglican churches in different countries have developed other service books, the Prayer Book is still acknowledged as one of the ties that bind Anglicans together.

The founding of Christianity in Britain is commonly attributed to Joseph of Arimathea, according to Anglican legend, and is commemorated in Glastonbury Abbey. Many of the early Church Fathers wrote of the presence of Christianity in Roman Britain, with Tertullian stating "those parts of Britain into which the Roman arms had never penetrated were become subject to Christ". Saint Alban, who was executed in AD 209, is the first Christian martyr in the British Isles. For this reason he is venerated as the British protomartyr. The historian Heinrich Zimmer writes that "Just as Britain was a part of the Roman Empire, so the British Church formed (during the fourth century) a branch of the Catholic Church of the West; and during the whole of that century, from the Council of Arles (316) onward, took part in all proceedings concerning the Church."

After Roman troops withdrew from Britain, the "absence of Roman military and governmental influence and overall decline of Roman imperial political power enabled Britain and the surrounding isles to develop distinctively from the rest of the West. A new culture emerged around the Irish Sea among the Celtic peoples with Celtic Christianity at its core. What resulted was a form of Christianity distinct from Rome in many traditions and practices."

The historian Charles Thomas, in addition to the Celticist Heinrich Zimmer, writes that the distinction between sub-Roman and post-Roman Insular Christianity, also known as Celtic Christianity, began to become apparent around AD 475, with the Celtic churches allowing married clergy, observing Lent and Easter according to their own calendar, and having a different tonsure; moreover, like the Eastern Orthodox Churches and the Oriental Orthodox Churches, the Celtic churches operated independently of the Pope's authority, as a result of their isolated development in the British Isles.
In what is known as the Gregorian mission, Pope Gregory I sent Augustine of Canterbury to the British Isles in AD 596, with the purpose of evangelising the pagans there (who were largely Anglo-Saxons), as well as to reconcile the Celtic churches in the British Isles to the See of Rome. In Kent, Augustine persuaded the Anglo-Saxon king "Æthelberht and his people to accept Christianity". Augustine, on two occasions, "met in conference with members of the Celtic episcopacy, but no understanding was reached between them."

Eventually, the "Christian Church of the Anglo-Saxon kingdom of Northumbria convened the Synod of Whitby in 663/664 to decide whether to follow Celtic or Roman usages." This meeting, with King Oswiu as the final decision maker, "led to the acceptance of Roman usage elsewhere in England and brought the English Church into close contact with the Continent". As a result of assuming Roman usages, the Celtic Church surrendered its independence, and, from this point on, the Church in England "was no longer purely Celtic, but became Anglo-Roman-Celtic". The theologian Christopher L. Webber writes that, although "the Roman form of Christianity became the dominant influence in Britain as in all of western Europe, Anglican Christianity has continued to have a distinctive quality because of its Celtic heritage."

The Church in England remained united with Rome until the English Parliament, through the Act of Supremacy (1534), declared King Henry VIII to be the Supreme Head of the Church in England to fulfill the "English desire to be independent from continental Europe religiously and politically." Although now separate from Rome, the English Church, at this point in history, continued to maintain Roman Catholic doctrines and the sacraments. With little exception, Henry VIII allowed no changes during his lifetime. Under King Edward VI (1547–1553), however, the church in England underwent what is known as the English Reformation, in the course of which it acquired a number of characteristics that would subsequently become recognised as constituting its distinctive "Anglican" identity.

With the Elizabethan Settlement of 1559, the Protestant identity of the English and Irish churches was affirmed by means of parliamentary legislation which mandated allegiance and loyalty to the English Crown in all their members. The Elizabethan church began to develop distinct religious traditions, assimilating some of the theology of Reformed churches with the services in the "Book of Common Prayer" (which drew extensively on the Sarum Rite native to England), under the leadership and organisation of a continuing episcopate. Over the years, these traditions themselves came to command adherence and loyalty. The Elizabethan Settlement stopped the radical Protestant tendencies under Edward VI by combining the more radical elements of the Second Prayer Book of 1552 with the conservative "Catholic" First Prayer Book of 1549. From then on, Protestantism was in a "state of arrested development", regardless of the attempts to detach the Church of England from its "idiosyncratic anchorage in the medieval past" by various groups which tried to push it towards a more Reformed theology and governance in the years 1560–1660.
Although two important constitutive elements of what later would emerge as Anglicanism were present in 1559 – scripture, the historic episcopate, the Book of Common Prayer, the teachings of the First Four Ecumenical Councils as the yardstick of catholicity, the teaching of the Church Fathers and Catholic bishops, and informed reason – neither the laypeople nor the clergy perceived themselves as Anglicans at the beginning of Elizabeth I's reign, as there was no such identity. Neither does the term "via media" appear until the 1627 to describe a church which refused to identify itself definitely as Catholic or Protestant, or as both, "and had decided in the end that this is virtue rather than a handicap".

Historical studies on the period 1560–1660 written before the late 1960s tended to project the predominant conformist spirituality and doctrine of the 1660s on the ecclesiastical situation one hundred years before, and there was also a tendency to take polemically binary partitions of reality claimed by contestants studied (such as the dichotomies Protestant-"Popish" or "Laudian"-"Puritan") at face value. Since the late 1960s, these interpretations have been criticised. Studies on the subject written during the last forty-five years have, however, not reached any consensus on how to interpret this period in English church history. The extent to which one or several positions concerning doctrine and spirituality existed alongside the more well-known and articulate Puritan movement and the Durham House Party, and the exact extent of continental Calvinism among the English elite and among the ordinary churchgoers from the 1560s to the 1620s are subjects of current and ongoing debate.

In 1662, under King Charles II, a revised "Book of Common Prayer" was produced, which was acceptable to high churchmen as well as some Puritans, and is still considered authoritative to this day.

In so far as Anglicans derived their identity from both parliamentary legislation and ecclesiastical tradition, a crisis of identity could result wherever secular and religious loyalties came into conflict – and such a crisis indeed occurred in 1776 with the American Declaration of Independence, most of whose signatories were, at least nominally, Anglican. For these American patriots, even the forms of Anglican services were in doubt, since the Prayer Book rites of Matins, Evensong, and Holy Communion all included specific prayers for the British Royal Family. Consequently, the conclusion of the War of Independence eventually resulted in the creation of two new Anglican churches, the Episcopal Church in the United States in those states that had achieved independence; and in the 1830s The Church of England in Canada became independent from the Church of England in those North American colonies which had remained under British control and to which many Loyalist churchmen had migrated.

Reluctantly, legislation was passed in the British Parliament (the Consecration of Bishops Abroad Act 1786) to allow bishops to be consecrated for an American church outside of allegiance to the British Crown (since no dioceses had ever been established in the former American colonies). Both in the United States and in Canada, the new Anglican churches developed novel models of self-government, collective decision-making, and self-supported financing; that would be consistent with separation of religious and secular identities.

In the following century, two further factors acted to accelerate the development of a distinct Anglican identity. From 1828 and 1829, Dissenters and Catholics could be elected to the House of Commons, which consequently ceased to be a body drawn purely from the established churches of Scotland, England, and Ireland; but which nevertheless, over the following ten years, engaged in extensive reforming legislation affecting the interests of the English and Irish churches; which, by the Acts of Union of 1800, had been reconstituted as the United Church of England and Ireland. The propriety of this legislation was bitterly contested by the Oxford Movement (Tractarians), who in response developed a vision of Anglicanism as religious tradition deriving ultimately from the ecumenical councils of the patristic church. Those within the Church of England opposed to the Tractarians, and to their revived ritual practices, introduced a stream of bills in parliament aimed to control innovations in worship. This only made the dilemma more acute, with consequent continual litigation in the secular and ecclesiastical courts.

Over the same period, Anglican churches engaged vigorously in Christian missions, resulting in the creation, by the end of the century, of over ninety colonial bishoprics, which gradually coalesced into new self-governing churches on the Canadian and American models. However, the case of John Colenso, Bishop of Natal, reinstated in 1865 by the English Judicial Committee of the Privy Council over the heads of the Church in South Africa, demonstrated acutely that the extension of episcopacy had to be accompanied by a recognised Anglican ecclesiology of ecclesiastical authority, distinct from secular power.

Consequently, at the instigation of the bishops of Canada and South Africa, the first Lambeth Conference was called in 1867; to be followed by further conferences in 1878 and 1888, and thereafter at ten-year intervals. The various papers and declarations of successive Lambeth Conferences have served to frame the continued Anglican debate on identity, especially as relating to the possibility of ecumenical discussion with other churches. This ecumenical aspiration became much more of a possibility, as other denominational groups rapidly followed the example of the Anglican Communion in founding their own transnational alliances: the Alliance of Reformed Churches, the Ecumenical Methodist Council, the International Congregational Council, and the Baptist World Alliance.

Anglicanism was seen as a middle way, or "via media", between two branches of Protestantism, Lutheranism and Reformed Christianity. In their rejection of absolute parliamentary authority, the Tractarians – and in particular John Henry Newman – looked back to the writings of 17th-century Anglican divines, finding in these texts the idea of the English church as a "via media" between the Protestant and Catholic traditions. This view was associated – especially in the writings of Edward Bouverie Pusey – with the theory of Anglicanism as one of three "branches" (alongside the Catholic Church and the Orthodox Church) historically arising out of the common tradition of the earliest ecumenical councils. Newman himself subsequently rejected his theory of the "via media", as essentially historicist and static and hence unable to accommodate any dynamic development within the church. Nevertheless, the aspiration to ground Anglican identity in the writings of the 17th-century divines and in faithfulness to the traditions of the Church Fathers reflects a continuing theme of Anglican ecclesiology, most recently in the writings of Henry Robert McAdoo.

The Tractarian formulation of the theory of the "via media" between Protestantism and Catholicism was essentially a party platform, and not acceptable to Anglicans outside the confines of the Oxford Movement. However, this theory of the "via media" was reworked in the ecclesiological writings of Frederick Denison Maurice, in a more dynamic form that became widely influential. Both Maurice and Newman saw the Church of England of their day as sorely deficient in faith; but whereas Newman had looked back to a distant past when the light of faith might have appeared to burn brighter, Maurice looked forward to the possibility of a brighter revelation of faith in the future. Maurice saw the Protestant and Catholic strands within the Church of England as contrary but complementary, both maintaining elements of the true church, but incomplete without the other; such that a true catholic and evangelical church might come into being by a union of opposites.
Central to Maurice's perspective was his belief that the collective elements of family, nation, and church represented a divine order of structures through which God unfolds his continuing work of creation. Hence, for Maurice, the Protestant tradition had maintained the elements of national distinction which were amongst the marks of the true universal church, but which had been lost within contemporary Roman Catholicism in the internationalism of centralised papal authority. Within the coming universal church that Maurice foresaw, national churches would each maintain the six signs of Catholicity: baptism, Eucharist, the creeds, Scripture, an episcopal ministry, and a fixed liturgy (which could take a variety of forms in accordance with divinely ordained distinctions in national characteristics). Not surprisingly, this vision of a becoming universal church as a congregation of autonomous national churches proved highly congenial in Anglican circles; and Maurice's six signs were adapted to form the Chicago-Lambeth Quadrilateral of 1888.

In the latter decades of the 20th century, Maurice's theory, and the various strands of Anglican thought that derived from it, have been criticised by Stephen Sykes, who argues that the terms "Protestant" and "Catholic" as used in these approaches are synthetic constructs denoting ecclesiastic identities unacceptable to those to whom the labels are applied. Hence, the Catholic Church does not regard itself as a party or strand within the universal church – but rather identifies itself as the universal church. Moreover, Sykes criticises the proposition, implicit in theories of "via media", that there is no distinctive body of Anglican doctrines, other than those of the universal church; accusing this of being an excuse not to undertake systematic doctrine at all.

Contrariwise, Sykes notes a high degree of commonality in Anglican liturgical forms and in the doctrinal understandings expressed within those liturgies. He proposes that Anglican identity might rather be found within a shared consistent pattern of prescriptive liturgies, established and maintained through canon law, and embodying both a historic deposit of formal statements of doctrine, and also framing the regular reading and proclamation of scripture. Sykes nevertheless agrees with those heirs of Maurice who emphasise the incompleteness of Anglicanism as a positive feature, and quotes with qualified approval the words of Michael Ramsey:

The distinction between Reformed and Catholic, and the coherence of the two, is routinely a matter of debate both within specific Anglican churches and throughout the Anglican Communion by members themselves. Since the Oxford Movement of the mid-19th century, many churches of the communion have revived and extended doctrinal, liturgical, and pastoral practices similar to those of Roman Catholicism. This extends beyond the ceremony of high-church services to even more theologically significant territory, such as sacramental theology (see Anglican sacraments). While Anglo-Catholic practices, particularly liturgical ones, have become more common within the tradition over the last century, there remain many places where practices and beliefs remain on the more Reformed or evangelical side (see Sydney Anglicanism).

For high-church Anglicans, doctrine is neither established by a magisterium, nor derived from the theology of an eponymous founder (such as Calvinism), nor summed up in a confession of faith beyond the ecumenical creeds (such as the Lutheran Book of Concord). For them, the earliest Anglican theological documents are its prayer books, which they see as the products of profound theological reflection, compromise, and synthesis. They emphasise the "Book of Common Prayer" as a key expression of Anglican doctrine. The principle of looking to the prayer books as a guide to the parameters of belief and practice is called by the Latin name "lex orandi, lex credendi" ("the law of prayer is the law of belief").

Within the prayer books are the fundamentals of Anglican doctrine: the Apostles' and Nicene creeds, the Athanasian Creed (now rarely used), the scriptures (via the lectionary), the sacraments, daily prayer, the catechism, and apostolic succession in the context of the historic threefold ministry. For some low-church and evangelical Anglicans, the 16th-century Reformed Thirty-Nine Articles form the basis of doctrine.

The Thirty-Nine Articles played a significant role in Anglican doctrine and practice. Following the passing of the 1604 canons, all Anglican clergy had to formally subscribe to the articles. Today, however, the articles are no longer binding, but are seen as a historical document which has played a significant role in the shaping of Anglican identity. The degree to which each of the articles has remained influential varies.

On the doctrine of justification, for example, there is a wide range of beliefs within the Anglican Communion, with some Anglo-Catholics arguing for a faith with good works and the sacraments. At the same time, however, some evangelical Anglicans ascribe to the Reformed emphasis on "sola fide" ("faith alone") in their doctrine of justification (see Sydney Anglicanism). Still other Anglicans adopt a nuanced view of justification, taking elements from the early Church Fathers, Catholicism, Protestantism, liberal theology, and latitudinarian thought.

Arguably, the most influential of the original articles has been Article VI on the "sufficiency of scripture", which says that "Scripture containeth all things necessary to salvation: so that whatsoever is not read therein, nor may be proved thereby, is not to be required of any man, that it should be believed as an article of the Faith, or be thought requisite or necessary to salvation." This article has informed Anglican biblical exegesis and hermeneutics since earliest times.

Anglicans look for authority in their "standard divines" (see below). Historically, the most influential of these – apart from Cranmer – has been the 16th-century cleric and theologian Richard Hooker, who after 1660 was increasingly portrayed as the founding father of Anglicanism. Hooker's description of Anglican authority as being derived primarily from scripture, informed by reason (the intellect and the experience of God) and tradition (the practices and beliefs of the historical church), has influenced Anglican self-identity and doctrinal reflection perhaps more powerfully than any other formula. The analogy of the "three-legged stool" of scripture, reason, and tradition is often incorrectly attributed to Hooker. Rather, Hooker's description is a hierarchy of authority, with scripture as foundational and reason and tradition as vitally important, but secondary, authorities.

Finally, the extension of Anglicanism into non-English cultures, the growing diversity of prayer books, and the increasing interest in ecumenical dialogue have led to further reflection on the parameters of Anglican identity. Many Anglicans look to the Chicago-Lambeth Quadrilateral of 1888 as the "sine qua non" of communal identity. In brief, the quadrilateral's four points are the scriptures as containing all things necessary to salvation; the creeds (specifically, the Apostles' and Nicene Creeds) as the sufficient statement of Christian faith; the dominical sacraments of Baptism and Holy Communion; and the historic episcopate.

Within the Anglican tradition, "divines" are clergy of the Church of England whose theological writings have been considered standards for faith, doctrine, worship, and spirituality, and whose influence has permeated the Anglican Communion in varying degrees through the years. While there is no authoritative list of these Anglican divines, there are some whose names would likely be found on most lists – those who are commemorated in lesser feasts of the Anglican churches and those whose works are frequently anthologised.

The corpus produced by Anglican divines is diverse. What they have in common is a commitment to the faith as conveyed by scripture and the "Book of Common Prayer", thus regarding prayer and theology in a manner akin to that of the Apostolic Fathers. On the whole, Anglican divines view the "via media" of Anglicanism not as a compromise, but as "a positive position, witnessing to the universality of God and God's kingdom working through the fallible, earthly "ecclesia Anglicana"".

These theologians regard scripture as interpreted through tradition and reason as authoritative in matters concerning salvation. Reason and tradition, indeed, is extant in and presupposed by scripture, thus implying co-operation between God and humanity, God and nature, and between the sacred and secular. Faith is thus regarded as incarnational and authority as dispersed.

Amongst the early Anglican divines of the 16th and 17th centuries, the names of Thomas Cranmer, John Jewel, Matthew Parker, Richard Hooker, Lancelot Andrewes, and Jeremy Taylor predominate. The influential character of Hooker's "Of the Laws of Ecclesiastical Polity" cannot be overestimated. Published in 1593 and subsequently, Hooker's eight-volume work is primarily a treatise on church-state relations, but it deals comprehensively with issues of biblical interpretation, soteriology, ethics, and sanctification. Throughout the work, Hooker makes clear that theology involves prayer and is concerned with ultimate issues and that theology is relevant to the social mission of the church.

The 18th century saw the rise of two important movements in Anglicanism: Cambridge Platonism, with its mystical understanding of reason as the "candle of the Lord", and the evangelical revival, with its emphasis on the personal experience of the Holy Spirit. The Cambridge Platonist movement evolved into a school called Latitudinarianism, which emphasised reason as the barometer of discernment and took a stance of indifference towards doctrinal and ecclesiological differences.

The evangelical revival, influenced by such figures as John Wesley and Charles Simeon, re-emphasised the importance of justification through faith and the consequent importance of personal conversion. Some in this movement, such as Wesley and George Whitefield, took the message to the United States, influencing the First Great Awakening and creating an Anglo-American movement called Methodism that would eventually break away, structurally, from the Anglican churches after the American Revolution.

By the 19th century, there was a renewed interest in pre-Reformation English religious thought and practice. Theologians such as John Keble, Edward Bouverie Pusey, and John Henry Newman had widespread influence in the realm of polemics, homiletics and theological and devotional works, not least because they largely repudiated the old high-church tradition and replaced it with a dynamic appeal to antiquity which looked beyond the Reformers and Anglican formularies. Their work is largely credited with the development of the Oxford Movement, which sought to reassert Catholic identity and practice in Anglicanism.

In contrast to this movement, clergy such as the Bishop of Liverpool, J. C. Ryle, sought to uphold the distinctly Reformed identity of the Church of England. He was not a servant of the status quo, but argued for a lively religion which emphasised grace, holy and charitable living, and the plain use of the 1662 "Book of Common Prayer" (interpreted in a partisan evangelical way) without additional rituals. Frederick Denison Maurice, through such works as "The Kingdom of Christ", played a pivotal role in inaugurating another movement, Christian socialism. In this, Maurice transformed Hooker's emphasis on the incarnational nature of Anglican spirituality to an imperative for social justice.

In the 19th century, Anglican biblical scholarship began to assume a distinct character, represented by the so-called "Cambridge triumvirate" of Joseph Lightfoot, F. J. A. Hort, and Brooke Foss Westcott. Their orientation is best summed up by Lightfoot's observation that "Life which Christ is and which Christ communicates, the life which fills our whole beings as we realise its capacities, is active fellowship with God."

The earlier part of the 20th century is marked by Charles Gore, with his emphasis on natural revelation, and William Temple's focus on Christianity and society, while, from outside England, Robert Leighton, Archbishop of Glasgow, and several clergy from the United States have been suggested, such as William Porcher DuBose, John Henry Hobart (1775–1830, Bishop of New York 1816–30), William Meade, Phillips Brooks, and Charles Brent.

"Churchmanship" can be defined as the manifestation of theology in the realms of liturgy, piety, and, to some extent, spirituality. Anglican diversity in this respect has tended to reflect the diversity in the tradition's Reformed and Catholic identity. Different individuals, groups, parishes, dioceses, and provinces may identify more closely with one or the other, or some mixture of the two.

The range of Anglican belief and practice became particularly divisive during the 19th century, when some clergy were disciplined and even imprisoned on charges of introducing illegal ritual while, at the same time, others were criticised for engaging in public worship services with ministers of Reformed churches. Resistance to the growing acceptance and restoration of traditional Catholic ceremonial by the mainstream of Anglicanism ultimately led to the formation of small breakaway churches such as the Free Church of England in England (1844) and the Reformed Episcopal Church in North America (1873).

Anglo-Catholic (and some broad-church) Anglicans celebrate public liturgy in ways that understand worship to be something very special and of utmost importance. Vestments are worn by the clergy, sung settings are often used, and incense may be used. Nowadays, in most Anglican churches, the Eucharist is celebrated in a manner similar to the usage of Catholics and some Lutherans, though, in many churches, more traditional, "pre–Vatican II" models of worship are common (e.g., an "eastward orientation" at the altar). Whilst many Anglo-Catholics derive much of their liturgical practice from that of the pre-Reformation English church, others more closely follow traditional Roman Catholic practices.

The Eucharist may sometimes be celebrated in the form known as High Mass, with a priest, deacon, and subdeacon dressed in traditional vestments, with incense and sanctus bells, and with prayers adapted from the Roman Missal or other sources by the celebrant. Such churches may also have forms of Eucharistic adoration such as Benediction of the Blessed Sacrament. In terms of personal piety, some Anglicans may recite the Rosary and Angelus, be involved in a devotional society dedicated to "Our Lady" (the Blessed Virgin Mary), and seek the intercession of the saints.

In recent years, the prayer books of several provinces have, out of deference to a greater agreement with Eastern Conciliarism (and a perceived greater respect accorded Anglicanism by Eastern Orthodoxy than by Roman Catholicism), instituted a number of historically Eastern and Oriental Orthodox elements in their liturgies, including introduction of the Trisagion and deletion of the filioque clause from the Nicene Creed.

For their part, those evangelical (and some broad-church) Anglicans who emphasise the more Protestant aspects of the Church stress the Reformation theme of salvation by grace through faith. They emphasise the two dominical sacraments of Baptism and Eucharist, viewing the other five as "lesser rites". Some evangelical Anglicans may even tend to take the inerrancy of scripture literally, adopting the view of Article VI that it contains all things necessary to salvation in an explicit sense. Worship in churches influenced by these principles tends to be significantly less elaborate, with greater emphasis on the Liturgy of the Word (the reading of the scriptures, the sermon, and the intercessory prayers).

The Order for Holy Communion may be celebrated bi-weekly or monthly (in preference to the daily offices), by priests attired in choir habit, or more regular clothes, rather than Eucharistic vestments. Ceremony may be in keeping with their view of the provisions of the 17th-century Puritans – being a Reformed interpretation of the Ornaments Rubric – no candles, no incense, no bells, and a minimum of manual actions by the presiding celebrant (such as touching the elements at the Words of Institution).

In recent decades, there has been a growth of charismatic worship among Anglicans. Both Anglo-Catholics and evangelicals have been affected by this movement such that it is not uncommon to find typically charismatic postures, music, and other themes evident during the services of otherwise Anglo-Catholic or evangelical parishes.

The spectrum of Anglican beliefs and practice is too large to be fit into these labels. Many Anglicans locate themselves somewhere in the spectrum of the broad-church tradition and consider themselves an amalgam of evangelical and Catholic. Such Anglicans stress that Anglicanism is the "via media" (middle way) between the two major strains of Western Christianity and that Anglicanism is like a "bridge" between the two strains.

In accord with its prevailing self-identity as a "via media" or "middle path" of Western Christianity, Anglican sacramental theology expresses elements in keeping with its status as being both a church in the Catholic tradition as well as a Reformed church. With respect to sacramental theology, the Catholic heritage is perhaps most strongly asserted in the importance Anglicanism places on the sacraments as a means of grace, sanctification, and salvation, as expressed in the church's liturgy and doctrine.

Of the seven sacraments, all Anglicans recognise Baptism and the Eucharist as being directly instituted by Christ. The other five – Confession/Absolution, Matrimony, Confirmation, Holy Orders (also called Ordination), and Anointing of the Sick (also called Unction) – are regarded variously as full sacraments by Anglo-Catholics and many high-church and some broad-church Anglicans, but merely as "sacramental rites" by other broad-church and low-church Anglicans, especially evangelicals associated with Reform UK and the Diocese of Sydney.

Anglican eucharistic theology is divergent in practice, reflecting the essential comprehensiveness of the tradition. A few low-church Anglicans take a strictly memorialist (Zwinglian) view of the sacrament. In other words, they see Holy Communion as a memorial to Christ's suffering, and participation in the Eucharist as both a re-enactment of the Last Supper and a foreshadowing of the heavenly banquet – the fulfilment of the eucharistic promise.

Other low-church Anglicans believe in the real presence of Christ in the Eucharist but deny that the presence of Christ is carnal or is necessarily localised in the bread and wine (which is by coincidence what Thomas Aquinas wrote that the Presence of Christ in the Sacrament of the Holy Eucharist is not to be understood "materialiter ni localiter" as physical or trapped in a place). Despite explicit criticism in the Thirty-Nine Articles, many high-church or Anglo-Catholic Anglicans hold, more or less, the Catholic view of the real presence as expressed in the doctrine of transubstantiation, seeing the Eucharist as a liturgical representation of Christ's atoning sacrifice with the elements actually transformed into Christ's body and blood.

The majority of Anglicans, however, have in common a belief in the real presence, defined in one way or another. To that extent, they are in the company of the continental reformer Martin Luther and Calvin rather than Ulrich Zwingli. The Catechism of the American BCP of 1976 repeats the standard Anglican view ("The outward and visible sign in the Eucharist is the bread and wine"..."The inward and spiritual grace in the Holy Communion is the Body and Blood of Christ given to his people, and received by faith") without further definition. It should be remembered that Anglicanism has no official doctrine on this matter, believing it is wiser to leave the Presence a mystery. The faithful can believe privately whatever explanation they favor, be it transubstantiation, consubstantiation, receptionism, or virtualism (the two most congenial to Anglicans for centuries until the Oxford Movement), each of which espouses belief in the real presence in one way or another, or memorialism, which has never been an option with Anglicans.

A famous Anglican aphorism regarding Christ's presence in the sacrament, commonly misattributed to Queen Elizabeth I, is first found in print in a poem by John Donne:

<poem>
He was the word that spake it,
He took the bread and brake it:
And what that word did make it,
I do believe and take it.</poem>

An Anglican position on the eucharistic sacrifice ("Sacrifice of the Mass") was expressed in the response "Saepius officio" of the Archbishops of Canterbury and York to Pope Leo XIII's Papal Encyclical "Apostolicae curae": viz. that the Prayer Book contained a strong sacrificial theology. Later revisions of the Prayer Book influenced by the Scottish Canon of 1764 first adopted by the Protestant Episcopal Church in 1789 made this assertion quite evident: "we do make and celebrate before thy Divine Majesty with these thy holy gifts, which we now OFFER unto thee, the memorial thy Son has commanded us to make", which is repeated in the 1929 English BCP and included in such words or others such as "present" or "show forth" in subsequent revisions.

Anglican and Roman Catholic representatives declared that they had "substantial agreement on the doctrine of the Eucharist" in the "Windsor Statement on Eucharistic Doctrine" by the Anglican-Roman Catholic International Consultation (1971) and the Elucidation of the ARCIC Windsor Statement (1979). The final response (1991) to these documents by the Vatican made it plain that it did not consider the degree of agreement reached to be satisfactory.

In Anglicanism, there is a distinction between liturgy, which is the formal public and communal worship of the Church, and personal prayer and devotion, which may be public or private. Liturgy is regulated by the prayer books and consists of the Holy Eucharist (some call it Holy Communion or Mass), the other six Sacraments, and the Divine Office or Liturgy of the Hours.

The "Book of Common Prayer" (BCP) is the foundational prayer book of Anglicanism. The original book of 1549 (revised in 1552) was one of the instruments of the English Reformation, replacing the various "uses" or rites in Latin that had been used in different parts of the country with a single compact volume in the language of the people, so that "now from henceforth all the Realm shall have but one use". Suppressed under Queen Mary I, it was revised in 1559, and then again in 1662, after the Restoration of Charles II. This version was made mandatory in England and Wales by the Act of Uniformity and was in standard use until the mid-20th century.

With British colonial expansion from the 17th century onwards, Anglican churches were planted around the globe. These churches at first used and then revised the "Book of Common Prayer" until they, like their parent church, produced prayer books which took into account the developments in liturgical study and practice in the 19th and 20th centuries, which come under the general heading of the Liturgical Movement.

Anglican worship services are open to all visitors. Anglican worship originates principally in the reforms of Thomas Cranmer, who aimed to create a set order of service like that of the pre-Reformation church but less complex in its seasonal variety and said in English rather than Latin. This use of a set order of service is not unlike the Catholic tradition. Traditionally, the pattern was that laid out in the "Book of Common Prayer". Although many Anglican churches now use a wide range of modern service books written in the local language, the structures of the "Book of Common Prayer" are largely retained. Churches which call themselves Anglican will have identified themselves so because they use some form or variant of the "Book of Common Prayer" in the shaping of their worship.

Anglican worship, however, is as diverse as Anglican theology. A contemporary "low-church" service may differ little from the worship of many mainstream non-Anglican Protestant churches. The service is constructed around a sermon focused on Biblical exposition and opened with one or more Bible readings and closed by a series of prayers (both set and extemporised) and hymns or songs. A "high-church" or Anglo-Catholic service, by contrast, is usually a more formal liturgy celebrated by clergy in distinctive vestments and may be almost indistinguishable from a Roman Catholic service, often resembling the "pre–Vatican II" Tridentine rite.

Between these extremes are a variety of styles of worship, often involving a robed choir and the use of the organ to accompany the singing and to provide music before and after the service. Anglican churches tend to have pews or chairs, and it is usual for the congregation to kneel for some prayers but to stand for hymns and other parts of the service such as the Gloria, Collect, Gospel reading, Creed and either the Preface or all of the Eucharistic Prayer. High Anglicans may genuflect or cross themselves in the same way as Roman Catholics.

Other more traditional Anglicans tend to follow the 1662 "Book of Common Prayer", and retain the use of the King James Bible. This is typical in many Anglican cathedrals and particularly in Royal Peculiars such as the Savoy Chapel and the Queen's Chapel. These services reflect the original Anglican doctrine and differ from the Traditional Anglican Communion in that they are in favour of women vicars and the ability of vicars to marry. These Anglican church services include classical music instead of songs, hymns from the New English Hymnal (usually excluding modern hymns such as "Lord of the Dance"), and are generally non-evangelical and formal in practice. Due to their association with royalty, these churches are generally host to staunch Anglicans who are strongly opposed to Catholicism.

Until the mid-20th century the main Sunday service was typically morning prayer, but the Eucharist has once again become the standard form of Sunday worship in many Anglican churches; this again is similar to Roman Catholic practice. Other common Sunday services include an early morning Eucharist without music, an abbreviated Eucharist following a service of morning prayer, and a service of evening prayer, sometimes in the form of sung Evensong, usually celebrated between 3 and 6 pm. The late-evening service of Compline was revived in parish use in the early 20th century. Many Anglican churches will also have daily morning and evening prayer, and some have midweek or even daily celebration of the Eucharist.

An Anglican service (whether or not a Eucharist) will include readings from the Bible that are generally taken from a standardised lectionary, which provides for much of the Bible (and some passages from the Apocrypha) to be read out loud in the church over a cycle of one, two, or three years (depending on which eucharistic and office lectionaries are used, respectively). The sermon (or homily) is typically about ten to twenty minutes in length, often comparably short to sermons in evangelical churches. Even in the most informal Anglican services, it is common for set prayers such as the weekly Collect to be read. There are also set forms for intercessory prayer, though this is now more often extemporaneous. In high and Anglo-Catholic churches there are generally prayers for the dead.

Although Anglican public worship is usually ordered according to the canonically approved services, in practice many Anglican churches use forms of service outside these norms. Liberal churches may use freely structured or experimental forms of worship, including patterns borrowed from ecumenical traditions such as those of the Taizé Community or the Iona Community.

Anglo-Catholic parishes might use the modern Roman Catholic liturgy of the Mass or more traditional forms, such as the Tridentine Mass (which is translated into English in the English Missal), the Anglican Missal, or, less commonly, the Sarum Rite. Catholic devotions such as the Rosary, Angelus, and Benediction of the Blessed Sacrament are also common among Anglo-Catholics.

Only baptised persons are eligible to receive communion, although in many churches communion is restricted to those who have not only been baptised but also confirmed. In many Anglican provinces, however, all baptised Christians are now often invited to receive communion and some dioceses have regularised a system for admitting baptised young people to communion before they are confirmed.

The discipline of fasting before communion is practised by some Anglicans. Most Anglican priests require the presence of at least one other person for the celebration of the Eucharist (referring back to Christ's statement in Matthew 18:20, "When two or more are gathered in my name, I will be in the midst of them."), though some Anglo-Catholic priests (like Roman Catholic priests) may say private Masses. As in the Roman Catholic Church, it is a canonical requirement to use fermented wine for communion.

Unlike in Roman Catholicism, the consecrated bread and wine are always offered to the congregation at a eucharistic service ("communion in both kinds"). This practice is becoming more frequent in the Roman Catholic Church as well, especially through the Neocatechumenal Way. In some churches, the sacrament is reserved in a tabernacle or aumbry with a lighted candle or lamp nearby. In Anglican churches, only a priest or a bishop may be the celebrant at the Eucharist.

All Anglican prayer books contain offices for Morning Prayer (Matins) and Evening Prayer (Evensong). In the original "Book of Common Prayer", these were derived from combinations of the ancient monastic offices of Matins and Lauds; and Vespers and Compline, respectively. The prayer offices have an important place in Anglican history.

Prior to the Catholic revival of the 19th century, which eventually restored the Holy Eucharist as the principal Sunday liturgy, and especially during the 18th century, a morning service combining Matins, the Litany, and ante-Communion comprised the usual expression of common worship, while Matins and Evensong were sung daily in cathedrals and some collegiate chapels. This nurtured a tradition of distinctive Anglican chant applied to the canticles and psalms used at the offices (although plainsong is often used as well).

In some official and many unofficial Anglican service books, these offices are supplemented by other offices such as the Little Hours of Prime and prayer during the day such as (Terce, Sext, None, and Compline). Some Anglican monastic communities have a Daily Office based on that of the "Book of Common Prayer" but with additional antiphons and canticles, etc., for specific days of the week, specific psalms, etc. See, for example, Order of the Holy Cross and Order of St Helena, editors, "A Monastic Breviary" (Wilton, Conn.: Morehouse-Barlow, 1976). The All Saints Sisters of the Poor, with convents in Catonsville, Maryland, and elsewhere, use an elaborated version of the Anglican Daily Office. The Society of St. Francis publishes "Celebrating Common Prayer", which has become especially popular for use among Anglicans.

In England, the United States, Canada, Australia, New Zealand, and some other Anglican provinces, the modern prayer books contain four offices:

In addition, most prayer books include a section of prayers and devotions for family use. In the U.S., these offices are further supplemented by an "Order of Worship for the Evening", a prelude to or an abbreviated form of Evensong, partly derived from Orthodox prayers. In the United Kingdom, the publication of "Daily Prayer", the third volume of "Common Worship", was published in 2005. It retains the services for Morning and Evening Prayer and Compline and includes a section entitled "Prayer during the Day". "A New Zealand Prayer Book" of 1989 provides different outlines for Matins and Evensong on each day of the week, as well as "Midday Prayer", "Night Prayer", and "Family Prayer".

Some Anglicans who pray the office on daily basis use the present Divine Office of the Catholic Church. In many cities, especially in England, Anglican and Catholic priests and lay people often meet several times a week to pray the office in common. A small but enthusiastic minority use the Anglican Breviary, or other translations and adaptations of the pre–Vatican II Roman Rite and Sarum Rite, along with supplemental material from cognate western sources, to provide such things as a common of Octaves, a common of Holy Women, and other additional material. Others may privately use idiosyncratic forms borrowed from a wide range of Christian traditions.

In the late medieval period, many English cathedrals and monasteries had established small choirs of trained lay clerks and boy choristers to perform polyphonic settings of the Mass in their Lady chapels. Although these "Lady Masses" were discontinued at the Reformation, the associated musical tradition was maintained in the Elizabethan Settlement through the establishment of choral foundations for daily singing of the Divine Office by expanded choirs of men and boys. This resulted from an explicit addition by Elizabeth herself to the injunctions accompanying the 1559 "Book of Common Prayer" (that had itself made no mention of choral worship) by which existing choral foundations and choir schools were instructed to be continued, and their endowments secured. Consequently, some thirty-four cathedrals, collegiate churches, and royal chapels maintained paid establishments of lay singing men and choristers in the late 16th century.

All save four of these have – with an interruption during the Commonwealth – continued daily choral prayer and praise to this day. In the Offices of Matins and Evensong in the 1662 "Book of Common Prayer", these choral establishments are specified as "Quires and Places where they sing".

For nearly three centuries, this round of daily professional choral worship represented a tradition entirely distinct from that embodied in the intoning of Parish Clerks, and the singing of "west gallery choirs" which commonly accompanied weekly worship in English parish churches. In 1841, the rebuilt Leeds Parish Church established a surpliced choir to accompany parish services, drawing explicitly on the musical traditions of the ancient choral foundations. Over the next century, the Leeds example proved immensely popular and influential for choirs in cathedrals, parish churches, and schools throughout the Anglican communion. More or less extensively adapted, this choral tradition also became the direct inspiration for robed choirs leading congregational worship in a wide range of Christian denominations.

In 1719, the cathedral choirs of Gloucester, Hereford, and Worcester combined to establish the annual Three Choirs Festival, the precursor for the multitude of summer music festivals since. By the 20th century, the choral tradition had become for many the most accessible face of worldwide Anglicanism – especially as promoted through the regular broadcasting of choral evensong by the BBC; and also in the annual televising of the festival of Nine Lessons and Carols from King's College, Cambridge. Composers closely concerned with this tradition include Edward Elgar, Ralph Vaughan Williams, Gustav Holst, Charles Villiers Stanford, and Benjamin Britten. A number of important 20th-century works by non-Anglican composers were originally commissioned for the Anglican choral tradition – for example, the "Chichester Psalms" of Leonard Bernstein and the "Nunc dimittis" of Arvo Pärt.

Contrary to popular misconception, the British monarch is not the constitutional "head" but in law the "Supreme Governor" of the Church of England, nor does he or she have any role in provinces outside England. The role of the crown in the Church of England is practically limited to the appointment of bishops, including the Archbishop of Canterbury, and even this role is limited, as the Church presents the government with a short list of candidates from which to choose. This process is accomplished through collaboration with and consent of ecclesial representatives "(see Ecclesiastical Commissioners)". The monarch has no constitutional role in Anglican churches in other parts of the world, although the prayer books of several countries where she is head of state maintain prayers for her as sovereign.

A characteristic of Anglicanism is that it has no international juridical authority. All thirty-nine provinces of the Anglican Communion are autonomous, each with their own primate and governing structure. These provinces may take the form of national churches (such as in Canada, Uganda, or Japan) or a collection of nations (such as the West Indies, Central Africa, or South Asia), or geographical regions (such as Vanuatu and Solomon Islands), etc. Within these Communion provinces may exist subdivisions, called ecclesiastical provinces, under the jurisdiction of a metropolitan archbishop.

All provinces of the Anglican Communion consist of dioceses, each under the jurisdiction of a bishop. In the Anglican tradition, bishops must be consecrated according to the strictures of apostolic succession, which Anglicans consider one of the marks of Catholicity. Apart from bishops, there are two other orders of ordained ministry: deacon and priest.

No requirement is made for clerical celibacy, though many Anglo-Catholic priests have traditionally been bachelors. Because of innovations that occurred at various points after the latter half of the 20th century, women may be ordained as deacons in almost all provinces, as priests in some, and as bishops in a few provinces. Anglican religious orders and communities, suppressed in England during the Reformation, have re-emerged, especially since the mid-19th century, and now have an international presence and influence.

Government in the Anglican Communion is synodical, consisting of three houses of laity (usually elected parish representatives), clergy, and bishops. National, provincial, and diocesan synods maintain different scopes of authority, depending on their canons and constitutions. Anglicanism is not congregational in its polity: it is the diocese, not the parish church, which is the smallest unit of authority in the church. "(See Episcopal polity)".

The Archbishop of Canterbury has a precedence of honour over the other primates of the Anglican Communion, and for a province to be considered a part of the communion means specifically to be in full communion with the see of Canterbury – though this principle is currently subject to considerable debate, especially among those in the so-called Global South, including American Anglicans. The archbishop is, therefore, recognised as "primus inter pares" ("first amongst equals"), even though he does not exercise any direct authority in any province outside England, of which he is chief primate. Rowan Williams, the Archbishop of Canterbury from 2002 to 2012, was the first archbishop appointed from outside the Church of England since the Reformation: he was formerly the Archbishop of Wales.

As "spiritual head" of the Communion, the Archbishop of Canterbury maintains a certain moral authority, and has the right to determine which churches will be in communion with his see. He hosts and chairs the Lambeth Conferences of Anglican Communion bishops, and decides who will be invited to them. He also hosts and chairs the Anglican Communion Primates' Meeting and is responsible for the invitations to it. He acts as president of the secretariat of the Anglican Communion Office and its deliberative body, the Anglican Consultative Council.

The Anglican Communion has no international juridical organisation. All international bodies are consultative and collaborative, and their resolutions are not legally binding on the autonomous provinces of the Communion. There are three international bodies of note.


Like the Roman Catholic Church and the Orthodox churches, the Anglican Communion maintains the threefold ministry of deacons, presbyters (usually called "priests"), and bishops.

Bishops, who possess the fullness of Christian priesthood, are the successors of the Apostles. Primates, archbishops, and metropolitans are all bishops and members of the historical episcopate who derive their authority through apostolic succession – an unbroken line of bishops that can be traced back to the 12 apostles of Jesus.

Bishops are assisted by priests and deacons. Most ordained ministers in the Anglican Communion are priests, who usually work in parishes within a diocese. Priests are in charge of the spiritual life of parishes and are usually called the rector or vicar. A curate (or, more correctly, an "assistant curate") is a priest or deacon who assists the parish priest. Non-parochial priests may earn their living by any vocation, although employment by educational institutions or charitable organisations is most common. Priests also serve as chaplains of hospitals, schools, prisons, and in the armed forces.

An archdeacon is a priest or deacon responsible for administration of an archdeaconry, which is often the name given to the principal subdivisions of a diocese. An archdeacon represents the diocesan bishop in his or her archdeaconry. In the Church of England, the position of archdeacon can only be held by someone in priestly orders who has been ordained for at least six years. In some other parts of the Anglican Communion, the position can also be held by deacons. In parts of the Anglican Communion where women cannot be ordained as priests or bishops but can be ordained as deacons, the position of archdeacon is effectively the most senior office to which an ordained woman can be appointed.

A dean is a priest who is the principal cleric of a cathedral or other collegiate church and the head of the chapter of canons. If the cathedral or collegiate church has its own parish, the dean is usually also rector of the parish. However, in the Church of Ireland, the roles are often separated, and most cathedrals in the Church of England do not have associated parishes. In the Church in Wales, however, most cathedrals are parish churches and their deans are now also vicars of their parishes.

The Anglican Communion recognises Roman Catholic and Eastern Orthodox ordinations as valid. Outside the Anglican Communion, Anglican ordinations (at least of male priests) are recognised by the Old Catholic Church, Porvoo Communion Lutherans, and various Independent Catholic churches.

In Anglican churches, deacons often work directly in ministry to the marginalised inside and outside the church: the poor, the sick, the hungry, the imprisoned. Unlike Orthodox and most Roman Catholic deacons who may be married only before ordination, deacons are permitted to marry freely both before and after ordination, as are priests. Most deacons are preparing for priesthood and usually only remain as deacons for about a year before being ordained priests. However, there are some deacons who remain so.

Many provinces of the Anglican Communion ordain both men and women as deacons. Many of those provinces that ordain women to the priesthood previously allowed them to be ordained only to the diaconate. The effect of this was the creation of a large and overwhelmingly female diaconate for a time, as most men proceeded to be ordained priest after a short time as a deacon.

Deacons, in some dioceses, can be granted licences to solemnise matrimony, usually under the instruction of their parish priest and bishop. They sometimes officiate at Benediction of the Blessed Sacrament in churches which have this service. Deacons are not permitted to preside at the Eucharist (but can lead worship with the distribution of already consecrated communion where this is permitted), absolve sins, or pronounce a blessing. It is the prohibition against deacons pronouncing blessings that leads some to believe that deacons cannot solemnise matrimony.

All baptised members of the church are called Christian faithful, truly equal in dignity and in the work to build the church. Some non-ordained people also have a formal public ministry, often on a full-time and long-term basis – such as lay readers (also known as readers), churchwardens, vergers, and sextons. Other lay positions include acolytes (male or female, often children), lay eucharistic ministers (also known as chalice bearers), and lay eucharistic visitors (who deliver consecrated bread and wine to "shut-ins" or members of the parish who are unable to leave home or hospital to attend the Eucharist). Lay people also serve on the parish altar guild (preparing the altar and caring for its candles, linens, flowers, etc.), in the choir and as cantors, as ushers and greeters, and on the church council (called the "vestry" in some countries), which is the governing body of a parish.

A small yet influential aspect of Anglicanism is its religious orders and communities. Shortly after the beginning of the Catholic Revival in the Church of England, there was a renewal of interest in re-establishing religious and monastic orders and communities. One of Henry VIII's earliest acts was their dissolution and seizure of their assets. In 1841, Marian Rebecca Hughes became the first woman to take the vows of religion in communion with the Province of Canterbury since the Reformation. In 1848, Priscilla Lydia Sellon became the superior of the Society of the Most Holy Trinity at Devonport, Plymouth, the first organised religious order. Sellon is called "the restorer, after three centuries, of the religious life in the Church of England". For the next one hundred years, religious orders for both men and women proliferated throughout the world, becoming a numerically small but disproportionately influential feature of global Anglicanism.

Anglican religious life at one time boasted hundreds of orders and communities, and thousands of religious. An important aspect of Anglican religious life is that most communities of both men and women lived their lives consecrated to God under the vows of poverty, chastity, and obedience (or, in Benedictine communities, Stability, Conversion of Life, and Obedience) by practising a mixed life of reciting the full eight services of the Breviary in choir, along with a daily Eucharist, plus service to the poor. The mixed life, combining aspects of the contemplative orders and the active orders, remains to this day a hallmark of Anglican religious life. Another distinctive feature of Anglican religious life is the existence of some mixed-gender communities.

Since the 1960s, there has been a sharp decline in the number of professed religious in most parts of the Anglican Communion, especially in North America, Europe, and Australia. Many once large and international communities have been reduced to a single convent or monastery with memberships of elderly men or women. In the last few decades of the 20th century, novices have for most communities been few and far between. Some orders and communities have already become extinct. There are, however, still thousands of Anglican religious working today in approximately 200 communities around the world, and religious life in many parts of the Communion – especially in developing nations – flourishes.

The most significant growth has been in the Melanesian countries of the Solomon Islands, Vanuatu, and Papua New Guinea. The Melanesian Brotherhood, founded at Tabalia, Guadalcanal, in 1925 by Ini Kopuria, is now the largest Anglican Community in the world, with over 450 brothers in the Solomon Islands, Vanuatu, Papua New Guinea, the Philippines, and the United Kingdom. The Sisters of the Church, started by Mother Emily Ayckbowm in England in 1870, has more sisters in the Solomons than all their other communities. The Community of the Sisters of Melanesia, started in 1980 by Sister Nesta Tiboe, is a growing community of women throughout the Solomon Islands.

The Society of Saint Francis, founded as a union of various Franciscan orders in the 1920s, has experienced great growth in the Solomon Islands. Other communities of religious have been started by Anglicans in Papua New Guinea and in Vanuatu. Most Melanesian Anglican religious are in their early to mid-20s – vows may be temporary and it is generally assumed that brothers, at least, will leave and marry in due course – making the average age 40 to 50 years younger than their brothers and sisters in other countries. Growth of religious orders, especially for women, is marked in certain parts of Africa.

Anglicanism represents the third largest Christian communion in the world, after the Roman Catholic Church and the Eastern Orthodox Churches. The number of Anglicans in the world is over 85 million . The 11 provinces in Africa saw growth in the last two decades. They now include 36.7 million members, more Anglicans than there are in England. England remains the largest single Anglican province, with 26 million members. In most industrialised countries, church attendance has decreased since the 19th century. Anglicanism's presence in the rest of the world is due to large-scale emigration, the establishment of expatriate communities, or the work of missionaries.

The Church of England has been a church of missionaries since the 17th century, when the Church first left English shores with colonists who founded what would become the United States, Australia, Canada, New Zealand, and South Africa, and established Anglican churches. For example, an Anglican chaplain, Robert Wolfall, with Martin Frobisher's Arctic expedition, celebrated the Eucharist in 1578 in Frobisher Bay.

The first Anglican church in the Americas was built at Jamestown, Virginia, in 1607. By the 18th century, missionaries worked to establish Anglican churches in Asia, Africa, and Latin America. The great Church of England missionary societies were founded; for example, the Society for Promoting Christian Knowledge (SPCK) in 1698, the Society for the Propagation of the Gospel in Foreign Parts (SPG) in 1701, and the Church Mission Society (CMS) in 1799.

The 19th century saw the founding and expansion of social-oriented evangelism with societies such as the Church Pastoral Aid Society (CPAS) in 1836, Mission to Seafarers in 1856, Girls' Friendly Society (GFS) in 1875, Mothers' Union in 1876, and Church Army in 1882, all carrying out a personal form of evangelism.

The 20th century saw the Church of England developing new forms of evangelism such as the Alpha course in 1990, which was developed and propagated from Holy Trinity Brompton Church in London. In the 21st century, there has been renewed effort to reach children and youth. Fresh expressions is a Church of England missionary initiative to youth begun in 2005, and has ministries at a skate park through the efforts of St George's Church, Benfleet, Essex – Diocese of Chelmsford – or youth groups with evocative names, like the C.L.A.W (Christ Little Angels – Whatever!) youth group at Coventry Cathedral. And for the unchurched who do not actually wish to visit a brick and mortar church, there are Internet ministries such as the Diocese of Oxford's online Anglican i-Church, which appeared on the web in 2005.

Anglican interest in ecumenical dialogue can be traced back to the time of the Reformation and dialogues with both Orthodox and Lutheran churches in the 16th century. In the 19th century, with the rise of the Oxford Movement, there arose greater concern for reunion of the churches of "Catholic confession". This desire to work towards full communion with other denominations led to the development of the Chicago-Lambeth Quadrilateral, approved by the third Lambeth Conference of 1888. The four points (the sufficiency of scripture, the historic creeds, the two dominical sacraments, and the historic episcopate) were proposed as a basis for discussion, although they have frequently been taken as a non-negotiable bottom-line for any form of reunion.

Anglicanism in general has always sought a balance between the emphases of Catholicism and Protestantism, while tolerating a range of expressions of evangelicalism and ceremony. Clergy and laity from all Anglican churchmanship traditions have been active in the formation of the Continuing movement.

While there are high-church, broad-church, and low-church Continuing Anglicans, many Continuing churches are Anglo-Catholic with highly ceremonial liturgical practices. Others belong to a more evangelical or low-church tradition and tend to support the Thirty-nine Articles and simpler worship services. Morning Prayer, for instance, is often used instead of the Holy Eucharist for Sunday worship services, although this is not necessarily true of all low-church parishes.

Most Continuing churches in the United States reject the 1979 revision of the "Book of Common Prayer" by the Episcopal Church and use the 1928 version for their services instead. In addition, Anglo-Catholic bodies may use the Anglican Missal, Anglican Service Book, or English Missal in celebrating the Eucharist.

A changing focus on social issues after the Second World War led to Lambeth Conference resolutions countenancing contraception and the remarriage of divorced persons. Eventually, most provinces approved the ordination of women. In more recent years, some jurisdictions have permitted the ordination of people in same-sex relationships and authorised rites for the blessing of same-sex unions (see Homosexuality and Anglicanism). "The more liberal provinces that are open to changing Church doctrine on marriage in order to allow for same-sex unions include Brazil, Canada, New Zealand, Scotland, South India, South Africa, the US and Wales."

The lack of social consensus among and within provinces of diverse cultural traditions has resulted in considerable conflict and even schism concerning some or all of these developments (see Anglican realignment). More conservative elements within and outside of Anglicanism (primarily African churches and factions within North American Anglicanism) have opposed these changes, while some liberal and moderate Anglicans see this opposition as representing a new fundamentalism within Anglicanism and "believe a split is inevitable and preferable to continued infighting and paralysis." Some Anglicans opposed to various liberalising changes, in particular the ordination of women, have become Roman Catholics or Orthodox. Others have, at various times, joined the Continuing Anglican movement.

These trends reflect a countervailing tendency in Anglicanism towards insularity, reinforced perhaps by the "big tent" nature of the tradition which seeks to be comprehensive of various views and tendencies. The insularity and complacency of the early established Church of England has tended to influence Anglican self-identity and inhibit engagement with the broader society in favour of internal debate and dialogue. Nonetheless, there is significantly greater cohesion among Anglicans when they turn their attention outward.

The term "Continuing Anglicanism" refers to a number of church bodies which have formed outside of the Anglican Communion in the belief that traditional forms of Anglican faith, worship, and order have been unacceptably revised or abandoned within some Anglican Communion churches in recent decades. They therefore claim that they are "continuing" traditional Anglicanism.

The modern Continuing Anglican movement principally dates to the Congress of St. Louis, held in the United States in 1977, where participants rejected changes that had been made in the Episcopal Church's "Book of Common Prayer" and also the Episcopal Church's approval of the ordination of women to the priesthood. More recent changes in the North American churches of the Anglican Communion, such as the introduction of same-sex marriage rites and the ordination of gay and lesbian people to the priesthood and episcopate, have created further separations.

Continuing churches have generally been formed by people who have left the Anglican Communion. The original Anglican churches are charged by the Continuing Anglicans with being greatly compromised by secular cultural standards and liberal theology. Many Continuing Anglicans believe that the faith of some churches in communion with the Archbishop of Canterbury has become unorthodox and therefore have not sought to also be in communion with him.

The original continuing parishes in the United States were found mainly in metropolitan areas. Since the late 1990s, a number have appeared in smaller communities, often as a result of a division in the town's existing Episcopal churches. The 2007–08 "Directory of Traditional Anglican and Episcopal Parishes", published by the Fellowship of Concerned Churchmen, contained information on over 900 parishes affiliated with either the Continuing Anglican churches or the Anglican realignment movement, a more recent wave of Anglicans withdrawing from the Anglican Communion's North American provinces.

A concern for social justice can be traced to very early Anglican beliefs, relating to an intertwined theology of God, nature, and humanity. The Anglican theologian Richard Hooker wrote in his book "The Works of that Learned and Judicious Divine" that "God hath created nothing simply for itself, but each thing in all things, and of every thing each part in other have such interest, that in the whole world nothing is found whereunto any thing created can say, 'I need thee not.'" Such statements demonstrate a theological Anglican interest in social activism, which has historically appeared in movements such as evangelical Anglican William Wilberforce's campaign against slavery in the 18th century, or 19th century issues concerning industrialisation.

Lord Shaftesbury, a devout evangelical, campaigned to improve the conditions in factories, in mines, for chimney sweeps, and for the education of the very poor. For years, he was chairman of the Ragged School Board. Frederick Denison Maurice was a leading figure advocating reform, founding so-called "producer's co-operatives" and the Working Men's College. His work was instrumental in the establishment of the Christian socialist movement, although he himself was not in any real sense a socialist but "a Tory paternalist with the unusual desire to theories his acceptance of the traditional obligation to help the poor", influenced Anglo-Catholics such as Charles Gore, who wrote that "the principle of the incarnation is denied unless the Christian spirit can be allowed to concern itself with everything that interests and touches human life. Anglican focus on labour issues culminated in the work of William Temple in the 1930s and 1940s."

A question of whether or not Christianity is a pacifist religion has remained a matter of debate for Anglicans. The leading Anglican spokesman for pacifist ideas, from 1914 to 1945, was Ernest Barnes, bishop of Birmingham from 1924–1953. He opposed both world wars. In 1937, the Anglican Pacifist Fellowship emerged as a distinct reform organisation, seeking to make pacifism a clearly defined part of Anglican theology. The group rapidly gained popularity amongst Anglican intellectuals, including Vera Brittain, Evelyn Underhill, and the former British political leader George Lansbury. Furthermore, Dick Sheppard, who during the 1930s was one of Britain's most famous Anglican priests due to his landmark sermon broadcasts for BBC Radio, founded the Peace Pledge Union, a secular pacifist organisation for the non-religious that gained considerable support throughout the 1930s.

Whilst never actively endorsed by Anglican churches, many Anglicans unofficially have adopted the Augustinian "Just War" doctrine. The Anglican Pacifist Fellowship remains highly active throughout the Anglican world. It rejects this doctrine of "just war" and seeks to reform the Church by reintroducing the pacifism inherent in the beliefs of many of the earliest Christians and present in their interpretation of Christ's Sermon on the Mount. The principles of the Anglican Pacifist Fellowship are often formulated as a statement of belief that "Jesus' teaching is incompatible with the waging of war ... that a Christian church should never support or justify war ... [and] that our Christian witness should include opposing the waging or justifying of war."

Confusing the matter was the fact that the 37th Article of Religion in the "Book of Common Prayer" states that "it is lawful for Christian men, at the commandment of the Magistrate, to wear weapons, and serve in the wars." Therefore, the Lambeth Council in the modern era has sought to provide a clearer position by repudiating modern war and developed a statement that has been affirmed at each subsequent meeting of the Council.

This statement was strongly reasserted when "the 67th General Convention of the Episcopal Church reaffirms the statement made by the Anglican Bishops assembled at Lambeth in 1978 and adopted by the 66th General Convention of the Episcopal Church in 1979, calling "Christian people everywhere ... to engage themselves in non-violent action for justice and peace and to support others so engaged, recognising that such action will be controversial and may be personally very costly... this General Convention, in obedience to this call, urges all members of this Church to support by prayer and by such other means as they deem appropriate, those who engaged in such non-violent action, and particularly those who suffer for conscience' sake as a result; and be it further Resolved, that this General Convention calls upon all members of this Church seriously to consider the implications for their own lives of this call to resist war and work for peace for their own lives."

The focus on other social issues became increasingly diffuse after the Second World War. On the one hand, the growing independence and strength of Anglican churches in the Global South brought new emphasis to issues of global poverty, the inequitable distribution of resources, and the lingering effects of colonialism. In this regard, figures such as Desmond Tutu and Ted Scott were instrumental in mobilising Anglicans worldwide against the apartheid policies of South Africa. Rapid social change in the industrialised world during the 20th century compelled the church to examine issues of gender, sexuality, and marriage.

On 4 November 2009, Pope Benedict XVI issued an apostolic constitution, "Anglicanorum Coetibus", to allow groups of former Anglicans to enter into full communion with the Roman Catholic Church as members of personal ordinariates. The 20 October 2009 announcement of the imminent constitution mentioned:

For each personal ordinariate, the ordinary may be a former Anglican bishop or priest. It was expected that provision would be made to allow the retention of aspects of Anglican liturgy; cf. Anglican Use.



</doc>
<doc id="1216" url="https://en.wikipedia.org/wiki?curid=1216" title="Athens">
Athens

Athens (; , "Athína" ; , "Athênai" ) is the capital and largest city of Greece. Athens dominates the Attica region and is one of the world's oldest cities, with its recorded history spanning over 3,400 years and its earliest human presence starting somewhere between the 11th and 7th millennium BC.

Classical Athens was a powerful city-state that emerged in conjunction with the seagoing development of the port of Piraeus, which had been a distinct city prior to its 5th-century BC incorporation with Athens. A center for the arts, learning and philosophy, home of Plato's Academy and Aristotle's Lyceum, it is widely referred to as the cradle of Western civilization and the birthplace of democracy, largely because of its cultural and political impact on the European continent, and in particular the Romans. In modern times, Athens is a large cosmopolitan metropolis and central to economic, financial, industrial, maritime, political and cultural life in Greece.

Athens is a global city and one of the biggest economic centres in southeastern Europe. It has a large financial sector, and its port Piraeus is both the largest passenger port in Europe, and the second largest in the world. while at the same time being the sixth busiest passenger port in Europe.
The Municipality of Athens (also City of Athens) had a population of 664,046 (in 2011) within its administrative limits, and a land area of . The urban area of Athens (Greater Athens and Greater Piraeus) extends beyond its administrative municipal city limits, with a population of 3,090,508 (in 2011) over an area of . According to Eurostat in 2011, the functional urban area (FUA) of Athens was the 9th most populous FUA in the European Union (the 6th most populous capital city of the EU), with a population of 3.8 million people. Athens is also the southernmost capital on the European mainland.

The heritage of the classical era is still evident in the city, represented by ancient monuments and works of art, the most famous of all being the Parthenon, considered a key landmark of early Western civilization. The city also retains Roman and Byzantine monuments, as well as a smaller number of Ottoman monuments. Athens is home to two UNESCO World Heritage Sites, the Acropolis of Athens and the medieval Daphni Monastery. Landmarks of the modern era, dating back to the establishment of Athens as the capital of the independent Greek state in 1834, include the Hellenic Parliament and the so-called "architectural trilogy of Athens", consisting of the National Library of Greece, the National and Kapodistrian University of Athens and the Academy of Athens. Athens is also home to several museums and cultural institutions, such as the National Archeological Museum, featuring the world's largest collection of ancient Greek antiquities, the Acropolis Museum, the Museum of Cycladic Art, the Benaki Museum and the Byzantine and Christian Museum. Athens was the host city of the first modern-day Olympic Games in 1896, and 108 years later it welcomed home the 2004 Summer Olympics, making it one of only a handful of cities to have hosted the Olympics more than once.

In Ancient Greek, the name of the city was ("Athênai", in Classical Attic) a plural. In earlier Greek, such as Homeric Greek, the name had been current in the singular form though, as ("Athḗnē"). It was possibly rendered in the plural later on, like those of ("Thêbai") and ("Μukênai"). The root of the word is probably not of Greek or Indo-European origin, and is possibly a remnant of the Pre-Greek substrate of Attica. In antiquity, it was debated whether Athens took its name from its patron goddess Athena (Attic , "Athēnâ", Ionic , "Athḗnē", and Doric , "Athā́nā") or Athena took her name from the city. Modern scholars now generally agree that the goddess takes her name from the city, because the ending -"ene" is common in names of locations, but rare for personal names. During the medieval period, the name of the city was rendered once again in the singular as . However, after the establishment of the modern Greek state, and partly due to the conservatism of the written language, became again the official name of the city and remained so until the abandonment of Katharevousa in the 1970s, when Ἀθήνα, "Athína", became the official name.

According to the ancient Athenian founding myth, Athena, the goddess of wisdom, competed against Poseidon, the God of the Seas, for patronage of the yet-unnamed city; they agreed that whoever gave the Athenians the better gift would become their patron and appointed Cecrops, the king of Athens, as the judge. According to the account given by Pseudo-Apollodorus, Poseidon struck the ground with his trident and a salt water spring welled up. In an alternative version of the myth from Vergil's "Georgics", Poseidon instead gave the Athenians the first horse. In both versions, Athena offered the Athenians the first domesticated olive tree. Cecrops accepted this gift and declared Athena the patron goddess of Athens.

Different etymologies, now commonly rejected, were proposed during the 19th century. Christian Lobeck proposed as the root of the name the word ("áthos") or ("ánthos") meaning "flower", to denote Athens as the "flowering city". Ludwig von Döderlein proposed the stem of the verb , stem θη- ("tháō", "thē-", "to suck") to denote Athens as having fertile soil.

In classical literature, the city was sometimes referred to as the City of the Violet Crown, first documented in Pindar's ἰοστέφανοι Ἀθᾶναι ("iostéphanoi Athânai"), or as ("tò kleinòn ásty", "the glorious city"). In medieval texts, variant names include Setines, Satine, and Astines, all derivations involving false splitting of prepositional phrases. Today the caption ("ī protévousa"), "the capital", has become somewhat common.

The oldest known human presence in Athens is the Cave of Schist, which has been dated to between the 11th and 7th millennia BC. Athens has been continuously inhabited for at least 7,000 years.
By 1400 BC the settlement had become an important centre of the Mycenaean civilization and the Acropolis was the site of a major Mycenaean fortress, whose remains can be recognised from sections of the characteristic Cyclopean walls. Unlike other Mycenaean centers, such as Mycenae and Pylos, it is not known whether Athens suffered destruction in about 1200 BC, an event often attributed to a Dorian invasion, and the Athenians always maintained that they were pure Ionians with no Dorian element. However, Athens, like many other Bronze Age settlements, went into economic decline for around 150 years afterwards.

Iron Age burials, in the Kerameikos and other locations, are often richly provided for and demonstrate that from 900 BC onwards Athens was one of the leading centres of trade and prosperity in the region. The leading position of Athens may well have resulted from its central location in the Greek world, its secure stronghold on the Acropolis and its access to the sea, which gave it a natural advantage over inland rivals such as Thebes and Sparta.

By the 6th century BC, widespread social unrest led to the reforms of Solon. These would pave the way for the eventual introduction of democracy by Cleisthenes in 508 BC. Athens had by this time become a significant naval power with a large fleet, and helped the rebellion of the Ionian cities against Persian rule. In the ensuing Greco-Persian Wars Athens, together with Sparta, led the coalition of Greek states that would eventually repel the Persians, defeating them decisively at Marathon in 490 BC, and crucially at Salamis in 480 BC. However, this did not prevent Athens from being captured and sacked twice by the Persians within one year, after a heroic but ultimately failed resistance at Thermopylae by Spartans and other Greeks led by King Leonidas, after both Boeotia and Attica fell to the Persians.
The decades that followed became known as the Golden Age of Athenian democracy, during which time Athens became the leading city of Ancient Greece, with its cultural achievements laying the foundations for Western civilization. The playwrights Aeschylus, Sophocles and Euripides flourished in Athens during this time, as did the historians Herodotus and Thucydides, the physician Hippocrates, and the philosopher Socrates. Guided by Pericles, who promoted the arts and fostered democracy, Athens embarked on an ambitious building program that saw the construction of the Acropolis of Athens (including the Parthenon), as well as empire-building via the Delian League. Originally intended as an association of Greek city-states to continue the fight against the Persians, the league soon turned into a vehicle for Athens's own imperial ambitions. The resulting tensions brought about the Peloponnesian War (431–404 BC), in which Athens was defeated by its rival Sparta.

By the mid-4th century BC, the northern Greek kingdom of Macedon was becoming dominant in Athenian affairs. In 338 BC the armies of Philip II defeated an alliance of some of the Greek city-states including Athens and Thebes at the Battle of Chaeronea, effectively ending Athenian independence. Later, under Rome, Athens was given the status of a free city because of its widely admired schools. The Roman emperor Hadrian, in the 2nd century CE, ordered the construction of a library, a gymnasium, an aqueduct which is still in use, several temples and sanctuaries, a bridge and financed the completion of the Temple of Olympian Zeus.

By the end of Late Antiquity, the city experienced decline followed by recovery in the second half of the Middle Byzantine Period, in the 9th to 10th centuries CE, and was relatively prosperous during the Crusades, benefiting from Italian trade. After the Fourth Crusade the Duchy of Athens was established. In 1458 it was conquered by the Ottoman Empire and entered a long period of decline.

Following the Greek War of Independence and the establishment of the Greek Kingdom, Athens was chosen as the capital of the newly independent Greek state in 1834, largely because of historical and sentimental reasons. At the time, it was reduced to a town of about 4,000 people in a loose swarm of houses along the foot of the Acropolis. The first King of Greece, Otto of Bavaria, commissioned the architects Stamatios Kleanthis and Eduard Schaubert to design a modern city plan fit for the capital of a state.

The first modern city plan consisted of a triangle defined by the Acropolis, the ancient cemetery of Kerameikos and the new palace of the Bavarian king (now housing the Greek Parliament), so as to highlight the continuity between modern and ancient Athens. Neoclassicism, the international style of this epoch, was the architectural style through which Bavarian, French and Greek architects such as Hansen, Klenze, Boulanger or Kaftantzoglou designed the first important public buildings of the new capital. In 1896, Athens hosted the first modern Olympic Games. During the 1920s a number of Greek refugees, expelled from Asia Minor after the Greco-Turkish War, swelled Athens's population; nevertheless it was most particularly following World War II, and from the 1950s and 1960s, that the population of the city exploded, and Athens experienced a gradual expansion.
In the 1980s it became evident that smog from factories and an ever-increasing fleet of automobiles, as well as a lack of adequate free space due to congestion, had evolved into the city's most important challenge. A series of anti-pollution measures taken by the city's authorities in the 1990s, combined with a substantial improvement of the city's infrastructure (including the Attiki Odos motorway, the expansion of the Athens Metro, and the new Athens International Airport), considerably alleviated pollution and transformed Athens into a much more functional city. In 2004 Athens hosted the 2004 Summer Olympics.

Athens sprawls across the central plain of Attica that is often referred to as the "Athens or Attica Basin" (Greek: Λεκανοπέδιο Αττικής). The basin is bounded by four large mountains: Mount Aigaleo to the west, Mount Parnitha to the north, Mount Pentelicus to the northeast and Mount Hymettus to the east. Beyond Mount Aegaleo lies the Thriasian plain, which forms an extension of the central plain to the west. The Saronic Gulf lies to the southwest. Mount Parnitha is the tallest of the four mountains (), and has been declared a national park.

Athens is built around a number of hills. Lycabettus is one of the tallest hills of the city proper and provides a view of the entire Attica Basin. The meteorology of Athens is deemed to be one of the most complex in the world because its mountains cause a temperature inversion phenomenon which, along with the Greek Government's difficulties controlling industrial pollution, was responsible for the air pollution problems the city has faced. This issue is not unique to Athens; for instance, Los Angeles and Mexico City also suffer from similar atmospheric inversion problems.

The Cephissus river, the Ilisos and the Eridanos stream are the historical rivers of Athens.

By the late 1970s, the pollution of Athens had become so destructive that according to the then Greek Minister of Culture, Constantine Trypanis, ""...the carved details on the five the caryatids of the Erechtheum had seriously degenerated, while the face of the horseman on the Parthenon's west side was all but obliterated."" A series of measures taken by the authorities of the city throughout the 1990s resulted in the improvement of air quality; the appearance of smog (or "nefos" as the Athenians used to call it) has become less common.

Measures taken by the Greek authorities throughout the 1990s have improved the quality of air over the Attica Basin. Nevertheless, air pollution still remains an issue for Athens, particularly during the hottest summer days. In late June 2007, the Attica region experienced a number of brush fires, including a blaze that burned a significant portion of a large forested national park in Mount Parnitha, considered critical to maintaining a better air quality in Athens all year round. Damage to the park has led to worries over a stalling in the improvement of air quality in the city.

The major waste management efforts undertaken in the last decade (particularly the plant built on the small island of Psytalia) have improved water quality in the Saronic Gulf, and the coastal waters of Athens are now accessible again to swimmers. In January 2007, Athens faced a waste management problem when its landfill near Ano Liosia, an Athenian suburb, reached capacity. The crisis eased by mid-January when authorities began taking the garbage to a temporary landfill.

Athens has a hot-summer Mediterranean climate (Köppen climate classification: "Csa"). The dominant feature of Athens’ climate is alternation between prolonged hot and dry summers and mild winters with moderate rainfall. With an average of of yearly precipitation, rainfall occurs largely between the months of October and April. July and August are the driest months, when thunderstorms occur sparsely once or twice a month.

The capital of Greece is sometimes considered the hottest city in Europe (considering the annual average temperature and not the records surpassed in the ranking by the south coast of Spain and Portugal) and also the driest city.

Owing to the rain shadow of the Pindus Mountains, annual precipitation of Athens is lower than most other parts of Greece, especially western Greece. As an example, Ioannina receives around per year, and Agrinio around per year. Daily average highs for July (1989–2018) have been measured at , but some parts of the city may be even hotter, in particular western areas due to a combination of industrialization and a number of natural factors, knowledge of which has existed since the mid-19th century.

Athens is affected by the urban heat island effect in some areas which is caused by human activity, altering its temperatures compared to the surrounding rural areas, and leaving detrimental effects on energy usage, expenditure for cooling, and health. The urban heat island of the city has also been found to be partially responsible for alterations of the climatological temperature time-series of specific Athens meteorological stations, because of its impact on the temperatures and the temperature trends recorded by some meteorological stations. On the other hand, specific meteorological stations, such as the National Garden station and Thiseio meteorological station, are less affected or do not experience the urban heat island.

Athens holds the World Meteorological Organization record for the highest temperature ever recorded in Europe, at , which was recorded in the Elefsina and Tatoi suburbs of Athens on 10 July 1977.

The municipality of Athens, the city centre of the Athens Urban Area, is divided into several districts: Omonoia, Syntagma, Exarcheia, Agios Nikolaos, Neapolis, Lykavittos, Lofos Strefi, Lofos Finopoulou, Lofos Filopappou, Pedion Areos, Metaxourgeio, Aghios Kostantinos, Larissa Station, Kerameikos, Psiri, Monastiraki, Gazi, Thission, Kapnikarea, Aghia Irini, Aerides, Anafiotika, Plaka, Acropolis, Pnyka, Makrygianni, Lofos Ardittou, Zappeion, Aghios Spyridon, Pangrati, Kolonaki, Dexameni, Evaggelismos, Gouva, Aghios Ioannis, Neos Kosmos, Koukaki, Kynosargous, Fix, Ano Petralona, Kato Petralona, Rouf, Votanikos, Profitis Daniil, Akadimia Platonos, Kolonos, Kolokynthou, Attikis Square, Lofos Skouze, Sepolia, Kypseli, Aghios Meletios, Nea Kypseli, Gyzi, Polygono, Ampelokipoi, Panormou-Gerokomeio, Pentagono, Ellinorosson, Nea Filothei, Ano Kypseli, Tourkovounia-Lofos Patatsou, Lofos Elikonos, Koliatsou, Thymarakia, Kato Patisia, Treis Gefyres, Aghios Eleftherios, Ano Patisia, Kypriadou, Menidi, Prompona, Aghios Panteleimonas, Pangrati, Goudi and Ilisia.



Parnitha National Park is punctuated by well-marked paths, gorges, springs, torrents and caves dotting the protected area. Hiking and mountain-biking in all four mountains are popular outdoor activities for residents of the city. The National Garden of Athens was completed in 1840 and is a green refuge of 15.5 hectares in the centre of the Greek capital. It is to be found between the Parliament and Zappeion buildings, the latter of which maintains its own garden of seven hectares.

Parts of the city centre have been redeveloped under a masterplan called the "Unification of Archeological Sites of Athens", which has also gathered funding from the EU to help enhance the project. The landmark Dionysiou Areopagitou Street has been pedestrianised, forming a scenic route. The route starts from the Temple of Olympian Zeus at Vasilissis Olgas Avenue, continues under the southern slopes of the Acropolis near Plaka, and finishes just beyond the Temple of Hephaestus in Thiseio. The route in its entirety provides visitors with views of the Parthenon and the Agora (the meeting point of ancient Athenians), away from the busy city centre.

The hills of Athens also provide green space. Lycabettus, Philopappos hill and the area around it, including Pnyx and Ardettos hill, are planted with pines and other trees, with the character of a small forest rather than typical metropolitan parkland. Also to be found is the Pedion tou Areos ("Field of Mars") of 27.7 hectares, near the National Archaeological Museum.

Athens' largest zoo is the Attica Zoological Park, a 20-hectare (49-acre) private zoo located in the suburb of Spata. The zoo is home to around 2000 animals representing 400 species, and is open 365 days a year. Smaller zoos exist within public gardens or parks, such as the zoo within the National Garden of Athens.

The Athens Metropolitan Area consists of 58 densely populated municipalities, sprawling around the municipality of Athens (the city centre) in virtually all directions. For the Athenians, all the urban municipalities surrounding the city centre are called suburbs. According to their geographic location in relation to the City of Athens, the suburbs are divided into four zones; the northern suburbs (including Agios Stefanos, Dionysos, Ekali, Nea Erythraia, Kifissia, Maroussi, Pefki, Lykovrysi, Metamorfosi, Nea Ionia, Nea Filadelfeia, Irakleio, Vrilissia, Melissia, Penteli, Chalandri, Agia Paraskevi, Galatsi, Psychiko and Filothei); the southern suburbs (including Alimos, Nea Smyrni, Moschato, Kallithea, Agios Dimitrios, Palaio Faliro, Elliniko, Glyfada, Argyroupoli, Ilioupoli, Voula and Vouliagmeni); the eastern suburbs (including Zografou, Dafni, Vyronas, Kaisariani, Cholargos and Papagou); and the western suburbs (including Peristeri, Ilion, Egaleo, Koridallos, Agia Varvara, Chaidari, Petroupoli, Agioi Anargyroi and Kamatero).

The Athens city coastline, extending from the major commercial port of Piraeus to the southernmost suburb of Varkiza for some , is also connected to the city centre by a tram.

In the northern suburb of Maroussi, the upgraded main Olympic Complex (known by its Greek acronym OAKA) dominates the skyline. The area has been redeveloped according to a design by the Spanish architect Santiago Calatrava, with steel arches, landscaped gardens, fountains, futuristic glass, and a landmark new blue glass roof which was added to the main stadium. A second Olympic complex, next to the sea at the beach of Palaio Faliro, also features modern stadia, shops and an elevated esplanade. Work is underway to transform the grounds of the old Athens Airport – named Elliniko – in the southern suburbs, into one of the largest landscaped parks in Europe, to be named the Hellenikon Metropolitan Park.

Many of the southern suburbs (such as Alimos, Palaio Faliro, Elliniko, Glyfada, Voula, Vouliagmeni and Varkiza) known as the Athens Riviera, host a number of sandy beaches, most of which are operated by the Greek National Tourism Organisation and require an entrance fee. Casinos operate on both Mount Parnitha, some from downtown Athens (accessible by car or cable car), and the nearby town of Loutraki (accessible by car via the Athens – Corinth National Highway, or the suburban rail service Proastiakos).

The large City Centre of the Greek capital falls directly within the municipality of Athens, which is the largest in population size in Greece. Piraeus also forms a significant city centre on its own, within the Athens Urban Area and being the second largest in population size within it, with Peristeri and Kallithea following.

The Athens Urban Area today consists of 40 municipalities, 35 of which make up what is referred to as the Greater Athens municipalities, located within 4 regional units (North Athens, West Athens, Central Athens, South Athens); and a further 5, which make up the Greater Piraeus municipalities, located within the regional unit of Piraeus as mentioned above. The densely built up urban area of the Greek capital sprawls across throughout the "Attica Basin" and has a total population of 3,074,160 (in 2011).

The Athens municipality forms the core and center of Greater Athens, which consists of the Athens municipality and 34 more municipalities, divided in four regional units (Central, North, South and West Athens), accounting for 2,641,511 people (in 2011) within an area of . Until 2010, these four regional units made up the abolished Athens Prefecture. The municipality of Piraeus, the historic Athenian port, with its 4 suburban municipalities make up the regional unit of Piraeus, which in turn forms Greater Piraeus.

Greater Athens and Greater Piraeus with part of East and West Attica regional units combined make up the continuous built up Athens Urban Area (), also called the Urban Area of the Capital () or simply Athens (the most common use of the term), spanning over , with a population of 3,090,508 people as of 2011. The Athens Urban Area is considered to form the city of Athens as a whole, despite its administrative divisions, which is the largest in Greece and one of the most populated urban areas in Europe.

The Athens Metropolitan Area spans within the Attica region and includes a total of 58 municipalities, which are organized in 7 regional units (those outlined above, along with East Attica and West Attica), having reached a population of 3,737,550 based on the preliminary results of the 2011 census. Athens and Piraeus municipalities serve as the two metropolitan centres of the Athens Metropolitan Area. There are also some inter-municipal centres serving specific areas. For example, Kifissia and Glyfada serve as inter-municipal centres for northern and southern suburbs respectively.

The municipality of Athens has an official population of 664,046 people. The four regional units that make up what is referred to as Greater Athens have a combined population of 2,640,701. They together with the regional unit of Piraeus (Greater Piraeus) make up the dense Athens Urban Area which reaches a total population of 3,090,508 inhabitants (in 2011). As Eurostat the FUA of Athens had in 2013 3,828,434 inhabitants, being apparently decreasing compared with the pre-economic crisis date of 2009 (4,164,175)

The municipality (City) of Athens is the most populous in Greece, with a population of 664,046 people (in 2011) and an area of , forming the core of the Athens Urban Area within the "Attica Basin". The current mayor of Athens is Giorgos Kaminis. The municipality is divided into seven municipal districts which are mainly used for administrative purposes.

As of the 2011 census, the population for each of the seven municipal districts of Athens is as follows:


For the Athenians the most popular way of dividing the city proper is through its neighbourhoods such as Pagkrati, Ambelokipi, Exarcheia, Patissia, Ilissia, Petralona, Koukaki and Kypseli, each with its own distinct history and characteristics.

The Athens Metropolitan Area, with an area of and inhabited by 3,753,783 people in 2011, consists of the Athens Urban Area with the addition of the towns and villages of East and West Attica, which surround the dense urban area of the Greek capital. It actually sprawls over the whole peninsula of Attica, which is the best part of the region of Attica, excluding the islands.

Mycenean Athens in 1600–1100 BC could have reached the size of Tiryns; that would put the population at the range of 10,000 – 15,000. During the Greek Dark Ages the population of Athens was around 4,000 people. In 700 BC the population grew to 10,000. In 500 BC the area probably contained 200,000 people. During the classical period the city's population is estimated from 150,000–350,000 and up to 610,000 according to Thucydides. When Demetrius of Phalerum conducted a population census in 317 BC the population was 21,000 free citizens, plus 10,000 resident aliens and 400,000 slaves. This suggests a total population of 431,000. This figure is highly suspect because of the lopsided number of slaves and does not include free women and children and resident foreigners: an estimated based on Thucydides is: 40,000 male citizens, 100,000 family members, 70,000 metics (resident foreigners) and 150,000-400,000 slaves. However the numbers would include Attica and not just Athens the city.

The ancient site of Athens is centred on the rocky hill of the acropolis. In ancient times the port of Piraeus was a separate city, but it has now been absorbed into the Athens Urban Area. The rapid expansion of the city, which continues to this day, was initiated in the 1950s and 1960s, because of Greece's transition from an agricultural to an industrial nation. The expansion is now particularly toward the East and North East (a tendency greatly related to the new Eleftherios Venizelos International Airport and the Attiki Odos, the freeway that cuts across Attica). By this process Athens has engulfed many former suburbs and villages in Attica, and continues to do so. The table below shows the historical population of Athens in recent times.

Athens became the capital of Greece in 1834, following Nafplion, which was the provisional capital from 1829. The municipality (City) of Athens is also the capital of the Attica region. The term "Athens" can refer either to the municipality of Athens, to Greater Athens, or to the entire Athens Urban Area.

Athens is twinned with:

Athens is the financial capital of Greece. According to data from 2014, Athens as a metropolitan economic area produced 129.62 billion US-dollars as GDP in PPP, which consists nearly a half of the production for the whole country. In the list with the strongest economic metropoles of the world Athens was ranked that year 102nd, while the GDP per capita for the same year was 32.484 US-dollars. 

Athens is one of the major economic centres in south-eastern Europe and is considered as a regional economic power in Europe generally. The proximity to the port of Piraeus, where big investments by COSCO have already been delivered during the recent decade, the completion of the new Cargo Centre in Thriasion , the expansion of the Athens Metro and the Athens Tram, as well as the projected metropolitan park in Elliniko and other economic projects are the economic landmarks of the upcoming years. 

Important Greek companies are Mytilineos Holdings, Titan Cement, Folli Follie, Jumbo S.A., OPAP and COSMOTE have their headquarters in the metropolitan area of Athens, while multinational companies such as Ericsson, Siemens, Motorola, Samsung, Novartis and Coca-Cola have their regional research and development headquarters also there. 

The banking sector is represented by National Bank of Greece, Alpha Bank, Eurobank and Piraeus Bank, while the Bank of Greece is also situated in the city centre. The Athens Stock Exchange, the only in Greece, has been severely hit by the Greek government-debt crisis and the decision of the government to proceed into capital controls during summer 2015. As a whole the economy of Athens and Greece has been severely hit with today's data showing a change from long recession to growth of 1.4% in 2017. 

Tourism is also a great contributor for the economy of the city, which is considered as one of the top destinations in Europe for city-break tourism and is also the gateway for excursions to the islands or the mainland. Greece attracted 26.5 million visitors in 2015, 30.1 million visitors in 2017 and over 33 million in 2018,  making Greece one of the most visited countries in Europe and the world, and contributing 18% to the nation's Gross Domestic Product. Athens welcomed more than 5 million tourists in 2018 and 1,4 million of them were "city-breakers" (in 2013 the city-breakers were only 220.000). 

Athens is serviced by a variety of transportation means, forming the largest mass transit system of Greece. The Athens Mass Transit System consists of a large bus fleet, a trolleybus fleet that mainly serves Athens's city center, the city's Metro, a commuter rail service and a tram network, connecting the southern suburbs to the city centre.

OSY () (ODIKES SYGKOINONIES) which is subsidiary company of OASA (Athens transport urban organisation), is the main operator of buses and trolleybusses in Athens. Its network consists of about 300 bus lines and 22 trolleybus lines which span the Athens Metropolitan Area, with a fleet of 1,839 buses and 366 trolleybuses. Of those 1,839 buses 416 run on compressed natural gas, making up the largest fleet of natural gas-powered buses in Europe and all trolleybusses are equipped to enable them to run on diesel in case of power failure. 

International and regional bus links are provided by KTEL from two InterCity Bus Terminals, Kifissos Bus Terminal A and Liosion Bus Terminal B, both located in the north-western part of the city. "Kifissos" provides connections towards the Peloponnese and Attica, whereas "Liosion" is used for most northerly mainland destinations.

The Athens Metro is operated by STASY S.A (STATHERES SYGKOINONIES S.A) which is a subsidiary company of OASA (Athens urban transport organisation) and provides public transport throughout the Athens Urban Area. While its main purpose is transport, it also houses Greek artifacts found during construction of the system. The Athens Metro has an operating staff of 387 and runs three metro lines; namely the Green (line 1), Red (line 2) and Blue (line 3) lines, which the first were constructed 
in 1869, and the other two largely during the 1990s, with the initial sections opened in January 2000. The line 1 for the most part runs at ground level and the other two (line 2,3) routes run entirely underground and a fleet of 42 trains consisting of 252 cars operate within the network, with a daily occupancy of 1,353,000 passengers.

The Green Line (line 1) serves 24 stations, and forms the oldest line of the Athens metro network. Runs from Piraeus station to Kifissia station and covers a distance of 25.6-kilometre (15.9 mi). There are also transfer connections with the Blue (line 3) at the Monastiraki station and with Red (line 2) at Onomoia and Attiki stations.

The Red Line (line 2) runs from Anthoupoli station to Elliniko station and covers a distance of . The line connects the western suburbs of Athens with the southeast suburbs, passing through the center of Athens. The Red line has transfer connections with the Green (line 1) at Attiki and Omonoia Square stations. There are also transfer connections with the Blue (line 3) at the Syntagma Square station and with the Tram at Syntagma Square, Sygrou-Fix and Agios Ioannis stations.

The Blue Line (line 3) runs from the western suburbs, namely Agia Marina to the Egaleo station, through the central Monastiraki and Syntagma stations to Doukissis Plakentias avenue in the northeastern suburb of Halandri, covering a distance of , then ascending to ground level and reaching Eleftherios Venizelos International Airport, using the Suburban Railway infrastructure and extending its length to . The spring 2007 extension from Monastiraki westwards, to Egaleo, connected some of the main night life hubs of the city, namely the ones of Gazi (Kerameikos station) with Psirri (Monastiraki station) and the city centre (Syntagma station). Extensions are under construction to the west southwest suburbs of Athens, reaching the port of Piraeus. The new stations will be Agia Barvara, Koridallos, Nikaia, Maniatika, Piraeus and Dimotiko Theatro station. The stations will be ready in 2021 (the first three will open in June 2019), connecting the biggest port of Greece, Piraeus Port ,with the biggest airport of Greece the Athens International Airport.

The Athens commuter rail service, referred to as the "Proastiakós", connects Eleftherios Venizelos International Airport to the city of Kiato, west of Athens, via Larissa station, the city's central rail station and the port of Piraeus. The service is sometimes considered the fourth line of the Athens Metro. The length of Athens's commuter rail network extends to , and is expected to stretch to by 2010. The Proastiakos will be extended to Xylokastro west of Athens and Chalkida.

Athens Tram SA operates a fleet of 35 Sirio type vehicles which serve 48 stations, employ 345 people with an average daily occupancy of 65,000 passengers. The tram network spans a total length of and covers ten Athenian suburbs. The network runs from Syntagma Square to the southwestern suburb of Palaio Faliro, where the line splits in two branches; the first runs along the Athens coastline toward the southern suburb of Voula, while the other heads toward the Piraeus district of Neo Faliro. The network covers the majority of the Saronic coastline. Further extensions are planned towards the major commercial port of Piraeus. The expansion to Piraeus will include 12 new stations, increase the overall length of tram route by , and increase the overall transportation network.

Athens is served by the Athens International Airport (ATH), located near the town of Spata, in the eastern Messoghia plain, some east of Athens. The airport, awarded the "European Airport of the Year 2004" Award, is intended as an expandable hub for air travel in southeastern Europe and was constructed in 51 months, costing 2.2 billion euros. It employs a staff of 14,000.

The airport is served by the Metro, the suburban rail, buses to Piraeus port, Athens' city centre and its suburbs, and also taxis. The airport accommodates 65 landings and take-offs per hour, with its 24-passenger boarding bridges, 144 check-in counters and broader main terminal; and a commercial area of which includes cafés, duty-free shops, and a small museum.

In 2018,the airport handled 24,135,736 a huge increase over the last 4 years,In 2014, the airport handled 15,196,369 passengers, an increase of 21.2% over the previous year of 2013. Of those 15,196,369 passengers, 5,267,593 passed through the airport for domestic flights, and 9,970,006 passengers travelled through for international flights. Beyond the dimensions of its passenger capacity, ATH handled 205,294 total flights in 2007, or approximately 562 flights per day.

Athens is the hub of the country's national railway system (OSE), connecting the capital with major cities across Greece and abroad (Istanbul, Sofia and Bucharest).The Port of Piraeus connects Athens to the numerous Greek islands of the Aegean Sea, with ferries departing, while also serving the cruise ships that arrive.

Two main motorways of Greece begin in Athens, namely the A1/E75, which crosses through Athens's Urban Area from Piraeus, heading north towards Greece's second largest city, Thessaloniki; and the A8/E94 heading west, towards Patras, which incorporated the GR-8A. Before their completion much of the road traffic used the GR-1 and the GR-8.

Athens' Metropolitan Area is served by the motorway network of the Attiki Odos toll-motorway (code: A6). Its main section extends from the western industrial suburb of Elefsina to Athens International Airport; while two beltways, namely the Aigaleo Beltway (A65) and the Hymettus Beltway (A64) serve parts of western and eastern Athens respectively. The span of the Attiki Odos in all its length is , making it the largest metropolitan motorway network in all of Greece.

Located on Panepistimiou Street, the old campus of the University of Athens, the National Library, and the Athens Academy form the "Athens Trilogy" built in the mid-19th century. Most of the university's workings have been moved to a much larger, modern campus located in the eastern suburb of Zografou. The second higher education institution in the city is the Athens Polytechnic School, found in Patission Street. This was the location where on 17 November 1973, more than 13 students were killed and hundreds injured inside the university during the Athens Polytechnic uprising, against the military junta that ruled the nation from 21 April 1967 until 23 July 1974.

Other universities that lie within Athens are the Athens University of Economics and Business, the Panteion University, the Agricultural University of Athens and the University of Piraeus. There are overall eleven state-supported Institutions of Higher (or Tertiary) education located in the Metropolitan Area of Athens, these are by chronological order: Athens School of Fine Arts (1837), National Technical University of Athens (1837), National and Kapodistrian University of Athens (1837), Agricultural University of Athens (1920), Athens University of Economics and Business (1920), Panteion University of Social and Political Sciences (1927), University of Piraeus (1938), Technological Educational Institute of Piraeus (1976), Technological Educational Institute of Athens (1983), Harokopio University (1990), School of Pedagogical and Technological Education (2002). There are also several other private "colleges", as they called formally in Greece, as the establishment of private universities is prohibited by the constitution. Many of them are accredited by a foreign state or university such as the American College of Greece and the Athens Campus of the University of Indianapolis.

The city is a world centre of archaeological research. Along with national institutions, such as the Athens University and the Archaeological Society, there are multiple archaeological Museums including the National Archaeological Museum, the Cycladic Museum, the Epigraphic Museum, the Byzantine & Christian Museum, as well as museums at the ancient Agora, Acropolis, Kerameikos, and the Kerameikos Archaeological Museum. The city is also home to the Demokritos laboratory for Archaeometry, alongside regional and national archaeological authorities that form part of the Greek Department of Culture.
Athens hosts 17 Foreign Archaeological Institutes which promote and facilitate research by scholars from their home countries. As a result, Athens has more than a dozen archaeological libraries and three specialized archaeological laboratories, and is the venue of several hundred specialized lectures, conferences and seminars, as well as dozens of archaeological exhibitions, each year. At any given time, hundreds of international scholars and researchers in all disciplines of archaeology are to be found in the city.

Athens incorporates architectural styles ranging from Greco-Roman and Neoclassical to modern times. They are often to be found in the same areas, as Athens is not marked by a uniformity of architectural style. A visitor will quickly notice the absence of tall buildings: Athens has very strict height restriction laws in order to ensure the Acropolis hill is visible throughout the city.

For the greatest part of the 19th century Neoclassicism dominated Athens, as well as some deviations from it such as Eclecticism, especially in the early 20th century. Thus, the Old Royal Palace was the first important public building to be built, between 1836 and 1843. Later in the mid and late 19th century, Theophil Freiherr von Hansen and Ernst Ziller took part in the construction of many neoclassical buildings such as the Athens Academy and the Zappeion Hall. Ziller also designed many private mansions in the centre of Athens which gradually became public, usually through donations, such as Schliemann's Iliou Melathron.

Beginning in the 1920s, Modern architecture including Bauhaus and Art Deco began to exert an influence on almost all Greek architects, and buildings both public and private were constructed in accordance with these styles. Localities with a great number of such buildings include Kolonaki, and some areas of the centre of the city; neighbourhoods developed in this period include Kypseli.

In the 1950s and 1960s during the extension and development of Athens, other modern movements such as the International style played an important role. The centre of Athens was largely rebuilt, leading to the demolition of a number of neoclassical buildings. The architects of this era employed materials such as glass, marble and aluminium, and many blended modern and classical elements. After World War II, internationally known architects to have designed and built in the city included Walter Gropius, with his design for the US Embassy, and, among others, Eero Saarinen, in his postwar design for the east terminal of the Ellinikon Airport.

All over the city can be found several statues or busts. Apart from the neoclassicals by Leonidas Drosis at the Academy of Athens (Plato, Socrates, Apollo, Athena), other notable include the statue of Theseus by Georgios Fytalis at Thiseion, of philhellenes like Lord Byron, George Canning and William Gladstone, the equestrian statue of Theodoros Kolokotronis by Lazaros Sochos in front of the Old Parliament, statues of Ioannis Kapodistrias, Rigas Feraios and Adamantios Korais at the University, of Evangelos Zappas and Konstantinos Zappas at Zappeion, of Ioannis Varvakis at the National Garden, the "woodbreaker" by Dimitrios Filippotis, the equestrian statue of Alexandros Papagos at Papagou district and various busts of fighters of Greek independence at the Pedion tou Areos. An important landmark is also the Tomb of the Unknown Soldier in Syntagma.

Athens' most important museums include:

Athens has been a destination for travellers since antiquity. Over the past decade, the city's infrastructure and social amenities have improved, in part because of its successful bid to stage the 2004 Olympic Games. The Greek Government, aided by the EU, has funded major infrastructure projects such as the state-of-the-art Eleftherios Venizelos International Airport, the expansion of the Athens Metro system, and the new Attiki Odos Motorway.

Athens was voted as the third best European city to visit in 2015 by European Best Destination. More than 240,000 people voted.

Athens is home to 148 theatrical stages, more than any other city in the world, including the ancient Odeon of Herodes Atticus, home to the Athens Festival, which runs from May to October each year. In addition to a large number of multiplexes, Athens plays host to open air garden cinemas. The city also supports music venues, including the Athens Concert Hall ("Megaron Moussikis"), which attracts world class artists. The Athens Planetarium, located in Andrea Syngrou Avenue, is one of the largest and best equipped digital planetaria in the world. The Stavros Niarchos Foundation Cultural Center, inaugurated in 2016, will house the National Library of Greece and the Greek National Opera.

The most successful songs during the period 1870–1930 were the so-called Athenian serenades (Αθηναϊκές καντάδες), based on the Heptanesean kantádhes (καντάδες 'serenades'; sing.: καντάδα) and the songs performed on stage (επιθεωρησιακά τραγούδια 'theatrical revue songs') in revues, musical comedies, operettas and nocturnes that were dominating Athens' theatre scene.

Notable composers of operettas or nocturnes were Kostas Giannidis, Dionysios Lavrangas, Nikos Hatziapostolou, while Theophrastos Sakellaridis' "The Godson" remains probably the most popular operetta. Despite the fact that the Athenian songs were not autonomous artistic creations (in contrast with the serenades) and despite their original connection with mainly dramatic forms of Art, they eventually became hits as independent songs. Notable actors of Greek operettas, who made also a series of melodies and songs popular at that time, include Orestis Makris, Kalouta sisters, Vasilis Avlonitis, Afroditi Laoutari, Eleni Papadaki, Marika Nezer, Marika Krevata and others. After 1930, wavering among American and European musical influences as well as the Greek musical tradition. Greek composers begin to write music using the tunes of the tango, waltz, swing, foxtrot, some times combined with melodies in the style of Athenian serenades' repertory. Nikos Gounaris was probably the most renowned composer and singer of the time.

In 1923, after the population exchange between Greece and Turkey, many ethnic Greeks from Asia Minor fled to Athens as a result of the Greco-Turkish War. They settled in poor neighborhoods and brought with them Rebetiko music, making it popular also in Greece, which became later the base for the Laïko music. Other forms of song popular today in Greece are elafrolaika, entechno, dimotika, and skyladika. Greece's most notable, and internationally famous, composers of Greek song, mainly of the entechno form, are Manos Hadjidakis and Mikis Theodorakis. Both composers have achieved fame abroad for their composition of film scores.

Athens has a long tradition in sports and sporting events, serving as home to the most important clubs in Greek sport and housing a large number of sports facilities. The city has also been host to sports events of international importance.

Athens has hosted the Summer Olympic Games twice, in 1896 and 2004. The 2004 Summer Olympics required the development of the Athens Olympic Stadium, which has since gained a reputation as one of the most beautiful stadiums in the world, and one of its most interesting modern monuments. The biggest stadium in the country, it hosted two finals of the UEFA Champions League, in 1994 and 2007. Athens' other major stadium, located in the Piraeus area, is the Karaiskakis Stadium, a sports and entertainment complex, host of the 1971 UEFA Cup Winners' Cup Final.

Athens has hosted the EuroLeague final three times, the first in 1985 and second in 1993, both at the Peace and Friendship Stadium, most known as SEF, a large indoor arena, and the third time in 2007 at the Olympic Indoor Hall. Events in other sports such as athletics, volleyball, water polo etc., have been hosted in the capital's venues.

Athens is home to three European multi-sport clubs: Olympiacos, Panathinaikos, AEK Athens. In football, Olympiacos have dominated the domestic competitions, Panathinaikos made it to the 1971 European Cup Final, while AEK Athens is the other member of the big three. These clubs also have basketball teams; Panathinaikos and Olympiacos are among the top powers in European basketball, having won the Euroleague six times and three respectively, whilst AEK Athens was the first Greek team to win a European trophy in any team sport.

Other notable clubs within Athens are Athinaikos, Panionios, Atromitos, Apollon, Panellinios, Ethnikos Piraeus, Maroussi BCE and Peristeri B.C.. Athenian clubs have also had domestic and international success in other sports.

The Athens area encompasses a variety of terrain, notably hills and mountains rising around the city, and the capital is the only major city in Europe to be bisected by a mountain range. Four mountain ranges extend into city boundaries and thousands of miles of trails criss-cross the city and neighbouring areas, providing exercise and wilderness access on foot and bike.

Beyond Athens and across the prefecture of Attica, outdoor activities include skiing, rock climbing, hang gliding and windsurfing. Numerous outdoor clubs serve these sports, including the Athens Chapter of the Sierra Club, which leads over 4,000 outings annually in the area.

Beside the above clubs, inside the boundaries of Athens municipality there are some more clubs with presence in national divisions or notable action for short periods. Some of them are PAO Rouf (Rouf) with earlier presence in Gamma Ethniki, Petralona F.C.() (Petralona), football club founded in 1963, with earlier presence in Beta Ethniki, Attikos F.C.() (Kolonos), football club founded in 1919 with short presence in Gamma Ethniki, (Kypseli), football club founded in 1938 with short presence in Gamma Ethniki, Gyziakos (Gyzi), basketball club founded in 1937 with short presence in Beta Ethniki basketball and Aetos B.C.() (Agios Panteleimonas), basketball club founded in 1992 with earlier presence in A2 Ethniki Basketball. Another important Athenian sport club is the Athens Tennis Club founded in 1895 with important offer for the Greek tennis.

1896 brought forth the revival of the modern Olympic Games, by Frenchman Pierre de Coubertin. Thanks to his efforts, Athens was awarded the first modern Olympic Games. In 1896, the city had a population of 123,000 and the event helped boost the city's international profile. Of the venues used for these Olympics, the Kallimarmaro Stadium, and Zappeion were most crucial. The Kallimarmaro is a replica of the ancient Athenian stadiums, and the only major stadium (in its capacity of 60,000) to be made entirely of white marble from Mount Penteli, the same material used for construction of the Parthenon.

The 1906 Summer Olympics, or the 1906 Intercalated games, were held in Athens. The intercalated competitions were intermediate games to the internationally organized Olympics, and were meant to be organized in Greece every four years, between the main Olympics. This idea later lost support from the IOC and these games were discontinued.

Athens was awarded the 2004 Summer Olympics on 5 September 1997 in Lausanne, Switzerland, after having lost a previous bid to host the 1996 Summer Olympics, to Atlanta, United States. It was to be the second time Athens would host the games, following the inaugural event of 1896. After an unsuccessful bid in 1990, the 1997 bid was radically improved, including an appeal to Greece's Olympic history. In the last round of voting, Athens defeated Rome with 66 votes to 41. Prior to this round, the cities of Buenos Aires, Stockholm and Cape Town had been eliminated from competition, having received fewer votes.

During the first three years of preparations, the International Olympic Committee had expressed concern over the speed of construction progress for some of the new Olympic venues. In 2000 the Organising Committee's president was replaced by Gianna Angelopoulos-Daskalaki, who was the president of the original Bidding Committee in 1997. From that point forward, preparations continued at a highly accelerated, almost frenzied pace.

Although the heavy cost was criticized, estimated at $1.5 billion, Athens was transformed into a more functional city that enjoys modern technology both in transportation and in modern urban development. Some of the finest sporting venues in the world were created in the city, all of which were fully ready for the games. The games welcomed over 10,000 athletes from all 202 countries.

The 2004 Games were judged a success, as both security and organization worked well, and only a few visitors reported minor problems mainly concerning accommodation issues. The 2004 Olympic Games were described as "Unforgettable, dream Games", by IOC President Jacques Rogge for their return to the birthplace of the Olympics, and for meeting the challenges of holding the Olympic Games. The only observable problem was a somewhat sparse attendance of some early events. Eventually, however, a total of more than 3.5 million tickets were sold, which was higher than any other Olympics with the exception of Sydney (more than 5 million tickets were sold there in 2000).

In 2008 it was reported that most of the Olympic venues had fallen into disrepair: according to those reports, 21 of the 22 facilities built for the games had either been left abandoned or are in a state of dereliction, with several squatter camps having sprung up around certain facilities, and a number of venues afflicted by vandalism, graffiti or strewn with rubbish. These claims, however, are disputed and likely to be inaccurate, as most of the facilities used for the Athens Olympics are either in use or in the process of being converted for post-Olympics use. The Greek Government has created a corporation, Olympic Properties SA, which is overseeing the post-Olympics management, development and conversion of these facilities, some of which will be sold off (or have already been sold off) to the private sector, while other facilities are still in use just as during the Olympics, or have been converted for commercial use or modified for other sports. Concerts and theatrical shows, such as those by the troupe Cirque du Soleil, have recently been held in the complex.







</doc>
