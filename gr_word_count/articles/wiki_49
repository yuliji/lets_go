<doc id="6446" url="https://en.wikipedia.org/wiki?curid=6446" title="Camouflage">
Camouflage

Camouflage is the use of any combination of materials, coloration, or illumination for concealment, either by making animals or objects hard to see (crypsis), or by disguising them as something else (mimesis). Examples include the leopard's spotted coat, the battledress of a modern soldier, and the leaf-mimic katydid's wings. A third approach, motion dazzle, confuses the observer with a conspicuous pattern, making the object visible but momentarily harder to locate. The majority of camouflage methods aim for crypsis, often through a general resemblance to the background, high contrast disruptive coloration, eliminating shadow, and countershading. In the open ocean, where there is no background, the principal methods of camouflage are transparency, silvering, and countershading, while the ability to produce light is among other things used for counter-illumination on the undersides of cephalopods such as squid. Some animals, such as chameleons and octopuses, are capable of actively changing their skin pattern and colours, whether for camouflage or for signalling. It is possible that some plants use camouflage to evade being eaten by herbivores.

Military camouflage was spurred by the increasing range and accuracy of firearms in the 19th century. In particular the replacement of the inaccurate musket with the rifle made personal concealment in battle a survival skill. In the 20th century, military camouflage developed rapidly, especially during the First World War. On land, artists such as André Mare designed camouflage schemes and observation posts disguised as trees. At sea, merchant ships and troop carriers were painted in dazzle patterns that were highly visible, but designed to confuse enemy submarines as to the target's speed, range, and heading. During and after the Second World War, a variety of camouflage schemes were used for aircraft and for ground vehicles in different theatres of war. The use of radar since the mid-20th century has largely made camouflage for fixed-wing military aircraft obsolete.

Non-military use of camouflage includes making cell telephone towers less obtrusive and helping hunters to approach wary game animals. Patterns derived from military camouflage are frequently used in fashion clothing, exploiting their strong designs and sometimes their symbolism. Camouflage themes recur in modern art, and both figuratively and literally in science fiction and works of literature.

In ancient Greece, Aristotle (384–322 BC) commented on the colour-changing abilities, both for camouflage and for signalling, of cephalopods including the octopus, in his "Historia animalium":

Camouflage has been a topic of interest and research in zoology for well over a century. According to Charles Darwin's 1859 theory of natural selection, features such as camouflage evolved by providing individual animals with a reproductive advantage, enabling them to leave more offspring, on average, than other members of the same species. In his "Origin of Species", Darwin wrote:

The English zoologist Edward Bagnall Poulton studied animal coloration, especially camouflage. In his 1890 book "The Colours of Animals", he classified different types such as "special protective resemblance" (where an animal looks like another object), or "general aggressive resemblance" (where a predator blends in with the background, enabling it to approach prey). His experiments showed that swallowtailed moth pupae were camouflaged to match the backgrounds on which they were reared as larvae. Poulton's "general protective resemblance" was at that time considered to be the main method of camouflage, as when Frank Evers Beddard wrote in 1892 that "tree-frequenting animals are often green in colour. Among vertebrates numerous species of parrots, iguanas, tree-frogs, and the green tree-snake are examples". Beddard did however briefly mention other methods, including the "alluring coloration" of the flower mantis and the possibility of a different mechanism in the orange tip butterfly. He wrote that "the scattered green spots upon the under surface of the wings might have been intended for a rough sketch of the small flowerets of the plant [an umbellifer], so close is their mutual resemblance." He also explained the coloration of sea fish such as the mackerel: "Among pelagic fish it is common to find the upper surface dark-coloured and the lower surface white, so that the animal is inconspicuous when seen either from above or below."

The artist Abbott Handerson Thayer formulated what is sometimes called Thayer's Law, the principle of countershading. However, he overstated the case in the 1909 book "Concealing-Coloration in the Animal Kingdom", arguing that "All patterns and colors whatsoever of all animals that ever preyed or are preyed on are under certain normal circumstances obliterative" (that is, cryptic camouflage), and that "Not one 'mimicry' mark, not one 'warning color'... nor any 'sexually selected' color, exists anywhere in the world where there is not every reason to believe it the very best conceivable device for the concealment of its wearer", and using paintings such as "Peacock in the Woods" (1907) to reinforce his argument. Thayer was roundly mocked for these views by critics including Teddy Roosevelt.

The English zoologist Hugh Cott's 1940 book "Adaptive Coloration in Animals" corrected Thayer's errors, sometimes sharply: "Thus we find Thayer straining the theory to a fantastic extreme in an endeavour to make it cover almost every type of coloration in the animal kingdom." Cott built on Thayer's discoveries, developing a comprehensive view of camouflage based on "maximum disruptive contrast", countershading and hundreds of examples. The book explained how disruptive camouflage worked, using streaks of boldly contrasting colour, paradoxically making objects less visible by breaking up their outlines. While Cott was more systematic and balanced in his view than Thayer, and did include some experimental evidence on the effectiveness of camouflage, his 500-page textbook was, like Thayer's, mainly a natural history narrative which illustrated theories with examples.

Camouflage is a soft-tissue feature that is rarely preserved in the fossil record, but rare fossilised skin samples from the Cretaceous period show that some marine reptiles were countershaded. The skins, pigmented with dark-coloured eumelanin, reveal that both leatherback turtles and mosasaurs had dark backs and light bellies.

Experimental evidence that camouflage helps prey avoid being detected by predators was first provided in 2016, when ground-nesting birds (plovers and coursers) were shown to survive according to how well their egg contrast matched the local environment.

Camouflage can be achieved by different methods, described below. Most of the methods contribute to crypsis, helping to hide against a background; but mimesis and motion dazzle protect without hiding. Methods may be applied on their own or in combination.

Crypsis means making the animal or military equipment hard to see (or to detect in other ways, such as by sound or scent). Visual crypsis can be achieved in many different ways, such as by living underground or by being active only at night, as well as by a variety of methods of camouflage.

Some animals' colours and patterns resemble a particular natural background. This is an important component of camouflage in all environments. For instance, tree-dwelling parakeets are mainly green; woodcocks of the forest floor are brown and speckled; reedbed bitterns are streaked brown and buff; in each case the animal's coloration matches the hues of its habitat. Similarly, desert animals are almost all desert coloured in tones of sand, buff, ochre, and brownish grey, whether they are mammals like the gerbil or fennec fox, birds such as the desert lark or sandgrouse, or reptiles like the skink or horned viper.Military uniforms, too, generally resemble their backgrounds; for example khaki uniforms are a muddy or dusty colour, originally chosen for service in South Asia.Many moths show industrial melanism, including the peppered moth which has coloration that blends in with tree bark. The coloration of these insects evolved between 1860 and 1940 to match the changing colour of the tree trunks on which they rest, from pale and mottled to almost black in polluted areas. This is taken by zoologists as evidence that camouflage is influenced by natural selection, as well as demonstrating that it changes where necessary to resemble the local background.

Disruptive patterns use strongly contrasting, non-repeating markings such as spots or stripes to break up the outlines of an animal or military vehicle, or to conceal telltale features, especially by masking the eyes, as in the common frog. Disruptive patterns may use more than one method to defeat visual systems such as edge detection. Predators like the leopard use disruptive camouflage to help them approach prey, while potential prey like the Egyptian nightjar use it to avoid detection by predators. Disruptive patterning is common in military usage, both for uniforms and for military vehicles. Disruptive patterning, however, does not always achieve crypsis on its own, as an animal or a military target may be given away by factors like shape, shine, and shadow.

The presence of bold skin markings does not in itself prove that an animal relies on camouflage, as that depends on its behaviour. For example, although giraffes have a high contrast pattern that could be disruptive coloration, the adults are very conspicuous when in the open. Some authors have argued that adult giraffes are cryptic, since when standing among trees and bushes they are hard to see at even a few metres distance. However, adult giraffes move about to gain the best view of an approaching predator, relying on their size and ability to defend themselves, even from lions, rather than on camouflage. A different explanation is implied by young giraffes being far more vulnerable to predation than adults: more than half of all giraffe calves die within a year, and giraffe mothers hide their calves, which spend much of the time lying down in cover while their mothers are away feeding. Since the presence of a mother nearby does not affect survival, it is argued that young giraffes must be very well camouflaged; this is supported by coat markings being strongly inherited.

The possibility of camouflage in plants has been little studied until the late 20th century. Leaf variegation with white spots may serve as camouflage in forest understory plants, where there is a dappled background; leaf mottling is correlated with closed habitats. Disruptive camouflage would have a clear evolutionary advantage in plants: they would tend to escape from being eaten by herbivores. Another possibility is that some plants have leaves differently coloured on upper and lower surfaces or on parts such as veins and stalks to make green-camouflaged insects conspicuous, and thus benefit the plants by favouring the removal of herbivores by carnivores. These hypotheses are testable.

Some animals, such as the horned lizards of North America, have evolved elaborate measures to eliminate shadow. Their bodies are flattened, with the sides thinning to an edge; the animals habitually press their bodies to the ground; and their sides are fringed with white scales which effectively hide and disrupt any remaining areas of shadow there may be under the edge of the body. The theory that the body shape of the horned lizards which live in open desert is adapted to minimise shadow is supported by the one species which lacks fringe scales, the roundtail horned lizard, which lives in rocky areas and resembles a rock. When this species is threatened, it makes itself look as much like a rock as possible by curving its back, emphasizing its three-dimensional shape. Some species of butterflies, such as the speckled wood, "Pararge aegeria", minimise their shadows when perched by closing the wings over their backs, aligning their bodies with the sun, and tilting to one side towards the sun, so that the shadow becomes a thin inconspicuous line rather than a broad patch. Similarly, some ground-nesting birds including the European nightjar select a resting position facing the sun. Eliminating shadow was identified as a principle of military camouflage during the Second World War.

Many prey animals have conspicuous high-contrast markings which paradoxically attract the predator's gaze. These distractive markings serve as camouflage by distracting the predator's attention from recognising the prey as a whole, for example by keeping the predator from identifying the prey's outline. Experimentally, search times for blue tits increased when artificial prey had distractive markings.

Some animals actively seek to hide by decorating themselves with materials such as twigs, sand, or pieces of shell from their environment, to break up their outlines, to conceal the features of their bodies, and to match their backgrounds. For example, a caddis fly larva builds a decorated case and lives almost entirely inside it; a decorator crab covers its back with seaweed, sponges and stones. The nymph of the predatory masked bug uses its hind legs and a 'tarsal fan' to decorate its body with sand or dust. There are two layers of bristles (trichomes) over the body. On these, the nymph spreads an inner layer of fine particles and an outer layer of coarser particles. The camouflage may conceal the bug from both predators and prey.

Similar principles can be applied for military purposes, for instance when a sniper wears a ghillie suit designed to be further camouflaged by decoration with materials such as tufts of grass from the sniper's immediate environment. Such suits were used as early as 1916, the British army having adopted "coats of motley hue and stripes of paint" for snipers. Cott takes the example of the larva of the blotched emerald moth, which fixes a screen of fragments of leaves to its specially hooked bristles, to argue that military camouflage uses the same method, pointing out that the "device is ... essentially the same as one widely practised during the Great War for the concealment, not of caterpillars, but of caterpillar-tractors, [gun] battery positions, observation posts and so forth."

Movement catches the eye of prey animals on the lookout for predators, and of predators hunting for prey. Most methods of crypsis therefore also require suitable cryptic behaviour, such as lying down and keeping still to avoid being detected, or in the case of stalking predators such as the tiger, moving with extreme stealth, both slowly and quietly, watching its prey for any sign they are aware of its presence. As an example of the combination of behaviours and other methods of crypsis involved, young giraffes seek cover, lie down, and keep still, often for hours until their mothers return; their skin pattern blends with the pattern of the vegetation, while the chosen cover and lying position together hide the animals' shadows. The flat-tail horned lizard similarly relies on a combination of methods: it is adapted to lie flat in the open desert, relying on stillness, its cryptic coloration, and concealment of its shadow to avoid being noticed by predators. In the ocean, the leafy sea dragon sways mimetically, like the seaweeds amongst which it rests, as if rippled by wind or water currents. Swaying is seen also in some insects, like Macleay's Spectre stick insect, "Extatosoma tiaratum". The behaviour may be motion crypsis, preventing detection, or motion masquerade, promoting misclassification (as something other than prey), or a combination of the two.

Most forms of camouflage are ineffective when the camouflaged animal or object moves, because the motion is easily seen by the observing predator, prey or enemy. However, insects such as hoverflies and dragonflies use motion camouflage: the hoverflies to approach possible mates, and the dragonflies to approach rivals when defending territories. Motion camouflage is achieved by moving so as to stay on a straight line between the target and a fixed point in the landscape; the pursuer thus appears not to move, but only to loom larger in the target's field of vision. The same method can be used for military purposes, for example by missiles to minimise their risk of detection by an enemy. However, missile engineers, and animals such as bats, use the method mainly for its efficiency rather than camouflage.

Animals such as chameleon, frog, flatfish such as the peacock flounder, squid and octopus actively change their skin patterns and colours using special chromatophore cells to resemble their current background, or, as in most chameleons, for signalling. However, Smith's dwarf chameleon does use active colour change for camouflage.
Each chromatophore contains pigment of only one colour. In fish and frogs, colour change is mediated by the type of chromatophores known as melanophores that contain dark pigment. A melanophore is star-shaped; it contains many small pigmented organelles which can be dispersed throughout the cell, or aggregated near its centre. When the pigmented organelles are dispersed, the cell makes a patch of the animal's skin appear dark; when they are aggregated, most of the cell, and the animal's skin, appears light. In frogs, the change is controlled relatively slowly, mainly by hormones. In fish, the change is controlled by the brain, which sends signals directly to the chromatophores, as well as producing hormones.

The skins of cephalopods such as the octopus contain complex units, each consisting of a chromatophore with surrounding muscle and nerve cells. The cephalopod chromatophore has all its pigment grains in a small elastic sac, which can be stretched or allowed to relax under the control of the brain to vary its opacity. By controlling chromatophores of different colours, cephalopods can rapidly change their skin patterns and colours.

On a longer timescale, animals like the Arctic hare, Arctic fox, stoat, and rock ptarmigan have snow camouflage, changing their coat colour (by moulting and growing new fur or feathers) from brown or grey in the summer to white in the winter; the Arctic fox is the only species in the dog family to do so. However, Arctic hares which live in the far north of Canada, where summer is very short, remain white year-round.

The principle of varying coloration either rapidly or with the changing seasons has military applications. "Active camouflage" could in theory make use of both dynamic colour change and counterillumination. Simple methods such as changing uniforms and repainting vehicles for winter have been in use since World War II. In 2011, BAE Systems announced their Adaptiv infrared camouflage technology. It uses about 1000 hexagonal panels to cover the sides of a tank. The Peltier plate panels are heated and cooled to match either the vehicle's surroundings (crypsis), or an object such as a car (mimesis), when viewed in infrared.

Countershading uses graded colour to counteract the effect of self-shadowing, creating an illusion of flatness. Self-shadowing makes an animal appear darker below than on top, grading from light to dark; countershading 'paints in' tones which are darkest on top, lightest below, making the countershaded animal nearly invisible against a suitable background. Thayer observed that "Animals are painted by Nature, darkest on those parts which tend to be most lighted by the sky's light, and "vice versa"". Accordingly, the principle of countershading is sometimes called "Thayer's Law". Countershading is widely used by terrestrial animals, such as gazelles and grasshoppers; marine animals, such as sharks and dolphins; and birds, such as snipe and dunlin.

Countershading is less often used for military camouflage, despite Second World War experiments that showed its effectiveness. English zoologist Hugh Cott encouraged the use of methods including countershading, but despite his authority on the subject, failed to persuade the British authorities. Soldiers often wrongly viewed camouflage netting as a kind of invisibility cloak, and they had to be taught to look at camouflage practically, from an enemy observer's viewpoint. At the same time in Australia, zoologist William John Dakin advised soldiers to copy animals' methods, using their instincts for wartime camouflage.

The term countershading has a second meaning unrelated to "Thayer's Law". It is that the upper and undersides of animals such as sharks, and of some military aircraft, are different colours to match the different backgrounds when seen from above or from below. Here the camouflage consists of two surfaces, each with the simple function of providing concealment against a specific background, such as a bright water surface or the sky. The body of a shark or the fuselage of an aircraft is not gradated from light to dark to appear flat when seen from the side. The camouflage methods used are the matching of background colour and pattern, and disruption of outlines.

Counter-illumination means producing light to match a background that is brighter than an animal's body or military vehicle; it is a form of active camouflage. It is notably used by some species of squid, such as the firefly squid and the midwater squid. The latter has light-producing organs (photophores) scattered all over its underside; these create a sparkling glow that prevents the animal from appearing as a dark shape when seen from below. Counterillumination camouflage is the likely function of the bioluminescence of many marine organisms, though light is also produced to attract or to detect prey and for signalling.

Counterillumination has rarely been used for military purposes. "Diffused lighting camouflage" was trialled by Canada's National Research Council during the Second World War. It involved projecting light on to the sides of ships to match the faint glow of the night sky, requiring awkward external platforms to support the lamps. The Canadian concept was refined in the American Yehudi lights project, and trialled in aircraft including B-24 Liberators and naval Avengers. The planes were fitted with forward-pointing lamps automatically adjusted to match the brightness of the night sky. This enabled them to approach much closer to a target – within 3,000 yards (2,700 metres) – before being seen. Counterillumination was made obsolete by radar, and neither diffused lighting camouflage nor Yehudi lights entered active service.

Many marine animals that float near the surface are highly transparent, giving them almost perfect camouflage. However, transparency is difficult for bodies made of materials that have different refractive indices from seawater. Some marine animals such as jellyfish have gelatinous bodies, composed mainly of water; their thick mesogloea is acellular and highly transparent. This conveniently makes them buoyant, but it also makes them large for their muscle mass, so they cannot swim fast, making this form of camouflage a costly trade-off with mobility. Gelatinous planktonic animals are between 50 and 90 percent transparent. A transparency of 50 percent is enough to make an animal invisible to a predator such as cod at a depth of ; better transparency is required for invisibility in shallower water, where the light is brighter and predators can see better. For example, a cod can see prey that are 98 percent transparent in optimal lighting in shallow water. Therefore, sufficient transparency for camouflage is more easily achieved in deeper waters.
Some tissues such as muscles can be made transparent, provided either they are very thin or organised as regular layers or fibrils that are small compared to the wavelength of visible light. A familiar example is the transparency of the lens of the vertebrate eye, which is made of the protein crystallin, and the vertebrate cornea which is made of the protein collagen. Other structures cannot be made transparent, notably the retinas or equivalent light-absorbing structures of eyes – they must absorb light to be able to function. The camera-type eye of vertebrates and cephalopods must be completely opaque. Finally, some structures are visible for a reason, such as to lure prey. For example, the nematocysts (stinging cells) of the transparent siphonophore "Agalma okenii" resemble small copepods. Examples of transparent marine animals include a wide variety of larvae, including radiata (coelenterates), siphonophores, salps (floating tunicates), gastropod molluscs, polychaete worms, many shrimplike crustaceans, and fish; whereas the adults of most of these are opaque and pigmented, resembling the seabed or shores where they live. Adult comb jellies and jellyfish obey the rule, often being mainly transparent. Cott suggests this follows the more general rule that animals resemble their background: in a transparent medium like seawater, that means being transparent. The small Amazon river fish "Microphilypnus amazonicus" and the shrimps it associates with, "Pseudopalaemon gouldingi", are so transparent as to be "almost invisible"; further, these species appear to select whether to be transparent or more conventionally mottled (disruptively patterned) according to the local background in the environment.

Where transparency cannot be achieved, it can be imitated effectively by silvering to make an animal's body highly reflective. At medium depths at sea, light comes from above, so a mirror oriented vertically makes animals such as fish invisible from the side. Most fish in the upper ocean such as sardine and herring are camouflaged by silvering.

The marine hatchetfish is extremely flattened laterally, leaving the body just millimetres thick, and the body is so silvery as to resemble aluminium foil. The mirrors consist of microscopic structures similar to those used to provide structural coloration: stacks of between 5 and 10 crystals of guanine spaced about ¼ of a wavelength apart to interfere constructively and achieve nearly 100 per cent reflection. In the deep waters that the hatchetfish lives in, only blue light with a wavelength of 500 nanometres percolates down and needs to be reflected, so mirrors 125 nanometres apart provide good camouflage.

In fish such as the herring which live in shallower water, the mirrors must reflect a mixture of wavelengths, and the fish accordingly has crystal stacks with a range of different spacings. A further complication for fish with bodies that are rounded in cross-section is that the mirrors would be ineffective if laid flat on the skin, as they would fail to reflect horizontally. The overall mirror effect is achieved with many small reflectors, all oriented vertically. Silvering is found in other marine animals as well as fish. The cephalopods, including squid, octopus and cuttlefish, have multi-layer mirrors made of protein rather than guanine.

In mimesis (also called "masquerade"), the camouflaged object looks like something else which is of no special interest to the observer. Mimesis is common in prey animals, for example when a peppered moth caterpillar mimics a twig, or a grasshopper mimics a dry leaf. It is also found in nest structures; some eusocial wasps, such as "Leipomeles dorsata", build a nest envelope in patterns that mimic the leaves surrounding the nest.

Mimesis is also employed by some predators and parasites to lure their prey. For example, a flower mantis mimics a particular kind of flower, such as an orchid. This tactic has occasionally been used in warfare, for example with heavily armed Q-ships disguised as merchant ships.

The common cuckoo, a brood parasite, provides examples of mimesis both in the adult and in the egg. The female lays her eggs in nests of other, smaller species of bird, one per nest. The female mimics a sparrowhawk. The resemblance is sufficient to make small birds take action to avoid the apparent predator. The female cuckoo then has time to lay her egg in their nest without being seen to do so. The cuckoo's egg itself mimics the eggs of the host species, reducing its chance of being rejected.

Most forms of camouflage are made ineffective by movement: a deer or grasshopper may be highly cryptic when motionless, but instantly seen when it moves. But one method, motion dazzle, requires rapidly moving bold patterns of contrasting stripes. Motion dazzle may degrade predators' ability to estimate the prey's speed and direction accurately, giving the prey an improved chance of escape. Motion dazzle distorts speed perception and is most effective at high speeds; stripes can also distort perception of size (and so, perceived range to the target). As of 2011, motion dazzle had been proposed for military vehicles, but never applied. Since motion dazzle patterns would make animals more difficult to locate accurately when moving, but easier to see when stationary, there would be an evolutionary trade-off between motion dazzle and crypsis.

An animal that is commonly thought to be dazzle-patterned is the zebra. The bold stripes of the zebra have been claimed to be disruptive camouflage, background-blending and countershading. After many years in which the purpose of the coloration was disputed, an experimental study by Tim Caro suggested in 2012 that the pattern reduces the attractiveness of stationary models to biting flies such as horseflies and tsetse flies. However, a simulation study by Martin How and Johannes Zanker in 2014 suggests that when moving, the stripes may confuse observers, such as mammalian predators and biting insects, by two visual illusions: the wagon-wheel effect, where the perceived motion is inverted, and the barberpole illusion, where the perceived motion is in a wrong direction.

Ship camouflage was occasionally used in ancient times. Philostratus (c. 172–250 AD) wrote in his "Imagines" that Mediterranean pirate ships could be painted blue-gray for concealment. Vegetius () says that "Venetian blue" (sea green) was used in the Gallic Wars, when Julius Caesar sent his "speculatoria navigia" (reconnaissance boats) to gather intelligence along the coast of Britain; the ships were painted entirely in bluish-green wax, with sails, ropes and crew the same colour. There is little evidence of military use of camouflage on land before 1800, but two unusual ceramics show men in Peru's Mochica culture from before 500 AD, hunting birds with blowpipes which are fitted with a kind of shield near the mouth, perhaps to conceal the hunters' hands and faces. Another early source is a 15th-century French manuscript, "The Hunting Book of Gaston Phebus", showing a horse pulling a cart which contains a hunter armed with a crossbow under a cover of branches, perhaps serving as a hide for shooting game. Jamaican Maroons are said to have used plant materials as camouflage in the First Maroon War ().

The development of military camouflage was driven by the increasing range and accuracy of infantry firearms in the 19th century. In particular the replacement of the inaccurate musket with weapons such as the Baker rifle made personal concealment in battle essential. Two Napoleonic War skirmishing units of the British Army, the 95th Rifle Regiment and the 60th Rifle Regiment, were the first to adopt camouflage in the form of a rifle green jacket, while the Line regiments continued to wear scarlet tunics. A contemporary study in 1800 by the English artist and soldier Charles Hamilton Smith provided evidence that grey uniforms were less visible than green ones at a range of 150 yards.

In the American Civil War, rifle units such as the 1st United States Sharp Shooters (in the Federal army) similarly wore green jackets while other units wore more conspicuous colours. The first British Army unit to adopt khaki uniforms was the Corps of Guides at Peshawar, when Sir Harry Lumsden and his second in command, William Hodson introduced a "drab" uniform in 1848. Hodson wrote that it would be more appropriate for the hot climate, and help make his troops "invisible in a land of dust". Later they improvised by dyeing cloth locally. Other regiments in India soon adopted the khaki uniform, and by 1896 khaki drill uniform was used everywhere outside Europe; by the Second Boer War six years later it was used throughout the British Army.

During the late 19th century camouflage was applied to British coastal fortifications. The fortifications around Plymouth, England were painted in the late 1880s in 'irregular patches of red, brown, yellow and green'. From 1891 onwards British coastal artillery was permitted to be painted in suitable colours 'to harmonise with the surroundings' and by 1904 it was standard practice that artillery and mountings should be painted with 'large irregular patches of different colours selected to suit local conditions'.

In the First World War, the French army formed a camouflage corps, led by Lucien-Victor Guirand de Scévola, employing artists known as "camoufleurs" to create schemes such as tree observation posts and covers for guns. Other armies soon followed them. The term "camouflage" probably comes from "camoufler", a Parisian slang term meaning "to disguise", and may have been influenced by "camouflet", a French term meaning "smoke blown in someone's face". The English zoologist John Graham Kerr, artist Solomon J. Solomon and the American artist Abbott Thayer led attempts to introduce scientific principles of countershading and disruptive patterning into military camouflage, with limited success. In early 1916 the Royal Naval Air Service began to create dummy air fields to draw the attention of enemy planes to empty land. They created decoy homes and lined fake runways with flares, which were meant to help protect real towns from night raids. This strategy was not common practice and did not succeed at first, but in 1918 it caught the Germans off guard multiple times. 

Ship camouflage was introduced in the early 20th century as the range of naval guns increased, with ships painted grey all over. In April 1917, when German U-boats were sinking many British ships with torpedoes, the marine artist Norman Wilkinson devised dazzle camouflage, which paradoxically made ships more visible but harder to target. In Wilkinson's own words, dazzle was designed "not for low visibility, but in such a way as to break up her form and thus confuse a submarine officer as to the course on which she was heading".

In the Second World War, the zoologist Hugh Cott, a protégé of Kerr, worked to persuade the British army to use more effective camouflage methods, including countershading, but, like Kerr and Thayer in the First World War, with limited success. For example, he painted two rail-mounted coastal guns, one in conventional style, one countershaded. In aerial photographs, the countershaded gun was essentially invisible. The power of aerial observation and attack led every warring nation to camouflage targets of all types. The Soviet Union's Red Army created the comprehensive doctrine of "Maskirovka" for military deception, including the use of camouflage. For example, during the Battle of Kursk, General Katukov, the commander of the Soviet 1st Tank Army, remarked that the enemy "did not suspect that our well-camouflaged tanks were waiting for him. As we later learned from prisoners, we had managed to move our tanks forward unnoticed". The tanks were concealed in previously prepared defensive emplacements, with only their turrets above ground level. In the air, Second World War fighters were often painted in ground colours above and sky colours below, attempting two different camouflage schemes for observers above and below. Bombers and night fighters were often black, while maritime reconnaissance planes were usually white, to avoid appearing as dark shapes against the sky. For ships, dazzle camouflage was mainly replaced with plain grey in the Second World War, though experimentation with colour schemes continued.

As in the First World War, artists were pressed into service; for example, the surrealist painter Roland Penrose became a lecturer at the newly founded Camouflage Development and Training Centre at Farnham Castle, writing the practical "Home Guard Manual of Camouflage". The film-maker Geoffrey Barkas ran the Middle East Command Camouflage Directorate during the 1941–1942 war in the Western Desert, including the successful deception of Operation Bertram. Hugh Cott was chief instructor; the artist camouflage officers, who called themselves "camoufleurs", included Steven Sykes and Tony Ayrton. In Australia, artists were also prominent in the Sydney Camouflage Group, formed under the chairmanship of Professor William John Dakin, a zoologist from Sydney University. Max Dupain, Sydney Ure Smith, and William Dobell were among the members of the group, which worked at Bankstown Airport, RAAF Base Richmond and Garden Island Dockyard. In the United States, artists like John Vassos took a certificate course in military and industrial camouflage at the American School of Design with Baron Nicholas Cerkasoff, and went on to create camouflage for the Air Force. 

Camouflage has been used to protect military equipment such as vehicles, guns, ships, aircraft and buildings as well as individual soldiers and their positions.
Vehicle camouflage methods begin with paint, which offers at best only limited effectiveness. Other methods for stationary land vehicles include covering with improvised materials such as blankets and vegetation, and erecting nets, screens and soft covers which may suitably reflect, scatter or absorb near infrared and radar waves. Some military textiles and vehicle camouflage paints also reflect infrared to help provide concealment from night vision devices.
After the Second World War, radar made camouflage generally less effective, though coastal boats are sometimes painted like land vehicles. Aircraft camouflage too came to be seen as less important because of radar, and aircraft of different air forces, such as the Royal Air Force's Lightning, were often uncamouflaged.

Many camouflaged textile patterns have been developed to suit the need to match combat clothing to different kinds of terrain (such as woodland, snow, and desert). The design of a pattern effective in all terrains has proved elusive. The American Universal Camouflage Pattern of 2004 attempted to suit all environments, but was withdrawn after a few years of service. Terrain-specific patterns have sometimes been developed but are ineffective in other terrains. The problem of making a pattern that works at different ranges has been solved with multiscale designs, often with a pixellated appearance and designed digitally, that provide a fractal-like range of patch sizes so they appear disruptively coloured both at close range and at a distance. The first genuinely digital camouflage pattern was the Canadian Disruptive Pattern (CADPAT), issued to the army in 2002, soon followed by the American Marine pattern (MARPAT). A pixellated appearance is not essential for this effect, though it is simpler to design and to print.

Hunters of game have long made use of camouflage in the form of materials such as animal skins, mud, foliage, and green or brown clothing to enable them to approach wary game animals. Field sports such as driven grouse shooting conceal hunters in hides (also called blinds or shooting butts). Modern hunting clothing makes use of fabrics that provide a disruptive camouflage pattern; for example, in 1986 the hunter Bill Jordan created cryptic clothing for hunters, printed with images of specific kinds of vegetation such as grass and branches.

Camouflage is occasionally used to make built structures less conspicuous: for example, in South Africa, towers carrying cell telephone antennae are sometimes camouflaged as tall trees with plastic branches, in response to "resistance from the community". Since this method is costly (a figure of three times the normal cost is mentioned), alternative forms of camouflage can include using neutral colours or familiar shapes such as cylinders and flagpoles. Conspicuousness can also be reduced by siting masts near, or on, other structures.

Automotive manufacturers often use patterns to disguise upcoming products. This camouflage is designed to obfuscate the vehicle's visual lines, and is used along with padding, covers, and decals. The patterns' purpose is to prevent visual observation (and to a lesser degree photography), that would subsequently enable reproduction of the vehicle's form factors.

Military camouflage patterns influenced fashion and art from the time of the First World War onwards. Gertrude Stein recalled the cubist artist Pablo Picasso's reaction in around 1915:

In 1919, the attendants of a "dazzle ball", hosted by the Chelsea Arts Club, wore dazzle-patterned black and white clothing. The ball influenced fashion and art via postcards and magazine articles. The "Illustrated London News" announced:
More recently, fashion designers have often used camouflage fabric for its striking designs, its "patterned disorder" and its symbolism. Camouflage clothing can be worn largely for its symbolic significance rather than for fashion, as when, during the late 1960s and early 1970s in the United States, anti-war protestors often ironically wore military clothing during demonstrations against the American involvement in the Vietnam War.

Modern artists such as Ian Hamilton Finlay have used camouflage to reflect on war. His 1973 screenprint of a tank camouflaged in a leaf pattern, "Arcadia", is described by the Tate as drawing "an ironic parallel between this idea of a natural paradise and the camouflage patterns on a tank". The title refers to the Utopian Arcadia of poetry and art, and the "memento mori" Latin phrase "Et in Arcadia ego" which recurs in Hamilton Finlay's work. In science fiction, "Camouflage" is a novel about shapeshifting alien beings by Joe Haldeman. The word is used more figuratively in works of literature such as Thaisa Frank's collection of stories of love and loss, "A Brief History of Camouflage".








</doc>
<doc id="6449" url="https://en.wikipedia.org/wiki?curid=6449" title="Clock">
Clock

A clock is an instrument used to measure, keep, and indicate time. The clock is one of the oldest human inventions, meeting the need to measure intervals of time shorter than the natural units: the day, the lunar month, and the year. Devices operating on several physical processes have been used over the millennia.

Some predecessors to the modern clock may be considered as "clocks" that are based on movement in nature: A sundial shows the time by displaying the position of a shadow on a flat surface. There is a range of duration timers, a well-known example being the hourglass. Water clocks, along with the sundials, are possibly the oldest time-measuring instruments. A major advance occurred with the invention of the verge escapement, which made possible the first mechanical clocks around 1300 in Europe, which kept time with oscillating timekeepers like balance wheels.

Traditionally in horology, the term "clock" was used for a striking clock, while a clock that did not strike the hours audibly was called a timepiece. In general usage today, a "clock" refers to any device for measuring and displaying the time. Watches and other timepieces that can be carried on one's person are often distinguished from clocks.
Spring-driven clocks appeared during the 15th century. During the 15th and 16th centuries, clockmaking flourished. The next development in accuracy occurred after 1656 with the invention of the pendulum clock. A major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The electric clock was patented in 1840. The development of electronics in the 20th century led to clocks with no clockwork parts at all.

The timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates at a particular frequency.
This object can be a pendulum, a tuning fork, a quartz crystal, or the vibration of electrons in atoms as they emit microwaves.

Clocks have different ways of displaying the time. Analog clocks indicate time with a traditional clock face, with moving hands. Digital clocks display a numeric representation of time. Two numbering systems are in use; 24-hour time notation and 12-hour notation. Most digital clocks use electronic mechanisms and LCD, LED, or VFD displays. For the blind and use over telephones, speaking clocks state the time audibly in words. There are also clocks for the blind that have displays that can be read by touch. The study of timekeeping is known as horology.

The word "clock" derives from the medieval Latin word for "bell"; "clogga", and has cognates in many European languages. Clocks spread to England from the Low Countries, so the English word came from the Middle Low German and Middle Dutch "Klocke".

The apparent position of the Sun in the sky moves over the course of each day, reflecting the rotation of the Earth. Shadows cast by stationary objects move correspondingly, so their positions can be used to indicate the time of day. A sundial shows the time by displaying the position of a shadow on a (usually) flat surface, which has markings that correspond to the hours. Sundials can be horizontal, vertical, or in other orientations. Sundials were widely used in ancient times. With the knowledge of latitude, a well-constructed sundial can measure local solar time with reasonable accuracy, within a minute or two. Sundials continued to be used to monitor the performance of clocks until the modern era.

Many devices can be used to mark passage of time without respect to reference time (time of day, minutes, etc.) and can be useful for measuring duration or intervals. Examples of such duration timers are candle clocks, incense clocks and the hourglass. Both the candle clock and the incense clock work on the same principle wherein the consumption of resources is more or less constant allowing reasonably precise and repeatable estimates of time passages. In the hourglass, fine sand pouring through a tiny hole at a constant rate indicates an arbitrary, predetermined, passage of time. The resource is not consumed but re-used.

Water clocks, also known as clepsydrae (sg: "clepsydra"), along with the sundials, are possibly the oldest time-measuring instruments, with the only exceptions being the vertical gnomon and the day counting tally stick. Given their great antiquity, where and when they first existed is not known and perhaps unknowable. The bowl-shaped outflow is the simplest form of a water clock and is known to have existed in Babylon and in Egypt around the 16th century BC. Other regions of the world, including India and China, also have early evidence of water clocks, but the earliest dates are less certain. Some authors, however, write about water clocks appearing as early as 4000 BC in these regions of the world.

Greek astronomer Andronicus of Cyrrhus supervised the construction of the Tower of the Winds in Athens in the 1st century B.C. The Greek and Roman civilizations are credited for initially advancing water clock design to include complex gearing, which was connected to fanciful automata and also resulted in improved accuracy. These advances were passed on through Byzantium and Islamic times, eventually making their way back to Europe. Independently, the Chinese developed their own advanced water clocks（水鐘）in 725 AD, passing their ideas on to Korea and Japan.

Some water clock designs were developed independently and some knowledge was transferred through the spread of trade. Pre-modern societies do not have the same precise timekeeping requirements that exist in modern industrial societies, where every hour of work or rest is monitored, and work may start or finish at any time regardless of external conditions. Instead, water clocks in ancient societies were used mainly for astrological reasons. These early water clocks were calibrated with a sundial. While never reaching the level of accuracy of a modern timepiece, the water clock was the most accurate and commonly used timekeeping device for millennia, until it was replaced by the more accurate pendulum clock in 17th-century Europe.

Islamic civilization is credited with further advancing the accuracy of clocks with elaborate engineering. In 797 (or possibly 801), the Abbasid caliph of Baghdad, Harun al-Rashid, presented Charlemagne with an Asian Elephant named Abul-Abbas together with a "particularly elaborate example" of a water clock.
Pope Sylvester II introduced clocks to northern and western Europe around 1000AD

In the 13th century, Al-Jazari, an engineer from Mesopotamia (lived 1136–1206) who worked for Artuqid king of Diyar-Bakr, Nasir al-Din, made numerous clocks of all shapes and sizes. A book on his work described 50 mechanical devices in 6 categories, including water clocks. The most reputed clocks included the Elephant, Scribe and Castle clocks, all of which have been successfully reconstructed. As well as telling the time, these grand clocks were symbols of status, grandeur and wealth of the Urtuq State.

The word "horologia" (from the Greek ὥρα, hour, and λέγειν, to tell) was used to describe early mechanical clocks, but the use of this word (still used in several Romance languages) for all timekeepers conceals the true nature of the mechanisms. For example, there is a record that in 1176 Sens Cathedral installed a ‘horologe’ but the mechanism used is unknown. According to Jocelin of Brakelond, in 1198 during a fire at the abbey of St Edmundsbury (now Bury St Edmunds), the monks 'ran to the clock' to fetch water, indicating that their water clock had a reservoir large enough to help extinguish the occasional fire. The word "clock" (from the Celtic words "clocca" and "clogan", both meaning "bell"), which gradually supersedes "horologe", suggests that it was the sound of bells which also characterized the prototype mechanical clocks that appeared during the 13th century in Europe.

A water-powered cogwheel clock was created in China in AD 725 by Yi Xing and Liang Lingzan. This is not considered an escapement mechanism clock as it was unidirectional, the Song dynasty polymath and genius Su Song (1020–1101) incorporated it into his monumental innovation of the astronomical clock-tower of Kaifeng in 1088. His astronomical clock and rotating armillary sphere still relied on the use of either flowing water during the spring, summer, autumn seasons and liquid mercury during the freezing temperature of winter (i.e. hydraulics). A mercury clock, described in the "Libros del saber", a Spanish work from 1277 consisting of translations and paraphrases of Arabic works, is sometimes quoted as evidence for Muslim knowledge of a mechanical clock. A mercury-powered cogwheel clock was created by Ibn Khalaf al-Muradi.

In Europe, between 1280 and 1320, there is an increase in the number of references to clocks and horologes in church records, and this probably indicates that a new type of clock mechanism had been devised. Existing clock mechanisms that used water power were being adapted to take their driving power from falling weights. This power was controlled by some form of oscillating mechanism, probably derived from existing bell-ringing or alarm devices. This controlled release of power—the escapement—marks the beginning of the true mechanical clock, which differed from the previously mentioned cogwheel clocks. Verge escapement mechanism derived in the surge of true mechanical clocks, which didn't need any kind of fluid power, like water or mercury, to work.

These mechanical clocks were intended for two main purposes: for signalling and notification (e.g. the timing of services and public events), and for modeling the solar system. The former purpose is administrative, the latter arises naturally given the scholarly interests in astronomy, science, astrology, and how these subjects integrated with the religious philosophy of the time. The astrolabe was used both by astronomers and astrologers, and it was natural to apply a clockwork drive to the rotating plate to produce a working model of the solar system.

Simple clocks intended mainly for notification were installed in towers, and did not always require faces or hands. They would have announced the canonical hours or intervals between set times of prayer. Canonical hours varied in length as the times of sunrise and sunset shifted. The more sophisticated astronomical clocks would have had moving dials or hands, and would have shown the time in various time systems, including Italian hours, canonical hours, and time as measured by astronomers at the time. Both styles of clock started acquiring extravagant features such as automata.

In 1283, a large clock was installed at Dunstable Priory; its location above the rood screen suggests that it was not a water clock. In 1292, Canterbury Cathedral installed a 'great horloge'. Over the next 30 years there are mentions of clocks at a number of ecclesiastical institutions in England, Italy, and France. In 1322, a new clock was installed in Norwich, an expensive replacement for an earlier clock installed in 1273. This had a large (2 metre) astronomical dial with automata and bells. The costs of the installation included the full-time employment of two clockkeepers for two years.

Besides the Chinese astronomical clock of Su Song in 1088 mentioned above, in Europe there were the clocks constructed by Richard of Wallingford in St Albans by 1336, and by Giovanni de Dondi in Padua from 1348 to 1364. They no longer exist, but detailed descriptions of their design and construction survive, and modern reproductions have been made. They illustrate how quickly the theory of the mechanical clock had been translated into practical constructions, and also that one of the many impulses to their development had been the desire of astronomers to investigate celestial phenomena.

Wallingford's clock had a large astrolabe-type dial, showing the sun, the moon's age, phase, and node, a star map, and possibly the planets. In addition, it had a wheel of fortune and an indicator of the state of the tide at London Bridge. Bells rang every hour, the number of strokes indicating the time. Dondi's clock was a seven-sided construction, 1 metre high, with dials showing the time of day, including minutes, the motions of all the known planets, an automatic calendar of fixed and movable feasts, and an eclipse prediction hand rotating once every 18 years. It is not known how accurate or reliable these clocks would have been. They were probably adjusted manually every day to compensate for errors caused by wear and imprecise manufacture. Water clocks are sometimes still used today, and can be examined in places such as ancient castles and museums. The Salisbury Cathedral clock, built in 1386, is considered to be the world's oldest surviving mechanical clock that strikes the hours.

Clockmakers developed their art in various ways. Building smaller clocks was a technical challenge, as was improving accuracy and reliability. Clocks could be impressive showpieces to demonstrate skilled craftsmanship, or less expensive, mass-produced items for domestic use. The escapement in particular was an important factor affecting the clock's accuracy, so many different mechanisms were tried.

Spring-driven clocks appeared during the 15th century, although they are often erroneously credited to Nuremberg watchmaker Peter Henlein (or Henle, or Hele) around 1511. The earliest existing spring driven clock is the chamber clock given to Phillip the Good, Duke of Burgundy, around 1430, now in the Germanisches Nationalmuseum. Spring power presented clockmakers with a new problem: how to keep the clock movement running at a constant rate as the spring ran down. This resulted in the invention of the "stackfreed" and the fusee in the 15th century, and many other innovations, down to the invention of the modern "going barrel" in 1760.

Early clock dials did not indicate minutes and seconds. A clock with a dial indicating minutes was illustrated in a 1475 manuscript by Paulus Almanus, and some 15th-century clocks in Germany indicated minutes and seconds.
An early record of a seconds hand on a clock dates back to about 1560 on a clock now in the Fremersdorf collection.

During the 15th and 16th centuries, clockmaking flourished, particularly in the metalworking towns of Nuremberg and Augsburg, and in Blois, France. Some of the more basic table clocks have only one time-keeping hand, with the dial between the hour markers being divided into four equal parts making the clocks readable to the nearest 15 minutes. Other clocks were exhibitions of craftsmanship and skill, incorporating astronomical indicators and musical movements. The cross-beat escapement was invented in 1584 by Jost Bürgi, who also developed the remontoire. Bürgi's clocks were a great improvement in accuracy as they were correct to within a minute a day. These clocks helped the 16th-century astronomer Tycho Brahe to observe astronomical events with much greater precision than before.

The next development in accuracy occurred after 1656 with the invention of the pendulum clock. Galileo had the idea to use a swinging bob to regulate the motion of a time-telling device earlier in the 17th century. Christiaan Huygens, however, is usually credited as the inventor. He determined the mathematical formula that related pendulum length to time (about 99.4 cm or 39.1 inches for the one second movement) and had the first pendulum-driven clock made. The first model clock was built in 1657 in the Hague, but it was in England that the idea was taken up. The longcase clock (also known as the "grandfather clock") was created to house the pendulum and works by the English clockmaker William Clement in 1670 or 1671. It was also at this time that clock cases began to be made of wood and clock faces to utilize enamel as well as hand-painted ceramics.

In 1670, William Clement created the anchor escapement, an improvement over Huygens' crown escapement. Clement also introduced the pendulum suspension spring in 1671. The concentric minute hand was added to the clock by Daniel Quare, a London clockmaker and others, and the second hand was first introduced.

In 1675, Huygens and Robert Hooke invented the spiral balance spring, or the hairspring, designed to control the oscillating speed of the balance wheel. This crucial advance finally made accurate pocket watches possible. The great English clockmaker, Thomas Tompion, was one of the first to use this mechanism successfully in his pocket watches, and he adopted the minute hand which, after a variety of designs were trialled, eventually stabilised into the modern-day configuration. The rack and snail striking mechanism for striking clocks, was introduced during the 17th century and had distinct advantages over the 'countwheel' (or 'locking plate') mechanism. During the 20th century there was a common misconception that Edward Barlow invented "rack and snail" striking. In fact, his invention was connected with a repeating mechanism employing the rack and snail. The repeating clock, that chimes the number of hours (or even minutes) was invented by either Quare or Barlow in 1676. George Graham invented the deadbeat escapement for clocks in 1720.

A major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The position of a ship at sea could be determined with reasonable accuracy if a navigator could refer to a clock that lost or gained less than about 10 seconds per day. This clock could not contain a pendulum, which would be virtually useless on a rocking ship. In 1714, the British government offered large financial rewards to the value of 20,000 pounds, for anyone who could determine longitude accurately. John Harrison, who dedicated his life to improving the accuracy of his clocks, later received considerable sums under the Longitude Act.

In 1735, Harrison built his first chronometer, which he steadily improved on over the next thirty years before submitting it for examination. The clock had many innovations, including the use of bearings to reduce friction, weighted balances to compensate for the ship's pitch and roll in the sea and the use of two different metals to reduce the problem of expansion from heat. The chronometer was tested in 1761 by Harrison's son and by the end of 10 weeks the clock was in error by less than 5 seconds.

The British had predominated in watch manufacture for much of the 17th and 18th centuries, but maintained a system of production that was geared towards high quality products for the elite. Although there was an attempt to modernise clock manufacture with mass production techniques and the application of duplicating tools and machinery by the British Watch Company in 1843, it was in the United States that this system took off. In 1816, Eli Terry and some other Connecticut clockmakers developed a way of mass-producing clocks by using interchangeable parts. Aaron Lufkin Dennison started a factory in 1851 in Massachusetts that also used interchangeable parts, and by 1861 was running a successful enterprise incorporated as the Waltham Watch Company.

In 1815, Francis Ronalds published the first electric clock powered by dry pile batteries. Alexander Bain, Scottish clockmaker, patented the electric clock in 1840. The electric clock's mainspring is wound either with an electric motor or with an electromagnet and armature. In 1841, he first patented the electromagnetic pendulum. By the end of the nineteenth century, the advent of the dry cell battery made it feasible to use electric power in clocks. Spring or weight driven clocks that use electricity, either alternating current (AC) or direct current (DC), to rewind the spring or raise the weight of a mechanical clock would be classified as an electromechanical clock. This classification would also apply to clocks that employ an electrical impulse to propel the pendulum. In electromechanical clocks the electricity serves no time keeping function. These types of clocks were made as individual timepieces but more commonly used in synchronized time installations in schools, businesses, factories, railroads and government facilities as a master clock and slave clocks.

Electric clocks that are powered from the AC supply often use synchronous motors. The supply current alternates with a frequency of 50 hertz in many countries, and 60 hertz in others. The rotor of the motor rotates at a speed that is related to the alternation frequency. Appropriate gearing converts this rotation speed to the correct ones for the hands of the analog clock. The development of electronics in the 20th century led to clocks with no clockwork parts at all. Time in these cases is measured in several ways, such as by the alternation of the AC supply, vibration of a tuning fork, the behaviour of quartz crystals, or the quantum vibrations of atoms. Electronic circuits divide these high-frequency oscillations to slower ones that drive the time display. Even mechanical clocks have since come to be largely powered by batteries, removing the need for winding.

The piezoelectric properties of crystalline quartz were discovered by Jacques and Pierre Curie in 1880. The first crystal oscillator was invented in 1917 by Alexander M. Nicholson after which, the first quartz crystal oscillator was built by Walter G. Cady in 1921. In 1927 the first quartz clock was built by Warren Marrison and J.W. Horton at Bell Telephone Laboratories in Canada. The following decades saw the development of quartz clocks as precision time measurement devices in laboratory settings—the bulky and delicate counting electronics, built with vacuum tubes, limited their practical use elsewhere. The National Bureau of Standards (now NIST) based the time standard of the United States on quartz clocks from late 1929 until the 1960s, when it changed to atomic clocks. In 1969, Seiko produced the world's first quartz wristwatch, the Astron. Their inherent accuracy and low cost of production resulted in the subsequent proliferation of quartz clocks and watches.

As of the 2010s, atomic clocks are the most accurate clocks in existence. They are considerably more accurate than quartz clocks as they can be accurate to within a few seconds over trillions of years. Atomic clocks were first theorized by Lord Kelvin in 1879. In the 1930s the development of Magnetic resonance created practical method for doing this. A prototype ammonia maser device was built in 1949 at the U.S. National Bureau of Standards (NBS, now NIST). Although it was less accurate than existing quartz clocks, it served to demonstrate the concept. The first accurate atomic clock, a caesium standard based on a certain transition of the caesium-133 atom, was built by Louis Essen in 1955 at the National Physical Laboratory in the UK. Calibration of the caesium standard atomic clock was carried out by the use of the astronomical time scale "ephemeris time" (ET). As of 2013, the most stable atomic clocks are ytterbium clocks, which are stable to within less than two parts in 1 quintillion ().

The invention of the mechanical clock in the 13th century initiated a change in timekeeping methods from continuous processes, such as the motion of the gnomon's shadow on a sundial or the flow of liquid in a water clock, to periodic oscillatory processes, such as the swing of a pendulum or the vibration of a quartz crystal, which had the potential for more accuracy. All modern clocks use oscillation.

Although the mechanisms they use vary, all oscillating clocks, mechanical, digital and atomic, work similarly and can be divided into analogous parts. They consist of an object that repeats the same motion over and over again, an "oscillator", with a precisely constant time interval between each repetition, or 'beat'. Attached to the oscillator is a "controller" device, which sustains the oscillator's motion by replacing the energy it loses to friction, and converts its oscillations into a series of pulses. The pulses are then counted by some type of "counter", and the number of counts is converted into convenient units, usually seconds, minutes, hours, etc. Finally some kind of "indicator" displays the result in human readable form.

The timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates repetitively at a precisely constant frequency.
The advantage of a harmonic oscillator over other forms of oscillator is that it employs resonance to vibrate at a precise natural resonant frequency or "beat" dependent only on its physical characteristics, and resists vibrating at other rates. The possible precision achievable by a harmonic oscillator is measured by a parameter called its Q, or quality factor, which increases (other things being equal) with its resonant frequency. This is why there has been a long term trend toward higher frequency oscillators in clocks. Balance wheels and pendulums always include a means of adjusting the rate of the timepiece. Quartz timepieces sometimes include a rate screw that adjusts a capacitor for that purpose. Atomic clocks are primary standards, and their rate cannot be adjusted.

Some clocks rely for their accuracy on an external oscillator; that is, they are automatically synchronized to a more accurate clock:

This has the dual function of keeping the oscillator running by giving it 'pushes' to replace the energy lost to friction, and converting its vibrations into a series of pulses that serve to measure the time.
In mechanical clocks, the low Q of the balance wheel or pendulum oscillator made them very sensitive to the disturbing effect of the impulses of the escapement, so the escapement had a great effect on the accuracy of the clock, and many escapement designs were tried. The higher Q of resonators in electronic clocks makes them relatively insensitive to the disturbing effects of the drive power, so the driving oscillator circuit is a much less critical component.

This counts the pulses and adds them up to get traditional time units of seconds, minutes, hours, etc. It usually has a provision for "setting" the clock by manually entering the correct time into the counter.

This displays the count of seconds, minutes, hours, etc. in a human readable form.

Clocks can be classified by the type of time display, as well as by the method of timekeeping.

Analog clocks usually use a clock face which indicates time using rotating pointers called "hands" on a fixed numbered dial or dials. The standard clock face, known universally throughout the world, has a short "hour hand" which indicates the hour on a circular dial of 12 hours, making two revolutions per day, and a longer "minute hand" which indicates the minutes in the current hour on the same dial, which is also divided into 60 minutes. It may also have a "second hand" which indicates the seconds in the current minute. The only other widely used clock face today is the 24 hour analog dial, because of the use of 24 hour time in military organizations and timetables. Before the modern clock face was standardized during the Industrial Revolution, many other face designs were used throughout the years, including dials divided into 6, 8, 10, and 24 hours. During the French Revolution the French government tried to introduce a 10-hour clock, as part of their decimal-based metric system of measurement, but it didn't catch on. An Italian 6 hour clock was developed in the 18th century, presumably to save power (a clock or watch striking 24 times uses more power).

Another type of analog clock is the sundial, which tracks the sun continuously, registering the time by the shadow position of its gnomon. Because the sun does not adjust to daylight saving time, users must add an hour during that time. Corrections must also be made for the equation of time, and for the difference between the longitudes of the sundial and of the central meridian of the time zone that is being used (i.e. 15 degrees east of the prime meridian for each hour that the time zone is ahead of GMT). Sundials use some or part of the 24 hour analog dial. There also exist clocks which use a digital display despite having an analog mechanism—these are commonly referred to as flip clocks. Alternative systems have been proposed. For example, the "Twelv" clock indicates the current hour using one of twelve colors, and indicates the minute by showing a proportion of a circular disk, similar to a moon phase.

Digital clocks display a numeric representation of time. Two numeric display formats are commonly used on digital clocks:

Most digital clocks use electronic mechanisms and LCD, LED, or VFD displays; many other display technologies are used as well (cathode ray tubes, nixie tubes, etc.). After a reset, battery change or power failure, these clocks without a backup battery or capacitor either start counting from 12:00, or stay at 12:00, often with blinking digits indicating that the time needs to be set. Some newer clocks will reset themselves based on radio or Internet time servers that are tuned to national atomic clocks. Since the advent of digital clocks in the 1960s, the use of analog clocks has declined significantly.

Some clocks, called 'flip clocks', have digital displays that work mechanically. The digits are painted on sheets of material which are mounted like the pages of a book. Once a minute, a page is turned over to reveal the next digit. These displays are usually easier to read in brightly lit conditions than LCDs or LEDs. Also, they do not go back to 12:00 after a power interruption. Flip clocks generally do not have electronic mechanisms. Usually, they are driven by AC-synchronous motors.
Clocks with analog quadrants, with a digital component, usually minutes and hours displayed analogously and seconds displayed in digital mode.

For convenience, distance, telephony or blindness, auditory clocks present the time as sounds. The sound is either spoken natural language, (e.g. "The time is twelve thirty-five"), or as auditory codes (e.g. number of sequential bell rings on the hour represents the number of the hour like the bell, Big Ben). Most telecommunication companies also provide a speaking clock service as well.

Word clocks are clocks that display the time visually using sentences. E.g.: "It’s about three o’clock." These clocks can be implemented in hardware or software.

Some clocks, usually digital ones, include an optical projector that shines a magnified image of the time display onto a screen or onto a surface such as an indoor ceiling or wall. The digits are large enough to be easily read, without using glasses, by persons with moderately imperfect vision, so the clocks are convenient for use in their bedrooms. Usually, the timekeeping circuitry has a battery as a backup source for an uninterrupted power supply to keep the clock on time, while the projection light only works when the unit is connected to an A.C. supply. Completely battery-powered portable versions resembling flashlights are also available.

Auditory and projection clocks can be used by people who are blind or have limited vision. There are also clocks for the blind that have displays that can be read by using the sense of touch. Some of these are similar to normal analog displays, but are constructed so the hands can be felt without damaging them. Another type is essentially digital, and uses devices that use a code such as Braille to show the digits so that they can be felt with the fingertips.

Some clocks have several displays driven by a single mechanism, and some others have several completely separate mechanisms in a single case. Clocks in public places often have several faces visible from different directions, so that the clock can be read from anywhere in the vicinity; all the faces show the same time. Other clocks show the current time in several time-zones. Watches that are intended to be carried by travellers often have two displays, one for the local time and the other for the time at home, which is useful for making pre-arranged phone calls. Some equation clocks have two displays, one showing mean time and the other solar time, as would be shown by a sundial. Some clocks have both analog and digital displays. Clocks with Braille displays usually also have conventional digits so they can be read by sighted people.

Clocks are in homes, offices and many other places; smaller ones (watches) are carried on the wrist or in a pocket; larger ones are in public places, e.g. a railway station or church. A small clock is often shown in a corner of computer displays, mobile phones and many MP3 players.

The primary purpose of a clock is to "display" the time. Clocks may also have the facility to make a loud alert signal at a specified time, typically to waken a sleeper at a preset time; they are referred to as "alarm clocks". The alarm may start at a low volume and become louder, or have the facility to be switched off for a few minutes then resume. Alarm clocks with visible indicators are sometimes used to indicate to children too young to read the time that the time for sleep has finished; they are sometimes called "training clocks".

A clock mechanism may be used to "control" a device according to time, e.g. a central heating system, a VCR, or a time bomb (see: digital counter). Such mechanisms are usually called timers. Clock mechanisms are also used to drive devices such as solar trackers and astronomical telescopes, which have to turn at accurately controlled speeds to counteract the rotation of the Earth.

Most digital computers depend on an internal signal at constant frequency to synchronize processing; this is referred to as a clock signal. (A few research projects are developing CPUs based on asynchronous circuits.) Some equipment, including computers, also maintains time and date for use as required; this is referred to as time-of-day clock, and is distinct from the system clock signal, although possibly based on counting its cycles.

In Chinese culture, giving a clock () is often taboo, especially to the elderly as the term for this act is a homophone with the term for the act of attending another's funeral (). A UK government official Susan Kramer gave a watch to Taipei mayor Ko Wen-je unaware of such a taboo which resulted in some professional embarrassment and a pursuant apology.

It is undesirable to give someone a clock or (depending on the region) other timepiece as a gift. Traditional superstitions regard this as counting the seconds to the recipient's death. Another common interpretation of this is that the phrase "to give a clock" () in Chinese is pronounced "sòng zhōng" in Mandarin, which is a homophone of a phrase for "terminating" or "attending a funeral" (both can be written as (traditional) or (simplified)). Cantonese people consider such a gift as a curse.

This homonymic pair works in both Mandarin and Cantonese, although in most parts of China only clocks and large bells, and not watches, are called ""zhong"", and watches are commonly given as gifts in China.

However, should such a gift be given, the "unluckiness" of the gift can be countered by exacting a small monetary payment so the recipient is buying the clock and thereby counteracting the ("give") expression of the phrase.

For some scientific work timing of the utmost accuracy is essential. It is also necessary to have a standard of the maximum accuracy against which working clocks can be calibrated. An ideal clock would give the time to unlimited accuracy, but this is not realisable. Many physical processes, in particular including some transitions between atomic energy levels, occur at exceedingly stable frequency; counting cycles of such a process can give a very accurate and consistent time—clocks which work this way are usually called atomic clocks. Such clocks are typically large, very expensive, require a controlled environment, and are far more accurate than required for most purposes; they are typically used in a standards laboratory.

Until advances in the late twentieth century, navigation depended on the ability to measure latitude and longitude. Latitude can be determined through celestial navigation; the measurement of longitude requires accurate knowledge of time. This need was a major motivation for the development of accurate mechanical clocks. John Harrison created the first highly accurate marine chronometer in the mid-18th century. The Noon gun in Cape Town still fires an accurate signal to allow ships to check their chronometers. Many buildings near major ports used to have (some still do) a large ball mounted on a tower or mast arranged to drop at a pre-determined time, for the same purpose. While satellite navigation systems such as the Global Positioning System (GPS) require unprecedentedly accurate knowledge of time, this is supplied by equipment on the satellites; vehicles no longer need timekeeping equipment.





</doc>
<doc id="6451" url="https://en.wikipedia.org/wiki?curid=6451" title="Charles Proteus Steinmetz">
Charles Proteus Steinmetz

Charles Proteus Steinmetz (born Karl August Rudolph Steinmetz, April 9, 1865 – October 26, 1923) was a German-born American mathematician and electrical engineer and professor at Union College. He fostered the development of alternating current that made possible the expansion of the electric power industry in the United States, formulating mathematical theories for engineers. He made ground-breaking discoveries in the understanding of hysteresis that enabled engineers to design better electromagnetic apparatus equipment including especially electric motors for use in industry.

At the time of his death, Steinmetz held over 200 patents. A genius in both mathematics and electronics, his work earned him the nicknames "Forger of Thunderbolts" and "The Wizard of Schenectady". Steinmetz's equation, Steinmetz solids, Steinmetz curves, and Steinmetz equivalent circuit theory are all named after him, as are numerous honors and scholarships, including the "IEEE Charles Proteus Steinmetz Award", one of the highest technical recognitions given by the Institute of Electrical and Electronics Engineers professional society.

Steinmetz was born Karl August Rudolph Steinmetz on April 9, 1865 in Breslau, Province of Silesia, Prussia (now Wrocław, Poland) the son of Caroline (Neubert) and Karl Heinrich Steinmetz. He was baptized a Lutheran into the Evangelical Church of Prussia. Steinmetz, who only stood four feet tall as an adult, suffered from dwarfism, hunchback, and hip dysplasia, as did his father and grandfather. Steinmetz attended Johannes Gymnasium and astonished his teachers with his proficiency in mathematics and physics.

Following the Gymnasium, Steinmetz went on to the University of Breslau to begin work on his undergraduate degree in 1883. He was on the verge of finishing his doctorate in 1888 when he came under investigation by the German police for activities on behalf of a socialist university group and articles he had written for a local socialist newspaper.

As socialist meetings and press had been banned in Germany, Steinmetz fled to Zürich in 1888 to escape possible arrest. Faced with an expiring visa, he emigrated to the United States in 1889. He changed his first name to "Charles" in order to sound more American, and chose the middle name "Proteus", a wise hunchbacked character from the "Odyssey" who knew many secrets, after a childhood epithet given by classmates Steinmetz felt suited him.

Cornell University Professor Ronald R. Kline, the author of "Steinmetz: Engineer and Socialist", contended that other factors were more directly involved in Steinmetz's decision to leave his homeland, such as being in arrears with his tuition at the University and life at home with his father, stepmother, and their daughters being tension filled.

Despite his earlier efforts and interest in socialism, by 1922 Steinmetz concluded that socialism would never work in the United States, because the country lacked a "powerful, centralized government of competent men, remaining continuously in office", and because "only a small percentage of Americans accept this viewpoint today".

A member of the original Technical Alliance, which also included Thorstein Veblen and Leland Olds, Steinmetz had great faith in the ability of machines to eliminate human toil and create abundance for all. He put it this way: "Some day we make the good things of life for everybody".

Steinmetz is known for his contribution in three major fields of alternating current (AC) systems theory: hysteresis, steady-state analysis, and transients.

Shortly after arriving in the United States, Steinmetz went to work for Rudolf Eickemeyer in Yonkers, New York, and published in the field of magnetic hysteresis, which gave him worldwide professional recognition. Eickemeyer's firm developed transformers for use in the transmission of electrical power among many other mechanical and electrical devices. In 1893 Eickemeyer's company, along with all of its patents and designs, was bought by the newly formed General Electric Company, where Steinmetz quickly became known as the engineering wizard in GE's engineering community.

Steinmetz's work revolutionized AC circuit theory and analysis, which had been carried out using complicated, time-consuming calculus-based methods. In the groundbreaking paper, "Complex Quantities and Their Use in Electrical Engineering", presented at a July 1893 meeting published in the American Institute of Electrical Engineers (AIEE), Steinmetz simplified these complicated methods to "a simple problem of algebra". He systematized the use of complex number phasor representation in electrical engineering education texts, whereby the lower-case letter "j" is used to designate the 90-degree rotation operator in AC system analysis. His seminal books and many other AIEE papers "taught a whole generation of engineers how to deal with AC phenomena".

Steinmetz also greatly advanced the understanding of lightning. His systematic experiments resulted in the first laboratory created "man-made lightning", earning him the nickname the "Forger of Thunderbolts". These were conducted in a football field-sized laboratory at General Electric, using 120,000 volt generators. He also erected a lightning tower to attract natural lightning in order to study its patterns and effects, which resulted in several theories.

Steinmetz acted in the following professional capacities:

He was granted an honorary degree from Harvard University in 1901 and a doctorate from Union College in 1903.

Steinmetz wrote 13 books and 60 articles, not exclusively about engineering. He was a member and adviser to the fraternity Phi Gamma Delta at Union College, whose chapter house there was one of the first ever electrified residences.

While serving as president of the Schenectady Board of Education Steinmetz introduced numerous progressive reforms, including extended school hours, school meals, school nurses, special classes for the children of immigrants, and the distribution of free textbooks.

In spite of his love for children and family life, Steinmetz remained unmarried to prevent the spinal deformity afflicting himself, his father, and grandfather from being passed on to any offspring.

When Joseph LeRoy Hayden, a loyal and hardworking lab assistant, announced that he would marry and look for his own living quarters, Steinmetz made the unusual proposal of opening his large home, complete with research lab, greenhouse, and office to the Haydens and their prospective family. Hayden favored the idea, but his future wife was very wary of the unorthodox setup. She finally agreed after Steinmetz's assurance she could run the house as she saw fit.

After an uneasy start, the arrangement worked well for all parties, especially after three Hayden children were born. Steinmetz legally adopted Joseph Hayden as his son, becoming grandfather to the youngsters, entertaining them with fantastic stories and spectacular scientific demonstrations. The unusual but harmonious living arrangements lasted for the rest of Steinmetz's life.

Steinmetz founded America's first glider club, but none of its prototypes "could be dignified with the term 'flight'".

Steinmetz was a lifelong agnostic. He died of a heart attack
on October 26, 1923, and was buried in Vale Cemetery in Schenectady.

The "Forger of Thunderbolts" and "Wizard of Schenectady" earned wide recognition among the scientific community and numerous awards and honors both during his life and posthumously.

"Steinmetz's equation", derived from his experiments, defines the approximate heat energy due to magnetic hysteresis released, per cycle per unit area of magnetic material. A Steinmetz solid is the solid body generated by the intersection of two or three cylinders of equal radius at right angles. Steinmetz equivalent circuit theory is still widely used for the design and testing of induction motors.

One of the highest technical recognitions given by the Institute of Electrical and Electronics Engineers, the "IEEE Charles Proteus Steinmetz Award", is given for major contributions to standardization within the field of electrical and electronics engineering. Other awards include the Certificate of Merit of Franklin Institute, 1908; the Elliott Cresson Medal, 1913; and the Cedergren Medal, 1914.

The "Charles P. Steinmetz Memorial Lecture" series was begun in his honor in 1925, sponsored by the Schenectady branch of the IEEE. Through 2017 seventy-three gatherings have taken place, held almost exclusively at Union College, featuring notable figures such as Nobel laureate experimental physicist Robert A. Millikan, helicopter inventor Igor Sikorsky, nuclear submarine pioneer Admiral Hyman G. Rickover (1963), Nobel-winning semiconductor inventor William Shockley, and Internet 'founding father' Leonard Kleinrock. The "Charles P. Steinmetz Scholarship" is awarded annually by the college, underwritten since its inception in 1923 by the General Electric Company.

The "Charles P. Steinmetz Memorial Scholarship" was established at Union by Marjorie Hayden, daughter of Joseph and Corrine Hayden, and is awarded to students majoring in engineering or physics.

Steinmetz's connection to Union is further celebrated with the annual Steinmetz Symposium, a day-long event in which Union undergraduates give presentations on research they have done. Steinmetz Hall, which houses the Union College computer center, is named after him.

Steinmetz was portrayed in 1959 by the actor Rod Steiger in the CBS television anthology series, "The Joseph Cotten Show". The episode focused on his socialist activities in Germany.

A Chicago public high school, Steinmetz College Prep, is named for him.

A public park in north Schenectady, New York was named for him in 1931.

Steinmetz is featured in John Dos Passos's "U.S.A." trilogy in one of the biographies. He also serves as a major character in Starling Lawrence's "The Lightning Keeper".

Novelist John Ball grew up in Steinmetz's house. His parents were graduate students paid by General Electric to live with and take care of the man Ball called "Uncle Steinie". Ball used to tell his Steinmetz stories at the Southern California Mystery Writers Association meetings.

Steinmetz is a major character in the novel "Electric City" by Elizabeth Rosner.

At the time of his death, Steinmetz held over 200 patents:





</doc>
<doc id="6452" url="https://en.wikipedia.org/wiki?curid=6452" title="Charles Martel">
Charles Martel

Charles Martel ( 688 – 22 October 741) was a Frankish statesman and military leader who as Duke and Prince of the Franks and Mayor of the Palace, was the "de facto" ruler of Francia from 718 until his death. He was a son of the Frankish statesman Pepin of Herstal and Pepin's mistress, a noblewoman named Alpaida. Charles successfully asserted his claims to power as successor to his father as the power behind the throne in Frankish politics. Continuing and building on his father's work, he restored centralized government in Francia and began the series of military campaigns that re-established the Franks as the undisputed masters of all Gaul. According to a near-contemporary source, the "Liber Historiae Francorum", Charles was "a warrior who was uncommonly [...] effective in battle". Much attention has been paid to his success in defeating an Arab raid in Aquitaine at the Battle of Tours. Alongside his military endeavours, Charles has been traditionally credited with a seminal role in the development of the Frankish system of feudalism.

At the end of his reign, Charles divided Francia between his sons, Carloman and Pepin. The latter became the first king of the Carolingian dynasty. Charles' grandson, Charlemagne, extended the Frankish realms, and became the first Emperor in the West since the fall of Rome.

Charles, nicknamed "Martel", or "the Hammer", in later chronicles, was the son of Pepin of Herstal and his second wife Alpaida. He had a brother named Childebrand, who later became the Frankish "dux" (that is, "duke") of Burgundy.

In older historiography, it was common to describe Charles as "illegitimate". But the dividing line between wives and concubines was not clear-cut in eighth-century Francia, and it is likely that the accusation of "illegitimacy" derives from the desire of Pepin's first wife Plectrude to see her progeny as heirs to Pepin's power.

After the reign of Dagobert I (629–639) the Merovingians effectively ceded power to the Pippinid Mayors of the Palace, who ruled the Frankish realm of Austrasia in all but name. They controlled the royal treasury, dispensed patronage, and granted land and privileges in the name of the figurehead king. Charles' father, Pepin of Herstal, was able to unite the Frankish realm by conquering Neustria and Burgundy. He was the first to call himself Duke and Prince of the Franks, a title later taken up by Charles.

In December 714, Pepin of Herstal died. Prior to his death, he had, at his wife Plectrude's urging, designated Theudoald, his grandson by their late son Grimoald, his heir in the entire realm. This was immediately opposed by the nobles because Theudoald was a child of only eight years of age. To prevent Charles using this unrest to his own advantage, Plectrude had him imprisoned in Cologne, the city which was intended to be her capital. This prevented an uprising on his behalf in Austrasia, but not in Neustria.

Pepin's death occasioned open conflict between his heirs and the Neustrian nobles who sought political independence from Austrasian control. In 715, Dagobert III named Ragenfrid mayor of their palace, effectively declaring political independence. On 26 September 715, Ragenfrid's Neustrians met the young Theudoald's forces at the Battle of Compiegne. Theudoald was defeated and fled back to Cologne.
Before the end of the year, Charles Martel had escaped from prison and been acclaimed mayor by the nobles of Austrasia. That same year, Dagobert III died and the Neustrians proclaimed Chilperic II, the cloistered son of Childeric II, as king.

In 716, Chilperic and Ragenfrid together led an army into Austrasia intent on seizing the Pippinid wealth at Cologne. The Neustrians allied with another invading force under Radbod, King of the Frisians and met Charles in battle near Cologne, which was still held by Plectrude. Charles had little time to gather men, or prepare, and the result was the only defeat of his career. The Frisians held off Charles, while the king and his mayor besieged Plectrude at Cologne, where she bought them off with a substantial portion of Pepin's treasure. Then they withdrew.

Charles retreated to the hills of the Eifel to gather men, and train them. Having made the proper preparations, in April 716, he fell upon the triumphant army near Malmedy as it was returning to its own province. In the ensuing Battle of Amblève, Martel attacked as the enemy rested at midday. According to one source, he split his forces into several groups which fell at them from many sides. Another suggests that while this was his intention, he then decided, given the enemy's unpreparedness, this was not necessary. In any event, the suddenness of the assault lead them to believe they were facing a much larger host. Many of the enemy fled and Martel's troops gathered the spoils of the camp. Martel's reputation increased considerably as a result, and he attracted more followers. This battle is often considered by historians as the turning point in Charles's struggle.

Richard Gerberding points out that up to this time, much of Martel's support was probably from his mother's kindred in the lands around Liege. After Amblève, he seems to have won the backing of the influential Willibrord, founder of the Abbey of Echternach. The abbey had been built on land donated by Plectrude's mother, Irmina of Oeren, but most of Willibrord's missionary work had been carried out in Frisia. In joining Chilperic and Ragenfrid, Radbod of Frisia sacked Utrecht, burning churches and killing many missionaries. Willibrord and his monks were forced to flee to Echternach. Gerberding suggests that Willibrord had decided that the chances of preserving his life's work were better with a successful field commander like Martel than with Plectrude in Cologne. Willibrord subsequently baptized Martel's son Pepin. Gerberding suggests a likely date of Easter 716. Martel also received support from Bishop Pepo of Verdun.

Charles took time to rally more men and prepare. By the following spring, Charles had attracted enough support to invade Neustria. Charles sent an envoy who proposed a cessation of hostilities if Chilperic would recognize his rights as mayor of the palace in Austrasia. The refusal was not unexpected but served to impress upon Martel's forces the unreasonableness of the Neustrians. They met near Cambrai at the Battle of Vincy on 21 March 717. The victorious Martel pursued the fleeing king and mayor to Paris, but as he was not yet prepared to hold the city, he turned back to deal with Plectrude and Cologne. He took the city and dispersed her adherents. Plectrude was allowed to retire to a convent; Theudoald lived to 741 under his uncle's protection, a kindness unusual for those times, when mercy to a former gaoler, or a potential rival, was rare.

Upon this success, Charles proclaimed Chlothar IV king of Austrasia in opposition to Chilperic and deposed Rigobert, archbishop of Reims, replacing him with Milo, a lifelong supporter.

In 718, Chilperic responded to Charles' new ascendancy by making an alliance with Odo the Great (or Eudes, as he is sometimes known), the duke of Aquitaine, who had become independent during the civil war in 715, but was again defeated, at the Battle of Soissons, by Charles. Chilperic fled with his ducal ally to the land south of the Loire and Ragenfrid fled to Angers. Soon Chlotar IV died and Odo surrendered King Chilperic in exchange for Charles recognizing his dukedom. Charles recognized Chilperic as king of the Franks in return for legitimate royal affirmation of his own mayoralty over all the kingdoms.

Between 718 and 723, Charles secured his power through a series of victories. Having unified the Franks under his banner, Charles was determined to punish the Saxons who had invaded Austrasia. Therefore, late in 718, he laid waste their country to the banks of the Weser, the Lippe, and the Ruhr. He defeated them in the Teutoburg Forest and thus secured the Frankish border in the name of King Chlotaire.

When the Frisian leader Radbod died in 719, Charles seized West Frisia without any great resistance on the part of the Frisians, who had been subjected to the Franks but had rebelled upon the death of Pippin. When Chilperic II died the following year (720), Charles appointed as his successor the son of Dagobert III, Theuderic IV, who was still a minor, and who occupied the throne from 720 to 737 Charles was now appointing the kings whom he supposedly served, "rois fainéants" who were mere figureheads; by the end of his reign he didn't appoint one at all. At this time, Charles again marched against the Saxons. Then the Neustrians rebelled under Ragenfrid, who had left the county of Anjou. They were easily defeated (724), but Ragenfrid gave up his sons as hostages in turn for keeping his county. This ended the civil wars of Charles' reign.

The next six years were devoted in their entirety to assuring Frankish authority over the neighbouring political groups. Between 720 and 723, Charles was fighting in Bavaria, where the Agilolfing dukes had gradually evolved into independent rulers, recently in alliance with Liutprand the Lombard. He forced the Alemanni to accompany him, and Duke Hugbert submitted to Frankish suzerainty. In 725 he brought back the Agilolfing Princess Swanachild as a second wife.

In 725 and 728, he again entered Bavaria, but in 730, he marched against Lantfrid, Duke of Alemannia, who had also become independent, and killed him in battle. He forced the Alemanni to capitulate to Frankish suzerainty and did not appoint a successor to Lantfrid. Thus, southern Germany once more became part of the Frankish kingdom, as had northern Germany during the first years of the reign.

In 731, after defeating the Saxons, Charles turned his attention to the rival southern realm of Aquitaine, and crossed the Loire, breaking the treaty with Duke Odo. The Franks ransacked Aquitaine twice, and captured Bourges, although Odo retook it. The "Continuations of Fredegar" allege that Odo called on assistance from the recently established emirate of al-Andalus, but there had been Arab raids into Aquitaine from the 720s onwards: indeed, in 721 the Chronicle of 754 records a victory of Odo at the Battle of Toulouse, while the "Liber Pontificalis" records that Odo had killed 375,000 Saracens. It is more likely that this invasion or raid took place in revenge for Odo's support for a rebel Berber leader named Munnuza.

Whatever the precise circumstances, it is clear that an army under the leadership of Abd al-Rahman al-Ghafiqi headed north, and after some minor engagements marched on the wealthy city of Tours. According to British medieval historian Paul Fouracre, "Their campaign should perhaps be interpreted as a long-distance raid rather than the beginning of a war". They were however defeated by the army of Charles at a location between Tours and Poitiers, in a victory described by the "Continuations of Fredegar". News of this battle spread, and may be recorded in Bede's "Ecclesiastical History" (Book V, ch. 23). However, it is not given prominence in Arabic sources from the period.

Despite his victory, Charles did not gain full control of Aquitaine, and Odo remained duke until his death in 735.

Between his victory of 732 and 735, Charles reorganized the kingdom of Burgundy, replacing the counts and dukes with his loyal supporters, thus strengthening his hold on power. He was forced, by the ventures of Bubo, Duke of the Frisians, to invade independent-minded Frisia again in 734. In that year, he slew the duke at the Battle of the Boarn. Charles ordered the Frisian pagan shrines destroyed, and so wholly subjugated the populace that the region was peaceful for twenty years after.

In 735, Duke Odo of Aquitaine died. Though Charles wished to rule the duchy directly and went there to elicit the submission of the Aquitainians, the aristocracy proclaimed Odo's son, Hunald I of Aquitaine, as duke, and Charles and Hunald eventually recognised each other's position.

In 737, at the tail end of his campaigning in Provence and Septimania, the Merovingian king, Theuderic IV, died. Charles, titling himself "maior domus" and "princeps et dux Francorum", did not appoint a new king and nobody acclaimed one. The throne lay vacant until Charles' death. The interregnum, the final four years of Charles' life, was more peaceful than most of it had been but in 738, he compelled the Saxons of Westphalia to submit and pay tribute, and in 739 he checked an uprising in Provence, the rebels being under the leadership of Maurontus.

Charles used the relative peace to set about integrating the outlying realms of his empire into the Frankish church. He erected four dioceses in Bavaria (Salzburg, Regensburg, Freising, and Passau) and gave them Boniface as archbishop and metropolitan over all Germany east of the Rhine, with his seat at Mainz. Boniface had been under his protection from 723 on; indeed the saint himself explained to his old friend, Daniel of Winchester, that without it he could neither administer his church, defend his clergy, nor prevent idolatry.

In 739, Pope Gregory III begged Charles for his aid against Liutprand, but Charles was loath to fight his onetime ally and ignored the plea. Nonetheless, the pope's request for Frankish protection showed how far Charles had come from the days he was tottering on excommunication, and set the stage for his son and grandson to assert themselves in the peninsula.

Charles Martel died on 22 October 741, at Quierzy-sur-Oise in what is today the Aisne "département" in the Picardy region of France. He was buried at Saint Denis Basilica in Paris.

His territories had been divided among his adult sons a year earlier: to Carloman he gave Austrasia, Alemannia, and Thuringia, and to Pippin the Younger Neustria, Burgundy, Provence, and Metz and Trier in the "Mosel duchy"; Grifo was given several lands throughout the kingdom, but at a later date, just before Charles died.

At the beginning of Charles Martel's career, he had many internal opponents and felt the need to appoint his own kingly claimant, Chlotar IV. By his end, however, the dynamics of rulership in Francia had changed, and no hallowed Merovingian ruler was required. Charles divided his realm between his sons without opposition (though he ignored his young son Bernard). For many historians, Charles Martel laid the foundations for his son Pepin's rise to the Frankish throne in 751, and his grandson Charlemagne's imperial acclamation in 800. However, for Paul Fouracre, while Charles was "the most effective military leader in Francia", his career "finished on a note of unfinished business".

Charles Martel married twice, his first wife being Rotrude of Treves, daughter either of Lambert II, Count of Hesbaye, or of Leudwinus, Count of Treves. They had the following children:


Most of the children married and had issue. Hiltrud married Odilo I (a Duke of Bavaria). Landrade was once believed to have married a Sigrand (Count of Hesbania) but Sigrand's wife was more likely the sister of Rotrude. Auda married Thierry IV (a Count of Autun and Toulouse). Charles also married a second time, to Swanhild, and they had a child, Grifo.

Finally, Charles Martel also had a known mistress, Ruodhaid, with whom he had children Bernard, Hieronymus, and Remigius. Remigius became an archbishop of Rouen.

For early medieval authors, Charles Martel was famous for his military victories. Paul the Deacon for instance attributed a victory against the Saracens actually won by Odo of Aquitaine to Charles. However, alongside this there soon developed a darker reputation, for his alleged abuse of church property. A ninth-century text, the "Visio Eucherii", possibly written by Hincmar of Reims, portrayed Martel as suffering in hell for this reason. According to British medieval historian Paul Fouracre, this was "the single most important text in the construction of Charles Martel's reputation as a seculariser or despoiler of church lands".

By the eighteenth century, historians such as Edward Gibbon had begun to portray the Frankish leader as the saviour of Christian Europe from a full-scale Islamic invasion. In Gibbon's "The Decline And Fall Of The Roman Empire" he wonders whether without Charles' victory, "Perhaps the interpretation of the Koran would now be taught in the schools of Oxford".

In the nineteenth century, the German historian Heinrich Brunner argued that Charles had confiscated church lands in order to fund military reforms that allowed him to defeat the Arab conquests, in this way brilliantly combining two traditions about the ruler. But Fouracre has argued that "...there is not enough evidence to show that there was a decisive change either in the way in which the Franks fought, or in the way in which they organised the resources needed to support their warriors."

Many twentieth-century European historians continued to develop Gibbon's perspectives, such as French medievalist Christian Pfister, who wrote in 1911 that

Similarly, William E. Watson who wrote of the battle's importance in Frankish and world history in 1993, suggested that

Other recent historians however argue that the importance of the battle is dramatically overstated, both for European history in general and for Charles Martel's reign in particular. This view is typified by Alessandro Barbero, who in 2004 wrote,

Similarly, in 2002 Tomaž Mastnak wrote: 
More recently, the memory of Charles Martel has been appropriated by far right and white nationalist groups, such as the 'Charles Martel Group' in France, and by Australia-born Brenton Harrison Tarrant, the alleged perpetrator of the Christchurch mosque shootings at Al Noor Mosque and Linwood Islamic Centre in Christchurch, New Zealand in 2019.



</doc>
<doc id="6456" url="https://en.wikipedia.org/wiki?curid=6456" title="Charles Edward Jones">
Charles Edward Jones

Colonel Charles Edward ("Chuck") Jones (November 8, 1952 – September 11, 2001) was a United States Air Force officer, a computer programmer, and an astronaut in the USAF Manned Spaceflight Engineer Program.

Jones was born November 8, 1952, in Clinton, Indiana. He graduated from Wichita East High School in 1970, earned a Bachelor of Science degree in Astronautical Engineering from the United States Air Force Academy in 1974, and received a Master of Science degree in Astronautics from MIT in 1980. He entered the USAF Manned Spaceflight Engineer program in 1982, and was scheduled to fly on mission STS-71-B in December 1986, but the mission was cancelled after the "Challenger" Disaster in January 1986. He left the Manned Spaceflight Engineer program in 1987.

He later worked for Defense Intelligence Agency, Bolling AFB in Washington D.C., and was Systems Program Director for Intelligence and Information Systems, Hanscom AFB, Massachusetts.

He was killed at the age of 48 in the attacks of September 11, 2001, aboard American Airlines Flight 11. He had been living as a retired U.S. Air Force Colonel in Bedford, Massachusetts, at the time of his death. He was survived by his wife Jeanette.

At the National 9/11 Memorial, Jones is memorialized at the North Pool, on Panel N-74.




</doc>
<doc id="6458" url="https://en.wikipedia.org/wiki?curid=6458" title="Ceramic">
Ceramic

A ceramic ( — , "potter's", from  — , "potter's clay") is a solid material comprising an inorganic compound of metal, non-metal or metalloid atoms primarily held in ionic and covalent bonds. Common examples are earthenware, porcelain, and brick.

The crystallinity of ceramic materials ranges from highly oriented to semi-crystalline, vitrified, and often completely amorphous (e.g., glasses). Most often, fired ceramics are either vitrified or semi-vitrified as is the case with earthenware, stoneware, and porcelain. Varying crystallinity and electron composition in the ionic and covalent bonds cause most ceramic materials to be good thermal and electrical insulators (extensively researched in ceramic engineering). With such a large range of possible options for the composition/structure of a ceramic (e.g. nearly all of the elements, nearly all types of bonding, and all levels of crystallinity), the breadth of the subject is vast, and identifiable attributes (e.g. hardness, toughness, electrical conductivity, etc.) are difficult to specify for the group as a whole. General properties such as high melting temperature, high hardness, poor conductivity, high moduli of elasticity, chemical resistance and low ductility are the norm, with known exceptions to each of these rules (e.g. piezoelectric ceramics, glass transition temperature, superconductive ceramics, etc.). Many composites, such as fiberglass and carbon fiber, while containing ceramic materials, are not considered to be part of the ceramic family.

The earliest ceramics made by humans were pottery objects (i.e. "pots" or "vessels") or figurines made from clay, either by itself or mixed with other materials like silica, hardened and sintered in fire. Later ceramics were glazed and fired to create smooth, colored surfaces, decreasing porosity through the use of glassy, amorphous ceramic coatings on top of the crystalline ceramic substrates. Ceramics now include domestic, industrial and building products, as well as a wide range of ceramic art. In the 20th century, new ceramic materials were developed for use in advanced ceramic engineering, such as in semiconductors.

The word ""ceramic"" comes from the Greek word (), "of pottery" or "for pottery", from (), "potter's clay, tile, pottery". The earliest known mention of the root "ceram-" is the Mycenaean Greek , "workers of ceramics", written in Linear B syllabic script. The word "ceramic" may be used as an adjective to describe a material, product or process, or it may be used as a noun, either singular, or, more commonly, as the plural noun "ceramics".

A ceramic material is an inorganic, non-metallic, often crystalline oxide, nitride or carbide material. Some elements, such as carbon or silicon, may be considered ceramics. Ceramic materials are brittle, hard, strong in compression, and weak in shearing and tension. They withstand chemical erosion that occurs in other materials subjected to acidic or caustic environments. Ceramics generally can withstand very high temperatures, ranging from 1,000 °C to 1,600 °C (1,800 °F to 3,000 °F). Glass is often not considered a ceramic because of its amorphous (noncrystalline) character. However, glassmaking involves several steps of the ceramic process, and its mechanical properties are similar to ceramic materials.

Traditional ceramic raw materials include clay minerals such as kaolinite, whereas more recent materials include aluminium oxide, more commonly known as alumina. The modern ceramic materials, which are classified as advanced ceramics, include silicon carbide and tungsten carbide. Both are valued for their abrasion resistance and hence find use in applications such as the wear plates of crushing equipment in mining operations. Advanced ceramics are also used in the medicine, electrical, electronics industries and body armor.

Crystalline ceramic materials are not amenable to a great range of processing. Methods for dealing with them tend to fall into one of two categories – either make the ceramic in the desired shape, by reaction "in situ", or by "forming" powders into the desired shape, and then sintering to form a solid body. Ceramic forming techniques include shaping by hand (sometimes including a rotation process called "throwing"), slip casting, tape casting (used for making very thin ceramic capacitors), injection molding, dry pressing, and other variations. 

Noncrystalline ceramics, being glass, tend to be formed from melts. The glass is shaped when either fully molten, by casting, or when in a state of toffee-like viscosity, by methods such as blowing into a mold. If later heat treatments cause this glass to become partly crystalline, the resulting material is known as a glass-ceramic, widely used as cook-tops and also as a glass composite material for nuclear waste disposal.

The physical properties of any ceramic substance are a direct result of its crystalline structure and chemical composition. Solid-state chemistry reveals the fundamental connection between microstructure and properties such as localized density variations, grain size distribution, type of porosity and second-phase content, which can all be correlated with ceramic properties such as mechanical strength σ by the Hall-Petch equation, hardness, toughness, dielectric constant, and the optical properties exhibited by transparent materials.

Ceramography is the art and science of preparation, examination and evaluation of ceramic microstructures. Evaluation and characterization of ceramic microstructures is often implemented on similar spatial scales to that used commonly in the emerging field of nanotechnology: from tens of angstroms (A) to tens of micrometers (µm). This is typically somewhere between the minimum wavelength of visible light and the resolution limit of the naked eye.

The microstructure includes most grains, secondary phases, grain boundaries, pores, micro-cracks, structural defects and hardness microindentions. Most bulk mechanical, optical, thermal, electrical and magnetic properties are significantly affected by the observed microstructure. The fabrication method and process conditions are generally indicated by the microstructure. The root cause of many ceramic failures is evident in the cleaved and polished microstructure. Physical properties which constitute the field of materials science and engineering include the following:

Mechanical properties are important in structural and building materials as well as textile fabrics. In modern materials science, fracture mechanics is an important tool in improving the mechanical performance of materials and components. It applies the physics of stress and strain, in particular the theories of elasticity and plasticity, to the microscopic crystallographic defects found in real materials in order to predict the macroscopic mechanical failure of bodies. Fractography is widely used with fracture mechanics to understand the causes of failures and also verify the theoretical failure predictions with real life failures.

Ceramic materials are usually ionic or covalent bonded materials, and can be crystalline or amorphous. A material held together by either type of bond will tend to fracture before any plastic deformation takes place, which results in poor toughness in these materials. Additionally, because these materials tend to be porous, the pores and other microscopic imperfections act as stress concentrators, decreasing the toughness further, and reducing the tensile strength. These combine to give catastrophic failures, as opposed to the more ductile failure modes of metals.

These materials do show plastic deformation. However, because of the rigid structure of the crystalline materials, there are very few available slip systems for dislocations to move, and so they deform very slowly. With the non-crystalline (glassy) materials, viscous flow is the dominant source of plastic deformation, and is also very slow. It is therefore neglected in many applications of ceramic materials.

To overcome the brittle behaviour, ceramic material development has introduced the class of ceramic matrix composite materials, in which ceramic fibers are embedded and with specific coatings are forming fiber bridges across any crack. This mechanism substantially increases the fracture toughness of such ceramics. Ceramic disc brakes are an example of using a ceramic matrix composite material manufactured with a specific process.

Often times if a ceramic will be subjected to substantial mechanical loading it will undergo a process called Ice-templating. This process allows the finite control of the microstructure of the ceramic material and therefore the control of the mechanical properties. Ceramic engineers use this technique to tune the mechanical properties to their desired application. Specifically, Strength is increased when this technique is employed. Ice templating allows one to create macroscopic pores in a unidirectional arrangement. The applications of this oxide strengthening technique are important for solid oxide fuel cells and also water filtration devices. 

In order to process a sample through ice templating a few steps are required to be completed by the ceramicist. First an aqueous colloidal suspension must be prepared containing the dissolved ceramic powder, say Yttria Stablized Zirconia (YSZ). After the ceramic precursor is ensured to be evenly dispersed throughout the colloidal solution then next processing step may begin. At this point we have a pure solution containing our YSZ dissolved powder and aqueous water in the liquid state. The solution is then cooled on a platform that allows for unidirectional cooling like the one shown in the animation to the right. The solution sample of YSZ is cooled from the bottom to the top in a unidirectional fashion. This forces ice crystals to grow in compliance to the unidirectional cooling. Inside the solution, as it is cooling, these ice crystals force the dissolved YSZ particles to the solidification front of the solid-liquid interphase boundary. At this stage of the process we have pure ice crystals lined up in a unidirectional fashion alongside concentrated pockets of the YSZ colloidal particles. The next step of the process is the sublimation step. The sample is simultaneously heated and the pressure is reduced enough to force to ice crystals to subliminate, since the sample is also heated the YSZ pockets begin to anneal together too form the first macroscopically aligned ceramic microstuctures. The sample is then further sintered to confirm the evaporation of the residual water and the final consolidation of the ceramic microstructure.

During the execution of this technique a few variables can be controlled to influence the pore size and morphology of the microstructure. These important variables of the ice-templating technique are namely the initial solids loading of the colloid, the cooling rate, the sintering temperature and time length, and also it has been shown that certain additives can influence the micro-structural morphology during this process. A good understanding of these parameters is essential to understanding the relationships between processing, microstructure, and mechanical properties of anisotropically porous materials.

Some ceramics are semiconductors. Most of these are transition metal oxides that are II-VI semiconductors, such as zinc oxide.

While there are prospects of mass-producing blue LEDs from zinc oxide, ceramicists are most interested in the electrical properties that show grain boundary effects.

One of the most widely used of these is the varistor. These are devices that exhibit the property that resistance drops sharply at a certain threshold voltage. Once the voltage across the device reaches the threshold, there is a breakdown of the electrical structure in the vicinity of the grain boundaries, which results in its electrical resistance dropping from several megohms down to a few hundred ohms. The major advantage of these is that they can dissipate a lot of energy, and they self-reset – after the voltage across the device drops below the threshold, its resistance returns to being high.

This makes them ideal for surge-protection applications; as there is control over the threshold voltage and energy tolerance, they find use in all sorts of applications. The best demonstration of their ability can be found in electrical substations, where they are employed to protect the infrastructure from lightning strikes. They have rapid response, are low maintenance, and do not appreciably degrade from use, making them virtually ideal devices for this application.

Semiconducting ceramics are also employed as gas sensors. When various gases are passed over a polycrystalline ceramic, its electrical resistance changes. With tuning to the possible gas mixtures, very inexpensive devices can be produced.

Under some conditions, such as extremely low temperature, some ceramics exhibit high-temperature superconductivity. The reason for this is not understood, but there are two major families of superconducting ceramics.

Piezoelectricity, a link between electrical and mechanical response, is exhibited by a large number of ceramic materials, including the quartz used to measure time in watches and other electronics. Such devices use both properties of piezoelectrics, using electricity to produce a mechanical motion (powering the device) and then using this mechanical motion to produce electricity (generating a signal). The unit of time measured is the natural interval required for electricity to be converted into mechanical energy and back again.

The piezoelectric effect is generally stronger in materials that also exhibit pyroelectricity, and all pyroelectric materials are also piezoelectric. These materials can be used to inter convert between thermal, mechanical, or electrical energy; for instance, after synthesis in a furnace, a pyroelectric crystal allowed to cool under no applied stress generally builds up a static charge of thousands of volts. Such materials are used in motion sensors, where the tiny rise in temperature from a warm body entering the room is enough to produce a measurable voltage in the crystal.

In turn, pyroelectricity is seen most strongly in materials which also display the ferroelectric effect, in which a stable electric dipole can be oriented or reversed by applying an electrostatic field. Pyroelectricity is also a necessary consequence of ferroelectricity. This can be used to store information in ferroelectric capacitors, elements of ferroelectric RAM.

The most common such materials are lead zirconate titanate and barium titanate. Aside from the uses mentioned above, their strong piezoelectric response is exploited in the design of high-frequency loudspeakers, transducers for sonar, and actuators for atomic force and scanning tunneling microscopes.

Increases in temperature can cause grain boundaries to suddenly become insulating in some semiconducting ceramic materials, mostly mixtures of heavy metal titanates. The critical transition temperature can be adjusted over a wide range by variations in chemistry. In such materials, current will pass through the material until joule heating brings it to the transition temperature, at which point the circuit will be broken and current flow will cease. Such ceramics are used as self-controlled heating elements in, for example, the rear-window defrost circuits of automobiles.

At the transition temperature, the material's dielectric response becomes theoretically infinite. While a lack of temperature control would rule out any practical use of the material near its critical temperature, the dielectric effect remains exceptionally strong even at much higher temperatures. Titanates with critical temperatures far below room temperature have become synonymous with "ceramic" in the context of ceramic capacitors for just this reason.

Optically transparent materials focus on the response of a material to incoming lightwaves of a range of wavelengths. Frequency selective optical filters can be utilized to alter or enhance the brightness and contrast of a digital image. Guided lightwave transmission via frequency selective waveguides involves the emerging field of fiber optics and the ability of certain glassy compositions as a transmission medium for a range of frequencies simultaneously (multi-mode optical fiber) with little or no interference between competing wavelengths or frequencies. This resonant mode of energy and data transmission via electromagnetic (light) wave propagation, though low powered, is virtually lossless. Optical waveguides are used as components in Integrated optical circuits (e.g. light-emitting diodes, LEDs) or as the transmission medium in local and long haul optical communication systems. Also of value to the emerging materials scientist is the sensitivity of materials to radiation in the thermal infrared (IR) portion of the electromagnetic spectrum. This heat-seeking ability is responsible for such diverse optical phenomena as Night-vision and IR luminescence.

Thus, there is an increasing need in the military sector for high-strength, robust materials which have the capability to transmit light (electromagnetic waves) in the visible (0.4 – 0.7 micrometers) and mid-infrared (1 – 5 micrometers) regions of the spectrum. These materials are needed for applications requiring transparent armor, including next-generation high-speed missiles and pods, as well as protection against improvised explosive devices (IED).

In the 1960s, scientists at General Electric (GE) discovered that under the right manufacturing conditions, some ceramics, especially aluminium oxide (alumina), could be made translucent. These translucent materials were transparent enough to be used for containing the electrical plasma generated in high-pressure sodium street lamps. During the past two decades, additional types of transparent ceramics have been developed for applications such as nose cones for heat-seeking missiles, windows for fighter aircraft, and scintillation counters for computed tomography scanners.

In the early 1970s, Thomas Soules pioneered computer modeling of light transmission through translucent ceramic alumina. His model showed that microscopic pores in ceramic, mainly trapped at the junctions of microcrystalline grains, caused light to scatter and prevented true transparency. The volume fraction of these microscopic pores had to be less than 1% for high-quality optical transmission.

This is basically a particle size effect. Opacity results from the incoherent scattering of light at surfaces and interfaces. In addition to pores, most of the interfaces in a typical metal or ceramic object are in the form of grain boundaries which separate tiny regions of crystalline order. When the size of the scattering center (or grain boundary) is reduced below the size of the wavelength of the light being scattered, the scattering no longer occurs to any significant extent.

In the formation of polycrystalline materials (metals and ceramics) the size of the crystalline grains is determined largely by the size of the crystalline particles present in the raw material during formation (or pressing) of the object. Moreover, the size of the grain boundaries scales directly with particle size. Thus a reduction of the original particle size below the wavelength of visible light (~ 0.5 micrometers for shortwave violet) eliminates any light scattering, resulting in a transparent material.

Recently, Japanese scientists have developed techniques to produce ceramic parts that rival the transparency of traditional crystals (grown from a single seed) and exceed the fracture toughness of a single crystal. In particular, scientists at the Japanese firm Konoshima Ltd., a producer of ceramic construction materials and industrial chemicals, have been looking for markets for their transparent ceramics.

Livermore researchers realized that these ceramics might greatly benefit high-powered lasers used in the National Ignition Facility (NIF) Programs Directorate. In particular, a Livermore research team began to acquire advanced transparent ceramics from Konoshima to determine if they could meet the optical requirements needed for Livermore’s Solid-State Heat Capacity Laser (SSHCL). Livermore researchers have also been testing applications of these materials for applications such as advanced drivers for laser-driven fusion power plants.

A composite material of ceramic and metal is known as cermet.

Other ceramic materials, generally requiring greater purity in their make-up than those above, include forms of several chemical compounds, including:

For convenience, ceramic products are usually divided into four main types; these are shown below with some examples:

Frequently, the raw materials of modern ceramics do not include clays.
Those that do are classified as follows:

Ceramics can also be classified into three distinct material categories: 

Each one of these classes can be developed into unique material properties because ceramics tend to be crystalline.



Ceramic artifacts have an important role in archaeology for understanding the culture, technology and behavior of peoples of the past. They are among the most common artifacts to be found at an archaeological site, generally in the form of small fragments of broken pottery called sherds. Processing of collected sherds can be consistent with two main types of analysis: technical and traditional.

Traditional analysis involves sorting ceramic artifacts, sherds and larger fragments into specific types based on style, composition, manufacturing and morphology. By creating these typologies it is possible to distinguish between different cultural styles, the purpose of the ceramic and technological state of the people among other conclusions. In addition, by looking at stylistic changes of ceramics over time is it possible to separate (seriate) the ceramics into distinct diagnostic groups (assemblages). A comparison of ceramic artifacts with known dated assemblages allows for a chronological assignment of these pieces.

The technical approach to ceramic analysis involves a finer examination of the composition of ceramic artifacts and sherds to determine the source of the material and through this the possible manufacturing site. Key criteria are the composition of the clay and the temper used in the manufacture of the article under study: temper is a material added to the clay during the initial production stage, and it is used to aid the subsequent drying process. Types of temper include shell pieces, granite fragments and ground sherd pieces called 'grog'. Temper is usually identified by microscopic examination of the temper material. Clay identification is determined by a process of refiring the ceramic, and assigning a color to it using Munsell Soil Color notation. By estimating both the clay and temper compositions, and locating a region where both are known to occur, an assignment of the material source can be made. From the source assignment of the artifact further investigations can be made into the site of manufacture.




</doc>
<doc id="6459" url="https://en.wikipedia.org/wiki?curid=6459" title="Wu Xing">
Wu Xing

The Wu Xing (), also known as the Five Elements, Five Phases, the Five Agents, the Five Movements, Five Processes, the Five Steps/Stages and the Five Planets of significant gravity (Mars: 火, Mercury: 水, Jupiter: 木, Venus: 金, and Saturn: 土) is the short form of "Wǔ zhǒng liúxíng zhī qì" (五種流行之氣) or "the five types of chi dominating at different times". It is a fivefold conceptual scheme that many traditional Chinese fields used to explain a wide array of phenomena, from cosmic cycles to the interaction between internal organs, and from the succession of political regimes to the properties of medicinal drugs. The "Five Phases" are Wood (木 "mù"), Fire (火 "huǒ"), Earth (土 "tǔ"), Metal (金 "jīn"), and Water (水 "shuǐ"). This order of presentation is known as the "mutual generation" (相生 "xiāngshēng") sequence. In the order of "mutual overcoming" (相剋/相克 "xiāngkè"), they are Wood, Earth, Water, Fire, and Metal.

The system of five phases was used for describing interactions and relationships between phenomena. After it came to maturity in the second or first century BCE during the Han dynasty, this device was employed in many fields of early Chinese thought, including seemingly disparate fields such as geomancy or Feng shui, astrology, traditional Chinese medicine, music, military strategy, and martial arts. The system is still used as a reference in some forms of complementary and alternative medicine and martial arts.

Xing () of 'Wu Xing' means moving; a planet is called a 'moving star' () in Chinese. Wu Xing () originally refers to the five major planets (Jupiter, Saturn, Mercury, Mars, Venus) that create five dimensions of earth life. "Wu Xing" is also widely translated as "Five Elements" and this is used extensively by many including practitioners of Five Element acupuncture. This translation arose by false analogy with the Western system of the four elements. Whereas the classical Greek elements were concerned with substances or natural qualities, the Chinese "xíng" are "primarily concerned with process and change," hence the common translation as "phases" or "agents". By the same token, "Mù" is thought of as "Tree" rather than "Wood". The word 'element' is thus used within the context of Chinese medicine with a different meaning to its usual meaning.

It should be recognized that the word "phase", although commonly preferred, is not perfect. "Phase" is a better translation for the five "seasons" (五運 Wǔ Yùn) mentioned below, and so "agents" or "processes" might be preferred for the primary term "xíng". Manfred Porkert attempts to resolve this by using "Evolutive Phase" for 五行 "Wǔ Xíng" and "Circuit Phase" for 五運 "Wǔ Yùn", but these terms are unwieldy.

Some of the Mawangdui Silk Texts (no later than 168 BC) also present the Wu Xing as "five virtues" or types of activities. Within Chinese medicine texts the Wu Xing are also referred to as Wu Yun (; wǔ yùn) or a combination of the two characters (Wu Xing-Yun) these emphasise the correspondence of five elements to five 'seasons' (four seasons plus one). Another tradition refers to the "Wǔ Xíng" as "Wǔ Dé" (五德), the .

The five phases are around 72 days each and are usually used to describe the state in nature:

The doctrine of five phases describes two cycles, a generating or creation (生, "shēng") cycle, also known as "mother-son", and an overcoming or destruction (剋/克, "kè") cycle, also known as "grandfather-grandson", of interactions between the phases. Within Chinese medicine the effects of these two main relations are further elaborated:

The common memory jogs, which help to remind in what order the phases are:


Other common words for this cycle include "begets", "engenders" and "mothers".


This cycle might also be called "controls", "restrains" or "fathers".

According to Wu Xing theory, the structure of the cosmos mirrors the five phases. Each phase has a complex series of associations with different aspects of nature, as can be seen in the following table. In the ancient Chinese form of geomancy, known as Feng Shui, practitioners all based their art and system on the five phases (Wu Xing). All of these phases are represented within the trigrams. Associated with these phases are colors, seasons and shapes; all of which are interacting with each other.

Based on a particular directional energy flow from one phase to the next, the interaction can be expansive, destructive, or exhaustive. A proper knowledge of each aspect of energy flow will enable the Feng Shui practitioner to apply certain cures or rearrangement of energy in a way they believe to be beneficial for the receiver of the Feng Shui Treatment.

According to the Warring States period political philosopher Zou Yan 鄒衍 (c. 305–240 BCE), each of the five elements possesses a personified "virtue" ("de" 德), which indicates the foreordained destiny ("yun" 運) of a dynasty; accordingly, the cyclic succession of the elements also indicates dynastic transitions. Zou Yan claims that the Mandate of Heaven sanctions the legitimacy of a dynasty by sending self-manifesting auspicious signs in the ritual color (yellow, blue, white, red, and black) that matches the element of the new dynasty (Earth, Wood, Metal, Fire, and Water). From the Qin dynasty onward, most Chinese dynasties invoked the theory of the Five Elements to legitimize their reign.

The interdependence of zang-fu networks in the body was said to be a circle of five things, and so mapped by the Chinese doctors onto the five phases.

In Ziwei, "neiyin" (纳音) or the method of divination is the further classification of the Five Elements into 60 "ming" (命), or life orders, based on the ganzhi. Similar to the astrology zodiac, the ming is used by fortune-tellers to analyse a person's personality and future fate.

The "Yuèlìng" chapter (月令篇) of the "Lǐjì" (禮記) and the "Huáinánzǐ" (淮南子) make the following correlations:


T'ai chi ch'uan uses the five elements to designate different directions, positions or footwork patterns. Either forward, backward, left, right and centre, or three steps forward (attack) and two steps back (retreat).

"The Five Steps ( wǔ bù):"

Xingyiquan uses the five elements metaphorically to represent five different states of combat.

There are spring, summer, fall, and winter teas. The perennial tea ceremony includes four tea settings (茶席) and a tea master (司茶). Each tea setting is arranged and stands for the four directions (north, south, east, and west). A vase of the seasons' flowers is put on tea table. The tea settings are:






</doc>
<doc id="6462" url="https://en.wikipedia.org/wiki?curid=6462" title="Church of Christ, Scientist">
Church of Christ, Scientist

The Church of Christ, Scientist was founded in 1879 in Boston, Massachusetts, by Mary Baker Eddy, author of "Science and Health with Key to the Scriptures," and founder of Christian Science. The church was founded "to commemorate the word and works of [Christ Jesus]" and "reinstate primitive Christianity and its lost element of healing". Sunday services are held throughout the year and weekly testimony meetings are held on Wednesday evenings, where following brief readings from the Bible and the Christian Science textbook, those in attendance are invited to give testimonies of healing brought about through Christian Science prayer.

In the early decades of the 20th century, Christian Science churches sprang up in communities around the world, though in the last several decades of that century, there was a marked decline in membership, except in Africa, where there has been growth. Headquartered in Boston, the church does not officially report membership, and estimates as to worldwide membership range between about 400,000 to less than 100,000.

The church was incorporated by Mary Baker Eddy in 1879 following a claimed personal healing in 1866, which she said resulted from reading the Bible. The Bible and Eddy's textbook on Christian healing, "Science and Health with Key to the Scriptures", are together the church's key doctrinal sources and have been ordained as the church's "dual impersonal pastor".

The First Church of Christ, Scientist, is widely known for its publications, especially "The Christian Science Monitor", a weekly newspaper published internationally in print and online. The seal of Christian Science is a cross and crown with the words, "Heal the sick, raise the dead, cleanse the lepers, cast out demons," and is a registered trademark of the church.

The Church has collected over 50,000 testimonies of incidents that it considers healing through Christian Science treatment alone. While most of these testimonies represent ailments neither diagnosed nor treated by medical professionals, the Church requires three other people to vouch for any testimony published in its official organ, the "Christian Science Journal"; verifiers say that they witnessed the healing or know the testifier well.

Christian Scientists may take an intensive two-week "Primary" class from an authorized Christian Science teacher. Those who wish to become "Journal-listed" (accredited) practitioners, devoting themselves full-time to the practice of healing, must first have Primary class instruction. When they have what the church regards as a record of healing, they may submit their names for publication in the directory of practitioners and teachers in the "Christian Science Journal." A practitioner who has been listed for at least three years' may apply for "Normal" class instruction, given once every three years. Those who receive a certificate are authorized to teach. Both Primary and Normal classes are based on the Bible and the writings of Mary Baker Eddy. The Primary class focuses on the chapter, "Recapitulation" in "Science and Health with Key to the Scriptures". This chapter uses the Socratic method of teaching and contains the "Scientific Statement of Being". The "Normal" class focuses on the platform of Christian Science, contained on pages 330-340 of "Science and Health."

The First Church of Christ, Scientist is the legal title of the Mother Church and administrative headquarters of the Christian Science Church. The complex is located in a plaza alongside Huntington Avenue in the Back Bay neighborhood of Boston, Massachusetts.

The church itself was built in 1894, and an annex larger in footprint than the original structure was added in 1906. It boasts one of the world's largest pipe organs, built by the Aeolian-Skinner Company of Boston. The Mary Baker Eddy Library for the Betterment of Humanity is housed in an 11-story structure originally built for The Christian Science Publishing Society constructed between 1932 and 1934, and the present plaza was constructed in the late 1960s and early 1970s to include a 28 story administration building, a colonnade, and a reflecting pool with fountain, designed by Araldo Cossutta of I. M. Pei and Partners (now Pei Cobb Freed).

Branch churches of The Mother Church may take the title of "First Church of Christ, Scientist"; Second; but the article "The" must not be used, presumably to concede the primacy of the Boston Mother Church.

An international newspaper, the "Christian Science Monitor", founded by Eddy in 1908 and winner of seven Pulitzer prizes, is published by the church through the Christian Science Publishing Society.

Branch Christian Science churches and Christian Science societies are subordinate to the Mother Church, but are self-governed. They have their own by-laws, bank accounts, assets and officers, but in order to be recognised must abide by the by-laws in the "Manual of The Mother Church". Church services are regulated by the "Manual," the set of by-laws written by Eddy, that establishes the church organization and explains the duties and responsibilities of members, officers, practitioners, teachers and nurses; and establishes rules for discipline and other aspects of church business.

The Christian Science Board of Directors is a five-person executive entity created by Mary Baker Eddy to conduct the business of the Christian Science Church under the terms defined in the by-laws of the "Church Manual". Its functions and restrictions are defined by the "Manual."

The Board (occasionally CSBD or the BoD for short) also includes functions defined by a Deed of Trust written by Eddy (one of several, in fact) under which it consisted of four persons, though she later expanded the Board to five persons, thus in effect leaving one of its members out of Deed functions. This later bore on a dispute during the 1920s, known as the Great Litigation in CS circles, pivoting on whether the CSBD could remove trustees of the Christian Science Publishing Society or whether the CSPS trustees were established independently.

While Eddy's Manual established limited executive functions under the rule of law in place of a traditional hierarchy, the controversial 1991 publication of a book by Bliss Knapp led the then Board of Directors to make the unusual affidavit during a suit over Knapp's estate that neither acts by it violating the "Manual," nor acts refraining from required action, constituted violations of the "Manual". A traditionally-minded minority held that the Board's act in publishing Knapp's book constituted a fundamental violation of several by-laws and its legal trust, automatically mandating the offending Board members' resignations under Article I, Section 9.

Another minority believed that Eddy intended various requirements for her consent (in their view, "estoppels") to effect the church's dissolution on her death, since they could no longer be followed literally. Ironically, one of the stronger arguments against this position came from an individual highly respected by their theological quarter, Bliss Knapp, who claimed that Eddy understood through her lawyer that these consent clauses would not hinder normal operation after her decease.

Churches worldwide hold a one-hour service each Sunday, consisting of hymns, prayer, and currently, readings from the "King James Version" (KJV) of the Bible (although there is no requirement that this version of the Bible be used) and "Science and Health with Key to the Scriptures". These readings are the weekly Lesson-Sermon, which is read aloud at all Sunday services in all Christian Science churches worldwide, and is studied by individuals at home throughout the preceding week. The Lesson, as it is informally called, is compiled by a committee at The Mother Church, and is usually made up of six sections, each of which consists of passages from the Bible (read by the Second Reader) and passages from "Science and Health" (read by the First Reader).

Eddy selected 26 subjects for the Lesson-Sermon. These Lessons run in continuous rotation in the order she established, hence each subject is studied twice a year. In years in which there are 53 Sundays, the topic "Christ Jesus" occurs a third time, in December. In addition, there is a special, shortened Lesson-Sermon for Thanksgiving Day. Branch churches outside the United States may schedule their Thanksgiving service when convenient for them, most choosing a day in October or November, and the Thanksgiving Day proclamation by the United States president, may be omitted.

Because there are no clergy in the church, branch church Sunday services are conducted by two Readers: the First Reader, who reads passages from Science and Health, and the Second Reader, who reads passages from the Bible. First Readers determine the beginning "scriptural selection", hymns to be sung on Sundays, and the benediction. The vast majority of the service is the reading of the weekly Bible lesson supplied by Boston, and the order of the service set out by the Manual. To be elected the First Reader in one's branch church is one of the highest and most important positions the lay Christian Scientist may aspire to.

Churches also hold a one-hour Wednesday evening testimony meeting, with similar readings, after which, those in attendance are invited to share accounts of healing through prayer. At these services, the First Reader reads passages from the Bible and Science and Health. Departing from denominational practice for over 120 years, English language churches may now choose alternate Bible translations at these services (i.e. Phillips).

Branch churches also sponsor annual public talks (called lectures) given by speakers selected annually by the Board of Lectureship in Boston.

Beginning in the mid-1980s, church executives undertook a controversial and ambitious foray into electronic broadcast media. The first significant effort was to create a weekly half-hour syndicated television program, The Christian Science Monitor Reports. "Monitor Reports" was anchored in its first season by newspaper veteran Rob Nelson. He was replaced in the second by the "Christian Science Monitor"'s former Moscow correspondent, David Willis. The program was usually broadcast by independent stations — often at odd hours.

In 1988, Monitor Reports was supplanted by a nightly half-hour news show, World Monitor, which was broadcast by the Discovery Channel. The program was anchored by veteran journalist John Hart. The Church then purchased a Boston cable TV station for elaborate in-house programming production. In parallel, the church purchased a shortwave radio station and syndicated radio production to National Public Radio. However, revenues fell far short of optimistic predictions by church managers, who had ignored early warnings by members and media experts.

In October 1991, after a series of conflicts over the boundaries between Christian Science teachings and his journalistic independence, John Hart resigned. The Monitor Channel went off the air in June 1992. Most of the other operations closed in well under a decade. Public accounts in both the mainstream and trade media reported that the church lost approximately $250 million on these ventures.

The hundreds of millions lost on broadcasting brought the church to the brink of bankruptcy. However, with the 1991 publication of "The Destiny of The Mother Church" by the late Bliss Knapp, the church secured a $90 million bequest from the Knapp trust. The trust dictated that the book be published as "Authorized Literature," with neither modification nor comment. Historically, the church had censured Knapp for deviating at several points from Eddy's teaching, and had refused to publish the work. The church's archivist, fired in anticipation of the book's publication, wrote to branch churches to inform them of the book's history. Many Christian Scientists thought the book violated the church's by-laws, and the editors of the church's religious periodicals and several other church employees resigned in protest. Alternate beneficiaries subsequently sued to contest the church's claim it had complied fully with the will's terms, and the church ultimately received only half of the original sum.

The fallout of the broadcasting debacle also sparked a minor revolt among some prominent church members. In late 1993, a group of Christian Scientists filed suit against the Board of Directors, alleging a willful disregard for the Manual of the Mother Church in its financial dealings. The suit was thrown out by the Supreme Judicial Court of Massachusetts in 1997, but a lingering discontent with the church's financial matters persists to this day.

In spite of its early meteoric rise, church membership has declined over the past eight decades, according to the church's former treasurer, J. Edward Odegaard. Though the Church is prohibited by the Manual from publishing membership figures, the number of branch churches in the United States has fallen steadily since World War II. In 2009, for the first time in church history, more new members came from Africa than the United States.

In 2005, the "Boston Globe" reported that the church was considering consolidating Boston operations into fewer buildings and leasing out space in buildings it owned. Church official Philip G. Davis noted that the administration and Colonnade buildings had not been fully used for many years and that vacancy increased after staff reductions in 2004. The church posted an $8 million financial loss in fiscal 2003, and in 2004 cut 125 jobs, a quarter of the staff, at the "Christian Science Monitor". Conversely, Davis noted that "the financial situation right now is excellent" and stated that the church was not facing financial problems.




</doc>
<doc id="6466" url="https://en.wikipedia.org/wiki?curid=6466" title="Connecticut">
Connecticut

Connecticut () is the southernmost state in the New England region of the United States. As of the 2010 Census, it has the highest per-capita income, Human Development Index (0.962), and median household income in the United States. It is bordered by Rhode Island to the east, Massachusetts to the north, New York to the west, and Long Island Sound to the south. Its capital is Hartford and its most populous city is Bridgeport. It is part of New England, although portions of it are often grouped with New York and New Jersey as the Tri-state area. The state is named for the Connecticut River which approximately bisects the state. The word "Connecticut" is derived from various anglicized spellings of an Algonquian word for "long tidal river".

Connecticut's first European settlers were Dutchmen who established a small, short-lived settlement called Fort Hoop in Hartford at the confluence of the Park and Connecticut Rivers. Half of Connecticut was initially part of the Dutch colony New Netherland, which included much of the land between the Connecticut and Delaware Rivers, although the first major settlements were established in the 1630s by the English. Thomas Hooker led a band of followers from the Massachusetts Bay Colony and founded the Connecticut Colony; other settlers from Massachusetts founded the Saybrook Colony and the New Haven Colony. The Connecticut and New Haven colonies established documents of Fundamental Orders, considered the first constitutions in America. In 1662, the three colonies were merged under a royal charter, making Connecticut a crown colony. This was one of the Thirteen Colonies which rejected British rule in the American Revolution.

Connecticut is the third smallest state by area, the 29th most populous, and the fourth most densely populated of the 50 states. It is known as the "Constitution State", the "Nutmeg State", the "Provisions State", and the "Land of Steady Habits". It was influential in the development of the federal government of the United States (see Connecticut Compromise).

The Connecticut River, Thames River, and ports along Long Island Sound have given Connecticut a strong maritime tradition which continues today. The state also has a long history of hosting the financial services industry, including insurance companies in Hartford and hedge funds in Fairfield County.

Connecticut is bordered on the south by Long Island Sound, on the west by New York, on the north by Massachusetts, and on the east by Rhode Island. The state capital and fourth largest city is Hartford, and other major cities and towns (by population) include Bridgeport, New Haven, Stamford, Waterbury, Norwalk, Danbury, New Britain, Greenwich, and Bristol. Connecticut is slightly larger than the country of Montenegro. There are 169 incorporated towns in Connecticut.
The highest peak in Connecticut is Bear Mountain in Salisbury in the northwest corner of the state. The highest point is just east of where Connecticut, Massachusetts, and New York meet (42° 3' N; 73° 29' W), on the southern slope of Mount Frissell, whose peak lies nearby in Massachusetts. At the opposite extreme, many of the coastal towns have areas that are less than 20 feet (6 m) above sea level.

Connecticut has a long maritime history and a reputation based on that history—yet the state has no direct oceanfront (technically speaking). The coast of Connecticut sits on Long Island Sound, which is an estuary. The state's access to the open Atlantic Ocean is both to the west (toward New York City) and to the east (toward the "race" near Rhode Island). This situation provides many safe harbors from ocean storms, and many transatlantic ships seek anchor inside Long Island Sound when tropical cyclones pass off the upper East Coast.

The Connecticut River cuts through the center of the state, flowing into Long Island Sound. The most populous metropolitan region centered within the state lies in the Connecticut River Valley. Despite Connecticut's relatively small size, it features wide regional variations in its landscape; for example, in the northwestern Litchfield Hills, it features rolling mountains and horse farms, whereas in areas to the east of New Haven along the coast, the landscape features coastal marshes, beaches, and large scale maritime activities.

Connecticut's rural areas and small towns in the northeast and northwest corners of the state contrast sharply with its industrial cities such as Stamford, Bridgeport, and New Haven, located along the coastal highways from the New York border to New London, then northward up the Connecticut River to Hartford. Many towns in northeastern and northwestern Connecticut center around a green, such as the Litchfield Green, Lebanon Green (the largest in the state), and Wethersfield Green (the oldest in the state). Near the green typically stand historical visual symbols of New England towns, such as a white church, a colonial meeting house, a colonial tavern or inn, several colonial houses, and so on, establishing a scenic historical appearance maintained for both historic preservation and tourism. Many of the areas in southern and coastal Connecticut have been built up and rebuilt over the years, and look less visually like traditional New England.

The northern boundary of the state with Massachusetts is marked by the Southwick Jog or Granby Notch, an approximately square detour into Connecticut. The origin of this anomaly is clearly established in a long line of disputes and temporary agreements which were finally concluded in 1804, when southern Southwick's residents sought to leave Massachusetts, and the town was split in half.

The southwestern border of Connecticut where it abuts New York State is marked by a panhandle in Fairfield County, containing the towns of Greenwich, Stamford, New Canaan, Darien, and parts of Norwalk and Wilton. This irregularity in the boundary is the result of territorial disputes in the late 17th century, culminating with New York giving up its claim to the area, whose residents considered themselves part of Connecticut, in exchange for an equivalent area extending northwards from Ridgefield to the Massachusetts border, as well as undisputed claim to Rye, New York.
Areas maintained by the National Park Service include Appalachian National Scenic Trail, Quinebaug and Shetucket Rivers Valley National Heritage Corridor, and Weir Farm National Historic Site.

Most of Connecticut lies at the southern end of the humid continental climate, with cold winters with moderate snowfall and hot, humid summers. Far southern and coastal Connecticut is the rough transition zone from the cold continental climates of the north to the temperate climates to the south (called subtropical in some climate classifications). As such, far southern and coastal Connecticut has milder winters with a mix of rain and infrequent snow, and the typical hot and humid summers found on the middle and lower East Coast. 

Connecticut sees a fairly even precipitation pattern with rainfall/snowfall spread throughout the 12 months. Connecticut averages 56% of possible sunshine (higher than the USA average), averaging 2,400 hours of sunshine annually.

Early spring (April) can range from slightly cool (40's to low 50's F) to warm (65 to 70 F), while mid and late spring (late April/May) is warm. By late May, the building Bermuda High creates a southerly flow of warm and humid tropical air, bringing hot weather conditions throughout the state, with average highs in New London of and in Windsor Locks at the peak of summer in late July. On occasion, heat waves with highs from 90 to 100 F occur across Connecticut. Although summers are sunny in Connecticut, quick moving summer thunderstorms can bring brief downpours with thunder and lightning. Occasionally these thunderstorms can be severe, and the state usually averages one tornado per year. During hurricane season, the remains of tropical cyclones occasionally affect the region, though a direct hit is rare.

Weather commonly associated with the fall season typically begins in October and lasts to the first days of December. Daily high temperatures in October and November range from the 50s to 60s (Fahrenheit) with nights in the 40s and upper 30s. Colorful foliage begins across northern parts of the state in early October and moves south and east reaching southeast Connecticut by early November. Far southern and coastal areas, however, have more oak and hickory trees (and fewer maples) and are often less colorful than areas to the north. By December daytime highs are in the 40's F for much of the state, and average overnight lows are below freezing.

Winters (December through mid-March) are generally cold from south to north in Connecticut. The coldest month (January) has average high temperatures ranging from in the coastal lowlands to in the inland and northern portions on the state. The average yearly snowfall ranges from about in the higher elevations of the northern portion of the state to only along the southeast coast of Connecticut (Branford to Groton). Generally, any locale north or west of Interstate 84 receives the most snow, during a storm, and throughout the season. Most of Connecticut has less than 60 days of snow cover. Snow usually falls from late November to late March in the northern part of the state, and from early December to mid-March in the southern and coastal parts of the state.

Connecticut's record high temperature is which occurred in Danbury on July 15, 1995; the record low is which occurred in the Northwest Hills Falls Village on February 16, 1943, and Coventry on January 22, 1961.
Forests consist of a mix of Northeastern coastal forests of Oak in southern areas of the state, to the upland New England-Acadian forests in the northwestern parts of the state. Mountain Laurel (Kalmia latifolia) is the state flower and is native to low ridges in several parts of Connecticut. Rosebay Rhododendron (Rhododendron maximum) is also native to eastern uplands of Connecticut and Pachaug State Forest is home to the Rhododendron Sanctuary Trail. Atlantic white cedar (Chamaecyparis thyoides), is found in wetlands in the southern parts of the state. Connecticut has one native cactus (Opuntia humifusa), found in sandy coastal areas and low hillsides. Several types of beach grasses and wildflowers are also native to Connecticut. Connecticut spans USDA Plant Hardiness Zones 5b to 7a. Coastal Connecticut is the broad transition zone where more southern and subtropical plants are cultivated. In some coastal communities, Magnolia grandiflora (southern magnolia), Crape Myrtles, scrub palms (Sabal minor), and other broadleaved evergreens are cultivated in small numbers.

The name Connecticut is derived from the Algonquian word that has been translated as "long tidal river" and "upon the long river", referring to the Connecticut River. The Connecticut region was inhabited by multiple Indian tribes before European settlement and colonization, including the Mohegans, the Pequots, and the Paugusetts.

The first European explorer in Connecticut was Dutchman Adriaen Block, who explored the region in 1614. Dutch fur traders then sailed up the Connecticut River, which they called Versche Rivier ("Fresh River"), and built a fort at Dutch Point in Hartford that they named "House of Hope" ().

The Connecticut Colony was originally a number of separate, smaller settlements at Windsor, Wethersfield, Saybrook, Hartford, and New Haven. The first English settlers came in 1633 and settled at Windsor, and then at Wethersfield the following year. John Winthrop the Younger of Massachusetts received a commission to create Saybrook Colony at the mouth of the Connecticut River in 1635.

The main body of settlers came in one large group in 1636. They were Puritans from Massachusetts Bay Colony led by Thomas Hooker, who established the Connecticut Colony at Hartford. The Quinnipiack Colony was established by John Davenport, Theophilus Eaton, and others at New Haven in March 1638. The New Haven Colony had its own constitution called "The Fundamental Agreement of the New Haven Colony", signed on June 4, 1639.

The settlements were established without official sanction of the English Crown, and each was an independent political entity. In 1662, Winthrop traveled to England and obtained a charter from Charles II which united the settlements of Connecticut. Historically important colonial settlements included Windsor (1633), Wethersfield (1634), Saybrook (1635), Hartford (1636), New Haven (1638), Fairfield (1639), Guilford (1639), Milford (1639), Stratford (1639), Farmington (1640), Stamford (1641), and New London (1646).

The Pequot War marked the first major clash between colonists and Indians in New England. The Pequots reacted with increasing aggression to Colonial settlements in their territory—while simultaneously taking lands from the Narragansett and Mohegan tribes. Settlers responded to a murder in 1636 with a raid on a Pequot village on Block Island; the Pequots laid siege to Saybrook Colony's garrison that autumn, then raided Wethersfield in the spring of 1637. Colonists declared war on the Pequots, organized a band of militia and allies from the Mohegan and Narragansett tribes, and attacked a Pequot village on the Mystic River, with death toll estimates ranging between 300 and 700 Pequots. After suffering another major loss at a battle in Fairfield, the Pequots asked for a truce and peace terms.

The western boundaries of Connecticut have been subject to change over time. The Hartford Treaty with the Dutch was signed on September 19, 1650, but it was never ratified by the British. According to it, the western boundary of Connecticut ran north from Greenwich Bay for a distance of , "provided the said line come not within 10 miles of Hudson River." This agreement was observed by both sides until war erupted between England and The Netherlands in 1652. Conflict continued concerning colonial limits until the Duke of York captured New Netherland in 1664.

On the other hand, Connecticut's original Charter in 1662 granted it all the land to the "South Sea"—that is, to the Pacific Ocean. Most Colonial royal grants were for long east-west strips. Connecticut took its grant seriously and established a ninth county between the Susquehanna River and Delaware River named Westmoreland County. This resulted in the brief Pennamite Wars with Pennsylvania.

Yale College was established in 1701, providing Connecticut with an important institution to educate clergy and civil leaders. The Congregational church dominated religious life in the colony and, by extension, town affairs in many parts.

Connecticut designated four delegates to the Second Continental Congress who signed the Declaration of Independence: Samuel Huntington, Roger Sherman, William Williams, and Oliver Wolcott.

Connecticut's legislature authorized the outfitting of six new regiments in 1775, in the wake of the clashes between British regulars and Massachusetts militia at Lexington and Concord. There were some 1,200 Connecticut troops on hand at the Battle of Bunker Hill in June 1775.

In 1777, the British got word of Continental Army supplies in Danbury, and they landed an expeditionary force of some 2,000 troops in Westport. This force then marched to Danbury and destroyed homes and much of the depot. Continental Army troops and militia led by General David Wooster and General Benedict Arnold engaged them on their return march at Ridgefield in 1777.

For the winter of 1778–79, General George Washington decided to split the Continental Army into three divisions encircling New York City, where British General Sir Henry Clinton had taken up winter quarters. Major General Israel Putnam chose Redding as the winter encampment quarters for some 3,000 regulars and militia under his command. The Redding encampment allowed Putnam's soldiers to guard the replenished supply depot in Danbury and to support any operations along Long Island Sound and the Hudson River Valley. Some of the men were veterans of the winter encampment at Valley Forge, Pennsylvania the previous winter. Soldiers at the Redding camp endured supply shortages, cold temperatures, and significant snow, with some historians dubbing the encampment "Connecticut's Valley Forge".

The state was also the launching site for a number of raids against Long Island orchestrated by Samuel Holden Parsons and Benjamin Tallmadge, and provided men and material for the war effort, especially to Washington's army outside New York City. General William Tryon raided the Connecticut coast in July 1779, focusing on New Haven, Norwalk, and Fairfield. New London and Groton Heights were raided in September 1781 by Benedict Arnold, who had turned traitor to the British.

Connecticut ratified the U.S. Constitution on January 9, 1788, becoming the fifth state. The state prospered during the era following the American Revolution, as mills and textile factories were built and seaports flourished from trade and fisheries.

In 1786, Connecticut ceded territory to the U.S. government that became part of the Northwest Territory. The state retained land extending across the northern part of present-day Ohio called the Connecticut Western Reserve. The Western Reserve section was settled largely by people from Connecticut, and they brought Connecticut place names to Ohio.

Connecticut made agreements with Pennsylvania and New York which extinguished the land claims within those states' boundaries and created the Connecticut Panhandle. The state then ceded the Western Reserve in 1800 to the federal government, which brought it to its present boundaries (other than minor adjustments with Massachusetts).

The British blockade during the War of 1812 hurt exports and bolstered the influence of Federalists who opposed the war. The cessation of imports from Britain stimulated the construction of factories to manufacture textiles and machinery. Connecticut came to be recognized as a major center for manufacturing, due in part to the inventions of Eli Whitney and other early innovators of the Industrial Revolution.

The state was known for its political conservatism, typified by its Federalist party and the Yale College of Timothy Dwight. The foremost intellectuals were Dwight and Noah Webster, who compiled his great dictionary in New Haven. Religious tensions polarized the state, as the Congregational Church struggled to maintain traditional viewpoints, in alliance with the Federalists. The failure of the Hartford Convention in 1814 hurt the Federalist cause, with the Democratic-Republican Party gaining control in 1817.

Connecticut had been governed under the "Fundamental Orders" since 1639, but the state adopted a new constitution in 1818.

Connecticut manufacturers played a major role in supplying the Union forces with weapons and supplies during the Civil War. The state furnished 55,000 men, formed into thirty full regiments of infantry, including two in the U.S. Colored Troops, with several Connecticut men becoming generals. The Navy attracted 250 officers and 2,100 men, and Glastonbury native Gideon Welles was Secretary of the Navy. James H. Ward of Hartford was the first U.S. Naval Officer killed in the Civil War. Connecticut casualties included 2,088 killed in combat, 2,801 dying from disease, and 689 dying in Confederate prison camps.

A surge of national unity in 1861 brought thousands flocking to the colors from every town and city. However, as the war became a crusade to end slavery, many Democrats (especially Irish Catholics) pulled back. The Democrats took a pro-slavery position and included many Copperheads willing to let the South secede. The intensely fought 1863 election for governor was narrowly won by the Republicans.

Connecticut's extensive industry, dense population, flat terrain, and wealth encouraged the construction of railroads starting in 1839. By 1840, of line were in operation, growing to in 1850 and in 1860.

The New York, New Haven and Hartford Railroad, called the "New Haven" or "The Consolidated", became the dominant Connecticut railroad company after 1872. J. P. Morgan began financing the major New England railroads in the 1890s, dividing territory so that they would not compete. The New Haven purchased 50 smaller companies, including steamship lines, and built a network of light rails (electrified trolleys) that provided inter-urban transportation for all of southern New England. By 1912, the New Haven operated over of track with 120,000 employees.

In 1875, the first telephone exchange in the world was established in New Haven.

When World War I broke out in 1914, Connecticut became a major supplier of weaponry to the U.S. military; by 1918, 80% of the state's industries were producing goods for the war effort. Remington Arms in Bridgeport produced half the small-arms cartridges used by the U.S. Army, with other major suppliers including Winchester in New Haven and Colt in Hartford.

Connecticut was also an important U.S. Navy supplier, with Electric Boat receiving orders for 85 submarines, Lake Torpedo Boat building more than 20 subs, and the Groton Iron Works building freighters. On June 21, 1916, the U.S. Navy made Groton the site for its East Coast submarine base and school.

The state enthusiastically supported the American war effort in 1917 and 1918, with large purchases of war bonds, a further expansion of industry, and an emphasis on increasing food production on the farms. Thousands of state, local, and volunteer groups mobilized for the war effort and were coordinated by the Connecticut State Council of Defense. Manufacturers wrestled with manpower shortages; Waterbury's American Brass and Manufacturing Company was running at half capacity, so the federal government agreed to furlough soldiers to work there.

In 1919, J. Henry Roraback started the Connecticut Light & Power Co. which became the state's dominant electric utility. In 1925, Frederick Rentschler spurred the creation of Pratt & Whitney in Hartford to develop engines for aircraft; the company became an important military supplier in World War II and one of the three major manufacturers of jet engines in the world.

On September 21, 1938, the most destructive storm in New England history struck eastern Connecticut, killing hundreds of people. The eye of the "Long Island Express" passed just west of New Haven and devastated the Connecticut shoreline between Old Saybrook and Stonington from the full force of wind and waves, even though they had partial protection by Long Island. The hurricane caused extensive damage to infrastructure, homes, and businesses. In New London, a 500-foot (150 m) sailing ship was driven into a warehouse complex, causing a major fire. Heavy rainfall caused the Connecticut River to flood downtown Hartford and East Hartford. An estimated 50,000 trees fell onto roadways.

The advent of lend-lease in support of Britain helped lift Connecticut from the Great Depression, with the state a major production center for weaponry and supplies used in World War II. Connecticut manufactured 4.1% of total U.S. military armaments produced during World War II, ranking ninth among the 48 states, with major factories including Colt for firearms, Pratt & Whitney for aircraft engines, Chance Vought for fighter planes, Hamilton Standard for propellers, and Electric Boat for submarines and PT boats. In Bridgeport, General Electric produced a significant new weapon to combat tanks: the bazooka.

On May 13, 1940, Igor Sikorsky made an untethered flight of the first practical helicopter. The helicopter saw limited use in World War II, but future military production made Sikorsky Aircraft's Stratford plant Connecticut's largest single manufacturing site by the start of the 21st century.

Connecticut lost some wartime factories following the end of hostilities, but the state shared in a general post-war expansion that included the construction of highways and resulting in middle-class growth in suburban areas.

Prescott Bush represented Connecticut in the U.S. Senate from 1952 to 1963; his son George H.W. Bush and grandson George W. Bush both became Presidents of the United States. In 1965, Connecticut ratified its current constitution, replacing the document that had served since 1818.

In 1968, commercial operation began for the Connecticut Yankee Nuclear Power Plant in East Haddam; in 1970, the Millstone Nuclear Power Station began operations in Waterford. In 1974, Connecticut elected Democratic Governor Ella T. Grasso, who became the first woman in any state to be elected governor.

Connecticut's dependence on the defense industry posed an economic challenge at the end of the Cold War. The resulting budget crisis helped elect Lowell Weicker as governor on a third-party ticket in 1990. Weicker's remedy was a state income tax which proved effective in balancing the budget, but only for the short-term. He did not run for a second term, in part because of this politically unpopular move.

In 1992, initial construction was completed on Foxwoods Casino at the Mashantucket Pequots reservation in eastern Connecticut, which became the largest casino in the Western Hemisphere. Mohegan Sun followed four years later.

In 2000, presidential candidate Al Gore chose Senator Joe Lieberman as his running mate, marking the first time that a major party presidential ticket included someone of the Jewish faith. Gore and Lieberman fell five votes short of George W. Bush and Dick Cheney in the Electoral College.
In the terrorist attacks of September 11, 2001, 65 state residents were killed, mostly Fairfield County residents who were working in the World Trade Center.
In 2004, Republican Governor John G. Rowland resigned during a corruption investigation, later pleading guilty to federal charges.
Connecticut was hit by three major storms in just over 14 months in 2011 and 2012, with all three causing extensive property damage and electric outages. Hurricane Irene struck Connecticut August 28, and damage totaled $235 million. Two months later, the "Halloween nor'easter" dropped extensive snow onto trees, resulting in snapped branches and trunks that damaged power lines; some areas were without electricity for 11 days. Hurricane Sandy had tropical storm-force winds when it reached Connecticut October 29, 2012. Sandy's winds drove storm surges into streets and cut power to 98% of homes and businesses, with more than $360 million in damage.

On December 14, 2012, Adam Lanza shot and killed 26 people at Sandy Hook Elementary School in Newtown, and then killed himself. The massacre spurred renewed efforts by activists for tighter laws on gun ownership nationally.

In the summer and fall of 2016, Connecticut experienced a drought in many parts of the state, causing some water-use bans. As of , 45% of the state was listed at Severe Drought by the US Drought Monitor, including almost all of Hartford and Litchfield counties. All the rest of the state was in Moderate Drought or Severe Drought, including Middlesex, Fairfield, New London, New Haven, Windham, and Tolland counties. This affected the agricultural economy in the state.

The United States Census Bureau estimates that the population of Connecticut was 3,572,665 on July 1, 2018, a −0.04% decrease since the 2010 United States Census.

, Connecticut had an estimated population of 3,572,665, which is an decrease of 15,519, or -1.00%, from the prior year and an decrease of 1,432, or -0.04%, since the year 2010. This includes a natural increase since the last census of 67,427 people (that is 222,222 births minus 154,795 deaths) and an increase due to net migration of 41,718 people into the state. Immigration from outside the United States resulted in a net increase of 75,991 people, and migration within the country produced a net loss of 34,273 people. Based on the 2005 estimates, Connecticut moved from the 29th most populous state to 30th. 2018 estimates put Connecticut's population at 3,572,665.

6.6% of its population was reported as being under 5 years old, 24.7% under 18 years old, and 13.8% were 65 years of age or older. Females made up approximately 51.6% of the population, with 48.4% male.

In 1790, 97% of the population in Connecticut was classified as "rural". The first census in which less than half the population was classified as rural was 1890. In the 2000 census, only 12.3% was considered rural. Most of western and southern Connecticut (particularly the Gold Coast) is strongly associated with New York City; this area is the most affluent and populous region of the state and has high property costs and high incomes. The center of population of Connecticut is located in the town of Cheshire.
As of the 2010 United States Census, Connecticut's race and ethnic percentages were:

Hispanics and Latinos of any race made up 13.4% of the population in the 2010 Census.

The state's most populous ethnic group is Non-Hispanic White, but this has declined from 98% in 1940 to 71% in 2010.

As of 2004, 11.4% of the population (400,000) was foreign-born. In 1870, native-born Americans had accounted for 75% of the state's population, but that had dropped to 35% by 1918.

As of 2000, 81.69% of Connecticut residents age 5 and older spoke English at home and 8.42% spoke Spanish, followed by Italian at 1.59%, French at 1.31%, and Polish at 1.20%.

The largest European ancestry groups are:
, 46.1% of Connecticut's population younger than age 1 were minorities.

"Note: Births in table do not add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."


The religious affiliations of the people of Connecticut :
A Pew survey of Connecticut residents' religious self-identification showed the following distribution of affiliations: Protestant 35%, Mormonism 1%, Jewish 3%, Roman Catholic 33%, Orthodox 1%, Non-religious 28%, Jehovah's Witness 1%, Hinduism 1%, Buddhism 1% and Islam 1%. Jewish congregations had 108,280 (3.2%) members in 2000. The Jewish population is concentrated in the towns near Long Island Sound between Greenwich and New Haven, in Greater New Haven and in Greater Hartford, especially the suburb of West Hartford. According to the Association of Religion Data Archives, the largest Christian denominations, by number of adherents, in 2010 were: the Catholic Church, with 1,252,936; the United Church of Christ, with 96,506; and non-denominational Evangelical Protestants, with 72,863.

Recent immigration has brought other non-Christian religions to the state, but the numbers of adherents of other religions are still low. Connecticut is also home to New England's largest Protestant Church: The First Cathedral in Bloomfield, Connecticut located in Hartford County. Hartford is seat to the Roman Catholic Archdiocese of Hartford, which is sovereign over the Diocese of Bridgeport and the Diocese of Norwich.

The total gross state product for 2012 was $229.3 billion, up from $225.4 billion in 2011.

Connecticut's per capita personal income in 2013 was estimated at $60,847, the highest of any state. There is, however, a great disparity in incomes throughout the state; after New York, Connecticut had the second largest gap nationwide between the average incomes of the top 1% and the average incomes of the bottom 99%. According to a 2013 study by Phoenix Marketing International, Connecticut had the third-largest number of millionaires per capita in the United States, with a ratio of 7.32%. New Canaan is the wealthiest town in Connecticut, with a per capita income of $85,459. Darien, Greenwich, Weston, Westport and Wilton also have per capita incomes over $65,000. Hartford is the poorest municipality in Connecticut, with a per capita income of $13,428 in 2000.

The state's seasonally adjusted unemployment rate in December 2018 was 4.0%, the 33rd highest in the nation.

Before 1991, Connecticut had an investment-only income tax system. Income from employment was untaxed, but income from investments was taxed at 13%, the highest rate in the U.S., with no deductions allowed for costs of producing the investment income, such as interest on borrowing.

In 1991, under Governor Lowell P. Weicker Jr., an independent, the system was changed to one in which the taxes on employment income and investment income were equalized at a maximum rate of 4%. The new tax policy drew investment firms to Connecticut; , Fairfield County was home to the headquarters for 14 of the 200 largest hedge funds in the world.

, the income tax rates on Connecticut individuals are divided into six tax brackets of 3% (on income up to $10,000); 5% ($10,000-$50,000); 5.5% ($50,000-$100,000); 6% ($100,000-$200,000); 6.5% ($200,000-$250,000); and 6.7% (more than $250,000), with additional amounts owed depending on the bracket.

All wages of Connecticut residents are subject to the state's income tax, even if earned outside the state. However, in those cases, Connecticut income tax must be withheld only to the extent the Connecticut tax exceeds the amount withheld by the other jurisdiction. Since New York and Massachusetts have higher tax rates than Connecticut, this effectively means that Connecticut residents that work in those states have no Connecticut income tax withheld. Connecticut permits a credit for taxes paid to other jurisdictions, but since residents who work in other states are still subject to Connecticut income taxation, they may owe taxes if the jurisdictional credit does not fully offset the Connecticut tax amount.

Connecticut levies a 6.35% state sales tax on the retail sale, lease, or rental of most goods. Some items and services in general are not subject to sales and use taxes unless specifically enumerated as taxable by statute. A provision excluding clothing under $50 from sales tax was repealed . There are no additional sales taxes imposed by local jurisdictions. In August 2013, Connecticut authorized a sales tax "holiday" for one week during which retailers did not have to remit sales tax on certain items and quantities of clothing.

All real and personal property located within the state of Connecticut is taxable unless specifically exempted by statute. All assessments are at 70% of fair market value. Another 20% of the value may be taxed by the local government though. The maximum property tax credit is $300 per return and any excess may not be refunded or carried forward. Connecticut does not levy an intangible personal property tax. According to the Tax Foundation, the 2010 Census data shows Connecticut residents paying the 2nd highest average property taxes in the nation with only New Jersey ahead of them.

The Tax Foundation determined Connecticut residents had the third highest burden in the nation for state and local taxes at 11.86%, or $7,150, compared to the national average of 9.8%.

, the gasoline tax in Connecticut is 49.3 cents per gallon (the third highest in the nation) and the diesel tax is 54.9 cents per gallon (the highest in the nation).

Of home-sale transactions that closed in March 2014, the median home in Connecticut sold for $225,000, up 3.2% from March 2013. Connecticut ranked ninth nationally in foreclosure activity , with one of every 887 residential units involved in a foreclosure proceeding, or 0.11% of the total housing stock., including City Place I and the Traveler's Tower, both housing the major insurance industry.

Finance and insurance is Connecticut's largest industry, according to the U.S. Census Bureau, generating 16.4% of gross domestic product (GDP) in 2009. Major financial industry employers include The Hartford, Travelers, Cigna, Aetna, Mass Mutual, People's United Financial, Royal Bank of Scotland, UBS Bridgewater Associates, and GE Capital. Separately, the real estate industry accounted for an additional 15% of economic activity in 2009, with major employers including Realogy and William Raveis Real Estate.

Manufacturing is the third biggest industry at 11.9% of GDP and dominated by Hartford-based United Technologies Corporation (UTC), which employs more than 22,000 people in Connecticut. Lockheed Martin subsidiary Sikorsky Aircraft operates Connecticut's single largest manufacturing plant in Stratford, where it makes helicopters. Other UTC divisions include UTC Propulsion and Aerospace Systems, including jet engine manufacturer Pratt & Whitney and UTC Building and Industrial Systems.

Other major manufacturers include the Electric Boat division of General Dynamics, which makes submarines in Groton, and Boehringer Ingelheim, a pharmaceuticals manufacturer with its U.S. headquarters in Ridgefield.

Connecticut historically was a center of gun manufacturing, and four gun-manufacturing firms continued to operate in the state , employing 2,000 people: Colt, Stag, Ruger, and Mossberg. Marlin, owned by Remington, closed in April 2011.

A report issued by the Connecticut Commission on Culture & Tourism on December 7, 2006 demonstrated that the areas of the arts, film, history, and tourism generated more than $14 billion in economic activity and 170,000 jobs annually. This provides $9 billion in personal income for Connecticut residents and $1.7 billion in state and local revenue. The Foxwoods Resort Casino and Mohegan Sun casino number among the state's largest employers; both are located on Indian reservations in the eastern part of Connecticut.

Connecticut's agricultural sector employed about 12,000 people , with more than a quarter of that number involved in nursery stock production. Other agricultural products include dairy products and eggs, tobacco, fish and shellfish, and fruit.

Oyster harvesting was historically an important source of income to towns along the Connecticut coastline. In the 19th century, oystering boomed in New Haven, Bridgeport, and Norwalk and achieved modest success in neighboring towns. In 1911, Connecticut's oyster production reached its peak at nearly 25 million pounds of oyster meats. This was, at the time, higher than production in New York, Rhode Island, or Massachusetts. During this time, the Connecticut coast was known in the shellfishing industry as the oyster capital of the world. From before World War 1 until 1969, Connecticut laws restricted the right to harvest oysters in state-owned beds to sailing vessels. These laws prompted the construction of the oyster sloop style vessel that lasted well into the 20th century. The sloop is believed to be the last oyster sloop built in Connecticut, completed in Greenwich in 1948.

The Interstate highways in the state are Interstate 95 (I-95) traveling southwest to northeast along the coast, I-84 traveling southwest to northeast in the center of the state, I-91 traveling north to south in the center of the state, and I-395 traveling north to south near the eastern border of the state. The other major highways in Connecticut are the Merritt Parkway and Wilbur Cross Parkway, which together form Connecticut Route 15 (Route 15), traveling from the Hutchinson River Parkway in New York parallel to I-95 before turning north of New Haven and traveling parallel to I-91, finally becoming a surface road in Berlin. I-95 and Route 15 were originally toll roads; they relied on a system of toll plazas at which all traffic stopped and paid fixed tolls. A series of major crashes at these plazas eventually contributed to the decision to remove the tolls in 1988. Other major arteries in the state include U.S. Route 7 (US 7) in the west traveling parallel to the New York state line, Route 8 farther east near the industrial city of Waterbury and traveling north–south along the Naugatuck River Valley nearly parallel with US 7, and Connecticut Route 9 in the east.

Between New Haven and New York City, I-95 is one of the most congested highways in the United States. Although I-95 has been widened in several spots, some areas are only 3 lanes and this strains traffic capacity, resulting in frequent and lengthy rush hour delays. Frequently, the congestion spills over to clog the parallel Merritt Parkway and even US 1. The state has encouraged traffic reduction schemes, including rail use and ride-sharing.

Connecticut also has a very active bicycling community, with one of the highest rates of bicycle ownership and use in the United States, particularly in New Haven. According to the US Census 2006 American Community Survey, New Haven has the highest percentage of commuters who bicycle to work of any major metropolitan center on the East Coast.

Rail is a popular travel mode between New Haven and New York City's Grand Central Terminal. Southwestern Connecticut is served by the Metro-North Railroad's New Haven Line, operated by the Metropolitan Transportation Authority and providing commuter service to New York City and New Haven, with branches servicing New Canaan, Danbury, and Waterbury. Connecticut lies along Amtrak's Northeast Corridor which features frequent Northeast Regional and Acela Express service from New Haven south to New York City, Philadelphia, Baltimore, Washington, DC, and Norfolk, VA.

Coastal cities and towns between New Haven and New London are also served by the Shore Line East commuter line. Several new stations were completed along the Connecticut shoreline recently, and a commuter rail service called the Hartford Line between New Haven and Springfield on Amtrak's New Haven-Springfield Line began operating in June 2018.
A proposed commuter rail service, the Central Corridor Rail Line, will connect New London with Norwich, Willimantic, Storrs, and Stafford Springs, with service continuing into Massachusetts and Brattleboro. Amtrak also operates a shuttle service between New Haven and Springfield, Massachusetts, serving Wallingford, Meriden, Berlin, Hartford, Windsor Locks, and Springfield, MA and the Vermonter runs from Washington to St. Albans, Vermont via the same line.

Statewide bus service is supplied by Connecticut Transit, owned by the Connecticut Department of Transportation, with smaller municipal authorities providing local service. Bus networks are an important part of the transportation system in Connecticut, especially in urban areas like Hartford, Stamford, Norwalk, Bridgeport and New Haven. Connecticut Transit also operates CTfastrak, a bus rapid transit service between New Britain and Hartford. The bus route opened to the public on March 28, 2015.
Bradley International Airport, is located in Windsor Locks, north of Hartford. Many residents of central and southern Connecticut also make heavy use of JFK International Airport and Newark International Airports, especially for international travel. Smaller regional air service is provided at Tweed New Haven Regional Airport. Larger civil airports include Danbury Municipal Airport and Waterbury-Oxford Airport in western Connecticut, Hartford–Brainard Airport in central Connecticut, and Groton-New London Airport in eastern Connecticut. Sikorsky Memorial Airport is located in Stratford and mostly services cargo, helicopter and private aviation.

The Bridgeport & Port Jefferson Ferry travels between Bridgeport, Connecticut and Port Jefferson, New York by crossing Long Island Sound. Ferry service also operates out of New London to Orient, New York; Fishers Island, New York; and Block Island, Rhode Island, which are popular tourist destinations. Small local services operate the Rocky Hill – Glastonbury Ferry and the Chester–Hadlyme Ferry which cross the Connecticut River.

Hartford has been the sole capital of Connecticut since 1875. Before then, New Haven and Hartford alternated as capitals.

Connecticut is known as the "Constitution State". The origin of this nickname is uncertain, but it likely comes from Connecticut's pivotal role in the federal constitutional convention of 1787, during which Roger Sherman and Oliver Ellsworth helped to orchestrate what became known as the Connecticut Compromise, or the Great Compromise. This plan combined the Virginia Plan and the New Jersey Plan to form a bicameral legislature, a form copied by almost every state constitution since the adoption of the federal constitution. Variations of the bicameral legislature had been proposed by Virginia and New Jersey, but Connecticut's plan was the one that was in effect until the early 20th century, when Senators ceased to be selected by their state legislatures and were instead directly elected. Otherwise, it is still the design of Congress.

The nickname also might refer to the Fundamental Orders of 1638–39. These Fundamental Orders represent the framework for the first formal Connecticut state government written by a representative body in Connecticut. The State of Connecticut government has operated under the direction of four separate documents in the course of the state's constitutional history. After the Fundamental Orders, Connecticut was granted governmental authority by King Charles II of England through the Connecticut Charter of 1662.

Separate branches of government did not exist during this period, and the General Assembly acted as the supreme authority. A constitution similar to the modern U.S. Constitution was not adopted in Connecticut until 1818. Finally, the current state constitution was implemented in 1965. The 1965 constitution absorbed a majority of its 1818 predecessor, but incorporated a handful of important modifications.

The governor heads the executive branch. , Ned Lamont is the Governor and Susan Bysiewicz is the Lieutenant Governor; both are Democrats. From 1639 until the adoption of the 1818 constitution, the governor presided over the General Assembly. In 1974, Ella Grasso was elected as the governor of Connecticut. This was the first time in United States history when a woman was a governor without her husband being governor first.

There are several executive departments: Administrative Services, Agriculture, Banking, Children and Families, Consumer Protection, Correction, Economic and Community Development, Developmental Services, Construction Services, Education, Emergency Management and Public Protection, Energy & Environmental Protection, Higher Education, Insurance, Labor, Mental Health and Addiction Services, Military, Motor Vehicles, Public Health, Public Utility Regulatory Authority, Public Works, Revenue Services, Social Services, Transportation, and Veterans Affairs. In addition to these departments, there are other independent bureaus, offices and commissions.

In addition to the Governor and Lieutenant Governor, there are four other executive officers named in the state constitution that are elected directly by voters: Secretary of the State, Treasurer, Comptroller, and Attorney General. All executive officers are elected to four-year terms.

The legislature is the General Assembly. The General Assembly is a bicameral body consisting of an upper body, the State Senate (36 senators); and a lower body, the House of Representatives (151 representatives). Bills must pass each house in order to become law. The governor can veto the bill, but this veto can be overridden by a two-thirds majority in each house. Per Article XV of the state constitution, Senators and Representatives must be at least 18 years of age and are elected to two-year terms in November on even-numbered years. There also must always be between 30 and 50 senators and 125 to 225 representatives. The Lieutenant Governor presides over the Senate, except when absent from the chamber, when the President pro tempore presides. The Speaker of the House presides over the House. , Joe Aresimowicz is the Speaker of the House of Connecticut.

, Connecticut's United States Senators are Richard Blumenthal (Democrat) and Chris Murphy (Democrat). Connecticut has five representatives in the U.S. House, all of whom are Democrats.

Locally elected representatives also develop Local ordinances to govern cities and towns. The town ordinances often include noise control and zoning guidelines. However, the State of Connecticut does also provide statewide ordinances for noise control as well.

The highest court of Connecticut's judicial branch is the Connecticut Supreme Court, headed by the Chief Justice of Connecticut. The Supreme Court is responsible for deciding on the constitutionality of the law or cases as they relate to the law. Its proceedings are similar to those of the United States Supreme Court, with no testimony given by witnesses, and the lawyers of the two sides each present oral arguments no longer than thirty minutes. Following a court proceeding, the court may take several months to arrive at a judgment. the Chief Justice is Chase T. Rogers.

In 1818, the court became a separate entity, independent of the legislative and executive branches. The Appellate Court is a lesser statewide court and the Superior Courts are lower courts that resemble county courts of other states.

The State of Connecticut also offers access to Arrest warrant enforcement statistics through the Office of Policy and Management.

Connecticut does not have county government, unlike all other states except Rhode Island. Connecticut county governments were mostly eliminated in 1960, with the exception of sheriffs elected in each county. In 2000, the county sheriff was abolished and replaced with the state marshal system, which has districts that follow the old county territories. The judicial system is divided into judicial districts at the trial-court level which largely follow the old county lines. The eight counties are still widely used for purely geographical and statistical purposes, such as weather reports and census reporting.

Connecticut shares with the rest of New England a governmental institution called the New England town. The state is divided into 169 towns which serve as the fundamental political jurisdictions. There are also 21 cities, most of which simply follow the boundaries of their namesake towns and have a merged city-town government. There are two exceptions: the City of Groton, which is a subsection of the Town of Groton, and the City of Winsted in the Town of Winchester. There are also nine incorporated boroughs which may provide additional services to a section of town. Naugatuck is a consolidated town and borough.

The state is also divided into 15 planning regions defined by the state Office of Planning and Management, with the exception of the Town of Stafford in Tolland County. The Intragovernmental Policy Division of this Office coordinates regional planning with the administrative bodies of these regions. Each region has an administrative body known as a regional council of governments, a regional council of elected officials, or a regional planning agency. The regions are established for the purpose of planning "coordination of regional and state planning activities; redesignation of logical planning regions and promotion of the continuation of regional planning organizations within the state; and provision for technical aid and the administration of financial assistance to regional planning organizations".

Connecticut residents who register to vote have the option of declaring an affiliation to a political party, may become unaffiliated at will, and may change affiliations subject to certain waiting periods. about 60% of registered voters are enrolled (just over 1% total in 28 third parties minor parties), and ratios among unaffiliated voters and the two major parties are about 8 unaffiliated for every 7 in the Democratic Party of Connecticut and for every 4 in the Connecticut Republican Party.

Many Connecticut towns and cities show a marked preference for moderate candidates of either party.

In April 2012 both houses of the Connecticut state legislature passed a bill (20 to 16 and 86 to 62) that abolished the capital punishment for all future crimes, while 11 inmates who were waiting on the death row at the time could still be executed.

In July 2009 the Connecticut legislature overrode a veto by Governor M. Jodi Rell to pass SustiNet, the first significant public-option health care reform legislation in the nation.

Connecticut ranked third in the nation for educational performance, according to Education Week’s Quality Counts 2018 report. It earned an overall score of 83.5 out of 100 points. On average, the country received a score of 75.2.
Connecticut posted a B-plus in the Chance-for-Success category, ranking fourth on factors that contribute to a person’s success both within and outside the K-12 education system. Connecticut received a mark of B-plus and finished fourth for School Finance. It ranked 12th with a grade of C on the K-12 Achievement Index.

The Connecticut State Board of Education manages the public school system for children in grades K–12. Board of Education members are appointed by the Governor of Connecticut. Statistics for each school are made available to the public through an online database system called "CEDAR". The CEDAR database also provides statistics for "ACES" or "RESC" schools for children with behavioral disorders.

Connecticut was home to the nation's first law school, Litchfield Law School, which operated from 1773 to 1833 in Litchfield. Hartford Public High School (1638) is the third-oldest secondary school in the nation after the Collegiate School (1628) in Manhattan and the Boston Latin School (1635).




The state also has many noted private day schools, and its boarding schools draw students from around the world.

There are two Connecticut teams in the American Hockey League. The Bridgeport Sound Tigers is a farm team for the New York Islanders which competes at the Webster Bank Arena in Bridgeport. The Hartford Wolf Pack is the affiliate of the New York Rangers; they play in the XL Center in Hartford.

The Hartford Yard Goats of the Eastern League are a AA affiliate of the Colorado Rockies. Also, the Connecticut Tigers play in the New York-Penn League and are an A affiliate of the Detroit Tigers. The New Britain Bees play in the Atlantic League of Professional Baseball. The Connecticut Sun of the WNBA currently play at the Mohegan Sun Arena in Uncasville. In soccer, Hartford Athletic will begin play in the USL Championship in 2019, serving as the reserve team for the New England Revolution of Major League Soccer.

The state hosts several major sporting events. Since 1952, a PGA Tour golf tournament has been played in the Hartford area. It was originally called the "Insurance City Open" and later the "Greater Hartford Open" and is now known as the Travelers Championship. The Connecticut Open tennis tournament is held annually in the Cullman-Heyman Tennis Center at Yale University in New Haven.

Lime Rock Park in Salisbury is a road racing course, home to the International Motor Sports Association, SCCA, United States Auto Club, and K&N Pro Series East races. Thompson International Speedway, Stafford Motor Speedway, and Waterford Speedbowl are oval tracks holding weekly races for NASCAR Modifieds and other classes, including the NASCAR Whelen Modified Tour. The state also hosts several major mixed martial arts events for Bellator MMA and the Ultimate Fighting Championship.

The Hartford Whalers of the National Hockey League played in Hartford from 1975 to 1997 at the Hartford Civic Center. They departed to Raleigh, North Carolina after disputes with the state over the construction of a new arena, and they are now known as the Carolina Hurricanes. In 1926, Hartford had a franchise in the National Football League known as the Hartford Blues. They joined the National League for one season in 1876, making them the state's only Major League baseball franchise before moving to Brooklyn, New York and then disbanding one season later. From 2000 until 2006 the city was home to the Hartford FoxForce of World TeamTennis.

The Connecticut Huskies are the team of the University of Connecticut (UConn); they play NCAA Division I sports. Both the men's basketball and women's basketball teams have won multiple national championships. In 2004, UConn became the first school in NCAA Division I history to have its men's and women's basketball programs win the national title in the same year; they repeated the feat in 2014 and are still the only school to win both titles in the same year. The UConn women's basketball team holds the record for the longest consecutive winning streak in NCAA college basketball at 111 games, a streak that ended in 2017. The UConn Huskies football team has played in the Football Bowl Subdivision since 2002, and has played in four bowl games.

New Haven biennially hosts "The Game" between the Yale Bulldogs and the Harvard Crimson, the country's second-oldest college football rivalry. Yale alumnus Walter Camp is deemed the "Father of American Football", and he helped develop modern football while living in New Haven. Other Connecticut universities which feature Division I sports teams are Quinnipiac University, Fairfield University, Central Connecticut State University, Sacred Heart University, and the University of Hartford.

The name "Connecticut" originated with the Mohegan word "quonehtacut", meaning "place of long tidal river". Connecticut's official nickname is "The Constitution State", adopted in 1959 and based on its colonial constitution of 1638–1639 which was the first in America and, arguably, the world. Connecticut is also unofficially known as "The Nutmeg State," whose origin is unknown. It may have come from its sailors returning from voyages with nutmeg, which was a very valuable spice in the 18th and 19th centuries. It may have originated in the early machined sheet tin nutmeg grinders sold by early Connecticut peddlers. It is also facetiously said to come from Yankee peddlers from Connecticut who would sell small carved nobs of wood shaped to look like nutmeg to unsuspecting customers. George Washington gave Connecticut the title of "The Provisions State" because of the material aid that the state rendered to the American Revolutionary War effort. Connecticut is also known as "The Land of Steady Habits".

According to "Webster's New International Dictionary" (1993), a person who is a native or resident of Connecticut is a "Connecticuter". There are numerous other terms coined in print but not in use, such as "Connecticotian" (Cotton Mather in 1702) and "Connecticutensian" (Samuel Peters in 1781). Linguist Allen Walker Read suggests the more playful term "connecticutie". "Nutmegger" is sometimes used, as is "Yankee" The official state song is "Yankee Doodle". The traditional abbreviation of the state's name is "Conn."; the official postal abbreviation is CT.

Commemorative stamps issued by the United States Postal Service with Connecticut themes include Nathan Hale, Eugene O'Neill, Josiah Willard Gibbs, Noah Webster, Eli Whitney, the whaling ship the "Charles W. Morgan", which is docked at Mystic Seaport, and a decoy of a broadbill duck.





</doc>
<doc id="6468" url="https://en.wikipedia.org/wiki?curid=6468" title="Country Liberal Party">
Country Liberal Party

The Country Liberal Party (CLP), officially the Country Liberals (Northern Territory), is a liberal conservative political party in Australia founded in 1974, which operates solely in the Northern Territory.

The CLP first fielded candidates at the 1975 federal election, winning one seat in the Senate and the non-voting seat in the House of Representatives. Since 1979, the CLP has been formally affiliated with both the federal Liberal Party of Australia and the National Party of Australia (previously the Country Party and National Country Party). The Liberal Party, National Party, Liberal National Party of Queensland, and CLP form the Coalition of Australian centre-right parties, with the CLP alone contesting seats for the Coalition in the Northern Territory. The CLP has full voting rights within the National Party, and observer status with the Liberal Party. Currently, the CLP has one representative in federal parliament, Senator Nigel Scullion, who also serves as the Senate leader of the National Party.

The CLP dominated the Northern Territory Legislative Assembly from its establishment in 1974 until the 2001 general election, when the CLP lost government winning only 10 of the 25 seats, and was reduced further to four parliamentary members at the 2005 election. At the 2008 election it increased its numbers, winning 11 seats.

The CLP returned to office following the 2012 election, winning 16 of 25 seats, and leader Terry Mills became Chief Minister of the Northern Territory. Less than a year later, Mills was replaced as Chief Minister and CLP leader by Adam Giles at the 2013 CLP leadership ballot on 13 March. Giles was the first indigenous Australian to lead a state or territory government in Australia. Giles was defeated at the 2015 CLP leadership ballot but managed to survive in the aftermath. Multiple defections saw the CLP reduced to minority government a few months later. At the 27 August 2016 Territory election, the CLP was resoundingly defeated, winning just two of 25 seats. Gary Higgins became CLP leader and opposition leader on 2 September, with Lia Finocchiaro as his deputy.

The Territory Country Party members first contested the 1919 federal election, with a newly established federal Country Party contesting the 1922 federal election. The 1922 election saw the main opposition party to the Australian Labor Party, the Nationalist Party of Australia deprived of a majority, and were required to form a coalition in order to command a majority on the floor of parliament. The price for such support was the resignation of Nationalist (ex-Labor) Prime Minister, Billy Hughes, who was replaced by Stanley Bruce.

In 1922, the federal Division of Northern Territory was created, with one non-voting Member in the House of Representatives. Harold George Nelson was the inaugural member serving between 16 December 1922 and 15 September 1934. He was elected as an Independent but later joined the Australian Labor Party (ALP). Between 15 September 1934 and 10 December 1949 the Division of Northern Territory was held by Adair Blain, an independent member. Between 10 December 1949 and 31 October 1966 the Division was held by Jock Nelson, a member of the ALP. The Territory seat was won by the Country Party's Sam Calder at the 1966 federal election, who held the seat from 26 November 1966 to 19 September 1980.

In 1966, the Country Party was established in the Northern Territory, while the Liberal Party was a small party. In recognition of this, the local Liberals supported the Country Party's Calder for the sole NT seat from 1969 to 1972. An alliance had formed, primarily against the conservatives' main opponent, the ALP. After the gradual extension of limited voting rights, in 1968 the federal Coalition government gave the Member for Northern Territory full voting rights.

After the 1974 federal election and the subsequent Joint Sitting of parliament, legislation was passed to give the Australian Capital Territory and the Northern Territory representation in the Australian Senate, with two senators being elected.

The Whitlam Government passed legislation in 1974 to establish a fully elected unicameral Northern Territory Legislative Assembly to replace the previous partly elected Northern Territory Legislative Council, which had been in existence since 1947. The term of the Legislative Assembly was four years. Initially, the Legislative Assembly consisted of 19 members, which was increased in 1982 to 25 members, the present number. The Northern Territory was granted self-government in 1978.

Following the creation of the Legislative Assembly in 1974, the Territory's branches of the Country and Liberal parties merged to form the "Country Liberal Party" (CLP) to field candidates at the 1974 general election for the Legislative Assembly, going on to win 17 out of 19 seats. Calder was largely responsible for the push to unite the non-Labor forces in the Territory.

The CLP fielded candidates at the 1975 federal election, winning one seat each in the Senate and in the House of Representatives. Since 1979, the CLP has been formally affiliated with both the federal National (previously the Country Party and National Country Party) and Liberal parties. The CLP contests seats for the Coalition in the Northern Territory rather than the Liberal or National parties. The CLP has full voting rights within the National Party, and observer status with the Liberal Party.

The CLP governed the Northern Territory from 1974 until the 2001 election. During this time, it never faced more than nine opposition members. Indeed, the CLP's dominance was so absolute that its internal politics were seen as a bigger threat than any opposition party. This was especially pronounced in the mid-1980s, when a series of party-room coups resulted in the Territory having three Chief Ministers in four years.

At the 2001 election the Australian Labor Party won government by one seat, ending 27 years of CLP government. The loss marked a major turning point in Northern Territory politics, a result which was exacerbated when, at the 2005 election, the ALP won the second-largest majority government in the history of the Territory, reducing the once-dominant party to just four members in the Legislative Assembly. This result was only outdone by the 1974 election, in which the CLP faced only two independents as opposition. The CLP even lost two seats in Palmerston, an area where the ALP had never come close to winning any seats before.

In the 2001 federal election, the CLP won the newly formed seat of Solomon, based on Darwin/Palmerston, in the House of Representatives.
In the 2004 federal election, the CLP held one seat in the House of Representatives, and one seat in the Senate. The CLP lost its federal lower house in the 2007 federal election, but regained it when Palmerston deputy mayor Natasha Griggs won back Solomon for the CLP. She sat with the Liberals in the House.

The 2008 election saw the CLP recover from the severe loss it suffered three years earlier, increasing its representation from four to 11 members. Following the 2011 decision of ALP-turned-independent member Alison Anderson to join the CLP, this increased to CLP's representation to 12 in the Assembly, leaving the incumbent Henderson Government to govern in minority with the support of Independent MP Gerry Wood.

Historically, the CLP has been particularly dominant in the Territory's two major cities, Darwin/Palmerston and Alice Springs. However, in recent years the ALP has pulled even with the CLP in the Darwin area; indeed, its 2001 victory was fueled by an unexpected swing in Darwin.

The CLP under the leadership of Terry Mills returned to power in the 2012 election with 16 of 25 seats, defeating the incumbent Labor Government led by Paul Henderson. In the lead up to the Territory election, CLP Senator Nigel Scullion sharply criticised the Federal Labor Government for its suspension of the live cattle trade to Indonesia - an economic mainstay of the territory.

The election victory ended 11 years of ALP rule in the Northern Territory. The victory was also notable for the support it achieved from indigenous people in pastoral and remote electorates. Large swings were achieved in remote Territory electorates (where the indigenous population comprised around two-thirds of voters) and a total of five Aboriginal CLP candidates won election to the Assembly. Among the indigenous candidates elected were high-profile Aboriginal activist Bess Price and former ALP member Alison Anderson. Anderson was appointed Minister for Indigenous Advancement. In a nationally reported speech in November 2012, Anderson condemned welfare dependency and a culture of entitlement in her first ministerial statement on the status of Aboriginal communities in the Territory and said the CLP would focus on improving education and on helping create real jobs for indigenous people.

Adam Giles replaced Mills as Chief Minister of the Northern Territory and party leader at the 2013 CLP leadership ballot on 13 March while Mills was on a trade mission in Japan. Giles was sworn in as Chief Minister on 14 March, becoming the first indigenous head of government of an Australian state or territory.

When the CLP introduced mandatory alcohol rehabilitation for recidivist problem drinkers to replace a banned drinker register, Giles dismissed critics of the policy as "lefty welfare-orientated people".

Willem Westra van Holthe challenged Giles at the 2015 CLP leadership ballot on 2 February and was elected leader by the party room in a late night vote conducted by phone. However, Giles refused to resign as Chief Minister following the vote. On 3 February, "ABC News" reported that officials were preparing an instrument for Giles' removal by the Administrator. The swearing-in of Westra van Holthe, which had been scheduled for 11:00 local time (01:30 UTC), was delayed. After a meeting of the parliamentary wing of the CLP, Giles announced that he would remain as party leader and Chief Minister, and that Westra van Holthe would be his deputy.

Just one opinion poll has been released since the 2012 election – conducted by ReachTEL and commissioned by The Australian which surveyed 1036 residents via robocall on the afternoon of Sunday 1 March 2015 across all 18 electorates in Darwin, Palmerston and Alice Springs – which indicated a landslide 17.6% two-party swing against the incumbent CLP government since the last election.

After four defections during the parliamentary term, the CLP was reduced to minority government by July 2015. Giles raised the possibility of an early election on 20 July stating that he would "love" to call a snap poll, but that it was "pretty much impossible to do". Crossbenchers dismissed the notion of voting against a confidence motion to bring down the government.

Territory government legislation passed in February 2016 changed the voting method of single-member electorates from full-preferential voting to optional preferential voting ahead of the 2016 territory election held on 27 August.

Federally, a MediaReach seat-level opinion poll of 513 voters in the seat of Solomon conducted 22−23 June ahead of the 2016 federal election held on 2 July surprisingly found Labor candidate Luke Gosling heavily leading two-term CLP incumbent Natasha Griggs 61–39 on the two-party vote from a large 12.4 percent swing. The CLP lost Solomon to Labor at the election, with Gosling defeating Griggs 56–44 on the two-party vote from a 7.4 percent swing.

At the 27 August Territory election, the CLP was swept from power in a massive Labor landslide, suffering easily the worst defeat of a sitting government in Territory history. The party not only lost all of the bush seats it picked up in 2012, but was all but shut out of Darwin/Palmerston, winning only one seat there. All told, the CLP only won two seats, easily its worst showing in an election. Giles himself lost his own seat, becoming the second Majority Leader/Chief Minister to lose his own seat. Even before Giles' defeat was confirmed, second-term MP Gary Higgins—the only surviving member of the Giles cabinet—was named the party's new leader, with Lia Finocchiaro as his deputy.

By the spring of 2016, the party website had turned into a redirect to its Facebook page. However, a full site was rolled back out in 2018.

The CLP stands for office in the Northern Territory Assembly and Federal Parliament of Australia and primarily concerns itself with representing Territory interests. It is a regionally based party, that has parliamentary representation in both the Federal Parliament and at the Territory level.

The CLP competes against the Australian Labor Party (Northern Territory Branch) (the local branch of Australia's social-democratic party). It is closely affiliated with, but is independent from the Liberal Party of Australia (a mainly urban, pro-private enterprise party comprising mainly liberal membership) and the National Party of Australia (a conservative-liberal agrarian and regional interests party).

The party promotes traditional Liberal Party values such as individualism and private enterprise, and what it describes as "progressive" political policy such as full statehood for the Northern Territory.

Branch delegates and members of the party's Central Council attend the Annual Conference of the Country Liberal Party to decide the party's platform. The Central Council is composed of the party's office bearers, its leaders from the Territory Assembly and the Federal Parliament and representatives of party branches.

The Annual Conference of the Country Liberal Party, attended by branch delegates and members of the party's Central Council, decides matters relating to the party's platform and philosophy. The Central Council administers the party and makes decisions on pre-selections. It is composed of the party's office bearers, its leaders in the Northern Territory Legislative Assembly, members in the Federal Parliament, and representation from each of the party's branches.

The CLP president has full voting rights with the National Party and observer status with the Liberal Party. Both the Liberals and Nationals receive Country Liberal delegations at their conventions. After federal elections, the CLP directs its federal members and senators as to which of the two other parties they should sit with in the parliamentary chamber. In practice, CLP House members usually sit with the Liberals, while CLP Senators sit with the Nationals.




</doc>
<doc id="6469" url="https://en.wikipedia.org/wiki?curid=6469" title="Canon law">
Canon law

Canon law (from Greek "kanon", a 'straight measuring rod, ruler') is a set of ordinances and regulations made by ecclesiastical authority (Church leadership), for the government of a Christian organization or church and its members. It is the internal ecclesiastical law, or operational policy, governing the Catholic Church (both the Latin Church and the Eastern Catholic Churches), the Eastern Orthodox and Oriental Orthodox churches, and the individual national churches within the Anglican Communion. The way that such church law is legislated, interpreted and at times adjudicated varies widely among these three bodies of churches. In all three traditions, a canon was originally a rule adopted by a church council; these canons formed the foundation of canon law.

Greek "kanon" / , Arabic Qaanoon / قانون, Hebrew kaneh / קנה, "straight"; a rule, code, standard, or measure; the root meaning in all these languages is "reed" ("cf." the Romance-language ancestors of the English word "cane").

The "Apostolic Canons" or "Ecclesiastical Canons of the Same Holy Apostles" is a collection of ancient ecclesiastical decrees (eighty-five in the Eastern, fifty in the Western Church) concerning the government and discipline of the Early Christian Church, incorporated with the Apostolic Constitutions which are part of the Ante-Nicene Fathers.
In the Fourth century the First Council of Nicaea (325) calls canons the disciplinary measures of the Church: the term canon, κανὠν, means in Greek, a rule. There is a very early distinction between the rules enacted by the Church and the legislative measures taken by the State called "leges", Latin for laws.

In the Catholic Church, canon law is the system of laws and legal principles made and enforced by the Church's hierarchical authorities to regulate its external organization and government and to order and direct the activities of Catholics toward the mission of the Church.

In the Latin Church, positive ecclesiastical laws, based directly or indirectly upon immutable divine law or natural law, derive formal authority in the case of universal laws from the supreme legislator (i.e., the Supreme Pontiff), who possesses the totality of legislative, executive, and judicial power in his person, while particular laws derive formal authority from a legislator inferior to the supreme legislator. The actual subject material of the canons is not just doctrinal or moral in nature, but all-encompassing of the human condition.

The Catholic Church also includes the main five rites (groups) of churches which are in full union with the Holy See and the Latin Church:
All of these church groups are in full communion with the Supreme Pontiff and are subject to the "Code of Canons of the Eastern Churches".

The Catholic Church has what is claimed to be the oldest continuously functioning internal legal system in Western Europe, much later than Roman law but predating the evolution of modern European civil law traditions. What began with rules ("canons") adopted by the Apostles at the Council of Jerusalem in the first century has developed into a highly complex legal system encapsulating not just norms of the New Testament, but some elements of the Hebrew (Old Testament), Roman, Visigothic, Saxon, and Celtic legal traditions.

The history of Latin canon law can be divided into four periods: the "jus antiquum", the "jus novum", the "jus novissimum" and the "Code of Canon Law". In relation to the Code, history can be divided into the "jus vetus" (all law before the Code) and the "jus novum" (the law of the Code, or "jus codicis").

The canon law of the Eastern Catholic Churches, which had developed some different disciplines and practices, underwent its own process of codification, resulting in the Code of Canons of the Eastern Churches promulgated in 1990 by Pope John Paul II.

Roman canon law is a fully developed legal system, with all the necessary elements: courts, lawyers, judges, a fully articulated legal code principles of legal interpretation, and coercive penalties, though it lacks civilly-binding force in most secular jurisdictions. One example where it did not previously apply was in the English legal system, as well as systems, such as the U.S., that derived from it. Here criminals could apply for the Benefit of clergy. Being in holy orders, or fraudulently claiming to be, meant that criminals could opt to be tried by ecclesiastical rather than secular courts. The ecclesiastical courts were generally more lenient. Under the Tudors, the scope of clerical benefit was steadily reduced by Henry VII, Henry VIII, and Elizabeth I. The Vatican disputed secular authority over priests' criminal offences, and this in turn contributed to the English Reformation. The benefit of clergy was systematically removed from English legal systems over the next 200 years, although it still occurred in South Carolina in 1827.

The structure that the fully developed Roman Law provides is a contribution to the Canon Law. The academic degrees in canon law are the J.C.B. ("Juris Canonici Baccalaureatus", Bachelor of Canon Law, normally taken as a graduate degree), J.C.L. ("Juris Canonici Licentiatus", Licentiate of Canon Law) and the J.C.D. ("Juris Canonici Doctor", Doctor of Canon Law). Because of its specialized nature, advanced degrees in civil law or theology are normal prerequisites for the study of canon law.

Much of the legislative style was adapted from the Roman Law Code of Justinian. As a result, Roman ecclesiastical courts tend to follow the Roman Law style of continental Europe with some variation, featuring collegiate panels of judges and an investigative form of proceeding, called "inquisitorial", from the Latin "inquirere", to enquire. This is in contrast to the adversarial form of proceeding found in the common law system of English and U.S. law, which features such things as juries and single judges.

The institutions and practices of canon law paralleled the legal development of much of Europe, and consequently both modern civil law and common law bear the influences of canon law. Edson Luiz Sampel, a Brazilian expert in canon law, says that canon law is contained in the genesis of various institutes of civil law, such as the law in continental Europe and Latin American countries. Sampel explains that canon law has significant influence in contemporary society.

Canonical jurisprudential theory generally follows the principles of Aristotelian-Thomistic legal philosophy. While the term "law" is never explicitly defined in the Code, the Catechism of the Catholic Church cites Aquinas in defining law as "...an ordinance of reason for the common good, promulgated by the one who is in charge of the community" and reformulates it as "...a rule of conduct enacted by competent authority for the sake of the common good."

The law of the Eastern-rite Churches in full communion with the Roman papacy was in much the same state as that of the Latin or Western Church before 1917; much more diversity in legislation existed in the various Eastern Catholic Churches. Each had its own special law, in which custom still played an important part. One major difference in Eastern Europe however, specifically in the Orthodox Christian churches was in regards to divorce. Divorce started to slowly be allowed in specific instances such as adultery being committed, abuse, abandonment, impotence and barrenness being the primary justifications for divorce. Eventually, the church began to allow remarriage to occur (for both spouses) post-divorce. In 1929 Pius XI informed the Eastern Churches of his intention to work out a Code for the whole of the Eastern Church. The publication of these Codes for the Eastern Churches regarding the law of persons was made between 1949 through 1958 but finalized nearly 30 years later.

The first Code of Canon Law (1917) was almost exclusively for the Latin Church, with extremely limited application to the Eastern Churches. After the Second Vatican Council, (1962 - 1965), another edition was published specifically for the Roman Rite in 1983. Most recently, 1990, the Vatican produced the "Code of Canons" of the Eastern Churches which became the 1st code of "Eastern Catholic Canon Law".

The Eastern Orthodox Church, principally through the work of 18th-century Athonite monastic scholar Nicodemus the Hagiorite, has compiled canons and commentaries upon them in a work known as the "Pēdálion" (Greek: Πηδάλιον, "Rudder"), so named because it is meant to "steer" the Church in her discipline. The dogmatic determinations of the Councils are to be applied rigorously, since they are considered to be essential for the Church's unity and the faithful preservation of the Gospel.

In the Church of England, the ecclesiastical courts that formerly decided many matters such as disputes relating to marriage, divorce, wills, and defamation, still have jurisdiction of certain church-related matters (e.g. discipline of clergy, alteration of church property, and issues related to churchyards). Their separate status dates back to the 12th century when the Normans split them off from the mixed secular/religious county and local courts used by the Saxons. In contrast to the other courts of England the law used in ecclesiastical matters is at least partially a civil law system, not common law, although heavily governed by parliamentary statutes. Since the Reformation, ecclesiastical courts in England have been royal courts. The teaching of canon law at the Universities of Oxford and Cambridge was abrogated by Henry VIII; thereafter practitioners in the ecclesiastical courts were trained in civil law, receiving a Doctor of Civil Law (D.C.L.) degree from Oxford, or a Doctor of Laws (LL.D.) degree from Cambridge. Such lawyers (called "doctors" and "civilians") were centered at "Doctors Commons", a few streets south of St Paul's Cathedral in London, where they monopolized probate, matrimonial, and admiralty cases until their jurisdiction was removed to the common law courts in the mid-19th century.

Other churches in the Anglican Communion around the world (e.g., the Episcopal Church in the United States, and the Anglican Church of Canada) still function under their own private systems of canon law.

Currently, (2004), there are principles of canon law common to the churches within the Anglican Communion; their existence can be factually established; each province or church contributes through its own legal system to the principles of canon law common within the Communion; these principles have a strong persuasive authority and are fundamental to the self-understanding of each of the churches of the Communion; these principles have a living force, and contain in themselves the possibility of further development; and the existence of these principles both demonstrates unity and promotes unity within the Anglican Communion.

In Presbyterian and Reformed churches, canon law is known as "practice and procedure" or "church order", and includes the church's laws respecting its government, discipline, legal practice and worship.

Roman canon law had been criticized by the Presbyterians as early as 1572 in the Admonition to Parliament. The protest centered on the standard defense that canon law could be retained so long as it did not contradict the civil law. According to Polly Ha, the Reformed Church Government refuted this claiming that the bishops had been enforcing canon law for 1500 years.

The Book of Concord is the historic doctrinal statement of the Lutheran Church, consisting of ten credal documents recognized as authoritative in Lutheranism since the 16th century. However, the Book of Concord is a confessional document (stating orthodox belief) rather than a book of ecclesiastical rules or discipline, like canon law. Each Lutheran national church establishes its own system of church order and discipline, though these are referred to as "canons."

The Book of Discipline contains the laws, rules, policies and guidelines for The United Methodist Church. Its last edition was published in 2016.







</doc>
<doc id="6501" url="https://en.wikipedia.org/wiki?curid=6501" title="Columbanus">
Columbanus

Columbanus (, 540 – 23 November 615), also known as St. Columban, was an Irish missionary notable for founding a number of monasteries from around 590 in the Frankish and Lombard kingdoms, most notably Luxeuil Abbey in present-day France and Bobbio Abbey in present-day Italy. He is remembered as a key figure in the Hiberno-Scottish mission, or Irish missionary activity in early medieval Europe. In recent years, however, as Columbanus's deeds and legacy have come to be re-examined by historians, the traditional narrative of his career has been challenged and doubts have been raised regarding his actual involvement in missionary work and the extent to which he was driven by purely religious motives or also by a concern for playing an active part in politics and church politics in Francia.

Columbanus taught an Irish monastic rule and penitential practices for those repenting of sins, which emphasised private confession to a priest, followed by penances levied by the priest in reparation for the sins. Columbanus is one of the earliest identifiable Hiberno-Latin writers.

Most of what we know about Columbanus is based on Columbanus' own works (as far as they have been preserved) and Jonas of Bobbio's "Vita Columbani" ("Life of Columbanus"), which was written between 639 and 641. Jonas entered Bobbio after Columbanus' death but relied on reports of monks who still knew Columbanus. A description of miracles of Columbanus written by an anonymous monk of Bobbio is of much later date. In the second volume of his "Acta Sanctorum O.S.B.", Mabillon gives the life in full, together with an appendix on the miracles of the saint, written by an anonymous member of the Bobbio community.

Columbanus (the Latinised form of "Columbán", meaning "the white dove") was born in the Kingdom of Meath, now part of Leinster, in Ireland in 540, the year Saint Benedict died at Monte Cassino. Prior to his birth, his mother was said to have had visions of bearing a child who, in the judgment of those interpreting the visions, would become a "remarkable genius". Columbanus was well-educated in the areas of grammar, rhetoric, geometry, and the Holy Scriptures.

Columbanus left home to study under Sinell, Abbot of Cleenish in Lough Erne. Under Sinell's instruction, Columbanus composed a commentary on the Psalms. He then moved to Bangor Abbey on the coast of Down, where Saint Comgall was serving as the abbot. He stayed at Bangor until his fortieth year, when he received Comgall's permission to travel to the continent.

Columbanus gathered twelve companions for his journey—Saint Attala, Columbanus the Younger, Cummain, Domgal (Deicolus), Eogain, Eunan, Saint Gall, Gurgano, Libran, Lua, Sigisbert, and Waldoleno—and together they set sail for the continent. After a brief stop in Britain, most likely on the Scottish coast, they crossed the channel and landed in Brittany in 585. At Saint-Malo in Brittany, there is a granite cross bearing the saint's name to which people once came to pray for rain in times of drought. The nearby village of Saint-Coulomb commemorates him in name.

Columbanus and his companions were received with favour by King Gontram of Burgundy, and soon they made their way to Annegray, where they founded a monastery in an abandoned Roman fortress. Despite its remote location in the Vosges Mountains, the community became a popular pilgrimage site that attracted so many monastic vocations that two new monasteries had to be formed to accommodate them. In 590, Columbanus obtained from King Gontram the Gallo-Roman castle called "Luxovium" in present-day Luxeuil-les-Bains, some eight miles from Annegray. The castle, soon transformed into a monastery, was located in a wild region, thickly covered with pine forests and brushwood. Columbanus erected a third monastery called "Ad-fontanas" at present-day Fontaine-lès-Luxeuil, named for its numerous springs. These monastic communities remained under Columbanus' authority, and their rules of life reflected the Irish tradition in which he had been formed. As these communities expanded and drew more pilgrims, Columbanus sought greater solitude, spending periods of time in a hermitage and communicating with the monks through an intermediary. Often he would withdraw to a cave seven miles away, with a single companion who acted as messenger between himself and his companions.

During his twenty years in Gaul (in present-day France), Columbanus became involved in a dispute with the Frankish bishops who may have feared his growing influence. During the first half of the sixth century, the councils of Gaul had given to bishops absolute authority over religious communities. As heirs to the Irish monastic tradition, Columbanus and his monks used the Irish Easter calculation, a version of Bishop Augustalis's 84-year "computus" for determining the date of Easter (Quartodecimanism), whereas the Franks had adopted the Victorian cycle of 532 years. The bishops objected to the newcomers' continued observance of their own dating, which—among other issues—caused the end of Lent to differ. They also complained about the distinct Irish tonsure. In 602, the bishops assembled to judge Columbanus, but he did not appear before them as requested. Instead, he sent a letter to the prelates—a strange mixture of freedom, reverence, and charity—admonishing them to hold synods more frequently, and advising them to pay more attention to matters of equal importance to that of the date of Easter. In defence of his following his traditional paschal cycle, he wrote:

When the bishops refused to abandon the matter, Columbanus, following Saint Patrick's canon, appealed directly to Pope Gregory I. In the third and only surviving letter, he asks "the holy Pope, his Father" to provide "the strong support of his authority" and to render a "verdict of his favour", apologising for "presuming to argue as it were, with him who sits in the chair of Peter, Apostle and Bearer of the Keys". None of the letters were answered, most likely due to the pope's death in 604. Columbanus then sent a letter to Gregory's successor, Pope Boniface IV, asking him to confirm the tradition of his elders—if it is not contrary to the Faith—so that he and his monks can follow the rites of their ancestors. Before Boniface responded, Columbanus moved outside the jurisdiction of the Frankish bishops. Since the Easter issue appears to end around that time, Columbanus may have stopped celebrating Irish date of Easter after moving to Italy.

Columbanus was also involved in a dispute with members of the Frankish royal family. Upon the death of King Gontram of Burgundy, the succession passed to his nephew, Childebert II, the son of his brother Sigebert and Sigebert's wife Brunhilda of Austrasia. When Childebert II died, he left two sons, Theuderic II who inherited the Kingdom of Burgundy, and Theudebert II who inherited the Kingdom of Austrasia. Since both were minors, Brunhilda, their grandmother, declared herself their guardian and controlled the governments of the two kingdoms.

Theuderic II venerated Columbanus and often visited him, but the saint admonished and rebuked him for his behaviour. When Theuderic began living with a mistress, the saint objected, earning the displeasure of Brunhilda, who thought a royal marriage would threaten her own power. The saint did not spare the demoralised court, and Brunhilda became his bitterest foe. Angered by the saint's moral stand, Brunhilda stirred up the bishops and nobles to find fault with his monastic rules. When Theuderic II finally confronted Columbanus at Luxeuil, ordering him to conform to the country's conventions, the saint refused and was then taken prisoner to Besançon. Columbanus managed to escape his captors and returned to his monastery at Luxeuil. When the king and his grandmother found out, they sent soldiers to drive him back to Ireland by force, separating him from his monks by insisting that only those from Ireland could accompany him into exile.

Columbanus was taken to Nevers, then travelled by boat down the Loire river to the coast. At Tours he visited the tomb of Saint Martin, and sent a message to Theuderic II indicating that within three years he and his children would perish. When he arrived at Nantes, he wrote a letter before embarkation to his fellow monks at Luxeuil monastery. Filled with love and affection, the letter urges his brethren to obey Attala, who stayed behind as abbot of the monastic community. The letter concludes:

Soon after the ship set sail from Nantes, a severe storm drove the vessel back ashore. Convinced that his holy passenger caused the tempest, the captain refused further attempts to transport the monk. Columbanus made his way across Gaul to visit King Chlothar II of Neustria at Soissons where he was gladly received. Despite the king's offers to stay in his kingdom, Columbanus left Neustria in 611 for the court of King Theudebert II of Austrasia in the northeastern part of the Kingdom of the Merovingian Franks.

Columbanus travelled to Metz, where he received an honourable welcome, and then proceeding to Mainz, where he sailed upwards the Rhine river to the lands of the Suebi and Alemanni in the northern Alps, intending to preach the Gospel to these people. He followed the Rhine river and its tributaries, the Aar and the Limmat, and then on to Lake Zurich. Columbanus chose the village of Tuggen as his initial community, but the work was not successful. He continued north-east by way of Arbon to Bregenz on Lake Constance. Here the saint found an oratory dedicated to Saint Aurelia containing three brass images of their tutelary deities. Columbanus commanded Gallus, who knew the local language, to preach to the inhabitants, and many were converted. The three brass images were destroyed, and Columbanus blessed the little church, placing the relics of Saint Aurelia beneath the altar. A monastery was erected, Mehrerau Abbey, and the brethren observed their regular life. Columbanus stayed in Bregenz for about one year. Following an uprising against the community, possibly related to that region being taken over by the saint's old enemy King Theuderic II, Columbanus resolved to cross the Alps into Italy. Gallus remained in this area and died there 646. About seventy years later at the place of Gallus' cell the Monastery of Saint Gall was founded, which in itself was the origin of the city of St. Gallen again about another three hundred years later.

Columbanus arrived in Milan in 612 and was warmly greeted by King Agilulf and Queen Theodelinda of the Lombards. He immediately began refuting the teachings of Arianism, which had enjoyed a degree of acceptance in Italy. He wrote a treatise against Arianism, which has since been lost. Queen Theodelinda, the devout daughter of Duke Garibald I of Bavaria, played an important role in restoring Nicene Christianity to a position of primacy against Arianism, and was largely responsible for the king's conversion to Christianity.

At the king's request, Columbanus wrote a letter to Pope Boniface IV on the controversy over the "Three Chapters"—writings by Syrian bishops suspected of Nestorianism, which had been condemned in the fifth century as heresy. Pope Gregory I had tolerated in Lombardy those persons who defended the "Three Letters", among them King Agilulf. Columbanus agreed to take up the issue on behalf of the king. The letter begins with an apology that a "foolish Scot ("Scottus", Irishman)" would be writing for a Lombard king. After acquainting the pope with the imputations brought against him, he entreats the pontiff to prove his orthodoxy and assemble a council. He writes that his freedom of speech is consistent with the custom of his country. Some of the language used in the letter might now be regarded as disrespectful, but in that time, faith and austerity could be more indulgent. At the same time, the letter expresses the most affectionate and impassioned devotion to the Holy See.

If Columbanus' zeal for orthodoxy caused him to overstep the limits of discretion, his real attitude towards Rome is sufficiently clear, calling the pope "his Lord and Father in Christ", the "Chosen Watchman", and the "First Pastor, set higher than all mortals".

King Agilulf gave Columbanus a tract of land called Bobbio between Milan and Genoa near the Trebbia river, situated in a defile of the Apennine Mountains, to be used as a base for the conversion of the Lombard people. The area contained a ruined church and wastelands known as "Ebovium", which had formed part of the lands of the papacy prior to the Lombard invasion. Columbanus wanted this secluded place, for while enthusiastic in the instruction of the Lombards he preferred solitude for his monks and himself. Next to the little church, which was dedicated to Saint Peter, Columbanus erected a monastery in 614. Bobbio Abbey at its foundation followed the Rule of Saint Columbanus, based on the monastic practices of Celtic Christianity. For centuries it remained the stronghold of orthodoxy in northern Italy.

During the last year of his life, Columbanus received messenges from King Chlothar II, inviting the saint to return to Burgundy, now that his enemies were dead. Columbanus did not return, but requested that the king should always protect his monks at Luxeuil Abbey. He prepared for death by retiring to his cave on the mountainside overlooking the Trebbia river, where, according to a tradition, he had dedicated an oratory to Our Lady. Columbanus died at Bobbio on 23 November 615.

The Rule of Saint Columbanus embodied the customs of Bangor Abbey and other Irish monasteries. Much shorter than the Rule of Saint Benedict, the Rule of Saint Columbanus consists of ten chapters, on the subjects of obedience, silence, food, poverty, humility, chastity, choir offices, discretion, mortification, and perfection.

In the first chapter, Columbanus introduces the great principle of his Rule: obedience, absolute and unreserved. The words of seniors should always be obeyed, just as "Christ obeyed the Father up to death for us." One manifestation of this obedience was constant hard labour designed to subdue the flesh, exercise the will in daily self-denial, and set an example of industry in cultivation of the soil. The least deviation from the Rule entailed corporal punishment, or a severe form of fasting. In the second chapter, Columbanus instructs that the rule of silence be "carefully observed", since it is written: "But the nurture of righteousness is silence and peace". He also warns, "Justly will they be damned who would not say just things when they could, but preferred to say with garrulous loquacity what is evil ..." In the third chapter, Columbanus instructs, "Let the monks' food be poor and taken in the evening, such as to avoid repletion, and their drink such as to avoid intoxication, so that it may both maintain life and not harm ..." Columbanus continues:

In the fourth chapter, Columbanus presents the virtue of poverty and of overcoming greed, and that monks should be satisfied with "small possessions of utter need, knowing that greed is a leprosy for monks". Columbanus also instructs that "nakedness and disdain of riches are the first perfection of monks, but the second is the purging of vices, the third the most perfect and perpetual love of God and unceasing affection for things divine, which follows on the forgetfulness of earthly things. Since this is so, we have need of few things, according to the word of the Lord, or even of one." In the fifth chapter, Columbanus warns against vanity, reminding the monks of Jesus' warning in Luke 16:15: "You are the ones who justify yourselves in the eyes of others, but God knows your hearts. What people value highly is detestable in God's sight." In the sixth chapter, Columbanus instructs that "a monk's chastity is indeed judged in his thoughts" and warns, "What profit is it if he be virgin in body, if he be not virgin in mind? For God, being Spirit."

In the seventh chapter, Columbanus instituted a service of perpetual prayer, known as "laus perennis", by which choir succeeded choir, both day and night. In the eighth chapter, Columbanus stresses the importance of discretion in the lives of monks to avoid "the downfall of some, who beginning without discretion and passing their time without a sobering knowledge, have been unable to complete a praiseworthy life." Monks are instructed to pray to God for to "illumine this way, surrounded on every side by the world's thickest darkness". Columbanus continues: 
In the ninth chapter, Columbanus presents mortification as an essential element in the lives of monks, who are instructed, "Do nothing without counsel." Monks are warned to "beware of a proud independence, and learn true lowliness as they obey without murmuring and hesitation." According to the Rule, there are three components to mortification: "not to disagree in mind, not to speak as one pleases with the tongue, not to go anywhere with complete freedom." This mirrors the words of Jesus, "For I have come down from heaven not to do my will but to do the will of him who sent me." (John 6:38) In the tenth and final chapter, Columbanus regulates forms of penance (often corporal) for offences, and it is here that the Rule of Saint Columbanus differs significantly from that of Saint Benedict.

The habit of the monks consisted of a tunic of undyed wool, over which was worn the cuculla, or cowl, of the same material. A great deal of time was devoted to various kinds of manual labour, not unlike the life in monasteries of other rules. The Rule of Saint Columbanus was approved of by the Synod of Mâcon in 627, but it was superseded at the close of the century by the Rule of Saint Benedict. For several centuries in some of the greater monasteries the two rules were observed conjointly.

Columbanus did not lead a perfect life. According to Jonas and other sources, he could be impetuous and even headstrong, for by nature he was eager, passionate, and dauntless. These qualities were both the source of his power and the cause of his mistakes. His virtues, however, were quite remarkable. Like many saints, he had a great love for God's creatures. Stories claim that as he walked in the woods, it was not uncommon for birds to land on his shoulders to be caressed, or for squirrels to run down from the trees and nestle in the folds of his cowl. Although a strong defender of Irish traditions, he never wavered in showing deep respect for the Holy See as the supreme authority. His influence in Europe was due to the conversions he effected and to the rule that he composed. It may be that the example and success of Saint Columba in Caledonia inspired him to similar exertions. The life of Columbanus stands as the prototype of missionary activity in Europe, followed by such men as Saint Kilian, Vergilius of Salzburg, Donatus of Fiesole, Wilfrid, Willibrord, Suitbert of Kaiserwerdt, Saint Boniface, and Ursicinus of Saint-Ursanne.

The following are the principal miracles attributed to his intercession:

Jonas relates the occurrence of a miracle during Columbanus' time in Bregenz, when that region was experiencing a period of severe famine.
One historians states Columbanus had a "very strong sense of Irish identity...He’s the first person to write about Irish identity, he’s the first Irish person that we have a body of literary work from, so even on that point of view he’s very important in terms of Irish identity.” In 1950 a congress celebrating the 1400 anniversary of his birth took place in Luxeuil, France. It was attended by Robert Schuman, Sean MacBride, future Pope John XXIII and John A. Costello who said “All statesmen of today might well turn their thoughts to St Columban and his teaching. History records that it was by men like him that civilisation was saved in the 6th century.”

Columbanus is also remembered as the first Irish person to be the subject of a biography. An Italian monk named Jonas of Bobbio wrote a biography of him some 20 years after Columbanus’ death. His use of the phrase in 600 AD totius Europae (all of Europe) in a letter to Pope Gregory the Great is the first known use of the expression.

In France, the ruins of Columbanus' first monastery at Annegray are legally protected through the efforts of the Association Internationale des Amis de St Columban, which purchased the site in 1959. The association also owns and protects the site containing the cave, which acted as Columbanus' cell, and the holy well, which he created nearby. At Luxeuil-les-Bains, the Basilica of Saint Peter stands on the site of Columbanus' first church. A statue near the entrance, unveiled in 1947, shows him denouncing the immoral life of King Theuderic II. Formally an abbey church, the basilica contains old monastic buildings, which have been used as a minor seminary since the nineteenth century. It is dedicated to Columbanus and houses a bronze statue of him in its courtyard.

In Lombardy, San Colombano al Lambro in Milan, San Colombano Belmonte in Turin, and San Colombano Certénoli in Genoa all take their names from the saint. The last monastery erected by Columbanus at Bobbio remained for centuries the stronghold of orthodoxy in northern Italy.

If Bobbio Abbey in Italy became a citadel of faith and learning, Luxeuil Abbey in France became the "nursery of saints and apostles". The monastery produced sixty-three apostles who carried his rule, together with the Gospel, into France, Germany, Switzerland, and Italy. These disciples of Columbanus are accredited with founding over one hundred different monasteries. The canton and town still bearing the name of St. Gallen testify to how well one of his disciples succeeded.

The Missionary Society of Saint Columban, founded in 1916, and the Missionary Sisters of St. Columban, founded in 1924, are both dedicated to Columbanus.

The remains of Columbanus are preserved in the crypt at Bobbio Abbey. Many miracles have been credited to his intercession. In 1482, the relics were placed in a new shrine and laid beneath the altar of the crypt. The sacristy at Bobbio possesses a portion of the skull of the saint, his knife, wooden cup, bell, and an ancient water vessel, formerly containing sacred relics and said to have been given to him by Pope Gregory I. According to some authorities, twelve teeth of the saint were taken from the tomb in the fifteenth century and kept in the treasury, but these have since disappeared.

Columbanus is named in the Roman Martyrology on 23 November, which is his feast day in Ireland. His feast is observed by the Benedictines on 24 November. Columbanus is the patron saint of motorcyclists. In art, Columbanus is represented bearded bearing the monastic cowl, holding in his hand a book with an Irish satchel, and standing in the midst of wolves. Sometimes he is depicted in the attitude of taming a bear, or with sun-beams over his head.




</doc>
<doc id="6503" url="https://en.wikipedia.org/wiki?curid=6503" title="Concord, New Hampshire">
Concord, New Hampshire

Concord () is the capital city of the U.S. state of New Hampshire and the county seat of Merrimack County. As of the 2010 census, its population was 42,695.

Concord includes the villages of Penacook, East Concord, and West Concord. The city is home to the University of New Hampshire School of Law, New Hampshire's only law school; St. Paul's School, a private preparatory school; NHTI, a two-year community college; and the Granite State Symphony Orchestra. It is the resting place of Franklin Pierce, 14th President of the United States.

The area that would become Concord was originally settled thousands of years ago by Abenaki Native Americans called the Pennacook. The tribe fished for migrating salmon, sturgeon, and alewives with nets strung across the rapids of the Merrimack River. The stream was also the transportation route for their birch bark canoes, which could travel from Lake Winnipesaukee to the Atlantic Ocean. The broad sweep of the Merrimack River valley floodplain provided good soil for farming beans, gourds, pumpkins, melons and maize.

On January 17, 1725, the Province of Massachusetts Bay, which then claimed territories west of the Merrimack River, granted the Concord area as the Plantation of Penacook. It was settled between 1725 and 1727 by Captain Ebenezer Eastman and others from Haverhill, Massachusetts. On February 9, 1734, the town was incorporated as Rumford, from which Sir Benjamin Thompson, Count Rumford would take his title. It was renamed Concord in 1765 by Governor Benning Wentworth following a bitter boundary dispute between Rumford and the town of Bow; the city name was meant to reflect the new concord, or harmony, between the disputant towns. Citizens displaced by the resulting border adjustment were given land elsewhere as compensation. In 1779, New Pennacook Plantation was granted to Timothy Walker, Jr. and his associates at what would be incorporated in 1800 as Rumford, Maine, the site of Pennacook Falls.

Concord grew in prominence throughout the 18th century, and some of its earliest houses survive at the northern end of Main Street. In the years following the Revolution, Concord's central geographical location made it a logical choice for the state capital, particularly after Samuel Blodget in 1807 opened a canal and lock system to allow vessels passage around the Amoskeag Falls downriver, connecting Concord with Boston by way of the Middlesex Canal. In 1808, Concord was named the official seat of state government. The 1819 State House is the oldest capitol in the nation in which the state's legislative branches meet in their original chambers. The city would become noted for furniture-making and granite quarrying. In 1828, Lewis Downing joined J. Stephens Abbot to form Abbot and Downing. Their most famous product was their Concord stagecoach, widely used in the development of the American West. In the 19th century, Concord became a hub for the railroad industry, with Penacook a textile manufacturing center using water power from the Contoocook River. Today, the city is a center for health care and several insurance companies.

Concord is located at (43.2070, −71.5371).

According to the United States Census Bureau, the city has a total area of . of it is land and of it is water, comprising 4.79% of the city. Concord is drained by the Merrimack River. Penacook Lake is in the west. The highest point in Concord is above sea level on Oak Hill, just west of the hill's summit in neighboring Loudon.

Concord lies fully within the Merrimack River watershed, and is centered on the river, which runs from northwest to southeast through the city. Downtown is located on a low terrace to the west of the river, with residential neighborhoods climbing hills to the west and extending southwards towards the town of Bow. To the east of the Merrimack, atop a bluff, is a flat, sandy plain known as Concord Heights, which has seen most of the city's commercial development since 1960. The eastern boundary of Concord (with the town of Pembroke) is formed by the Soucook River, a tributary of the Merrimack. The Turkey River winds through the southwestern quarter of the city, passing through the campus of St. Paul's School before entering the Merrimack River in Bow. In the northern part of the city, the Contoocook River enters the Merrimack at the village of Penacook. Other village centers in the city include West Concord (actually north of downtown, on the west side of the Merrimack) and East Concord (also north of downtown, but on the east side of the Merrimack).
The city's neighboring communities are Bow to the south, Pembroke to the southeast, Loudon to the northeast, Canterbury, Boscawen, and Webster to the north, and Hopkinton to the west. It is north of Manchester, New Hampshire's largest city, and north of Boston.

Concord, as with much of New England, is within the humid continental climate zone (Köppen "Dfb"), with long, cold, snowy winters, very warm (and at times humid) summers, and relatively brief autumns and springs. In winter, successive storms deliver light to moderate snowfall amounts, contributing to the relatively reliable snow cover. In addition, lows reach at least on an average 15 nights per year, and the city straddles the border between USDA Hardiness Zone 5b and 6a. However, thaws are frequent, with one to three days per month with + highs from December to February. Summer can bring stretches of humid conditions as well as thunderstorms, and there is an average of 12 days of + highs annually. The window for freezing temperatures on average begins on September 27 and expires on May 14.

The monthly daily average temperature range from in January to in July. Temperature extremes have ranged from in February 1943 to in July 1966.

As of the census of 2010, there were 42,695 people, 17,592 households, and 10,052 families residing in the city. The population density was 632.5 people per square mile (244.2/km²). There were 18,852 housing units at an average density of 293.2 per square mile (113.2/km²). The racial makeup of the city was 91.8% White, 2.2% Black or African American, 0.3% Native American, 3.4% Asian, 0.0% Pacific Islander, 0.4% from some other race, and 1.8% from two or more races. 2.1% of the population were Hispanic or Latino of any race.

There were 17,592 households out of which 28.7% had children under the age of 18 living with them, 41.3% were headed by married couples living together, 11.6% had a female householder with no husband present, and 42.9% were non-families. 33.6% of all households were made up of individuals, and 12.0% were someone living alone who was 65 years of age or older. The average household size was 2.26, and the average family size was 2.90.

In the city, the population was spread out with 20.7% under the age of 18, 9.3% from 18 to 24, 28.0% from 25 to 44, 28.2% from 45 to 64, and 13.8% who were 65 years of age or older. The median age was 39.4 years. For every 100 females, there were 98.5 males. For every 100 females age 18 and over, there were 96.9 males.

For the period 2009-11, the estimated median annual income for a household in the city was $52,695, and the median income for a family was $73,457. Male full-time workers had a median income of $49,228 versus $38,782 for females. The per capita income for the city was $29,296. About 5.5% of families and 10.1% of the population were below the poverty line, including 8.4% of those under age 18 and 5.5% of those age 65 or over.

In 2018, according to Concord's 2018 Comprehensive Annual Financial Report, the top employers in the city were:

Interstate 89 and Interstate 93 are the two main interstate highways serving Concord, and join just south of the city limits. Interstate 89 links Concord with Lebanon and the state of Vermont to the northwest, while Interstate 93 connects the city to Plymouth, Littleton, and the White Mountains to the north and Manchester to the south. Interstate 393 is a spur highway leading east from Concord and merging with U.S. Route 4 as a direct route to New Hampshire's seacoast. North-south U.S. Route 3 serves as Concord's Main Street, while U.S. Route 202 and New Hampshire Route 9 cross the city from east to west. Also, state routes 13 and 132 serve the city: Route 13 leads southwest out of Concord towards Goffstown and Milford, while Route 132 travels north parallel to Interstate 93. New Hampshire Route 106 passes through the easternmost part of Concord, crossing I-393 and NH 9 before crossing the Soucook River into the town of Pembroke. To the north, NH 106 leads to Loudon, Belmont, and Laconia.

Local bus service is provided by Concord Area Transit (CAT), with three routes through the city. Regional bus service provided by Concord Coach Lines and Greyhound Lines is available from the Concord Transportation Center at 30 Stickney Avenue next to Exit 14 on Interstate 93, with service south to Boston and points in between, as well as north to Littleton and northeast to Berlin.

There is no passenger rail service to Concord.

General aviation services are available through Concord Municipal Airport, located east of downtown. There is no commercial air service within the city limits; the nearest such airport is Manchester–Boston Regional Airport, located to the south.

Concord is governed via the manager-council system. The city council consists of 14 members, ten of which are elected from single-member wards, while the other four are elected at large. The mayor is elected directly every two years. The current mayor is Jim Bouley.

According to the Concord city charter, the mayor chairs the council (composed of 15 members, including the mayor). However, the mayor has very few formal powers over the day-to-day management of the city. The actual operations of the city are overseen by the city manager, currently Thomas J. Aspell, Jr. The current police chief is Bradley S. Osgood.

In the New Hampshire Senate, Concord is in the 15th District, represented by Democrat Dan Feltes. On the New Hampshire Executive Council, Concord is in the 2nd District, represented by Democrat Andru Volinsky. In the United States House of Representatives, Concord is in New Hampshire's 2nd congressional district, represented by Democrat Ann McLane Kuster.

New Hampshire Department of Corrections operates the New Hampshire State Prison for Men and New Hampshire State Prison for Women in Concord.

Newspapers

Radio
New Hampshire Public Radio is headquartered in Concord.

Television

The New Hampshire State House, designed by architect Stuart Park and constructed between 1815 and 1818, is the oldest state house in which the legislature meets in its original chambers. The building was remodeled in 1866, and the third story and west wing were added in 1910.

Across from the State House is the Eagle Hotel on Main Street, which has been a downtown landmark since its opening in 1827. U.S. Presidents Ulysses S. Grant, Rutherford Hayes, and Benjamin Harrison all dined there, and Franklin Pierce spent the night before departing for his inauguration. Other well-known guests included Jefferson Davis, Charles Lindbergh, Eleanor Roosevelt, Richard M. Nixon (who carried New Hampshire in all three of his presidential bids), and Thomas E. Dewey. The hotel closed in 1961.

South from the Eagle Hotel on Main Street is Phenix Hall, which replaced "Old" Phenix Hall, which burned in 1893. Both the old and new buildings featured multi-purpose auditoriums used for political speeches, theater productions, and fairs. Abraham Lincoln spoke at the old hall in 1860; Theodore Roosevelt, at the new hall in 1912.

North on Main Street is the Walker-Woodman House, also known as the Reverend Timothy Walker House, the oldest standing two-story house in Concord. It was built for the Reverend Timothy Walker between 1733 and 1735.

On the north end of Main Street is the Pierce Manse, in which President Franklin Pierce lived in Concord before and following his presidency. The mid-1830s Greek Revival house was moved from Montgomery Street to North Main Street in 1971 to prevent its demolition.

Beaver Meadow Golf Course, located in the northern part of Concord, is one of the oldest golf courses in New England. Besides this golf course, other important sporting venues in Concord include Everett Arena and Memorial Field.

The SNOB (Somewhat North Of Boston) Film Festival, started in the fall of 2002, brings independent films and filmmakers to Concord and has provided an outlet for local filmmakers to display their films. SNOB Film Festival was a catalyst for the building of Red River Theatres, a locally owned, nonprofit, independent cinema in 2007. The SNOB Film Festival is one of the many arts organizations in the city.

Other sites of interest include the Capitol Center for the Arts, the New Hampshire Historical Society, which has two facilities in Concord, and the McAuliffe-Shepard Discovery Center, a planetarium named after Christa McAuliffe, the Concord teacher who died during the Space Shuttle Challenger disaster in 1986.

Concord's public schools are within the Concord School District, except for schools in the Penacook area of the city, which are within the Merrimack Valley School District, a district which also includes several towns north of Concord. The only public high school in the Concord School District is Concord High School, which has about 2,000 students. The only public middle school in the Concord School District is Rundlett Middle School, which has roughly 1,500 students. Concord School District's elementary schools underwent a major re-configuration in 2012, with three newly constructed schools opening and replacing six previous schools. Kimball School and Walker School were replaced by Christa McAuliffe School on the Kimball School site, Conant School (and Rumford School, which closed a year earlier) were replaced by Abbot-Downing School at the Conant site, and Eastman and Dame schools were replaced by Mill Brook School, serving kindergarten through grade two, located next to Broken Ground Elementary School, serving grades three to five. Beaver Meadow School, the remaining elementary school, was unaffected by the changes.

Concord schools in the Merrimack Valley School District include Merrimack Valley High School and Merrimack Valley Middle School, which are adjacent to each other and to Rolfe Park in Penacook village, and Penacook Elementary School, just south of the village.

Concord has two parochial schools, Bishop Brady High School and Saint John Regional School.

Other area private schools include Concord Christian Academy, Parker Academy, Trinity Christian School, Shaker Road School, and St. Paul's School.

Concord is also home to NHTI, Concord's Community College, Granite State College, the University of New Hampshire School of Law, and the Franklin Pierce University Doctorate of Physical Therapy program.



</doc>
<doc id="6505" url="https://en.wikipedia.org/wiki?curid=6505" title="Chlorophyceae">
Chlorophyceae

The Chlorophyceae are one of the classes of green algae, distinguished mainly on the basis of ultrastructural morphology. For example, the chlorophycean CW clade, and chlorophycean DO clade, are defined by the arrangement of their flagella. Members of the CW clade have flagella that are displaced in a "clockwise" (CW, 1–7 o'clock) direction e.g. Chlamydomonadales. Members of the DO clade have flagella that are "directly opposed" (DO, 12–6 o'clock) e.g. Sphaeropleales. They are usually green due to the dominance of pigments chlorophyll a and chlorophyll b. The chloroplast may be discoid, plate-like, reticulate, cup-shaped, spiral or ribbon shaped in different species. Most of the members have one or more storage bodies called pyrenoids located in the chloroplast. Pyrenoids contain protein besides starch. Some algae may store food in the form of oil droplets. Green algae usually have a rigid cell wall made up of an inner layer of cellulose and outer layer of pectose.


Vegetative reproduction usually takes place by fragmentation. Asexual reproduction is by flagellated zoospores. And haplospore, perrination (akinate and palmellastage). Asexual reproduction by mytospore absent in spyrogyra.
Sexual reproduction shows considerable variation in the type and formation of sex cells and it may be isogamous e.g. "Chlamydomonas, Spirogyra". anisogamous e.g. "Chlamydomonas", "Ulothrix" or "Ooulothrix" e.g. "Chlamydomonas", "Volvox". "Chlamydomonas" has all three types of sexual reproduction.
They share many similarities with the higher plants, including the presence of asymmetrical flagellated cells, the breakdown of the nuclear envelope at mitosis, and the presence of phytochromes, flavonoids, and the chemical precursors to the cuticle.

The following orders are typically recognised:


In older classifications, the term Chlorophyceae is sometimes used to apply to all the green algae except the Charales, and the internal division is considerably different.

The Orders of the Chlorophyceae as listed by: in Hoek, Mann and Jahns (1995)




</doc>
<doc id="6508" url="https://en.wikipedia.org/wiki?curid=6508" title="Cyril">
Cyril

Cyril (also Cyrillus or Cyryl) is a masculine given name. It is derived from the Greek name Κύριλλος ("Kýrillos") meaning "Lordly, Masterful", which in turn derives from Greek κυριος ("kýrios") "lord". There are various variant forms of the Cyril name such as Cyrill, Cyrille, Ciril, Kirill, Kiryl, Kirillos, Kyrylo, Kiril, Kiro and Kyrill.

It may also refer to:







</doc>
<doc id="6511" url="https://en.wikipedia.org/wiki?curid=6511" title="Computational complexity">
Computational complexity

In computer science, the computational complexity, or simply complexity of an algorithm is the amount of resources required for running it. The computational complexity of a problem is the minimum of the complexities of all possible algorithms for this problem (including the unknown algorithms).

As the amount of needed resources varies with the input, the complexity is generally expressed as a function , where is the size of the input, and is either the worst-case complexity, that is the maximum of the amount of resources that are needed for all inputs of size , or the average-case complexity, that is average of the amount of resources over all input of size .

When the nature of the resources is not explicitly given, this is usually the time needed for running the algorithm, and one talks of time complexity. However, this depends on the computer that is used, and the time is generally expressed as the number of needed elementary operations, which are supposed to take a constant time on a given computer, and to change by a constant factor when one changes of computer.

Otherwise, the resource that is considered is often the size of the memory that is needed, and one talks of space complexity.

The study of the complexity of explicitly given algorithms is called analysis of algorithms, while the study of the complexity of problems is called computational complexity theory. Clearly, both areas are strongly related, as the complexity of an algorithm is always an upper bound of the complexity of the problem solved by this algorithm.

The resource that is most commonly considered is the time, and one talks of time complexity. When "complexity" is used without being qualified, this generally means time complexity.

The usual units of time are not used in complexity theory, because they are too dependent on the choice of a specific computer and of the evolution of the technology. Therefore, instead of the real time, one generally consider the elementary operations that are done during the computation. These operations are supposed to take a constant time on a given machine, and are often called "steps".

Another important resource is the size of computer memory that is needed for running algorithms.

The number of arithmetic operations is another resource that is commonly used. In this case, one talks of arithmetic complexity. If one knows an upper bound on the size of the binary representation of the numbers that occur during a computation, the time complexity is generally the product of the arithmetic complexity by a constant factor.

For many algorithms the size of the integers that are used during a computation is not bounded, and it is not realistic to consider that arithmetic operations take a constant time. Therefore, the time complexity, generally called bit complexity in this context, may be much larger than the arithmetic complexity. For example, the arithmetic complexity of the computation of the determinant of a integer matrix is formula_1 for the usual algorithms (Gaussian elimination). The bit complexity of the same algorithms is exponential in , because the size of the coefficients may grow exponentially during the computation. On the other hand, if these algorithms are coupled with multi-modular arithmetic, the bit complexity may be reduced to .

In sorting and searching, the resource that is generally considered is the number of entries comparisons. This is generally a good measure of the time complexity if data are suitably organized.

It is impossible to count the number of steps of an algorithm on all possible inputs. As the complexity increases generally with the size of the input, the complexity is generally expressed as a function of the size (in bits) of the input, and therefore, the complexity is a function of . However, the complexity of an algorithm may vary dramatically for different inputs of the same size. Therefore several complexity functions are commonly used.

The worst-case complexity is the maximum of the complexity over all inputs of size , and the average-case complexity is the average of the complexity over all inputs of size (this makes sense, as the number of possible inputs of a given size is finite). Generally, when "complexity" is used without being further specified, this is the worst-case time complexity that is considered.

It is generally difficult to compute precisely the worst-case and the average-case complexity. In addition, these exact values provide little practical application, as any change of computer or of model of computation would change the complexity somewhat. Moreover, the resource use is not critical for small values of , and this makes that, for small , the ease of implementation is generally more interesting than a good complexity.

For these reasons, one generally focuses on the behavior of the complexity for large , that is on its asymptotic behavior when tends to the infinity. Therefore, the complexity is generally expressed by using big O notation.

For example, the usual algorithm for integer multiplication has a complexity of formula_2 this means that there is a constant formula_3 such that the multiplication of two integers of at most digits may be done in a time less than formula_4 This bound is "sharp" in the sense that the worst-case complexity and the average-case complexity are formula_5 which means that there is a constant formula_6 such that these complexities are larger than formula_7 The radix does not appear in these complexity, as changing of radix changes only the constants formula_3 and formula_9

The evaluation of the complexity relies on the choice of a model of computation, which consist in defining the basic operations that are done in a unit of time. When the model of computation is not explicitly specified, this is generally meant as being multitape Turing machine.

A deterministic model of computation is a model of computation such that the successive states of the machine and the operations to be performed are completely determined by the preceding state. Historically, the first deterministic models were recursive functions, lambda calculus, and Turing machines. The model of Random access machines (also called RAM-machines) is also widely used, as closer to real computers.

When the model of computation is not specified, it is generally the model of multitape Turing machines. For most algorithms, the complexity is the same on multitape Turing machines and on RAM-machines, although, some care may be needed in storing data for getting this equivalence.

In a non-deterministic model of computation, such as non-deterministic Turing machines, some choices may be done at some steps of the computation. In complexity theory, one considers all possible choices simultaneously, and the non-deterministic time complexity is the time needed, when the best choices are always done. In other words, one considers that the computation is done simultaneously on as many (identical) processors as needed, and the non-deterministic computation time is the time spent by the first processor that finishes the computation. This parallelism is partly amenable to quantum computing via superposed entangled states in running specific quantum algorithms, like e.g. Shor's factorization of yet only small integers (: 21 = 3 × 7).

Even when such a computation model is not realistic yet, it has theoretical importance, mostly related to the P = NP problem, which questions the identity of the complexity classes formed by taking "polynomial time" and "non-deterministic polynomial time" as least upper bounds. Simulating an NP-algorithm on a deterministic computer usually takes "exponential time". A problem is in the complexity class NP, if it may be solved in polynomial time on a non-deterministic machine. A problem is NP-complete if, roughly speaking, it is in NP and is not easier than any other NP problem. Many combinatorial problems, such as the Knapsack problem, the travelling salesman problem, and the Boolean satisfiability problem are NP-complete. For all these problems, the best known algorithm has exponential complexity. If any one of these problems could be solved in polynomial time on a deterministic machine, then all NP problems could also be solved in polynomial time, and one would have P = NP. it is generally conjectured that with the practical implication that the worst cases of NP problems are intrinsically difficult to solve, i.e., take longer than any reasonable time span (decades!) for interesting lengths of input.

Parallel and distributed computing consist of splitting computation on several processors, which work simultaneously. The difference between the different model lies mainly in the way of transmitting information between processors. Typically, in parallel computing the data transmission between processors is very fast, while, in distributed computating, the data transmission is done through a network and is therefore much slower.

The time needed for a computation on processors is at least the quotient by of the time needed by a single processor. In fact this theoretically optimal bound can never be reached, because some subtasks cannot be parallelized, and some processors may have to wait a result from another processor.

The main complexity problem is thus to design algorithms such that the product of the computation time by the number of processors is as close as possible to the time needed for the same computation on a single processor.

A quantum computer is a computer whose model of computation is based on quantum mechanics. The Church–Turing thesis applies to quantum computers, that is, every problem that can be solved by a quantum computer may be also solved by a Turing machine. However, some problems may theoretically be solved with a much lower complexity using a quantum computer than using a classical computer. This is, for the moment, purely theoretical, as no one knows how to build an efficient quantum computer.

Quantum complexity theory has been developed for studying computational complexity of quantum computing. It is used in post-quantum cryptography, which consists of designing cryptographic protocols that will resist to attacks with quantum computers, when such computers will really exist.

The complexity of a problem is the infimum of the complexities of the algorithms that may solve the problem, including the unknowns algorithm. Thus the complexity of a problem is not greater than the complexity of any algorithm that solves the problems.

It follows that every complexity that is expressed with big O notation is a complexity of the algorithm as well as of the corresponding problem.

On the other hand, it is generally hard to obtain nontrivial lower bounds for problem complexity, and there are few methods for obtaining such lower bounds.

For solving most problems, it is required to read all input data, which, normally, needs a time proportional to the size of the data. Thus, such problems have a complexity that is at least linear, that is, using big omega notation, a complexity formula_10

The solution of some problems, typically in computer algebra and computational algebraic geometry, may be very large. In such a case, the complexity is lower bounded by the maximal size of the output, since the output must be written. For example, a system of polynomial equations of degree in indeterminates may have up to formula_11 complex solutions, if the number of solutions is finite (this is Bézout's theorem). As these solutions must be written down, the complexity of this problem is formula_12 For this problem, an algorithm of complexity formula_13 is known, which may thus be considered as asymptotically quasi-optimal.

A nonlinear lower bound of formula_14 is known for the number comparisons needed for a sorting algorithm. Thus the best sorting algorithms are optimal, as their complexity is formula_15 This lower bound results from the fact that there are ways of ordering objects. As each comparison splits in two parts this set of orders, the number of of comparisons that are needed for distinguishing all orders must verify formula_16 which implies formula_17 by Stirling's formula.

A standard method for getting lower bounds of complexity consists of "reducing" a problem to another problem. More precisely, suppose that one may encode a problem of size into a subproblem of size of a problem , and that the complexity of is formula_18 Without loss of generality, one may suppose that the function increases with and has an inverse function . Then the complexity of the problem is formula_19 This is this method that is used for proving that, if P ≠ NP (a unsolved conjecture), the complexity of every NP-complete problem is formula_20 for every positive integer .

Evaluating the complexity of an algorithm is an important part of algorithm design, as this gives useful information on the performance that may be expected.

It is a common misconception that the evaluation of the complexity of algorithms becomes less important, because of the exponential growth (Moore's law) of the power of modern computers. This is wrong because, this power increase allows working with large input data (big data). For example, when one want to sort alphabetically a list of a few hundreds of entries, such as the bibliography of a book, any algorithm should work well in less than a second. On the other hand, for a list of a million of entries (the phone numbers of a large town, for example), the elementary algorithms that require formula_21 comparisons would have to do a trillion of comparisons, which would need around three hours at the speed of 10 million of comparisons per second. On the other hand, the quicksort and merge sort require only formula_22 comparisons (as average-case complexity for the former, as worst-case complexity for the latter). For , this gives approximately 30,000,000 comparisons, which may be done in less than a second on a powerful computer.

Thus the evaluation of the complexity may allow eliminating many inefficient algorithms before any implementation. This may also be used for tuning complex algorithms without testing all variants. By determining the most costly steps of a complex algorithms, the study of complexity allows also focusing on these steps the effort for improving the efficiency of an implementation.




</doc>
<doc id="6512" url="https://en.wikipedia.org/wiki?curid=6512" title="Coercion">
Coercion

Coercion () is the practice of forcing another party to act in an involuntary manner by use of threats or force. It involves a set of various types of forceful actions that violate the free will of an individual to induce a desired response, for example: a bully demanding lunch money from a student or the student gets beaten. These actions may include extortion, blackmail, torture, threats to induce favors, or even sexual assault. In law, coercion is codified as a duress crime. Such actions are used as leverage, to force the victim to act in a way contrary to their own interests. Coercion may involve the actual infliction of physical pain/injury or psychological harm in order to enhance the credibility of a threat. The threat of further harm may lead to the cooperation or obedience of the person being coerced.

The purpose of coercion is to substitute one's aims to those of the victim. For this reason, many social philosophers have considered coercion as the polar opposite to freedom.

Various forms of coercion are distinguished: first on the basis of the "kind of injury" threatened, second according to its "aims" and "scope", and finally according to its "effects", from which its legal, social, and ethical implications mostly depend.

Physical coercion is the most commonly considered form of coercion, where the content of the conditional threat is the use of force against a victim, their relatives or property. An often used example is "putting a gun to someone's head" ("at gunpoint") or putting a "knife under the throat" ("at knifepoint" or cut-throat) to compel action or the victim gets killed or injured. These are so common that they are also used as metaphors for other forms of coercion.

Armed forces in many countries use firing squads to maintain discipline and intimidate the masses, or opposition, into submission or silent compliance. However, there also are nonphysical forms of coercion, where the threatened injury does not immediately imply the use of force. Byman and Waxman (2000) define coercion as "the use of threatened force, including the limited use of actual force to back up the threat, to induce an adversary to behave differently than it otherwise would." Coercion does not in many cases amount to destruction of property or life since compliance is the goal.

In psychological coercion, the threatened injury regards the victim's relationships with other people. The most obvious example is "blackmail", where the threat consists of the dissemination of damaging information. However, many other types are possible e.g. "emotional blackmail", which typically involves threats of rejection from or disapproval by a peer-group, or creating feelings of guilt/obligation via a display of anger or hurt by someone whom the victim loves or respects. Another example is coercive persuasion.

Psychological coercion – along with the other varieties – was extensively and systematically used by the government of the People's Republic of China during the "Thought Reform" campaign of 1951–1952. The process – carried out partly at "revolutionary universities" and partly within prisons – was investigated and reported upon by Robert Jay Lifton, then Research Professor of Psychiatry at Yale University: see Lifton (1961). The techniques used by the Chinese authorities included a technique derived from standard group psychotherapy, which was aimed at forcing the victims (who were generally intellectuals) to produce detailed and sincere ideological "confessions". For instance, a professor of formal logic called Chin Yueh-lin – who was then regarded as China's leading authority on his subject – was induced to write: "The new philosophy [of Marxism-Leninism], being scientific, is the supreme truth" [Lifton (1961) p. 545].




</doc>
<doc id="6513" url="https://en.wikipedia.org/wiki?curid=6513" title="Client–server model">
Client–server model

Client–server model is a distributed application structure that partitions tasks or workloads between the providers of a resource or service, called servers, and service requesters, called clients. Often clients and servers communicate over a computer network on separate hardware, but both client and server may reside in the same system. A server host runs one or more server programs which share their resources with clients. A client does not share any of its resources, but requests a server's content or service function. Clients therefore initiate communication sessions with servers which await incoming requests.
Examples of computer applications that use the client–server model are Email, network printing, and the World Wide Web.

The "client-server" characteristic describes the relationship of cooperating programs in an application. The server component provides a function or service to one or many clients, which initiate requests for such services.
Servers are classified by the services they provide. For example, a web server serves web pages and a file server serves computer files. A shared resource may be any of the server computer's software and electronic components, from programs and data to processors and storage devices. The sharing of resources of a server constitutes a "service".

Whether a computer is a client, a server, or both, is determined by the nature of the application that requires the service functions. For example, a single computer can run web server and file server software at the same time to serve different data to clients making different kinds of requests. Client software can also communicate with server software within the same computer. Communication between servers, such as to synchronize data, is sometimes called "inter-server" or "server-to-server" communication.

In general, a service is an abstraction of computer resources and a client does not have to be concerned with how the server performs while fulfilling the request and delivering the response. The client only has to understand the response based on the well-known application protocol, i.e. the content and the formatting of the data for the requested service.

Clients and servers exchange messages in a request–response messaging pattern. The client sends a request, and the server returns a response. This exchange of messages is an example of inter-process communication. To communicate, the computers must have a common language, and they must follow rules so that both the client and the server know what to expect. The language and rules of communication are defined in a communications protocol. All client-server protocols operate in the application layer. The application layer protocol defines the basic patterns of the dialogue. To formalize the data exchange even further, the server may implement an application programming interface (API). The API is an abstraction layer for accessing a service. By restricting communication to a specific content format, it facilitates parsing. By abstracting access, it facilitates cross-platform data exchange.

A server may receive requests from many distinct clients in a short period of time. A computer can only perform a limited number of tasks at any moment, and relies on a scheduling system to prioritize incoming requests from clients to accommodate them. To prevent abuse and maximize availability, server software may limit the availability to clients. Denial of service attacks are designed to exploit a server's obligation to process requests by overloading it with excessive request rates.

When a bank customer accesses online banking services with a web browser (the client), the client initiates a request to the bank's web server. The customer's login credentials may be stored in a database, and the web server accesses the database server as a client. An application server interprets the returned data by applying the bank's business logic, and provides the output to the web server. Finally, the web server returns the result to the client web browser for display. 

In each step of this sequence of client–server message exchanges, a computer processes a request and returns data. This is the request-response messaging pattern. When all the requests are met, the sequence is complete and the web browser presents the data to the customer.

This example illustrates a design pattern applicable to the client–server model: separation of concerns.

An early form of client–server architecture is remote job entry, dating at least to OS/360 (announced 1964), where the request was to run a job, and the response was the output.

While formulating the client–server model in the 1960s and 1970s, computer scientists building ARPANET (at the Stanford Research Institute) used the terms "server-host" (or "serving host") and "user-host" (or "using-host"), and these appear in the early documents RFC 5 and RFC 4. This usage was continued at Xerox PARC in the mid-1970s.

One context in which researchers used these terms was in the design of a computer network programming language called Decode-Encode Language (DEL). The purpose of this language was to accept commands from one computer (the user-host), which would return status reports to the user as it encoded the commands in network packets. Another DEL-capable computer, the server-host, received the packets, decoded them, and returned formatted data to the user-host. A DEL program on the user-host received the results to present to the user. This is a client–server transaction. Development of DEL was just beginning in 1969, the year that the United States Department of Defense established ARPANET (predecessor of Internet).

"Client-host" and "server-host" have subtly different meanings than "client" and "server". A host is any computer connected to a network. Whereas the words "server" and "client" may refer either to a computer or to a computer program, "server-host" and "user-host" always refer to computers. The host is a versatile, multifunction computer; "clients" and "servers" are just programs that run on a host. In the client–server model, a server is more likely to be devoted to the task of serving.

An early use of the word "client" occurs in "Separating Data from Function in a Distributed File System", a 1978 paper by Xerox PARC computer scientists Howard Sturgis, James Mitchell, and Jay Israel. The authors are careful to define the term for readers, and explain that they use it to distinguish between the user and the user's network node (the client). (By 1992, the word "server" had entered into general parlance.)

The client–server model does not dictate that server-hosts must have more resources than client-hosts. Rather, it enables any general-purpose computer to extend its capabilities by using the shared resources of other hosts. Centralized computing, however, specifically allocates a large amount of resources to a small number of computers. The more computation is offloaded from client-hosts to the central computers, the simpler the client-hosts can be. It relies heavily on network resources (servers and infrastructure) for computation and storage. A diskless node loads even its operating system from the network, and a computer terminal has no operating system at all; it is only an input/output interface to the server. In contrast, a fat client, such as a personal computer, has many resources, and does not rely on a server for essential functions.

As microcomputers decreased in price and increased in power from the 1980s to the late 1990s, many organizations transitioned computation from centralized servers, such as mainframes and minicomputers, to fat clients. This afforded greater, more individualized dominion over computer resources, but complicated information technology management. During the 2000s, web applications matured enough to rival application software developed for a specific microarchitecture. This maturation, more affordable mass storage, and the advent of service-oriented architecture were among the factors that gave rise to the cloud computing trend of the 2010s.

In addition to the client–server model, distributed computing applications often use the peer-to-peer (P2P) application architecture.

In the client–server model, the server is often designed to operate as a centralized system that serves many clients. The computing power, memory and storage requirements of a server must be scaled appropriately to the expected work-load ("i.e.", the number of clients connecting simultaneously). Load-balancing and failover systems are often employed to scale the server implementation.

In a peer-to-peer network, two or more computers ("peers") pool their resources and communicate in a decentralized system. Peers are coequal, or equipotent nodes in a non-hierarchical network. Unlike clients in a client–server or client–queue–client network, peers communicate with each other directly.
In peer-to-peer networking, an algorithm in the peer-to-peer communications protocol balances load, and even peers with modest resources can help to share the load. If a node becomes unavailable, its shared resources remain available as long as other peers offer it. Ideally, a peer does not need to achieve high availability because other, redundant peers make up for any resource downtime; as the availability and load capacity of peers change, the protocol reroutes requests.

Both client-server and master-slave are regarded as sub-categories of distributed peer-to-peer systems.


</doc>
<doc id="6514" url="https://en.wikipedia.org/wiki?curid=6514" title="County Dublin">
County Dublin

County Dublin ( or "Contae Átha Cliath") is one of the thirty-two traditional counties of Ireland. Prior to 1994 it was also an administrative county covering the whole county outside of Dublin City Council. In 1994, as part of a reorganisation of local government within Dublin the boundaries of Dublin City were redrawn, Dublin County Council was abolished and three new administrative county councils were established: Dún Laoghaire–Rathdown, Fingal and South Dublin.

While it is no longer used as an administrative division for local government, it retains a strong identity in popular culture. It is in the province of Leinster, and is named after the city of Dublin, the capital city of Ireland. County Dublin was one of the first parts of Ireland to be shired by John, King of England following the Norman invasion of Ireland. 

According to the 2016 census, the total population of County Dublin was 1,345,402. The county is a NUTS 3 region, and is part of the NUTS 2 region of Eastern and Midland.

There are four local authorities whose remit collectively encompasses the geographic area of the county and city of Dublin. These are Dublin City Council, South Dublin County Council, Dún Laoghaire–Rathdown County Council and Fingal County Council.

Prior to the enactment of the Local Government (Dublin) Act 1993, the county was a unified whole even though it was administered by two local authorities – Dublin County Council and Dublin Corporation. Since the enactment of the Local Government Act 2001 in particular, the geographic area of the county has been divided between three entities at the level of "county" and a further entity at the level of "city". They rank equally as first level local administrative units of the NUTS 3 Dublin Region for Eurostat purposes. There are 34 LAU 1 entities in the Republic of Ireland. Each local authority is responsible for certain local services such as sanitation, planning and development, libraries, the collection of motor taxation, local roads and social housing.

Dublin County Council (which did not include the county borough of Dublin) was abolished in 1994 and the area divided among the administrative counties of Dún Laoghaire–Rathdown, Fingal and South Dublin each with its county seat. To these areas may be added the area of Dublin city which collectively comprise the Dublin Region ("") and come under the remit of the Dublin Regional Authority.

The area lost its administrative county status in 1994, with Section 9 Part 1(a) of the "Local Government (Dublin) Act, 1993" stating that "the county shall cease to exist." In discussing the legislation to dissolve Dublin County Council, Avril Doyle TD said, "The Bill before us today effectively abolishes County Dublin, and as one born and bred in these parts of Ireland I find it rather strange that we in this House are abolishing County Dublin. I am not sure whether Dubliners realise that that is what we are about today, but in effect that is the case."

The county is part of the Dublin constituency for the purposes of European elections. For elections to Dáil Éireann, the area of the county is currently (2016) divided into eleven constituencies: Dublin Bay North, Dublin Bay South, Dublin Central, Dublin Fingal, Dublin Mid-West, Dublin North-West, Dublin Rathdown, Dublin South-Central, Dublin South-West, Dublin West, and Dún Laoghaire. Together they return 44 deputies (TDs) to the Dáil.

Despite the legal status of the Dublin Region, the term "County Dublin" is still in common usage. Many organisations and sporting teams continue to organise on a "County Dublin" or "Dublin Region" basis. The area formerly known as "County Dublin" is now defined in legislation solely as the "Dublin Region" under the "Local Government Act, 1991 (Regional Authorities) (Establishment) Order, 1993", and this is the terminology officially used by the four Dublin administrative councils in press releases concerning the former county area. The term "Greater Dublin Area", which might consist of some or all of the Dublin Region along with counties of Kildare, Meath and Wicklow, has no legal standing.

The Dublin Region is a NUTS Level III region of Ireland. The region is one of eight regions of the Republic of Ireland for the purposes of Eurostat statistics. Its NUTS code is IE061. It is co-extensive with the old county. The regional capital is Dublin City which is also the national capital.

The latest Ordnance Survey Ireland "Discovery Series" (Third Edition 2005) 1:50,000 map of the Dublin Region, Sheet 50, shows the boundaries of the city and three surrounding counties of the region. Extremities of the Dublin Region, in the north and south of the region, appear in other sheets of the series, 43 and 56 respectively.

Local radio stations include 98FM, FM104, 103.2 Dublin City FM, Q102, SPIN 1038, Sunshine 106.8, TXFM, Raidió Na Life and Radio Nova.

Local newspapers include "The Echo", "Northside People", "Southside People" and the "Liffey Champion".

Most of the area can receive the five main UK television channels as well as the main Irish channels, along with Sky TV and Virgin Media Ireland cable television.


The economy of County Dublin was identified as being the powerhouse behind the Celtic Tiger, a period of strong economic growth of the state. This resulted in the economy of the county expanding by almost 100% between the early 1990s and 2007. This growth resulted from incoming high-value industries, such as financial services and software manufacturing, as well as low-skilled retail and domestic services, which caused a shift away from older manufacturing-industry. This change saw high unemployment in the 1980s and early 1990s which resulted in damage to the capitals social structure.

According to CSO figures, the region had a GDP of €87.238 bn and a GDP per capita of €68,208 in 2014 (the second highest was Cork at €50,544 per capita). 

Separately, Eurostat figures for 2012 suggested the region then had a GDP of €72.384 bn and a GDP per capita of €57,200 – the highest on the island of Ireland (the second highest being Cork with €48,500). 

As of early 2017, the unemployment rate for the Dublin region was estimated at 6%.

County Dublin is the main transport node of Ireland, and contains one international airport, Dublin Airport. It is also served by two main seaports, Dún Laoghaire port and Dublin Port, which is just located outside of the city center. The two main train stations are Dublin Heuston and Dublin Connolly, both of which serve intercity trains.

According to the 2006 census, County Dublin had a population of 1,187,176, which constitutes 30% of the national population. This was an increase of 9.5% on 2002 figures. Its population density was 1,218/km². The population of Dublin City, was 506,211.

The median age of the population of the county in the 2006 census was 35.6 years, with 62% of people aged between 20–64 years old. Net migration to the county between 2002 and 2006 was 48,000, with a natural increase of 33,000 people.

There are 10,469 Irish speakers in County Dublin attending the 31 Gaelscoileanna (Irish language primary schools) and eight Gaelcholáistí (Irish language secondary schools). There may be up to another 10,000 Irish speakers from the Gaeltacht living and working in Dublin also.

A list of the largest urban areas (those with over 1,000 inhabitants) in County Dublin. Administrative county seats are shown in bold.




</doc>
<doc id="6516" url="https://en.wikipedia.org/wiki?curid=6516" title="Cosmological argument">
Cosmological argument

In natural theology and philosophy, a cosmological argument is an argument in which the existence of a unique being, generally seen as some kind of god, is deduced or inferred from facts or alleged facts concerning causation, change, motion, contingency, or finitude in respect of the universe as a whole or processes within it. It is traditionally known as an argument from universal causation, an argument from first cause, or the causal argument, and is more precisely a cosmo"gonic"al argument (about the "origin"). Whichever term is employed, there are three basic variants of the argument, each with subtle yet important distinctions: the arguments from "in causa" (causality), "in esse" (essentiality), and "in fieri" (becoming).

The basic premises of all of these are the concept of causality. The conclusion of these arguments is first cause, subsequently deemed to be God. The history of this argument goes back to Aristotle or earlier, was developed in Neoplatonism and early Christianity and later in medieval Islamic theology during the 9th to 12th centuries, and re-introduced to medieval Christian theology in the 13th century by Thomas Aquinas. The cosmological argument is closely related to the principle of sufficient reason as addressed by Gottfried Leibniz and Samuel Clarke, itself a modern exposition of the claim that "nothing comes from nothing" attributed to Parmenides.

Contemporary defenders of cosmological arguments include William Lane Craig, Robert Koons, Alexander Pruss, and William L. Rowe.

Plato (c. 427–347 BC) and Aristotle (c. 384–322 BC) both posited first cause arguments, though each had certain notable caveats. In "The Laws" (Book X), Plato posited that all movement in the world and the Cosmos was "imparted motion". This required a "self-originated motion" to set it in motion and to maintain it. In "Timaeus", Plato posited a "demiurge" of supreme wisdom and intelligence as the creator of the Cosmos.

Aristotle argued "against" the idea of a first cause, often confused with the idea of a "prime mover" or "unmoved mover" ( or "primus motor") in his "Physics" and "Metaphysics". Aristotle argued in "favor" of the idea of several unmoved movers, one powering each celestial sphere, which he believed lived beyond the sphere of the fixed stars, and explained why motion in the universe (which he believed was eternal) had continued for an infinite period of time. Aristotle argued the atomist's assertion of a non-eternal universe would require a first uncaused cause – in his terminology, an efficient first cause – an idea he considered a nonsensical flaw in the reasoning of the atomists.

Like Plato, Aristotle believed in an eternal cosmos with no beginning and no end (which in turn follows Parmenides' famous statement that "nothing comes from nothing"). In what he called "first philosophy" or metaphysics, Aristotle "did" intend a theological correspondence between the prime mover and deity (presumably Zeus); functionally, however, he provided an explanation for the apparent motion of the "fixed stars" (now understood as the daily rotation of the Earth). According to his theses, immaterial unmoved movers are eternal unchangeable beings that constantly think about thinking, but being immaterial, they are incapable of interacting with the cosmos and have no knowledge of what transpires therein. From an "aspiration or desire", the celestial spheres, "imitate" that purely intellectual activity as best they can, by uniform circular motion. The unmoved movers "inspiring" the planetary spheres are no different in kind from the prime mover, they merely suffer a dependency of relation to the prime mover. Correspondingly, the motions of the planets are subordinate to the motion inspired by the prime mover in the sphere of fixed stars. Aristotle's natural theology admitted no creation or capriciousness from the immortal pantheon, but maintained a defense against dangerous charges of impiety.

Plotinus, a third-century Platonist, taught that the One transcendent absolute caused the universe to exist simply as a consequence of its existence ("creatio ex deo"). His disciple Proclus stated "The One is God".

Centuries later, the Islamic philosopher Avicenna (c. 980–1037) inquired into the question of being, in which he distinguished between essence ("Mahiat") and existence ("Wujud"). He argued that the fact of existence could not be inferred from or accounted for by the essence of existing things, and that form and matter by themselves could not originate and interact with the movement of the Universe or the progressive actualization of existing things. Thus, he reasoned that existence must be due to an agent cause that necessitates, imparts, gives, or adds existence to an essence. To do so, the cause must coexist with its effect and be an existing thing.

Steven Duncan writes that it "was first formulated by a Greek-speaking Syriac Christian neo-Platonist, John Philoponus, who claims to find a contradiction between the Greek pagan insistence on the eternity of the world and the Aristotelian rejection of the existence of any actual infinite". Referring to the argument as the "'Kalam' cosmological argument", Duncan asserts that it "received its fullest articulation at the hands of [medieval] Muslim and Jewish exponents of "Kalam" ("the use of reason by believers to justify the basic metaphysical presuppositions of the faith").

Thomas Aquinas (c. 1225–1274) adapted and enhanced the argument he found in his reading of Aristotle and Avicenna to form one of the most influential versions of the cosmological argument. His conception of First Cause was the idea that the Universe must be caused by something that is itself uncaused, which he claimed is that which we call God: 

Importantly, Aquinas' Five Ways, given the second question of his Summa Theologica, are not the entirety of Aquinas' demonstration that the Christian God exists. The Five Ways form only the beginning of Aquinas' Treatise on the Divine Nature.

In the scholastic era, Aquinas formulated the "argument from contingency", following Aristotle in claiming that there must be something to explain why the Universe exists. Since the Universe could, under different circumstances, conceivably "not" exist (contingency), its existence must have a cause – not merely another contingent thing, but something that exists by necessity (something that "must" exist in order for anything else to exist). In other words, even if the Universe has always existed, it still owes its existence to an uncaused cause, Aquinas further said: "... and this we understand to be God."

Aquinas's argument from contingency allows for the possibility of a Universe that has no beginning in time. It is a form of argument from universal causation. Aquinas observed that, in nature, there were things with contingent existences. Since it is possible for such things not to exist, there must be some time at which these things did not in fact exist. Thus, according to Aquinas, there must have been a time when nothing existed. If this is so, there would exist nothing that could bring anything into existence. Contingent beings, therefore, are insufficient to account for the existence of contingent beings: there must exist a "necessary" being whose non-existence is an impossibility, and from which the existence of all contingent beings is derived.

The German philosopher Gottfried Leibniz made a similar argument with his principle of sufficient reason in 1714. "There can be found no fact that is true or existent, or any true proposition," he wrote, "without there being a sufficient reason for its being so and not otherwise, although we cannot know these reasons in most cases." He formulated the cosmological argument succinctly: "Why is there something rather than nothing? The sufficient reason ... is found in a substance which ... is a necessary being bearing the reason for its existence within itself."

Leibniz's contingency argument was summarised by William Lane Craig, as follows:


Craig states that the only disputable statements are 1. and 2. He defended 1. from the question of "What caused God?" by saying that God cannot be caused by anything, as that would imply that there is something greater than him, which is logically contradictory. He also denied that the universe was an exception to the rule, claiming that such a proposition begs the question. He states that saying 2. is wrong contradicts modern science, and that, far from not being specific to the God of Christianity, it actually leads to evidence specifically linking to a being outside of space and time, as well as one that is omnipotent and omniscient.

The difference between the arguments from causation "in fieri" and "in esse" is a fairly important one. "In fieri" is generally translated as "becoming", while "in esse" is generally translated as "in essence". "In fieri", the process of becoming, is similar to building a house. Once it is built, the builder walks away, and it stands on its own accord; compare the watchmaker analogy. (It may require occasional maintenance, but that is beyond the scope of the first cause argument.)

"In esse" (essence) is more akin to the light from a candle or the liquid in a vessel. George Hayward Joyce, SJ, explained that, "where the light of the candle is dependent on the candle's continued existence, not only does a candle produce light in a room in the first instance, but its continued presence is necessary if the illumination is to continue. If it is removed, the light ceases. Again, a liquid receives its shape from the vessel in which it is contained; but were the pressure of the containing sides withdrawn, it would not retain its form for an instant." This form of the argument is far more difficult to separate from a purely first cause argument than is the example of the house's maintenance above, because here the First Cause is insufficient without the candle's or vessel's continued existence.

Thus, Leibniz' argument is "in fieri", while Aquinas' argument is both "in fieri" and "in esse". This distinction is an excellent example of the difference between a deistic view (Leibniz) and a theistic view (Aquinas). As a general trend, the modern slants on the cosmological argument, including the Kalam argument, tend to lean very strongly towards an "in fieri" argument.

The philosopher Robert Koons has stated a new variant on the cosmological argument. He says that to deny causation is to deny all empirical ideas – for example, if we know our own hand, we know it because of the chain of causes including light being reflected upon one's eyes, stimulating the retina and sending a message through the optic nerve into your brain. He summarised the purpose of the argument as "that if you don't buy into theistic metaphysics, you're undermining empirical science. The two grew up together historically and are culturally and philosophically inter-dependent ... If you say I just don't buy this causality principle – that's going to be a big big problem for empirical science." This "in fieri" version of the argument therefore does not intend to prove God, but only to disprove objections involving science, and the idea that contemporary knowledge disproves the cosmological argument. 

William Lane Craig gives this argument in the following general form:

Craig explains, by nature of the event (the Universe coming into existence), attributes unique to (the concept of) God must also be attributed to the cause of this event, including but not limited to: omnipotence, Creator, being eternal and absolute self-sufficiency. Since these attributes are unique to God, anything with these attributes must be God. Something does have these attributes: the cause; hence, the cause is God, the cause exists; hence, God exists.

Craig defends the second premise, that the Universe had a beginning starting with Al-Ghazali's proof that an actual infinite is impossible. However, If the universe never had a beginning then there indeed would be an actual infinite, an infinite amount of cause and effect events. Hence, the Universe had a beginning.

Duns Scotus, the influential Medieval Christian theologian, created a metaphysical argument for the existence of God. Though it was inspired by Aquinas' argument from motion, he, like other philosophers and theologians, believed that his statement for God's existence could be considered separate to Aquinas'. His explanation for God's existence is long, and can be summarised as follows:

Scotus deals immediately with two objections he can see: first, that there cannot be a first, and second, that the argument falls apart when 1) is questioned. He states that infinite regress is impossible, because it provokes unanswerable questions, like, in modern English, "What is infinity minus infinity?" The second he states can be answered if the question is rephrased using modal logic, meaning that the first statement is instead "It is possible that something can be produced."

One objection to the argument is that it leaves open the question of why the First Cause is unique in that it does not require any causes. Proponents argue that the First Cause is exempt from having a cause, while opponents argue that this is special pleading or otherwise untrue. Critics often press that arguing for the First Cause's exemption raises the question of why the First Cause is indeed exempt, whereas defenders maintain that this question has been answered by the various arguments, emphasizing that none of its major forms rests on the premise that everything has a cause.

William Lane Craig, who famously uses the Kalam cosmological argument, argues that, as the infinite is impossible, whichever perspective the viewer takes, there must always have been one unmoved thing to begin the universe. He uses Hilbert's paradox of the Grand Hotel and the question 'What is infinity minus infinity?' to illustrate the idea that the infinite is metaphysically, mathematically, and even conceptually, impossible. Other reasons include the fact that it is impossible to count down from infinity, and that, had the universe existed for an infinite amount of time, every possible event, including the final end of the universe, would already have occurred. He therefore states his argument in three points- firstly, everything that begins to exist has a cause of its existence; secondly, the universe began to exist; so, thirdly, therefore, the universe has a cause of its existence. A response to this argument would be that the cause of the universe's existence (God) would need a cause for its existence, which, in turn, could be responded to as being logically inconsistent with the evidence already presented- even if God did have a cause, there would still necessarily be a cause which began everything, owing to the impossibility of the infinite stated by Craig.

Secondly, it is argued that the premise of causality has been arrived at via "a posteriori" (inductive) reasoning, which is dependent on experience. David Hume highlighted this problem of induction and argued that causal relations were not true "a priori". However, as to whether inductive or deductive reasoning is more valuable still remains a matter of debate, with the general conclusion being that neither is prominent. Opponents of the argument tend to argue that it is unwise to draw conclusions from an extrapolation of causality beyond experience. Andrew Loke replies that, according to the Kalam Cosmological Argument, only things which begin to exist require a cause. On the other hand, something that is without beginning has always existed and therefore does not require a cause. The Cosmological Argument shows that there cannot be an actual infinite regress of causes, therefore there must be an uncaused First Cause that is beginningless and does not require a cause.

The basic cosmological argument merely establishes that a First Cause exists, not that it has the attributes of a theistic god, such as omniscience, omnipotence, and omnibenevolence. This is why the argument is often expanded to show that at least some of these attributes are necessarily true, for instance in the modern Kalam argument given above.

A causal loop is a form of predestination paradox arising where traveling backwards in time is deemed a possibility. A sufficiently powerful entity in such a world would have the capacity to travel backwards in time to a point before its own existence, and to then create itself, thereby initiating everything which follows from it.

The usual reason which is given to refute the possibility of a causal loop is it requires that the loop as a whole be its own cause. Richard Hanley argues that causal loops are not logically, physically, or epistemically impossible: "[In timed systems,] the only possibly objectionable feature that all causal loops share is that coincidence is required to explain them." However, Andrew Loke argues that causal loop of the type that is supposed to avoid a First Cause suffers from the problem of vicious circularity and thus it would not work.

David Hume and later Paul Edwards have invoked a similar principle in their criticisms of the cosmological argument. Rowe has called the principle the Hume-Edwards principle:
Nevertheless, David White argues that the notion of an infinite causal regress providing a proper explanation is fallacious. Furthermore, Demea states that even if the succession of causes is infinite, the whole chain still requires a cause. To explain this, suppose there exists a causal chain of infinite contingent beings. If one asks the question, "Why are there any contingent beings at all?", it does not help to be told that "There are contingent beings because other contingent beings caused them." That answer would just presuppose additional contingent beings. An adequate explanation of why some contingent beings exist would invoke a different sort of being, a necessary being that is "not" contingent. A response might suppose each individual is contingent but the infinite chain as a whole is not; or the whole infinite causal chain to be its own cause.

Severinsen argues that there is an "infinite" and complex causal structure. White tried to introduce an argument "without appeal to the principle of sufficient reason and without denying the possibility of an infinite causal regress". A number of other arguments have been offered to demonstrate that an actual infinite regress cannot exist, viz. the argument for the impossibility of concrete actual infinities, the argument for the impossibility of traversing an actual infinite, the argument from the lack of capacity to begin to exist, and various arguments from paradoxes.

Some cosmologists and physicists argue that a challenge to the cosmological argument is the nature of time: "One finds that time just disappears from the Wheeler–DeWitt equation" (Carlo Rovelli). The Big Bang theory states that it is the point in which all dimensions came into existence, the start of both space and time. Then, the question "What was there before the Universe?" makes no sense; the concept of "before" becomes meaningless when considering a situation without time. This has been put forward by J. Richard Gott III, James E. Gunn, David N. Schramm, and Beatrice Tinsley, who said that asking what occurred before the Big Bang is like asking what is north of the North Pole. However, some cosmologists and physicists do attempt to investigate causes for the Big Bang, using such scenarios as the collision of membranes.

Philosopher Edward Feser states that classical philosophers' arguments for the existence of God do not care about the Big Bang or whether the universe had a beginning. The question is not about what got things started or how long they have been going, but rather what keeps them going.

Alternatively, the above objections can be dispelled by separating the Cosmological Argument from the A-Theory of Time and subsequently discussing God as a "timeless" (rather than "before" in a linear sense) cause of the Big Bang. There is also a Big Bang Argument, which is a variation of the Cosmological Argument using the Big Bang Theory to validate the premise that the Universe had a beginning.



</doc>
<doc id="6517" url="https://en.wikipedia.org/wiki?curid=6517" title="Clutch">
Clutch

A clutch is a mechanical device which engages and disengages power transmission especially from driving shaft to driven shaft.

In the simplest application, clutches connect and disconnect two rotating shafts (drive shafts or line shafts). In these devices, one shaft is typically attached to an engine or other power unit (the driving member) while the other shaft (the driven member) provides output power for work. While typically the motions involved are rotary, linear clutches are also possible.

In a torque-controlled drill, for instance, one shaft is driven by a motor and the other drives a drill chuck. The clutch connects the two shafts so they may be locked together and spin at the same speed (engaged), locked together but spinning at different speeds (slipping), or unlocked and spinning at different speeds (disengaged).

The vast majority of clutches ultimately rely on frictional forces for their operation. The purpose of friction clutches is to connect a moving member to another that is moving at a different speed or stationary, often to synchronize the speeds, and/or to transmit power. Usually, as little slippage (difference in speeds) as possible between the two members is desired.

Various materials have been used for the disc-friction facings, including asbestos in the past. Modern clutches typically use a compound organic resin with copper wire facing or a ceramic material. Ceramic materials are typically used in heavy applications such as racing or heavy-duty hauling, though the harder ceramic materials increase flywheel and pressure plate wear.

In the case of "wet" clutches, composite paper materials are very common. Since these "wet" clutches typically use an oil bath or flow-through cooling method for keeping the disc pack lubricated and cooled, very little wear is seen when using composite paper materials.

Friction-disc clutches generally are classified as "push type" or "pull type" depending on the location of the pressure plate fulcrum points. In a pull-type clutch, the action of pressing the pedal pulls the release bearing, pulling on the diaphragm spring and disengaging the vehicle drive. The opposite is true with a push type, the release bearing is pushed into the clutch disengaging the vehicle drive. In this instance, the release bearing can be known as a thrust bearing (as per the image above).

A clutch damper is a device that softens the response of the clutch engagement/disengagement. In automotive applications, this is often provided by a mechanism in the clutch disc centres. In addition to the damped disc centres, which reduce driveline vibration, pre-dampers may be used to reduce gear rattle at idle by changing the natural frequency of the disc. These weaker springs are compressed solely by the radial vibrations of an idling engine. They are fully compressed and no longer in use once the main damper springs take up drive.

Mercedes truck examples:
A clamp load of 33 kN is normal for a single plate 430. The 400 Twin application offers a clamp load of a mere 23 kN. Bursts speeds are typically around 5,000 rpm with the weakest point being the facing rivet.

Modern clutch development focuses its attention on the simplification of the overall assembly and/or manufacturing method. For example, drive straps are now commonly employed to transfer torque as well as lift the pressure plate upon disengagement of vehicle drive. With regard to the manufacture of diaphragm springs, heat treatment is crucial. Laser welding is becoming more common as a method of attaching the drive plate to the disc ring with the laser typically being between 2-3KW and a feed rate 1m/minute.

This type of clutch has several driving members interleaved or "stacked" with several driven members. It is used in racing cars including Formula 1, IndyCar, World Rally and even most club racing. Multiplate clutches see much use in drag racing, which requires the best acceleration possible, and is notorious for the abuse the clutch is subjected to. Thus, they can be found in motorcycles, in automatic transmissions and in some diesel locomotives with mechanical transmissions. It is also used in some electronically controlled all-wheel drive systems as well as in some transfer cases. They can also be found in some heavy machinery such as tanks and AFVs (T-54) and earthmoving equipment (front-end loaders, bulldozers), as well as components in certain types of limited slip differentials. The benefit in the case of motorsports is that you can achieve the same total friction force with a much smaller overall diameter (or conversely, a much greater friction force for the same diameter, important in cases where a vehicle is modified with greater power, yet the maximum physical size of the clutch unit is constrained by the clutch housing). In motorsports vehicles that run at high engine/drivetrain speeds, the smaller diameter reduces rotational inertia, making the drivetrain components accelerate more rapidly, as well as reducing the velocity of the outer areas of the clutch unit, which could become highly stressed and fail at the extremely high drivetrain rotational rates achieved in sports such as Formula 1 or drag racing. In the case of heavy equipment, which often deal with very high torque forces and drivetrain loads, a single plate clutch of the necessary strength would be too large to easily package as a component of the driveline.

Another, different theme on the multiplate clutch is the clutches used in the fastest classes of drag racing, highly specialized, purpose-built cars such as Top Fuel dragsters or Funny Cars. These cars are so powerful that to attempt a start with a simple clutch would result in complete loss of traction. To avoid this problem, Top Fuel cars actually use a single, fixed gear ratio, and a "series" of clutches that are engaged one at a time, rather than in unison, progressively allowing more power to the wheels. A single one of these clutch plates (as designed) cannot hold more than a fraction of the power of the engine, so the driver starts with only the first clutch engaged. This clutch is overwhelmed by the power of the engine, allowing only a fraction of the power to the wheels, much like "slipping the clutch" in a slower car, but working without requiring concentration from the driver. As speed builds, the driver pulls a lever, which engages a second clutch, sending a bit more of the engine power to the wheels, and so on. This continues through several clutches until the car has reached a speed where the last clutch can be engaged. With all clutches engaged, the engine is now sending all of its power to the rear wheels. This is far more predictable and repeatable than the driver manually slipping the clutch himself and then shifting through the gears, given the extreme violence of the run and the speed at which it all unfolds. Another benefit is that there is no need to break the power flow in order to swap gears (a conventional manual cannot transmit power while between gears, which is important because 1/100ths of a second are important in Top Fuel races). A traditional multiplate clutch would be more prone to overheating and failure, as all the plates must be subjected to heat and friction together until the clutch is fully engaged, while a Top Fuel car keeps its last clutches in "reserve" until the cars speed allows full engagement. It is relatively easy to design the last stages to be much more powerful than the first, in order to ensure they can absorb the power of the engine even if the first clutches burn out or overheat from the extreme friction.

A "wet clutch" is immersed in a cooling lubricating fluid that also keeps surfaces clean and provides smoother performance and longer life. Wet clutches, however, tend to lose some energy to the liquid. Since the surfaces of a wet clutch can be slippery (as with a motorcycle clutch bathed in engine oil), stacking multiple clutch discs can compensate for the lower coefficient of friction and so eliminate slippage under power when fully engaged.
The Hele-Shaw clutch was a wet clutch that relied entirely on viscous effects, rather than on friction.

A "dry clutch", as the name implies, is not bathed in liquid and uses friction to engage.

A centrifugal clutch is used in some vehicles (e.g., mopeds) and also in other applications where the speed of the engine defines the state of the clutch, for example, in a chainsaw. This clutch system employs centrifugal force to automatically engage the clutch when the engine rpm rises above a threshold and to automatically disengage the clutch when the engine rpm falls low enough. See Saxomat and Variomatic.

As the name implies, a cone clutch has conical friction surfaces. The cone's taper means that a given amount of movement of the actuator makes the surfaces approach (or recede) much more slowly than in a disc clutch. As well, a given amount of actuating force creates more pressure on the mating surfaces.
The best known example of a cone clutch is a synchronizer ring in a manual transmission. The synchronizer ring is responsible for "synchronizing" the speeds of the shift hub and the gear wheel to ensure a smooth gear change.

Also known as a slip clutch or "safety clutch", this device allows a rotating shaft to slip when higher than normal resistance is encountered on a machine. An example of a safety clutch is the one mounted on the driving shaft of a large grass mower. The clutch yields if the blades hit a rock, stump, or other immobile object, thus avoiding a potentially damaging torque transfer to the engine, possibly twisting or fracturing the crankshaft.

Motor-driven mechanical calculators had these between the drive motor and gear train, to limit damage when the mechanism jammed, as motors used in such calculators had high stall torque and were capable of causing damage to the mechanism if torque wasn't limited.

Carefully designed clutches operate, but continue to transmit maximum permitted torque, in such tools as controlled-torque screwdrivers.

Some clutches are designed not to slip; torque may only be transmitted either fully engaged or disengaged to avoid catastrophic damage. An example of this is the dog clutch, most commonly used in non-synchromesh transmissions.

There are multiple designs of vehicle clutch, but most are based on one or more friction discs pressed tightly together or against a flywheel using springs. The friction material varies in composition depending on many considerations such as whether the clutch is "dry" or "wet". Friction discs once contained asbestos, but this has been largely discontinued. Clutches found in heavy duty applications such as trucks and competition cars use ceramic plates that have a greatly increased friction coefficient. However, these have a "grabby" action generally considered unsuitable for passenger cars. The spring pressure is released when the clutch pedal is depressed thus either pushing or pulling the diaphragm of the pressure plate, depending on type. Raising the engine speed too high while engaging the clutch causes excessive clutch plate wear. Engaging the clutch abruptly when the engine is turning at high speed causes a harsh, jerky start. This kind of start is necessary and desirable in drag racing and other competitions, where speed is more important than comfort.

In a modern car with a manual transmission the clutch is operated by the left-most pedal using a hydraulic or cable connection from the pedal to the clutch mechanism. On older cars the clutch might be operated by a mechanical linkage. Even though the clutch may physically be located very close to the pedal, such remote means of actuation are necessary to eliminate the effect of vibrations and slight engine movement, engine mountings being flexible by design. With a rigid mechanical linkage, smooth engagement would be near-impossible because engine movement inevitably occurs as the drive is "taken up."

The default state of the clutch is "engaged" - that is the connection between engine and gearbox is always "on" unless the driver presses the pedal and disengages it. If the engine is running with the clutch engaged and the transmission in neutral, the engine spins the input shaft of the transmission but power is not transmitted to the wheels.

The clutch is located between the engine and the gearbox, as disengaging it is usually required to change gear. Although the gearbox does not stop rotating during a gear change, there is no torque transmitted through it, thus less friction between gears and their engagement dogs. The output shaft of the gearbox is permanently connected to the final drive, then the wheels, and so both always rotate together, at a fixed speed ratio. With the clutch disengaged, the gearbox input shaft is free to change its speed as the internal ratio is changed. Any resulting difference in speed between the engine and gearbox is evened out as the clutch slips slightly during re-engagement.

Clutches in typical cars are mounted directly to the face of the engine's flywheel, as this already provides a convenient large diameter steel disk that can act as one driving plate of the clutch. Some racing clutches use small multi-plate disk packs that are not part of the flywheel. Both clutch and flywheel are enclosed in a conical bellhousing, which (in a rear-wheel drive car) usually forms the main mounting for the gearbox.

A few cars, notably the Alfa Romeo Alfetta and 75, Porsche 924, and Chevrolet Corvette (since 1997), sought a more even weight distribution between front and back by placing the weight of the transmission at the rear of the car, combined with the rear axle to form a transaxle. The clutch was mounted with the transaxle and so the propeller shaft rotated continuously with the engine, even when in neutral gear or declutched.

Motorcycles typically employ a wet clutch with the clutch riding in the same oil as the transmission. These clutches are usually made up of a stack of alternating friction plates and steel plates. The friction plates have lugs on their outer diameters that lock them to a basket that is turned by the crankshaft. The steel plates have lugs on their inner diameters that lock them to the transmission input shaft. A set of coil springs or a diaphragm spring plate force the plates together when the clutch is engaged.

On motorcycles the clutch is operated by a hand lever on the left handlebar. No pressure on the lever means that the clutch plates are engaged (driving), while pulling the lever back towards the rider disengages the clutch plates through cable or hydraulic actuation, allowing the rider to shift gears or coast. Racing motorcycles often use slipper clutches to eliminate the effects of engine braking, which, being applied only to the rear wheel, can cause instability.

Cars use clutches in places other than the drive train. For example, a belt-driven engine cooling fan may have a heat-activated clutch. The driving and driven members are separated by a silicone-based fluid and a valve controlled by a bimetallic spring. When the temperature is low, the spring winds and closes the valve, which lets the fan spin at about 20% to 30% of the shaft speed. As the temperature of the spring rises, it unwinds and opens the valve, allowing fluid past the valve, makes the fan spin at about 60% to 90% of shaft speed. Other clutches—such as for an air conditioning compressor—electronically engage clutches using magnetic force to couple the driving member to the driven member.


Single-revolution clutches were developed in the 19th century to power machinery such as shears or presses where a single pull of the operating lever or (later) press of a button would trip the mechanism, engaging the clutch between the power source and the machine's crankshaft for exactly one revolution before disengaging the clutch. When the clutch is disengaged and the driven member is stationary. Early designs were typically dog clutches with a cam on the driven member used to disengage the dogs at the appropriate point.

Greatly simplified single-revolution clutches were developed in the 20th century, requiring much smaller operating forces and in some variations, allowing for a fixed fraction of a revolution per operation. Fast action friction clutches replaced dog clutches in some applications, eliminating the problem of impact loading on the dogs every time the clutch engaged.

In addition to their use in heavy manufacturing equipment, single-revolution clutches were applied to numerous small machines. In tabulating machines, for example, pressing the operate key would trip a single revolution clutch to process the most recently entered number. In typesetting machines, pressing any key selected a particular character and also engaged a single rotation clutch to cycle the mechanism to typeset that character. Similarly, in teleprinters, the receipt of each character tripped a single-revolution clutch to operate one cycle of the print mechanism.

In 1928, Frederick G. Creed developed a single-turn spring clutch (see above) that was particularly well suited to the repetitive start-stop action required in teleprinters. In 1942, two employees of Pitney Bowes Postage Meter Company developed an improved single turn spring clutch. In these clutches, a coil spring is wrapped around the driven shaft and held in an expanded configuration by the trip lever. When tripped, the spring rapidly contracts around the power shaft engaging the clutch. At the end of one revolution, if the trip lever has been reset, it catches the end of the spring (or a pawl attached to it) and the angular momentum of the driven member releases the tension on the spring. These clutches have long operating lives—many have performed tens and perhaps hundreds of millions of cycles without need of maintenance other than occasional lubrication.

These superseded wrap-spring single-revolution clutches in page printers, such as teleprinters, including the Teletype Model 28 and its successors, using the same design principles. IBM Selectric typewriters also used them. These are typically disc-shaped assemblies mounted on the driven shaft. Inside the hollow disc-shaped drive drum are two or three freely floating pawls arranged so that when the clutch is tripped, the pawls spring outward much like the shoes in a drum brake. When engaged, the load torque on each pawl transfers to the others to keep them engaged. These clutches do not slip once locked up, and they engage very quickly, on the order of milliseconds. A trip projection extends out from the assembly. If the trip lever engaged this projection, the clutch was disengaged. When the trip lever releases this projection, internal springs and friction engage the clutch. The clutch then rotates one or more turns, stopping when the trip lever again engages the trip projection.

These mechanisms were found in some types of synchronous-motor-driven electric clocks. Many different types of synchronous clock motors were used, including the pre-World War II Hammond manual-start clocks. Some types of self-starting synchronous motors always started when power was applied, but in detail, their behaviour was chaotic and they were equally likely to start rotating in the wrong direction. Coupled to the rotor by one (or possibly two) stages of reduction gearing was a wrap-spring clutch-brake. The spring did not rotate. One end was fixed; the other was free. It rode freely but closely on the rotating member, part of the clock's gear train. The clutch-brake locked up when rotated backwards, but also had some spring action. The inertia of the rotor going backwards engaged the clutch and wound the spring. As it unwound, it restarted the motor in the correct direction. Some designs had no explicit spring as such—but were simply compliant mechanisms. The mechanism was lubricated and wear did not present a problem.

A Lock-up clutch is used in some automatic transmissions for motor vehicles. Above a certain speed (usually 60 km/h) it locks the torque converter to minimise power loss and improve fuel efficiency.




</doc>
<doc id="6520" url="https://en.wikipedia.org/wiki?curid=6520" title="Cow tipping">
Cow tipping

Cow tipping is the purported activity of sneaking up on any unsuspecting or sleeping upright cow and pushing it over for entertainment. The practice of cow tipping is generally considered an urban legend, and stories of such feats viewed as tall tales. The implication that rural citizens seek such entertainment due to lack of alternatives is viewed as a stereotype. The concept of cow tipping apparently developed in the 1970s, though tales of animals that cannot rise if they fall has historical antecedents dating to the Roman Empire.

Cows routinely lie down and can easily regain their footing unless sick or injured. Scientific studies have been conducted to determine if cow tipping is theoretically possible, with varying conclusions. All agree that cows are large animals that are difficult to surprise and will generally resist attempts to be tipped. Estimates suggest a force of between is needed, and that at least four and possibly as many as fourteen people would be required to achieve this. In real-life situations where cattle have to be laid on the ground, or "cast", such as for branding, hoof care or veterinary treatment, either rope restraints are required or specialized mechanical equipment is used that confines the cow and then tips it over. On rare occasions, cattle can lie down or fall down in proximity to a ditch or hill that restricts their normal ability to rise without help. Cow tipping has many references in popular culture and is also used as a figure of speech.

The urban legend of cow tipping relies upon the presumption that cattle are slow-moving, dim-witted, and weak-legged, thus easily pushed over without much force. Some versions suggest that because cows sleep standing up, it is possible to approach them and push them over without the animals reacting. However, cows only sleep lightly while standing up, and they are easily awakened. They lie down to sleep deeply. Furthermore, numerous sources have questioned the practice's feasibility, since most cows weigh over half a ton and easily resist any lesser force.

A 2005 study led by Margo Lillie, a zoologist at the University of British Columbia, and her student Tracy Boechler, concluded that tipping a cow would require a force of nearly and is therefore impossible to accomplish by a single person. Her calculations found that it would require more than four people to apply enough force to push over a cow, based on an estimate that a single person could exert of force. However, since a cow can brace itself, Lillie and Boechler suggested that five or six people would, most likely, be needed. Further, cattle are well aware of their surroundings and are very difficult to surprise, due to excellent senses of both smell and hearing. Lillie and Boechler's analysis found that if a cow did not move, the principles of static physics suggest that two people might be able to tip a cow if its centre of mass were pushed over its hooves before the cow could react. However, cows are not rigid or unresponsive, and the faster humans have to move, the less force they can exert. Thus Lillie and Boechler concluded that it is unlikely that cows can actually be tipped over in this way. Lillie stated, "It just makes the physics of it all, in my opinion, impossible."

Although he agrees that it would take a force of about 3,000 newtons to push over a standing cow, biologist Steven Vogel thinks that the study by Lillie and Boechler overestimates the pushing ability of an individual human. Using data from Cotterell and Kamminga, who estimated that humans exert a pushing force of 280 newtons, Vogel suggests that someone applying force at the requisite height to topple a cow might generate a maximum push of no more than 300 newtons. By this calculation, at least 10 people would be needed to tip over a non-reacting cow. However, this combined force requirement, he says, might not be the greatest impediment to such a prank. Standing cows are not asleep and like other animals have ever-vigilant reflexes. "If the cow does no more than modestly widen its stance without an overall shift of its center of gravity", he says, "about 4,000 newtons or 14 pushers would be needed—quite a challenge to deploy without angering the cow."

The belief that certain animals cannot rise if pushed over has historical antecedents, though cattle have never been so classified. Julius Caesar recorded a belief that a European elk had no knee joints and could not get up if it fell. Pliny said the same about the hind legs of an animal he called the achlis, which Pliny's 19th-century translators Bostock and Riley said was merely another name for the elk. They also noted that Pliny's belief about the jointless back legs of the achlis (elk) was false.

In 1255, Louis IX of France gave an elephant to Henry III of England for his menagerie in the Tower of London. A drawing by the historian Matthew Paris for his "Chronica Majora" can be seen in his bestiary at Parker Library of Corpus Christi College, Cambridge. An accompanying text cites elephant lore suggesting that elephants did not have knees and were unable to get up if they fell.

Journalist Jake Steelhammer believes the American urban myth of cow tipping originated in the 1970s. It "stampeded into the '80s", he says, "when movies like "Tommy Boy" and "Heathers" featured cow tipping expeditions." Stories about cow tipping tend to be second-hand, he says, told by someone who does not claim to have tipped a cow but who knows someone else who says he or she did.

Cattle may need to be deliberately thrown or tipped over for certain types of husbandry practices and medical treatment. When done for medical purposes, this is often called "casting", and when performed without mechanical assistance requires the attachment of of rope around the body and legs of the animal. After the rope is secured by non-slip bowline knots, it is pulled to the rear until the animal is off-balance. Once the cow is forced to lie down in sternal recumbency (on its chest), it can be rolled onto its side and its legs tied to prevent kicking.

A calf table or calf cradle, also called a "tipping table" or a "throw down", is a relatively modern invention designed to be used on calves that are being branded. A calf is run into a chute, confined, and then tipped by the equipment onto its side for easier branding and castration.

Hydraulic tilt tables for adult cattle have existed since the 1970s and are designed to lift and tip cattle onto their sides to enable veterinary care, particularly of the animals' genitalia, and for hoof maintenance. (Unlike horses, cows generally do not cooperate with a farrier when standing.) A Canadian veterinarian explained, "Using the table is much safer and easier than trying to get underneath to examine the animal", and noted that cows tipped over on a padded table usually stop struggling and become calm fairly quickly. One design, developed at the Western College of Veterinary Medicine in Saskatoon, Saskatchewan, included "cow comfort" as a unique aspect of care using this type of apparatus.

Cows may tip themselves inadvertently. Due to their bulk and relatively short legs, cattle cannot roll over. Those that lie down and roll to their sides with their feet pointing uphill may become stuck and unable to rise without assistance, with potentially fatal results. In such cases, two humans can roll or flip a cow onto its other side, so that its feet are aimed downhill, thus allowing it to rise on its own.
In one documented case of "real-life cow tipping", a pregnant cow rolled into a gully in New Hampshire and became trapped in an inverted state until rescued by volunteer fire fighters. The owner of the cow commented that he had seen this happen "once or twice" before.

Trauma or illness may also result in a cow unable to rise to its feet. Such animals are sometimes called "downers." Sometimes this occurs as a result of muscle and nerve damage from calving or a disease such as mastitis. Leg injuries, muscle tears, or a massive infection of some sort may also be causes. Downer cows are encouraged to get to their feet and have a much greater chance of recovery if they do. If unable to rise, some have survived—with medical care—as long as 14 days and were ultimately able to get back on their feet. Appropriate medical treatment for a downer cow to prevent further injury includes rolling from one side to the other every three hours, careful and frequent feeding of small amounts of fodder, and access to clean water.

Dead animals may appear to have been tipped over. But this is actually the process of rigor mortis, which stiffens the muscles of the carcass, beginning six to eight hours after death and lasting for one to two days. It is particularly noticeable in the limbs, which stick out straight. Post-mortem bloat also occurs because of gas formation inside the body. The process may result in cattle carcasses that wind up on their back with all four feet in the air.

Assorted individuals have claimed to have performed cow tipping, often while under the influence of alcohol. These claims, to date, cannot be reliably verified, with Jake Swearingen of "Modern Farmer" noting in 2013 that YouTube, a popular source of videos of challenges and stunts, "fails to deliver one single actual cow-tipping video".

Pranksters have sometimes pushed over artificial cows. Along Chicago's Michigan Avenue in 1999, two "apparently drunk" men felled six fiberglass cows that were part of a Cows on Parade public art exhibit. Four other vandals removed a "Wow cow" sculpture from its lifeguard chair at Oak Street Beach and abandoned it in a pedestrian underpass. A year later, New York City anchored its CowParade art cows, including "A Streetcow Named Desire", to concrete bases "to prevent the udder disrespect of cow-tippers and thieves."

Cow tipping has been featured in films from the 1980s and later, such as "Heathers" (1988), "Tommy Boy" (1995), " Barnyard" (2006), and "I Love You, Beth Cooper" (2009). It was also used in the title of a 1992 documentary film by Randy Redroad, "Cow Tipping–The Militant Indian Waiter". The film "Cars" (2006) features a vehicular variant called tractor-tipping.

In The Little Willies song "Lou Reed" from their 2006 eponymous debut album, Norah Jones sings about a fictional event during which musician Lou Reed tips cows in Texas. In another medium, "The Big Bang Theory", a television show, uses cow tipping lore as an element to establish the nature of a rural character, Penny.

The term "cow tipping" is sometimes used as a figure of speech for pushing over something big. In "A Giant Cow-Tipping by Savages", author John Weir Close uses the term to describe contemporary mergers and acquisitions. "Tipping sacred cows" has been used as a deliberate mixed metaphor in titles of books on Christian ministry and business management.





</doc>
<doc id="6526" url="https://en.wikipedia.org/wiki?curid=6526" title="Cassandra">
Cassandra

Cassandra or Kassandra (Ancient Greek: Κασσάνδρα, , also ), also known as Alexandra, was a woman in Greek mythology cursed to utter prophecies that were true but that no one believed.

Cassandra was reputed to be a daughter of King Priam and of Queen Hecuba of Troy. The older and most common versions state that she was admired by the god Apollo, and he offered her the gift to see the future in order to win her heart. She promised to be his lover in return for his gift, but after receiving it, she went back on her word and refused him. Apollo, angered that she lied and deceived him, wanted to take back the powers he had already given. But since divine powers granted cannot be simply revoked, he placed a counter curse that though she would see the future accurately, nobody would ever believe her prophecies. 

Some later versions have her falling asleep in a temple, where the snakes licked (or whispered in) her ears so that she could hear the future.

Cassandra became a figure of epic tradition and of tragedy.

In modern usage her name is employed as a rhetorical device to indicate someone whose accurate prophecies are not believed by those around them.

Hjalmar Frisk ("Griechisches Etymologisches Wörterbuch", Heidelberg, 1960–1970) notes "unexplained etymology", citing "various hypotheses" found in Wilhelm Schulze, Edgar Howard Sturtevant, J. Davreux, and . R. S. P. Beekes cites García Ramón's derivation of the name from the Proto-Indo-European root *"(s)kend-" "raise".

Cassandra was a princess of Troy, the daughter of King Priam and Queen Hecuba and the fraternal twin sister of Helenus. According to legend, Cassandra had dark brown curly hair and dark brown eyes, and was both beautiful and clever, but considered insane.

Cassandra was given the gift of prophecy, but was also cursed by the god Apollo so that her accurate prophecies would not be believed. Many versions of the myth relate that she incurred the god's wrath by refusing him sex, after promising herself to him in exchange for the power of prophecy. In Aeschylus' "Agamemnon", she bemoans her relationship with Apollo:
<poem>Apollo, Apollo!
God of all ways, but only Death's to me,
Once and again, O thou, Destroyer named,
Thou hast destroyed me, thou, my love of old!</poem>

And she acknowledges her fault
<poem>" I promised that [love] to Loxias [Apollo], but I broke my word. And ever since that fault I could persuade no one."</poem>

Latin author Hyginus in Fabulae says:
In some versions of the myth, Apollo curses her by spitting into her mouth.

Cassandra had served as a priestess of Apollo and taken a sacred vow of chastity to remain a virgin for her entire life.

Her cursed gift from Apollo became a source of endless pain and frustration to Cassandra. She was seen as a liar and a madwoman by her family and by the Trojan people. In some versions of the story, she was often locked up in a pyramidal building on the citadel on the orders of her father, King Priam. She was accompanied there by the wardress, who cared for her under orders to inform the King of all of his daughter's "prophetic utterances".

According to legend, Cassandra had instructed her twin brother Helenus in the power of prophecy so he could be a prophet. Like her, Helenus was always correct whenever he had made his predictions, but unlike his sister, people believed him.

Cassandra made many predictions, and all of her prophecies were disbelieved except for one, when she foresaw who Paris was and proclaimed that he was her abandoned brother. Cassandra foresaw that Paris’ abduction of Helen for his wife would bring about the Trojan War and warned Paris not to go to Sparta. Helenus echoed her prophecy, but his warnings were ignored. Cassandra saw Helen coming into Troy when Paris returned home from Sparta. Cassandra furiously snatched away Helen's golden veil and tore at her hair, for she had foreseen that Helen's arrival would bring the calamities of the Trojan War and the destruction of Troy. The Trojan people, however, welcomed Helen into their city.

Cassandra foresaw the destruction of Troy. In various accounts of the war, she warned the Trojans about the Greeks hiding inside the Trojan Horse, Agamemnon's death, her own demise at the hands of Aegisthus and Clytemnestra, her mother Hecuba's fate, Odysseus's ten-year wanderings before returning to his home, and the murder of Aegisthus and Clytemnestra by the latter's children Electra and Orestes. Cassandra predicted that her cousin Aeneas would escape during the fall of Troy and found a new nation in Rome. However, she was unable to do anything to forestall these tragedies since no one believed her.

Coroebus and Othronus came to the aid of Troy during the Trojan War out of love for Cassandra and in exchange for her hand in marriage, but both were killed. According to one account, Priam offered Cassandra to Telephus’s son Eurypylus, in order to induce Eurypylus to fight on the side of the Trojans. Cassandra was also the first to see the body of her brother Hector being brought back to the city.

In "The Fall of Troy", told by Quintus Smyrnaeus, Cassandra had attempted to warn the Trojan people that Greek warriors were hiding in the Trojan Horse while they were celebrating their victory over the Greeks with feasting. They disbelieved her, calling her names and degrading her with insults. She grabbed an axe in one hand and a burning torch in her other, and ran towards the Trojan Horse, intent on destroying it herself to stop the Greeks from destroying Troy. The Trojan people stopped her before she could do so. The Greeks hiding inside the Horse were relieved that the Trojans had stopped Cassandra from destroying it, but they were surprised by how clearly she had seen their plan to defeat Troy.

At the fall of Troy, Cassandra sought shelter in the temple of Athena. There she embraced the wooden statue of Athena in supplication for her protection, but was abducted and brutally raped by Ajax the Lesser. Cassandra was clinging so tightly to the statue of the goddess that Ajax knocked it from its stand as he dragged her away. One account claimed that even Athena, who had worked hard to help the Greeks destroy Troy, was not able to restrain her tears and her cheeks burned with anger. In one account, this caused her image to give forth a sound that shook the floor of the temple at the sight of Cassandra's rape, and her image turned its eyes away as Cassandra was violated, although others found this account too bold. Ajax's actions were a sacrilege because Cassandra was a supplicant of Athena and supplicants were untouchable in the sanctuary of a god, being under the protection of that god. Furthermore, he committed another sacrilege by raping her inside the temple of Athena, despite it being strictly forbidden for people to have sexual intercourse in a temple.

Odysseus insisted to the other Greek leaders that Ajax should be stoned to death for his crimes, which had enraged Athena and the other gods. Ajax avoided their wrath, because none of them dared to punish him after he clung, as a supplicant, to Athena's altar and swore an oath proclaiming his innocence. Athena was furious at the Greeks' failure to punish Ajax for raping Cassandra in her temple, and she punished them severely with the help of Poseidon and Zeus. Poseidon sent storms and strong winds to destroy much of the Greek fleet on their way home from Troy. Athena punished Ajax herself, by causing him to have a terrible death, although the sources differ as to the manner of his death. The Locrians had to atone for Ajax's great sacrilege against Cassandra in Athena's temple by sending two maidens to Troy every year for a thousand years to serve as slaves in Athena's temple. However, if they were caught by the inhabitants before they reached the temple they were executed.

In some versions, Cassandra intentionally left a chest behind in Troy, with a curse on whichever Greek opened it first. Inside the chest was an image of Dionysus, made by Hephaestus and presented to the Trojans by Zeus. It was given to the Greek leader Eurypylus as a part of his share of the victory spoils of Troy. When he opened the chest and saw the image of the god, he went mad.

Cassandra was then taken as a "pallake" (concubine) by King Agamemnon of Mycenae. Unbeknown to Agamemnon, while he was away at war, his wife, Clytemnestra, had begun an affair with Aegisthus. Clytemnestra and Aegisthus then murdered both Agamemnon and Cassandra. Some sources mention that Cassandra and Agamemnon had twin boys, Teledamus and Pelops, both of whom were killed by Aegisthus.

Cassandra was sent to the Elysian Fields after her death, because her soul was judged worthy due to her dedication to the gods, and her religious nature during her life.

Cassandra was buried either at Amyclae or Mycenae. The two towns disputed the possession of her grave. Heinrich Schliemann was certain that he had discovered Cassandra’s tomb when he had excavated Mycenae, because he found the remains of a woman and two infants in one of the circle graves at Mycenae.

The play "Agamemnon" from Aeschylus's trilogy "Oresteia" depicts the king treading the scarlet cloth laid down for him, and walking offstage to his death. After the chorus's ode of foreboding, time is suspended in Cassandra's "mad scene". She has been onstage, silent and ignored. Her madness that is unleashed now is not the physical torment of other characters in Greek tragedy, such as in Euripides' "Heracles" or Sophocles' "Ajax".

According to author Seth Schein, two further familiar descriptions of her madness are that of Heracles in "The Women of Trachis" or Io in "Prometheus Bound". She speaks, disconnectedly and transcendent, in the grip of her psychic possession by Apollo, witnessing past and future events. Schein says, "She evokes the same awe, horror and pity as do schizophrenics". Cassandra is someone "who often combine deep, true insight with utter helplessness, and who retreat into madness."

Eduard Fraenkel remarked on the powerful contrasts between declaimed and sung dialogue in this scene. The frightened and respectful chorus are unable to comprehend her. She goes to her inevitable offstage murder by Clytemnestra with full knowledge of what is to befall her.

Cassandra is an enduring archetype. Modern invocations of Cassandra are most frequently an example of a Cassandra complex. To emphasize such a situation, Cassandra's name is frequently used in fiction when prophecy comes up, especially true prophecy that is not believed. This can include the names of people, objects, or places.

Cassandra has been used as metaphor and allegory in psychological and philosophical tracts. For example, Florence Nightingale's book "Suggestions for Thought to Searchers after Religious Truth" has a section named for Cassandra, using her as a metaphor for the helplessness of women that she attributes to over-feminization. (Further examples are located on the Cassandra complex page.)

The Cassandra myth itself has also been retold several times by modern authors of novels and dramatizations, including works by Eric Shanower, Lindsay Clarke, Christa Wolf, Lesya Ukrainka, Woody Allen, Marion Zimmer Bradley, David Gemmell, and Hector Berlioz. A number of songs have also referred to her, such as "Cassandra" (1982), by Swedish pop band ABBA.





</doc>
<doc id="6530" url="https://en.wikipedia.org/wiki?curid=6530" title="Couplet">
Couplet

A couplet is a pair of successive lines of metre in poetry. A couplet usually consists of two successive lines that rhyme and have the same metre. A couplet may be formal (closed) or run-on (open). In a formal (or closed) couplet, each of the two lines is end-stopped, implying that there is a grammatical pause at the end of a line of verse. In a run-on (or open) couplet, the meaning of the first line continues to the second.

The word "couplet" comes from the French word meaning "two pieces of iron riveted or hinged together." The term "couplet" was first used to describe successive lines of verse in Sir P. Sidney's " Arcadia " in 1590: "In singing some short coplets, whereto the one halfe beginning, the other halfe should answere."

While couplets traditionally rhyme, not all do. Poems may use white space to mark out couplets if they do not rhyme. Couplets in iambic pentameter are called "heroic couplets". John Dryden in the 17th century and Alexander Pope in the 18th century were both well known for their writing in heroic couplets. The Poetic epigram is also in the couplet form. Couplets can also appear as part of more complex rhyme schemes, such as sonnets.

Rhyming couplets are one of the simplest rhyme schemes in poetry. Because the rhyme comes so quickly, it tends to call attention to itself. Good rhyming couplets tend to "explode" as both the rhyme and the idea come to a quick close in two lines. Here are some examples of rhyming couplets where the sense as well as the sound "rhymes":

On the other hand, because rhyming couplets have such a predictable rhyme scheme, they can feel artificial and plodding. Here is a Pope parody of the predictable rhymes of his era:

Rhyming couplets are often used in Early Modern English poetry, as seen in Chaucer's "The Canterbury Tales". This work of literature is written almost entirely in rhyming couplets. Similarly, Shakespearean sonnets often employ rhyming couplets at the end to emphasize the theme. Take one of Shakespeare's most famous sonnets, Sonnet 18, for example (the rhyming couplet is shown in italics):

Chinese couplets or "contrapuntal couplets" may be seen on doorways in Chinese communities worldwide. Couplets displayed as part of the Chinese New Year festival, on the first morning of the New Year, are called "chunlian" (春联). These are usually purchased at a market a few days before and glued to the doorframe. The text of the couplets is often traditional and contains hopes for prosperity. Other chunlian reflect more recent concerns. For example, the CCTV New Year's Gala usually promotes couplets reflecting current political themes in mainland China.

Some Chinese couplets may consist of two lines of four characters each. Couplets are read from top to bottom where the first pline starts from the right. But is also a 6 word diagraph with 19 lines

Tamil literature contains some of the best known examples of ancient couplet poetry. The Tamil language has a rich and refined grammar for couplet poetry, and distichs in Tamil poetry follow the venpa metre. The most famous example for Tamil couplet poetry is the ancient Tamil moral text of Tirukkural, which contains a total of 1330 couplets written in the kural venpa metre from which the title of the work was derived centuries later. Each Kural couplet is made of exactly 7 words—4 in the first line and 3 in the second. The first word may rhyme with the fourth or the fifth word. Below is an example of a couplet:

The American poet J. V. Cunningham was noted for many distichs included in the various forms of epigrams included in his poetry collections, as exampled here:

Deep summer, and time passes. Sorrow wastes<br>To a new sorrow. While Time heals time hastes



</doc>
<doc id="6532" url="https://en.wikipedia.org/wiki?curid=6532" title="Charlotte Brontë">
Charlotte Brontë

Charlotte Brontë (, ; 21 April 1816 – 31 March 1855) was an English novelist and poet, the eldest of the three Brontë sisters who survived into adulthood and whose novels became classics of English literature.

She enlisted in school at Roe Head in January 1831, aged 14 years. She left the year after to teach her sisters, Emily and Anne, at home, returning in 1835 as a governess. In 1839 she undertook the role as governess for the Sidgwick family but left after a few months to return to Haworth where the sisters opened a school, but failed to attract pupils. Instead, they turned to writing and they each first published in 1846 under the pseudonyms of Currer, Ellis and Acton Bell. Her first novel "The Professor" was rejected by publishers, her second novel "Jane Eyre" was published in 1847. The sisters admitted to their Bell pseudonyms in 1848, and by the following year were celebrated in London literary circles.

Brontë experienced the early deaths of all her siblings. She became pregnant shortly after her marriage in June 1854 but died on 31 March 1855, almost certainly from hyperemesis gravidarum, a complication of pregnancy which causes excessive nausea and vomiting.

Charlotte Brontë was born on 21 April 1816 in Market Street Thornton, west of Bradford in the West Riding of Yorkshire, the third of the six children of Maria (née Branwell) and Patrick Brontë (formerly surnamed Brunty), an Irish Anglican clergyman. In 1820 her family moved a few miles to the village of Haworth, where her father had been appointed perpetual curate of St Michael and All Angels Church. Maria died of cancer on 15 September 1821, leaving five daughters, Maria, Elizabeth, Charlotte, Emily and Anne, and a son, Branwell, to be taken care of by her sister, Elizabeth Branwell.

In August 1824, Patrick sent Charlotte, Emily, Maria and Elizabeth to the Clergy Daughters' School at Cowan Bridge in Lancashire. Charlotte maintained that the school's poor conditions permanently affected her health and physical development, and hastened the deaths of Maria (born 1814) and Elizabeth (born 1815), who both died of tuberculosis in June 1825. After the deaths of his older daughters, Patrick removed Charlotte and Emily from the school. Charlotte used the school as the basis for Lowood School in "Jane Eyre".

At home in Haworth Parsonage, Brontë acted as "the motherly friend and guardian of her younger sisters". Brontë wrote her first known poem at the age of 13 in 1829, and was to go on to write more than 200 poems in the course of her life. Many of her poems were "published" in their homemade magazine "Branwell's Blackwood's Magazine", and concerned the fictional Glass Town Confederacy. She and her surviving siblings – Branwell, Emily and Anne – created their own fictional worlds, and began chronicling the lives and struggles of the inhabitants of their imaginary kingdoms. Charlotte and Branwell wrote Byronic stories about their jointly imagined country, Angria, and Emily and Anne wrote articles and poems about Gondal. The sagas they created were episodic and elaborate, and they exist in incomplete manuscripts, some of which have been published as juvenilia. They provided them with an obsessive interest during childhood and early adolescence, which prepared them for literary vocations in adulthood.

Between 1831 and 1832, Brontë continued her education at Roe Head in Mirfield, where she met her lifelong friends and correspondents Ellen Nussey and Mary Taylor. In 1833 she wrote a novella, "The Green Dwarf", using the name Wellesley. Around about 1833, her stories shifted from tales of the supernatural to more realistic stories. She returned to Roe Head as a teacher from 1835 to 1838. Unhappy and lonely as a teacher at Roe Head, Brontë took out her sorrows in poetry, writing a series of melancholic poems. In "We wove a Web in Childhood" written in December 1835, Brontë drew a sharp contrast between her miserable life as a teacher and the vivid imaginary worlds she and her siblings had created. In another poem "Morning was its freshness still" written at the same time, Brontë wrote "Tis bitter sometimes to recall/Illusions once deemed fair". Many of her poems concerned the imaginary world of Angria, often concerning Byronic heroes, and in December 1836 she wrote to the Poet Laureate Robert Southey asking him for encouragement of her career as a poet. Southey replied, famously, that "Literature cannot be the business of a woman's life, and it ought not to be. The more she is engaged in her proper duties, the less leisure will she have for it even as an accomplishment and a recreation." This advice she respected but did not heed. 

In 1839 she took up the first of many positions as governess to families in Yorkshire, a career she pursued until 1841. In particular, from May to July 1839 she was employed by the Sidgwick family at their summer residence, Stone Gappe, in Lothersdale, where one of her charges was John Benson Sidgwick (1835–1927), an unruly child who on one occasion threw a Bible at Charlotte, an incident that may have been the inspiration for a part of the opening chapter of "Jane Eyre" in which John Reed throws a book at the young Jane. Brontë did not enjoy her work as a governess, noting her employers treated her almost as a slave, constantly humiliating her.

Brontë was of slight build and was less than five feet tall.

In 1842 Charlotte and Emily travelled to Brussels to enrol at the boarding school run by Constantin Héger (1809–1896) and his wife Claire Zoé Parent Héger (1804–1887). During her time in Brussels, Brontë, who favoured the Protestant ideal of an individual in direct contact with God, objected to the stern Catholicism of Madame Héger, which she considered a tyrannical religion that enforced conformity and submission to the Pope. In return for board and tuition Charlotte taught English and Emily taught music. Their time at the school was cut short when their aunt Elizabeth Branwell, who had joined the family in Haworth to look after the children after their mother's death, died of internal obstruction in October 1842. Charlotte returned alone to Brussels in January 1843 to take up a teaching post at the school. Her second stay was not happy: she was homesick and deeply attached to Constantin Héger. She returned to Haworth in January 1844 and used the time spent in Brussels as the inspiration for some of the events in "The Professor" and "Villette".

In May 1846 Charlotte, Emily, and Anne self-financed the publication of a joint collection of poems under their assumed names Currer, Ellis and Acton Bell. The pseudonyms veiled the sisters' sex while preserving their initials; thus Charlotte was Currer Bell. "Bell" was the middle name of Haworth's curate, Arthur Bell Nicholls whom Charlotte later married, and "Currer" was the surname of Frances Mary Richardson Currer who had funded their school (and maybe their father). Of the decision to use "noms de plume", Charlotte wrote:

Although only two copies of the collection of poems were sold, the sisters continued writing for publication and began their first novels, continuing to use their "noms de plume" when sending manuscripts to potential publishers.

Brontë's first manuscript, "The Professor", did not secure a publisher, although she was heartened by an encouraging response from Smith, Elder & Co. of Cornhill, who expressed an interest in any longer works Currer Bell might wish to send. Brontë responded by finishing and sending a second manuscript in August 1847. Six weeks later, "Jane Eyre" was published. It tells the story of a plain governess, Jane, who, after difficulties in her early life, falls in love with her employer, Mr Rochester. They marry, but only after Rochester's insane first wife, of whom Jane initially has no knowledge, dies in a dramatic house fire. The book's style was innovative, combining naturalism with gothic melodrama, and broke new ground in being written from an intensely evoked first-person female perspective. Brontë believed art was most convincing when based on personal experience; in "Jane Eyre" she transformed the experience into a novel with universal appeal.

"Jane Eyre" had immediate commercial success and initially received favourable reviews. G. H. Lewes wrote that it was "an utterance from the depths of a struggling, suffering, much-enduring spirit", and declared that it consisted of ""suspiria de profundis"!" (sighs from the depths). Speculation about the identity and gender of the mysterious Currer Bell heightened with the publication of "Wuthering Heights" by Ellis Bell (Emily) and "Agnes Grey" by Acton Bell (Anne). Accompanying the speculation was a change in the critical reaction to Brontë's work, as accusations were made that the writing was "coarse", a judgement more readily made once it was suspected that Currer Bell was a woman. However, sales of "Jane Eyre" continued to be strong and may even have increased as a result of the novel developing a reputation as an "improper" book. A talented amateur artist, Brontë personally did the drawings for the second edition of "Jane Eyre" and in the summer of 1834 two of her paintings were shown at an exhibition by the Royal Northern Society for the Encouragement of the Fine Arts in Leeds.

In 1848 Brontë began work on the manuscript of her second novel, "Shirley". It was only partially completed when the Brontë family suffered the deaths of three of its members within eight months. In September 1848 Branwell died of chronic bronchitis and marasmus, exacerbated by heavy drinking, although Brontë believed that his death was due to tuberculosis. Branwell may have had a laudanum addiction. Emily became seriously ill shortly after his funeral and died of pulmonary tuberculosis in December 1848. Anne died of the same disease in May 1849. Brontë was unable to write at this time.

After Anne's death Brontë resumed writing as a way of dealing with her grief, and "Shirley", which deals with themes of industrial unrest and the role of women in society, was published in October 1849. Unlike "Jane Eyre", which is written in the first person, "Shirley" is written in the third person and lacks the emotional immediacy of her first novel, and reviewers found it less shocking. Brontë, as her late sister's heir, suppressed the republication of Anne's second novel, "The Tenant of Wildfell Hall", an action which had a deleterious effect on Anne's popularity as a novelist and has remained controversial among the sisters' biographers ever since.
In view of the success of her novels, particularly "Jane Eyre", Brontë was persuaded by her publisher to make occasional visits to London, where she revealed her true identity and began to move in more exalted social circles, becoming friends with Harriet Martineau and Elizabeth Gaskell, and acquainted with William Makepeace Thackeray and G.H. Lewes. She never left Haworth for more than a few weeks at a time, as she did not want to leave her ageing father. Thackeray's daughter, writer Anne Isabella Thackeray Ritchie, recalled a visit to her father by Brontë:

Brontë's friendship with Elizabeth Gaskell, while not particularly close, was significant in that Gaskell wrote the first biography of Brontë after her death in 1855.

Brontë's third novel, the last published in her lifetime, was "Villette", which appeared in 1853. Its main themes include isolation, how such a condition can be borne, and the internal conflict brought about by social repression of individual desire. Its main character, Lucy Snowe, travels abroad to teach in a boarding school in the fictional town of Villette, where she encounters a culture and religion different from her own and falls in love with a man (Paul Emanuel) whom she cannot marry. Her experiences result in a breakdown but eventually, she achieves independence and fulfilment through running her own school. A substantial amount of the novel's dialogue is in the French language. "Villette" marked Brontë's return to writing from a first-person perspective (that of Lucy Snowe); the technique she had used in "Jane Eyre". Another similarity to "Jane Eyre" lies in the use of aspects of her own life as inspiration for fictional events; in particular her reworking of the time she spent at the "pensionnat" in Brussels. "Villette" was acknowledged by critics of the day as a potent and sophisticated piece of writing although it was criticised for "coarseness" and for not being suitably "feminine" in its portrayal of Lucy's desires.

Before the publication of "Villette", Brontë received an expected proposal of marriage from Arthur Bell Nicholls, her father's curate, who had long been in love with her. She initially turned down his proposal and her father objected to the union at least partly because of Nicholls's poor financial status. Elizabeth Gaskell, who believed that marriage provided "clear and defined duties" that were beneficial for a woman, encouraged Brontë to consider the positive aspects of such a union and tried to use her contacts to engineer an improvement in Nicholls's finances. Brontë meanwhile was increasingly attracted to Nicholls and by January 1854 she had accepted his proposal. They gained the approval of her father by April and married in June. Her father Patrick had intended to give Charlotte away, but at the last minute decided he could not, and Charlotte had to make her way to the church without him. The married couple took their honeymoon in Banagher, County Offaly, Ireland. By all accounts, her marriage was a success and Brontë found herself very happy in a way that was new to her.

Brontë became pregnant soon after her wedding, but her health declined rapidly and, according to Gaskell, she was attacked by "sensations of perpetual nausea and ever-recurring faintness". She died, with her unborn child, on 31 March 1855, three weeks before her 39th birthday. Her death certificate gives the cause of death as tuberculosis, but biographers including Claire Harman and others suggest that she died from dehydration and malnourishment due to vomiting caused by severe morning sickness or hyperemesis gravidarum. Charlotte Brontë was buried in the family vault in the Church of St Michael and All Angels at Haworth.

"The Professor", the first novel Brontë had written, was published posthumously in 1857. The fragment of a new novel she had been writing in her last years has been twice completed by recent authors, the more famous version being "Emma Brown: A Novel from the Unfinished Manuscript by Charlotte Brontë" by Clare Boylan in 2003. Most of her writings about the imaginary country Angria have also been published since her death. In 2018, "The New York Times" published a belated obituary for her.

The daughter of an Irish Anglican clergyman, Brontë was herself an Anglican. In a letter to her publisher, she claims to "love the Church of England. Her Ministers indeed, I do not regard as infallible personages, I have seen too much of them for that – but to the Establishment, with all her faults – the profane Athanasian Creed excluded – I am sincerely attached."

In a letter to Ellen Nussey she wrote: 

Elizabeth Gaskell's biography "The Life of Charlotte Brontë" was published in 1857. It was an important step for a leading female novelist to write a biography of another, and Gaskell's approach was unusual in that, rather than analysing her subject's achievements, she concentrated on private details of Brontë's life, emphasising those aspects that countered the accusations of "coarseness" that had been levelled at her writing. The biography is frank in places, but omits details of Brontë's love for Héger, a married man, as being too much of an affront to contemporary morals and a likely source of distress to Brontë's father, widower, and friends. Mrs Gaskell also provided doubtful and inaccurate information about Patrick Brontë, claiming that he did not allow his children to eat meat. This is refuted by one of Emily Brontë's diary papers, in which she describes preparing meat and potatoes for dinner at the parsonage. It has been argued that Gaskell's approach transferred the focus of attention away from the 'difficult' novels, not just Brontë's, but all the sisters', and began a process of sanctification of their private lives.

On 29 July 1913 "The Times" of London printed four letters Brontë had written to Constantin Héger after leaving Brussels in 1844. Written in French except for one postscript in English, the letters broke the prevailing image of Brontë as an angelic martyr to Christian and female duties that had been constructed by many biographers, beginning with Gaskell. The letters, which formed part of a larger and somewhat one-sided correspondence in which Héger frequently appears not to have replied, reveal that she had been in love with a married man, although they are complex and have been interpreted in numerous ways, including as an example of literary self-dramatisation and an expression of gratitude from a former pupil.

In 1980 a commemorative plaque was unveiled at the Centre for Fine Arts, Brussels (BOZAR), on the site of the Madam Heger's school, in honour of Charlotte and Emily. In May 2017 the plaque was cleaned.


"The Green Dwarf, A Tale of the Perfect Tense" was written in 1833 under the pseudonym Lord Charles Albert Florian Wellesley. It shows the influence of Walter Scott, and Brontë's modifications to her earlier gothic style have led Christine Alexander to comment that, in the work, "it is clear that Brontë was becoming tired of the gothic mode "per se"".









</doc>
<doc id="6533" url="https://en.wikipedia.org/wiki?curid=6533" title="Charles Williams (British writer)">
Charles Williams (British writer)

Charles Walter Stansby Williams (20 September 1886 – 15 May 1945) was a British poet, novelist, playwright, theologian, literary critic, and member of the Inklings.

Williams was born in London in 1886, the only son of (Richard) Walter Stansby Williams (1848–1929), a journalist and foreign business correspondent for an importing firm, writing in French and German, who was a 'regular and valued' contributor of verse, stories and articles to many popular magazines, and his wife Mary (née Wall, the sister of the ecclesiologist and historian J. Charles Wall), a former milliner, of Islington. He had one sister, Edith, born in 1889. The Williams family lived in 'shabby-genteel' circumstances, owing to Walter's increasing blindness and the decline of the firm by which he was employed, in Holloway.

In 1894 the family moved to St Albans in Hertfordshire, where Williams lived until his marriage in 1917.

Educated at St Albans School, Williams was awarded a scholarship to University College London, but he left school in 1904 without attempting to gain a degree due to an inability to pay tuition fees.

Williams began work in 1904 in a Methodist bookroom. He was hired by the Oxford University Press (OUP) as a proofreading assistant in 1908 and quickly climbed to the position of editor. He continued to work at the OUP in various positions of increasing responsibility until his death in 1945. One of his greatest editorial achievements was the publication of the first major English-language edition of the works of Søren Kierkegaard.

Although chiefly remembered as a novelist, Williams also published poetry, works of literary criticism, theology, drama, history, biography, and a voluminous number of book reviews. Some of his best known novels are "War in Heaven" (1930), "Descent into Hell" (1937), and "All Hallows' Eve" (1945). T. S. Eliot, who wrote an introduction for the last of these, described Williams's novels as "supernatural thrillers" because they explore the sacramental intersection of the physical with the spiritual while also examining the ways in which power, even spiritual power, can corrupt as well as sanctify. All of Williams's fantasies, unlike those of J. R. R. Tolkien and most of those of C. S. Lewis, are set in the contemporary world. Williams has been described by Colin Manlove as one of the three main writers of "Christian fantasy" in the twentieth century (the other two being C.S. Lewis and T. F. Powys). More recent writers of fantasy novels with contemporary settings, notably Tim Powers, cite Williams as a model and inspiration. W. H. Auden, one of Williams's greatest admirers, reportedly re-read Williams's extraordinary and highly unconventional history of the church, "The Descent of the Dove" (1939), every year. Williams's study of Dante entitled "The Figure of Beatrice" (1944) was very highly regarded at its time of publication and continues to be consulted by Dante scholars today. His work inspired Dorothy L. Sayers to undertake her translation of "The Divine Comedy". Williams, however, regarded his most important work to be his extremely dense and complex Arthurian poetry, of which two books were published, "Taliessin through Logres" (1938) and "The Region of the Summer Stars" (1944), and more remained unfinished at his death. Some of Williams's essays were collected and published posthumously in "Image of the City and Other Essays" (1958), edited by Anne Ridler.

Williams gathered many followers and disciples during his lifetime. He was, for a period, a member of the Salvator Mundi Temple of the Fellowship of the Rosy Cross. He met fellow Anglican Evelyn Underhill (who was affiliated with a similar group, the Order of the Golden Dawn) in 1937 and was later to write the introduction to her published "Letters" in 1943.

When World War II broke out in 1939, Oxford University Press moved its offices from London to Oxford. Williams was reluctant to leave his beloved city, and Florence refused to go. From the nearly 700 letters he wrote his wife during the war years a generous selection has been published; "primarily… love letters," the editor calls them. But the move to Oxford did allow him to participate regularly in Lewis’s literary society known as the Inklings. In this setting Williams was able to read (and improve) his final published novel, "All Hallows' Eve", as well as to hear J. R. R. Tolkien read aloud to the group some of his early drafts of "The Lord of the Rings". In addition to meeting in Lewis's rooms at Oxford, they also regularly met at The Eagle and Child pub in Oxford (better known by its nickname "The Bird and Baby"). During this time Williams also gave lectures at Oxford on John Milton, William Wordsworth, and other authors, and received an honorary M.A. degree. Williams is buried in Holywell Cemetery in Oxford: his headstone bears the word "poet", followed by the words "Under the Mercy", a phrase often used by Williams himself.

In 1917 Williams married his first sweetheart, Florence Conway, following a long courtship during which he presented her with a sonnet sequence that would later become his first published book of poetry, "The Silver Stair". Their son Michael was born in 1922.

Williams was an unswerving and devoted member of the Church of England, reputedly with a tolerance of the scepticism of others and a firm belief in the necessity of a "doubting Thomas" in any apostolic body.

Although Williams attracted the attention and admiration of some of the most notable writers of his day, including T. S. Eliot and W. H. Auden, his greatest admirer was probably C. S. Lewis, whose novel "That Hideous Strength" (1945) has been regarded as partially inspired by his acquaintance with both the man and his novels and poems. Williams came to know Lewis after reading Lewis's then-recently published study "The Allegory of Love"; he was so impressed he jotted down a letter of congratulation and dropped it in the mail. Coincidentally, Lewis had just finished reading Williams's novel "The Place of the Lion" and had written a similar note of congratulation. The letters crossed in the mail and led to an enduring and fruitful friendship.

Williams developed the concept of co-inherence and gave rare consideration to the theology of romantic love. Falling in love for Williams was a form of mystical envisioning in which one saw the beloved as he or she was seen through the eyes of God. Co-inherence was a term used in Patristic theology to describe the relationship between the human and divine natures of Jesus Christ and the relationship between the persons of the blessed Trinity. Williams extended the term to include the ideal relationship between the individual parts of God's creation, including human beings. It is our mutual indwelling: Christ in us and we in Christ, interdependent. It is also the web of interrelationships, social and economic and ecological, by which the social fabric and the natural world function. But especially for Williams, co-inherence is a way of talking about the Body of Christ and the communion of saints. For Williams, salvation was not a solitary affair: "The thread of the love of God was strong enough to save you and all the others, but not strong enough to save you alone." He proposed an order, the Companions of the Co-inherence, who would practice substitution and exchange, living in love-in-God, truly bearing one another's burdens, being willing to sacrifice and to forgive, living from and for one another in Christ. According to Gunnar Urang, co-inherence is the focus of all Williams's novels.












</doc>
<doc id="6535" url="https://en.wikipedia.org/wiki?curid=6535" title="Celery">
Celery

Celery ("Apium graveolens") is a marshland plant in the family Apiaceae that has been cultivated as a vegetable since antiquity. Celery has a long fibrous stalk tapering into leaves. Depending on location and cultivar, either its stalks, leaves or hypocotyl are eaten and used in cooking. Celery seed is also used as a spice and its extracts have been used in herbal medicine.

Celery leaves are pinnate to bipinnate with rhombic leaflets long and broad. The flowers are creamy-white, in diameter, and are produced in dense compound umbels. The seeds are broad ovoid to globose, long and wide. Modern cultivars have been selected for solid petioles, leaf stalks. A celery stalk readily separates into "strings" which are bundles of angular collenchyma cells exterior to the vascular bundles.

Wild celery, "Apium graveolens" var. "graveolens", grows to tall.
It occurs around the globe. The first cultivation is thought to have happened in the Mediterranean region, where the natural habitats were salty and wet, or marshy soils near the coast where celery grew in agropyro-rumicion-plant communities.

North of the alps wild celery is found only in the foothill zone on soils with some salt content. It prefers moist or wet, nutrient rich, muddy soils. It cannot be found in Austria and is increasingly rare in Germany.
First attested in English in 1664, the word "celery" derives from the French "céleri", in turn from Italian "seleri", the plural of "selero", which comes from Late Latin "selinon", the latinisation of the , "celery". The earliest attested form of the word is the Mycenaean Greek "se-ri-no", written in Linear B syllabic script.

Celery was described by Carl Linnaeus in Volume One of his "Species Plantarum" in 1753.

The plants are raised from seed, sown either in a hot bed or in the open garden according to the season of the year, and, after one or two thinnings and transplantings, they are, on attaining a height of , planted out in deep trenches for convenience of blanching, which is effected by earthing up to exclude light from the stems.

In the past, celery was grown as a vegetable for winter and early spring; it was perceived as a cleansing tonic, welcomed to counter the deficiencies of a winter diet based on salted meats without fresh vegetables. By the 19th century, the season for celery had been extended, to last from the beginning of September to late in April.

In North America, commercial production of celery is dominated by the cultivar called 'Pascal' celery. Gardeners can grow a range of cultivars, many of which differ from the wild species, mainly in having stouter leaf stems. They are ranged under two classes, white and red.
The stalks grow in tight, straight, parallel bunches, and are typically marketed fresh that way, without roots and just a little green leaf remaining.

The stalks are eaten raw, or as an ingredient in salads, or as a flavoring in soups, stews, and pot roasts.

In Europe, another popular variety is celeriac (also known as "celery root"), "Apium graveolens" var. "rapaceum", grown because its hypocotyl forms a large bulb, white on the inside. The bulb can be kept for months in winter and mostly serves as a main ingredient in soup. It can also be shredded and used in salads.
The leaves are used as seasoning; the small, fibrous stalks find only marginal use.

Leaf celery (Chinese celery, "Apium graveolens var. secalinum") is a cultivar from East Asia that grows in marshlands. Leaf celery is most likely the oldest cultivated form of celery. Leaf celery has characteristically thin skin stalks and a stronger taste and smell compared to other cultivars. It is used as a flavoring in soups and sometimes pickled as a side dish.

The wild form of celery is known as "smallage". It has a furrowed stalk with wedge-shaped leaves, the whole plant having a coarse, earthy taste, and a distinctive smell. The stalks are not usually eaten (except in soups or stews in French cuisine), but the leaves may be used in salads, and its seeds are those sold as a spice. With cultivation and blanching, the stalks lose their acidic qualities and assume the mild, sweetish, aromatic taste particular to celery as a salad plant.

Because wild celery is rarely eaten, yet susceptible to the same diseases as more well-used cultivars, it is often removed from fields to help prevent transmission of viruses like celery mosaic virus.

Harvesting occurs when the average size of celery in a field is marketable; due to extremely uniform crop growth, fields are harvested only once. The petioles and leaves are removed and harvested; celery is packed by size and quality (determined by color, shape, straightness and thickness of petiole, stalk and midrib length and absence of disease, cracks, splits, insect damage and rot). During commercial harvesting, celery is packaged into cartons which contain between 36 and 48 stalks and weigh up to . Under optimal conditions, celery can be stored for up to seven weeks between . Inner stalks may continue growing if kept at temperatures above . Shelf life can be extended by packaging celery in anti-fogging, micro-perforated shrink wrap. Freshly cut petioles of celery are prone to decay, which can be prevented or reduced through the use of sharp blades during processing, gentle handling, and proper sanitation. 

Celery stalk may be preserved through pickling by first removing the leaves, then boiling the stalks in water before finally adding vinegar, salt, and vegetable oil.

In the past, restaurants used to store celery in a container of water with powdered vegetable preservative, but it was found that the sulfites in the preservative caused allergic reactions in some people. In 1986, the U.S. Food and Drug Administration banned the use of sulfites on fruits and vegetables intended to be eaten raw.

Celery is eaten around the world as a vegetable. In North America the crisp petiole (leaf stalk) is used. In Europe the hypocotyl is used as a root vegetable. The leaves are strongly flavored and are used less often, either as a flavoring in soups and stews or as a dried herb. Celery, onions, and bell peppers are the "holy trinity" of Louisiana Creole and Cajun cuisine. Celery, onions, and carrots make up the French mirepoix, often used as a base for sauces and soups. Celery is a staple in many soups, such as chicken noodle soup. 

Phthalides occur naturally in celery.

Celery juice reputedly has detoxifying benefits and demand for celery spiked in 2019.

Celery leaves are frequently used in cooking to add a mild spicy flavor to foods, similar to, but milder than black pepper. Celery leaves are suitable dried as a sprinkled on seasoning for use with baked, fried or roasted fish, meats and as part of a blend of fresh seasonings suitable for use in soups and stews. They may also be eaten raw, mixed into a salad or as a garnish.

In temperate countries, celery is also grown for its seeds. Actually very small fruit, these "seeds" yield a valuable essential oil that is used in the perfume industry. The oil contains the chemical compound apiole. Celery seeds can be used as flavoring or spice, either as whole seeds or ground.

The seeds can be ground and mixed with salt, to produce celery salt. Celery salt can be made from an extract of the roots or using dried leaves. Celery salt is used as a seasoning, in cocktails (notably to enhance the flavor of Bloody Mary cocktails), on the Chicago-style hot dog, and in Old Bay Seasoning.

Celery seeds have been used widely in Eastern herbal traditions such as Ayurveda. Aulus Cornelius Celsus wrote that celery seeds could relieve pain in around AD 30.

In 2019, a fad in celery water was reported in the USA.

Celery is used in weight loss diets, where it provides low-calorie dietary fiber bulk. Celery is often incorrectly thought to be a "negative-calorie food", the digestion of which burns more calories than the body can obtain. In fact, eating celery provides positive net calories, with digestion consuming only a small proportion of the calories taken in.

Celery is among a small group of foods (headed by peanuts) that appear to provoke the most severe allergic reactions; for people with celery allergy, exposure can cause potentially fatal anaphylactic shock. The allergen does not appear to be destroyed at cooking temperatures. Celery root—commonly eaten as celeriac, or put into drinks—is known to contain more allergen than the stalk. Seeds contain the highest levels of allergen content. Exercise-induced anaphylaxis may be exacerbated. An allergic reaction also may be triggered by eating foods that have been processed with machines that have previously processed celery, making avoiding such foods difficult. In contrast with peanut allergy being most prevalent in the US, celery allergy is most prevalent in Central Europe. In the European Union, foods that contain or may contain celery, even in trace amounts, must be clearly marked as such.

Polyynes can be found in Apiaceae vegetables like celery, and their extracts show cytotoxic activities.
Celery contains phenolic acid, which is an antioxidant.

Apiin and apigenin can be extracted from celery and parsley. Lunularin is a dihydrostilbenoid found in common celery.

The main chemicals responsible for the aroma and taste of celery are butylphthalide and sedanolide.

Daniel Zohary and Maria Hopf note that celery leaves and inflorescences were part of the garlands found in the tomb of pharaoh Tutankhamun (died 1323 BC), and celery mericarps dated to the seventh century BC were recovered in the Heraion of Samos. However, they note "since "A. graveolens" grows wild in these areas, it is hard to decide whether these remains represent wild or cultivated forms." Only by classical times is it certain that celery was cultivated.

M. Fragiska mentions an archeological find of celery dating to the 9th century BC, at Kastanas; however, the literary evidence for ancient Greece is far more abundant. In Homer's "Iliad", the horses of the Myrmidons graze on wild celery that grows in the marshes of Troy, and in "Odyssey", there is mention of the meadows of violet and wild celery surrounding the cave of Calypso.

In the "Capitulary" of Charlemagne, compiled ca. 800, "apium" appears, as does "olisatum", or alexanders, among medicinal herbs and vegetables the Frankish emperor desired to see grown. At some later point in medieval Europe celery displaced alexanders.

The name "celery" retraces the plant's route of successive adoption in European cooking, as the English "celery" (1664) is derived from the French "céleri" coming from the Lombard term, "seleri", from the Latin "selinon", borrowed from Greek.

Celery's late arrival in the English kitchen is an end-product of the long tradition of seed selection needed to reduce the sap's bitterness and increase its sugars. By 1699, John Evelyn could recommend it in his "Acetaria. A Discourse of Sallets": "Sellery, apium Italicum, (and of the Petroseline Family) was formerly a stranger with us (nor very long since in Italy) is an hot and more generous sort of Macedonian Persley or Smallage... and for its high and grateful Taste is ever plac'd in the middle of the Grand Sallet, at our Great Men's tables, and Praetors feasts, as the Grace of the whole Board".

Celery makes a minor appearance in colonial American gardens; its culinary limitations are reflected in the observation by the author of "A Treatise on Gardening, by a Citizen of Virginia" that it is "one of the species of parsley." Its first extended treatment in print was in Bernard M'Mahon's "American Gardener's Calendar" (1806). 

After the mid-19th century, continued selections for refined crisp texture and taste brought celery to American tables, where it was served in celery vases to be salted and eaten raw. Celery was so popular in the USA in the 1800s and early 1900s that the New York Public Library's historical menu archive shows that it was the third most popular dish in New York City menus during that time, behind only coffee and tea. In those days celery cost more than caviar, as it was difficult to cultivate. There were also many varieties of celery back then that are no longer around because they are difficult to grow and do not ship well.

A chthonian symbol among the ancient Greeks, celery was said to have sprouted from the blood of Kadmilos, father of the Cabeiri, chthonian divinities celebrated in Samothrace, Lemnos, and Thebes. The spicy odor and dark leaf color encouraged this association with the cult of death. In classical Greece, celery leaves were used as garlands for the dead, and the wreaths of the winners at the Isthmian Games were first made of celery before being replaced by crowns made of pine. According to Pliny the Elder in Achaea, the garland worn by the winners of the sacred Nemean Games was also made of celery. The Ancient Greek colony of Selinous (, "Selinous"), on Sicily, was named after wild parsley that grew abundantly there; Selinountian coins depicted a parsley leaf as the symbol of the city.

The perennial BBC television series Doctor Who featured the Fifth Doctor (played by Peter Davison, from 1981–84), who wore a sprig of celery as a corsage.

In (TV series) Portlandia's 'The Celery Incident' episode (2014), actor Steve Buscemi plays an unlucky celery salesman who must fight for his job at the "Produce Sales Headquarters", because celery sales are not up to par.

Freelance writer and radio producer Maya Kroth produced a story about celery for the food podcast Proof (from America's Test Kitchen) in 2018, and she appeared on The Sporkful podcast (also in 2018) to discuss the history of celery in the U.S.



</doc>
<doc id="6536" url="https://en.wikipedia.org/wiki?curid=6536" title="CPM">
CPM

CPM may refer to:









</doc>
<doc id="6537" url="https://en.wikipedia.org/wiki?curid=6537" title="Celestines">
Celestines

The Celestines were a Roman Catholic monastic order, a branch of the Benedictines, founded in 1244. At the foundation of the new rule, they were called Hermits of St Damiano, or Moronites (or Murronites), and did not assume the appellation of Celestines until after the election of their founder, Peter of Morone (Pietro Murrone), to the Papacy as Celestine V. They used the post-nominal initials O.S.B. Cel. The order was absorbed by Order of the Most Holy Annunciation from 1778 by order of Pius VI in 1776. In 1810 the last Celestines were transferred.

The fame of the holy life and the austerities practised by Pietro Morone in his solitude on the Mountain of Majella, near Sulmona, attracted many visitors, several of whom were moved to remain and share his mode of life. They built a small convent on the spot inhabited by the holy hermit, which became too small for the accommodation of those who came to share their life of privations. Peter of Morone (later Pope Celestine V), their founder, built a number of other small oratories in that neighborhood.

About the year 1254, Peter of Morone gave the order a rule formulated in accordance with his own practices. In 1264 the new institution was approved as a branch of the Benedictines by Urban IV; however, the next pope Pope Gregory X had commanded that all orders founded since the prior Lateran Council should not be further multiplied. Hearing a rumor that the order was to be suppressed, the reclusive Peter traveled to Lyon, where the Pope was holding a council. There he persuaded Gregory to approve his new order, making it a branch of the Benedictines and following the rule of Saint Benedict, but adding to it additional severities and privations. Gregory took it under the Papal protection, assured to it the possession of all property it might acquire, and endowed it with exemption from the authority of the ordinary. Nothing more was needed to ensure the rapid spread of the new association and Peter the hermit of Morone lived to see himself "Superior-General" to thirty-six monasteries and more than six hundred monks. 

As soon as he had seen his new order thus consolidated he gave up the government of it to a certain Robert, and retired once again to an even more remote site to devote himself to solitary penance and prayer. Shortly afterwards, in a chapter of the order held in 1293, the original monastery of Majella being judged to be too desolate and exposed to too rigorous a climate, it was decided that the Abbey of the Holy Spirit at Monte Morrone, located in Sulmona, should be the headquarters of the order and the residence of the General-Superior, where it continued for centuries. The next year Peter of Morrone, despite his reluctance, was elected Pope by the name of Celestine V. From there on, the order he had founded took the name of Celestines. During his short reign as Pope, the former hermit confirmed the rule of the order, which he had himself composed, and conferred on the society a variety of special graces and privileges. In the only creation of cardinals promoted by him, among the twelve raised to the purple, there were two monks of his order. He also visited personally the Benedictine monastery on Monte Cassino, where he persuaded the monks to accept his more rigorous rule. He sent fifty monks of his order to introduce it, who remained there, however, for only a few months.

After the death of the founder the order was favoured and privileged by Benedict XI, and rapidly spread through Italy, Germany, Flanders, and France, where they were received by Philip the Fair in 1300. The administration of the order was carried on somewhat after the pattern of Cluny, that is all monasteries were subject to the Abbey of the Holy Ghost at Sulmona, and these dependent houses were divided into provinces. The Celestines had ninety-six houses in Italy, twenty-one in France, and a few in Germany.

Subsequently the French Celestines, with the consent of the Italian superiors of the order, and of Pope Martin V in 1427, obtained the privilege of making new constitutions for themselves, which they did in the 17th century in a series of regulations accepted by the provincial chapter in 1667. At that time the French congregation of the order was composed of twenty-one monasteries, the head of which was that of Paris, and was governed by a Provincial with the authority of General. Paul V was a notable benefactor of the order. The order became extinct in the eighteenth century.

According to their special constitutions the Celestines were bound to say matins in the choir at two o'clock in the morning, and always to abstain from eating meat, save in illness. The distinct rules of their order with regard to fasting are numerous, but not more severe than those of similar congregations, though much more so than is required by the old Benedictine rule. In reading their minute directions for divers degrees of abstinence on various days, it is impossible to avoid being struck by the conviction that the great object of the framers of these rules was the general purpose of ensuring an ascetic mode of life.

The Celestines wore a white woollen cassock bound with a linen band, and a leathern girdle of the same colour, with a scapular unattached to the body of the dress, and a black hood. It was not permitted to them to wear any shirt save of serge. Their dress in short was very like that of the Cistercians. But it is a tradition in the order that in the time of the founder they wore a coarse brown cloth. The church and monastery of San Pietro in Montorio originally belonged to the Celestines in Rome; but they were turned out of it by Sixtus IV to make way for Franciscans, receiving from the Pope in exchange the Church of St Eusebius of Vercelli with the adjacent mansion for a monastery.



</doc>
<doc id="6539" url="https://en.wikipedia.org/wiki?curid=6539" title="Cessna">
Cessna

The Cessna Aircraft Company () was an American general aviation aircraft manufacturing corporation headquartered in Wichita, Kansas. Best known for small, piston-powered aircraft, Cessna also produced business jets. For many years the company was one of the highest-volume producers of general aviation aircraft in the world. Founded in 1927, it was purchased by General Dynamics in 1985, then by Textron, Inc. in 1992. In March 2014, when Textron purchased the Beechcraft and Hawker Aircraft businesses, Cessna ceased operations as a subsidiary company and joined the others as one of the three distinct brands produced by Textron Aviation.

Clyde Cessna, a farmer in Rago, Kansas, built his own aircraft and flew it in June 1911, the first person to do so between the Mississippi River and the Rocky Mountains. Cessna started his wood-and-fabric aircraft ventures in Enid, Oklahoma, testing many of his early planes on the salt flats. When bankers in Enid refused to lend him more money to build his planes, he moved to Wichita.
Cessna Aircraft was formed when Clyde Cessna and Victor Roos became partners in the Cessna-Roos Aircraft Company in 1927. Roos resigned just one month into the partnership selling back his interest to Cessna. In the same year, the Kansas Secretary of State approved dropping Roos's name from the company name.

The Cessna DC-6 earned certification on the same day as the stock market crash of 1929, October 29, 1929.

In 1932 the Cessna Aircraft Company closed its doors due to the Great Depression.

However the Cessna CR-3 custom racer took its first flight in 1933. The plane won the 1933 American Air Race in Chicago and later set a new world speed record for engines smaller than 500 cubic inches by averaging .

Cessna's nephews, Dwane Wallace and his brother Dwight, bought the company from Cessna in 1934. They reopened it and began the process of building it into what would become a global success.
The Cessna C-37 was introduced in 1937 as Cessna's first seaplane when equipped with Edo floats. In 1940, Cessna received their largest order to date, when they signed a contract with the U.S. Army for 33 specially equipped Cessna T-50s. Later in 1940, the Royal Canadian Air Force placed an order for 180 T-50s.

Cessna returned to commercial production in 1946, after the revocation of wartime production restrictions (L-48) with the release of the Model 120 and Model 140. The approach was to introduce a new line of all-metal aircraft that used production tools, dies and jigs rather than the hand-built process tube-and-fabric construction used before the war.

The Model 140 was named by the US Flight Instructors Association as the "Outstanding Plane of the Year", in 1948.

Cessna's first helicopter, the Cessna CH-1, received FAA type certification, in 1955.

Cessna introduced the Cessna 172 in 1956. It became the most produced airplane in history.

In 1960 Cessna affiliated itself with Reims Aviation of Reims, France. In 1963 Cessna produced its 50,000th airplane, a Cessna 172.

Cessna's first business jet, the Cessna Citation I performed its maiden flight on September 15, 1969.

Cessna produced its 100,000th single-engine airplane in 1975.

In 1985 Cessna ceased to be an independent company. It was purchased by General Dynamics Corporation and became a wholly owned subsidiary. Production of the Cessna Caravan began. General Dynamics in turn, sold Cessna to Textron, in 1992.
Late in 2007, Cessna purchased the bankrupt Columbia Aircraft company for US$26.4M and would continue production of the Columbia 350 and 400 as the Cessna 350 and Cessna 400 at the Columbia factory in Bend, Oregon.

On November 27, 2007, Cessna announced the then-new Cessna 162 would be built in the People's Republic of China by Shenyang Aircraft Corporation, which is a subsidiary of the China Aviation Industry Corporation I (AVIC I), a Chinese government-owned consortium of aircraft manufacturers. Cessna reported that the decision was made to save money and also that the company had no more plant capacity in the United States at the time. Cessna received much negative feedback for this decision, with complaints centering on the recent quality problems with Chinese production of other consumer products, China's human rights record, exporting of jobs, and China's less than friendly political relationship with the United States. The customer backlash surprised Cessna and resulted in a company public relations campaign. In early 2009, the company attracted further criticism for continuing plans to build the 162 in China while laying off large numbers of workers in the United States. In the end the Cessna 162 was not a commercial success and only a small number were delivered before production was cancelled.

The company's business suffered notably during the late-2000s recession, laying off more than half its workforce between January 2009 and September 2010.

On November 4, 2008, Cessna's parent company, Textron, indicated that Citation production would be reduced from the original 2009 target of 535 "due to continued softening in the global economic environment" and that this would result in an undetermined number of lay-offs at Cessna.

On November 8, 2008, at the Aircraft Owners and Pilots Association (AOPA) Expo, CEO Jack Pelton indicated that sales of Cessna aircraft to individual buyers had fallen but piston and turboprop sales to businesses had not. "While the economic slowdown has created a difficult business environment, we are encouraged by brisk activity from new and existing propeller fleet operators placing almost 200 orders for 2009 production aircraft," Pelton stated.

Beginning in January 2009, a total of 665 jobs were cut at Cessna's Wichita and Bend, Oregon plants. The Cessna factory at Independence, Kansas, which builds the Cessna piston-engined aircraft and the Cessna Mustang, did not see any layoffs, but one third of the workforce at the former Columbia Aircraft facility in Bend was laid off. This included 165 of the 460 employees who built the Cessna 350 and 400. The remaining 500 jobs were eliminated at the main Cessna Wichita plant.

In January 2009, the company laid off an additional 2,000 employees, bringing the total to 4,600. The job cuts included 120 at the Bend, Oregon, facility reducing the plant that built the Cessna 350 and 400 to fewer than half the number of workers that it had when Cessna bought it. Other cuts included 200 at the Independence, Kansas, plant that builds the single-engined Cessnas and the Mustang, reducing that facility to 1,300 workers.

On April 29, 2009 the company suspended the Citation Columbus program and closing the Bend, Oregon, facility. The Columbus program was finally cancelled in early July 2009. The company reported "Upon additional analysis of the business jet market related to this product offering, we decided to formally cancel further development of the Citation Columbus". With the 350 and 400 production moving to Kansas, the company indicated that it would lay off 1,600 more workers, including the remaining 150 employees at the Bend plant and up to 700 workers from the Columbus program.

In early June 2009 Cessna laid off an additional 700 salaried employees, bringing the total number of lay-offs to 7,600, which was more than half the company's workers at the time.

The company closed its three Columbus, Georgia, manufacturing facilities between June 2010 and December 2011. The closures included the new facility that was opened in August 2008 at a cost of US$25M, plus the McCauley Propeller Systems plant. These closures resulted in total job losses of 600 in Georgia. Some of the work was relocated to Cessna's Independence, Kansas, or Mexican facilities.

Cessna's parent company, Textron, posted a loss of US$8M in the first quarter of 2010, largely driven by continuing low sales at Cessna, which were down 44%. Half of Cessna's workforce remained laid-off and CEO Jack Pelton stated that he expected the recovery to be long and slow.

In September 2010, a further 700 employees were laid off, bringing the total to 8,000 jobs lost. CEO Jack Pelton indicated this round of layoffs was due to a "stalled [and] lackluster economy" and noted that while the number of orders cancelled for jets had been decreasing new orders had not met expectations. Pelton added "our strategy is to defend and protect our current markets while investing in products and services to secure our future, but we can do this only if we succeed in restructuring our processes and reducing our costs."

On May 2, 2011 CEO Jack Pelton retired. The new CEO, Scott A. Ernest, started on May 31, 2011. Ernest joined Textron after 29 years at GE, where he had most recently served as vice president and general manager, global supply chain for GE Aviation. Ernest previously worked for Textron CEO Scott Donnelly when both worked at GE.

In September 2011 the Federal Aviation Administration proposed a US$2.4M fine against the company for its failure to follow quality assurance requirements while producing fiberglass components at its plant in Chihuahua, Mexico. Excess humidity meant that the parts did not cure correctly and quality assurance did not detect the problems. The failure to follow procedures resulted in the delamination in flight of a section of one Cessna 400's wing skin from the spar while the aircraft was being flown by an FAA test pilot. The aircraft was landed safely. The FAA also discovered 82 other aircraft parts that had been incorrectly made and not detected by the company's quality assurance. The investigation resulted in an emergency airworthiness directive that affected 13 Cessna 400s.

Since March 2012, Cessna has been pursuing building business jets in China as part of a joint venture with Aviation Industry Corporation of China (AVIC). The company stated that it intends to eventually build all aircraft models in China, saying "The agreements together pave the way for a range of business jets, utility single-engine turboprops and single-engine piston aircraft to be manufactured and certified in China."

In late April 2012 the company added 150 workers in Wichita as a result of anticipated increased demand for aircraft production. Overall they have cut more than 6000 jobs in the Wichita plant since 2009.
In March 2014 Cessna ceased operations as a company and instead became a brand of Textron Aviation.

During the 1950s and 1960s Cessna's marketing department followed the lead of Detroit automakers and came up with many unique marketing terms in an effort to differentiate its product line from their competitions'.

Other manufacturers and the aviation press widely ridiculed and spoofed many of the marketing terms, but Cessna built and sold more aircraft than any other manufacturer during the boom years of the 1960s and 1970s.

Generally, the names of Cessna models do not follow a theme, but there is logic to the numbering: the 100 series are the light singles, the 200s are the heftier, the 300s are light to medium twins, the 400s have “wide oval” cabin-class accommodation, and the 500s are jets. Many Cessna models have names starting with C for the sake of alliteration (e.g. Citation, Crusader, Chancellor).

Cessna marketing terminology includes:


As of July 2018, Textron Aviation is producing the following Cessna models:



</doc>
<doc id="6542" url="https://en.wikipedia.org/wiki?curid=6542" title="Czesław Miłosz">
Czesław Miłosz

Czesław Miłosz (; 30 June 1911 – 14 August 2004) was a Polish-American poet, prose writer, translator, and diplomat. Regarded as one of the great poets of the twentieth century, he won the 1980 Nobel Prize in Literature. The Swedish Academy, in its Nobel citation, described Miłosz as a writer who "voices man’s exposed condition in a world of severe conflicts". 

Miłosz survived the German occupation of Warsaw during World War II and became a cultural attaché for the Polish government during the post-war period. When communist authorities threatened his safety, he defected to France and ultimately chose exile in the United States, where he became a professor at the University of California at Berkeley. His poetry—particularly about his wartime experience—and his appraisal of Stalinism in a prose book, "The Captive Mind", brought him renown as a leading émigré artist and intellectual. 

Throughout his life and work, Miłosz tackled questions of morality, politics, history, and faith. As a translator, he introduced Western works to a Polish audience, and as a scholar and editor, he championed a greater awareness of Slavic literature in the West. Faith played a role in his work as he explored his Catholicism and personal experience.

Miłosz died in Kraków, Poland, in 2004. He is interred in Skałka, a church that is known in Poland as a place of honor for distinguished Poles.

Czesław Miłosz was born on June 30, 1911, in the village of Szetejnie (), Kovno Governorate, Russian Empire (now Kėdainiai district, Kaunas County, Lithuania). He was the son of Aleksander Miłosz (1883 – 1959), a Polish civil engineer, and Weronika (née Kunat; 1887 – 1945). 

Miłosz was born into a notable family. On his mother’s side, his grandfather was Zygmunt Kunat, a descendant of a Polish family that could trace its lineage to the thirteenth century, and which owned an estate in Krasnogruda (in present-day Poland). Having studied agriculture in Warsaw, Zygmunt settled in Szetejnie after marrying Miłosz’s grandmother, Jozefa, a descendant of the noble Syruć family, which was of Lithuanian origin. One of her ancestors, Szymon Syruć, had been personal secretary to Stanisław I, King of Poland and Grand Duke of Lithuania. On Miłosz’s father’s side, his grandfather, Artur Miłosz, was also from a noble family and fought in the 1863 January Uprising for Polish independence. Miłosz’s grandmother, Stanisława, was a doctor’s daughter from Riga, Latvia, and a member of the German/Polish von Mohl family. The Miłosz estate was located in Serbiny, a name which Miłosz’s biographer, Andrzej Franaszek, has suggested could indicate a Serbian origin—it is possible the Miłosz family originated in Serbia and settled in present-day Lithuania after being expelled from Germany centuries earlier. Miłosz’s father was born and educated in Riga. Miłosz’s mother was born in Szetejnie and educated in Kraków.

Despite this noble lineage, Miłosz’s childhood on his maternal grandfather’s estate in Szetejnie was not filled with the trappings of wealth or the customs of the upper class. He memorialized his childhood in a 1955 novel, "The Issa Valley", and in a 1959 memoir, "Native Realm." In these works, he described the influence of his Catholic grandmother, Jozefa, his burgeoning love for literature, and his early awareness, as a member of the Polish gentry in Lithuania, of the role of class in society.

Miłosz’s early years were marked by upheaval. When his father was hired to work on infrastructure projects in Siberia, he and his mother traveled to be with him. After World War I broke out in 1914, Miłosz’s father was conscripted into the Russian army, tasked with engineering roads and bridges for troop movements. Miłosz and his mother were sheltered in Wilno when the German army captured it in 1915. Afterward, they once again joined Miłosz’s father, following him as the front moved further into Russia, where, in 1917, Miłosz’s brother, Andrzej, was born. Finally, after moving through Estonia and Latvia, the family returned to their home in Szetejnie in 1918. However, the Polish-Soviet War broke out in 1919, during which Miłosz’s father was involved in a failed attempt to incorporate the newly independent Lithuania into the Second Polish Republic, resulting in his expulsion from Lithuania and the family’s move to Wilno, which had become part of Poland after the Polish-Lithuanian War of 1920. The Polish-Soviet War continued, forcing the family to move again. At one point during the conflict, Miłosz and his mother were fired upon by Polish soldiers, an episode Miłosz later recounted in his memoir, "Native Realm." The family returned to Wilno when the war ended in 1921.

Despite the interruptions of wartime wanderings, Miłosz proved to be an exceptional student with a facility for languages. He ultimately learned Polish, Lithuanian, Russian, English, French, and Hebrew. After graduation from Sigismund Augustus Gymnasium in Wilno, he entered Stefan Batory University in 1929 as a law student. While at university, Miłosz joined a student group called The Intellectuals’ Club and a student poetry group called Żagary, along with the young poets Jerzy Zagórski, Teodor Bujnicki, Aleksander Rymkiewicz, Jerzy Putrament, and Józef Maśliński. His first published poems appeared in the university’s student magazine in 1930.

In 1931, he visited Paris, where he first met his distant cousin, Oscar Miłosz, a French-language poet of Lithuanian descent who had become a Swedenborgian. Oscar became a mentor and inspiration. Returning to Wilno, Miłosz’s early awareness of class difference, and his sympathy for those less fortunate than himself, inspired his defense of Jewish students at the university who were being harassed by an anti-Semitic mob. Stepping between the mob and the Jewish students, Miłosz fended off attacks. One student was killed when a rock was thrown at his head.

Miłosz's first volume of poetry, "A Poem on Frozen Time", was published in Polish in 1933. In the same year, he publicly read his poetry at an anti-racist "Poetry of Protest" event in Wilno, occasioned by Hitler’s rise to power in Germany. In 1934, he graduated with a law degree, and the poetry group Żagary disbanded. Miłosz relocated to Paris on a scholarship to study for one year and write articles for a newspaper back in Wilno. In Paris, he frequently met with his cousin Oscar. 

By 1936, he had returned to Wilno, where he worked on literary programs at Radio Wilno. His second poetry collection, "Three Winters", was published that same year, eliciting, from one critic, a comparison to Adam Mickiewicz. After only one year at Radio Wilno, however, Miłosz was dismissed due to an accusation that he was a left-wing sympathizer—as a student, he had adopted socialist views from which, by then, he had publicly distanced himself, and he and his boss, Tadeusz Byrski, had produced programming that included performances by Jews and Byelorussians—activities that angered right-wing nationalists. After Byrski made a trip to the Soviet Union, an anonymous complaint was lodged with the management of Radio Wilno, claiming the station housed a communist cell, and Byrski and Miłosz were subsequently dismissed. In the summer of 1937, Miłosz moved to Warsaw, where he found work at Polish Radio and met his future wife, Janina (née Dłuska; 1909 – 1986), who was, at the time, married to another man.

Miłosz was in Warsaw when it was bombarded as part of the German invasion of Poland in September 1939. Along with colleagues from Polish Radio, he escaped the city, making his way to Lwów. However, when he learned that Janina had remained in Warsaw with her parents, he looked for a way back. The Soviet invasion of Poland thwarted his plans, and, to avoid the incoming Red Army, he fled to Bucharest. There, he obtained a Lithuanian identity document and Soviet visa that allowed him to travel, by train, to Kiev and then to Wilno. After Lithuania was invaded by the Red Army, he procured fake documents that he used to enter the part of German-occupied Poland which the Germans had dubbed the "General Government". It was a difficult journey, mostly on foot, that ended in the summer of 1940. Finally back in Warsaw, he reunited with Janina.

Like many Poles at the time, to evade notice by German authorities, Miłosz participated in underground activities. For example, with higher education officially forbidden to Poles, he attended underground lectures by Władysław Tatarkiewicz, the Polish philosopher and historian of philosophy and aesthetics. He translated Shakespeare’s "As You Like It" and T.S. Eliot’s "The Waste Land" into Polish. Along with his good friend, the novelist Jerzy Andrzejewski, he also arranged for the publication of his third volume of poetry, entitled "Poems", under a pseudonym in September 1940. The title page claimed the author was "Jan Syruć" and the volume had been published by a fictional press in Lwów in 1939—in fact, it may have been the first clandestine book published in occupied Warsaw. In 1942, Miłosz arranged for the publication of an anthology of Polish poets, entitled "Invincible Song: Polish Poetry of War Time", by an underground press.

However, Miłosz’s riskiest underground wartime activity was aiding Jews in Warsaw, which he did through an underground socialist organization called Freedom. His brother, Andrzej, was also active in helping Jews in Nazi-occupied Poland; in 1943, he transported the Polish Jew Seweryn Tross and his wife from Wilno to Warsaw. Miłosz took in the Trosses, found them a hiding place, and supported them financially. The Trosses ultimately died during the Warsaw Uprising. Miłosz helped at least three other Jews in similar ways: Felicja Wołkomińska and her brother and sister.

Despite his willingness to engage in underground activity and his vehement opposition to the Nazis, Miłosz did not join the Polish Home Army. In later years, he explained that this was partly from an instinct for self-preservation and partly because he saw its leadership as right-wing and dictatorial. He also did not participate in the planning or execution of the Warsaw Uprising. According to Irena Grudzińska-Gross, he saw the uprising as a "doomed military effort" and he lacked the "patriotic elation" for it. He called the uprising "a blameworthy, lightheaded enterprise", although he later criticized the Soviet Red Army for failing to support it when it had the opportunity to do so.

As German troops began torching Warsaw buildings in August 1944, Miłosz and Janina escaped the city, ultimately settling in a village outside Kraków, where they were staying when the Red Army swept through Poland in January 1945, after Warsaw had been largely destroyed. 

In the preface to his 1953 book, "The Captive Mind", Miłosz wrote, "I do not regret those years in Warsaw, which was, I believe, the most agonizing spot in the whole of terrorized Europe. Had I then chosen emigration, my life would certainly have followed a very different course. But my knowledge of the crimes which Europe has witnessed in the twentieth century would be less direct, less concrete than it is". Immediately after the war, Miłosz published his fourth poetry collection, "Rescue"; it focused on his wartime experiences and contains some of his most critically praised work, including the twenty-poem cycle "The World," composed like a primer for naïve schoolchildren, and the cycle "Voices of Poor People". The volume also contains some of his most frequently anthologized poems, including "A Song on the End of the World", "Campo Dei Fiori", and "A Poor Christian Looks at the Ghetto".

From 1945 to 1951, Miłosz served as a cultural attaché for the newly formed Polish People's Republic. In this capacity, he moved from New York City to Washington, D.C., and finally to Paris, organizing and promoting Polish cultural occasions such as musical concerts, art exhibitions, and literary and cinematic events. Though he was a representative of Poland, which had become a Soviet satellite country behind the Iron Curtain, he was not a member of the Communist Party. Writing in "The Captive Mind", he explained his reasons for accepting the role:"My mother tongue, work in my mother tongue, is for me the most important thing in life. And my country, where what I wrote could be printed and could reach the public, lay within the Eastern Empire. My aim and purpose was to keep alive freedom of thought in my own special field; I sought in full knowledge and conscience to subordinate my conduct to the fulfillment of that aim. I served abroad because I was thus relieved from direct pressure and, in the material which I sent to my publishers, could be bolder than my colleagues at home. I did not want to become an émigré and so give up all chance of taking a hand in what was going on in my own country."Miłosz did not publish a book during his time as a representative of the Polish government. Instead, he wrote articles for various Polish periodicals introducing readers to American writers like T.S. Eliot, William Faulkner, Ernest Hemingway, Norman Mailer, Robert Lowell, and W.H. Auden. He also translated into Polish Shakespeare’s "Othello" and the work of Walt Whitman, Carl Sandburg, Pablo Neruda, and others. 

In 1947, Miłosz’s son, Anthony, was born in Washington, D.C.

In 1948, Miłosz arranged for the Polish government to fund a Department of Polish Studies at Columbia University. Named for Adam Mickiewicz, the department would feature lectures by Manfred Kridl, Miłosz’s friend who was then on the faculty of Smith College, as well as produce a scholarly book about Mickiewicz. Mickiewicz’s granddaughter wrote a letter to Dwight Eisenhower, then the president of Columbia University, to express her approval. However, the Polish American Congress, an influential group of Polish émigrés, denounced the arrangement in a letter to Eisenhower that they shared with the press, which reported that there was a communist infiltration at Columbia. Students picketed and called for boycotts. One faculty member resigned in protest. Despite the controversy, the department was established, the lectures took place, and the book was produced. However, the department was discontinued in 1954 when funding from Poland ceased.

In 1949, Miłosz visited Poland for the first time since joining its diplomatic corps and was appalled by the conditions he saw there, including an atmosphere of pervasive fear of the government. After returning to the U.S., he began to look for a way to leave his post, even soliciting advice from Albert Einstein, whom he met in the course of his duties.

As the Polish government, influenced by Stalin, became more oppressive, his superiors began to view Miłosz as a threat—he was outspoken in his reports to Warsaw and met with individuals not officially approved by his superiors. Consequently, his superiors labelled him "an individual who ideologically is totally alien". Toward the end of 1950, when Janina was pregnant with their second child, Miłosz was recalled to Warsaw, where in December 1950 his passport was confiscated, ostensibly until it could be determined that he did not plan to defect. After intervention by Poland’s foreign minister, Zygmunt Modzelewski, Miłosz’s passport was returned. Realizing that he was in danger if he remained in Poland, Miłosz left for Paris in January 1951.

Upon arriving in Paris, Miłosz immediately went into hiding, aided by the staff of the Polish émigré magazine "Kultura." With his wife and son still in the United States, Miłosz applied to enter the U.S. and was denied. At the time, the U.S. was in the grip of McCarthyism, and influential Polish émigrés had convinced American officials that Miłosz was a communist. Unable to leave France, Miłosz was not present for the birth of his second son, John Peter, in Washington, D.C., in 1951.

With the United States closed to him, Miłosz requested—and was granted—political asylum in France. After three months in hiding, he announced his defection with a press conference and an article in "Kultura", entitled "No", that explained his refusal to live in Poland or continue working for the Polish regime. He was the first artist of note from a communist country to make public his reasons for breaking ties with his government. His case attracted attention in Poland, where his writing was banned and he was attacked in the press, and in the West, where prominent individuals voiced criticism and support. For example, the future Nobel laureate Pablo Neruda, then a supporter of the Soviet Union, attacked him in a communist newspaper as "The Man Who Ran Away". On the other hand, Albert Camus, another future Nobel laureate, visited with Miłosz and offered his support.

Miłosz was finally reunited with his family in 1953, when Janina and the children joined him in France. That same year saw the publication of "The Captive Mind", a nonfiction work that uses case studies to dissect the methods and consequences of Soviet communism, which at the time had prominent admirers in the West. The book brought Miłosz his first readership in the United States, where it was credited by some on the political left (such as Susan Sontag) with helping to change perceptions about communism. The German philosopher Karl Jaspers described it as a "significant historical document". It became a staple of political science courses and is considered a classic work in the study of totalitarianism.

Miłosz’s years in France were productive. In addition to "The Captive Mind", he published two poetry collections ("Daylight" (1954) and "A Treatise on Poetry" (1957)), two novels ("The Seizure of Power" (1955) and "The Issa Valley" (1955)), and a memoir ("Native Realm" (1959)). All were published in Polish by an émigré press in Paris.

Notably, "A Treatise on Poetry" has been described by Andrzej Franaszek as Miłosz’s "magnum opus", while the scholar Helen Vendler compared it to T.S. Eliot’s "The Waste Land", a work "so powerful that it bursts the bounds in which it was written—the bounds of language, geography, epoch". A long poem divided into four sections, "A Treatise on Poetry" surveys Polish history, recounts Miłosz’s experience of war, and explores the relationship between art and history.

In 1956, Miłosz and Janina were married.

In 1960, Miłosz was offered a position as a visiting lecturer at the University of California at Berkeley. With this offer, and with the climate of McCarthyism abated, he was able to move to the United States. He proved to be an adept and popular teacher, and was offered tenure after only two months. The rarity of this feat, and the degree to which he had impressed his colleagues, are underscored by the fact that Miłosz lacked both a PhD and teaching experience. Yet his deep learning was obvious, and after years of working administrative jobs that he found stifling, he reported to friends that he was in his element in a classroom. With stable employment as a tenured Professor of Slavic Languages and Literature, Miłosz was able to secure American citizenship in 1962 and purchase a home in Berkeley.

Miłosz began to publish scholarly articles in English and Polish on a variety of authors, including Fyodor Dostoevsky. However, despite his successful transition to the U.S., he described his early years at Berkeley as frustrating, as he was isolated from friends and viewed as a political figure rather than a great poet. (In fact, some of his Berkeley faculty colleagues, unaware of his creative output, expressed astonishment when he won the Nobel Prize.) His poetry was not available in English, and he was not able to publish in Poland. 

As part of an effort to introduce American readers to his poetry, as well as to the work of his fellow Polish poets, Miłosz conceived and edited the anthology "Postwar Polish Poetry", which was published in English in 1965. It has been credited by American poets like W.S. Merwin, and American scholars like Clare Cavanagh, with having a profound impact. For many English-language readers, it was their first exposure to Miłosz’s poetry, as well as the work of Polish poets like Wisława Szymborska, Zbigniew Herbert, and Tadeusz Różewicz. In 1969, his textbook, "The History of Polish Literature", was published in English. Miłosz then followed this with a volume of his own work, "Selected Poems" (1973), some of which he translated into English himself. 

At the same time, Miłosz continued to publish in Polish with an émigré press in Paris. His poetry collections from this period include "King Popiel and Other Poems" (1962), "Bobo’s Metamorphosis" (1965), "City Without a Name" (1969), and "From the Rising of the Sun" (1974). 

During Miłosz’s time at Berkeley, the campus became a hotbed of student protest, notably as the home of the Free Speech Movement, which has been credited with helping to "define a generation of student activism" across the United States. Miłosz’s relationship to student protestors was sometimes antagonistic: he called them "spoiled children of the bourgeoisie," and deemed their political zeal naïve. At one campus event in 1970, he mocked protestors who claimed to be demonstrating for peace and love: "Talk to me about love when they come into your cell one morning, line you all up, and say 'You and you, step forward—it’s your time to die—unless any of your friends loves you so much he wants to take your place!'" Comments like these were in keeping with his stance toward American counterculture of the 1960s in general. For example, in 1968, when Miłosz was listed as a signatory of an open letter of protest written by poet and counterculture figure Allen Ginsberg and published in "The New York Review of Books", Miłosz responded by calling the letter “dangerous nonsense” and insisting that he had not signed it.

After eighteen years, Miłosz officially retired from teaching in 1978. To mark the occasion, he was awarded a "Berkeley Citation", the University of California’s equivalent of an honorary doctorate. However, when his wife, Janina, fell ill and required expensive medical treatment, Miłosz returned to teaching seminars.

On October 9, 1980, The Swedish Academy announced that Miłosz had won the Nobel Prize in Literature. The award catapulted him to global fame. On the day the prize was announced, Miłosz held a brief press conference and then left to teach a class on Dostoevsky. In his Nobel lecture, Miłosz described his view of the role of the poet, lamented the tragedies of the twentieth century, and paid tribute to his cousin, Oscar.

Miłosz's winning the Nobel Prize was the first time that many Poles became aware of him. After a thirty-year ban in his home country, his writing was finally published in Poland in limited selections. He was also able to visit Poland for the first time since fleeing in 1951 and was greeted by crowds with a hero’s welcome. He met with leading Polish figures like Lech Wałęsa and Pope John Paul II. At the same time, his early work, until then only available in Polish, began to be translated into English and many other languages.

In 1981, Miłosz was appointed the Norton Professor of Poetry at Harvard University, where he was invited to deliver the Charles Eliot Norton Lectures. He used the opportunity, as he did before and after becoming a Nobel laureate, to draw attention to writers who had been unjustly imprisoned or persecuted. The lectures were published as "The Witness of Poetry" (1983).

Miłosz continued to publish work in Polish through his longtime publisher in Paris. This included the poetry collections "Hymn of the Pearl" (1981), "Bells in Winter" (1984) and "Unattainable Earth" (1986), as well as the essay collection "Beginning with My Streets" (1986). 

In 1986, Miłosz’s wife, Janina, died.

In 1988, his "Collected Poems" appeared in English; it was the first of several attempts to collect all of Miłosz’s voluminous poetry into a single volume. After the fall of communism in Poland, he split his time between Berkeley and Kraków, and he began to publish his writing in Polish with a publisher based in Kraków. When Lithuania broke free from the Soviet Union in 1991, Miłosz visited for the first time since 1939.

In 1992, Miłosz married Carol Thigpen (1944 – 2002), an academic at Emory University in Atlanta, Georgia. They remained married until her death in 2002. His work from the 1990s included the poetry collections "Facing the River" (1994) and "Roadside Dog" (1997), and the collection of short prose, "Miłosz’s ABC’s" (1997). Miłosz’s last stand-alone volumes of poetry were "This" (2000), and "The Second Space" (2002). Uncollected poems written afterward appeared in English in "New and Selected Poems" (2004) and, posthumously, in "Selected and Last Poems" (2011).

Czesław Miłosz died on August 14, 2004, at his Kraków home, aged 93. He was given a state funeral at the historic Mariacki Church in Kraków. The Prime Minister of Poland, Marek Belka, attended, as did the former President of Poland, Lech Wałęsa. Thousands of people lined the streets to witness his coffin moved by military escort to his final resting place at Skałka Roman Catholic Church, where he was one of the last to be commemorated. In front of that church, the poets Seamus Heaney, Adam Zagajewski, and Robert Hass read Miłosz’s poem, "In Szetejnie", in Polish, French, English, Russian, Lithuanian, and Hebrew—all of the languages Miłosz knew. The funeral was covered by media from around the world.

Protesters threatened to disrupt the proceedings on the grounds that Miłosz was anti-Polish, anti-Catholic, and had signed a petition supporting gay and lesbian freedom of speech and assembly. Pope John Paul II, along with Miłosz's confessor, issued public messages confirming that Miłosz had received the sacraments, which quelled the protest.

Miłosz’s brother, Andrzej Miłosz (1917 – 2002), was a Polish journalist, translator, and documentary film producer. His work included Polish documentaries about his brother.

Miłosz’s son, Anthony, is a music composer and software designer. He studied linguistics, anthropology, and chemistry at the University of California at Berkeley, and neuroscience at the University of California Medical Center in San Francisco. In addition to releasing recordings of his own compositions, he has translated some of his father’s poems into English.

Miłosz received numerous honors during his life. In addition to the Nobel Prize in Literature, he received the following awards for his body of work:


Miłosz was named a distinguished visiting professor or fellow at many institutions, including the University of Michigan and University of Oklahoma, where he was a Puterbaugh Fellow in 1999. He was an elected member of both the American Academy of Arts and Sciences and the American Academy of Arts and Letters. He received honorary doctorates from Harvard University, University of Michigan, University of California at Berkeley, Jagiellonian University, Catholic University of Lublin, and Vytautas Magnus University in Lithuania. The latter institution also has an academic center named for Miłosz. 

In 1992, Miłosz was made an honorary citizen of Lithuania, where his birthplace was made into a museum and conference center. In 1993, he was made an honorary citizen of Kraków.

His individual books also received awards. His first book, "A Poem on Frozen Time", won an award from the Union of Polish Writers in Wilno. His book, "The Seizure of Power", received the Prix Littéraire Européen (European Literary Prize), while the collection "Roadside Dog" received a Nike Award in Poland.

In 1989, he was named one of the "Righteous Among the Nations" at Israel's Yad Vashem memorial to the Holocaust, in recognition of his efforts to save Jews in Warsaw during World War II. 

Miłosz has also been honored posthumously. The Polish Parliament declared 2011, the centennial of his birth, the "Year of Miłosz". It was marked by conferences and tributes throughout Poland, as well as in New York City, at Yale University, and at the Dublin Writers Festival, among many other locations. In the same year, he was featured on a Lithuanian postage stamp. Streets are named for him near Paris, France, Vilnius, Lithuania, and in the Polish cities of Kraków, Poznań, Gdańsk, Białystok, and Wrocław. In Gdańsk, there is also a Czesław Miłosz Square. In 2013, a primary school in Vilnius was named for Miłosz, joining schools in Mierzecice, Poland, and Schaumburg, Illinois, that bear his name.

In 1978, the Russian-American poet Joseph Brodsky called Miłosz "one of the great poets of our time; perhaps the greatest". Miłosz has been cited as an influence by numerous writers—both among his contemporaries and succeeding generations. For example, scholars have written about Miłosz’s influence on the writing of Seamus Heaney, and the scholar Clare Cavanagh has identified the following poets as having benefited from Miłosz’s influence: Robert Pinsky, Edward Hirsch, Rosanna Warren, Robert Hass, Charles Simic, Mary Karr, Carolyn Forché, Mark Strand, Ted Hughes, Joseph Brodsky, and Derek Walcott. 

By being smuggled into Poland, Miłosz’s writing was a source of inspiration to the anti-communist Solidarity movement there in the early 1980s. Lines from his poem, "You Who Wronged", are inscribed on the Monument to the Fallen Shipyard Workers of 1970 in Gdańsk, where Solidarity originated.

Writing about the effect of Miłosz’s edited volume, "Postwar Polish Poetry", on English-language poets, W.S. Merwin claimed that "Miłosz’s book had been a talisman and had made most of the literary bickering among the various ideological encampments, then most audible in the poetic doctrines in English, seem frivolous and silly". Similarly, the British poet and scholar Donald Davie argued that, for many English-language writers, Miłosz’s work encouraged an expansion of poetry to include multiple viewpoints and an engagement with subjects of intellectual and historical importance: "I have suggested, going for support to the writings of Miłosz, that no concerned and ambitious poet of the present day, aware of the enormities of twentieth-century history, can for long remain content with the privileged irresponsibility allowed to, or imposed on, the lyric poet". 

Miłosz’s writing continues to be the subject of academic study, conferences, and cultural events. His papers, including manuscripts, correspondence, and other materials, are housed at the Beinecke Rare Book and Manuscript Library at Yale University.

Miłosz’s birth in a time and place of shifting borders and overlapping cultures has led to competing claims about his nationality. Although his family identified as Polish and Polish was his primary language, and although he frequently spoke of Poland as his country, he also publicly identified himself as one of the last citizens of the multi-ethnic Grand Duchy of Lithuania. Writing in a Polish newspaper in 2000, he claimed, "I was born in the very center of Lithuania and so have a greater right than my great forebear, Mickiewicz, to write 'O Lithuania, my country.'" However, in his Nobel lecture, he said, "My family in the sixteenth century already spoke Polish, just as many families in Finland spoke Swedish and in Ireland English, so I am a Polish, not a Lithuanian, poet". 

Public statements such as these, and numerous others, inspired discussion about his nationality, including a claim that he was "arguably the greatest spokesman and representative of a Lithuania that, in Miłosz’s mind, was bigger than its present incarnation". However, writing in the "New York Review of Books" in 1981, the critic John Bayley claimed that "nationality is not a thing [Miłosz] can take seriously; it would be hard to imagine a greater writer more emancipated from even its most subtle pretensions". Speaking at a ceremony to celebrate the poet’s birth centenary in 2011, the President of Lithuania, Dalia Grybauskaité, stressed that Miłosz’s works "unite the Lithuanian and Polish people and reveal how close and how fruitful the ties between our people can be".

Though raised Catholic, Miłosz as a young man came to adopt a "scientific, atheistic position mostly", though he later returned to the Catholic faith. He translated parts of the Bible into Polish, and allusions to Catholicism pervade his poetry, culminating in a long 2001 poem, "A Theological Treatise". For some critics, Miłosz’s belief that literature should provide spiritual fortification was outdated: Franaszek suggests that Miłosz’s belief was evidence of a "beautiful naïveté", while David Orr, citing Miłosz’s dismissal of "poetry which does not save nations or people", accused him of "pompous nonsense". 

Miłosz had expressed some criticisms of both Catholicism and Poland (a majority-Catholic country), causing a furor in some quarters when it was announced that he would be interred in Kraków's historic Skałka church. Cynthia Haven writes that, to some readers, Miłosz’s embrace of Catholicism can seem surprising and complicates an understanding of the poet and his work.

Miłosz’s body of work comprised multiple literary genres: poetry, fiction (particularly the novel), autobiography, scholarship, personal essay, and lectures. His letters are also of interest to scholars and lay readers; for example, his correspondence with writers such as Jerzy Andrzejewski, Witold Gombrowicz, and Thomas Merton have been published. 

At the outset of his career, Miłosz was known as a "catastrophist" poet—a label critics applied to him and other poets from the Żagary poetry group to describe their use of surreal imagery and formal inventiveness in reaction to a Europe beset by extremist ideologies and war. While Miłosz evolved away from the apocalyptic view of “catastrophist” poetry, he continued to pursue formal inventiveness throughout his career. As a result, his poetry demonstrates a wide-ranging mastery of form, from long or epic poems (e.g., "A Treatise on Poetry") to poems of just two lines (e.g., "On the Death of a Poet" from the collection "This"), and from prose poems and free verse to classic forms such as the ode or elegy. Some of his poems use rhyme, but many do not. In numerous cases, Miłosz used form to illuminate meaning in his poetry; for example, by juxtaposing variable stanzas to accentuate ideas or voices that challenge each other.

Miłosz’s work is known for its complexity; according to the scholars Leonard Nathan and Arthur Quinn, Miłosz "prided himself on being an esoteric writer accessible to a mere handful of readers". Nevertheless, some common themes are readily apparent throughout his body of work. 

The poet, critic, and frequent Miłosz translator Robert Hass has described Miłosz as "a poet of great inclusiveness" with a fidelity to capturing life in all of its sensuousness and multiplicities. In fact, according to Hass, Miłosz’s poems can be viewed as "dwelling in contradiction", where one idea or voice is presented only to be immediately challenged or changed. According to Donald Davie, this allowance for contradictory voices—a shift from the solo lyric voice to a chorus—is among the most important aspects of Miłosz’s work. 

The poetic chorus is deployed not just to highlight the complexity of the modern world but also to search for morality, another of Miłosz’s recurrent themes. Nathan and Quinn claim that "Miłosz’s work is devoted to unmasking man’s fundamental duality; he wants to make his readers admit the contradictory nature of their own experience" because doing so "forces us to assert our preferences as preferences". That is, it forces readers to make conscious choices, which is the arena of morality. At times, Miłosz’s exploration of morality was explicit and concrete, such as when, in "The Captive Mind", he ponders the right way to respond to three Lithuanian women who were forcibly moved to a Russian communal farm and wrote to him for help, or when, in the poems "Campo Dei Fiori" and "A Poor Christian Looks at the Ghetto", he addresses survivor’s guilt and the morality of writing about another’s suffering.

Miłosz’s exploration of morality takes place in the context of history, and a confrontation with history is another of his important themes. The scholar Helen Vendler argued that "for Miłosz, the person is irrevocably a person in history, and the interchange between external event and the individual life is the matrix of poetry". Miłosz, who had experienced both Nazism and Stalinism, was particularly concerned with the notion of "historical necessity", which, in the twentieth century, was used to justify human suffering on a previously unheard-of scale. Yet Miłosz did not reject the concept entirely. Nathan and Quinn summarize Miłosz’s appraisal of historical necessity as it appears in his essay collection, "Views from San Francisco Bay": "Some species rise, others fall, as do human families, nations, and whole civilizations. There may well be an internal logic to these transformations, a logic that when viewed from sufficient distance has its own elegance, harmony, and grace. Our reason tempts us to be enthralled by this superhuman splendor; but when so enthralled we find it difficult to remember, except perhaps as an element in an abstract calculus, the millions of individuals, the millions upon millions, who unwillingly paid for this splendor with pain and blood".

Miłosz’s willingness to accept a form of logic in history points to another recurrent aspect of his writing: his capacity for wonder, amazement, and, ultimately, faith—not always religious in a traditional sense, but "faith in the objective reality of a world to be known by the human mind but not constituted by that mind". At other times, however, Miłosz was more explicitly religious in his work. According to scholar and translator Michael Parker, "crucial to any understanding of Miłosz’s work is his complex relationship to Catholicism". His writing is filled with allusions to Christian figures, symbols, and theological ideas, although Miłosz himself was closer to Gnosticism, or what he called Manichaeism, in his personal beliefs, viewing the universe as ruled by an evil whose influence human beings must try to escape. From this perspective, "he can at once admit that the world is ruled by necessity, by evil, and yet still find hope and sustenance in the beauty of the world. History reveals the pointlessness of human striving, the instability of human things; but time also is the moving image of eternity". According to Hass, this viewpoint left Miłosz "with the task of those heretical Christians…to suffer time, to contemplate being, and to live in the hope of the redemption of the world".

Miłosz had numerous literary and intellectual influences, although scholars of his work—and Miłosz himself, in his writings—have identified the following as significant: Oscar Miłosz (who inspired Miłosz’s interest in the metaphysical) and, through him, Emanuel Swedenborg; Lev Shestov; Simone Weil (whose work Miłosz translated into Polish); Fyodor Dostoevsky; William Blake (whose concept of "Ulro" Miłosz borrowed for his book "The Land of Ulro"), and T.S. Eliot.












</doc>
<doc id="6543" url="https://en.wikipedia.org/wiki?curid=6543" title="Carnivore">
Carnivore

A carnivore , meaning "meat eater" (Latin, "caro", genitive "carnis", meaning "meat" or "flesh" and "vorare" meaning "to devour"), is an organism that derives its energy and nutrient requirements from a diet consisting mainly or exclusively of animal tissue, whether through predation or scavenging. Animals that depend solely on animal flesh for their nutrient requirements are called obligate carnivores while those that also consume non-animal food are called facultative carnivores. Omnivores also consume both animal and non-animal food, and, apart from the more general definition, there is no clearly defined ratio of plant to animal material that would distinguish a facultative carnivore from an omnivore. A carnivore at the top of the food chain, not preyed upon by other animals, is termed an apex predator.

"Carnivore" also may refer to the mammalian order Carnivora, but this is somewhat misleading: many, but not all, Carnivora are meat eaters, and even fewer are true obligate carnivores (see below). For example, while the Arctic polar bear eats meat almost exclusively (more than 90% of its diet is meat), most species of bears are actually omnivorous, and the giant panda is exclusively herbivorous. There are also many carnivorous species that are not members of Carnivora.

Outside the animal kingdom, there are several genera containing carnivorous plants (predominantly insectivores) and several phyla containing carnivorous fungi (preying mostly on microscopic invertebrates such as nematodes, amoebae and springtails).

Carnivores are sometimes characterized by their type of prey. For example, animals that eat mainly insects and similar invertebrates are called insectivores, while those that eat mainly fish are called piscivores. The first tetrapods, or land-dwelling vertebrates, were piscivorous amphibians known as labyrinthodonts. They gave rise to insectivorous vertebrates and, later, to predators of other tetrapods.

Carnivores may alternatively be classified according to the percentage of meat in their diet. The diet of a hypercarnivore consists of more than 70% meat, that of a mesocarnivore 30–70%, and that of a hypocarnivore less than 30%, with the balance consisting of non-animal foods such as fruits, other plant material, or fungi.

Obligate or "true" carnivores are those whose diet requires nutrients found only in animal flesh. While obligate carnivores might be able to ingest small amounts of plant matter, they lack the necessary physiology required to digest it. In fact, some obligate carnivorous mammals will only ingest vegetation for the sole purpose of its use as an emetic, to self-induce vomiting of the vegetation along with the other food it had ingested that upset its stomach.

Obligate carnivores include the axolotl, which consumes mainly worms and larvae in its environment, but if necessary will consume algae, as well as all felids (including the domestic cat) which require a diet of primarily animal flesh and organs. Specifically, cats have high protein requirements and their metabolisms appear unable to synthesize essential nutrients such as retinol, arginine, taurine, and arachidonic acid; thus, in nature, they must consume flesh to supply these nutrients.

Characteristics commonly associated with carnivores include strength, speed, and keen senses for hunting, as well as teeth and claws for capturing and tearing prey. However, some carnivores do not hunt and are scavengers, lacking the physical characteristics to bring down prey; in addition, most hunting carnivores will scavenge when the opportunity arises. Carnivores have comparatively short digestive systems, as they are not required to break down the tough cellulose found in plants.

Many hunting animals have evolved eyes facing forward, enabling depth perception. This is almost universal among mammalian predators, while most reptile and amphibian predators have eyes facing sideways.

"Predation" (the eating of one living creature by another for nutrition) predates the rise of commonly recognized carnivores by hundreds of millions (perhaps billions) of years. The earliest predators were microbial organisms, which engulfed or grazed on others. Because the fossil record is poor, these first predators could date back anywhere between 1 and over 2.7 Gya (billion years ago). The rise of eukaryotic cells at around 2.7 Gya, the rise of multicellular organisms at about 2 Gya, and the rise of mobile predators (around 600 Mya – 2 Gya, probably around 1 Gya) have all been attributed to early predatory behavior, and many very early remains show evidence of boreholes or other markings attributed to small predator species.

Among more familiar species, the first vertebrate carnivores were fish, and then amphibians that moved on to land. Early tetrapods were large amphibious piscivores. Some scientists assert that "Dimetrodon" "was the first terrestrial vertebrate to develop the curved, serrated teeth that enable a predator to eat prey much larger than itself." While amphibians continued to feed on fish and later insects, reptiles began exploring two new food types: tetrapods (carnivory) and then plants (herbivory). Carnivory was a natural transition from insectivory for medium and large tetrapods, requiring minimal adaptation; in contrast, a complex set of adaptations was necessary for feeding on highly fibrous plant materials.

In the Mesozoic, some theropod dinosaurs such as "Tyrannosaurus rex" were probably obligate carnivores. Though the theropods were the larger carnivores, several carnivorous mammal groups were already present. Most notable are the gobiconodontids, the triconodontid "Jugulator", the deltatheroideans and "Cimolestes". Many of these, such as "Repenomamus", "Jugulator" and "Cimolestes", were among the largest mammals in their faunal assemblages, capable of attacking dinosaurs.

In the early-to-mid-Cenozoic, the dominant predator forms were mammals: hyaenodonts, oxyaenids, entelodonts, ptolemaiidans, arctocyonids and mesonychians, representing a great diversity of eutherian carnivores in the northern continents and Africa. In South America, sparassodonts were dominant, while Australia saw the presence of several marsupial predators, such as the dasyuromorphs and thylacoleonids. From the Miocene to the present, the dominant carnivorous mammals have been carnivoramorphs.

Most carnivorous mammals, from dogs to "Deltatheridium", share several dental adaptations, such as carnassialiforme teeth, long canines and even similar tooth replacement patterns. Most aberrant are thylacoleonids, with a diprodontan dentition completely unlike that of any other mammal; and eutriconodonts like gobioconodontids and "Jugulator", with a three-cusp anatomy which nevertheless functioned similarly to carnassials.




</doc>
<doc id="6546" url="https://en.wikipedia.org/wiki?curid=6546" title="Celts">
Celts

The Celts (, see pronunciation of "Celt" for different usages) are an Indo-European ethnolinguistic group of Europe identified by their use of Celtic languages and cultural similarities. The history of pre-Celtic Europe and the exact relationship between ethnic, linguistic and cultural factors in the Celtic world remains uncertain and controversial. The exact geographic spread of the ancient Celts is disputed; in particular, the ways in which the Iron Age inhabitants of Great Britain and Ireland should be regarded as Celts have become a subject of controversy. According to one theory, the common root of the Celtic languages, the Proto-Celtic language, arose in the Late Bronze Age Urnfield culture of Central Europe, which flourished from around 1200 BC. 

According to a theory proposed in the 19th century, the first people to adopt cultural characteristics regarded as Celtic were the people of the Iron Age Hallstatt culture in central Europe (c. 800–450 BC), named for the rich grave finds in Hallstatt, Austria. Thus this area is sometimes called the "Celtic homeland". By or during the later La Tène period (c. 450 BC to the Roman conquest), this Celtic culture was supposed to have expanded by trans-cultural diffusion or migration to the British Isles (Insular Celts), France and the Low Countries (Gauls), Bohemia, Poland and much of Central Europe, the Iberian Peninsula (Celtiberians, Celtici, Lusitanians and Gallaeci) and northern Italy (Golasecca culture and Cisalpine Gauls) and, following the Celtic settlement of Eastern Europe beginning in 279 BC, as far east as central Anatolia (Galatians) in modern-day Turkey.

The earliest undisputed direct examples of a Celtic language are the Lepontic inscriptions beginning in the 6th century BC. Continental Celtic languages are attested almost exclusively through inscriptions and place-names. Insular Celtic languages are attested beginning around the 4th century in Ogham inscriptions, although they were clearly being spoken much earlier. Celtic literary tradition begins with Old Irish texts around the 8th century CE. Coherent texts of Early Irish literature, such as the "Táin Bó Cúailnge" ("Cattle Raid of Cooley"), survive in 12th-century recensions.

By the mid-1st millennium, with the expansion of the Roman Empire and migrating Germanic tribes, Celtic culture and Insular Celtic languages had become restricted to Ireland, the western and northern parts of Great Britain (Wales, Scotland, and Cornwall), the Isle of Man, and Brittany. Between the 5th and 8th centuries, the Celtic-speaking communities in these Atlantic regions emerged as a reasonably cohesive cultural entity. They had a common linguistic, religious and artistic heritage that distinguished them from the culture of the surrounding polities. By the 6th century, however, the Continental Celtic languages were no longer in wide use.

Insular Celtic culture diversified into that of the Gaels (Irish, Scottish and Manx) and the Celtic Britons (Welsh, Cornish, and Bretons) of the medieval and modern periods. A modern Celtic identity was constructed as part of the Romanticist Celtic Revival in Great Britain, Ireland, and other European territories, such as Portugal and Spanish Galicia. Today, Irish, Scottish Gaelic, Welsh, and Breton are still spoken in parts of their historical territories, and Cornish and Manx are undergoing a revival.

The first recorded use of the name of Celts – as ("Keltoi") – to refer to an ethnic group was by Hecataeus of Miletus, the Greek geographer, in 517 BC, when writing about a people living near Massilia (modern Marseille). In the fifth century BC, Herodotus referred to "Keltoi" living around the head of the Danube and also in the far west of Europe. The etymology of the term "Keltoi" is unclear. Possible roots include Indo-European *"kʲel" 'to hide' (present also in Old Irish "ceilid"), IE *"kʲel" 'to heat' or *"kel" 'to impel'. Several authors have supposed it to be Celtic in origin, while others view it as a name coined by Greeks. Linguist Patrizia De Bernardo Stempel falls in the latter group, and suggests the meaning "the tall ones".

In the 1st century BC, Julius Caesar reported that the people known to the Romans as Gauls () called themselves Celts, which suggests that even if the name "Keltoi" was bestowed by the Greeks, it had been adopted to some extent as a collective name by the tribes of Gaul. The geographer Strabo, writing about Gaul towards the end of the first century BC, refers to the "race which is now called both Gallic and Galatic," though he also uses the term Celtica as a synonym for Gaul, which is separated from Iberia by the Pyrenees. Yet he reports Celtic peoples in Iberia, and also uses the ethnic names Celtiberi and Celtici for peoples there, as distinct from Lusitani and Iberi. Pliny the Elder cited the use of Celtici in Lusitania as a tribal surname, which epigraphic findings have confirmed.

Latin Gallus (pl. "Galli") might stem from a Celtic ethnic or tribal name originally, perhaps one borrowed into Latin during the Celtic expansions into Italy during the early fifth century BC. Its root may be the Proto-Celtic "*galno", meaning "power, strength", hence Old Irish "gal" "boldness, ferocity" and Welsh "gallu" "to be able, power". The tribal names of Gallaeci and the Greek Γαλάται ("Galatai", Latinized "Galatae"; see the region Galatia in Anatolia) most probably have the same origin. The suffix "-atai" might be an Ancient Greek inflection. Classical writers did not apply the terms ("Keltoi") or "Celtae" to the inhabitants of Britain or Ireland, which has led to some scholars preferring not to use the term for the Iron Age inhabitants of those islands.

Celt is a modern English word, first attested in 1707, in the writing of Edward Lhuyd, whose work, along with that of other late 17th-century scholars, brought academic attention to the languages and history of the early Celtic inhabitants of Great Britain. The English form Gaul (first recorded in the 17th century) and Gaulish come from the French "Gaule" and "Gaulois", a borrowing from Frankish "*Walholant", "Land of foreigners or Romans" (see Gaul: Name), the root of which is Proto-Germanic "*walha-", "foreigner, Roman, Celt", whence the English word Welsh (Old English "wælisċ" < *"walhiska-"), South German "", meaning "Celtic speaker", "French speaker" or "Italian speaker" in different contexts, and Old Norse "valskr", pl. "valir", "Gaulish, French"). Proto-Germanic "*walha" is derived ultimately from the name of the Volcae, a Celtic tribe who lived first in the south of Germany and in central Europe and then migrated to Gaul. This means that English Gaul, despite its superficial similarity, is not actually derived from Latin "Gallia" (which should have produced "**Jaille" in French), though it does refer to the same ancient region.

Celtic refers to a family of languages and, more generally, means "of the Celts" or "in the style of the Celts". Several archaeological cultures are considered Celtic in nature, based on unique sets of artefacts. The link between language and artefact is aided by the presence of inscriptions. The relatively modern idea of an identifiable Celtic cultural identity or "Celticity" generally focuses on similarities among languages, works of art, and classical texts, and sometimes also among material artefacts, social organisation, homeland and mythology. Earlier theories held that these similarities suggest a common racial origin for the various Celtic peoples, but more recent theories hold that they reflect a common cultural and language heritage more than a genetic one. Celtic cultures seem to have been widely diverse, with the use of a Celtic language being the main thing they had in common.

Today, the term Celtic generally refers to the languages and respective cultures of Ireland, Scotland, Wales, Cornwall, the Isle of Man, and Brittany, also known as the Celtic nations. These are the regions where four Celtic languages are still spoken to some extent as mother tongues. The four are Irish Gaelic, Scottish Gaelic, Welsh, and Breton; plus two recent revivals, Cornish (one of the Brittonic languages) and Manx (one of the Goidelic languages). There are also attempts to reconstruct Cumbric, a Brittonic language from North West England and South West Scotland. Celtic regions of Continental Europe are those whose residents claim a Celtic heritage, but where no Celtic language has survived; these areas include the western Iberian Peninsula, i.e. Portugal and north-central Spain (Galicia, Asturias, Cantabria, Castile and León, Extremadura).

Continental Celts are the Celtic-speaking people of mainland Europe and Insular Celts are the Celtic-speaking peoples of the British and Irish islands and their descendants. The Celts of Brittany derive their language from migrating insular Celts, mainly from Wales and Cornwall, and so are grouped accordingly.

The Celtic languages form a branch of the larger Indo-European family. By the time speakers of Celtic languages entered history around 400 BC, they were already split into several language groups, and spread over much of Western continental Europe, the Iberian Peninsula, Ireland and Britain.
The Greek historian Ephorus of Cyme in Asia Minor, writing in the 4th century BC, believed that the Celts came from the islands off the mouth of the Rhine and were "driven from their homes by the frequency of wars and the violent rising of the sea".

Some scholars think that the Urnfield culture of western Middle Europe represents an origin for the Celts as a distinct cultural branch of the Indo-European family. This culture was preeminent in central Europe during the late Bronze Age, from circa 1200 BC until 700 BC, itself following the Unetice and Tumulus cultures. The Urnfield period saw a dramatic increase in population in the region, probably due to innovations in technology and agriculture.

The spread of iron-working led to the development of the Hallstatt culture directly from the Urnfield (c. 700 to 500 BC). Proto-Celtic, the latest common ancestor of all known Celtic languages, is considered by this school of thought to have been spoken at the time of the late Urnfield or early Hallstatt cultures, in the early 1st millennium BC. The spread of the Celtic languages to Iberia, Ireland and Britain would have occurred during the first half of the 1st millennium BC, the earliest chariot burials in Britain dating to c. 500 BC. Other scholars see Celtic languages as covering Britain and Ireland, and parts of the Continent, long before any evidence of "Celtic" culture is found in archaeology. Over the centuries the language(s) developed into the separate Celtiberian, Goidelic and Brittonic languages.

The Hallstatt culture was succeeded by the La Tène culture of central Europe, which was overrun by the Roman Empire, though traces of La Tène style are still to be seen in Gallo-Roman artefacts. In Britain and Ireland La Tène style in art survived precariously to re-emerge in Insular art. Early Irish literature casts light on the flavour and tradition of the heroic warrior elites who dominated Celtic societies. Celtic river-names are found in great numbers around the upper reaches of the Danube and Rhine, which led many Celtic scholars to place the ethnogenesis of the Celts in this area.

Diodorus Siculus and Strabo both suggest that the heartland of the people they called Celts was in southern France. The former says that the Gauls were to the north of the Celts, but that the Romans referred to both as Gauls (in linguistic terms the Gauls were certainly Celts). Before the discoveries at Hallstatt and La Tène, it was generally considered that the Celtic heartland was southern France, see Encyclopædia Britannica for 1813.

Myles Dillon and Nora Kershaw Chadwick accepted that "the Celtic settlement of the British Isles" might have to be dated to the Bell Beaker culture concluding that "There is no reason why so early a date for the coming of the Celts should be impossible". Martín Almagro Gorbea proposed the origins of the Celts could be traced back to the 3rd millennium BC, also seeking the initial roots in the Beaker period, thus offering the wide dispersion of the Celts throughout western Europe, as well as the variability of the different Celtic peoples, and the existence of ancestral traditions and ancient perspective. Using a multidisciplinary approach, Alberto J. Lorrio and Gonzalo Ruiz Zapatero reviewed and built on Almagro Gorbea's work to present a model for the origin of the Celtic archaeological groups in the Iberian Peninsula (Celtiberian, Vetton, Vaccean, the Castro culture of the northwest, Asturian-Cantabrian and Celtic of the southwest) and proposing a rethinking of the meaning of "Celtic" from a European perspective. More recently, John Koch and Barry Cunliffe have suggested that Celtic origins lie with the Atlantic Bronze Age, roughly contemporaneous with the Hallstatt culture but positioned considerably to the West, extending along the Atlantic coast of Europe.

Stephen Oppenheimer points out that the only written evidence that locates the Keltoi near the source of the Danube (i.e. in the Hallstatt region) is in the "Histories" of Herodotus. However, Oppenheimer shows that Herodotus seemed to believe the Danube rose near the Pyrenees, which would place the Ancient Celts in a region which is more in agreement with later classical writers and historians (i.e. in Gaul and the Iberian peninsula).

The Proto-Celtic language is usually dated to the Late Bronze Age. The earliest records of a Celtic language are the Lepontic inscriptions of Cisalpine Gaul (Northern Italy), the oldest of which predate the La Tène period. Other early inscriptions, appearing from the early La Tène period in the area of Massilia, are in Gaulish, which was written in the Greek alphabet until the Roman conquest. Celtiberian inscriptions, using their own Iberian script, appear later, after about 200 BC. Evidence of Insular Celtic is available only from about 400 AD, in the form of Primitive Irish Ogham inscriptions.

Besides epigraphical evidence, an important source of information on early Celtic is toponymy.

Historically many scholars postulated that there was genetic evidence of a common origin of the European Atlantic populations i.e.: Orkney Islands, Scottish, Irish, British, Bretons, Iberians (Basques, Galicians), Guanches and Berbers.

More recent genetic evidence does not support the notion of a significant genetic link between these populations, beyond the fact that they are all West Eurasians. Sardinian like Neolithic farmers did populate Britain (and all of Northern Europe) during the Neolithic period, however, recent genetics research has claimed that, between 2400BC and 2000BC, over 90% of British DNA was overturned by a North European population of ultimate Russian Steppe origin as part of an ongoing migration process that brought large amounts of Steppe DNA (including the R1b haplogroup) to North and West Europe. Modern autosomal genetic clustering is testament to this fact, as both modern and Iron Age British and Irish samples cluster genetically very closely with other North European populations, not Iberians, Galicians, Basques or those from the south of France. Such findings have largely put to rest the theory that there is a significant genetic link (beyond being Europeans) between the various 'Celtic' peoples in the Atlantic area.

Before the 19th century, scholars assumed that the original land of the Celts was west of the Rhine, more precisely in Gaul, because it was where Greek and Roman ancient sources, namely Caesar, located the Celts. This view was challenged by the 19th-century historian Marie Henri d'Arbois de Jubainville who placed the land of origin of the Celts east of the Rhine. Jubainville based his arguments on a phrase of Herodotus' that placed the Celts at the source of the Danube, and argued that Herodotus had meant to place the Celtic homeland in southern Germany.
The finding of the prehistoric cemetery of Hallstat in 1846 by Johan Ramsauer and the finding of the archaeological site of La Tène by Hansli Kopp in 1857 drew attention to this area.

The concept that the Hallstatt and La Tène cultures could be seen not just as chronological periods but as "Culture Groups", entities composed of people of the same ethnicity and language, had started to grow by the end of the 19th century. At the beginning of the 20th century the belief that these "Culture Groups" could be thought of in racial or ethnic terms was strongly held by Gordon Childe whose theory was influenced by the writings of Gustaf Kossinna. As the 20th century progressed, the racial ethnic interpretation of La Tène culture became much more strongly rooted, and any findings of La Tène culture and flat inhumation cemeteries were directly associated with the Celts and the Celtic language.
The Iron Age Hallstatt (c. 800–475 BC) and La Tène (c. 500–50 BC) cultures are typically associated with Proto-Celtic and Celtic culture.

In various academic disciplines the Celts were considered a Central European Iron Age phenomenon, through the cultures of Hallstatt and La Tène. However, archaeological finds from the Halstatt and La Tène culture were rare in the Iberian Peninsula, in southwestern France, northern and western Britain, southern Ireland and Galatia and did not provide enough evidence for a cultural scenario comparable to that of Central Europe. It is considered equally difficult to maintain that the origin of the Peninsular Celts can be linked to the preceding Urnfield culture. This has resulted in a more recent approach that introduces a 'proto-Celtic' substratum and a process of Celticisation, having its initial roots in the Bronze Age Bell Beaker culture.

The La Tène culture developed and flourished during the late Iron Age (from 450 BC to the Roman conquest in the 1st century BC) in eastern France, Switzerland, Austria, southwest Germany, the Czech Republic, Slovakia and Hungary. It developed out of the Hallstatt culture without any definite cultural break, under the impetus of considerable Mediterranean influence from Greek, and later Etruscan civilisations. A shift of settlement centres took place in the 4th century.

The western La Tène culture corresponds to historical Celtic Gaul. Whether this means that the whole of La Tène culture can be attributed to a unified Celtic people is difficult to assess; archaeologists have repeatedly concluded that language, material culture, and political affiliation do not necessarily run parallel. Frey notes that in the 5th century, "burial customs in the Celtic world were not uniform; rather, localised groups had their own beliefs, which, in consequence, also gave rise to distinct artistic expressions". Thus, while the La Tène culture is certainly associated with the Gauls, the presence of La Tène artefacts may be due to cultural contact and does not imply the permanent presence of Celtic speakers.

Polybius published a history of Rome about 150 BC in which he describes the Gauls of Italy and their conflict with Rome. Pausanias in the 2nd century AD says that the Gauls "originally called Celts", "live on the remotest region of Europe on the coast of an enormous tidal sea". Posidonius described the southern Gauls about 100 BC. Though his original work is lost it was used by later writers such as Strabo. The latter, writing in the early 1st century AD, deals with Britain and Gaul as well as Hispania, Italy and Galatia. Caesar wrote extensively about his Gallic Wars in 58–51 BC. Diodorus Siculus wrote about the Celts of Gaul and Britain in his 1st-century history.

The Romans knew the Celts then living in what became present-day France as Gauls. The territory of these peoples probably included the Low Countries, the Alps and present-day northern Italy. Julius Caesar in his "Gallic Wars" described the 1st-century BC descendants of those Gauls.

Eastern Gaul became the centre of the western La Tène culture. In later Iron Age Gaul, the social organisation resembled that of the Romans, with large towns. From the 3rd century BC the Gauls adopted coinage. Texts with Greek characters from southern Gaul have survived from the 2nd century BC.

Greek traders founded Massalia about 600 BC, with some objects (mostly drinking ceramics) being traded up the Rhone valley. But trade became disrupted soon after 500 BC and re-oriented over the Alps to the Po valley in the Italian peninsula. The Romans arrived in the Rhone valley in the 2nd century BC and encountered a mostly Celtic-speaking Gaul. Rome wanted land communications with its Iberian provinces and fought a major battle with the Saluvii at Entremont in 124–123 BC. Gradually Roman control extended, and the Roman Province of Gallia Transalpina developed along the Mediterranean coast. The Romans knew the remainder of Gaul as Gallia Comata – "Hairy Gaul".

In 58 BC the Helvetii planned to migrate westward but Julius Caesar forced them back. He then became involved in fighting the various tribes in Gaul, and by 55 BC had overrun most of Gaul. In 52 BC Vercingetorix led a revolt against the Roman occupation but was defeated at the Siege of Alesia and surrendered.

Following the Gallic Wars of 58–51 BC, Caesar's "Celtica" formed the main part of Roman Gaul, becoming the province of Gallia Lugdunensis. This territory of the Celtic tribes was bounded on the south by the Garonne and on the north by the Seine and the Marne. The Romans attached large swathes of this region to neighboring provinces Belgica and Aquitania, particularly under Augustus.

Place- and personal-name analysis and inscriptions suggest that the Gaulish Celtic language was spoken over most of what is now France.

Until the end of the 19th century, traditional scholarship dealing with the Celts did acknowledge their presence in the Iberian Peninsula as a material culture relatable to the Hallstatt and La Tène cultures. However, since according to the definition of the Iron Age in the 19th century Celtic populations were supposedly rare in Iberia and did not provide a cultural scenario that could easily be linked to that of Central Europe, the presence of Celtic culture in that region was generally not fully recognised. Modern scholarship, however, has clearly proven that Celtic presence and influences were most substantial in what is today Spain and Portugal (with perhaps the highest settlement saturation in Western Europe), particularly in the central, western and northern regions.

In addition to Gauls infiltrating from the north of the Pyrenees, the Roman and Greek sources mention Celtic populations in three parts of the Iberian Peninsula: the eastern part of the "Meseta" (inhabited by the Celtiberians), the southwest (Celtici, in modern-day Alentejo) and the northwest (Gallaecia and Asturias). A modern scholarly review found several archaeological groups of Celts in Spain:

The origins of the Celtiberians might provide a key to understanding the Celticisation process in the rest of the Peninsula. The process of Celticisation of the southwestern area of the peninsula by the Keltoi and of the northwestern area is, however, not a simple Celtiberian question. Recent investigations about the Callaici and Bracari in northwestern Portugal are providing new approaches to understanding Celtic culture (language, art and religion) in western Iberia.

John T. Koch of Aberystwyth University suggested that Tartessian inscriptions of the 8th century BC might be classified as Celtic. This would mean that Tartessian is the earliest attested trace of Celtic by a margin of more than a century.

The Canegrate culture represented the first migratory wave of the proto-Celtic population from the northwest part of the Alps that, through the Alpine passes, had already penetrated and settled in the western Po valley between Lake Maggiore and Lake Como (Scamozzina culture). It has also been proposed that a more ancient proto-Celtic presence can be traced back to the beginning of the Middle Bronze Age, when North Westwern Italy appears closely linked regarding the production of bronze artefacts, including ornaments, to the western groups of the Tumulus culture. La Tène cultural material appeared over a large area of mainland Italy, the southernmost example being the Celtic helmet from Canosa di Puglia.

Italy is home to Lepontic, the oldest attested Celtic language (from the 6th century BC). Anciently spoken in Switzerland and in Northern-Central Italy, from the Alps to Umbria. According to the "Recueil des Inscriptions Gauloises", more than 760 Gaulish inscriptions have been found throughout present-day France – with the notable exception of Aquitaine – and in Italy, which testifies the importance of Celtic heritage in the peninsula.

In 391 BC, Celts "who had their homes beyond the Alps streamed through the passes in great strength and seized the territory that lay between the Apennine mountains and the Alps" according to Diodorus Siculus. The Po Valley and the rest of northern Italy (known to the Romans as Cisalpine Gaul) was inhabited by Celtic-speakers who founded cities such as Milan. Later the Roman army was routed at the battle of Allia and Rome was sacked in 390 BC by the Senones.

At the battle of Telamon in 225 BC, a large Celtic army was trapped between two Roman forces and crushed.

The defeat of the combined Samnite, Celtic and Etruscan alliance by the Romans in the Third Samnite War sounded the beginning of the end of the Celtic domination in mainland Europe, but it was not until 192 BC that the Roman armies conquered the last remaining independent Celtic kingdoms in Italy.

The Celts also expanded down the Danube river and its tributaries. One of the most influential tribes, the Scordisci, had established their capital at Singidunum in the 3rd century BC, which is present-day Belgrade, Serbia. The concentration of hill-forts and cemeteries shows a density of population in the Tisza valley of modern-day Vojvodina, Serbia, Hungary and into Ukraine. Expansion into Romania was however blocked by the Dacians.

The Serdi were a Celtic tribe inhabiting Thrace. They were located around and founded Serdika (, , ), now Sofia in Bulgaria, which reflects their ethnonym. They would have established themselves in this area during the Celtic migrations at the end of the 4th century BC, though there is no evidence for their existence before the 1st century BC. "Serdi" are among traditional tribal names reported into the Roman era. They were gradually Thracianized over the centuries but retained their Celtic character in material culture up to a late date. According to other sources they may have been simply of Thracian origin, according to others they may have become of mixed Thraco-Celtic origin. Further south, Celts settled in Thrace (Bulgaria), which they ruled for over a century, and Anatolia, where they settled as the Galatians "(see also: Gallic Invasion of Greece)". Despite their geographical isolation from the rest of the Celtic world, the Galatians maintained their Celtic language for at least 700 years. St Jerome, who visited Ancyra (modern-day Ankara) in 373 AD, likened their language to that of the Treveri of northern Gaul.

For Venceslas Kruta, Galatia in central Turkey was an area of dense Celtic settlement.

The Boii tribe gave their name to Bohemia, Bologna and possibly Bavaria, and Celtic artefacts and cemeteries have been discovered further east in what is now Poland and Slovakia. A Celtic coin (Biatec) from Bratislava's mint was displayed on the old Slovak 5-crown coin.

As there is no archaeological evidence for large-scale invasions in some of the other areas, one current school of thought holds that Celtic language and culture spread to those areas by contact rather than invasion. However, the Celtic invasions of Italy and the expedition in Greece and western Anatolia, are well documented in Greek and Latin history.

There are records of Celtic mercenaries in Egypt serving the Ptolemies. Thousands were employed in 283–246 BC and they were also in service around 186 BC. They attempted to overthrow Ptolemy II.

All Celtic languages extant today belong to the Insular Celtic languages, derived from the Celtic languages spoken in Iron Age Britain and Ireland. They were separated into a Goidelic and a Brythonic branch from an early period.

Linguists have been arguing for many years whether a Celtic language came to Britain and Ireland and then split or whether there were two separate "invasions". The older view of prehistorians was that the Celtic influence in the British Isles was the result of successive invasions from the European continent by diverse Celtic-speaking peoples over the course of several centuries, accounting for the P-Celtic vs. Q-Celtic isogloss. This view has been challenged by the hypothesis that the Celtic languages of the British Isles form a phylogenetic Insular Celtic dialect group.

In the 19th and 20th centuries, scholars commonly dated the "arrival" of Celtic culture in Britain (via an invasion model) to the 6th century BC, corresponding to archaeological evidence of Hallstatt influence and the appearance of chariot burials in what is now England. Some Iron Age migration does seem to have occurred but the nature of the interactions with the indigenous populations of the isles is unknown. According to this model, by about the 6th century (Sub-Roman Britain), most of the inhabitants of the Isles were speaking Celtic languages of either the Goidelic or the Brythonic branch. Since the late 20th century, a new model has emerged (championed by archaeologists such as Barry Cunliffe and Celtic historians such as John T. Koch) which places the emergence of Celtic culture in Britain much earlier, in the Bronze Age, and credits its spread not to invasion, but due to a gradual emergence "in situ" out of Proto-Indo-European culture (perhaps introduced to the region by the Bell Beaker People, and enabled by an extensive network of contacts that existed between the peoples of Britain and Ireland and those of the Atlantic seaboard.

Classical writers did not apply the terms ("Keltoi") or "Celtae" to the inhabitants of Britain or Ireland, leading a number of scholars to question the use of the term Celt to describe the Iron Age inhabitants of those islands. The first historical account of the islands of Britain and Ireland was by Pytheas, a Greek from the city of Massalia, who around 310-306 BC, sailed around what he called the "Pretannikai nesoi", which can be translated as the "Pretannic Isles". In general, classical writers referred to the inhabitants of Britain as Pretannoi or Britanni.
Strabo, writing in the Roman era, clearly distinguished between the Celts and Britons.

Under Caesar the Romans conquered Celtic Gaul, and from Claudius onward the Roman empire absorbed parts of Britain. Roman local government of these regions closely mirrored pre-Roman tribal boundaries, and archaeological finds suggest native involvement in local government.

The native peoples under Roman rule became Romanised and keen to adopt Roman ways. Celtic art had already incorporated classical influences, and surviving Gallo-Roman pieces interpret classical subjects or keep faith with old traditions despite a Roman overlay.

The Roman occupation of Gaul, and to a lesser extent of Britain, led to Roman-Celtic syncretism. In the case of the continental Celts, this eventually resulted in a language shift to Vulgar Latin, while the Insular Celts retained their language.

There was also considerable cultural influence exerted by Gaul on Rome, particularly in military matters and horsemanship, as the Gauls often served in the Roman cavalry. The Romans adopted the Celtic cavalry sword, the spatha, and Epona, the Celtic horse goddess.

To the extent that sources are available, they depict a pre-Christian Iron Age Celtic social structure based formally on class and kingship, although this may only have been a particular late phase of organization in Celtic societies. Patron-client relationships similar to those of Roman society are also described by Caesar and others in the Gaul of the 1st century BC.

In the main, the evidence is of tribes being led by kings, although some argue that there is also evidence of oligarchical republican forms of government eventually emerging in areas which had close contact with Rome. Most descriptions of Celtic societies portray them as being divided into three groups: a warrior aristocracy; an intellectual class including professions such as druid, poet, and jurist; and everyone else. In historical times, the offices of high and low kings in Ireland and Scotland were filled by election under the system of tanistry, which eventually came into conflict with the feudal principle of primogeniture in which succession goes to the first-born son.

Little is known of family structure among the Celts. Patterns of settlement varied from decentralised to urban. The popular stereotype of non-urbanised societies settled in hillforts and duns, drawn from Britain and Ireland (there are about 3,000 hill forts known in Britain) contrasts with the urban settlements present in the core Hallstatt and La Tène areas, with the many significant "oppida" of Gaul late in the first millennium BC, and with the towns of Gallia Cisalpina.

Slavery, as practised by the Celts, was very likely similar to the better documented practice in ancient Greece and Rome. Slaves were acquired from war, raids, and penal and debt servitude. Slavery was hereditary, though manumission was possible. The Old Irish and Welsh words for 'slave', "cacht" and "caeth" respectively, are cognate with Latin "captus" 'captive' suggesting that the slave trade was an early means of contact between Latin and Celtic societies. In the Middle Ages, slavery was especially prevalent in the Celtic countries. Manumissions were discouraged by law and the word for "female slave", "cumal", was used as a general unit of value in Ireland.

Archaeological evidence suggests that the pre-Roman Celtic societies were linked to the network of overland trade routes that spanned Eurasia. Archaeologists have discovered large prehistoric trackways crossing bogs in Ireland and Germany. Due to their substantial nature, these are believed to have been created for wheeled transport as part of an extensive roadway system that facilitated trade. The territory held by the Celts contained tin, lead, iron, silver and gold. Celtic smiths and metalworkers created weapons and jewellery for international trade, particularly with the Romans.

The myth that the Celtic monetary system consisted of wholly barter is a common one, but is in part false. The monetary system was complex and is still not understood (much like the late Roman coinages), and due to the absence of large numbers of coin items, it is assumed that "proto-money" was used. This included bronze items made from the early La Tène period and onwards, which were often in the shape of axeheads, rings, or bells. Due to the large number of these present in some burials, it is thought they had a relatively high monetary value, and could be used for "day to day" purchases. Low-value coinages of potin, a bronze alloy with high tin content, were minted in most Celtic areas of the continent and in South-East Britain prior to the Roman conquest of these lands. Higher-value coinages, suitable for use in trade, were minted in gold, silver, and high-quality bronze. Gold coinage was much more common than silver coinage, despite being worth substantially more, as while there were around 100 mines in Southern Britain and Central France, silver was more rarely mined. This was due partly to the relative sparsity of mines and the amount of effort needed for extraction compared to the profit gained. As the Roman civilisation grew in importance and expanded its trade with the Celtic world, silver and bronze coinage became more common. This coincided with a major increase in gold production in Celtic areas to meet the Roman demand, due to the high value Romans put on the metal. The large number of gold mines in France is thought to be a major reason why Caesar invaded.

There are only very limited records from pre-Christian times written in Celtic languages. These are mostly inscriptions in the Roman and sometimes Greek alphabets. The Ogham script, an Early Medieval alphabet, was mostly used in early Christian times in Ireland and Scotland (but also in Wales and England), and was only used for ceremonial purposes such as inscriptions on gravestones. The available evidence is of a strong oral tradition, such as that preserved by bards in Ireland, and eventually recorded by monasteries. Celtic art also produced a great deal of intricate and beautiful metalwork, examples of which have been preserved by their distinctive burial rites.

In some regards the Atlantic Celts were conservative: for example, they still used chariots in combat long after they had been reduced to ceremonial roles by the Greeks and Romans. However, despite being outdated, Celtic chariot tactics were able to repel the invasion of Britain attempted by Julius Caesar.

According to Diodorus Siculus:

During the later Iron Age the Gauls generally wore long-sleeved shirts or tunics and long trousers (called "braccae" by the Romans). Clothes were made of wool or linen, with some silk being used by the rich. Cloaks were worn in the winter. Brooches and armlets were used, but the most famous item of jewellery was the torc, a neck collar of metal, sometimes gold. The horned Waterloo Helmet in the British Museum, which long set the standard for modern images of Celtic warriors, is in fact a unique survival, and may have been a piece for ceremonial rather than military wear.

Very few reliable sources exist regarding Celtic views on gender divisions and societal status, though some archaeological evidence does suggest that their views of gender roles may differ from contemporary and less egalitarian classical counterparts of the Roman era. There are some general indications from Iron Age burial sites in the Champagne and Bourgogne regions of Northeastern France suggesting that women may have had roles in combat during the earlier "La Tène" period. However, the evidence is far from conclusive. Examples of individuals buried with both female jewellery and weaponry have been identified, such as the Vix Grave, and there are questions about the gender of some skeletons that were buried with warrior assemblages. However, it has been suggested that "the weapons may indicate rank instead of masculinity".

Among the insular Celts, there is a greater amount of historic documentation to suggest warrior roles for women. In addition to commentary by Tacitus about Boudica, there are indications from later period histories that also suggest a more substantial role for "women as warriors", in symbolic if not actual roles.
Posidonius and Strabo described an island of women where men could not venture for fear of death, and where the women ripped each other apart. Other writers, such as Ammianus Marcellinus and Tacitus, mentioned Celtic women inciting, participating in, and leading battles. Posidonius' anthropological comments on the Celts had common themes, primarily primitivism, extreme ferocity, cruel sacrificial practices, and the strength and courage of their women.

Under Brehon Law, which was written down in early Medieval Ireland after conversion to Christianity, a woman had the right to divorce her husband and gain his property if he was unable to perform his marital duties due to impotence, obesity, homosexual inclination or preference for other women.

Classical literature records the views of the Celts' neighbours, though historians are not sure how much relation to reality these had. According to Aristotle, most "belligerent nations" were strongly influenced by their women, but the Celts were unusual because their men openly preferred male lovers ("Politics" II 1269b). H. D. Rankin in "Celts and the Classical World" notes that "Athenaeus echoes this comment (603a) and so does Ammianus (30.9). It seems to be the general opinion of antiquity." In book XIII of his "Deipnosophists", the Roman Greek rhetorician and grammarian Athenaeus, repeating assertions made by Diodorus Siculus in the 1st century BC (Bibliotheca historica 5:32), wrote that Celtic women were beautiful but that the men preferred to sleep together. Diodorus went further, stating that "the young men will offer themselves to strangers and are insulted if the offer is refused". Rankin argues that the ultimate source of these assertions is likely to be Posidonius and speculates that these authors may be recording male "bonding rituals".

The sexual freedom of women in Britain was noted by Cassius Dio:

There are instances recorded where women participated both in warfare and in kingship, although they were in the minority in these areas. Plutarch reports that Celtic women acted as ambassadors to avoid a war among Celts chiefdoms in the Po valley during the 4th century BC.

Celtic art is generally used by art historians to refer to art of the La Tène period across Europe, while the Early Medieval art of Britain and Ireland, that is what "Celtic art" evokes for much of the general public, is called Insular art in art history. Both styles absorbed considerable influences from non-Celtic sources, but retained a preference for geometrical decoration over figurative subjects, which are often extremely stylised when they do appear; narrative scenes only appear under outside influence. Energetic circular forms, triskeles and spirals are characteristic. Much of the surviving material is in precious metal, which no doubt gives a very unrepresentative picture, but apart from Pictish stones and the Insular high crosses, large monumental sculpture, even with decorative carving, is very rare; possibly it was originally common in wood. Celts were also able to create developed musical instruments such as the carnyces, these famous war trumpets used before the battle to frighten the enemy, as the best preserved found in Tintignac (Gaul) in 2004 and which were decorated with a boar head or a snake head.

The interlace patterns that are often regarded as typical of "Celtic art" were characteristic of the whole of the British Isles, a style referred to as Insular art, or Hiberno-Saxon art. This artistic style incorporated elements of La Tène, Late Roman, and, most importantly, animal Style II of Germanic Migration Period art. The style was taken up with great skill and enthusiasm by Celtic artists in metalwork and illuminated manuscripts. Equally, the forms used for the finest Insular art were all adopted from the Roman world: Gospel books like the Book of Kells and Book of Lindisfarne, chalices like the Ardagh Chalice and Derrynaflan Chalice, and penannular brooches like the Tara Brooch. These works are from the period of peak achievement of Insular art, which lasted from the 7th to the 9th centuries, before the Viking attacks sharply set back cultural life.

In contrast the less well known but often spectacular art of the richest earlier Continental Celts, before they were conquered by the Romans, often adopted elements of Roman, Greek and other "foreign" styles (and possibly used imported craftsmen) to decorate objects that were distinctively Celtic. After the Roman conquests, some Celtic elements remained in popular art, especially Ancient Roman pottery, of which Gaul was actually the largest producer, mostly in Italian styles, but also producing work in local taste, including figurines of deities and wares painted with animals and other subjects in highly formalised styles. Roman Britain also took more interest in enamel than most of the Empire, and its development of champlevé technique was probably important to the later Medieval art of the whole of Europe, of which the energy and freedom of Insular decoration was an important element. Rising nationalism brought Celtic revivals from the 19th century.

Tribal warfare appears to have been a regular feature of Celtic societies. While epic literature depicts this as more of a sport focused on raids and hunting rather than organised territorial conquest, the historical record is more of tribes using warfare to exert political control and harass rivals, for economic advantage, and in some instances to conquer territory.

The Celts were described by classical writers such as Strabo, Livy, Pausanias, and Florus as fighting like "wild beasts", and as hordes. Dionysius said that their Such descriptions have been challenged by contemporary historians.

Polybius (2.33) indicates that the principal Celtic weapon was a long bladed sword which was used for hacking edgewise rather than stabbing. Celtic warriors are described by Polybius and Plutarch as frequently having to cease fighting in order to straighten their sword blades. This claim has been questioned by some archaeologists, who note that Noric steel, steel produced in Celtic Noricum, was famous in the Roman Empire period and was used to equip the Roman military. However, Radomir Pleiner, in "The Celtic Sword" (1993) argues that "the metallographic evidence shows that Polybius was right up to a point", as around one third of surviving swords from the period might well have behaved as he describes.

Polybius also asserts that certain of the Celts fought naked, "The appearance of these naked warriors was a terrifying spectacle, for they were all men of splendid physique and in the prime of life." According to Livy, this was also true of the Celts of Asia Minor.

Celts had a reputation as head hunters. According to Paul Jacobsthal, "Amongst the Celts the human head was venerated above all else, since the head was to the Celt the soul, centre of the emotions as well as of life itself, a symbol of divinity and of the powers of the other-world." Arguments for a Celtic cult of the severed head include the many sculptured representations of severed heads in La Tène carvings, and the surviving Celtic mythology, which is full of stories of the severed heads of heroes and the saints who carry their own severed heads, right down to "Sir Gawain and the Green Knight", where the Green Knight picks up his own severed head after Gawain has struck it off, just as St. Denis carried his head to the top of Montmartre. Physical evidence exists for the ritual importance of the severed head at the religious centre at Roquepertuse (southern France), destroyed by the Romans in 124 BC, where stone pillars with prominent niches for displaying severed heads were found.

A further example of this regeneration after beheading lies in the tales of Connemara's St. Feichin, who after being beheaded by Viking pirates carried his head to the Holy Well on Omey Island and on dipping the head into the well placed it back upon his neck and was restored to full health.

Diodorus Siculus, in his 1st-century "History" had this to say about Celtic head-hunting:
In "Gods and Fighting Men", Lady Gregory's Celtic Revival translation of Irish mythology, heads of men killed in battle are described in the beginning of the story "The Fight with the Fir Bolgs" as pleasing to Macha, one aspect of the war goddess Morrigu.

Like other European Iron Age tribal societies, the Celts practised a polytheistic religion.
Many Celtic gods are known from texts and inscriptions from the Roman period.
Rites and sacrifices were carried out by priests known as druids. The Celts did not see their gods as having human shapes until late in the Iron Age. Celtic shrines were situated in remote areas such as hilltops, groves, and lakes.

Celtic religious patterns were regionally variable; however, some patterns of deity forms, and ways of worshipping these deities, appeared over a wide geographical and temporal range. The Celts worshipped both gods and goddesses. In general, Celtic gods were deities of particular skills, such as the many-skilled Lugh and Dagda, while goddesses were associated with natural features, particularly rivers (such as Boann, goddess of the River Boyne). This was not universal, however, as goddesses such as Brighid and The Morrígan were associated with both natural features (holy wells and the River Unius) and skills such as blacksmithing and healing.

Triplicity is a common theme in Celtic cosmology, and a number of deities were seen as threefold. This trait is exhibited by The Three Mothers, a group of goddesses worshipped by many Celtic tribes (with regional variations).

The Celts had hundreds of deities, some of which were unknown outside a single family or tribe, while others were popular enough to have a following that crossed lingual and cultural barriers. For instance, the Irish god Lugh, associated with storms, lightning, and culture, is seen in similar forms as Lugos in Gaul and Lleu in Wales. Similar patterns are also seen with the continental Celtic horse goddess Epona and what may well be her Irish and Welsh counterparts, Macha and Rhiannon, respectively.

Roman reports of the druids mention ceremonies being held in sacred groves. La Tène Celts built temples of varying size and shape, though they also maintained shrines at sacred trees and votive pools.

Druids fulfilled a variety of roles in Celtic religion, serving as priests and religious officiants, but also as judges, sacrificers, teachers, and lore-keepers. Druids organised and ran religious ceremonies, and they memorised and taught the calendar. Other classes of druids performed ceremonial sacrifices of crops and animals for the perceived benefit of the community.

The Coligny calendar, which was found in 1897 in Coligny, Ain, was engraved on a bronze tablet, preserved in 73 fragments, that originally was wide and high (Lambert p. 111). Based on the style of lettering and the accompanying objects, it probably dates to the end of the 2nd century. It is written in Latin inscriptional capitals, and is in the Gallic language. The restored tablet contains 16 vertical columns, with 62 months distributed over 5 years.

The French archaeologist J. Monard speculated that it was recorded by druids wishing to preserve their tradition of timekeeping in a time when the Julian calendar was imposed throughout the Roman Empire. However, the general form of the calendar suggests the public peg calendars (or "parapegmata") found throughout the Greek and Roman world.

The Roman invasion of Gaul brought a great deal of Celtic peoples into the Roman Empire. Roman culture had a profound effect on the Celtic tribes which came under the empire's control. Roman influence led to many changes in Celtic religion, the most noticeable of which was the weakening of the druid class, especially religiously; the druids were to eventually disappear altogether. Romano-Celtic deities also began to appear: these deities often had both Roman and Celtic attributes, combined the names of Roman and Celtic deities, and/or included couples with one Roman and one Celtic deity. Other changes included the adaptation of the Jupiter Column, a sacred column set up in many Celtic regions of the empire, primarily in northern and eastern Gaul. Another major change in religious practice was the use of stone monuments to represent gods and goddesses. The Celts had only created wooden idols (including monuments carved into trees, which were known as sacred poles) previously to Roman conquest.

While the regions under Roman rule adopted Christianity along with the rest of the Roman empire, unconquered areas of Ireland and Scotland began to move from Celtic polytheism to Christianity in the 5th century. Ireland was converted by missionaries from Britain, such as Saint Patrick. Later missionaries from Ireland were a major source of missionary work in Scotland, Anglo-Saxon parts of Britain, and central Europe (see Hiberno-Scottish mission). Celtic Christianity, the forms of Christianity that took hold in Britain and Ireland at this time, had for some centuries only limited and intermittent contact with Rome and continental Christianity, as well as some contacts with Coptic Christianity. Some elements of Celtic Christianity developed, or retained, features that made them distinct from the rest of Western Christianity, most famously their conservative method of calculating the date of Easter. In 664, the Synod of Whitby began to resolve these differences, mostly by adopting the current Roman practices, which the Gregorian Mission from Rome had introduced to Anglo-Saxon England.



Geography

Organisations


</doc>
<doc id="6547" url="https://en.wikipedia.org/wiki?curid=6547" title="Conductor">
Conductor

Conductor or conduction may refer to:






</doc>
<doc id="6548" url="https://en.wikipedia.org/wiki?curid=6548" title="Claude Monet">
Claude Monet

Oscar-Claude Monet (; ; 14 November 1840 – 5 December 1926) was a French painter, a founder of French Impressionist painting and the most consistent and prolific practitioner of the movement's philosophy of expressing one's perceptions before nature, especially as applied to plein air landscape painting. The term "Impressionism" is derived from the title of his painting "Impression, soleil levant" ("Impression, Sunrise"), which was exhibited in 1874 in the first of the independent exhibitions mounted by Monet and his associates as an alternative to the Salon de Paris.

Monet's ambition of documenting the French countryside led him to adopt a method of painting the same scene many times in order to capture the changing of light and the passing of the seasons. From 1883, Monet lived in Giverny, where he purchased a house and property and began a vast landscaping project which included lily ponds that would become the subjects of his best-known works. In 1899, he began painting the water lilies, first in vertical views with a Japanese bridge as a central feature and later in the series of large-scale paintings that was to occupy him continuously for the next 20 years of his life.

Claude Monet was born on 14 November 1840 on the fifth floor of 45 rue Laffitte, in the 9th arrondissement of Paris. He was the second son of Claude Adolphe Monet and Louise Justine Aubrée Monet, both of them second-generation Parisians. On 20 May 1841, he was baptized in the local parish church, Notre-Dame-de-Lorette, as Oscar-Claude, but his parents called him simply Oscar. (He signed his juvenilia "O. Monet".) Despite being baptized Catholic, Monet later became an atheist.

In 1845, his family moved to Le Havre in Normandy. His father wanted him to go into the family's ship-chandling and grocery business, but Monet wanted to become an artist. His mother was a singer, and supported Monet's desire for a career in art.

On 1 April 1851, Monet entered Le Havre secondary school of the arts. Locals knew him well for his charcoal caricatures, which he would sell for ten to twenty francs. Monet also undertook his first drawing lessons from Jacques-François Ochard, a former student of Jacques-Louis David. On the beaches of Normandy around 1856 he met fellow artist Eugène Boudin, who became his mentor and taught him to use oil paints. Boudin taught Monet "en plein air" (outdoor) techniques for painting. Both received the influence of Johan Barthold Jongkind.

On 28 January 1857, his mother died. At the age of sixteen, he left school and went to live with his widowed, childless aunt, Marie-Jeanne Lecadre.
When Monet traveled to Paris to visit the Louvre, he witnessed painters copying from the old masters. Having brought his paints and other tools with him, he would instead go and sit by a window and paint what he saw. Monet was in Paris for several years and met other young painters, including Édouard Manet and others who would become friends and fellow Impressionists.

After drawing a low ballot number in March 1861, Monet was drafted into the First Regiment of African Light Cavalry ("Chasseurs d'Afrique") in Algeria for a seven-year period of military service. His prosperous father could have purchased Monet's exemption from conscription but declined to do so when his son refused to give up painting. While in Algeria Monet did only a few sketches of casbah scenes, a single landscape, and several portraits of officers, all of which have been lost. In a "Le Temps" interview of 1900 however he commented that the light and vivid colours of North Africa "contained the germ of my future researches". After about a year of garrison duty in Algiers, Monet contracted typhoid fever and briefly went absent without leave. Following convalescence, Monet's aunt intervened to remove him from the army if he agreed to complete a course at an art school. It is possible that the Dutch painter Johan Barthold Jongkind, whom Monet knew, may have prompted his aunt on this matter.

Disillusioned with the traditional art taught at art schools, in 1862 Monet became a student of Charles Gleyre in Paris, where he met Pierre-Auguste Renoir, Frédéric Bazille and Alfred Sisley. Together they shared new approaches to art, painting the effects of light "en plein air" with broken colour and rapid brushstrokes, in what later came to be known as Impressionism.

In January 1865 Monet was working on a version of "Le déjeuner sur l'herbe", aiming to present it for hanging at the Salon, which had rejected Manet's "Le déjeuner sur l'herbe" two years earlier. Monet's painting was very large and could not be completed in time. (It was later cut up, with parts now in different galleries.) Monet submitted instead a painting of "Camille" or "The Woman in the Green Dress" ("La femme à la robe verte"), one of many works using his future wife, Camille Doncieux, as his model. Both this painting and a small landscape were hung. The following year Monet used Camille for his model in "Women in the Garden", and "On the Bank of the Seine, Bennecourt" in 1868. Camille became pregnant and gave birth to their first child, Jean, in 1867. Monet and Camille married on 28 June 1870, just before the outbreak of the Franco-Prussian War, and, after their excursion to London and Zaandam, they moved to Argenteuil, in December 1871. During this time Monet painted various works of modern life. He and Camille lived in poverty for most of this period. Following the successful exhibition of some maritime paintings, and the winning of a silver medal at Le Havre, Monet's paintings were seized by creditors, from whom they were bought back by a shipping merchant, Gaudibert, who was also a patron of Boudin.

From the late 1860s, Monet and other like-minded artists met with rejection from the conservative Académie des Beaux-Arts, which held its annual exhibition at the Salon de Paris. During the latter part of 1873, Monet, Pierre-Auguste Renoir, Camille Pissarro, and Alfred Sisley organized the (Anonymous Society of Painters, Sculptors, and Engravers) to exhibit their artworks independently. At their first exhibition, held in April 1874, Monet exhibited the work that was to give the group its lasting name. He was inspired by the style and subject matter of previous modern painters Camille Pissarro and Edouard Manet.

"Impression, Sunrise" was painted in 1872, depicting a Le Havre port landscape. From the painting's title the art critic Louis Leroy, in his review, "L'Exposition des Impressionnistes," which appeared in "Le Charivari", coined the term "Impressionism". It was intended as disparagement but the Impressionists appropriated the term for themselves.

After the outbreak of the Franco-Prussian War (19 July 1870), Monet and his family took refuge in England in September 1870, where he studied the works of John Constable and Joseph Mallord William Turner, both of whose landscapes would serve to inspire Monet's innovations in the study of colour. In the spring of 1871, Monet's works were refused authorisation for inclusion in the Royal Academy exhibition.

In May 1871, he left London to live in Zaandam, in the Netherlands, where he made twenty-five paintings (and the police suspected him of revolutionary activities). He also paid a first visit to nearby Amsterdam. In October or November 1871, he returned to France. From December 1871 to 1878 he lived at Argenteuil, a village on the right bank of the Seine river near Paris, and a popular Sunday-outing destination for Parisians, where he painted some of his best-known works. In 1873, Monet purchased a small boat equipped to be used as a floating studio. From the boat studio Monet painted landscapes and also portraits of Édouard Manet and his wife; Manet in turn depicted Monet painting aboard the boat, accompanied by Camille, in 1874. In 1874, he briefly returned to Holland.

The first Impressionist exhibition was held in 1874 at 35 boulevard des Capucines, Paris, from 15 April to 15 May. The primary purpose of the participants was not so much to promote a new style, but to free themselves from the constraints of the Salon de Paris. The exhibition, open to anyone prepared to pay 60 francs, gave artists the opportunity to show their work without the interference of a jury.

Renoir chaired the hanging committee and did most of the work himself, as others members failed to present themselves.

In addition to "" (pictured above), Monet presented four oil paintings and seven pastels. Among the paintings he displayed was "The Luncheon" (1868), which features Camille Doncieux and Jean Monet, and which had been rejected by the Paris Salon of 1870. Also in this exhibition was a painting titled "Boulevard des Capucines", a painting of the boulevard done from the photographer Nadar's apartment at no. 35. Monet painted the subject twice, and it is uncertain which of the two pictures, that now in the Pushkin Museum in Moscow, or that in the Nelson-Atkins Museum of Art in Kansas City, was the painting that appeared in the groundbreaking 1874 exhibition, though more recently the Moscow picture has been favoured. Altogether, 165 works were exhibited in the exhibition, including 4 oils, 2 pastels and 3 watercolours by Morisot; 6 oils and 1 pastel by Renoir; 10 works by Degas; 5 by Pissarro; 3 by Cézanne; and 3 by Guillaumin. Several works were on loan, including Cézanne's "Modern Olympia", Morisot's "Hide and Seek" (owned by Manet) and 2 landscapes by Sisley that had been purchased by Durand-Ruel.

The total attendance is estimated at 3500, and some works did sell, though some exhibitors had placed their prices too high. Pissarro was asking 1000 francs for "The Orchard" and Monet the same for "Impression: Sunrise", neither of which sold. Renoir failed to obtain the 500 francs he was asking for "La Loge", but later sold it for 450 francs to Père Martin, dealer and supporter of the group.

In 1876, Camille Monet became ill with tuberculosis. Their second son, Michel, was born on 17 March 1878. This second child weakened her already fading health. In the summer of that year, the family moved to the village of Vétheuil where they shared a house with the family of Ernest Hoschedé, a wealthy department store owner and patron of the arts. In 1878, Camille Monet was diagnosed with uterine cancer. She died on 5 September 1879 at the age of thirty-two.

Monet made a study in oils of his dead wife. Many years later, Monet confessed to his friend Georges Clemenceau that his need to analyse colours was both the joy and torment of his life. He explained,

I one day found myself looking at my beloved wife's dead face and just systematically noting the colours according to an automatic reflex!

John Berger describes the work as "a blizzard of white, grey, purplish paint ... a terrible blizzard of loss which will forever efface her features. In fact there can be very few death-bed paintings which have been so intensely felt or subjectively expressive."

After several difficult months following the death of Camille, Monet began to create some of his best paintings of the 19th century. During the early 1880s, Monet painted several groups of landscapes and seascapes in what he considered to be campaigns to document the French countryside. These began to evolve into series of pictures in which he documented the same scene many times in order to capture the changing of light and the passing of the seasons.

Monet's friend Ernest Hoschedé became bankrupt, and left in 1878 for Belgium. After the death of Camille Monet in September 1879, and while Monet continued to live in the house in Vétheuil, Alice Hoschedé helped Monet to raise his two sons, Jean and Michel. She took them to Paris to live alongside her own six children, Blanche (who married Jean Monet), Germaine, Suzanne, Marthe, Jean-Pierre, and Jacques. In the spring of 1880, Alice Hoschedé and all the children left Paris and rejoined Monet at Vétheuil. In 1881, all of them moved to Poissy, which Monet hated. In April 1883, looking out the window of the little train between Vernon and Gasny, he discovered Giverny in Normandy. Monet, Alice Hoschedé and the children moved to Vernon, then to the house in Giverny, where he planted a large garden and where he painted for much of the rest of his life. Following the death of her estranged husband, Monet married Alice Hoschedé in 1892.

Monet rented and eventually purchased a house and gardens in Giverny. At the beginning of May 1883, Monet and his large family rented the home and from a local landowner. The house was situated near the main road between the towns of Vernon and Gasny at Giverny. There was a barn that doubled as a painting studio, orchards and a small garden. The house was close enough to the local schools for the children to attend, and the surrounding landscape offered many suitable motifs for Monet's work.

The family worked and built up the gardens, and Monet's fortunes began to change for the better as his dealer, Paul Durand-Ruel, had increasing success in selling his paintings. By November 1890, Monet was prosperous enough to buy the house, the surrounding buildings and the land for his gardens. During the 1890s, Monet built a greenhouse and a second studio, a spacious building well lit with skylights.

Monet wrote daily instructions to his gardener, precise designs and layouts for plantings, and invoices for his floral purchases and his collection of botany books. As Monet's wealth grew, his garden evolved. He remained its architect, even after he hired seven gardeners.

Monet purchased additional land with a water meadow. In 1893 he began a vast landscaping project which included lily ponds that would become the subjects of his best-known works. White water lilies local to France were planted along with imported cultivars from South America and Egypt, resulting in a range of colours including yellow, blue and white lilies that turned pink with age. In 1899 he began painting the water lilies, first in vertical views with a Japanese bridge as a central feature, and later in the series of large-scale paintings that was to occupy him continuously for the next 20 years of his life. This scenery, with its alternating light and mirror-like reflections, became an integral part of his work. By the mid-1910s Monet had achieved

Monet's second wife, Alice, died in 1911, and his oldest son Jean, who had married Alice's daughter Blanche, Monet's particular favourite, died in 1914. After Alice died, Blanche looked after and cared for Monet. It was during this time that Monet began to develop the first signs of cataracts.

During World War I, in which his younger son Michel served and his friend and admirer Georges Clemenceau led the French nation, Monet painted a series of weeping willow trees as homage to the French fallen soldiers. In 1923, he underwent two operations to remove his cataracts. The paintings done while the cataracts affected his vision have a general reddish tone, which is characteristic of the vision of cataract victims. It may also be that after surgery he was able to see certain ultraviolet wavelengths of light that are normally excluded by the lens of the eye; this may have had an effect on the colours he perceived. After his operations he even repainted some of these paintings, with bluer water lilies than before.

Monet died of lung cancer on 5 December 1926 at the age of 86 and is buried in the Giverny church cemetery. Monet had insisted that the occasion be simple; thus only about fifty people attended the ceremony. At his funeral, his long-time friend Georges Clemenceau removed the black cloth draped over the coffin, stating, "No black for Monet!" and replaced it with a flower-patterned cloth.

His home, garden, and waterlily pond were bequeathed by his son Michel, his only heir, to the French Academy of Fine Arts (part of the Institut de France) in 1966. Through the "Fondation Claude Monet", the house and gardens were opened for visits in 1980, following restoration. In addition to souvenirs of Monet and other objects of his life, the house contains his collection of Japanese woodcut prints. The house and garden, along with the Museum of Impressionism, are major attractions in Giverny, which hosts tourists from all over the world.

Monet has been described as "the driving force behind Impressionism". Crucial to the art of the Impressionist painters was the understanding of the effects of light on the local colour of objects, and the effects of the juxtaposition of colours with each other. Monet's long career as a painter was spent in the pursuit of this aim.

In 1856, his chance meeting with Eugene Boudin, a painter of small beach scenes, opened his eyes to the possibility of plein-air painting. From that time, with a short interruption for military service, he dedicated himself to searching for new and improved methods of painterly expression. To this end, as a young man, he visited the Paris Salon and familiarised himself with the works of older painters, and made friends with other young artists. The five years that he spent at Argenteuil, spending much time on the River Seine in a little floating studio, were formative in his study of the effects of light and reflections. He began to think in terms of colours and shapes rather than scenes and objects. He used bright colours in dabs and dashes and squiggles of paint. Having rejected the academic teachings of Gleyre's studio, he freed himself from theory, saying "I like to paint as a bird sings."

In 1877 a series of paintings at St-Lazare Station had Monet looking at smoke and steam and the way that they affected colour and visibility, being sometimes opaque and sometimes translucent. He was to further use this study in the painting of the effects of mist and rain on the landscape. The study of the effects of atmosphere was to evolve into a number of series of paintings in which Monet repeatedly painted the same subject (such as his water lilies series) in different lights, at different hours of the day, and through the changes of weather and season. This process began in the 1880s and continued until the end of his life in 1926.

His first series exhibited as such was of Haystacks, painted from different points of view and at different times of the day. Fifteen of the paintings were exhibited at the Galerie Durand-Ruel in 1891. In 1892 he produced what is probably his best-known series, twenty-six views of "Rouen Cathedral". In these paintings Monet broke with painterly traditions by cropping the subject so that only a portion of the façade is seen on the canvas. The paintings do not focus on the grand Medieval building, but on the play of light and shade across its surface, transforming the solid masonry.

Other series include "Poplars", "Mornings on the Seine", and the "Water Lilies" that were painted on his property at Giverny. Between 1883 and 1908, Monet traveled to the Mediterranean, where he painted landmarks, landscapes, and seascapes, including a series of paintings in Venice. In London he painted four series: "the Houses of Parliament, London", "Charing Cross Bridge", "Waterloo Bridge", and "Views of Westminster Bridge". Helen Gardner writes:

In 2004, "London, the Parliament, Effects of Sun in the Fog (Londres, le Parlement, trouée de soleil dans le brouillard)" (1904), sold for US$20.1 million. In 2006, the journal "Proceedings of the Royal Society" published a paper providing evidence that these were painted in situ at St Thomas' Hospital over the river Thames.

"Falaises près de Dieppe (Cliffs near Dieppe)" has been stolen on two separate occasions: once in 1998 (in which the museum's curator was convicted of the theft and jailed for five years and two months along with two accomplices) and most recently in August 2007. It was recovered in June 2008.

Monet's "Le Pont du chemin de fer à Argenteuil", an 1873 painting of a railway bridge spanning the Seine near Paris, was bought by an anonymous telephone bidder for a record $41.4 million at Christie's auction in New York on 6 May 2008. The previous record for his painting stood at $36.5 million. Just a few weeks later, "Le bassin aux nymphéas" (from the water lilies series) sold at Christie's 24 June 2008 auction in London, lot 19, for £36,500,000 ($71,892,376.34) (hammer price) or £40,921,250 ($80,451,178) with fees, nearly doubling the record for the artist and representing one of the top 20 highest prices paid for a painting at the time.

In October 2013, Monet's paintings, "L'Eglise de Vetheuil" and "Le Bassin aux Nympheas", became subjects of a legal case in New York against NY-based Vilma Bautista, one-time aide to Imelda Marcos, wife of dictator Ferdinand Marcos, after she sold "Le Bassin aux Nympheas" for $32 million to a Swiss buyer. The said Monet paintings, along with two others, were acquired by Imelda during her husband's presidency and allegedly bought using the nation's funds. Bautista's lawyer claimed that the aide sold the painting for Imelda but did not have a chance to give her the money. The Philippine government seeks the return of the painting. "Le Bassin aux Nympheas", also known as "Japanese Footbridge over the Water-Lily Pond at Giverny", is part of Monet's famed Water Lilies series.




</doc>
<doc id="6552" url="https://en.wikipedia.org/wiki?curid=6552" title="Conectiva">
Conectiva

Conectiva was a company founded on August 28, 1995, in Curitiba, Paraná, Brazil, by a group of friends, among them Arnaldo Carvalho de Melo, who was a pioneer in the distribution of Linux and open source software in Brazilian Portuguese, Spanish and English for all of Latin America. Besides a customized Linux distribution for the Latin American market, Conectiva developed a series of products and additional services directed to meet the market demand for open source tools, including books, manuals, additional software like Linux Tools and embedded systems, OEM programs, applications port, training kits and the "Revista do Linux" Linux magazine. In addition, the company provided consulting services, training and technical support in all of Latin America through its own service centers and certified partners.

Conectiva also provided development, customization and professional services on a worldwide basis through its team of open source software engineers. Conectiva's development team had expertise in, amongst others, the following areas: Linux kernel development, high availability, device drivers, XFree86, network protocols, firewalling, clustering, performance analysis and optimisation, filesystems and resource management.

On 24 January 2005 it was announced that Mandrakesoft had acquired Conectiva for 1.79 million euro (2.3 million U.S. dollars at the time). On 7 April 2005 Mandrakesoft announced the decision to change the name of the parent company to Mandriva and their distribution name to Mandriva Linux, although the Brazilian operation would not change its name from Conectiva immediately.





</doc>
<doc id="6555" url="https://en.wikipedia.org/wiki?curid=6555" title="Carthage">
Carthage

Carthage (; , "", "New City"; ; , "Qarṭāj") was the center or capital city of the ancient Carthaginian civilization, on the eastern side of the Lake of Tunis in what is now the Tunis Governorate in Tunisia.

The city developed from a Phoenician colony into the capital of a Punic empire which dominated the Mediterranean during the first millennium BC. The legendary Queen Dido is regarded as the founder of the city, though her historicity has been questioned. According to accounts by Timaeus of Tauromenium, she purchased from a local tribe the amount of land that could be covered by an oxhide. Cutting the skin into strips, she laid out her claim and founded an empire that would become, through the Punic Wars, the only existential threat to Rome until the coming of the Vandals several centuries later.

The ancient city was destroyed by the Roman Republic in the Third Punic War in 146 BC and then re-developed as Roman Carthage, which became the major city of the Roman Empire in the province of Africa. The city was sacked and destroyed by Umayyad forces after the Battle of Carthage in 698 to prevent it from being reconquered by the Byzantine Empire. It remained occupied during the Muslim period and was used as a fort by the Muslims until the Hafsid period when it was taken by the Crusaders with its inhabitants massacred during the Eighth Crusade. The Hafsids decided to destroy its defenses so it couldn't be used as a base by a hostile power again. It also continued to function as an episcopal see.

The regional power had shifted to Kairouan and the Medina of Tunis in the medieval period, until the early 20th century, when it began to develop into a coastal suburb of Tunis, incorporated as Carthage municipality in 1919. The archaeological site was first surveyed in 1830, by Danish consul Christian Tuxen Falbe. Excavations were performed in the second half of the 19th century by
Charles Ernest Beulé and by Alfred Louis Delattre. The Carthage National Museum was founded in 1875 by Cardinal Charles Lavigerie.
Excavations performed by French archaeologists in the 1920s first attracted an extraordinary amount of attention because of the evidence they produced for child sacrifice. There has been considerable disagreement among scholars concerning whether child sacrifice was practiced by ancient Carthage. The open-air Carthage Paleo-Christian Museum has exhibits excavated under the auspices of UNESCO from 1975 to 1984.

The name "Carthage" /ˈkarθɪdʒ/ is the Early Modern anglicisation of French "Carthage" /kaʁ.taʒ/, from Latin ' and ' (cf. Greek "Karkhēdōn" () and Etruscan "*Carθaza") from the Punic ' "new city", implying it was a "new Tyre". The Latin adjective "pūnicus", meaning "Phoenician", is reflected in English in some borrowings from Latin—notably the Punic Wars and the Punic language.

The Modern Standard Arabic form ("") is an adoption of French "Carthage", replacing an older local toponym reported as "Cartagenna" that directly continued the Latin name.

Carthage was built on a promontory with sea inlets to the north and the south. The city's location made it master of the Mediterranean's maritime trade. All ships crossing the sea had to pass between Sicily and the coast of Tunisia, where Carthage was built, affording it great power and influence. Two large, artificial harbors were built within the city, one for harboring the city's massive navy of 220 warships and the other for mercantile trade. A walled tower overlooked both harbors. The city had massive walls, in length, longer than the walls of comparable cities. Most of the walls were located on the shore, thus could be less impressive, as Carthaginian control of the sea made attack from that direction difficult. The of wall on the isthmus to the west were truly massive and were never penetrated. The city had a huge necropolis or burial ground, religious area, market places, council house, towers, and a theater, and was divided into four equally sized residential areas with the same layout. Roughly in the middle of the city stood a high citadel called the Byrsa.

Carthage was one of the largest cities of the Hellenistic period and was among the largest cities in preindustrial history. Whereas by AD 14, Rome had at least 750,000 inhabitants and in the following century may have reached 1 million, the cities of Alexandria and Antioch numbered only a few hundred thousand or less. According to the not-always-reliable history of Herodian, Carthage rivaled Alexandria for second place in the Roman empire.
On top of Byrsa hill, the location of the Roman Forum, a residential area from the last century of existence (early second century BCE.) of the Punic city was excavated by the French archaeologist Serge Lancel. The neighborhood, with its houses, shops, and private spaces, is significant for what it reveals about daily life there over 2100 years ago.

The remains have been preserved under embankments, the substructures of the later Roman forum, whose foundation piles dot the district. The housing blocks are separated by a grid of straight streets about wide, with a roadway consisting of clay; "in situ" stairs compensate for the slope of the hill. Construction of this type presupposes organization and political will, and has inspired the name of the neighborhood, "Hannibal district", referring to the legendary Punic general or sufet (consul) at the beginning of the second century BCE.

The habitat is typical, even stereotypical. The street was often used as a storefront/shopfront; cisterns were installed in basements to collect water for domestic use, and a long corridor on the right side of each residence led to a courtyard containing a sump, around which various other elements may be found. In some places, the ground is covered with mosaics called punica pavement, sometimes using a characteristic red mortar.

The merchant harbor at Carthage was developed, after settlement of the nearby Punic town of Utica. Eventually the surrounding countryside was brought into the orbit of the Punic urban centers, first commercially, then politically. Direct management over cultivation of neighbouring lands by Punic owners followed. A 28-volume work on agriculture written in Punic by Mago, a retired army general (c. 300), was translated into Latin and later into Greek. The original and both translations have been lost; however, some of Mago's text has survived in other Latin works. Olive trees (e.g., grafting), fruit trees (pomegranate, almond, fig, date palm), viniculture, bees, cattle, sheep, poultry, implements, and farm management were among the ancient topics which Mago discussed. As well, Mago addresses the wine-maker's art (here a type of sherry).

In Punic farming society, according to Mago, the small estate owners were the chief producers. They were, two modern historians write, not absent landlords. Rather, the likely reader of Mago was "the master of a relatively modest estate, from which, by great personal exertion, he extracted the maximum yield." Mago counselled the rural landowner, for the sake of their own 'utilitarian' interests, to treat carefully and well their managers and farm workers, or their overseers and slaves. Yet elsewhere these writers suggest that rural land ownership provided also a new power base among the city's nobility, for those resident in their country villas. By many, farming was viewed as an alternative endeavour to an urban business. Another modern historian opines that more often it was the urban merchant of Carthage who owned rural farming land to some profit, and also to retire there during the heat of summer. It may seem that Mago anticipated such an opinion, and instead issued this contrary advice (as quoted by the Roman writer Columella):

"The man who acquires an estate must sell his house, lest he prefer to live in the town rather than in the country. Anyone who prefers to live in a town has no need of an estate in the country." "One who has bought land should sell his town house, so that he will have no desire to worship the household gods of the city rather than those of the country; the man who takes greater delight in his city residence will have no need of a country estate."

The issues involved in rural land management also reveal underlying features of Punic society, its structure and stratification. The hired workers might be considered 'rural proletariat', drawn from the local Berbers. Whether there remained Berber landowners next to Punic-run farms is unclear. Some Berbers became sharecroppers. Slaves acquired for farm work were often prisoners of war. In lands outside Punic political control, independent Berbers cultivated grain and raised horses on their lands. Yet within the Punic domain that surrounded the city-state of Carthage, there were ethnic divisions in addition to the usual quasi feudal distinctions between lord and peasant, or master and serf. This inherent instability in the countryside drew the unwanted attention of potential invaders. Yet for long periods Carthage was able to manage these social difficulties.

The many amphorae with Punic markings subsequently found about ancient Mediterranean coastal settlements testify to Carthaginian trade in locally made olive oil and wine. Carthage's agricultural production was held in high regard by the ancients, and rivaled that of Rome—they were once competitors, e.g., over their olive harvests. Under Roman rule, however, grain production ([wheat] and barley) for export increased dramatically in 'Africa'; yet these later fell with the rise in Roman Egypt's grain exports. Thereafter olive groves and vineyards were re-established around Carthage. Visitors to the several growing regions that surrounded the city wrote admiringly of the lush green gardens, orchards, fields, irrigation channels, hedgerows (as boundaries), as well as the many prosperous farming towns located across the rural landscape.

Accordingly, the Greek author and compiler Diodorus Siculus (fl. 1st century BCE), who enjoyed access to ancient writings later lost, and on which he based most of his writings, described agricultural land near the city of Carthage circa 310 BC:

"It was divided into market gardens and orchards of all sorts of fruit trees, with many streams of water flowing in channels irrigating every part. There were country homes everywhere, lavishly built and covered with stucco. ... Part of the land was planted with vines, part with olives and other productive trees. Beyond these, cattle and sheep were pastured on the plains, and there were meadows with grazing horses."

The "Chora" (farm lands of Carthage) encompassed a limited area: the north coastal "tell", the lower Bagradas river valley (inland from Utica), Cape Bon, and the adjacent "sahel" on the east coast. Punic culture here achieved the introduction of agricultural sciences first developed for lands of the eastern Mediterranean, and their adaptation to local African conditions.

The "urban landscape" of Carthage is known in part from ancient authors, augmented by modern digs and surveys conducted by archeologists. The "first urban nucleus" dating to the seventh century, in area about , was apparently located on low-lying lands along the coast (north of the later harbors). As confirmed by archaeological excavations, Carthage was a "creation "ex nihilo"", built on 'virgin' land, and situated at what was then the end of a peninsula. Here among "mud brick walls and beaten clay floors" (recently uncovered) were also found extensive cemeteries, which yielded evocative grave goods like clay masks. "Thanks to this burial archaeology we know more about archaic Carthage than about any other contemporary city in the western Mediterranean." Already in the eighth century, fabric dyeing operations had been established, evident from crushed shells of murex (from which the 'Phoenician purple' was derived). Nonetheless, only a "meager picture" of the cultural life of the earliest pioneers in the city can be conjectured, and not much about housing, monuments or defenses. The Roman poet Virgil (70–19 BC) imagined early Carthage, when his legendary character Aeneas had arrived there:

"Aeneas found, where lately huts had been,
marvelous buildings, gateways, cobbled ways,
and din of wagons. There the Tyrians
were hard at work: laying courses for walls,
rolling up stones to build the citadel,
while others picked out building sites and plowed
a boundary furrow. Laws were being enacted,
magistrates and a sacred senate chosen.
Here men were dredging harbors, there they laid
the deep foundations of a theatre,
and quarried massive pillars... ."
The two inner harbours [called in Punic "cothon"] were located in the southeast; one being commercial, and the other for war. Their definite functions are not entirely known, probably for the construction, outfitting, or repair of ships, perhaps also loading and unloading cargo. Larger anchorages existed to the north and south of the city. North and west of the "cothon" were located several industrial areas, e.g., metalworking and pottery (e.g., for amphora), which could serve both inner harbours, and ships anchored to the south of the city.

About the Byrsa, the citadel area to the north, considering its importance our knowledge of it is patchy. Its prominent heights were the scene of fierce combat during the fiery destruction of the city in 146 BC. The Byrsa was the reported site of the Temple of Eshmun (the healing god), at the top of a stairway of sixty steps. A temple of Tanit (the city's queen goddess) was likely situated on the slope of the 'lesser Byrsa' immediately to the east, which runs down toward the sea. Also situated on the Byrsa were luxury homes.

South of the citadel, near the "cothon" (the inner harbours) was the "tophet", a special and very old cemetery, which when begun lay outside the city's boundaries. Here the "Salammbô" was located, the "Sanctuary of Tanit", not a temple but an enclosure for placing stone stelae. These were mostly short and upright, carved for funeral purposes. The presence of infant skeletons from here may indicate the occurrence of child sacrifice, as claimed in the Bible, although there has been considerable doubt among archeologists as to this interpretation and many consider it simply a cemetery devoted to infants. Probably the "tophet" burial fields were "dedicated at an early date, perhaps by the first settlers." Recent studies, on the other hand, indicate that child sacrifice was practiced by the Carthaginians.

Between the sea-filled "cothon" for shipping and the Byrsa heights lay the "agora" [Greek: "market"], the city-state's central marketplace for business and commerce. The "agora" was also an area of public squares and plazas, where the people might formally assemble, or gather for festivals. It was the site of religious shrines, and the location of whatever were the major municipal buildings of Carthage. Here beat the heart of civic life. In this district of the Carthage, more probably, the ruling suffets presided, the council of elders convened, the tribunal of the 104 met, and justice was dispensed at trials in the open air.

Early residential districts wrapped around the Byrsa from the south to the north east. Houses usually were whitewashed and blank to the street, but within were courtyards open to the sky. In these neighborhoods multistory construction later became common, some up to six stories tall according to an ancient Greek author. Several architectural floorplans of homes have been revealed by recent excavations, as well as the general layout of several city blocks. Stone stairs were set in the streets, and drainage was planned, e.g., in the form of soakways leaching into the sandy soil. Along the Byrsa's southern slope were located not only fine old homes, but also many of the earliest grave-sites, juxtaposed in small areas, interspersed with daily life.

Artisan workshops were located in the city at sites north and west of the harbours. The location of three metal workshops (implied from iron slag and other vestiges of such activity) were found adjacent to the naval and commercial harbours, and another two were further up the hill toward the Byrsa citadel. Sites of pottery kilns have been identified, between the "agora" and the harbours, and further north. Earthenware often used Greek models. A fuller's shop for preparing woolen cloth (shrink and thicken) was evidently situated further to the west and south, then by the edge of the city. Carthage also produced objects of rare refinement. During the 4th and 3rd centuries, the sculptures of the sarcophagi became works of art. "Bronze engraving and stone-carving reached their zenith."

The elevation of the land at the promontory on the seashore to the north-east (now called Sidi Bou Saïd), was twice as high above sea level as that at the Byrsa (100 m and 50 m). In between runs a ridge, several times reaching 50 m; it continues northwestward along the seashore, and forms the edge of a plateau-like area between the Byrsa and the sea. Newer urban developments lay here in these northern districts.

Surrounding Carthage were walls "of great strength" said in places to rise above 13 m, being nearly 10 m thick, according to ancient authors. To the west, three parallel walls were built. The walls altogether ran for about to encircle the city. The heights of the Byrsa were additionally fortified; this area being the last to succumb to the Romans in 146 BC. Originally the Romans had landed their army on the strip of land extending southward from the city.

Greek cities contested with Carthage for the Western Mediterranean culminating in the Sicilian Wars and the Pyrrhic War over Sicily, while the Romans fought three wars against Carthage, known as the Punic Wars, "Punic" meaning "Phoenician" in Latin.

The Carthaginian republic was one of the longest-lived and largest states in the ancient Mediterranean. Reports relay several wars with Syracuse and finally, Rome, which eventually resulted in the defeat and destruction of Carthage in the Third Punic War. The Carthaginians were Phoenician settlers originating in the Mediterranean coast of the Near East. They spoke Canaanite, a Semitic language, and followed a local variety of the ancient Canaanite religion.

The fall of Carthage came at the end of the Third Punic War in 146 BC at the Battle of Carthage. Despite initial devastating Roman naval losses and Rome's recovery from the brink of defeat after the terror of a 15-year occupation of much of Italy by Hannibal, the end of the series of wars resulted in the end of Carthaginian power and the complete destruction of the city by Scipio Aemilianus. The Romans pulled the Phoenician warships out into the harbor and burned them before the city, and went from house to house, capturing and enslaving the people. About 50,000 Carthaginians were sold into slavery. The city was set ablaze and razed to the ground, leaving only ruins and rubble. After the fall of Carthage, Rome annexed the majority of the Carthaginian colonies, including other North African locations such as Volubilis, Lixus, Chellah, and Mogador.

The legend that the city was sown with salt remains widely accepted despite a lack of evidence among ancient historical accounts; According to R.T. Ridley, the earliest such claim is attributable to B.L. Hallward's chapter in "Cambridge Ancient History", published in 1930. Ridley contended that Hallward's claim may have gained traction due to historical evidence of other salted-earth instances such as Abimelech's salting of Shechem in Judges 9:45. B.H. Warmington admitted he had repeated Hallward's error, but posited that the legend precedes 1930 and inspired repetitions of the practice. He also suggested that it is useful to understand how subsequent historical narratives have been framed and that the symbolic value of the legend is so great and enduring that it mitigates a deficiency of concrete evidence.

For many years but especially beginning in the 19th century, various texts claim that after defeating the city of Carthage in the Third Punic War (146 BC), the Roman general Scipio Aemilianus Africanus ordered the city be sacked, forced its surviving inhabitants into slavery, plowed it over and sowed it with salt. However, no ancient sources exist documenting the salting itself. The element of salting is therefore probably a later invention modeled on the Biblical story of Shechem. The ritual of symbolically drawing a plow over the site of a city is mentioned in ancient sources, but not in reference to Carthage specifically. When Pope Boniface VIII destroyed Palestrina in 1299, he issued a papal bull that it be plowed "following the old example of Carthage in Africa" and also salted. "I have run the plough over it, like the ancient Carthage of Africa, and I have had salt sown upon it..."

When Carthage fell, its nearby rival Utica, a Roman ally, was made capital of the region and replaced Carthage as the leading center of Punic trade and leadership. It had the advantageous position of being situated on the outlet of the Medjerda River, Tunisia's only river that flowed all year long. However, grain cultivation in the Tunisian mountains caused large amounts of silt to erode into the river. This silt accumulated in the harbor until it became useless, and Rome was forced to rebuild Carthage.

By 122 BC, Gaius Gracchus founded a short-lived colony, called "Colonia Iunonia", after the Latin name for the Punic goddess Tanit, "Iuno Caelestis". The purpose was to obtain arable lands for impoverished farmers. The Senate abolished the colony some time later, to undermine Gracchus' power.

After this ill-fated attempt, a new city of Carthage was built on the same land by Julius Caesar in the period from 49 to 44 BC, and by the first century, it had grown to be the second-largest city in the western half of the Roman Empire, with a peak population of 500,000. It was the center of the province of Africa, which was a major breadbasket of the Empire. Among its major monuments was an amphitheater.

Carthage also became a center of early Christianity (see Carthage (episcopal see)). In the first of a string of rather poorly reported councils at Carthage a few years later, no fewer than 70 bishops attended. Tertullian later broke with the mainstream that was increasingly represented in the West by the primacy of the Bishop of Rome, but a more serious rift among Christians was the Donatist controversy, which Augustine of Hippo spent much time and parchment arguing against. At the Council of Carthage (397), the biblical canon for the western Church was confirmed.
The political fallout from the deep disaffection of African Christians is supposedly a crucial factor in the ease with which Carthage and the other centers were captured in the fifth century by Gaiseric, king of the Vandals, who defeated the Roman general Bonifacius and made the city the capital of the Vandal Kingdom. Gaiseric was considered a heretic, too, an Arian, and though Arians commonly despised Catholic Christians, a mere promise of toleration might have caused the city's population to accept him.

The Vandals during their conquest are said to have destroyed parts of Carthage by Victor Vitensis in "Historia Persecutionis Africanae Provincia" including various buildings and churches.

After a failed attempt to recapture the city in the fifth century, the Eastern Roman Empire finally subdued the Vandals in the Vandalic War in 533–534. Thereafter, the city became the seat of the praetorian prefecture of Africa, which was made into an exarchate during the emperor Maurice's reign, as was Ravenna on the Italian Peninsula. These two exarchates were the western bulwarks of the Byzantine Empire, all that remained of its power in the West. In the early seventh century Heraclius the Elder, the exarch of Carthage, overthrew the Byzantine emperor Phocas, whereupon his son Heraclius succeeded to the imperial throne.

The Roman Exarchate of Africa was not able to withstand the seventh-century Muslim conquest of the Maghreb. The Umayyad Caliphate under Abd al-Malik ibn Marwan in 686 sent a force led by Zuhayr ibn Qays, who won a battle over the Romans and Berbers led by King Kusaila of the Kingdom of Altava on the plain of Kairouan, but he could not follow that up. In 695, Hassan ibn al-Nu'man captured Carthage and advanced into the Atlas Mountains. An imperial fleet arrived and retook Carthage, but in 698, Hasan ibn al-Nu'man returned and defeated Emperor Tiberios III at the 698 Battle of Carthage. Roman imperial forces withdrew from all of Africa except Ceuta. Fearing that the Byzantine Empire might reconquer it, they decided to destroy Roman Carthage in a scorched earth policy and establish their headquarters somewhere else. Its walls were torn down, its water supply cut off, the agricultural land was ravaged and its harbors made unusable.

The destruction of the Exarchate of Africa marked a permanent end to the Byzantine Empire's influence in the region.

It is visible from archaeological evidence, that the town of Carthage continued to be occupied. The neighborhood of Bjordi Djedid continued to be occupied. The Baths of Antoninus continued to function in the Arab period and the historian Al-Bakri stated that they were still in good condition. They also had production centers nearby. It is difficult to determine whether the continued habitation of some other buildings belonged to Late Byzantine or Early Arab period. The Bir Ftouha church might have continued to remain in use though it is not clear when it became uninhabited. Constantine the African was born in Carthage.

The Medina of Tunis, originally a Berber settlement, was established as the new regional center under the Umayyad Caliphate in the early 8th century. Under the Aghlabids, the people of Tunis revolted numerous times, but the city profited from economic improvements and quickly became the second most important in the kingdom. It was briefly the national capital, from the end of the reign of Ibrahim II in 902, until 909, when the Shi'ite Berbers took over Ifriqiya and founded the Fatimid Caliphate.

Carthage remained a residential see until the high medieval period, mentioned in
two letters of Pope Leo IX dated 1053, written in reply to consultations regarding a conflict between the bishops of Carthage and Gummi.
In each of the two letters, Pope Leo declares that, after the Bishop of Rome, the first archbishop and chief metropolitan of the whole of Africa is the bishop of Carthage.
Later, an archbishop of Carthage named Cyriacus was imprisoned by the Arab rulers because of an accusation by some Christians. Pope Gregory VII wrote him a letter of consolation, repeating the hopeful assurances of the primacy of the Church of Carthage, "whether the Church of Carthage should still lie desolate or rise again in glory".
By 1076, Cyriacus was set free, but there was only one other bishop in the province. These are the last of whom there is mention in that period of the history of the see.

The fortress of Carthage was used by the Muslims until Hafsid era and was captured by the Crusaders during the Eighth Crusade. The inhabitants of Carthage were slaughtered by the Crusaders after they took it and it was used as a base of operations against the Hafsids. After repulsing them, Muhammad I al-Mustansir decided to completely destroy Cathage's defenses to prevent a repeat.

Carthage is some east-northeast of Tunis; the settlements nearest to Carthage were the town of Sidi Bou Said to the north and the village of Le Kram to the south.
Sidi Bou Saint was a village which had grown around the tomb of the eponymous sufi saint (d. 1231), which had been developed into a town under Ottoman rule in the 18th century. Le Kram was developed in the late 19th century under French administration as a settlement close to the port of La Goulette.

In 1881, Tunisia became a French protectorate, and in the same year Charles Lavigerie, who was archbishop of Algiers, became apostolic administrator of the vicariate of Tunis. In the following year, Lavigerie became a cardinal. He "saw himself as the reviver of the ancient Christian Church of Africa, the Church of Cyprian of Carthage", and, on 10 November 1884, was successful in his great ambition of having the metropolitan see of Carthage restored, with himself as its first archbishop. In line with the declaration of Pope Leo IX in 1053, Pope Leo XIII acknowledged the revived Archdiocese of Carthage as the primatial see of Africa and Lavigerie as primate.

The Acropolium of Carthage (Saint Louis Cathedral of Carthage) was erected on Byrsa hill in 1884.

The Danish consul Christian Tuxen Falbe conducted a first survey of the topography of the archaeological site (published in 1833).
Antiquarian interest was intensified following the publication of Flaubert's "Salammbô" in 1858. Charles Ernest Beulé performed some preliminary excavations of Roman remains on Byrsa hill in 1860. A more systematic survey of both Punic and Roman-era remains is due to Alfred Louis Delattre, who was sent to Tunis by cardinal Charles Lavigerie in 1875 on both an apostolic and an archaeological mission.
Audollent (1901, p. 203) cites Delattre and Lavigerie to the effect that in the 1880s, locals still knew the area of the ancient city under the name of "Cartagenna" (i.e. reflecting the Latin "n"-stem "Carthāgine").

Auguste Audollent divides the area of Roman Carthage into four quarters, "Cartagenna", "Dermèche", "Byrsa" and "La Malga". Cartagenna and Dermèche correspond with the lower city, including the site of Punic Carthage; Byrsa is associated with the upper city, which in Punic times was a walled citadel above the harbour; and "La Malga" is linked with the more remote parts of the upper city in Roman times.

French-led excavations at Carthage began in 1921, and from 1923 reported finds of a large quantity of urns containing a mixture of animal and children's bones. René Dussaud identified a 4th-century BC stela found in Carthage as depicting a child sacrifice.

A temple at Amman (1400–1250 BC) excavated and reported upon by J.B. Hennessy in 1966, shows the possibility of bestial and human sacrifice by fire. While evidence of child sacrifice in Canaan was the object of academic disagreement, with some scholars arguing that merely children's cemeteries had been unearthed in Carthage, the mixture of children's with animal bones as well as associated epigraphic evidence involving mention of "mlk" led to a consensus that, at least in Carthage, child sacrifice was indeed common practice.

In 2016, an ancient Carthaginian individual, who was excavated from a Punic tomb in Byrsa Hill, was found to belong to the rare U5b2c1 maternal haplogroup. The Young Man of Byrsa specimen dates from the late 6th century BCE, and his lineage is believed to represent early gene flow from Iberia to the Maghreb.

In 1920, the first seaplane base was built on the Lake of Tunis for the seaplanes of Compagnie Aéronavale. The Tunis Airfield opened in 1938, serving around 5,800 passengers annually on the Paris-Tunis route.
During World War II, the airport was used by the United States Army Air Force Twelfth Air Force as a headquarters and command control base for the Italian Campaign of 1943.
Construction on the Tunis-Carthage Airport, which was fully funded by France, began in 1944, and in 1948 the airport become the main hub for Tunisair.

In the 1950s the Lycée Français de Carthage was established to serve French families in Carthage. In 1961 it was given to the Tunisian government as part of the Independence of Tunisia, so the nearby Collège Maurice Cailloux in La Marsa, previously an annex of the Lycée Français de Carthage, was renamed to the Lycée Français de La Marsa and began serving the "lycée" level. It is currently the Lycée Gustave Flaubert.

After Tunisian independence in 1956, the Tunis conurbation gradually extended around the airport, and Carthage (قرطاج " Qarṭāj") is now a suburb of Tunis, covering the area between Sidi Bou Said and Le Kram.
Its population as of January 2013 was estimated at 21,276,
mostly attracting the more wealthy residents. If Carthage is not the capital, it tends to be the political pole, a « place of emblematic power » according to Sophie Bessis, leaving to Tunis the economic and administrative roles. The Carthage Palace (the Tunisian presidential palace) is located in the coast.

The suburb has six train stations of the TGM line between Le Kram and Sidi Bou Said:
Carthage Salammbo (named for Salambo, the fictional daughter of Hamilcar), Carthage Byrsa (named for Byrsa hill), Carthage Dermech ("Dermèche"), Carthage Hannibal (named for Hannibal), Carthage Présidence (named for the Presidential Palace) and Carthage Amilcar (named for Hamilcar).

The merchants of Carthage were in part heirs of the Mediterranean trade developed by Phoenicia, and so also heirs of the rivalry with Greek merchants. Business activity was accordingly both stimulated and challenged. Cyprus had been an early site of such commercial contests. The Phoenicians then had ventured into the western Mediterranean, founding trading posts, including Utica and Carthage. The Greeks followed, entering the western seas where the commercial rivalry continued. Eventually it would lead, especially in Sicily, to several centuries of intermittent war. Although Greek-made merchandise was generally considered superior in design, Carthage also produced trade goods in abundance. That Carthage came to function as a manufacturing colossus was shown during the Third Punic War with Rome. Carthage, which had previously disarmed, then was made to face the fatal Roman siege. The city "suddenly organised the manufacture of arms" with great skill and effectiveness. According to Strabo (63 BC – AD 21) in his "Geographica":

"[Carthage] each day produced one hundred and forty finished shields, three hundred swords, five hundred spears, and one thousand missiles for the catapults... . Furthermore, [Carthage although surrounded by the Romans] built one hundred and twenty decked ships in two months... for old timber had been stored away in readiness, and a large number of skilled workmen, maintained at public expense."

The textiles industry in Carthage probably started in private homes, but the existence of professional weavers indicates that a sort of factory system later developed. Products included embroidery, carpets, and use of the purple murex dye (for which the Carthaginian isle of Djerba was famous). Metalworkers developed specialized skills, i.e., making various weapons for the armed forces, as well as domestic articles, such as knives, forks, scissors, mirrors, and razors (all articles found in tombs). Artwork in metals included vases and lamps in bronze, also bowls, and plates. Other products came from such crafts as the potters, the glassmakers, and the goldsmiths. Inscriptions on votive stele indicate that many were not slaves but 'free citizens'.

Phoenician and Punic merchant ventures were often run as a family enterprise, putting to work its members and its subordinate clients. Such family-run businesses might perform a variety of tasks: own and maintain the ships, providing the captain and crew; do the negotiations overseas, either by barter or buying and selling, of their own manufactured commodities and trade goods, and native products (metals, foodstuffs, etc.) to carry and trade elsewhere; and send their agents to stay at distant outposts in order to make lasting local contacts, and later to establish a warehouse of shipped goods for exchange, and eventually perhaps a settlement. Over generations, such activity might result in the creation of a wide-ranging network of trading operations. Ancillary would be the growth of reciprocity between different family firms, foreign and domestic.

State protection was extended to its sea traders by the Phoenician city of Tyre and later likewise by the daughter city-state of Carthage. , the well-regarded French historian of ancient North Africa, summarized the major principles guiding the civic rulers of Carthage with regard to its policies for trade and commerce:

Both the Phoenicians and the Cathaginians were well known in antiquity for their secrecy in general, and especially pertaining to commercial contacts and trade routes. Both cultures excelled in commercial dealings. Strabo (63BC-AD21) the Greek geographer wrote that before its fall (in 146 BC) Carthage enjoyed a population of 700,000, and directed an alliance of 300 cities. The Greek historian Polybius (c.203–120) referred to Carthage as "the wealthiest city in the world".

A "suffet" (possibly two) was elected by the citizens, and held office with no military power for a one-year term. Carthaginian generals marshalled mercenary armies and were separately elected. From about 550 to 450 the Magonid family monopolized the top military position; later the Barcid family acted similarly. Eventually it came to be that, after a war, the commanding general had to testify justifying his actions before a court of 104 judges.

Aristotle (384–322) discusses Carthage in his work, "Politica"; he begins: "The Carthaginians are also considered to have an excellent form of government." He briefly describes the city as a "mixed constitution", a political arrangement with cohabiting elements of monarchy, aristocracy, and democracy, i.e., a king (Gk: basileus), a council of elders (Gk: gerusia), and the people (Gk: demos). Later Polybius of Megalopolis (c.204–122, Greek) in his "Histories" would describe the Roman Republic in more detail as a mixed constitution in which the Consuls were the monarchy, the Senate the aristocracy, and the Assemblies the democracy.

Evidently Carthage also had an institution of elders who advised the Suffets, similar to a Greek "gerusia" or the Roman Senate. We do not have a Punic name for this body. At times its members would travel with an army general on campaign. Members also formed permanent committees. The institution had several hundred members drawn from the wealthiest class who held office for life. Vacancies were probably filled by recruitment from among the elite, i.e., by co-option. From among its members were selected the 104 Judges mentioned above. Later the 104 would come to evaluate not only army generals but other office holders as well. Aristotle regarded the 104 as most important; he compared it to the ephorate of Sparta with regard to control over security. In Hannibal's time, such a Judge held office for life. At some stage there also came to be independent self-perpetuating boards of five who filled vacancies and supervised (non-military) government administration.

Popular assemblies also existed at Carthage. When deadlocked the Suffets and the quasi-senatorial institution of elders might request the assembly to vote; also, assembly votes were requested in very crucial matters in order to achieve political consensus and popular coherence. The assembly members had no "legal" wealth or birth qualification. How its members were selected is unknown, e.g., whether by festival group or urban ward or another method.

The Greeks were favourably impressed by the constitution of Carthage; Aristotle had a separate study of it made which unfortunately is lost. In his "Politica" he states: "The government of Carthage is oligarchical, but they successfully escape the evils of oligarchy by enriching one portion of the people after another by sending them to their colonies." "[T]heir policy is to send some [poorer citizens] to their dependent towns, where they grow rich." Yet Aristotle continues, "[I]f any misfortune occurred, and the bulk of the subjects revolted, there would be no way of restoring peace by legal means." Aristotle remarked also:

"Many of the Carthaginian institutions are excellent. The superiority of their constitution is proved by the fact that the common people remain loyal to the constitution; the Carthaginians have never had any rebellion worth speaking of, and have never been under the rule of a tyrant."

Here one may remember that the city-state of Carthage, who citizens were mainly "Libyphoenicians" (of Phoenician ancestry born in Africa), dominated and exploited an agricultural countryside composed mainly of native Berber sharecroppers and farmworkers, whose affiliations to Carthage were open to divergent possibilities. Beyond these more settled Berbers and the Punic farming towns and rural manors, lived the independent Berber tribes, who were mostly pastoralists.

In the brief, uneven review of government at Carthage found in his "Politica" Aristotle mentions several faults. Thus, "that the same person should hold many offices, which is a favorite practice among the Carthaginians." Aristotle disapproves, mentioning the flute-player and the shoemaker. Also, that "magistrates should be chosen not only for their merit but for their wealth." Aristotle's opinion is that focus on pursuit of wealth will lead to oligarchy and its evils.

"[S]urely it is a bad thing that the greatest offices... should be bought. The law which allows this abuse makes wealth of more account than virtue, and the whole state becomes avaricious. For, whenever the chiefs of the state deem anything honorable, the other citizens are sure to follow their example; and, where virtue has not the first place, their aristocracy cannot be firmly established."

In Carthage the people seemed politically satisfied and submissive, according to the historian Warmington. They in their assemblies only rarely exercised the few opportunities given them to assent to state decisions. Popular influence over government appears not to have been an issue at Carthage. Being a commercial republic fielding a mercenary army, the people were not conscripted for military service, an experience which can foster the feel for popular political action. But perhaps this misunderstands the society; perhaps the people, whose values were based on small-group loyalty, felt themselves sufficiently connected to their city's leadership by the very integrity of the person-to-person linkage within their social fabric. Carthage was very stable; there were few openings for tyrants. Only after defeat by Rome devastated Punic imperial ambitions did the people of Carthage seem to question their governance and to show interest in political reform.

In 196, following the Second Punic War (218–201), Hannibal Barca, still greatly admired as a Barcid military leader, was elected suffet. When his reforms were blocked by a financial official about to become a judge for life, Hannibal rallied the populace against the 104 judges. He proposed a one-year term for the 104, as part of a major civic overhaul. Additionally, the reform included a restructuring of the city's revenues, and the fostering of trade and agriculture. The changes rather quickly resulted in a noticeable increase in prosperity. Yet his incorrigible political opponents cravenly went to Rome, to charge Hannibal with conspiracy, namely, plotting war against Rome in league with Antiochus the Hellenic ruler of Syria. Although the Roman Scipio Africanus resisted such manoeuvre, eventually intervention by Rome forced Hannibal to leave Carthage. Thus, corrupt city officials efficiently blocked Hannibal Barca in his efforts to reform the government of Carthage.

Mago (6th century) was King of Carthage; the head of state, war leader, and religious figurehead. His family was considered to possess a sacred quality. Mago's office was somewhat similar to that of a pharaoh, but although kept in a family it was not hereditary, it was limited by legal consent. Picard, accordingly, believes that the council of elders and the popular assembly are late institutions. Carthage was founded by the king of Tyre who had a royal monopoly on this trading venture. Thus it was the royal authority stemming from this traditional source of power that the King of Carthage possessed. Later, as other Phoenician ship companies entered the trading region, and so associated with the city-state, the King of Carthage had to keep order among a rich variety of powerful merchants in their negotiations among themselves and over risky commerce across the Mediterranean. Under these circumstance, the office of king began to be transformed. Yet it was not until the aristocrats of Carthage became wealthy owners of agricultural lands in Africa that a council of elders was institutionalized at Carthage.

Most ancient literature concerning Carthage comes from Greek and Roman sources as Carthage's own documents were destroyed by the Romans. Apart from inscriptions, hardly any Punic literature has survived, and none in its own language and script. A brief catalogue would include:

"[F]rom the Greek author Plutarch [(c. 46 – c. 120)] we learn of the 'sacred books' in Punic safeguarded by the city's temples. Few Punic texts survive, however." Once "the City Archives, the Annals, and the scribal lists of "suffets"" existed, but evidently these were destroyed in the horrific fires during the Roman capture of the city in 146 BC.

Yet some Punic books (Latin: "libri punici") from the libraries of Carthage reportedly did survive the fires. These works were apparently given by Roman authorities to the newly augmented Berber rulers. Over a century after the fall of Carthage, the Roman politician-turned-author Gaius Sallustius Crispus or Sallust (86–34) reported his having seen volumes written in Punic, which books were said to be once possessed by the Berber king, Hiempsal II (r. 88–81). By way of Berber informants and Punic translators, Sallust had used these surviving books to write his brief sketch of Berber affairs.

Probably some of Hiempsal II's "libri punici", that had escaped the fires that consumed Carthage in 146 BC, wound up later in the large royal library of his grandson Juba II (r.25 BC-AD 24). Juba II not only was a Berber king, and husband of Cleopatra's daughter, but also a scholar and author in Greek of no less than nine works. He wrote for the Mediterranean-wide audience then enjoying classical literature. The "libri punici" inherited from his grandfather surely became useful to him when composing his "Libyka", a work on North Africa written in Greek. Unfortunately, only fragments of "Libyka" survive, mostly from quotations made by other ancient authors. It may have been Juba II who 'discovered' the five-centuries-old 'log book' of Hanno the Navigator, called the "Periplus", among library documents saved from fallen Carthage.

In the end, however, most Punic writings that survived the destruction of Carthage "did not escape the immense wreckage in which so many of Antiquity's literary works perished." Accordingly, the long and continuous interactions between Punic citizens of Carthage and the Berber communities that surrounded the city have no local historian. Their political arrangements and periodic crises, their economic and work life, the cultural ties and social relations established and nourished (infrequently as kin), are not known to us directly from ancient Punic authors in written accounts. Neither side has left us their stories about life in Punic-era Carthage.

Regarding "Phoenician" writings, few remain and these seldom refer to Carthage. The more ancient and most informative are cuneiform tablets, ca. 1600–1185, from ancient Ugarit, located to the north of Phoenicia on the Syrian coast; it was a Canaanite city politically affiliated with the Hittites. The clay tablets tell of myths, epics, rituals, medical and administrative matters, and also correspondence. The highly valued works of Sanchuniathon, an ancient priest of Beirut, who reportedly wrote on Phoenician religion and the origins of civilization, are themselves completely lost, but some little content endures twice removed. Sanchuniathon was said to have lived in the 11th century, which is considered doubtful. Much later a "Phoenician History" by Philo of Byblos (64–141) reportedly existed, written in Greek, but only fragments of this work survive. An explanation proffered for why so few Phoenician works endured: early on (11th century) archives and records began to be kept on papyrus, which does not long survive in a moist coastal climate. Also, both Phoenicians and Carthaginians were well known for their secrecy.

Thus, of their ancient writings we have little of major interest left to us by Carthage, or by Phoenicia the country of origin of the city founders. "Of the various Phoenician and Punic compositions alluded to by the ancient classical authors, not a single work or even fragment has survived in its original idiom." "Indeed, not a single Phoenician manuscript has survived in the original [language] or in translation." We cannot therefore access directly the line of thought or the contour of their worldview as expressed in their own words, in their own voice. Ironically, it was the Phoenicians who "invented or at least perfected and transmitted a form of writing [the alphabet] that has influenced dozens of cultures including our own."

As noted, the celebrated ancient books on agriculture written by Mago of Carthage survives only via quotations in Latin from several later Roman works.




</doc>
<doc id="6556" url="https://en.wikipedia.org/wiki?curid=6556" title="Coprime integers">
Coprime integers

In number theory, two integers and are said to be relatively prime, mutually prime, or coprime (also written co-prime) if the only positive integer (factor) that divides both of them is 1. Consequently, any prime number that divides one does not divide the other. This is equivalent to their greatest common divisor (gcd) being 1. 

The numerator and denominator of a reduced fraction are coprime. As specific examples, 14 and 15 are coprime, being commonly divisible only by 1, while 14 and 21 are not coprime, because they are both divisible by 7. 

Standard notations for relatively prime integers and are: and . Graham, Knuth and Patashnik have proposed that the notation formula_1 be used to indicate that and are relatively prime and that the term "prime" be used instead of coprime (as in is "prime" to ).

A fast way to determine whether two numbers are coprime is given by the Euclidean algorithm and its faster variants such as binary GCD algorithm or Lehmer's GCD algorithm.

The number of integers coprime to a positive integer , between 1 and , is given by Euler's totient function (or Euler's phi function) .

A set of integers can also be called coprime if its elements share no common positive factor except 1. A stronger condition on a set of integers is pairwise coprime, which means that and are coprime for every pair of different integers in the set. The set } is coprime, but it is not pairwise coprime since 2 and 4 are not relatively prime.

The numbers 1 and −1 are the only integers coprime to every integer, and they are the only integers that are coprime with 0.

A number of conditions are equivalent to and being coprime:

As a consequence of the third point, if "a" and "b" are coprime and "br" ≡ "bs" (mod "a"), then "r" ≡ "s" (mod "a"). That is, we may "divide by "b"" when working modulo "a". Furthermore, if "b" and "b" are both coprime with "a", then so is their product "b""b" (i.e., modulo "a" it is a product of invertible elements, and therefore invertible); this also follows from the first point by Euclid's lemma, which states that if a prime number "p" divides a product "bc", then "p" divides at least one of the factors "b", "c".

As a consequence of the first point, if "a" and "b" are coprime, then so are any powers "a" and "b".

If "a" and "b" are coprime and "a" divides the product "bc", then "a" divides "c". This can be viewed as a generalization of Euclid's lemma.

The two integers "a" and "b" are coprime if and only if the point with coordinates ("a", "b") in a Cartesian coordinate system is "visible" from the origin (0,0), in the sense that there is no point with integer coordinates on the line segment between the origin and ("a", "b"). (See figure 1.)

In a sense that can be made precise, the probability that two randomly chosen integers are coprime is 6/π (see pi), which is about 61%. See below.

Two natural numbers "a" and "b" are coprime if and only if the numbers 2 − 1 and 2 − 1 are coprime. As a generalization of this, following easily from the Euclidean algorithm in base "n" > 1:

A set of integers "S" = {"a", "a", ... "a"} can also be called "coprime" or "setwise coprime" if the greatest common divisor of all the elements of the set is 1. For example, the integers 6, 10, 15 are coprime because 1 is the only positive integer that divides all of them.

If every pair in a set of integers is coprime, then the set is said to be "pairwise coprime" (or "pairwise relatively prime", "mutually coprime" or "mutually relatively prime"). Pairwise coprimality is a stronger condition than setwise coprimality; every pairwise coprime finite set is also setwise coprime, but the reverse is not true. For example, the integers 4, 5, 6 are (setwise) coprime (because the only positive integer dividing "all" of them is 1), but they are not "pairwise" coprime (because gcd(4, 6) = 2).

The concept of pairwise coprimality is important as a hypothesis in many results in number theory, such as the Chinese remainder theorem.

It is possible for an infinite set of integers to be pairwise coprime. Notable examples include the set of all prime numbers, the set of elements in Sylvester's sequence, and the set of all Fermat numbers.

Two ideals "A" and "B" in the commutative ring "R" are called coprime (or comaximal) if "A" + "B" = "R". This generalizes Bézout's identity: with this definition, two principal ideals ("a") and ("b") in the ring of integers Z are coprime if and only if "a" and "b" are coprime. If the ideals "A" and "B" of "R" are coprime, then "AB" = "A"∩"B"; furthermore, if "C" is a third ideal such that "A" contains "BC", then "A" contains "C". The Chinese remainder theorem can be generalized to any commutative ring, using coprime ideals.

Given two randomly chosen integers "a" and "b", it is reasonable to ask how likely it is that "a" and "b" are coprime. In this determination, it is convenient to use the characterization that "a" and "b" are coprime if and only if no prime number divides both of them (see Fundamental theorem of arithmetic).

Informally, the probability that any number is divisible by a prime (or in fact any integer) formula_3 is formula_4; for example, every 7th integer is divisible by 7. Hence the probability that two numbers are both divisible by "p" is formula_5, and the probability that at least one of them is not is formula_6. Any finite collection of divisibility events associated to distinct primes is mutually independent. For example, in the case of two events, a number is divisible by primes "p" and "q" if and only if it is divisible by "pq"; the latter event has probability 1/"pq". If one makes the heuristic assumption that such reasoning can be extended to infinitely many divisibility events, one is led to guess that the probability that two numbers are coprime is given by a product over all primes,

Here "ζ" refers to the Riemann zeta function, the identity relating the product over primes to "ζ"(2) is an example of an Euler product, and the evaluation of "ζ"(2) as "π"/6 is the Basel problem, solved by Leonhard Euler in 1735.

There is no way to choose a positive integer at random so that each positive integer occurs with equal probability, but statements about "randomly chosen integers" such as the ones above can be formalized by using the notion of "natural density". For each positive integer "N", let "P" be the probability that two randomly chosen numbers in formula_8 are coprime. Although "P" will never equal formula_9 exactly, with work one can show that in the limit as formula_10, the probability formula_11 approaches formula_9.

More generally, the probability of "k" randomly chosen integers being coprime is formula_13.

All pairs of positive coprime numbers formula_14 (with formula_15) can be arranged in two disjoint complete ternary trees, one tree starting from formula_16 (for even-odd and odd-even pairs), and the other tree starting from formula_17 (for odd-odd pairs). The children of each vertex formula_18 are generated as follows:

This scheme is exhaustive and non-redundant with no invalid members.




</doc>
<doc id="6557" url="https://en.wikipedia.org/wiki?curid=6557" title="Control unit">
Control unit

The control unit (CU) is a component of a computer's central processing unit (CPU) that directs the operation of the processor. It tells the computer's memory, arithmetic and logic unit and input and output devices how to respond to the instructions that have been sent to the processor.

It directs the operation of the other units by providing timing and control signals.
Most computer resources are managed by the CU. It directs the flow of data between the CPU and the other devices. John von Neumann included the control unit as part of the von Neumann architecture. In modern computer designs, the control unit is typically an internal part of the CPU with its overall role and operation unchanged since its introduction.

The Control unit (CU) is digital circuitry contained within the processor that coordinates the sequence of data movements into, out of, and between a processor's many sub-units. The result of these routed data movements through various digital circuits (sub-units) within the processor produces the manipulated data expected by a software instruction (loaded earlier, likely from memory). It controls (conducts) data flow inside the processor and additionally provides several external control signals to the rest of the computer to further direct data and instructions to/from processor external destinations (i.e. memory).

Examples of devices that require a CU are CPUs and graphics processing units (GPUs). The CU receives external instructions or commands which it converts into a sequence of control signals that the CU applies to the data path to implement a sequence of register-transfer level operations.

More precisely, the Control Unit (CU) is generally a sizable collection of complex digital circuitry interconnecting and directing the many execution units (i.e. ALU, data buffers, registers) contained within a CPU. The CU is normally the first CPU unit to accept from an externally stored computer program, a single instruction (based on the CPU's instruction set). The CU then decodes this individual instruction into several sequential steps (fetching addresses/data from registers/ memory, managing execution [i.e. data sent to the ALU or I/O], and storing the resulting data back into registers/memory) that controls and coordinates the CPU's inner works to properly manipulate the data. The design of these sequential steps are based on the needs of each instruction and can range in number of steps, the order of execution, and which units are enabled.

Thus by only using a program of set instructions in memory, the CU will configure all the CPU's data flows as needed to manipulate the data correctly between instructions. This results in a computer that could run a complete program and require no human intervention to make hardware changes between instructions (as had to be done when using only punch cards for computations before stored programmed computers with CUs were invented). These detailed steps from the CU dictate which of the CPU's interconnecting hardware control signals to enable/disable or which CPU units are selected/de-selected and the unit's proper order of execution as required by the instruction's operation to produce the desired manipulated data. Additionally, the CU's orderly hardware coordination properly sequences these control signals then configures the many hardware units comprising the CPU, directing how data should also be moved, changed, and stored outside the CPU (i.e. memory) according to the instruction's objective.

Depending on the type of instruction entering the CU, the order and number of sequential steps produced by the CU could vary the selection and configuration of which parts of the CPU's hardware are utilized to achieve the instruction's objective (mainly moving, storing, and modifying data within the CPU). This one feature, that efficiently uses just software instructions to control/select/configure a computer's CPU hardware (via the CU) and eventually manipulates a program's data, is a significant reason most modern computers are flexible and universal when running various programs. As compared to some 1930s or 1940s computers without a proper CU, they often required rewiring their hardware when changing programs. This CU instruction decode process is then repeated when the Program Counter is incremented to the next stored program address and the new instruction enters the CU from that address, and so on till the programs end.

Other more advanced forms of Control Units manage the translation of instructions (but not the data containing portion) into several micro-instructions and the CU manages the scheduling of the micro-instructions between the selected execution units to which the data is then channeled and changed according to the execution unit's function (i.e., ALU contains several functions). On some processors, the Control Unit may be further broken down into additional units, such as an instruction unit or scheduling unit to handle scheduling, or a retirement unit to deal with results coming from the instruction pipeline. Again, the Control Unit orchestrates the main functions of the CPU: carrying out stored instructions in the software program then directing the flow of data throughout the computer based upon these instructions (roughly likened to how traffic lights will systematically control the flow of cars [containing data] to different locations within the traffic grid [CPU] until it parks at the desired parking spot [memory address/register]. The car occupants [data] then go into the building [execution unit] and comes back changed in some way then get back into the car and returns to another location via the controlled traffic grid).

Hardwired control units are implemented through use of combinational logic units, featuring a finite number of gates that can generate specific results based on the instructions that were used to invoke those responses. Hardwired control units are generally faster than the microprogrammed designs.

Their design uses a fixed architecture—it requires changes in the wiring if the instruction set is modified or changed.
This architecture is preferred in reduced instruction 
set computers (RISC) as they use a simpler instruction set.

A controller that uses this approach can operate at high speed; however, it has little flexibility, and the complexity of the instruction set it can implement is limited.

The hardwired approach has become less popular as computers to have evolved. Previously, control units for CPUs used ad-hoc logic, and they were difficult to design.

The idea of microprogramming was introduced by Maurice Wilkes in 1951 as an intermediate level to execute computer program instructions. Microprograms were organized as a sequence of "microinstructions" and stored in special control memory. The algorithm for the microprogram control unit,unlike the hardwired control unit, is usually specified by flowchart description. The main advantage of the microprogram control unit is the simplicity of its structure. Outputs of the controller are organized in microinstructions and they can be easily replaced.



</doc>
<doc id="6558" url="https://en.wikipedia.org/wiki?curid=6558" title="Cello">
Cello

The cello ( ; plural celli or cellos) or violoncello ( ; ) is a bowed (and occasionally plucked) string instrument of the violin family. Its four strings are usually tuned in perfect fifths: from low to high, C, G, D and A, an octave lower than the viola. Music for the cello is generally written in the bass clef, with tenor clef and treble clef used for higher-range passages.

Played by a "cellist" or "violoncellist", it enjoys a large solo repertoire with and without accompaniment, as well as numerous concerti. The cello often plays the bass part, both in chamber music such as string quartets and the orchestra's string section, where the celli may be reinforced an octave lower by the double basses. Figured bass music of the Baroque-era typically assumes a cello, viola da gamba or bassoon as part of the basso continuo group alongside chordal instruments such as organ, harpsichord), lute or theorbo). Cellos are found in many other ensembles, from modern Chinese orchestras to cello rock bands. 

The name "cello" is derived from the ending of the Italian "violoncello", which means "little violone". Violone ("big viola") was a large-sized member of viol (viola da gamba) family or the violin (viola da braccio) family. The term "violone" today usually refers to the lowest-pitched instrument of the viols, a family of stringed instruments that went out of fashion around the end of the 17th century in most countries except England and, especially, France, where they survived another half-century before the louder violin family came into greater favour in that country as well. In modern symphony orchestras, it is the second largest stringed instrument (the double bass is the largest). Thus, the name "violoncello" contained both the augmentative ""-one"" ("big") and the diminutive ""-cello"" ("little"). By the turn of the 20th century, it had become common to shorten the name to 'cello, with the apostrophe indicating the missing stem. It is now customary to use "cello" without apostrophe as the full designation. "Viol" is derived from the root "viola", which was derived from Medieval Latin "vitula", meaning stringed instrument.

Cellos are tuned in fifths, starting with C (two octaves below middle C), followed by G, D, and then A. It is tuned in the same intervals as the viola, but an octave lower. Unlike the violin or viola but similar to the double bass, the cello has an endpin that rests on the floor to support the instrument's weight. The cello is most closely associated with European classical music, and has been described as the closest sounding instrument to the human voice. The instrument is a part of the standard orchestra, as part of the string section, and is the bass voice of the string quartet (although many composers give it a melodic role as well), as well as being part of many other chamber groups.

Among the most well-known Baroque works for the cello are Johann Sebastian Bach's six unaccompanied Suites. The cello possibly figures as a member of the basso continuo group in chamber works by Francesca Caccini (1587–1641), Barbara Strozzi (1619–1677) with pieces such as "Il primo libro di madrigali, per 2–5 voci e basso continuo, op. 1" and Elisabeth Jacquet de La Guerre (1665–1729) who wrote six sonatas for violin and basso continuo.

From the Classical era, the two concertos by Joseph Haydn in C major and D major stand out, as do the five sonatas for cello and pianoforte of Ludwig van Beethoven, which span the important three periods of his compositional evolution. A "Divertimento for Piano, Clarinet, Viola and Cello" is among the surviving works by Duchess Anna Amalia of Brunswick-Wolfenbüttel (1739–1807).

A review of compositions for cello in the Romantic era must include the German composer Fanny Mendelssohn (1805–1847) who wrote the Fantasy in G minor for cello and piano and a Capriccio in A-flat for cello. Other well-known works of the era include the Robert Schumann Concerto, the Antonín Dvořák Concerto as well as the two sonatas and the Double Concerto by Johannes Brahms.

Compositions from the late-19th and early 20th century include three cello sonatas (including the Cello Sonata in C Minor written in 1880) by Dame Ethel Smyth (1858–1944), Edward Elgar's Cello Concerto in E minor, Claude Debussy's Sonata for Cello and Piano, and unaccompanied cello sonatas by Zoltán Kodály and Paul Hindemith. Pieces including cello were written by American Music Cente founder Marion Bauer (1882–1955) (two trio sonatas for flute, cello and piano) and Ruth Crawford Seeger (1901–1953) (Diaphonic suite No. 2 for bassoon and cello).

Polish composer Grażyna Bacewicz (1909–1969) was writing for cello in the mid 20th century with Concerto No. 1 for Cello and Orchestra (1951), Concerto No. 2 for Cello and Orchestra (1963) and in 1964 composed her Quartet for four cellos. The cello's versatility made it popular with many male composers in this era as well, such as Sergei Prokofiev, Dmitri Shostakovich, Benjamin Britten, György Ligeti, Witold Lutoslawski and Henri Dutilleux.

Well-known cellists include Jacqueline du Pre, Raya Garbousova, Zara Nelsova, Hildur Gudnadottir, Han-Na Chang, Mstislav Rostropovich and Beatrice Harrison. Others include Anner Bylsma, Yo-Yo Ma, Pablo Casals, Julian Lloyd Webber, Alfred Wallenstein, Mischa Maisky and Gregor Piatigorsky. See the comprehensive list of cellists here.

In the 2010s, the instrument is found in popular music, but was more commonly used in 1970s pop and disco music. Today it is sometimes featured in pop and rock recordings, examples of which are noted later in this article. The cello has also appeared in major hip-hop and R & B performances, such as singers Rihanna and Ne-Yo's 2007 performance at the American Music Awards. The instrument has also been modified for Indian classical music by Nancy Lesh and Saskia Rao-de Haas.

The violin family, including cello-sized instruments, emerged c. 1500 as family of instruments distinct from the viola da gamba family. The earliest depictions of the violin family, from northern Italy c. 1530, show three sizes of instruments, roughly corresponding to what we now call violins, violas, and cellos. Contrary to a popular misconception, the cello did not evolve from the viola da gamba, but existed alongside it for about two and a half centuries. The violin family is also known as the viola da braccio (meaning viola of the arm) family, a reference to the primary way the members of the family are held. This is to distinguish it from the viola da gamba (meaning viola of the leg) family, in which all the members are all held with the legs. The likely predecessors of the violin family include the lira da braccio and the rebec. The earliest surviving cellos are made by Andrea Amati, the first known member of the celebrated Amati family of luthiers.

The direct ancestor to the violoncello was the bass violin. Monteverdi referred to the instrument as "basso de viola da braccio" in "Orfeo" (1607). Although the first bass violin, possibly invented as early as 1538, was most likely inspired by the viol, it was created to be used in consort with the violin. The bass violin was actually often referred to as a ""violone"", or "large viola", as were the viols of the same period. Instruments that share features with both the bass violin and the "viola da gamba" appear in Italian art of the early 16th century.

The invention of wire-wound strings (fine wire around a thin gut core), around 1660 in Bologna, allowed for a finer bass sound than was possible with purely gut strings on such a short body. Bolognese makers exploited this new technology to create the cello, a somewhat smaller instrument suitable for solo repertoire due to both the timbre of the instrument and the fact that the smaller size made it easier to play virtuosic passages. This instrument had disadvantages as well, however. The cello's light sound was not as suitable for church and ensemble playing, so it had to be doubled by organ, theorbo or violone.

Around 1700, Italian players popularized the cello in northern Europe, although the bass violin (basse de violon) continued to be used for another two decades in France. Many existing bass violins were literally cut down in size to convert them into cellos according to the smaller pattern developed by Stradivarius, who also made a number of old pattern large cellos (the 'Servais'). The sizes, names, and tunings of the cello varied widely by geography and time. The size was not standardized until around 1750.

Despite similarities to the viola da gamba, the cello is actually part of the viola da braccio family, meaning "viol of the arm", which includes, among others, the violin and viola. Though paintings like Bruegel's "The Rustic Wedding", and Jambe de Fer in his "Epitome Musical" suggest that the bass violin had alternate playing positions, these were short-lived and the more practical and ergonomic "a gamba" position eventually replaced them entirely.
Baroque-era cellos differed from the modern instrument in several ways. The neck has a different form and angle, which matches the baroque bass-bar and stringing. Modern cellos have an endpin at the bottom to support the instrument (and transmit some of the sound through the floor), while Baroque cellos are held only by the calves of the player. Modern bows curve in and are held at the frog; Baroque bows curve out and are held closer to the bow's point of balance. Modern strings normally have a metal core, although some use a synthetic core; Baroque strings are made of gut, with the G and C strings wire-wound. Modern cellos often have fine-tuners connecting the strings to the tailpiece, which make it much easier to tune the instrument, but such pins are rendered ineffective by the flexibility of the gut strings used on Baroque cellos. Overall, the modern instrument has much higher string tension than the Baroque cello, resulting in a louder, more projecting tone, with fewer overtones.

Few educational works specifically devoted to the cello existed before the 18th century, and those that do exist contain little value to the performer beyond simple accounts of instrumental technique. One of the earliest cello manuals is Michel Corrette's "Méthode, thèorique et pratique pour apprendre en peu de temps le violoncelle dans sa perfection" (Paris, 1741).

Cellos are part of the standard symphony orchestra, which usually includes eight to twelve cello players. The cello section, in standard orchestral seating, is located on stage left (the audience's right) in the front, opposite the first violin section. However, some orchestras and conductors prefer switching the positioning of the viola and cello sections. The "principal" cellist is the section leader, determining bowings for the section in conjunction with other string principals, playing solos and leading entrances (when the section begins to play its part). Principal players always sit closest to the audience.

The cellos are a critical part of orchestral music; all symphonic works involve the cello section, and many pieces require cello soli or solos. Much of the time, cellos provide part of the low-register harmony for the orchestra. Often, the cello section plays the melody for a brief period, before returning to the harmony role. There are also cello concertos, which are orchestral pieces that feature a solo cellist accompanied by an entire orchestra.

There are numerous cello concertos – where a solo cello is accompanied by an orchestra – notably 25 by Vivaldi, 12 by Boccherini, at least 3 by Haydn, 3 by C. P. E. Bach, 2 by Saint-Saëns, 2 by Dvořák, and one each by Robert Schumann], Lalo, and Elgar. There were also some cellists who, while not otherwise composers, did write cello-specific repertoire, such as Nikolaus Kraft who wrote six cello concertos. Beethoven's Triple Concerto for Cello, Violin and Piano and Brahms' Double Concerto for Cello and Violin are also part of the concertante repertoire although in both cases the cello shares solo duties with at least one other instrument. Moreover, several composers wrote large-scale pieces for cello and orchestra, which are concertos in all but name. Some familiar "concertos" are Richard Strauss' tone poem "Don Quixote", Tchaikovsky's "Variations on a Rococo Theme", Bloch's "Schelomo" and Bruch's "Kol Nidrei".

In the 20th century, the cello repertoire grew immensely. This was partly due to the influence of virtuoso cellist Mstislav Rostropovich, who inspired, commissioned and premiered dozens of new works. Among these, Prokofiev's "Symphony-Concerto", Britten's "Cello Symphony", the concertos of Shostakovich and Lutosławski as well as Dutilleux's "Tout un monde lointain..." have already become part of the standard repertoire. Other major composers who wrote concertante works for him include Messiaen, Jolivet, Berio and Penderecki. In addition, Arnold, Barber, Glass, Hindemith, Honegger, Ligeti, Myaskovsky, Penderecki, Rodrigo, Villa-Lobos and Walton also wrote major concertos for other cellists, notably for Gaspar Cassadó, Aldo Parisot, Gregor Piatigorsky, Siegfried Palm and Julian Lloyd Webber.

There are also many sonatas for cello and piano. Those written by Beethoven, Mendelssohn, Chopin, Brahms, Grieg, Rachmaninoff, Debussy, Fauré, Shostakovich, Prokofiev, Poulenc, Carter, and Britten are particularly well known.

Other important pieces for cello and piano include Schumann's five "Stücke im Volkston" and transcriptions like Schubert's Arpeggione Sonata (originally for arpeggione and piano), César Franck's Cello Sonata (originally a violin sonata, transcribed by Jules Delsart with the composer's approval), Stravinsky's "Suite italienne" (transcribed by the composer – with Gregor Piatigorsky – from his ballet "Pulcinella") and Bartók's first rhapsody (also transcribed by the composer, originally for violin and piano).

There are pieces for cello solo, J. S. Bach's six Suites for Cello (which are among the best-known solo cello pieces), Kodály's Sonata for Solo Cello and Britten's three Cello Suites. Other notable examples include Hindemith's and Ysaÿe's Sonatas for Solo Cello, Dutilleux's "Trois Strophes sur le Nom de Sacher", Berio's "Les Mots Sont Allés", Cassadó's Suite for Solo Cello, Ligeti's Solo Sonata, Carter's two "Figment"s and Xenakis' "Nomos Alpha" and "Kottos".

The cello is a member of the traditional string quartet as well as string quintets, sextet or trios and other mixed ensembles.
There are also pieces written for two, three, four or more cellos; this type of ensemble is also called a "cello choir" and its sound is familiar from the introduction to Rossini's William Tell Overture as well as Zaccharia's prayer scene in Verdi's Nabucco. Tchaikovsky's 1812 Overture also starts with a cello ensemble, with four cellos playing the top lines and two violas playing the bass lines. As a self-sufficient ensemble, its most famous repertoire is Villa-Lobos' first of his Bachianas Brasileiras for cello ensemble (the fifth is for soprano and 8 cellos). Other examples are Offenbach's cello duets, quartet, and sextet, Pärt's Fratres for 8 cellos and Boulez' "Messagesquisse" for 7 cellos, or even Villa-Lobos' rarely played "Fantasia Concertante" (1958) for 32 cellos. The 12 cellists of the Berlin Philharmonic Orchestra (or "the Twelve" as they have since taken to being called) specialize in this repertoire and have commissioned many works, including arrangements of well-known popular songs.

The cello is less common in popular music than in classical music. Several bands feature a cello in their standard line-up, e.g. Joe Kwon of The Avett Brothers. The more common use in pop and rock is to bring the instrument in for a particular song. In the 1960s, artists such as the Beatles and Cher used the cello in popular music, in songs such as The Beatles' "Yesterday", "Eleanor Rigby" and "Strawberry Fields Forever", and Cher's "Bang Bang (My Baby Shot Me Down)". "Good Vibrations" by the Beach Boys includes the cello in its instrumental ensemble, which includes a number of instruments unusual for this sort of music. Bass guitarist Jack Bruce, who had originally studied music on a performance scholarship for cello, played a prominent cello part in "As You Said" on Cream's "Wheels of Fire" studio album (1968).

In the 1970s, the Electric Light Orchestra enjoyed great commercial success taking inspiration from so-called "Beatlesque" arrangements, adding the cello (and violin) to the standard rock combo line-up and in 1978 the UK based rock band, Colosseum II, collaborated with cellist Julian Lloyd Webber on the recording "Variations". Most notably, Pink Floyd included a cello solo in their 1970 epic instrumental "Atom Heart Mother". Bass guitarist Mike Rutherford of Genesis was originally a cellist and included some cello parts in their "Foxtrot" album.

Established non-traditional cello groups include Apocalyptica, a group of Finnish cellists best known for their versions of Metallica songs, Rasputina, a group of cellists committed to an intricate cello style intermingled with Gothic music, the Massive Violins, an ensemble of seven singing cellists known for their arrangements of rock, pop and classical hits, Von Cello, a cello fronted rock power trio, Break of Reality who mix elements of classical music with the more modern rock and metal genre, Cello Fury, a cello rock band that performs original rock/classical crossover music, and Jelloslave, a Minneapolis-based Cello duo with two percussionists. These groups are examples of a style that has become known as cello rock. The crossover string quartet bond also includes a cellist. Silenzium and Cellissimo Quartet are Russian (Novosibirsk) groups playing rock and metal and having more and more popularity in Siberia. Cold Fairyland from Shanghai, China is using a cello along a Pipa as the main solo instrument to create East meets West progressive (folk) rock.

More recent bands using the cello are Clean Bandit, Aerosmith, The Auteurs, Nirvana, Oasis, Smashing Pumpkins, James, Talk Talk, Phillip Phillips, OneRepublic, and the baroque rock band Arcade Fire. An Atlanta-based trio, King Richard's Sunday Best, also uses a cellist in their lineup. So-called "chamber pop" artists like Kronos Quartet, The Vitamin String Quartet and Margot and the Nuclear So and So's have also recently made cello common in modern alternative rock. Heavy metal band System of a Down has also made use of the cello's rich sound. The indie rock band The Stiletto Formal are known for using a cello as a major staple of their sound, similarly, the indie rock band Canada employs two cello players in their lineup. The orch-rock group, The Polyphonic Spree, which has pioneered the use of stringed and symphonic instruments, employs the cello in very creative ways for many of their "psychedelic-esque" melodies. The first wave screamo band "I Would Set Myself On Fire For You" featured a cello as well as a viola to create a more folk-oriented sound. The band, Panic! at the Disco uses a cello in their song, "Build God, Then We'll Talk". The lead vocalist of the band, Brendon Urie, also did the recording of the cello solo. The Lumineers added cellist Nela Pekarek to the band in 2010. She plays cello, sings harmony and duets.

In jazz, bassists Oscar Pettiford and Harry Babasin were among the first to use the cello as a solo instrument; both tuned their instrument in fourths, an octave above the double bass. Fred Katz (who was not a bassist) was one of the first notable jazz cellists to use the instrument's standard tuning and arco technique. Contemporary jazz cellists include Abdul Wadud, Diedre Murray, Ron Carter, Dave Holland, David Darling, Lucio Amanti, Akua Dixon, Ernst Reijseger, Fred Lonberg-Holm, Tom Cora and Erik Friedlander. Modern musical theatre pieces like Jason Robert Brown's The Last Five Years, Duncan Sheik's Spring Awakening, Adam Guettel's Floyd Collins, and Ricky Ian Gordon's My Life with Albertine use small string ensembles (including solo cellos) to a prominent extent.

In Indian Classical music Saskia Rao-de Haas is a well established soloist as well as playing duets with her sitarist husband Pt. Shubhendra Rao. Other cellists performing Indian classical music are: Nancy Lesh (Dhrupad) and Anup Biswas. Both Rao and Lesh play the cello sitting cross-legged on the floor.

The cello can also be used in bluegrass and folk music, with notable players including Ben Sollee of the Sparrow Quartet and the "Cajun cellist" Sean Grissom, as well as Vyvienne Long who, in addition to her own projects, has played for those of Damien Rice. Cellists such as Natalie Haas, Abby Newton and Liz Davis Maxfield have contributed significantly to the use of cello playing in Celtic folk music, often with the cello featured as a primary melodic instrument and employing the skills and techniques of traditional fiddle playing. Lindsay Mac is becoming well known for playing the cello like a guitar, with her cover of The Beatles' "Blackbird".

The cello is typically made from carved wood, although other materials such as carbon fiber or aluminum may be used. A traditional cello has a spruce top, with maple for the back, sides, and neck. Other woods, such as poplar or willow, are sometimes used for the back and sides. Less expensive cellos frequently have tops and backs made of laminated wood. Laminated cellos are widely used in elementary and secondary school orchestras and youth orchestras, because they are much more durable than carved wood cellos (i.e., they are less likely to crack if bumped or dropped) and they are much less expensive.

The top and back are traditionally hand-carved, though less expensive cellos are often machine-produced. The sides, or ribs, are made by heating the wood and bending it around forms. The cello body has a wide top bout, narrow middle formed by two C-bouts, and wide bottom bout, with the bridge and F holes just below the middle. The top and back of the cello has decorative border inlay known as purfling. While purfling is attractive, it is also functional: if the instrument is struck, the purfling can prevent cracking of the wood. A crack may form at the rim of the instrument, but spreads no further. Without purfling, cracks can spread up or down the top or back. Playing, traveling and the weather all affect the cello and can increase a crack if purfling is not in place. Less expensive instruments typically have painted purfling.

Cello manufacturer Luis & Clark constructs cellos from carbon fibre. Carbon fibre instruments are particularly suitable for outdoor playing because of the strength of the material and its resistance to humidity and temperature fluctuations. Luis & Clark has produced over 1000 cellos, some of which are owned by cellists such as Yo-Yo Ma and Josephine van Lier. In the late 1920s and early 1930s, the Aluminum Company of America (Alcoa) as well as German luthier G.A. Pfretzschner produced an unknown number of aluminum cellos (in addition to aluminum double basses and violins).

Above the main body is the carved neck. The neck has a curved cross-section on its underside, which is where the player's thumb runs along the neck during playing. The neck which leads to a pegbox and the scroll. The neck, pegbox, and scroll are normally carved out of a single piece of wood, usually maple. The fingerboard is glued to the neck and extends over the body of the instrument. The fingerboard is given a curved shape, matching the curve on the bridge. Both the fingerboard and bridge need to be curved so that the performer can bow individual strings. If the cello were to have a flat fingerboard and bridge, as with a typical guitar, the performer would only be able to bow the "outer" two strings or bow all the strings. The performer would not be able to play the "inner" two strings alone.

The nut is a raised piece of wood, fitted where the fingerboard meets the pegbox, in which the strings rest in shallow slots or grooves to keep them the correct distance apart. The pegbox houses four tapered tuning pegs, one for each string. The pegs are used to tune the cello by either tightening or loosening the string. The pegs are called "friction pegs", because they maintain their position by friction. The scroll is a traditional ornamental part of the cello and a feature of all other members of the violin family. Ebony is usually used for the tuning pegs, fingerboard, and nut, but other hardwoods, such as boxwood or rosewood, can be used. Black fittings on low-cost instruments are often made from inexpensive wood that has been blackened or "ebonized" to look like ebony, which is much harder and more expensive. Ebonised parts such as tuning pegs may crack or split, and the black surface of the fingerboard will eventually wear down to reveal the lighter wood underneath.

Historically, cello strings had cores made out of catgut, which, despite its name is made from sheep or goat intestines which are dried out. Most modern strings used in the 2010s are wound with metallic materials like aluminum, titanium and chromium. Cellists may mix different types of strings on their instruments. The pitches of the open strings are C, G, D, and A (black note heads in the playing range figure above), unless alternative tuning (scordatura) is specified by the composer. Some composers (e.g. Ottorino Respighi in the final movement of ‘’The Pines of Rome’’) ask that the low C be tuned down to a B or B so that the performer can play a different low note on the lowest open string.

The tailpiece and endpin are found in the lower part of the cello. The tailpiece is the part of the cello to which the "ball ends" of the strings are attached by passing them through holes. The tailpiece is attached to the bottom of the cello. The tailpiece is traditionally made of ebony or another hard wood, but can also be made of plastic or steel on lower-cost instruments. It attaches the strings to the lower end of the cello, and can have one or more fine tuners. The fine tuners are used to make smaller adjustments to the pitch of the string. The fine tuners can increase the tension of each string (raising the pitch) or decrease the tension of the string (lowering the pitch). When the performer is putting on a new string, the fine tuner for that string is normally reset to a middle position, and then the peg is turned to bring the string up to pitch. The fine turners are used for subtle, minor adjustments to pitch, such as tuning a cello to the oboe's 440 Hz A note or to tune the cello to a piano.

The endpin or spike is made of wood, metal or rigid carbon fibre and supports the cello in playing position. The endpin can be retracted into the hollow body of the instrument when the cello is being transported in its case. This makes the cello easier to move about. When the performer wishes to play the cello, the endpin is pulled out to lengthen it. The endpin is locked into the player's preferred length with a screw mechanism. The adjustable nature of endpins enables performers of different ages and body sizes to adjust the endpin length to suit them. In the Baroque period the cello was held between the calves, as there was no endpin at that time. The endpin was "introduced by Adrien Servais 1845 to give the instrument greater stability". Modern endpins are retractable and adjustable; older ones were removed when not in use. (The word "endpin" sometimes also refers to the button of wood located at this place in all instruments in the violin family, but this is usually called "tailpin".) The sharp tip of the cello's endpin is sometimes capped with a rubber tip that protects the tip from dulling and prevents the cello from slipping on the floor. Many cellists use a rubber pad with a metal cup to keep the tip from slipping on the floor. A number of accessories to keep the endpin from slipping; these include ropes which attach to the chair leg and other devices.

The bridge holds the strings above the cello and transfers their vibrations to the top of the instrument and the soundpost inside (see below). The bridge is not glued, but rather held in place by the tension of the strings. The bridge is usually positioned by the cross point of the "f-hole" (i.e., where the horizontal line occurs in the "f"). The f-holes, named for their shape, are located on either side of the bridge, and allow air to move in and out of the instrument as part of the sound-production process. They probably actually stand for an old style medial S, for words related to Sound. The f-holes also act as access points to the interior of the cello for repairs or maintenance. Sometimes a small length of rubber hose containing a water-soaked sponge, called a Dampit, is inserted through the f-holes, and serves as a humidifier. This keeps the wood components of the cello from drying out.

Internally, the cello has two important features: a bass bar, which is glued to the underside of the top of the instrument, and a round wooden sound post, a solid wooden cylinder which is wedged between the top and bottom plates. The bass bar, found under the bass foot of the bridge, serves to support the cello's top and distribute the vibrations from the strings to the body of the instrument. The sound post, found under the treble side of the bridge, connects the back and front of the cello. Like the bridge, the sound post is not glued, but is kept in place by the tensions of the bridge and strings. Together, the bass bar and sound post transfer the strings' vibrations to the top (front) of the instrument (and to a lesser extent the back), acting as a diaphragm to produce the instrument's sound.

Cellos are constructed and repaired using hide glue, which is strong but reversible, allowing for disassembly when needed. Tops may be glued on with diluted glue, since some repairs call for the removal of the top. Theoretically, hide glue is weaker than the body's wood, so as the top or back shrinks side-to-side, the glue holding it lets go, so the plate does not crack. Cellists repairing cracks in their cello do not use regular wood glue, because it cannot be steamed open when a repair has to be made by a luthier.

Traditionally, bows are made from pernambuco or brazilwood. Both come from the same species of tree ("Caesalpinia echinata"), but pernambuco, used for higher-quality bows, is the heartwood of the tree and is darker in color than brazilwood (which is sometimes stained to compensate). Pernambuco is a heavy, resinous wood with great elasticity, which makes it an ideal wood for instrument bows. Horsehair is stretched out between the two ends of the bow. The taut horsehair is drawn over the strings to produce the cello's characteristic tone. A small knob is twisted to increase or decrease the tension of the horsehair. The tension on the bow is released when the instrument is not being used. The amount of tension a cellist puts on the bow hair depends on the preferences of the player, the style of music being played, and for students, the preferences of their teacher.

Bows are also made from other materials, such as carbon-fibre—stronger than wood—and fiberglass (often used to make inexpensive, lower-quality student bows). An average cello bow is long (shorter than a violin or viola bow) high (from the frog to the stick) and wide. The frog of a cello bow typically has a rounded corner like that of a viola bow, but is wider. A cello bow is roughly heavier than a viola bow, which in turn is roughly heavier than a violin bow. 

Bow hair is traditionally horsehair, though synthetic hair, in varying colors, is also used. Prior to playing, the musician tightens the bow by turning a screw to pull the frog (the part of the bow under the hand) back, and increase the tension of the hair. Rosin is applied by the player to make the hair sticky. Bows need to be re-haired periodically. Baroque style (1600–1750) cello bows were much thicker and were formed with a larger outward arch when compared to modern cello bows. The inward arch of a modern cello bow produces greater tension, which in turn gives off a louder sound.

The cello bow has also been used to play electric guitars. Jimmy Page pioneered its application on tracks such as "Dazed and Confused". The post-rock Icelandic band Sigur Rós's lead singer often plays a guitar using a cello bow.

In 1989, the German cellist Michael Bach began developing a curved bow, encouraged by John Cage, Dieter Schnebel, Mstislav Rostropovich and Luigi Colani: and since then many pieces have been composed especially for it. This curved bow ("BACH.Bow") is a convex curved bow which, unlike the ordinary bow, renders possible polyphonic playing on the various strings of the instrument. The solo repertoire for violin and cello by J. S. Bach the BACH.Bow is particularly suited to it: and it was developed with this in mind, polyphonic playing being required, as well as monophonic.

When a string is bowed or plucked, it vibrates and moves the air around it, producing sound waves. Because the string is quite thin, not much air is moved by the string itself, and consequently if the string was not mounted on a hollow body, the sound would be weak. In acoustic stringed instruments such as the cello, this lack of volume is solved by mounting the vibrating string on a larger hollow wooden body. The vibrations are transmitted to the larger body, which can move more air and produce a louder sound. Different designs of the instrument produces variations in the instrument’s vibrational patterns and thus changes the character of the sound produced. A string’s fundamental pitch can be adjusted by changing its stiffness, which depends on tension and length. Tightening a string stiffens it by increasing both the outward forces along its length and the net forces it experiences during a distortion. A cello can be tuned by adjusting the tension of its strings, by turning the tuning pegs mounted on its pegbox, and tension adjusters (fine tuners) on the tail piece.

A string’s length also affects its fundamental pitch. Shortening a string stiffens it by increasing its curvature during a distortion and subjecting it to larger net forces. Shortening the string also reduces its mass, but does not alter the mass per unit length, and it is the latter ratio rather than the total mass which governs the frequency. The string vibrates in a standing wave whose speed of propagation is given by , where "T" is the tension and "m" is the mass per unit length; there is a node at either end of the vibrating length, and thus the vibrating length "l" is half a wavelength. Since the frequency of any wave is equal to the speed divided by the wavelength, we have frequency = . (Note that some writers, including Muncaster (cited below) use the Greek letter "μ" in place of "m".) Thus shortening a string increases the frequency, and thus the pitch. Because of this effect, you can raise and change the pitch of a string by pressing it against the fingerboard in the cello’s neck and effectively shortening it. Likewise strings with less mass per unit length, if under the same tension, will have a higher frequency and thus higher pitch than more massive strings. This is a prime reason why the different strings on all string instruments have different fundamental pitches, with the lightest strings having the highest pitches.

A played note of E or F has a frequency which is often very close to the natural resonating frequency of the body of the instrument, and if the problem is not addressed this can set the body into near resonance. This may cause an unpleasant sudden amplification of this pitch, and additionally a loud beating sound results from the interference produced between these nearby frequencies; this is known as the “wolf tone” because it is an unpleasant growling sound. The wood resonance appears to be split into two frequencies by the driving force of the sounding string. These two periodic resonances beat with each other. This wolf tone must be eliminated or significantly reduced for the cello to play the nearby notes with a pleasant tone. This can be accomplished by modifying the cello front plate, attaching a wolf eliminator (a metal cylinder or a rubber cylinder encased in metal), or moving the sound post.
When a string is bowed or plucked to produce a note, the fundamental note is accompanied by higher frequency overtones. Each sound has a particular recipe of frequencies that combine to make the total sound.

Playing the cello is done while seated with the instrument supported on the floor by the endpin. The left hand fingertips stop the strings on the fingerboard, determining the pitch of the fingered note. The right hand plucks or bows the strings to sound the notes. The left hand fingertips stop the strings along their length, determining the pitch of each fingered note. Stopping the string closer to the bridge results in higher-pitched sound, because the vibrating string length has been shortened. In the "neck" positions (which use just less than half of the fingerboard, nearest the top of the instrument), the thumb rests on the back of the neck; in "thumb position" (a general name for notes on the remainder of the fingerboard) the thumb usually rests alongside the fingers on the string and the side of the thumb is used to play notes. The fingers are normally held curved with each knuckle bent, with the fingertips in contact with the string. If a finger is required on two (or more) strings at once to play perfect fifths (in double stops or chords) it is used flat. In slower, or more expressive playing, the contact point can move slightly away from the nail to the pad of the finger, allowing a fuller vibrato.

Vibrato is a small oscillation in the pitch of a note, usually considered expressive. Harmonics played on the cello fall into two classes; natural and artificial. Natural harmonics are produced by lightly touching (but not depressing) the string with the finger at certain places, and then bowing (or, rarely, plucking) the string. For example, the halfway point of the string will produce a harmonic that is one octave above the unfingered (open) string. Natural harmonics only produce notes that are part of the harmonic series on a particular string. Artificial harmonics (also called false harmonics or stopped harmonics), in which the player depresses the string fully with one finger while touching the same string lightly with another finger, can produce any note above middle C. 
Glissando (Italian for "sliding") is an effect played by sliding the finger up or down the fingerboard without releasing the string. This causes the pitch to rise and fall smoothly, without separate, discernible steps.

In cello playing, the bow is much like the breath of a wind instrument player. Arguably, it is the major determinant in the expressiveness of the playing. The right hand holds the bow and controls the duration and character of the notes. The bow is drawn across the strings roughly halfway between the end of the fingerboard and the bridge, in a direction perpendicular to the strings. The bow is held with all five fingers of the right hand, the thumb opposite the fingers and closer to the cellist's body. Tone production and volume of sound depend on a combination of several factors. The three most important ones are: bow speed, weight applied to the string, and point of contact of the bow hair with the string.

Double stops involve the playing of two notes at the same time. Two strings are fingered simultaneously, and the bow is drawn so as to sound them both at once. In pizzicato playing, the string is plucked directly with the fingers or thumb. Pizzicato is often abbreviated as "Pizz.". Position of the hand is slightly over the finger board and away from the bridge.

A player using the col legno technique strikes or rubs the strings with the wood of the bow rather than the hair. In spiccato playing, the strings are not "drawn" by the bow hair but struck by it, while still retaining some horizontal motion, to generate a more percussive, crisp sound. In staccato, the player moves the bow a small distance and stops it on the string, making a short sound, the rest of the written duration being taken up by silence. 
Legato is a technique where the notes are smoothly connected without accents or breaks. It is noted by a slur (curved line) above or below – depending on their position on the staff – the notes of the passage that is to be played legato.

"Sul ponticello" ("on the bridge") refers to bowing closer to the bridge, while "sul tasto" ("on the fingerboard") calls for bowing nearer the end of the fingerboard. Sul tasto produces a more flute-like sound, with more emphasis on the fundamental frequency of the note, and softer overtones.

Standard-sized cellos are referred to as "full-size" or "" but are also made in smaller (fractional) sizes (e.g. , , , , , , ). The fractions refer to volume rather than length, so a 1/2 size cello is much longer than half the length of a full size. The smaller cellos are identical to standard cellos in construction, range, and usage, but are simply scaled-down for the benefit of children and shorter adults.

Cellos in sizes larger than do exist, and cellists with unusually large hands may require such a non-standard instrument. Cellos made before approximately 1700 tended to be considerably larger than those made and commonly played today. Around 1680, changes in string-making technology made it possible to play lower-pitched notes on shorter strings. The cellos of Stradivari, for example, can be clearly divided into two models: the style made before 1702, characterized by larger instruments (of which only three exist in their original size and configuration), and the style made during and after 1707, when Stradivari began making smaller cellos. This later model is the design most commonly used by modern luthiers. The scale length of a cello is about . The new size offered fuller tonal projection and greater range of expression. The instrument in this form was able to contribute to more pieces musically and offered the possibility of greater physical dexterity for the player to develop technique.

There are many accessories for the cello.



Cellos are made by luthiers, specialists in building and repairing stringed instruments, ranging from guitars to violins. The following luthiers are notable for the cellos they have produced:

A person who plays the cello is called a "cellist". For a list of notable cellists, see the list of cellists and .

Careers in cello vary widely by genre and by region or country. Most cellists earn their living from a mixture of performance and teaching jobs. The first step to getting most performance jobs is by playing at an audition. In some styles of music, cellists may be asked to sight read printed music or perform standard repertoire with an ensemble.

In classical music, cellists audition for playing jobs in orchestras and for admission into university or Conservatory programs or degrees. At a classical cello audition, the performer typically plays a movement from a Bach suite or a movement from a concerto and a variety of excerpts from the orchestral literature. Orchestral auditions are typically held in front of a panel that includes the conductor, the Concertmaster, the Principal cellist and other principal players.

The most promising candidates are invited to return for a second or third round of auditions, which allows the conductor and the panel to compare the best candidates. Performers may be asked to sight read orchestral music. The final stage of the audition process in some orchestras is a "test week", in which the performer plays with the orchestra for a week or two, which allows the conductor and principal players to see if the individual can function well in an actual performance setting.

Performance jobs include playing as a freelancer in small groups, playing in a chamber music group, large ensembles, or performing solo music, either live onstage or as a session player for radio or TV broadcasts or for recordings; and working as the employee of an orchestra, big band, or recording studio. Many cello players find extra work by substituting ("subbing") for cellists who are double-booked or ill. It is hard for many cello players to be able to find full-time, full-year work at a single job. About the closest that a cellist can come to this is in the case of those who win an audition at a professional orchestra. Even full-time orchestra jobs do not usually last for the entire year. When the orchestra stops playing (which is often in the summer), orchestral cellists have to find other work, either as a teacher or coach, or in another group.

Teaching work for cellists includes giving private lessons in the home or at colleges and universities; coaching cellists who are preparing for recordings or auditions; doing group coaching at music camps or for youth ensembles; and working as a high school music teacher. Due to the limited number of full-time orchestral jobs, many classical cellists are not able to find full-time work with a single orchestra. Some cellists increase their employ-ability by learning several different styles, such as folk or pop.

In some cases, cellists supplement their performing and teaching income with other related music jobs, such as working as a stringed instrument repairer (luthier); as a contractor who hires musicians for orchestras or big bands, composing music, songwriting, conducting, or organizing festivals (e.g., Julian Armour).

Specific instruments are famous (or become famous) for a variety of reasons. An instrument's notability may arise from its age, the fame of its maker, its physical appearance, its acoustic properties, and its use by notable performers. The most famous instruments are generally known for all of these things. The most highly prized instruments are now collector's items, and are priced beyond the reach of most musicians. These instruments are typically owned by some kind of organization or investment group, which may loan the instrument to a notable performer. (For example, the Davidov Stradivarius, which is currently in the possession of one of the most widely known living cellists, Yo-Yo Ma, is actually owned by the Vuitton Foundation.)

Some notable cellos:







</doc>
<doc id="6559" url="https://en.wikipedia.org/wiki?curid=6559" title="Control store">
Control store

A control store is the part of a CPU's control unit that stores the CPU's microprogram. It is usually accessed by a microsequencer. Early types of control store took the form of diode-arrays that were accessed via address decoders, but were later implemented as writable microcode that was stored in a form of read-only memory called a writable control store. The outputs generally had to go through a register to prevent a race condition from occurring. The register was clocked by the clock signal of the system it was running on.

Early control stores were implemented as a diode-array accessed via address decoders, a form of read-only memory. This tradition dates back to the "program timing matrix" on the MIT Whirlwind, first described in 1947. Modern VLSI processors instead use matrices of field-effect transistors to build the ROM and/or PLA structures used to control the processor as well as its internal sequencer in a microcoded implementation. IBM System/360 used a variety of techniques: CCROS (Card Capacitor Read-Only Storage) on the Model 30, TROS (Transformer Read-Only Storage) on the Model 40, and BCROS (Balanced Capacitor Read-Only Storage) on the Model 50.

Some computers were built using "writable microcode" — rather than storing the microcode in ROM or hard-wired logic, the microcode was stored in a RAM called a "writable control store" or "WCS". Such a computer is sometimes called a "Writable Instruction Set Computer" or "WISC". Many of these machines were experimental laboratory prototypes, such as the WISC CPU/16 and the RTX 32P.

The original System/360 models of IBM mainframe had read-only control store, but later System/360, System/370 and successor models loaded part or all of their microprograms from floppy disks or other DASD into a writable control store consisting of ultra-high speed random-access read-write memory. The System/370 architecture included a facility called Initial-Microprogram Load (IML or IMPL) that could be invoked from the console, as part of Power On Reset (POR) or from another processor in a tightly coupled multiprocessor complex. This permitted IBM to easily repair microprogramming defects in the field. Even when the majority of the control store is stored in ROM, computer vendors would often sell writable control store as an option, allowing the customers to customize the machine's microprogram. Other vendors, e.g., IBM, use the WCS to run microcode for emulator features and hardware diagnostics.

Other commercial machines that used writable microcode include the Burroughs Small Systems (1970s and 1980s), the Xerox processors in their Lisp machines and Xerox Star workstations, the DEC VAX 8800 ("Nautilus") family, and the Symbolics L- and G-machines (1980s). Some DEC PDP-10 machines stored their microcode in SRAM chips (about 80 bits wide x 2 Kwords), which was typically loaded on power-on through some other front-end CPU. Many more machines offered user-programmable writable control stores as an option (including the HP 2100, DEC PDP-11/60 and Varian Data Machines V-70 series minicomputers).
The Mentec M11 and Mentec M1 stored its microcode in SRAM chips, loaded on power-on through another CPU.
The Data General Eclipse MV/8000 ("Eagle") had a SRAM writable control store, loaded on power-on through another CPU.

WCS offered several advantages including the ease of patching the microprogram and, for certain hardware generations, faster access than ROMs could provide. User-programmable WCS allowed the user to optimize the machine for specific purposes.

Some CPU designs compile the instruction set to a writable RAM or FLASH inside the CPU (such as the Rekursiv processor and the Imsys Cjip), or an FPGA (reconfigurable computing).

Several Intel CPUs in the x86 architecture family have writable microcode, starting with the Pentium Pro in 1995.
This has allowed bugs in the Intel Core 2 microcode and Intel Xeon microcode to be fixed in software, rather than requiring the entire chip to be replaced.
Such fixes can be installed by Linux, FreeBSD, Microsoft Windows, or the motherboard BIOS.

The control store usually has a register on its outputs. The outputs that go back into the sequencer to determine the next address have to go through some sort of register to prevent the creation of a race condition. In most designs all of the other bits also go through a register. This is because the machine will work faster if the execution of the next microinstruction is delayed by one cycle. This register is known as a pipeline register. Very often the execution of the next microinstruction is dependent on the result of the current microinstruction, which will not be stable until the end of the current microcycle. It can be seen that either way, all of the outputs of the control store go into one big register. Historically it used to be possible to buy EPROMs with these register bits on the same chip.

The clock signal determining the clock rate, which is the cycle time of the system, primarily clocks this register.



</doc>
<doc id="6561" url="https://en.wikipedia.org/wiki?curid=6561" title="Columba">
Columba

Saint Columba (, 'church dove'; ; 7 December 521 – 9 June 597) was an Irish abbot and missionary Evangelist credited with spreading Christianity in what is today Scotland at the start of the Hiberno-Scottish mission. He founded the important abbey on Iona, which became a dominant religious and political institution in the region for centuries. He is the Patron Saint of Derry. He was highly regarded by both the Gaels of Dál Riata and the Picts, and is remembered today as a Catholic saint and one of the Twelve Apostles of Ireland.

Colmcille studied under some of Ireland's most prominent church figures and founded several monasteries in the country. Around 563 he and his twelve companions crossed to Dunaverty near Southend, Argyll, in Kintyre before settling in Iona in Scotland, then part of the Ulster kingdom of Dál Riata, where they founded a new abbey as a base for spreading Celtic Christianity among the northern Pictish kingdoms who were pagan. He remained active in Irish politics, though he spent most of the remainder of his life in Scotland. Three surviving early medieval Latin hymns may be attributed to him.

Colmcille was born to Fedlimid and Eithne of the Cenel Conaill in Gartan, a district beside Lough Gartan, in Tír Chonaill (mainly modern County Donegal) in the north of Ireland. On his father's side, he was great-great-grandson of Niall of the Nine Hostages, an Irish high king of the 5th century. He was baptised in Temple-Douglas, in the County Donegal parish of Conwal (midway between Gartan and Letterkenny), by his teacher and foster-uncle Saint Crunathan. It is not known for sure if his name at birth was Colmcille or if he adopted this name later in life; Adomnán (Eunan) of Iona thought it was his birth name but other Irish sources have claimed his name at birth was Crimthann (meaning 'fox'). In the Irish language his name means 'dove', which is the same name as the Prophet Jonah (Jonah in Hebrew is also 'dove'), which Adomnán of Iona as well as other early Irish writers were aware of, although it is not clear if he was deliberately named after Jonah or not.
When sufficiently advanced in letters he entered the monastic school of Movilla, at Newtownards, under St. Finnian who had studied at St. Ninian's "Magnum Monasterium" on the shores of Galloway. He was about twenty, and a deacon when, having completed his training at Movilla, he travelled southwards into Leinster, where he became a pupil of an aged bard named Gemman. On leaving him, Colmcille entered the monastery of Clonard, governed at that time by Finnian, noted for sanctity and learning. Here he imbibed the traditions of the Welsh Church, for Finnian had been trained in the schools of St. David.

In early Christian Ireland the druidic tradition collapsed due to the spread of the new Christian faith. The study of Latin learning and Christian theology in monasteries flourished. Colmcille became a pupil at the monastic school at Clonard Abbey, situated on the River Boyne in modern County Meath. During the sixth century, some of the most significant names in the history of Celtic Christianity studied at the Clonard monastery. It is said that the average number of scholars under instruction at Clonard was 3,000. Colmcille was one of twelve students of St. Finnian who became known as the Twelve Apostles of Ireland. He became a monk and eventually was ordained a priest.

Another preceptor of Colmcille was St. Mobhi, whose monastery at Glasnevin was frequented by such famous men as St. Canice, St. Comgall, and St. Ciarán. A pestilence which devastated Ireland in 544 caused the dispersion of Mobhi's disciples, and Colmcille returned to Ulster, the land of his kindred. He was a striking figure of great stature and powerful build, with a loud, melodious voice which could be heard from one hilltop to another. The following years were marked by the foundation of several important monasteries: Derry, at the southern edge of Inishowen; Durrow, County Offaly; Kells, County Meath; and Swords. While at Derry it is said that he planned a pilgrimage to Rome and Jerusalem, but did not proceed farther than Tours. Thence he brought a copy of those gospels that had lain on the bosom of St. Martin for the space of 100 years. This relic was deposited in Derry.

Tradition asserts that, sometime around 560, he became involved in a quarrel with Saint Finnian of Movilla Abbey over a psalter. Colmcille copied the manuscript at the scriptorium under Saint Finnian, intending to keep the copy. Saint Finnian disputed his right to keep the copy. The dispute eventually led to the pitched Battle of Cúl Dreimhne in Cairbre Drom Cliabh (now in County Sligo) in 561, during which many men were killed. A second grievance that led him to induce the clan Neill to rise and engage in battle against King Diarmait at Cooldrevny in 561 was the king's violation of the right of sanctuary belonging to Colmcille's person as a monk on the occasion of the murder of Prince Curnan, the saint's kinsman. Prince Curnan of Connaught, who had fatally injured a rival in a hurling match and had taken refuge with Colmcille, was dragged from his protector's arms and slain by Diarmaid's men, in defiance of the rights of sanctuary.

A synod of clerics and scholars threatened to excommunicate him for these deaths, but St. Brendan of Birr spoke on his behalf with the result that he was allowed to go into exile instead. Colmcille's own conscience was uneasy, and on the advice of an aged hermit, Molaise, he resolved to expiate his offence by going into exile and win for Christ as many souls as had perished in the terrible battle of Cúl Dreimhne. He left Ireland, to return only once, many years later. Colmcille's copy of the psalter has been traditionally associated with the Cathach of St. Colmcille.

In 563, he travelled to Scotland with twelve companions (said to include Odran of Iona) in a wicker currach covered with leather. According to legend he first landed on the Kintyre Peninsula, near Southend. However, being still in sight of his native land, he moved farther north up the west coast of Scotland. The island of Iona was made over to him by his kinsman Conall mac Comgaill King of Dál Riata, who perhaps had invited him to come to Scotland in the first place. However, there is a sense in which he was not leaving his native people, as the Ulster Gaels had been colonising the west coast of Scotland for the previous couple of centuries. Aside from the services he provided guiding the only centre of literacy in the region, his reputation as a holy man led to his role as a diplomat among the tribes. There are also many stories of miracles which he performed during his work to convert the Picts, the most famous being his encounter with an unidentified animal that some have equated with the Loch Ness Monster in 565. It is said that he banished a ferocious "water beast" to the depths of the River Ness after it had killed a Pict and then tried to attack Colmcille's disciple named Lugne (see Vita Columbae Book 2 below). He visited the pagan King Bridei, King of Fortriu, at his base in Inverness, winning Bridei's respect, although not his conversion. He subsequently played a major role in the politics of the country. He was also very energetic in his work as a missionary, and, in addition to founding several churches in the Hebrides, he worked to turn his monastery at Iona into a school for missionaries. He was a renowned man of letters, having written several hymns and being credited with having transcribed 300 books. One of the few, if not the only, times he left Scotland was towards the end of his life, when he returned to Ireland to found the monastery at Durrow.

Colmcille died on Iona and was buried in 597 by his monks in the abbey he created. In 794 the Vikings descended on Iona. Colmcille's relics were finally removed in 849 and divided between Scotland and Ireland. The parts of the relics which went to Ireland are reputed to be buried in Downpatrick, County Down, with St. Patrick and St. Brigid or at Saul Church neighbouring Downpatrick. (Names of Iona), Inchcolm and Eilean Chaluim Chille.

Saint Colmcille is one of the three patron saints of Ireland, after Saint Patrick and Saint Brigid of Kildare.

Colmcille is the patron-saint of the city of Derry, where he founded a monastic settlement in c. 540. The name of the city in Irish is "Doire Colmcille" and is derived from the native oak trees in the area and the city's association with Colmcille. The Catholic Church of Saint Colmcille's Long Tower, and the Church of Ireland St Augustine's Church both claim to stand at the spot of this original settlement. The Church of Ireland Cathedral in Derry is dedicated to St Colmcille.

St. Columba's Primary School in Drumcondra is a girl's school named after the saint.
St. Colmcille's Primary School and St. Colmcille's Community School are two schools in Knocklyon, Dublin, named after him, with the former having an annual day dedicated to the saint on 9 June.

The town of Swords, Dublin was reputedly founded by Saint Colmcille in 560 AD. St Colmcille’s Boys’ National School and St. Colmcille’s Girls’ National School, both located in the town of Swords, are also named after the saint.

The Columba Press, a religious and spiritual book company based in Dublin, is named after St. Colmcille.

Aer Lingus, Ireland's national flag carrier has named one of its Airbus A330 aircraft in commemoration of the saint (reg: EI-DUO).

Colmcille is credited as being a leading figure in the revitalisation of monasticism. The Clan Malcolm/Clan McCallum claims its name from Colmcille and was reputedly founded by the descendants of his original followers. It is also said that Clan Robertson Clan Donnachaidh / Duncan are heirs of Colmcille. Clan MacKinnon may also have some claim to being spiritual descendants of St Colmcille as after he founded his monastery on Isle Iona, the MacKinnons were the abbots of the Church for centuries. This would also account for the fact that Clan MacKinnon is amongst the ancient clans of Scotland.

The cathedral of the Catholic Diocese of Argyll and the Isles is placed under the patronage of St. Colmcille, as are numerous Catholic schools and parishes throughout the nation. The Scottish Episcopal Church, the Church of Scotland, and the Evangelical Lutheran Church of England also have parishes dedicated to him. The village of Kilmacolm in Renfrewshire is also derived from Colmcille's name.

St Columba's Hospice, a prominent hospice in Edinburgh, is named after the saint.

Saint Colmcille currently has two poems attributed to him: "Adiutor Laborantium" and "Altus Prosator". Both poems are examples of Abecedarian hymns in Latin written while Colmcille was at the Iona Abbey.

The shorter of the two poems, "Adiutor Laborantium" consists of twenty-seven lines of eight syllables each, with each line following the format of an Abecedarian hymn using the Classical Latin alphabet save for lines 10-11 and 25-27. The content of the poem addresses God as a helper, ruler, guard, defender and lifter for those who are good and an enemy of sinners whom he will punish.

"Altus Prosator" consists of twenty-three stanzas sixteen syllables long, with the first containing seven lines and six lines in each subsequent stanza. It uses the same format and alphabet as "Adiutor Laborantium" except with each stanza starting with a different letter rather than each line. The poem tells a story over three parts split into the beginning of time, history of Creation, and the Apocalypse or end of time.

As of 2011, Canadians who are of Scottish ancestry are the third largest ethnic group in the country and thus Columba's name is to be found attached to Catholic, Anglican and Presbyterian parishes. This is particularly the case in eastern Canada, apart from French-speaking Quebec.

Throughout the US there are numerous parishes within the Catholic and Episcopalian denominations dedicated to Colmcille. Within the Protestant tradition the Presbyterian Church (which has its roots in Scottish Presbyterianism) also has parishes named in honour of Colmcille. There is even an Orthodox Church monastery dedicated to the saint in the Massachusetts town of Southbridge. St. Colmcille is the Patron Saint of the Roman Catholic Diocese of Youngstown, Ohio. The Cathedral there is named for him.

Iona College, a small Catholic liberal arts college in New Rochelle, New York, is named after the island on which Colmcille established his first monastery in Scotland, as is Iona College in Windsor, Ontario, Iona Presentation College, Perth, and Iona College Geelong in Charlemont, Victoria.

There are at least four pipe bands named for him; one each from Tullamore, Ireland, from Derry, Northern Ireland, from Kearny, New Jersey, and from Cape Cod, Massachusetts.

St. Columba's School one of the most prominent English-Medium schools in India run by the Irish Christian Brothers is also named after the Saint.

The Munich GAA is named München Colmcilles.

St. Colmcille's Feast Day, 9 June, has been designated as International Celtic Art Day. The Book of Kells and the Book of Durrow, great medieval masterpieces of Celtic art, are associated with Colmcille.

The main source of information about Saint Colmcille's life is the Vita Columbae (i.e. "Life of Colmcille"), a hagiography written in the style of "saint's lives" narratives that had become widespread throughout medieval Europe. Compiled and drafted by scribes and clergymen, these accounts were written in Latin and served as written collections of the deeds and miracles attributed to the saint, both during his or her life or after death. The canonization of a saint, especially one who had lived on the fringes of the medieval Christian world like Saint Colmcille, required a well-written hagiography to be submitted to Rome, but popular belief and local cults of sainthood often led to the veneration of these men and women without official approval from the Church.

Writing a century after the death of Saint Colmcille, the author Adomnán (also known as Eunan), served as the ninth Abbot of Iona until his death in 704. James Earle Fraser asserts that Adomnán drew extensively from an existing body of accounts regarding the life of Saint Colmcille, including a Latin collection entitled "De uirtutibus sancti Columbae", composed c. 640 A.D. This earlier work is attributed to Cummene Find, who became the abbot of Iona and served as the leader of the monastic island community from 656 until his death in 668 A.D. or 669 A.D.

While the Vita Columbae often conflicts with contemporaneous accounts of various battles, figures, and dates, it remains the most important surviving work from early medieval Scotland and provides a wealth of knowledge regarding the Picts and other ethnic and political groups from this time period. The Vita also offers a valuable insight into the monastic practices of Iona and the daily life of the early medieval Gaelic monks.

The surviving manuscripts include:


Instead of relying on chronological order, Adomnán categorises the events recorded in the "Vita Columbae" into three different books: Columba’s Prophecies, Columba’s Miracles, and Columba’s Apparitions.

In the first book, the author Adomnán lists Saint Colmcille's prophetic revelations, which come as a result of the saint's ability to view the present and the future simultaneously. Most of the short chapters begin with Saint Colmcille informing his fellow monks that a person will soon arrive on the island or an event will imminently occur.

In one notable instance, Colmcille appears in a dream to King Oswald of Northumbria, and announces the king's incoming victory against the King Catlon (Cadwallon of Wales) in the Battle of Heavenfield. The people of Britain promise to convert to Christianity and receive baptism after the conclusion of the war. This victory signals the re-Christianizing of pagan England, and establishes King Oswald as ruler of the entirety of Britain.

Colmcille's other prophecies include when he sends a man named Batain off to perform his penance, but then Colmcille turns to his friends and says Batain will instead return to Scotia and be killed by his enemies. Several of Saint Colmcille's prophecies reflect the scribal culture in which he was immersed, such his miraculous knowledge of the missing letter "I” from Baithene's psalter or when he prophecies that an eager man will knock over his inkhorn and spill its contents.

In the second book, Colmcille performs various miracles such as healing people with diseases, expelling malignant spirits, subduing wild beasts, calming storms, and even returning the dead to life. He also performs agricultural miracles that would hold a special significance to the common people of Ireland and the Britain such as when he casts a demon out of a pail and restores the spilt milk to its container.

The Vita contains a story that has been interpreted as the first reference to the Loch Ness Monster. According to Adomnán, Colmcille came across a group of Picts burying a man who had been killed by the monster. Colmcille saves a swimmer from the monster with the sign of the Cross and the imprecation, "Thou shalt go no further, nor touch the man; go back with all speed." The beast flees, terrified, to the amazement of the assembled Picts who glorified Colmcille's God. Whether or not this incident is true, Adomnan's text specifically states that the monster was swimming in the River Ness – the river flowing from the loch – rather than in Loch Ness itself.

In book three, Adomnán describes different apparitions of the Saint, both that Colmcille receives and those that are seen by others regarding him. He mentions that, "For indeed after the lapse of many years, ... St. Colmcille was excommunicated by a certain synod for some pardonable and very trifling reasons, and indeed unjustly" (P.79- 80).

In one of the accounts, Saint Colmcille, in this period of excommunication, goes to a meeting held against him in Teilte. Saint Brendán, despite of all the negative reactions among the seniors toward Colmcille, kisses him reverently and assures that Colmcille is the man of God and that he sees Holy Angels accompanying Colmcille on his journey through the plain.

In the last Chapter, Colmcille foresees his own death when speaking to his attendant: This day in the Holy Scriptures is called the Sabbath, which means rest. And this day is indeed a Sabbath to me, for it is the last day of my present laborious life, and on it I rest after the fatigues of my labours; and this night at midnight, which commenceth the solemn Lord's Day, I shall, according to the sayings of Scripture, go the way of our fathers. For already my Lord Jesus Christ deigneth to invite me; and to Him, I say, in the middle of this night shall I depart, at His invitation. For so it hath been revealed to me by the Lord himself. 

And when the bell strikes midnight, Colmcille goes to the church and kneels beside the altar. His attendant witnesses heavenly light in the direction of Colmcille, and Holy angels join the saint in his passage to the Lord: And having given them his holy benediction in this way, he immediately breathed his last. After his soul had left the tabernacle of the body, his face still continued ruddy, and brightened in a wonderful way by his vision of the angels, and that to such a degree that he had the appearance, not so much of one dead, as of one alive and sleeping. 

Both the "Vita Columbae" and the Venerable Bede (672/673-735) record Colmcille's visit to Bridei. Whereas Adomnán just tells us that Colmcille visited Bridei, Bede relates a later, perhaps Pictish tradition, whereby the saint actually converts the Pictish king. Another early source is a poem in praise of Colmcille, most probably commissioned by Colmcille's kinsman, the King of the Uí Néill clan. It was almost certainly written within three or four years of Colmcille's death and is the earliest vernacular poem in European history. It consists of 25 stanzas of four verses of seven syllables each, called the Amra Coluim Chille.

Through the reputation of its venerable founder and its position as a major European centre of learning, Colmcille's Iona became a place of pilgrimage. Colmcille is historically revered as a warrior saint, and was often invoked for victory in battle.
His relics were finally removed in 849 and divided between Alba and Ireland. Relics of Colmcille were carried before Scottish armies in the reliquary made at Iona in the mid-8th century, called the Brecbennoch. Legend has it that the Brecbennoch was carried to the Battle of Bannockburn (24 June 1314) by the vastly outnumbered Scots army and the intercession of Colmcille helped them to victory. Since the 19th century the "Brecbennoch of St. Columba" has been identified with the Monymusk Reliquary, although this is now doubted by scholars.

In the Antiphoner of Inchcolm Abbey, the "Iona of the East" (situated on an island in the Firth of Forth), a 14th-century prayer begins "O Columba spes Scotorum..." "O Columbus, hope of the Scots".





 


</doc>
<doc id="6562" url="https://en.wikipedia.org/wiki?curid=6562" title="Conditional proof">
Conditional proof

A conditional proof is a proof that takes the form of asserting a conditional, and proving that the antecedent of the conditional necessarily leads to the consequent. 

The assumed antecedent of a conditional proof is called the conditional proof assumption (CPA). Thus, the goal of a conditional proof is to demonstrate that if the CPA were true, then the desired conclusion necessarily follows. The validity of a conditional proof does not require that the CPA be actually true, only that "if it were true" it would lead to the consequent.

Conditional proofs are of great importance in mathematics. Conditional proofs exist linking several otherwise unproven conjectures, so that a proof of one conjecture may immediately imply the validity of several others. It can be much easier to show a proposition's truth to follow from another proposition than to prove it independently.

A famous network of conditional proofs is the NP-complete class of complexity theory. There are a large number of interesting tasks, and while it is not known if a polynomial-time solution exists for any of them, it is known that if such a solution exists for any of them, one exists for all of them. Similarly, the Riemann hypothesis has a large number of consequences already proven.

As an example of a conditional proof in symbolic logic, suppose we want to prove A → C (if A, then C) from the first two premises below:




</doc>
<doc id="6563" url="https://en.wikipedia.org/wiki?curid=6563" title="Conjunction introduction">
Conjunction introduction

Conjunction introduction (often abbreviated simply as conjunction and also called and introduction) is a valid rule of inference of propositional logic. The rule makes it possible to introduce a conjunction into a logical proof. It is the inference that if the proposition "p" is true, and proposition "q" is true, then the logical conjunction of the two propositions "p and q" is true. For example, if it's true that "it's raining", and it's true that "I'm inside", then it's true that "it's raining and I'm inside". The rule can be stated:

where the rule is that wherever an instance of "formula_2" and "formula_3" appear on lines of a proof, a "formula_4" can be placed on a subsequent line.

The "conjunction introduction" rule may be written in sequent notation:

where formula_2 and formula_3 are propositions expressed in some formal system, and formula_8 is a metalogical symbol meaning that formula_4 is a syntactic consequence if formula_2 and formula_3 are each on lines of a proof in some logical system;


</doc>
<doc id="6566" url="https://en.wikipedia.org/wiki?curid=6566" title="English in the Commonwealth of Nations">
English in the Commonwealth of Nations

The use of the English language in most member countries of the Commonwealth of Nations was inherited from British colonisation. Mozambique is an exception – although English is widely spoken there, it is a former Portuguese colony which joined the Commonwealth in 1996. English is spoken as a first or second language in most of the Commonwealth. In a few countries, such as Cyprus and Malaysia, it does not have official status, but is widely used as a lingua franca.

Many regions, notably Canada, Australia, India, New Zealand, Pakistan, South Africa, Hong Kong, Malaysia, Brunei, Singapore, Sri Lanka and the Caribbean, have developed their own native varieties of the language, primarily at the spoken and informal written level.

These varieties of English are sometimes collectively called Commonwealth English; this term may have originated with the 1962 publication of "Aid to Commonwealth English", a TEFL resource, by the British Council. In practical usage, the term usually includes the original British English, as well as Irish English and Hong Kong English (despite neither country being a member of the Commonwealth), but often excludes Canadian English, which has many distinct features due to amalgamation with American English and influences from French.

Written English as used in the Commonwealth generally favours British spelling as opposed to American, with some exceptions in Canada, where there is a strong influence from neighbouring American English (collectively, the US and Canadian dialects form North American English). Few Commonwealth countries besides Canada and Australia have produced their own dictionaries and style guides from major publishers, and rely on those produced in the United Kingdom, especially for formal writing.

The report of the Inter-Governmental Group on Criteria for Commonwealth Membership states that English is a symbol of Commonwealth heritage and unity.

Southern Hemisphere native varieties of English began to develop during the 18th century, with the colonisation of Australasia and South Africa. Australian English and New Zealand English are closely related to each other, and share some similarities with South African English (though it has unique influences from indigenous African languages, and Dutch influences it inherited along with the development of Afrikaans from Dutch). The vocabularies of these dialects draw from both British English (in the main) and American English (especially for recent terminology), as well as numerous native peculiarities.

Canadian English contains elements of British English and American English, as well as many Canadianisms and some French influences. It is the product of several waves of immigration and settlement, from Britain, Ireland, France, the United States, and around the world, over a period of almost two centuries. Modern Canadian English has taken significant vocabulary and spelling from the shared political and social institutions of Commonwealth countries.

Caribbean English is influenced by the English-based Creole varieties spoken, but they are not one and the same. There is a great deal of variation in the way English is spoken, with a "Standard English" at one end of a bipolar linguistic continuum and Creole languages at the other. These dialects have roots in 17th-century British and Irish English, and African languages, plus localised influences from other colonial languages including French, Spanish, and Dutch; unlike most native varieties of English, West Indian dialects often tend to be syllable-timed rather than stress-timed.

Second-language varieties of English in Africa and Asia have often undergone "indigenisation"; that is, each English-speaking community has developed (or is in the process of developing) its own standards of usage, often under the influence of local languages. These dialects are sometimes referred to as "New Englishes" (McArthur, p. 36); most of them inherited non-rhoticity from Southern British English.

Several dialects of West African English exist, with a lot of regional variation and some influence from indigenous languages. West African English tends to be syllable-timed, and its phoneme inventory is much simpler than that of received pronunciation; this sometimes affects mutual intelligibility with native varieties of English. A distinctive East African English, often with significant influences from Bantu languages such as Swahili, is spoken in countries such as Kenya or Tanzania, particularly in Nairobi and other cities where there is an expanding middle class, for whom English is increasingly being used in the home as the first language.

Small communities of native English speakers can be found in Zimbabwe, Botswana, and Namibia; the dialects spoken are similar to native South African English.

India has the largest English-speaking population in the Commonwealth, although comparatively few speakers of Indian English are first-language speakers. The same is true of English spoken in other parts of South Asia, e.g. Pakistani English, and Bangladeshi English. South Asian English phonology is highly variable; stress, rhythm and intonation are generally different from those of native varieties. There are also several peculiarities at the levels of morphology, syntax and usage, some of which can also be found among educated speakers.

Southeast Asian English comprises Singapore English, Malaysian English, and Brunei English; it features some influence from Malay and Chinese languages, as well as Indian English.

Hong Kong ceased to be part of the Commonwealth in 1997. Nonetheless, the English language there still enjoys status as an official language.


Other languages:




</doc>
<doc id="6569" url="https://en.wikipedia.org/wiki?curid=6569" title="Charles McCarry">
Charles McCarry

Charles McCarry (June 14, 1930 – February 26, 2019) was an American writer, primarily of spy fiction, and a former undercover operative for the Central Intelligence Agency whom "The Wall Street Journal" described in 2013 as "the dean of American spy writers"; "The New Republic" magazine calls him "poet laureate of the CIA."; and Otto Penzler says he has produced some "poetic masterpieces". William Zinsser calls him a "political novelist:" Jonathan Yardley, Pulitzer Prize-winning critic for the "Washington Post", calls him a "'serious' novelist" whose work may include "the best novel ever written about life in high-stakes Washington, DC." P.J. O'Rourke called him "the best modern writer on the subject of intrigue." O'Rourke learned about McCarry from a working covert operative who called McCarry "very realistic."

His family from The Berkshires area of western Massachusetts, McCarry was born in Pittsfield and he lived in Virginia.

McCarry believed that "the best novels are about ordinary things: love, betrayal, death, trust, loneliness, marriage, fatherhood." He also said "if you write a political novel, you're writing what you believe instead of what you know."

McCarry said, "the themes of my novels have been ordinary things – love, death, betrayal and the American dream."

McCarry's books are not thrillers; thrillers maintain suspense mostly by letting the reader know more than does the character being depicted; e,g, someone with a knife is waiting in the dark room. In contrast, as you read a Paul Christopher novel, you rarely see or know anything that Christopher does not see and know.

In a 1988 essay published in the Washington "Post", McCarry wrote, "[I]n 1973 when I turned in the manuscript of my novel "The Tears of Autumn", [the publisher] summoned me to New York and, in his office high above lower Park Avenue, banged the manuscript on his desk."This book is talky, it's slow, and nobody is going to believe a goddamn word of the plot," he said. "Where's the car chase? Where's the torture scene? Where's the sex? Where's the good Russian? Do you call this a thriller?"
"No," I said. He didn't hear me."

McCarry wrote that: "After I resigned [from the CIA], intending to spend the rest of my life writing fiction and knowing what tricks the mind can play when the gates are thrown wide open, as they are by the act of writing, between the imagination and that part of the brain in which information is stored, I took the precaution of writing a closely remembered narrative of my clandestine experiences. After correcting the manuscript, I burned it.
What I kept for my own use was the atmosphere of secret life: How it worked on the five senses and what it did to the heart and mind. All the rest went up in flames, setting me free henceforth to make it all up. In all important matters, such as the creation of characters and the invention of plots, with rare and minor exceptions, that is what I have done. And, as might be expected, when I have been weak enough to use something that really happened as an episode in a novel, it is that piece of scrap, buried in a landfill of the imaginary, readers invariably refuse to believe."

Throughout McCarry's fiction are statements and descriptions such as "the average intelligence officer is a sort of latter-day Marcel Proust. He lies abed in a cork-lined room, hoping to profit by secrets that other people slip under the door."

Snippets from McCarry's CIA years can be found in his non-fiction writing for newspapers. For example, "In the early days of the cold war, a colleague of mine who had worked his way through college playing the saxophone was recruited by a certain United States intelligence agency. For his first assignment, he was posted to Cambodia and told to find an apartment near the royal palace, open the windows at night, and play “Muskrat Ramble.” Prince Sihanouk, the eccentric ruler of the country, was reputed to be an amateur musician who loved jazz and had his own band. Who knew but what he might hear that plaintive sax in the jungle night and invite the nice young American to come on over and sit in?"

McCarry's first published novel came out in 1973, which means he was 43; in contrast, most successful novelists have their first novel published while they are still in their twenties.

A critic for "Tin House" magazine approaches McCarry through what the critic calls "the art of the sentence," citing as an example a description in the opening pages of McCarry's "The Secret Lovers": “The sun shone feebly through the overcast, like a lamp covered by a woman’s scarf in a shabby hotel room.”

A recurrent statement found in McCarry's non-fiction writing is that events in real life are so strange that if presented as fiction no one would believe them.

McCarry's novels were all republished in 2005—which means major critics revisited his work—some of which was more than a third-of-a-century old Rereading "The Tears of Autumn" one critic called it "a perfect spy novel."

McCarry said in 1995, "If I had to do it over again, I would have written novels about a pediatrician, anonymously." Why? Because he thinks of himself as a novelist, not a writer of spy fiction. And yet, almost of his novels—including the non-Paul Christopher books—have a strong focus on espionage.

McCarry began his writing career in the United States Army as a correspondent for "Stars and Stripes". Afterwards, in the 1950s, serving as a speechwriter in the early Administration of President Dwight D. Eisenhower; a typical McCarry item was the 1953 Labor Day Proclamation, which read, in part, "Free American labor has won for itself the enjoyment of a standard of living unmatched in history. The contemporary world knows no comparison with it. There is only brutal contrast to it. To this, there is no more pitiful and dramatic testimony than the food which this free people has been able to send to feed hundreds of thousands suffering the peculiar torments of the proletarian paradise of Eastern Germany." In the late 1950s, he accepted a post with the CIA for whom he traveled the globe as a deep cover operative—his son, Nathan McCarry, CEO of Pluribus International Corporation, in 2014 described his father's work for the CIA as "trying for the family." He left the CIA, in 1967, becoming a writer of spy novels McCarry rarely spoke or wrote directly about those years, saying simply, "For a decade at the height of the Cold War, I worked abroad under cover as an intelligence agent."

In the mid-to-late 1970s, several books by former CIA operatives helped trigger and fuel what became known as the U.S. Senate Church Committee hearings that resulted in legislation limiting the power and secrecy of the CIA. McCarry had been "outed"—publicly identified as a secret CIA operative—in 1975, but was never called to testify.

McCarry was editor-at-large for "National Geographic" and contributed pieces to "The New York Times", "The Wall Street Journal", "The Washington Post", the "Saturday Evening Post," and other national publications.

In as essay published by the "Washington Post", he says that "for a writer in America, going out to dinner is like living as an American in Europe: Total strangers think they can say anything they like to you."


Ten of McCarry's novels involve the life story of a fictional character named Paul Christopher, who — in McCarry's telling — grew up in pre-Nazi Germany, and later became a lone operative for a U.S. government entity that is clearly the Central Intelligence Agency.

These books are, in order of publication:

Alternately, in chronological order of events depicted:

The Paul Christopher novels, together and separately, resemble a Christopher Nolan movie in that time sequences become jumbled; e.g. only as Paul Christopher becomes an old man do readers learn about his parents and childhood.

One critic notes that “As far as recurring characters go, one must look to John Updike’s ‘Rabbit’ Angstrom books or Philip Roth's Nathan Zuckerman novels for equivalents in the scope and breadth of what McCarry accomplishes with one character and his movements through the events of the twentieth century.” 

"It’s tempting to say that Charles McCarry’s "The Tears of Autumn" is the greatest espionage novel ever written by an American, if only because it’s hard to conceive of one that could possibly be better. But since no one can claim to have read every America espionage novel ever written, let’s just say that "The Tears of Autumn" is a perfect spy novel, and that its hero, Paul Christopher, should by all rights be known the world over as the thinking man’s James Bond — and woman’s too."—Brendan Bernard, "The Great American Spy Novel," March 31, 2005', LA Weekly"

""Old Boys" is a large yarn that will make yummy reading between long looks at Nantucket Sound this summer. (And a boffo movie in the right hands.) But it is a tale that travels from the outlandish to the absurd. As long as readers don't expect the taut realism we have come to expect from the man, they'll be fine. If they're looking for vintage McCarry, though, this will produce unhappy campers. The book does not approach his better grownup fiction. It is not in the same league, for example, with "The Miernik Dossier", the small gem that made McCarry's career. Rather, it is something of a "Treasure Island" for lovers of spook fiction, a near-juvenile adventure that entrances adults who know better with fabulous writing. What they do get is a fleeting reprise of McCarry's great creation, Paul Christopher. Christopher, the spy whom many first met in McCarry's bestseller "The Tears of Autumn", is now an opaque older man and an ascetic survivor of a Chinese prison camp."--Sam Allis, "McCarry's thriller 'Old Boys' is a trip past believable," Boston "Globe", July 26, 2004.

McCarry's most recent work has been cited for its "postmodern skepticism" and "epistemic aporia"--"literary reconstruction that profess to unmask" state-sponsored secrecy. These judgments are based on the work of Robert Snyder.

In 2007, novelist and former presidential speechwriter Patrick Andersson wrote that “a new generation of American spy novelists soon began [in the 1970s] to produce a body of work that has surpassed that of current British writers. The four most important are Charles McCarry, Robert Littell, Daniel Silva, and Alan Furst” 

--"...the most credible account of President Kennedy’s assassination. You will believe it’s what really happened."--"New York" magazine on "Tears of Autumn"—In "Lucky Bastards", JFK seems to have an illegitimate son. In real life, no such person is known to exist.

--In "Tears", Paul Christopher wakes up ten days after the JFK killing and intuitively and instantly knows "who had arranged the death of the President"—the family and followers of recently assassinated South Vietnamese leader Ngo Dinh Diem and his two brothers. In real life, the wife of one of Diem's murdered brothers attracted media attention for predicting the JFK assassination ("Anything that happens in Vietnam will find its equivalent in the United States"), and later telling reporters that JFK had got what he deserved.—JFK is the only real-life President mentioned by name in a McCarry novel.

--McCarry was a top aide to Henry Cabot Lodge, traveling with him as chief speechwriter in 1960, for example, when Lodge was the Republican Party's vice presidential candidate. After losing the election, Lodge served as U.S. Ambassador to South Vietnam under JFK, and in that capacity played an active role in the plot to assassinate Diem—which McCarry used as the center of action in "The Tears of Autumn".

Note: In McCarry's fiction, the CIA is called "the Outfit."




—Computer algorithms that analyses media content and specify—with accuracy—when a physical war between two countries will break out. "The Better Angels", 1979.—Terrorist suicide bombers appear in "Better Angels" (1979); the "New York Times" first reported this form of terrorism in 1983, when describing the Lebanese civil war. Suicide terrorists use fully loaded passenger planes as weapons in "Better Angels"—which did not occur in real life until September 11, 2001.

--Suicide bombers begin to blow themselves up at American iconic sites like the Alamo. The Lincoln Memorial and Rotunda of the U.S. Capitol soon follow.—On June 10. 2004, the "Wall Street Journal" published a review entitled, "He Has Seen The Future: It's in His Work; Charles McCarry's novels keep coming true. And his new book is about the end of the world."—Someone who thinks he is JFK's "love child" becomes President of the U.S..--"Lucky Bastard"

--"ARK" (2004) has people equipped with "artificial hornets as their primary defensive weapon;" as of 2017, experts discuss the impending possibility of "drones the size of bumblebees that could be programmed to kill certain people, or certain categories of people, by grabbing their skulls with tiny metal talons and drilling into their head."—Worsening and more frequent earthquakes and severe storms like hurricanes threaten society in "Ark".

--Soviet KGB has long-term operative control over a person who becomes President of the U.S.-- "Lucky Bastard"—A thirty-person expedition (15 men and 15 women) lands on Ganymede, one of Jupiter's moons--"The Better Angels", p. 164.

After the collapse of the USSR, McCarry turned to China in "The Shanghai Factor", "Old Boys", "Second Sight" and "Last Supper".

—Jacob Heilbrunn writes in the "N.Y. Times" (2006): "McCarry never succumbs to a bogus moral equivalence in which Western operatives are as nefarious as their Communist counterparts. He instructs us that the real problem is not so much moral quicksand as incompetent scheming. At a moment when the C.I.A.'s travails are evoking nostalgia for a golden age when it supposedly operated effectively, McCarry offers a useful reminder that such an era never existed."

--"The truth, once discovered, is of no use: people deny what they have done, forget what they had believed, and make the same mistakes over and over again."—Paul Christopher is eating dinner with a beautiful young woman in wartime Saigon. They discuss the morality of killing. "So you believe in nothing," she says to him. "I believe in consequences," he responds.--"Tears of Autumn"

--"You think the truth will make men free. But it only makes them angry."--"Tears of Autumn".




McCarry challenged accepted wisdom about JFK by hypothesizing that Kennedy caused his own death; asserting that efforts to force Richard Nixon from the White House constituted a coup.; and giving Ronald Reagan credit for triggering the collapse of the Soviet Union.

Paul Christopher, as a central character never is older than his forties—see "Tears of Autumn"—which is the same after McCarry was when he wrote it; after Tears, Christopher spends twenty (unseen) years at hard labor in a remote Chinese prison camp, and then is a minor character in his own rescue.

The novelist Alan Furst has written in "The Book of Spies" that "[Graham] Greene, [John] le Carré, [Somerset] Maugham, and McCarry write with a kind of cloaked anger, a belief that the world is a place where political power is maintained by treachery and betrayal..." In its subtitle, Furst's book calls such writing "literary espionage."



"Your name is the one key thing that cannot be taken from you," says Jan Scruggs, founder of the Vietnam Veterans Memorial, "It captures who you are and what happens to you throughout your life." In Existentialist literature, lack of a name—or of a full name—symbolizes human aloneness; the hero of Franz Kafka's "The Trial", for example is "Michael K.," and the hero of Ralph Ellison's
"Invisible Man" has no name at all. Named characters fill McCarry's last three novels, but each book's hero (in one case, heroine) never has a name; one has a "funny name" that is used for payroll and administrative paperwork, but is fictitious and meaningless. While McCarry's heroes with no name are different people in each story, the Man with No Name in three Clint Eastwood movies from the mid-1960s is the same person.

The film "Wrong is Right" (1982), starring Sean Connery, was loosely based on McCarry's novel, "The Better Angels" (1979).

Paul Christopher, J. D. Salinger's Holden Caulfield, and J. P. Donleavy's Sebastion Dangerfield in "The Ginger Man" (1955) are among the post-World War II literary heroes who have stymied Hollywood efforts to depict them.

McCarry is an admirer of the work of W. Somerset Maugham, especially the stories. He was also an admirer of Richard Condon, author of "The Manchurian Candidate" (1959), "Prizzi's Honor" (1982), and numerous other novels.


--Stories include: In March 1981, shortly after taking office, Ronald Reagan was shot; Secretary of State Haig appeared in the White House press room and announced, "I am in charge here!"

Otto Penzler, ed.:



Note: The fictional Paul Christopher had several books of poetry published before he joined the CIA;




</doc>
<doc id="6571" url="https://en.wikipedia.org/wiki?curid=6571" title="Cimbri">
Cimbri

The Cimbri (Greek κίμβροι, Latin Cimbri) were an ancient tribe. They are generally believed to have been a Germanic tribe originating in Jutland, but Celtic influences have also been suggested.

Together with the Teutones and the Ambrones, they fought the Roman Republic between 113 and 101 BC. The Cimbri were initially successful, particularly at the Battle of Arausio, in which a large Roman army was routed, after which they raided large areas in Gaul and Hispania. In 101 BC, during an attempted invasion of Italy, the Cimbri were decisively defeated by Gaius Marius, and their king, Boiorix, was killed. Some of the surviving captives are reported to have been among the rebelling gladiators in the Third Servile War.

The origin of the name "Cimbri" is unknown. One etymology is PIE ' "inhabitant", from ' "home" (> English "home"), itself a derivation from "" "live" (> Greek , Latin "sinō"); then, the Germanic *"himbra-" finds an exact cognate in Slavic "sębrъ" "farmer" (> Croatian, Serbian "sebar", Russian сябёр "syabyor").

The name has also been related to the word "kimme" meaning “rim”, i.e., "the people of the coast". Finally, since Antiquity, the name has been related to that of the Cimmerians.

"Himmerland" (Old Danish "Himbersysel") is generally thought to preserve their name; "Cimbri" with a "c" would be an older form without Grimm's law (PIE "k" > Germ. "h"). Alternatively, Latin "c-" represents an attempt to render the unfamiliar Proto-Germanic "h" = (Latin "h" was but was becoming silent in common speech at the time), perhaps due to Celtic-speaking interpreters (a Celtic intermediary would also explain why Germanic *"Þeuðanōz" became Latin "Teutones").

Because of the similarity of the names, the Cimbri have been at times associated with Cymry, the Welsh name for themselves. However, "Cymry" is derived from Brittonic *"Kombrogi", meaning “compatriots”, and is linguistically unrelated to Cimbri.

The Cimbri are generally believed to have been a Germanic tribe originating in Jutland. Though Celtic origins have been suggested, this is controversial.

Archaeologists have not found any clear indications of a mass migration from Jutland in the early Iron Age. The Gundestrup Cauldron, which was deposited in a bog in Himmerland in the 2nd or 1st century BC, shows that there was some sort of contact with southeastern Europe, but it is uncertain if this contact can be associated with the Cimbrian expedition.

Advocates for a northern homeland point to Greek and Roman sources that associate the Cimbri with the Jutland peninsula. According to the "Res gestae" (ch. 26) of Augustus, the Cimbri were still found in the area around the turn of the 1st century AD:

The contemporary Greek geographer Strabo testified that the Cimbri still existed as a Germanic tribe, presumably in the "Cimbric peninsula" (since they are said to live by the North Sea and to have paid tribute to Augustus):

On the map of Ptolemy, the "Kimbroi" are placed on the northernmost part of the peninsula of Jutland., i.e., in the modern landscape of Himmerland south of Limfjorden (since Vendsyssel-Thy north of the fjord was at that time a group of islands).

Some time before 100 BC many of the Cimbri, as well as the Teutons and Ambrones migrated south-east. After several unsuccessful battles with the Boii and other Celtic tribes, they appeared ca 113 BC in Noricum, where they invaded the lands of one of Rome's allies, the Taurisci.

On the request of the Roman consul Gnaeus Papirius Carbo, sent to defend the Taurisci, they retreated, only to find themselves deceived and attacked at the Battle of Noreia, where they defeated the Romans. Only a storm, which separated the combatants, saved the Roman forces from complete annihilation.

Now the road to Italy was open, but they turned west towards Gaul. They came into frequent conflict with the Romans, who usually came out the losers. In Commentarii de Bello Gallico the Aduaticii—Belgians of Cimbrian origin—repeatedly sided with Rome's enemies. In 109 BC, they defeated a Roman army under the consul Marcus Junius Silanus, who was the commander of Gallia Narbonensis. In 107 BC they defeated another Roman army under the consul Gaius Cassius Longinus, who was killed at the Battle of Burdigala (modern day Bordeaux) against the Tigurini, who were allies of the Cimbri.

It was not until 105 BC that they planned an attack on the Roman Republic itself. At the Rhône, the Cimbri clashed with the Roman armies. Discord between the Roman commanders, the proconsul Quintus Servilius Caepio and the consul Gnaeus Mallius Maximus, hindered Roman coordination and so the Cimbri succeeded in first defeating the legate Marcus Aurelius Scaurus and later inflicted a devastating defeat on Caepio and Maximus at the Battle of Arausio. The Romans lost as many as 80,000 men, according to Livy; Mommsen (in his "History of Rome") thought that excluded auxiliary cavalry and non-combatants who brought the total loss closer to 112,000. Other estimates are much smaller, but by any account a large Roman army was routed.

Rome was in panic, and the "terror cimbricus" became proverbial. Everyone expected to soon see the "new Gauls" outside of the gates of Rome. Desperate measures were taken: contrary to the Roman constitution, Gaius Marius, who had defeated Jugurtha, was elected consul and supreme commander for five years in a row (104–100 BC).

In 104–103 BC, the Cimbri had turned to the Iberian Peninsula where they pillaged far and wide, until they were confronted by a coalition of Celtiberians. Defeated, the Cimbri returned to Gaul, where they joined their allies, the Teutons. During this time C. Marius had the time to prepare and, in 102 BC, he was ready to meet the Teutons and the Ambrones at the Rhône. These two tribes intended to pass into Italy through the western passes, while the Cimbri and the Tigurines were to take the northern route across the Rhine and later across the Central Eastern Alps.

At the estuary of the Isère, the Teutons and the Ambrones met Marius, whose well-defended camp they did not manage to overrun. Instead, they pursued their route, and Marius followed them. At Aquae Sextiae, the Romans won two battles and took the Teuton king Teutobod prisoner.

The Cimbri had penetrated through the Alps into northern Italy. The consul Quintus Lutatius Catulus had not dared to fortify the passes, but instead he had retreated behind the river Po, and so the land was open to the invaders. The Cimbri did not hurry, and the victors of Aquae Sextiae had the time to arrive with reinforcements. At the Battle of Vercellae, at the confluence of the river Sesia with the Po, in 101 BC, the long voyage of the Cimbri also came to an end.

It was a devastating defeat, two chieftains, Lugius and Boiorix, died on the field, while the other chieftains Caesorix and Claodicus were captured. The women killed both themselves and their children in order to avoid slavery. The Cimbri were annihilated, although some may have survived to return to the homeland where a population with this name was residing in northern Jutland in the 1st century AD, according to the sources quoted above. Some of the surviving captives are reported to have been among the rebelling gladiators in the Third Servile War.

However, Justin's epitome of Trogus, 38.4, has Mithridates the Great state that the Cimbri are ravaging Italy while the Social War is going on, i.e. at some time in 90–88 BCE, thus more than a decade later, after having sent ambassadors to the Cimbri to request military aid; judging from the context they must then have been living in North Eastern Europe at the time.

According to Julius Caesar, the Belgian tribe of the Atuatuci "was descended from the Cimbri and Teutoni, who, upon their march into our province and Italy, set down such of their stock and stuff as they could not drive or carry with them on the near (i.e. west) side of the Rhine, and left six thousand men of their company there as guard and garrison" ("Gall." 2.29, trans. Edwards). They founded the city of Atuatuca in the land of the Belgic Eburones, whom they dominated. Thus Ambiorix king of the Eburones paid tribute and gave his son and nephew as hostages to the Atuatuci ("Gall." 6.27). In the first century AD, the Eburones were replaced or absorbed by the Germanic Tungri, and the city was known as Atuatuca Tungrorum, i.e. the modern city of Tongeren.

The population of modern-day Himmerland claims to be the heirs of the ancient Cimbri. The adventures of the Cimbri are described by the Danish Nobel Prize–winning author Johannes V. Jensen, himself born in Himmerland, in the novel "Cimbrernes Tog" (1922), included in the epic cycle "Den lange Rejse" (English "The Long Journey", 1923). The so-called Cimbrian bull ("Cimbrertyren"), a sculpture by Anders Bundgaard, was erected on 14 April 1937 in a central town square in Aalborg, the capital of the region of North Jutland.

A German ethnic minority speaking the Cimbrian language, having settled in the mountains between Vicenza, Verona, and Trento in Italy (also known as Seven Communities), is also called the . For hundreds of years this isolated population and its present 4,400 inhabitants have claimed to be the direct descendants of the Cimbri retreating to this area after the Roman victory over their tribe. However, it is more likely that Bavarians settled here in the Middle Ages. Most linguists remain committed to the hypothesis of a medieval (11th to 12th century AD) immigration to explain the presence of small German-speaking communities in the north of Italy. Some genetic studies seem to prove a Celtic, not Germanic, descent for most inhabitants in the region that is reinforced by Gaulish toponyms such as those ending with the suffix "-ago" < Celtic "-*ako(n)" (e.g. Asiago is clearly the same place name as the numerous variants – Azay, Aisy, Azé, Ezy – in France, all of which derive from "*Asiacum" < Gaulish "*Asiāko(n)"). On the other hand, the original place names in the region, from the specifically localized language known as 'Cimbro' are still in use alongside the more modern names today. These indicate a different origin (e.g., Asiago is known also by its original Cimbro name of "Sleghe"). The Cimbrian origin myth was popularized by humanists in the 14th century.

Despite these connections to southern Germany, belief in a Himmerland origin persisted well into modern times. On one occasion in 1709, for instance, Frederick IV of Denmark paid the region's inhabitants a visit and was greeted as their king. The population, which kept its independence during the time of the Venice Republic, was later severely devastated by World War I. As a result, many Cimbri have left this mountainous region of Italy, effectively forming a worldwide diaspora.

The Cimbri are depicted as ferocious warriors who did not fear death. The host was followed by women and children on carts. Aged women, priestesses, dressed in white sacrificed the prisoners of war and sprinkled their blood, the nature of which allowed them to see what was to come.

Strabo gives this vivid description of the Cimbric folklore:

If the Cimbri did in fact come from Jutland, evidence that they practiced ritualistic sacrifice may be found in the Haraldskær Woman discovered in Jutland in the year 1835. Noosemarks and skin piercing were evident and she had been thrown into a bog rather than buried or cremated. Furthermore, the Gundestrup cauldron, found in Himmerland, may be a sacrificial vessel like the one described in Strabo's text. In style, the work looks like Thracian silver work, while many of the engravings are Celtic objects.

A major problem in determining whether the Cimbri were speaking a Celtic language or a Germanic language is that at this time the Greeks and Romans tended to refer to all groups to the north of their sphere of influence as Gauls, Celts, or Germani rather indiscriminately. Caesar seems to be one of the first authors to distinguish the two groups, and he had a political motive for doing so (it was an argument in favour of the Rhine border). Yet, one cannot always trust Caesar and Tacitus when they ascribe individuals and tribes to one or the other category, although Caesar made clear distinctions between the two cultures. Most ancient sources categorize the Cimbri as a Germanic tribe, but some ancient authors include the Cimbri among the Celts.

There are few direct testimonies to the language of the Cimbri: Referring to the Northern Ocean (the Baltic or the North Sea), Pliny the Elder states: "Philemon says that it is called Morimarusa, i.e. the Dead Sea, by the Cimbri, until the promontory of Rubea, and after that Cronium." The contemporary Gaulish terms for “sea” and “dead” appear to have been "mori" and "*maruo-"; compare their well-attested modern Insular Celtic cognates "muir" and "marbh" (Irish), "môr" and "marw" (Welsh), and "mor" and "marv" (Breton). The same word for “sea” is also known from Germanic, but with an "a" (*"mari-"), whereas a cognate of "marbh" is unknown in all dialects of Germanic. Yet, given that Pliny had not heard the word directly from a Cimbric informant, it cannot be ruled out that the word is in fact Gaulish instead.

The known Cimbri chiefs have Celtic names, including Boiorix (which may mean "King of the Boii" or, more literally, "King of Strikers"), Gaesorix (which means "Spear King"), and Lugius (which may be named after the Celtic god Lugus). Other evidence to the language of the Cimbri is circumstantial: thus, we are told that the Romans enlisted Gaulish Celts to act as spies in the Cimbri camp before the final showdown with the Roman army in 101 BC.

Jean Markale wrote that the Cimbri were associated with the Helvetii, and more especially with the indisputably Celtic Tigurini. These associations may link to a common ancestry, recalled from two hundred years previous, though they may not. Henri Hubert states "All these names are Celtic, and they cannot be anything else". Some authors take a different perspective.

Countering the argument of a Celtic origin is the literary evidence that the Cimbri originally came from northern Jutland, an area with no Celtic placenames, instead only Germanic ones. This does not rule out Cimbric Gallicization during the period when they lived in Gaul. Boiorix, who may have a Celtic name if not a Celticized Germanic name, was king of the Cimbri after they moved away for their ancestral home of northern Jutland; Boiorix and his tribe lived around Celtic peoples during his era as J. B. Rives points out in his introduction to Tacitus's "Germania" and moreover that the name "Boiorix" can work in Proto-Germanic as well as Celtic.




</doc>
<doc id="6576" url="https://en.wikipedia.org/wiki?curid=6576" title="Cleveland Browns">
Cleveland Browns

The Cleveland Browns are a professional American football team based in Cleveland, Ohio. The Browns compete in the National Football League (NFL) as a member club of the American Football Conference (AFC) North division. The Browns play their home games at FirstEnergy Stadium, which opened in 1999, with administrative offices and training facilities in Berea, Ohio. The Browns' official colors are brown, orange, and white. They are unique among the 32 member franchises of the NFL in that they do not have a logo on their helmets.

The franchise was founded in 1945 by businessman Arthur B. McBride and coach Paul Brown as a charter member of the All-America Football Conference (AAFC). The Browns dominated the AAFC, compiling a 47–4–3 record in the league's four seasons and winning its championship in each. When the AAFC folded after the 1949 season, the Browns joined the National Football League along with the San Francisco 49ers and the original Baltimore Colts. The Browns won a championship in their inaugural NFL season, as well as in the 1954, 1955, and 1964 seasons, and in a feat unequaled in any of the North American major professional sports, played in their league championship game in each of the Browns' first ten years of existence. From 1965 to 1995, they made the playoffs 14 times, but did not win another championship or appear in the Super Bowl during that period.

In 1995, owner Art Modell, who had purchased the Browns in 1961, announced plans to move the team to Baltimore. After threats of legal action from the city of Cleveland and fans, a compromise was reached in early 1996 that allowed Modell to establish the Baltimore Ravens as a new franchise while retaining the contracts of all Browns personnel. The Browns' intellectual property, including team name, logos, training facility, and history, were kept in trust and the franchise was regarded by the NFL as suspended, with a new team to be established by 1999 either by expansion or relocation. The Browns were announced as an expansion team in 1998 and resumed play in 1999.

Since resuming operations in 1999, the Browns have struggled to find success. They have had only two winning seasons (in 2002 and 2007), one playoff appearance (2002), and no playoff wins. The franchise has also been noted for a lack of stability with quarterbacks, having started 30 players in the position since 1999. Through the end of the 2018 season, the Browns' win–loss record since returning to the NFL in 1999 is 95–224–1. In 2017, the Browns became only the second team in league history to finish a season 0–16, joining the 2008 Detroit Lions. Through the 2018 season, the Browns hold the longest active playoff drought in the NFL, at 16 seasons.

The history of the Cleveland Browns American football team began in 1944 when taxi-cab magnate Arthur B. "Mickey" McBride secured a Cleveland franchise in the newly formed All-America Football Conference (AAFC). Paul Brown was the team's namesake and first coach. The Browns began play in 1946 in the AAFC. The Browns won each of the league's four championship games before the league dissolved in 1949. The team then moved to the more established National Football League (NFL), where it continued to dominate. Between 1950 and 1955, Cleveland reached the NFL championship game every year, winning three times.

McBride and his partners sold the team to a group of Cleveland businessmen in 1953 for a then-unheard-of $600,000. Eight years later, the team was sold again, this time to a group led by New York advertising executive Art Modell. Modell fired Brown before the 1963 season, but the team continued to win behind running back Jim Brown. The Browns won the championship in 1964 and reached the title game the following season, losing to the Green Bay Packers.

When the AFL and NFL merged before the 1970 season, Cleveland became part of the new American Football Conference (AFC). While the Browns made it back to the playoffs in 1971 and 1972, they fell into mediocrity through the mid-1970s. A revival of sorts took place in 1979 and 1980, when quarterback Brian Sipe engineered a series of last-minute wins and the Browns came to be called the "Kardiac Kids". Under Sipe, however, the Browns did not make it past the first round of the playoffs. Quarterback Bernie Kosar, who the Browns drafted in 1985, led the team to three AFC Championship games in the late 1980s but lost each time to the Denver Broncos. In 1995, Modell announced he was relocating the Browns to Baltimore, sowing a mix of outrage and bitterness among Cleveland's dedicated fan base. Negotiations and legal battles led to an agreement where Modell was allowed to move the team, but Cleveland kept the Browns' name, colors and history.

After three years of suspension while Cleveland Stadium was demolished and FirstEnergy Stadium built on its site, the Browns started play again in 1999 under new owner Al Lerner. The Browns struggled throughout the 2000s and 2010s, posting a record of 95–224–1 () since their 1999 return. The Browns have only posted two winning seasons and one playoff appearance (2002) since returning to the NFL. The team's struggles have been magnified since 2012, when the Lerner family sold the team to businessman Jimmy Haslam. In six seasons under the Haslam ownership, the Browns went through four head coaches and four general managers, none of whom had found success. In 2016 and 2017 under head coach Hue Jackson, the Browns went 1–31 () (including a winless 0–16 season in 2017), the worst two-year stretch in NFL history, and received the number one overall draft pick in both of those years.

The Browns are the only National Football League team without a helmet logo. The logoless helmet serves as the Browns' official logo. The organization has used several promotional logos throughout the years; players' numbers were painted on the helmets from the 1957 to 1960; and an unused "CB" logo was created in 1965, But for much of their history, the Browns' helmets have been an unadorned burnt orange color with a top stripe of dark brown (officially called "seal brown") divided by a white stripe.

The team has had various promotional logos throughout the years, such as the "Brownie Elf" mascot or a Brown "B" in a white football. While Art Modell did away with the Brownie Elf in the mid-1960s, believing it to be too childish, its use has been revived under the current ownership. The popularity of the Dawg Pound section at First Energy Stadium has led to a brown and orange dog being used for various Browns functions. But overall, the orange, logo-less helmet continues as the primary trademark of the Cleveland Browns.

On February 24, 2015, the team unveiled its new logos and word marks, the only differences being minor color changes to the helmet with the helmet design remaining largely as is.

The original designs of the jerseys, pants, and socks remained mostly the same, but the helmets went through many significant revisions throughout the years. The Browns uniforms saw their first massive change prior to the 2015 season.

Jerseys:

Pants: 

Socks: 

Helmet: Solid white (1946–1949); solid white for day games and solid orange for night games (1950–1951); orange with a single white stripe (1952–1956); orange with a single white stripe and brown numerals on the sides (1957–1959); orange with a brown-white-brown stripe sequence and brown numerals on the sides (1960); orange with a brown-white-brown stripe sequence (1961–1995 and 1999–present).

Over the years, the Browns have had on-and-off periods of wearing white for their home games, particularly in the 1970s and 80s, as well as in the early 2000s after the team returned to the league. Until recently, when more NFL teams have started to wear white at home at least once a season, the Browns were the only non-subtropical team north of the Mason-Dixon line to wear white at home on a regular basis.

Secondary numerals (called "TV numbers") first appeared on the jersey sleeves in 1961. Over the years, there have been minor revisions to the sleeve stripes, the first occurring in 1968 (brown jerseys worn in early season) and 1969 (white and brown jerseys) when stripes began to be silk screened onto the sleeves and separated from each other to prevent color bleeding. However, the basic five-stripe sequence has remained intact (with the exception of the 1984 season). A recent revision was the addition of the initials "AL" to honor team owner Al Lerner who died in 2002; this was removed in 2013 upon Jimmy Haslam assuming ownership of the team.

Orange pants with a brown-white-brown stripe sequence were worn from 1975 to 1983 and become symbolic of the "Kardiac Kids" era. The orange pants were worn again occasionally in 2003 and 2004.

Other than the helmet, the uniform was completely redesigned for the 1984 season. New striping patterns appeared on the white jerseys, brown jerseys and pants. Solid brown socks were worn with brown jerseys and solid orange socks were worn with white jerseys. Brown numerals on the white jerseys were outlined in orange. White numerals on the brown jerseys were double outlined in brown and orange. (Orange numerals double outlined in brown and white appeared briefly on the brown jerseys in one pre-season game.) However, this particular uniform set was not popular with the fans, and in 1985 the uniform was returned to a look similar to the original design. It remained that way until 1995.

In 1999, the expansion Browns adopted the traditional design with two exceptions: first, the TV numbers, previously on the sleeves, were moved to the shoulders; and second, the orange-brown-orange pants stripes were significantly widened.

Experimentation with the uniform design began in 2002. An alternate orange jersey was introduced that season as the NFL encouraged teams to adopt a third jersey, and a major design change was made when solid brown socks appeared for the first time since 1984 and were used with white, brown and orange jerseys. Other than 1984, striped socks (matching the jersey stripes) had been a signature design element in the team's traditional uniform. The white striped socks appeared occasionally with the white jerseys in 2003–2005 and 2007.

Experimentation continued in 2003 and 2004 when the traditional orange-brown-orange stripes on the white pants were replaced by two variations of a brown-orange-brown sequence, one in which the stripes were joined (worn with white jerseys) and the other in which they were separated by white (worn with brown jerseys). The joined sequence was used exclusively with both jerseys in 2005. In 2006, the traditional orange-brown-orange sequence returned.

Additionally in 2006, the team reverted to an older uniform style, featuring gray face masks; the original stripe pattern on the brown jersey sleeves (The white jersey has had that sleeve stripe pattern on a consistent basis since the 1985 season.) and the older, darker shade of brown.

The Browns wore brown pants for the first time in team history on August 18, 2008, preseason game against the New York Giants. The pants contain no stripes or markings. The team had the brown pants created as an option for their away uniform when they integrated the gray facemask in 2006. They were not worn again until the Browns "family" scrimmage on August 9, 2009 with white-striped socks. The Browns have continued to wear the brown pants throughout the 2009 season. Browns quarterback Brady Quinn supported the team's move to wearing the brown pants full-time, claiming that the striped pattern on the white pants "prohibit[ed] mobility".
However, the fans generally did not like the brown pants, and after being used for only one season, the team returned to their white shirt-on-white pants in 2010. Coach Eric Mangini told "The Plain Dealer" the Browns won't use the brown pants anymore. "It wasn't very well-received," Mangini said. "I hope we can get to the point where we can wear fruit on our heads and people wouldn't notice." At the time, the brown pants weren't officially dropped by the team, but simply not used.

The Browns chose to wear white at home for the 2011 season, and wound up wearing white for all 16 games as when they were on the road, the home team would wear their darker colored uniform.

The Browns brought back the brown pants in their home game against the Buffalo Bills on October 3, 2013 on "Thursday Night Football", pairing them with the brown jerseys. It marked the first time the team wore an all-brown combination in team history.

On April 14, 2015, the Cleveland Browns unveiled their new uniform combinations, consisting of the team's colors of orange, brown and white.

The Cleveland Browns have rivalries with all three of its AFC North opponents. In addition, the team has had historical rivalries with the Indianapolis Colts, Denver Broncos, Buffalo Bills, and Detroit Lions.

The team's biggest rival in the AAFC was the San Francisco 49ers, though this has cooled and in some cases turned into a friendly relationship, as the Browns now play in AFC and the 49ers play in the NFC. Additionally, many 49ers personnel helped the Browns relaunch in 1999 as well as former team President Mike Holmgren having started his NFL career in San Francisco. Also, 49ers owners John York and Denise DeBartolo York reside in Youngstown, 60 miles southeast of Cleveland. Former long-time veteran placekicker and fan favorite, Phil Dawson, signed with the 49ers in 2014, along with backup quarterback Colt McCoy.

Often called the "Turnpike Rivalry", the Browns' biggest rival has long been the Pittsburgh Steelers. Former Browns owner Art Modell scheduled home games against the Steelers on Saturday nights from 1964 to 1970 to help fuel the rivalry. The rivalry has also been fueled by the proximity of the two teams, number of championships both teams have won, players and personnel having played and/or coached for both sides, and personal bitterness. The teams have played twice annually since 1950, making it the oldest rivalry in the AFC and the fifth-oldest rivalry in the NFL. Though the Browns dominated this rivalry early in the series (winning the first eight meetings and posting a 31–9 record in the 1950s and 1960s), the Steelers went 15–5 in the 1970s and 34–6–1 since the Browns returned to the league in 1999. The Steelers have been particularly dominant in Pittsburgh, posting a 42–6 record when hosting the Browns, including winning streaks of 16 (1970–85) and 15 games (2004-present).

The Steelers currently hold a 75–58–1 lead. The Browns and Steelers met in the playoffs in and , with the Steelers winning both meetings. Though the rivalry has cooled in Pittsburgh due to the Modell move as well as the Browns' poor play since 1999, the Steelers still remain the top rival for Cleveland.

Originally conceived due to the personal animosity between Paul Brown and Art Modell, the "Battle of Ohio" between the Browns and the Cincinnati Bengals has been fueled by the sociocultural differences between Cincinnati and Cleveland, a shared history between the two teams, and similar team colors, as Brown used the exact shade of orange for the Bengals that he used for the Browns. (Though this has changed since then, as the Bengals now use a brighter shade of orange.) Modell, in fact, moved the Browns to the AFC after the AFL–NFL merger in order to have a rivalry with the Bengals. The rivalry has also produced two of the eight highest-scoring games in NFL history. Cincinnati has the all-time edge 50–41. While the Bengals have a 26–14 edge since the Browns returned to the NFL in 1999, the Browns-Bengals series has been more competitive than the Browns' series with their other division rivals.

Created as a result of the Browns' relocation to Baltimore, the rivalry between the Browns and Baltimore Ravens was more directed at Art Modell than the team itself, and is simply considered a divisional game in Baltimore. This matchup is more bitter for Cleveland than the others due to the fact that the draft picks for 1995 to 1998 resulted in the rosters that won the Super Bowl for the Ravens in 2000. Had the Browns stayed in Cleveland, these teams (drafted by general manager Ozzie Newsome) might have given the Browns the title after a 35-year drought. This bitterness was compounded when the Ravens won their second Super Bowl in 2012.. The Ravens lead the overall series 30–10. The two teams have not met in the playoffs.

The Detroit Lions rivalry began in the 1950s, when the Browns and Lions played each other in four NFL championships. The Lions won three of those championships, while the Browns won one. This was arguably one of the NFL's best rivalries in the 1950s. Since the NFL-AFL merger of 1970, the teams have met much less frequently with the Browns' move to the AFC. From 2002 to 2014, the two teams played an annual preseason game known as the "Great Lakes Classic".

The Bills rivalry had its roots back to the days of the AAFC, when there was a team from Buffalo with the same name in that league. The Browns and AAFC Bills played six games, including a league championship game, before the Browns were selected to merge into the NFL and the Bills left out. After the current incarnation of the Bills joined the NFL, the Browns and Bills have played each other from time to time. Though the Browns and Bills are in different AFC divisions, a mellow rivalry defined by mutual respect has since developed between the teams due to the similarities between Buffalo and Cleveland and shared misfortune between the teams. Despite this "rivalry" being known for ugly games, such as an 8-0 Browns win played in a blizzard in 2007 and a 6-3 Browns win in 2009 in which Browns quarterback Derek Anderson only completed 2 of 17 passes, there have been some competitive moments between the Bills and Browns as well, such as a playoff game in 1990 and two games with playoff-implications in 2007 and 2014.

The Browns fans' respect for the Bills is partly due to Bills founding owner Ralph Wilson being one of only two NFL owners to vote against the decision to move the original Browns team to Baltimore.

The Browns had a brief rivalry with the Denver Broncos that arose from three AFC Championship Games from 1986 to 1989. In the 1986 AFC Championship, quarterback John Elway led The Drive to secure a tie in the waning moments at Cleveland Municipal Stadium; the Broncos went on to win in 23–20 in overtime. One year later, the two teams met again in the 1987 AFC Championship game at Mile High Stadium. Denver took a 21–3 lead, but Browns' quarterback Bernie Kosar threw four touchdown passes to tie the game at 31–31 halfway through the 4th quarter. After a long drive, John Elway threw a 20-yard touchdown pass to running back Sammy Winder to give Denver a 38–31 lead. Cleveland advanced to Denver's 8-yard line with 1:12 left, but Broncos' safety Jeremiah Castille stripped Browns' running back Earnest Byner of the football at the 2-yard line—a play that has been called The Fumble by Browns' fans. The Broncos recovered it, gave Cleveland an intentional safety, and went on to win 38–33. The two teams met yet again in the 1989 AFC Championship at Mile High Stadium, which the Broncos easily won by a score of 37–21.

A 2006 study conducted by "Bizjournal" determined that Browns fans are the most loyal fans in the NFL. The study, while not scientific, was largely based on fan loyalty during winning and losing seasons, attendance at games, and challenges confronting fans (such as inclement weather or long-term poor performance of their team). The study noted that Browns fans filled 99.8% of the seats at Cleveland Browns Stadium during the last seven seasons, despite a combined record of 36-76 over that span.

Perhaps the most visible Browns fans are those that can be found in the Dawg Pound. Originally the name for the bleacher section located in the open (east) end of old Cleveland Municipal Stadium, the current incarnation is likewise located in the east end of FirstEnergy Stadium and still features hundreds of orange and brown clad fans sporting various canine-related paraphernalia. The fans adopted that name in 1984 after members of the Browns defense used it to describe the team's defense.

Retired cornerback Hanford Dixon, who played his entire career for the Browns (1981–1989), is credited with naming the Cleveland Browns defense 'The Dawgs' in the mid-1980s. Dixon and teammates Frank Minnifield and Eddie Johnson would bark at each other and to the fans in the bleachers at the Cleveland Stadium to fire them up. It was from Dixon's naming that the "Dawg Pound" subsequently took its title. The fans adopted that name in the years after. Due to this nickname, since the team's revival the Browns have used a bulldog as an alternate logo.

The most prominent organization of Browns fans is the "Browns Backers Worldwide" (BBW). The organization has approximately 305,000 members and Browns Backers clubs can be found in every major city in the United States, and in a number of military bases throughout the world, with the largest club being in Phoenix, Arizona. In addition, the organization has a sizable foreign presence in places as far away as Egypt, Australia, Japan, Sri Lanka, and McMurdo Station in Antarctica. According to The Official Fan Club of the Cleveland Browns, the two largest international fan clubs are in Alon Shvut, West Bank and Niagara, Canada, with Alon Shvut having 129 members and Niagara having 310.

Following former Browns owner Randy Lerner's acquisition of English soccer club Aston Villa, official Villa outlets started selling Cleveland Browns goods such as jerseys and NFL footballs. This has raised interest in England and strengthened the link between the two sporting clubs. Aston Villa supporters have set up an organization known as the Aston (Villa) Browns Backers of Birmingham.

The Cleveland Browns were the favorite team of Elvis Presley. This was because his friend Gene Hickerson - with whom he had played football in their common youth in Memphis - was contracted by the Browns in 1957 and played there during his entire career until 1973. Also defender Bobby Franklin, who had played from 1960 to 1966 for the Browns, was a friend of Presley. WWE Hall of Fame wrestler and commentator Jerry "The King" Lawler - though he has spent most of his life in Memphis - spent part of his childhood in the Cleveland area and is a fan of the Browns. Fellow WWE wrestlers The Miz and Dolph Ziggler (both Cleveland natives) are also fans. Another fan of the team is baseball legend Hank Aaron. Other famous Browns fans include Arsenio Hall, Drew Carey, Patricia Heaton (her father, Chuck Heaton, was a sportswriter for "The Plain Dealer", which covered the Browns and wrote two books about the team), Terri Garr, Martin Mull, Condoleezza Rice, Valerie Bertinelli (her husband is from the Northeast Ohio area, and she stars in "Hot in Cleveland"), Machine Gun Kelly, Paul Adelstein, Iron Chef Michael Symon, C. J. McCollum, ESPN sportscaster Jay Crawford and Brad Paisley.

The Cleveland Browns have the fourth largest number of players enshrined in the Pro Football Hall of Fame with a total of 16 enshrined players elected based on their performance with the Browns, and eight more players or coaches elected who spent at least one year with the Browns franchise. No Browns players were inducted in the inaugural induction class of 1963. Otto Graham was the first Browns player to be enshrined as a member of the class of 1965, and the most recent Browns player to be included in the Pro Football Hall of Fame is Gene Hickerson, who was a member of the class of 2007. All of the Browns' Pro Football Hall of Fame inductees thus far have been from the pre-1996 incarnation; no members of the Hall of Fame played for the Browns after 1999.
The Cleveland Browns legends program honors former Browns who made noteworthy contributions to the history of the franchise. In addition to all the Hall of Famers listed above, the Legends list includes:

From 1993 to 2013, number 19 was unofficially retired for Bernie Kosar aside from Frisman Jackson briefly wearing it in 2004, later changing it due to fan outcry over the number being used. In 2014, Miles Austin asked for and received permission from Kosar to wear 19, after which 19 returned to regular circulation for the Browns.

Beginning in 2010, the Browns established a Ring of Honor, honoring the greats from the past by having their names displayed around the upper deck of FirstEnergy Stadium. The inaugural class in the Browns Ring of Honor was unveiled during the home opener on September 19, 2010, and featured the 16 Hall of Famers listed above who went into the Hall of Fame as Browns. In 2018, Joe Thomas was entered into the Ring of Honor with the number 10,363 - commemorating his NFL record of consecutive snaps played on offense.

The team has honored two of its alumni with statues - late owner Alfred Lerner (in front of the team's headquarters/practice facility), and Hall of Fame running back Jim Brown (in front of First Energy Stadium).

WKNR (850 AM), WKRK-FM (92.3 FM), and WNCX (98.5 FM) serve as co-flagship stations for the Cleveland Browns Radio Network. Play-by-play announcer Jim Donovan calls games on-site alongside color analyst Doug Dieken, a former Browns left tackle, and sideline reporter Nathan Zegura - who made news when he had to serve an eight-game suspension due to arguing with officials during a game in 2018. WKRK-FM personality Ken Carman, WKNR personalities Tony Rizzo & Je'Rod Cherry, and former Browns punter Dave Zastudil host the network pregame show, while WKRK-FM personalities Jeff Phelps and Dustin Fox host the network postgame show. WLFM-LP (87.7 FM) serves as the Spanish-language outlet for the team.

WEWS-TV (TV channel 5) serves as the broadcast TV home of the Browns, airing year-round team programming as well as non-network preseason games. Jay Crawford serves as play-by-play announcer, former Browns quarterback Tim Couch serves as color analyst, and former Browns quarterback Bernie Kosar and Dustin Fox serve as sideline analysts. SportsTime Ohio (STO) is the cable outlet for the team, airing various Browns related programming during the season, STO had previously served as the team's cable outlet from its founding in 2006 until 2014.

The Browns in-house production team won a pair of Lower Great Lakes Emmy Awards in 2005. One was for a primetime special honoring the 1964 NFL Championship team ("The 1964 Championship Show") and one was for a commercial spot ("The Paperboy").
The Browns have (either directly or indirectly) been featured in various movies and TV shows over the years. Notable examples include:




</doc>
<doc id="6579" url="https://en.wikipedia.org/wiki?curid=6579" title="Carbine">
Carbine

A carbine ( or ), from French "carabine", is a long gun firearm but with a shorter barrel than a rifle or musket. Many carbines are shortened versions of full-length rifles, shooting the same ammunition, while others fire lower-powered ammunition, including types designed for pistols.

The smaller size and lighter weight of carbines make them easier to handle. They are typically issued to high-mobility troops such as special-operations soldiers and paratroopers, as well as to mounted, artillery, logistics, or other non-infantry personnel whose roles do not require full-sized rifles, although there is a growing tendency for carbines to be issued to front-line soldiers to offset the increasing weight of other issued equipment. An example of this is the US Army's M4 carbine, which is standard issue.

The name comes from its first users — cavalry troopers called "carabiniers", from the French "carabine", from Old French "carabin" (soldier armed with a musket), whose origin is unclear. One theory connects it to an "ancient engine of war" called a "calabre"; another connects it to Medieval Latin "Calabrinus" 'Calabrian'; yet another, "less likely", to "escarrabin", gravedigger, from the scarab beetle.

The carbine was originally a lighter, shortened weapon developed for the cavalry. Carbines were short enough to be loaded and fired from horseback, but this was rarely donea moving horse is a very unsteady platform, and once halted, a soldier can load and fire more easily if dismounted, which also makes him a smaller target (Napoleonic-era and earlier cavalry did fight from horseback, but they fought with sabers and large muzzle-loading "horse pistols", so called because their large size meant they were most easily carried in a saddle holster, much like the later Colt-Walker revolver). The principal advantage of the carbine was that its length made it very portable. Troops could carry full-length muskets comfortably enough on horseback if just riding from A to B (the practice of the original dragoons and other mounted infantry). Cavalry proper (a "Regiment of Horse") had to ride with some agility and engage in sword-wielding melées with opposing cavalry or pursue running infantry, so carrying anything long would be a dangerous encumbrance. A carbine was typically no longer than a sheathed sabre, and like a sheathed sabre was carried arranged to hang clear of the rider's elbows and horse's legs.

Carbines were usually less accurate and less powerful than the longer muskets (and later rifles) of the infantry, due to a shorter sight plane and lower velocity of bullets fired from the shortened barrel. With the advent of fast-burning smokeless powder, the velocity disadvantages of a shorter barrel became less of an issue (see internal ballistics). Eventually, the use of horse-mounted cavalry would decline. But carbines continued to be issued and used by many who preferred a lighter, more compact weapon even at the cost of reduced long-range accuracy and power, such as artillery troops, who might need to defend themselves from attack but would be hindered by keeping full-sized rifles around; thus, a common title for many short rifles in the late 19th century was "artillery carbine".

During the early 19th century, carbines were often developed separately from the infantry rifles and, in many cases, did not even use the same ammunition, which made for supply difficulties. A notable weapon developed towards the end of the American Civil War by the Union was the Spencer carbine, one of the very first breechloading, repeating weapons. It had a spring-powered, removable tube magazine in the buttstock which held seven rounds and could be reloaded by inserting spare tubes. It was intended to give the cavalry a replacement weapon which could be fired from horseback without the need for awkward reloading after each shot (although it saw service mostly with dismounted troopers and infantrymen, as was typical of cavalry weapons during that war). In the late 19th century, it became common for a number of nations to make bolt-action rifles in both full-length and carbine versions. One of the most popular and recognizable carbines were the lever-action Winchester carbines, with several versions available firing revolver cartridges. This made it an ideal choice for cowboys and explorers, as well as other inhabitants of the American West, who could carry a revolver and a carbine, both using the same ammunition.

The Lee Enfield Cavalry Carbine (LEC) a shortened version of the standard British Army infantry rifle was introduced in 1896, although it did not become the standard British cavalry weapon until 1903.

In the decades following World War I, the standard battle rifle used by armies around the world had been growing shorter, either by redesign or by the general issue of carbine versions instead of full-length rifles. This move was initiated by the US Model 1903 Springfield, which was originally produced in 1907 with a short 24-inch barrel, providing a short rifle that was longer than a carbine but shorter than a typical rifle, so it could be issued to all troops without need for separate versions. Other nations followed suit after World War I, when they learned that their traditional long-barreled rifles provided little benefit in the trenches and merely proved a hindrance to the soldiers. Examples include the Russian Model 1891 rifle, originally with an barrel, later shortened to in 1930, and to in 1938, the German Mauser Gewehr 98 rifles went from in 1898 to in 1935 as the "Karabiner 98k" (K98k or Kar98k), or "short carbine". The barrel lengths in rifles used by the United States did not change between the bolt-action M1903 rifle of World War I and the World War II M1 Garand rifle, because the barrel on the M1903 was still shorter than even the shortened versions of the Model 1891 and Gewehr 98. The US M1 carbine was more of a traditional carbine in that it was significantly shorter and lighter, with a barrel, than the M1 Garand rifle, and that it was intended for rear-area troops who couldn't be hindered with full-sized rifles but needed something more powerful and accurate than a Model 1911 pistol (although this didn't stop soldiers from using them on the front line). Contrary to popular belief, and even what some books claim, in spite of both being designated "M1", the M1 Carbine was "not" a shorter version of the .30-06 M1 Garand, as is typical for most rifles and carbines, but a wholly different design firing a smaller, less-powerful cartridge. The "M1" designates each as the first model in the new US designation system, which no longer used the year of introduction, but a sequential series of numbers starting at "1": the M1 "Carbine" and M1 "Rifle".

The United Kingdom also developed a "Jungle Carbine" version of their Lee–Enfield service rifle, featuring a shorter barrel, flash suppressor, and manufacturing modifications designed to decrease the rifle's weight. Officially titled "Rifle, No. 5 Mk I", it was introduced in the closing months of World War II, but it did not see widespread service until the Korean War, the Mau Mau Uprising, and the Malayan Emergency as well the Vietnam War.

A shorter weapon was more convenient when riding in a truck, armored personnel carrier, helicopter, or aircraft, and also when engaged in close-range combat. Based on the combat experience of World War II, the criteria used for selecting infantry weapons began to change. Unlike previous wars, which were often fought mainly from fixed lines and trenches, World War II was a highly mobile war, often fought in cities, forests, or other areas where mobility and visibility were restricted. In addition, improvements in artillery made moving infantry in open areas even less practical than it had been.

The majority of enemy contacts were at ranges of less than , and the enemy was exposed to fire for only short periods of time as they moved from cover to cover. Most rounds fired were not aimed at an enemy combatant, but instead fired in the enemy's direction to keep them from moving and firing back (see suppressive fire). These situations did not require a heavy rifle, firing full-power rifle bullets with long-range accuracy. A less-powerful weapon would still produce casualties at the shorter ranges encountered in actual combat, and the reduced recoil would allow more shots to be fired in the short amount of time an enemy was visible. The lower-powered round would also weigh less, allowing a soldier to carry more ammunition. With no need of a long barrel to fire full-power ammunition, a shorter barrel could be used. A shorter barrel made the weapon weigh less, was easier to handle in tight spaces, and was easier to shoulder quickly to fire a shot at an unexpected target. Full-automatic fire was also considered a desirable feature, allowing the soldier to fire short bursts of three to five rounds, increasing the probability of a hit on a moving target.

The Germans had experimented with selective-fire carbines firing rifle cartridges during the early years of World War II. These were determined to be less than ideal, as the recoil of full-power rifle cartridges caused the weapon to be uncontrollable in full-automatic fire. They then developed an intermediate-power cartridge round, which was accomplished by reducing the power and the length of the standard 7.92×57mm Mauser rifle cartridge to create the 7.92×33mm "Kurz" (Short) cartridge. A selective-fire weapon was developed to fire this shorter cartridge, eventually resulting in the Sturmgewehr 44, later translated as "assault rifle" (also frequently called "machine carbines" by Allied intelligence, a quite accurate assessment, in fact). Very shortly after World War II, the USSR would adopt a similar weapon, the ubiquitous AK-47, the first model in the famed Kalashnikov-series, which became the standard Soviet infantry weapon, and which has been produced and exported in extremely large numbers up through the present day. Although the United States had developed the M2 Carbine, a selective-fire version of the M1 Carbine during WW2, the .30 Carbine cartridge was closer to a pistol round in power, making it more of a submachine gun than an assault rifle. It was also adopted only in very small numbers and issued to few troops (the semi-automatic M1 carbine was produced in a 10-to-1 ratio to the M2), while the AK47 was produced by the millions and was standard-issue to all Soviet troops, as well as those of many other nations. The US was slow to follow suit, insisting on retaining a full-power, 7.62×51mm NATO rifle, the M14 (although this "was" selective fire), until too-hastily adopting the 5.56mm M16 rifle in the mid-1960s, with initially poor results due to the rapidity of its introduction (but later to become a highly successful line of rifles and carbines).

In the 1950s, the British developed the .280 British, an intermediate cartridge, and a select-fire bullpup assault rifle to fire it, the EM-2. They pressed for the US to adopt it so it could become a NATO-standard round, but the US insisted on retaining a full-power, .30 caliber round. This forced NATO to adopt the 7.62×51mm NATO round (which in reality is only slightly different ballistically to the .30-06 Springfield), to maintain commonality. The British eventually adopted the 7.62mm FN FAL, and the US adopted the 7.62mm M14. These rifles are both what is known as "battle rifles" and were a few inches shorter than the standard-issue rifles they replaced (22" barrel as opposed to 24" for the M1 Garand), although they were still full-powered rifles, with selective fire capability. These can be compared to the even shorter, less-powerful assault rifle, which might be considered the "carbine branch of weapons development", although indeed, there are now carbine variants of many of the assault rifles which had themselves seemed quite small and light when adopted.
By the 1960s, after becoming involved in War in Vietnam, the US did an abrupt about-face and decided to standardize on the intermediate 5.56×45mm round (based on the .223 Remington varmint cartridge) fired from the new, lightweight M16 rifle, leaving NATO to hurry and catch up. Many of the NATO countries couldn't afford to re-equip so soon after the recent 7.62mm standardization, leaving them armed with full-power 7.62mm battle rifles for some decades afterwards, although by this point, the 5.56mm has been adopted by almost all NATO countries and many non-NATO nations as well. This 5.56mm NATO round was even lighter and smaller than the Soviet 7.62×39mm AK-47 cartridge, but possessed higher velocity. In U.S. service, the M16 assault rifle replaced the M14 as the standard infantry weapon, although the M14 continued to be used by designated marksmen. Although at 20", the barrel of the M16 was shorter than that of the M14, it was still designated a "rifle" rather than a "carbine", and it was still longer than the AK, which used a 16" barrel. (The SKS – an interim, semi-automatic, weapon adopted a few years before the AK-47 was put into service – was designated a carbine, even though it's 20" barrel was significantly longer than the AK series' 16.3". This is because of the Kalashnikov's revolutionary nature, which altered the old paradigm. Compared to previous rifles, particularly the Soviets' initial attempts at semi-automatic rifles, such as the 24" SVT-40, the SKS was significantly shorter. The Kalashnikov altered traditional notions and ushered in a change in what was considered a "rifle" in military circles.)

In 1974, shortly after the introduction of the 5.56mm NATO, the USSR began to issue a new Kalashnikov variant, the AK-74, chambered in the small-bore 5.45×39mm cartridge, which was a standard 7.62×39mm necked down to take a smaller, lighter, faster bullet. It soon became standard issue in Soviet nations, although many of the nations with export Kalashnikovs retained the larger 7.62×39mm round. In 1995, the People's Republic of China adopted a new 5.8×42mm cartridge to match the modern trend in military ammunition, replacing the previous 7.62×39mm and 5.45×39mm round as standard.

Later, even lighter carbines variants of many of these short-barreled assault rifles came to be adopted as the standard infantry weapon. In much modern tactical thinking, only a certain number of soldiers now need to retain longer-range weapons, these serving as designated marksmen. The rest can carry lighter, shorter-ranged weapons for close-quarters combat and suppressive fire. This is basically a more extreme extension of the idea that brought the original assault rifle. Another factor is that with the increasing weight of technology, sighting systems, ballistic armor, etc., the only way to reduce the burden on the modern soldier was to equip him/her with a smaller, lighter weapon. Also, modern soldier rely a great deal on vehicles and helicopters to transport them around the battle area, and a longer weapon can be a serious hindrance to entering and exiting these vehicles. Development of lighter assault rifles continued, matched by developments in even lighter carbines. In spite of the short barrels of the new assault rifles, carbines variants like the 5.45×39mm AKS-74U and Colt Commando were being developed for use when mobility was essential and a submachine gun wasn't sufficiently powerful. The AKS-74U featured an extremely short 8.1" barrel which necessitated redesigning and shortening the gas-piston and integrating front sights onto the gas tube; the Colt Commando was a bit longer, at 11.5". Neither was adopted as standard issue, although the US did later adopt the somewhat-longer M4 carbine, with a 14.5" barrel.

By the 1990s, the US had adopted the M4 carbine, a derivative of the M16 family which fired the same 5.56mm cartridge but was lighter and shorter (in overall length and barrel length), resulting in marginally reduced range and power, although offering better mobility and lighter weight to offset the weight of equipment and armor that a modern soldier has to carry.

However, in spite of the benefits of the modern carbine, many armies are experiencing a certain backlash against the universal equipping of soldiers with carbines and lighter rifles in general, and are equipping selected soldiers, usually called Designated Marksmen, or DM, with higher-power rifles. Another problem comes from the loss of muzzle velocity caused by the shorter barrel, which when coupled with the typical small, lightweight bullets, causes effectiveness to be diminished; a 5.56mm gets its lethality from its high velocity, and when fired from the 14.5" M4 carbine, its power, penetration, and range are diminished. Thus, there has been a move towards adopting a slightly more powerful round tailored for high performance from both long and short barrels. The US has done experiments regarding adopting a new, slightly larger and heavier caliber such as the 6.5mm Grendel or 6.8mm Remington SPC, which are heavier and thus retain more effectiveness at lower muzzle velocities, but has for the time decided to retain the 5.56mm NATO round as standard issue.

While the US Army adopted the M4 carbine in the 1990s, the US Marine Corps retained their 20" barrel M16A4 rifles long afterwards, citing the increased range and effectiveness over the carbine version; officers were required to carry an M4 carbine rather than an M9 pistol, as Army officers do. Due to the Marine Corps emphasis on being riflemen, the lighter carbine was considered a suitable compromise between a rifle and a pistol. Marines with restricted mobility such as vehicle operators, or a greater need for mobility such as squad leaders, were also issued M4 carbines. In July 2015, the Marine Corps approved the M4 carbine for standard issue to front-line Marines, replacing the M16A4 rifle. The rifles will be issued to support troops while the carbines go to the front-line Marines, in a reversal of the traditional roles of "rifles for the front line, carbines for the rear".

Special forces need to perform fast, decisive operations, frequently airborne or boat-mounted. A pistol, though light and quick to operate, is viewed as not having enough power, firepower, or range. A submachine gun has selective fire, but firing a pistol cartridge and having a short barrel and sight radius, it is not accurate or powerful enough at longer ranges. Submachine guns also tend to have poorer armor and cover penetration than rifles and carbines firing rifle ammunition. Consequently, carbines have gained wide acceptance among SOCOM, UKSF, and other communities, having relatively light weight, large magazine capacity, selective fire, and much better range and penetration than a submachine gun.

The smaller size and relative lighter weight of carbines makes them easier to handle in close-quarter situations such as urban engagements, when deploying from military vehicles, or in any situation where space is confined. The disadvantages of carbines relative to rifles include inferior long-range accuracy and a shorter effective range. These comparisons refer to carbines (short-barreled rifles) of the same power and class as the regular full-sized rifles.

Compared to submachine guns, assault carbines have a greater effective range and are capable of penetrating the helmets and body armor used by modern infantrymen. However, submachine guns are still used by military special forces and police SWAT teams for close quarters battle (CQB) because they are "a pistol caliber weapon that's easy to control, and less likely to over-penetrate the target." Also, carbines are harder to maneuver in tight encounters where superior range and stopping power at distance are not great considerations.

Firing the same ammunition as standard-issue rifles or pistols gives carbines the advantage of standardization over those personal defense weapons (PDWs) that require proprietary cartridges.

The modern usage of the term carbine covers much the same scope as it always had, namely lighter weapons (generally rifles) with barrels up to 20 inches in length. These weapons can be considered carbines, while rifles with barrels longer than 20 inches are generally not considered carbines unless specifically named so. Conversely, many rifles have barrels "shorter" than 20", yet aren't considered carbines. The AK series rifles has an almost universal barrel length of 16.3", well within carbine territory, yet has always been considered a rifle, perhaps because it was designed as such and not shortened from a longer weapon. Modern carbines use ammunition ranging from that used in light pistols up to powerful rifle cartridges, with the usual exception of high-velocity magnum cartridges. In the more powerful cartridges, the short barrel of a carbine has significant disadvantages in velocity, and the high residual pressure, and frequently still-burning powder and gases, when the bullet exits the barrel results in substantially greater muzzle blast. Flash suppressors are a common, partial solution to this problem, although even the best flash suppressors are hard put to deal with the excess flash from the still-burning powder leaving the short barrel (and they also add several inches to the length of the barrel, diminishing the purpose of having a short barrel in the first place). The shorter the barrel, the more difficult it is to hide the flash; the AKS-74U has a complex, effective muzzle-booster/flash suppressor, yet it still suffers from extreme muzzle flash.
The typical carbine is the pistol-caliber carbine. These first appeared soon after metallic cartridges became common. These were developed as "companions" to the popular revolvers of the day, firing the same cartridge but allowing more velocity and accuracy than the revolver. These were carried by cowboys, lawmen, and others in the Old West. The classic combination would be a Winchester lever-action carbine and a Colt Single Action Army revolver in .44-40 or .38-40. During the 20th century, this trend continued with more modern and powerful smokeless revolver cartridges, in the form of Winchester and Marlin lever action carbines chambered in .38 Special/.357 Magnum and .44 Special/.44 Magnum.

Modern equivalents include the Ruger Police Carbine, which uses the same magazine as the Ruger pistols of the same caliber, and the (discontinued) Marlin Camp Carbine, which, in .45 ACP, used M1911 magazines. The Ruger Model 44 and Ruger Deerfield Carbine were both carbines chambered in .44 Magnum. The Beretta Cx4 Storm shares magazines with many Beretta pistols and is designed to be complementary to the Beretta Px4 Storm pistol. The Hi-Point 995TS are popular, economical and reliable alternatives to other pistol caliber carbines in the United States, and their magazines can be used in the Hi-Point C-9 pistol. Another example is the Kel-Tec SUB-2000 series chambered in either 9 mm Luger or .40S&W, which can be configured to accept Glock, Beretta, S&W, or SIG pistol magazines. The SUB-2000 also has the somewhat unusual (although not unique) ability to fold in half.
The primary advantage of a carbine over a pistol using the same ammunition is controllability. The combination of firing from the shoulder, longer sight-radius, 3 points of contact (firing hand, support hand & shoulder), and precision offer a significantly more user-friendly platform. Carbines like the Kel-Tec SUB-2000, Hi Point 995TS and Beretta Cx4 Storm have the ability to mount user friendly optics, lights and lasers thanks to them having accessory rails, which make target acquisition and engagement much easier.

The longer barrel can offer increased velocity and, with it, greater energy and effective range due to the propellant having more time to burn. However, loss in bullet velocity can happen where the propellant is utilised before the bullet reaches the muzzle, combined with the friction from the barrel on the bullet. As long guns, pistol-caliber carbines may be less legally restricted than handguns in some jurisdictions. Compared to carbines chambered in intermediate or rifle calibers, such as .223 Remington and 7.62×54mmR, pistol-caliber carbines generally experience less of an increase in external ballistic properties as a result of the propellant. The drawback is that one loses the primary benefits of a handgun, i.e. portability and concealability, resulting in a weapon almost the size of, but less accurate than, a long-gun, but not much more powerful than a pistol.

Also widely produced are semi-automatic and typically longer-barreled derivatives of select-fire submachine guns, such as the FN PS90, HK USC, KRISS Vector, Thompson carbine, CZ Scorpion S1 Carbine and the Uzi carbine. In order to be sold legally in many countries, the barrel must meet a minimum length (16" in the USA). So the original submachine gun in given a legal-length barrel and made into a semi-automatic, transforming it into a carbine. Though less common, pistol-caliber conversions of centerfire rifles like the AR-15 are commercially available.

Some handguns used to come from the factory with mounting lugs for a shoulder stock, notably including the "Broomhandle" Mauser C96, Luger P.08, and Browning Hi-Power. In the case of the first two, the pistol could come with a hollow wooden stock that doubled as a holster.

Carbine conversion kits are commercially available for many other pistols, including M1911 and most Glocks. These can either be simple shoulder stocks fitted to a pistol or full carbine conversion kits, which are at least long and replace the pistol's barrel with one at least long for compliance with the US law. In the US, fitting a shoulder stock to a handgun with a barrel less than 16" long legally turns it into a short-barreled rifle, which is in violation of the National Firearms Act.

Under the National Firearms Act of 1934, firearms with shoulder stocks or originally manufactured as a rifle and barrels less than in length are classified as short-barreled rifles. Short-barreled rifles are restricted similarly to short-barreled shotguns, requiring a $200 tax paid prior to manufacture or transfer – a process which can take several months. Because of this, firearms with barrels of less than and a shoulder stock are uncommon. A list of firearms not covered by the NFA due to their antique status may be found here or due to their "Curio and Relic" status may be found here; these lists includes a number of carbines with barrels less than the minimum legal length and firearms that are "primarily collector's items and are not likely to be used as weapons and, therefore, are excluded from the provisions of the National Firearms Act." Machine guns, as their own class of firearm, are not subject to requirements of other class firearms.

Distinct from simple shoulder stock kits, full carbine conversion kits are not classified as short-barreled rifles. By replacing the pistol barrel with one at least in length and having an overall length of at least , a carbine converted pistol may be treated as a standard rifle under Title I of the Gun Control Act of 1968 (GCA). However, certain "Broomhandle" Mauser C96, Luger, and Browning Hi-Power Curio & Relic pistols with their originally issued stock attached only may retain their pistol classification.

Carbines without a stock and not originally manufactured as a rifle are not classified as rifles or short barreled rifles. A carbine manufactured under in length without a forward vertical grip will be a pistol and, state law notwithstanding, can be carried concealed without creating an unregistered Any Other Weapon. A nearly identical carbine with an overall length of or greater is simply an unclassified firearm under Title I of the Gun Control Act of 1968, as the Any Other Weapon catch-all only applies to firearms under or that have been concealed. However, a modification intending to fire from the shoulder and bypass the regulation of short-barreled rifles is considered the unlawful possession and manufacture of an unregistered short-barreled rifle.

In some historical cases, the term "machine carbine" was the official title for submachine guns, such as the British Sten and Australian Owen guns. The semiautomatic-only version of the Sterling submachine gun was also officially called a "carbine". The original Sterling semi-auto would be classed a "short barrel rifle" under the U.S. National Firearms Act, but fully legal long-barrel versions of the Sterling have been made for the U.S. collector market.




</doc>
<doc id="6583" url="https://en.wikipedia.org/wiki?curid=6583" title="Chinese cuisine">
Chinese cuisine

Chinese cuisine is an important part of Chinese culture, which includes cuisine originating from the diverse regions of China, as well as from Chinese people in other parts of the world. Because of the Chinese diaspora and historical power of the country, Chinese cuisine has influenced many other cuisines in Asia, with modifications made to cater to local palates. Chinese food staples such as rice, soy sauce, noodles, tea, and tofu, and utensils such as chopsticks and the wok, can now be found worldwide.

The preference for seasoning and cooking techniques of Chinese provinces depend on differences in historical background and ethnic groups. Geographic features including mountains, rivers, forests and deserts also have a strong effect on the local available ingredients, considering that the climate of China varies from tropical in the south to subarctic in the northeast. Imperial, royal and noble preference also plays a role in the change of Chinese cuisines. Because of imperial expansion and trading, ingredients and cooking techniques from other cultures are integrated into Chinese cuisines over time.

The most praised "Four Major Cuisines" are Chuan, Lu, Yue and Huaiyang, representing West, North, South and East China cuisine correspondingly. The modern "Eight Cuisines" of China are Anhui (徽菜 Huīcài), Cantonese (粤菜; Yuècài), Fujian (闽菜; Mǐncài), Hunan (湘菜; Xiāngcài), Jiangsu (苏菜; Sūcài), Shandong (鲁菜; Lǔcài), Sichuan (川菜; Chuāncài), and Zhejiang (浙菜; Zhècài) cuisines.

Color, smell and taste are the three traditional aspects used to describe Chinese food, as well as the meaning, appearance and nutrition of the food. Cooking should be appraised with respect to the ingredients used, knifework, cooking time and seasoning.

Chinese society greatly valued gastronomy, and developed an extensive study of the subject based on its traditional medical beliefs. Chinese culture initially centered around the North China Plain. The first domesticated crops seem to have been the foxtail and broomcorn varieties of millet, while rice was cultivated in the south. By 2000 BC, wheat had arrived from western Asia. These grains were typically served as warm noodle soups instead of baked into bread as in Europe. Nobles hunted various wild game and consumed mutton, pork and dog as these animals were domesticated. Grain was stored against famine and flood and meat was preserved with salt, vinegar, curing, and fermenting. The flavor of the meat was enhanced by cooking it in animal fats though this practice was mostly restricted to the wealthy.

By the time of Confucius in the late Zhou, gastronomy had become a high art. Confucius discussed the principles of dining: "The rice would never be too white, the meat would never be too finely cut... When it was not cooked right, man would not eat. When it was cooked bad, man would not eat. When the meat was not cut properly, man would not eat. When the food was not prepared with the right sauce, man would not eat. Although there are plenty of meats, they should not be cooked more than staple food. There is no limit for alcohol, before a man gets drunk." During Shi Huangdi's Qin dynasty, the empire expanded into the south. By the time of the Han dynasty, the different regions and cuisines of China's people were linked by major canals and leading to a greater complexity in the different regional cuisines. Not only is food seen as giving "qi", energy, but food is also about maintaining yin and yang. The philosophy behind it was rooted in the "I Ching" and Chinese traditional medicine: food was judged for color, aroma, taste, and texture and a good meal was expected to balance the Four Natures ('hot', warm, cool, and 'cold') and the Five Tastes (pungent, sweet, sour, bitter, and salty). Salt was used as a preservative from early times, but in cooking was added in the form of soy sauce, and not at the table. The predominance of chopsticks and spoons as eating utensils also necessitated that most food be prepared in bite-sized pieces or (as with fish) be so tender that it could be easily picked apart.

By the Later Han period (2nd century), writers frequently complained of lazy aristocrats who did nothing but sit around all day eating smoked meats and roasts.

During the Han dynasty, the Chinese developed methods of food preservation for military rations during campaigns such as drying meat into jerky and cooking, roasting, and drying grain.
Chinese legends claim that the roasted, flat bread shaobing was brought back from the "Xiyu" (the Western Regions, a name for Central Asia) by the Han dynasty General Ban Chao, and that it was originally known as hubing (, lit. "barbarian bread"). The shaobing is believed to be descended from the hubing. Shaobing is believed to be related to the Persian "nan" and Central Asian "nan", as well as the Middle Eastern pita. Foreign westerners made and sold sesame cakes in China during the Tang dynasty.

During the Southern and Northern Dynasties non-Han people like the Xianbei of Northern Wei introduced their cuisine to northern China, and these influences continued up to the Tang dynasty, popularizing meat like mutton and dairy products like goat milk, yogurts, and Kumis among even Han people. It was during the Song dynasty that Han Chinese developed an aversion to dairy products and abandoned the dairy foods introduced earlier.

The Han Chinese rebel Wang Su who received asylum in the Xianbei Northern Wei after fleeing from Southern Qi, at first could not stand eating dairy products like goat's milk and meat like mutton and had to consume tea and fish instead, but after a few years he was able to eat yogurt and lamb, and the Xianbei Emperor asked him which of the foods of China (Zhongguo) he preferred, fish vs mutton and tea vs yogurt.

The great migration of Chinese people south during the invasions preceding and during the Song dynasty increased the relative importance of southern Chinese staples such as rice and congee. Su Dongpo has improved the red braised pork as Dongpo pork.

The Yuan and Qing dynasties introduced Mongolian and Manchu cuisine, warm northern dishes that popularized hot pot cooking. During the Yuan dynasty many Muslim communities emerged in China, who practiced a porkless cuisine now preserved by Hui restaurants throughout the country. Yunnan cuisine is unique in China for its cheeses like Rubing and Rushan cheese made by the Bai people, and its yogurt, the yogurt may have been due to a combination of Mongolian influence during the Yuan dynasty, the Central Asian settlement in Yunnan, and the proximity and influence of India and Tibet on Yunnan.

As part of the last leg of the Columbian Exchange, Spanish and Portuguese traders began introducing foods from the New World to China through the port cities of Canton and Macau. Mexican chili peppers became essential ingredients in Sichuan cuisine and calorically-dense potatoes and corn became staple foods across the northern plains.

During the Qing Dynasty, Chinese gastronomes such as Yuan Mei focused upon a primary goal of extracting the maximum flavor of each ingredient. As noted in his culinary work the "Suiyuan shidan", however, the fashions of cuisine at the time were quite varied and in some cases were flamboyantly ostentatious, especially when the display served also a formal ceremonial purpose, as in the case of the Manchu Han Imperial Feast.

As the pace of life increases in modern China, fast food like fried noodles, fried rice and "gaifan" (dish over rice) become more and more popular.

A number of different styles contribute to Chinese cuisine but perhaps the best known and most influential are Cantonese cuisine, Shandong cuisine, Jiangsu cuisine (specifically Huaiyang cuisine) and Sichuan cuisine. These styles are distinctive from one another due to factors such as availability of resources, climate, geography, history, cooking techniques and lifestyle. One style may favour the use of garlic and shallots over chili and spices, while another may favour preparing seafood over other meats and fowl. Jiangsu cuisine favours cooking techniques such as braising and stewing, while Sichuan cuisine employs baking.

Based on the raw materials and ingredients used, the method of preparation and cultural differences, a variety of foods with different flavors and textures are prepared in different regions of the country. Many traditional regional cuisines rely on basic methods of preservation such as drying, salting, pickling and fermentation.

Rice is a major staple food for people from rice farming areas in southern China. Steamed rice, usually white rice, is the most commonly eaten form. People in southern China also like to use rice to make congee as breakfast. Rice is also used to produce beer, baijiu and vinegars. Glutinous rice ("sticky rice") is a variety of rice used in specialty dishes such as lotus leaf rice and glutinous rice balls.

In wheat-farming areas in Northern China, people largely rely on flour-based food, such as noodles, "bing" (bread), "jiaozi" (a kind of Chinese dumplings), and "mantou" (a type of steamed buns).

Chinese noodles come dry or fresh in a variety of sizes, shapes and textures and are often served in soups or fried as toppings. Some varieties, such as Shou Mian (寿面, literally noodles of longevity), is an avatar of long life and good health according to Chinese traditions. Noodles can be served hot or cold with different toppings, with broth, and occasionally dry (as is the case with mi-fen). Noodles are commonly made with rice flour or wheat flour, but other flours such as soybean are also used in minor groups.

Tofu is made of soybeans and is another popular food product that supplies protein. The production process of tofu varies from region to region, resulting in different kinds of tofu with a wide range of texture and taste. Other products such as soy milk, soy paste, soy oil, and fermented soy sauce are also important in Chinese cooking.

There are many kinds of soybean products, including tofu skin, smoked tofu, dried tofu, fried tofu and so on.

Stinky tofu is fermented tofu. Like blue cheese or durian, it has a very distinct, potent and strong smell, and is an acquired taste. Hard stinky tofu is often deep-fried and paired with soy sauce or salty spice. Soft stinky tofu are usually used as a spread on steamed buns.

Doufuru is another type of fermented tofu that has a salty taste. Doufuru can be pickled together with soy beans, red yeast rice or chili to create different color and flavor. This is more of a pickled type of tofu and is not as strongly scented as stinky tofu. Doufuru has the consistency of slightly soft blue cheese, and a taste similar to Japanese miso paste, but less salty. Doufuru can be used as a spread on steamed buns, or paired with rice congee.

Apart from vegetables that can be commonly seen, some unique vegetables used in Chinese cuisine include baby corn, bok choy, snow pea pods, Chinese eggplant, Chinese broccoli and straw mushrooms. Other vegetables including bean sprouts, pea vine tips, watercress, lotus roots, water chestnuts, and bamboo shoots are also used in different cuisines of China.

Because of different climate and soil conditions, cultivars of green beans, peas, and mushrooms can be found in rich variety.

A variety of dried or pickled vegetables are also processed, especially in drier or colder regions where fresh vegetables were hard to get out of season.

Seasonings such as fresh ginger root, garlic, scallion, cilantro and sesame are widely used in many regional cuisines. Sichuan peppercorns, star anise, cinnamon, fennel, cloves and white peppers are also used in different regions.

To add extra flavors to dishes, many Chinese cuisines also contain dried Chinese mushrooms, dried baby shrimp, dried tangerine peel, and dried Sichuan chillies.

When it comes to sauces, China is home to soy sauce, which is made from fermented soybeans and wheat. Oyster sauce, clear rice vinegar, chili, Chinkiang black rice vinegar, fish sauce and furu (fermented tofu) are also widely used. A number of sauces are also based on fermented soybeans, including hoisin sauce, ground bean sauce and yellow bean sauce.

Generally, seasonal fruits serve as the most common form of dessert consumed after dinner.

Dim Sum (點心), originally means small portion of food, can refer to dessert, pastries. Later to avoid the disambiguation, tian dian (甜點) and gao dian (糕點) are used to describe desserts and pastries.

Chinese desserts are sweet foods and dishes that are served with tea, usually during the meal, or at the end of meals in Chinese cuisine.

Besides served as a dim sum along with tea, pastries are used for celebration of traditional festivals. The most famous one is moon cake, used to celebrate the Mid-Autumn Festival.

A wide variety of Chinese desserts are available, mainly including steamed and boiled sweet snacks. Bing is an umbrella term for all breads in Chinese, also including pastries and sweets. These are baked wheat flour based confections, with different stuffings including red bean paste, jujube and various of others. Su (酥) is another kind of pastry made with more amount of oil, making the confection more friable. Chinese candies and sweets, called "táng" (糖) are usually made with cane sugar, malt sugar, honey, nuts and fruit. Gao or Guo are rice based snacks that are typically steamed and may be made from glutinous or normal rice.

Another cold dessert is called "baobing", which is shaved ice with sweet syrup. Chinese jellies are known collectively in the language as "ices". Many jelly desserts are traditionally set with agar and are flavored with fruits, though gelatin based jellies are also common in contemporary desserts.

Chinese dessert soups are typically sweet and served hot.

There are also western pastries in China, like mille-feuille, crème brûlée and cheesecake, but they are generally not as popular because the Chinese preference of dessert is mildly sweet and less oily.

Many types of street foods, which vary from region to region, can be eaten as snacks or light dinner. Prawn crackers are an often-consumed snack in Southeast China.

Chinese in earlier dynasties evidently drank milk and ate dairy products, although not necessarily from cows, but perhaps "koumiss" (fermented mare's milk) or goat's milk.

Many Chinese have until recently avoided milk, partly because pasturage for milk producers in a monsoon rice ecology is not economic, and partly because of the high rate of lactose intolerance among the Chinese population. As such the use of dairy products in Chinese cuisine has historically been rare, with regional exceptions such as the "double skin milk" dessert in Guangdong Province or the Rubing (milk cake) cheese in Yunnan. Today ice cream is commonly available and popular throughout China.

Cold dishes are usually served before the main meal. Besides salad and pickles as appetizers, they can range from jelly, beancurd, noodle salad, cooked meat and sausages, to jellyfish or cold soups.

Chinese sausages vary from region to region. The most common sausage is made of pork and pork fat. Flavor is generally salty-sweet in Southern China. In other parts of China, sausages are salted to be preserved. Chinese sausage is prepared in many different ways, including oven-roasting, stir-fry, and steaming.

In some part of South China, soups are served between the cold dishes and main dishes. In other parts of China, soups are served between the main dish and staple foods, before desserts or fruit salad.

Tea plays an important role in Chinese dining culture. Baijiu and huangjiu as strong alcoholic beverages are preferred by many people as well. Wine is not so popular as other drinks in China that are consumed whilst dining, although they are usually available in the menu.

As well as with dim sum, many Chinese drink their tea with snacks such as nuts, plums, dried fruit (in particular jujube), small sweets, melon seeds, and waxberry. China was the earliest country to cultivate and drink tea, which is enjoyed by people from all social classes. Tea processing began after the Qin and Han Dynasties.

The different types of Chinese tea include black, white, green, yellow, oolong, and dark tea. Chinese tea is often classified into several different categories according to the species of plant from which it is sourced, the region in which it is grown, and the method of production used. Some of these types are green tea, oolong tea, black tea, scented tea, white tea, and compressed tea. There are four major tea plantation regions: Jiangbei, Jiangnan, Huanan and the southwestern region. Well known types of green tea include Longjing, Huangshan, Mao Feng, Bilochun, Putuofeng Cha, and Liu'an Guapian. China is the world's largest exporter of green tea.

One of the most ubiquitous accessories in modern China, after a wallet or purse and an umbrella, is a double-walled insulated glass thermos with tea leaves in the top behind a strainer.

The importance of "baijiu" ( "white liquor") in China (99.5% of its alcoholic market) makes it the most-consumed alcoholic spirit in the world. It dates back to the introduction of distilling during the Song dynasty; can be made from wheat, corn, or rice; and is usually around 120 proof (60% ABV). The most ubiquitous brand is the cheap Er guo tou, but Mao Tai is the premium "baijiu". Other popular brands Kang, Lu Zhou Te Qu, and Wu Liang Ye.

"Huangjiu" ( "yellow liquor") is not distilled and is a strong rice wine (10–15% ABV). Popular brands include Shaoxing Lao Jiu, Shaoxing Hua Diao, and Te Jia Fan.

Chinese herb tea, also known as "medicinal herbal tea", is a kind of tea made from Chinese medicinal herbs.

Soy milk, almond milk, walnut milk and coconut milk are also drunk during the meal in different regions. In some parts of China, hawthorn and jujube juice are preferred. A small shot of fruit vinegar is served as an appetizer in Shanxi.

Where there are historical immigrant Chinese populations, the style of food has evolved and been adapted to local tastes and ingredients, and modified by the local cuisine, to greater or lesser extents. This has resulted in a deep Chinese influence on other national cuisines such as Cambodian cuisine, Filipino cuisine, Thai cuisine and Vietnamese cuisine. There are also a large number of forms of fusion cuisine, often popular in the country in question. Some, such as ramen (Japanese Chinese cuisine) have become popular internationally.

Deep fried meat combined with sweet and sour sauce as a cooking style receives an enormous preference outside of China. Therefore, many similar international Chinese cuisines are invented based on sweet and sour sauce, including Sweet and sour chicken (Europe and North America), Manchurian chicken (India) or "tangsuyuk" (South Korea). The Hawaiian pizza was inspired by Chinese sweet and sour flavors.

Apart from the host country, the dishes developed in overseas Chinese cuisines are heavily dependent on the cuisines derived from the origin of the Chinese immigrants. In Korean Chinese cuisine, the dishes derive primarily from Shandong cuisine while Filipino Chinese cuisine is strongly influenced by Fujian cuisine. The large population having Chinese ancestors in the United States operates many restaurants, has developed distinctive dishes (such as chop suey) based originally on Cantonese cuisine, while those are not popular among Chinese-American people.

The Chinese dining etiquette has that youths should not sit at the table before the elders. In addition to this, youths should not start eating before the elders start eating. When eating with a bowl, one should not hold it with its bottom part, because it resembles the act of begging. Also, when taking a break from eating at the table, one should not put the chopstick into the rice vertically, because it resembles the Chinese traditional funeral tribute, which involves putting chopstick inside a bowl of rice vertically. It is considered inappropriate to use knives on the dining table. Chopsticks are the main eating utensils for Chinese food, which can be used to cut and pick up food.

Chinese dishes stress the three main points of appearance, smell, and taste. A really well-cooked Chinese food would need to achieve all three of them. Also, there is teaching of food carving in Chinese culture, typically using vegetables as materials to carve the sculpture for animals and spiritual beings.

In Chinese philosophy, food is frequently used as the message that the author is trying to convey. A Chinese philosophy I Ching says, “Gentlemen use eating as a way to attain happiness. They should be aware of what they say, and refrain from eating too much." 

In Chinese folk religion, ancestor veneration is conducted by offering food to ancestors and Chinese festivals involve the consumption and preparation of specific foods which have symbolic meanings attached to them. Specific religions in China have their own cuisines such as the Taoist diet, Buddhist cuisine and Chinese Islamic Cuisine. The Kaifeng Jews in Henan province once had their own Chinese Jewish cuisine but the community has largely died out in the modern era and not much is known about the specifics of their cuisine but they did influence foods eaten in their region and some of their dishes remain.

The American group People for the Ethical Treatment of Animals has criticized practices in certain parts of the West, Japan and China that involve eating live animals and the consumption of exotic game and bushmeats as forms of animal cruelty. Examples of eating live animals in China include Yin Yang fish ("dead-and-alive" fish), drunken shrimp, and "San Zhi Er" (baby rodents). Other controversial dishes in Chinese cuisine includes Cantonese snake soup, dog meat and bear claws.





</doc>
<doc id="6585" url="https://en.wikipedia.org/wiki?curid=6585" title="Constantin Brâncuși">
Constantin Brâncuși

Constantin Brâncuși (; February 19, 1876 – March 16, 1957) was a Romanian sculptor, painter and photographer who made his career in France. Considered a pioneer of modernism, one of the most influential sculptors of the 20th-century, Brâncuși is called the patriarch of modern sculpture. As a child he displayed an aptitude for carving wooden farm tools. Formal studies took him first to Bucharest, then to Munich, then to the École des Beaux-Arts in Paris from 1905 to 1907. His art emphasizes clean geometrical lines that balance forms inherent in his materials with the symbolic allusions of representational art. Brâncuși sought inspiration in non-European cultures as a source of primitive exoticism, as did Paul Gauguin, Pablo Picasso, André Derain and others. However, other influences emerge from Romanian folk art traceable through Byzantine and Dionysian traditions.

Brâncuși grew up in the village of Hobiţa, Gorj, near Târgu Jiu, close to Romania's Carpathian Mountains, an area known for its rich tradition of folk crafts, particularly woodcarving. Geometric patterns of the region are seen in his later works.

His parents Nicolae and Maria Brâncuși were poor peasants who earned a meager living through back-breaking labor; from the age of seven, Constantin herded the family's flock of sheep. He showed talent for carving objects out of wood, and often ran away from home to escape the bullying of his father and older brothers.

At the age of nine, Brâncuși left the village to work in the nearest large town. At 11 he went into the service of a grocer in Slatina; and then he became a domestic in a public house in Craiova where he remained for several years. When he was 18, Brâncuși created a violin by hand with materials he found around his workplace. Impressed by Brâncuși's talent for carving, an industrialist enrolled him in the Craiova School of Arts and Crafts ("școala de arte și meserii"), where he pursued his love for woodworking, graduating with honors in 1898.

He then enrolled in the Bucharest School of Fine Arts, where he received academic training in sculpture. He worked hard, and quickly distinguished himself as talented. One of his earliest surviving works, under the guidance of his anatomy teacher, Dimitrie Gerota, is a masterfully rendered écorché (statue of a man with skin removed to reveal the muscles underneath) which was exhibited at the Romanian Athenaeum in 1903. Though just an anatomical study, it foreshadowed the sculptor's later efforts to reveal essence rather than merely copy outward appearance.

In 1903, Brâncuși traveled to Munich, and from there to Paris. In Paris, he was welcomed by the community of artists and intellectuals brimming with new ideas. He worked for two years in the workshop of Antonin Mercié of the École des Beaux-Arts, and was invited to enter the workshop of Auguste Rodin. Even though he admired the eminent Rodin he left the Rodin studio after only two months, saying, "Nothing can grow under big trees."

After leaving Rodin's workshop, Brâncuși began developing the revolutionary style for which he is known. His first commissioned work, "The Prayer", was part of a gravestone memorial. It depicts a young woman crossing herself as she kneels, and marks the first step toward abstracted, non-literal representation, and shows his drive to depict "not the outer form but the idea, the essence of things." He also began doing more carving, rather than the method popular with his contemporaries, that of modeling in clay or plaster which would be cast in metal, and by 1908 he worked almost exclusively by carving.

In the following few years he made many versions of "Sleeping Muse" and "The Kiss", further simplifying forms to geometrical and sparse objects.

His works became popular in France, Romania and the United States. Collectors, notably John Quinn, bought his pieces, and reviewers praised his works. In 1913 Brâncuși's work was displayed at both the Salon des Indépendants and the first exhibition in the U.S. of modern art, the Armory Show.
In 1920, he developed a notorious reputation with the entry of "Princess X" in the Salon. The phallic appearance of this large, gleaming bronze piece scandalized the Salon and, despite Brâncuși's explanation that it was simply meant to represent the essence of womanhood, removed it from the exhibition. "Princess X" was revealed to be Princess Marie Bonaparte, direct descendant of the younger brother of Napoleon Bonaparte. The sculpture has been interpreted by some as symbolizing her obsession with the penis and her lifelong quest to achieve vaginal orgasm, with the help of Sigmund Freud.

Around this time Brâncuși began crafting the bases for his sculptures with much care and originality because he considered them important to the works themselves.

One of his major groups of sculptures involved the "Bird in Space" — simple abstract shapes representing a bird in flight. The works are based on his earlier "Măiastra" series. In Romanian folklore the Măiastra is a beautiful golden bird who foretells the future and cures the blind. Over the following 20 years, Brâncuși made multiple versions of "Bird in Space" out of marble or bronze. Athena Tacha Spear's book, "Brâncuși's Birds," (CAA monographs XXI, NYU Press, New York, 1969), first sorted out the 36 versions and their development, from the early "Măiastra", to the "Golden Bird" of the late teens, to the "Bird in Space", which emerged in the early 1920s and which Brâncuși developed throughout his life.

One of these versions caused a major controversy in 1926, when photographer Edward Steichen purchased it and shipped it to the United States. Customs officers did not accept the "Bird" as a work of art and assessed customs duty on its import as an industrial item. After protracted court proceedings, this assessment was overturned, thus confirming the Bird's status as a duty-exempt work of art. The ruling also established the important principle that "art" does not have to involve a realistic representation of nature, and that it was legitimate for it to simply represent an abstract concept – in this case "flight".

His work became increasingly popular in the U.S, where he visited several times during his life. Worldwide fame in 1933 brought him the commission of building a meditation temple in India for Maharajah of Indore, but when Brâncuși went to India in 1937 to complete the plans and begin construction, the Mahrajah was away and lost interest in the project when he returned.

In 1938, he finished the World War I monument in Târgu-Jiu where he had spent much of his childhood. "Table of Silence", "The Gate of the Kiss", and "Endless Column" commemorate the courage and sacrifice of Romanians who in 1916 defended Târgu Jiu from the forces of the Central Powers. The restoration of this ensemble was spearheaded by the World Monuments Fund and was completed in 2004.

The Târgu Jiu ensemble marks the apex of his artistic career. In his remaining 19 years he created less than 15 pieces, mostly reworking earlier themes, and while his fame grew he withdrew. In 1955 "Life" magazine reported, "Wearing white pajamas and a yellow gnome-like cap, Brâncuși today hobbles about his studio tenderly caring for and communing with the silent host of fish, birds, heads, and endless columns which he created."

Brâncuși was cared for in his later years by a Romanian refugee couple. He became a French citizen in 1952 in order to make the caregivers his heirs, and to bequeath his studio and its contents to the Musée National d'Art Moderne in Paris.

Brâncuși always dressed in the simple ways the Romanian peasants did. His studio was reminiscent of the houses of the peasants from his native region: there was a big slab of rock as a table and a primitive fireplace, similar to those found in traditional houses in his native Oltenia, while the rest of the furniture was made by him out of wood. Brâncuși would cook his own food, traditional Romanian dishes, with which he would treat his guests.

Brâncuși held a large spectrum of interests, from science to music. He was a good violinist and he would sing old Romanian folk songs, often expressing by them his feelings of homesickness. After the installment of communism, he never considered moving back permanently to his native Romania, but he did visit it eight times.

His circle of friends included artists and intellectuals in Paris such as Amedeo Modigliani, Ezra Pound, Henri Pierre Roché, Guillaume Apollinaire, Louise Bourgeois, Pablo Picasso, Man Ray, Marcel Duchamp, Henri Rousseau, Peggy Guggenheim, Tristan Tzara and Fernand Léger. He was an old friend of Romany Marie, who was also Romanian, and referred Isamu Noguchi to her café in Greenwich Village.
Although surrounded by the Parisian avant-garde, Brâncuși never lost contact with Romania and had friends from the community of Romanian artists and intellectuals living in Paris, including Benjamin Fondane, George Enescu, Theodor Pallady, Camil Ressu, Nicolae Dărăscu, Panait Istrati, Traian Vuia, Eugène Ionesco, Emil Cioran and Paul Celan.

Brâncuși held a particular interest in mythology, especially Romanian mythology, folk tales, and traditional art (which also had a strong influence on his works), but he became interested in African and Mediterranean art as well.

A talented handyman, he built his own phonograph and made most of his furniture, utensils, and doorways. His worldview valued "differentiating the essential from the ephemeral," with Plato, Lao-Tzu, and Milarepa as influences. He was a saint-like idealist and near ascetic, turning his workshop into a place where visitors noted the deep spiritual atmosphere. However, particularly through the 1910s and 1920s, he was known as a pleasure seeker and merrymaker in his bohemian circle. He enjoyed cigarettes, good wine, and the company of women. He had one child, John Moore, with the New Zealand pianist Vera Moore, whom he never acknowledged.

Brâncuși died on March 16, 1957, aged 81. He was buried in the Cimetière du Montparnasse in Paris. This cemetery also displays statues that Brâncuși carved for deceased artists.

In 1962, Georg Olden used Brâncuși's "Bird in Space" as the inspiration behind his design of the Clio Award statuette.

At his death Brâncuși left 1200 photographs and 215 sculptures. He bequeathed part of his collection to the French state on condition that his workshop be rebuilt as it was on the day he died. This reconstruction of his studio, adjacent to the Pompidou Centre, is open to the public. Brâncuși's studio inspired Swedish architect Klas Anshelm's design of the Malmö Konsthall, which opened in 1975.

Brâncuși was elected posthumously to the Romanian Academy in 1990.

Google commemorated his 135th birthday with a Doodle in 2011 consisting of seven of his works.

Brâncuși's works are housed in the National Museum of Art of Romania (Bucharest), the Museum of Modern Art (New York) and other museums around the world. The Philadelphia Museum of Art holds the largest collection of Brâncuși sculptures in the United States.

In 2015 the Romanian Parliament declared February 19 "The Brâncuși Day", a working holiday in Romania.

Brâncuși's piece "Madame L.R." sold for €29.185 million ($37.2 million) in 2009, setting a record price for a sculpture sold at auction.

In May 2018, "La Jeune Fille Sophistiquée" ("Portrait de Nancy Cunard"), a polished bronze on a carved marble base (1932), sold for US$71 million (with fees) at Christie's New York, setting a world record auction price for the artist.

Both "Bird in Space" and "Sleeping Muse I" are sculptures of animate objects; however, unlike ones from Ancient Greece or Rome, or those from the High Renaissance period, these works of art are more abstract in style.

"Bird in Space" is a series from the 1920s. One of these, constructed in 1925 using wood, stone, and marble (Richler 178) stands around 72 inches tall and consists of a narrow feather standing erect on a wooden base. Similar models, but made from materials such as bronze, were also produced by Brâncuși and placed in exhibitions.

"Sleeping Muse I" has different versions as well; one, from 1909–10, is made of marble and measures 6 ¾ in. in height (Adams 549). This is a model of a head, without a body, with markings to show features such as hair, nose, lips, and closed eyes. In "A History of Western Art", Adams says that the sculpture has "an abstract, curvilinear quality and a smooth contour that create an impression of elegance" (549). The qualities which produce the effect can particularly be seen in the shape of the eyes and in the set of the mouth.







</doc>
<doc id="6586" url="https://en.wikipedia.org/wiki?curid=6586" title="Claus Sluter">
Claus Sluter

Claus Sluter (1340s in Haarlem – 1405 or 1406 in Dijon) was a sculptor of Dutch origin. He was the most important northern European sculptor of his age and is considered a pioneer of the "northern realism" of the Early Netherlandish painting that came into full flower with the work of Jan van Eyck and others in the next generation.

The name "Claes de Slutere van Herlam" is inscribed in the Register of the Corporation of Stonemasons and Sculptors of Brussels around the years 1379/1380. He then moved to the Burgundian capital of Dijon, where from 1385 to 1389 he was the assistant of Jean de Marville, Court Sculptor to Philip the Bold, Duke of Burgundy. From 1389 to his death he was Court Sculptor himself, with the rank of "valet de chambre". He was succeeded by his nephew Claus de Werve.

Sluter's most significant work is the so-called "Well of Moses" (1395–1403), or the Great Cross was created for the Carthusian monastery of Champmol, which was founded by Philip the Bold right outside Dijon in 1383. For many years, the top portion was thought to have included (along with Christ on a cross), sculptures of the Virgin and John the Evangelist. However it was more likely just Christ, with Mary Magdalene kneeling at the foot of the cross. The cross, and whatever was on the terrace below, was destroyed at some point after 1736 and before 1789, probable because the roof of the building protecting the monument collapsed. Some fragments from the original Cross are preserved in the Musée Archéologique de Dijon. Life-sized figures representing Old Testament prophets and kings (Moses, David, Daniel, Jeremiah, Zachariah, and Isaiah) stand around the base, holding phylacteries and books inscribed with verses from their respective texts, which were interpreted in the Middle Ages as typological prefigurations of the sacrifice of Christ. The work's physical structure, in which the Old Testament figures support those of the New Dispensation, literalizes the typological iconography. The pedestal surmounts a hexagonal fountain. The entire monument is executed in limestone quarried from Tonnerre and Asnières.
A few steps away from The Well of Moses one finds the portal of the former mortuary chapel of Champmol. The portal consists of three sculptural groups by Sluter: a standing Madonna and Child at the trumeau; the duke and St. John, his patron saint, at the left jamb and the duchess and her patron saint, Catherine, at the right one. Sluter was also responsible for the main part of the work on Philip's tomb, which (restored and partly reconstructed) has been moved to the Museum of Fine Arts which is housed in the former ducal palace in Dijon.

Sluter was one of the sculptors of the pleurants, or mourners, which occupy niches below the tombs of Philip the Bold, his wife Margaret, and John the Fearless.


</doc>
<doc id="6587" url="https://en.wikipedia.org/wiki?curid=6587" title="Cadillac, Michigan">
Cadillac, Michigan

Cadillac is a city in the U.S. state of Michigan, located in Haring Township. The city is the county seat of Wexford County. The population was 10,355 at the 2010 census. Today US 131, M-55 and M-115 have a junction at this city. The geographic center of Michigan is approximately five miles (8.05 km) north-northwest of Cadillac.

Cadillac became the county seat after the so-called "Battle of Manton." Local officials engaged in a show of force to enforce the controversial state legislative decision to move the county seat from Manton.

European explorers and fur traders visited this area from the 18th century, most of them initially French and French-Canadians who traded with regional Native Americans. More permanent communities were not established until the late 19th century. Initial settlements developed from logging camps and the logging industry.

In 1871, the first sawmill began operations at Cadillac. Originally called the Pioneer Mill, it was built by John R. Yale. That same year, George A. Mitchell, a prominent Cadillac banker and railroad entrepreneur, and Adam Gallinger, a local carpenter, formed the Clam Lake Canal Improvement and Construction Company. Two years later, the Clam Lake Canal was constructed between Big and Little Clam lakes, known as present-day lakes Mitchell and Cadillac. Sawmill owners used the canal to transport timber from Big Clam Lake to the mills and railroad sites on Little Clam Lake. The Grand Rapids and Indiana Railroad (|G.R. & I. Railroad) had reached the area in 1872.

This settlement was originally named Clam Lake and was incorporated as a village in 1874. George Mitchell was elected as the first mayor. The village was incorporated as a city in 1877 and renamed Cadillac, after Antoine Laumet de La Mothe, sieur de Cadillac, a French colonist who started the first permanent settlement at Detroit in 1701.

The Wexford County seat of government, originally located in Sherman, was moved to Manton in 1881, as the result of a compromise between the feuding residents of Cadillac and Sherman. Cadillac partisans, however, won the county seat by a county-wide vote in April 1882. The day following the election, a sheriff's posse left the city for Manton by special train to seize the county records. After they arrived and collected a portion of the materials, however, an angry crowd confronted the Cadillac men and drove them out of town.

When the sheriff returned to Cadillac, he encountered a force consisting of several hundred armed men; this group reportedly included a brass band. The Sheriff's force, some of whom may have been intoxicated, traveled back to Manton to seize the remaining records. Although Manton residents confronted the Cadillac men and barricaded the courthouse, the posse successfully seized the documents. They returned to Cadillac in dubious glory.

In 1878, Ephraim Shay perfected his Shay locomotive, which was particularly effective in its ability to climb steep grades, maneuver sharp turns, and accommodate imperfections in railroad tracks. Cadillac was home to the Michigan Iron Works Company, which manufactured the Shay locomotive for a short time in the early 1880s. The lumber industry continued to dominate the city, attracting a large immigrant labor force, most of whom were Swedish. (Later Cadillac made sister city arrangements with Mölnlycke, Sweden, and Rovaniemi, Finland).

In 1899, the Cadillac Club formed, the forerunner of the Cadillac Area Chamber of Commerce. Gradually, various manufacturing firms found success in Cadillac. 

By the early 20th century, with the lumber depleted, the timber industry was in decline. Industrial development soon dominated the local economy, and it continues to do so today. Cadillac's range of industries includes the manufacture of pleasure boats, automotive parts, water-well components, vacuum cleaners, and rubber products.

In 1936, the U.S. Forest Service and the Civilian Conservation Corps developed the Caberfae Ski Area during the Great Depression as an investment in future economic development. This resulted in promotion of this area as a tourist center. Caberfae remains in operation today, as the oldest ski resort in the midwest. Tourism and outdoor recreation have since become an important sector of Cadillac's economy. 

In the summer, tourists travel to the city and region for boating, fishing, hiking, mountain biking, and camping. During the fall, hunting and color tours are popular. The winter is possibly the busiest season; the area can be found packed with downhill skiers, cross-country skiers, ice-fishers, snow-shoers and–most of all-snowmobilers. The North American Snowmobile Festival (NASF) is held on frozen Lake Cadillac every winter.

Thirsty's, a gas station on M-55 west of Cadillac, was the home of Samantha or "Sam The Bear" from the 1970s through the late 1990s, when Sam died of old age. Sam was the only brown bear in captivity in the US at the time to hibernate naturally. Sam lived in a large cage in front of the gas station and was fed ice cream cones by tourists every summer.

In October 1975 the rock group Kiss visited Cadillac and performed at the Cadillac High School gymnasium. They played the concert to honor the Cadillac High School football team. In previous years, the team had compiled a record of sixteen consecutive victories, but the 1974 squad opened the season with two losses. The assistant coach, Jim Neff, an English teacher and rock'n'roll fan, thought to inspire the team by playing Kiss music in the locker room. He also connected the team's game plan, K-I-S-S or "Keep It Simple Stupid", with the band. The team went on to win seven straight games and their conference co-championship. After learning of their association with the team's success, the band decided to visit the school and play for the homecoming game.

Cadillac maintains a number of state historic landmarks. Most are marked with a green "Michigan Historical Marker" sign, which includes a description of the landmark. Six sites with the city are marked: Cadillac Carnegie Library, Charles T. Mitchell House, Clam Lake Canal, Cobbs & Mitchell Building, Cobbs & Mitchell No. 1, and the Shay Locomotive (pictured at the right). Two more are in the near Cadillac area: Caberfae Ski Resort and Greenwood Disciples of Christ Church; and another two are in surrounding Wexford County, marking Battle of Manton and the First Wexford County Court House.

According to the United States Census Bureau, the city has a total area of , of which is land and is water.

The Lake Cadillac is entirely within the city limits. The larger, Lake Mitchell is nearby on the west side of the city, with of shoreline within the city's municipal boundary. The lakes were connected by a stream which was replaced in 1873 by the Clam Lake Canal. The canal was featured on Ripley's Believe It or Not in the 1970s due to the phenomenon that in winter the canal freezes before the lakes and then after the lakes freeze, the canal thaws and remains unfrozen for the rest of the winter.

Cadillac is located at the eastern edge of what is now managed as the Manistee National Forest. The surrounding area is heavily wooded, with mixed hardwood and conifer forests. Christmas tree farming has been important to the area agricultural industry. Cadillac was chosen in 1988 to donate the holiday tree installed at the lawn of the U.S. Capitol building in Washington, D.C.

The area surrounding Cadillac is primarily rural, and is considered to be part of Northern Michigan. Given tThe small size of nearby communities, the city is a major commercial and industrial hub of the region.

The commercial center of the city is located on the eastern edge of Lake Cadillac. Most downtown buildings range from two to five stories in height. Many face Mitchell Street, the city's tree-lined main street and traditional corridor of travel through town. The downtown contains a movie theater, gift shops, restaurants, a bookstore, specialty food stores, jewelers, clothing retailers, and various other businesses. 

The Courthouse Hill Historic District, recognized in April 2005, lies adjacent to the city's commercial center. The District contains a number of large Victorian-style residences built by the lumber barons and businessmen who helped develop the city in the 1870s. Population and building density is highest in this area.

On the western bank of Lake Cadillac, where M-55 intersects M-115, is what is locally referred to as Cadillac West. This is a small commercial district, bordering Mitchell State Park and the two lakes; it caters mostly to tourists. It contains a number of motels and restaurants.

Along the northern and southern stretches of the lake are the main residential areas of the city. They are generally of low to moderate density, characterized primarily by single-family structures.

Cadillac experiences a typical northern Michigan climate, undergoing temperate seasonal changes, influenced by the presence of Lake Michigan and the inevitable lake effect. Winters are generally cold with large amounts of snowfall. Summers are warm. The average high temperature in July is 80 °F (27 °C) and the average low is in February, at 9 °F (−13 °C). Summer temperatures can exceed 90 °F (32 °C), and winter temperatures can drop below 0 °F (−18 °C). Average annual rainfall is 30 inches (76 cm), and average annual snowfall is 81 inches (206 cm) . Snowfall typically occurs between the months of November and March. According to the Köppen Climate Classification system, Cadillac has a humid continental climate, abbreviated "Dfb" on climate maps.

Cadillac has two superfund sites, according to the U.S. Environmental Protection Agency. One is located at 1100 Wright Street, the former site of Kysor Industrial Corp, which operations resulted in toxic wastes. The other is located at 1002 6th Street, the former site of Northernaire Plating. Its operations also produced hazardous wastes, which produced contamination. 

As of the census of 2010, there were 10,355 people, 4,280 households, and 2,625 families residing in the city. The population density was . There were 4,927 housing units at an average density of . The racial makeup of the city was 95.6% White, 0.5% African American, 0.6% Native American, 1.0% Asian, 0.4% from other races, and 1.8% from two or more races. Hispanic or Latino of any race were 1.8% of the population.

There were 4,280 households of which 32.9% had children under the age of 18 living with them, 39.2% were married couples living together, 16.4% had a female householder with no husband present, 5.7% had a male householder with no wife present, and 38.7% were non-families. 32.0% of all households were made up of individuals and 14% had someone living alone who was 65 years of age or older. The average household size was 2.34 and the average family size was 2.90.

The median age in the city was 36.5 years. 24.7% of residents were under the age of 18; 10% were between the ages of 18 and 24; 24.4% were from 25 to 44; 23.8% were from 45 to 64; and 17.1% were 65 years of age or older. The gender makeup of the city was 47.4% male and 52.6% female.

As of the census of 2000, there were 10,000 people, 4,118 households, and 2,577 families residing in the city. The population density was 1,466.0 per square mile (566.1/km²). There were 4,466 housing units at an average density of 654.7 per square mile (252.8/km²). The racial makeup of the city was 96.55% White, 0.21% Black or African American, 0.92% Native American, 0.63% Asian, 0.03% Pacific Islander, 0.28% from other races, and 1.38% from two or more races. 1.18% of the population were Hispanic or Latino of any race.

There were 4,118 households out of which 32.2% had children under the age of 18 living with them, 43.9% were married couples living together, 14.2% had a female householder with no husband present, and 37.4% were non-families. 31.8% of all households were made up of individuals and 14.4% had someone living alone who was 65 years of age or older. The average household size was 2.37 and the average family size was 2.96.

In the city, the population was spread out with 26.2% under the age of 18, 9.6% from 18 to 24, 27.9% from 25 to 44, 19.6% from 45 to 64, and 16.7% who were 65 years of age or older. The median age was 36 years. For every 100 females, there were 91.4 males. For every 100 females age 18 and over, there were 84.4 males.

The median income for a household in the city was $29,899, and the median income for a family was $36,825. Males had a median income of $29,773 versus $21,283 for females. The per capita income for the city was $16,801. About 10.9% of families and 13.7% of the population were below the poverty line, including 15.4% of those under age 18 and 13.3% of those age 65 or over.

Cadillac was incorporated as a city in 1877. It is a home rule city with a Council-Manager form of government-one.

Current council members are Shari Spoelman, Antoinette Schippers, Arthur Stevens, James Dean and Carla Filkins (mayor). The present City Manager is Marcus Peccia.

Cadillac is located in Michigan's 2nd congressional district, represented by Republican Bill Huizenga.

Manufacturing has been the greatest employer in Cadillac since the logging industry. More than 26% of the city's labor force is employed in manufacturing. Three industrial parks are located within the city limits, comprising 7% of the total land use in Cadillac. Their operations generate 47% of the city's tax base. Much of the city's economic performance is determined by the fortunes of local industry.

Major manufacturers include Four Winns, AAR Manufacturing, Avon Rubber, FIAMM Technologies, Michigan Rubber Products and Rexair.
The center of the city is generally perceived to have a "small-town-feel." In the summer, the downtown fills with tourists, many from southern Michigan. The city center is one block from Lake Cadillac. For visitors by boat who dock at the public docks, it is nearly as accessible by boat as it is by car. The city's immediate proximity to two lakes, as well as Manistee National Forest, Pere Marquette State Forest, Mitchell State Park and a number of major highways, has established tourism as a significant sector of the local economy.

During the winter months, Lake Cadillac and Lake Mitchell freeze over and the city becomes covered with snow. Cadillac is connected to a number of trail systems popular with winter recreation enthusiasts. The city integrates unusually well into the corridors of travel created by snowmobilers.

Cadillac is also known as Chestnut Town, USA. The local area has a relatively high number of American chestnut trees, planted by pioneers from New York and Pennsylvania who settled in western Michigan. A blight in the early 20th century killed nearly every American Chestnut tree, but those in western Michigan had developed a mysterious resistance and survived.

Based on a single, limited study involving twenty people, Cadillac was ranked as one of three "hot spots" for Lou Gehrig's disease (also known as ALS) in the US. But the study made no attempt to assess the frequency of the disease in other parts of the state, or elsewhere in the country. The study was designed to examine the possible occurrence of the disease due to genetic influences. According to the study, the frequency of diagnosis of the disease within the city limits is reportedly more than 100 times the normal rate. The cause of this anomaly is not known.

Cadillac's public education system has a total of 10 schools, with approximately 3,100 students and 166 teachers with a student:teacher ratio of 19.1:1. Cadillac has 4 private primary and secondary schools with approximately 394 students, 20 teachers and a student:teacher ratio of 20:1.

The city has two high schools: Cadillac High School and Innovation High School. The area also has a junior high school, covering grades 7 and 8, located adjacent to the high school, and a middle school, Mackinaw Trail Middle School, covering grades 5 and 6. There are four elementary schools, Forest View Elementary, Franklin Elementary, Kenwood Elementary, and Lincoln Elementary.

Cadillac also has an alternative high school, located in the building that formerly housed Cooley Elementary School. Adult high school and GED courses are offered there as well. As a whole, the programs at Cooley are part of a curriculum that aids individuals in overcoming the exceptional obstacles to their educational and workforce goals.

Vocational career training is available to high school students free of charge in Cadillac and nearby schools at Wexford-Missaukee Independent School District (ISD) Career Tech Center (formerly Wexford-Missaukee Vocational Center or Voc-Tech). Students are bussed for part of the day to the Career Tech Center from their respective schools and receive credits toward high school graduation. Students are also able to earn certification in a chosen trade. Courses include:


Cosmetology is offered through the Career Tech Center, but at an off-campus location in downtown Cadillac. Adults can attend the vocational or cosmetology school with tuition or financial aid for certification.

Cadillac hosts the Wexford-Missaukee ISD Special Education for residents of the two counties who are in need of special services. This school is on the same campus as the Career Tech Center.

The class of 2006 was the largest class to go through Cadillac Public Schools.

Cadillac offers several options for private religious education.

Cadillac Heritage Christian offers nondenominational Christian education from pre-K through 12th grade. It is a coed school with 98 students and a teacher:student ratio of 1:11. Graduating classes are typically between 3–12 students.

Northview SDA Christian School has 5 students in grades 1–9. It is a coed Seventh Day Adventist school.

Noah's Ark Day School is a small alternative non-denominational Christian school for students in pre-K through first grade only. It is coed with 42 students and 1 teacher.

Cadillac's largest and most well-known private school is St. Ann School, a coed private Roman Catholic school with 236 students in grades pre-K through 7. The teacher:student ratio is 1:26. St. Ann is a member of the National Catholic Education Association. No Catholic high school education is offered at St. Ann School, and students typically attend public school for grades 8–12.

Northwoods Aviation, located at Wexford County Airport, offers training programs for piloting and servicing aircraft. Northwoods Aviation also offers primary instruction for those interested in sport pilot, private, and commercial certificates.

The Cadillac Institute of Cosmetology (formerly Cadillac Academy of Beauty) is a full service teaching salon in downtown Cadillac that offers training for general cosmetologists and specialized technicians to high school students through a partnership with Wexford-Missaukee Intermediate School District. Training is also available to adult students though private courses on a tuition basis. Upon completion of the program, students are qualified to take the state board exam to become a licensed cosmetologist or specialty technician.

The Baker College-Cadillac campus occupies just outside the City of Cadillac. The school has an enrollment of more than 1,300 students and offers Associate's and bachelor's degrees, in addition to professional certifications.

Cadillac is situated as the confluence of three highways: US 131, M-55 and M-115. Prior to 2001, the northern end of the freeway portion of US 131 was located at the southern entrance to Cadillac. With the construction of a bypass, the US 131 freeway was extended around the east side of the city. The former route of the highway through downtown Cadillac was redesignated as BUS US 131. In the city, BUS US 131 is named Mitchell Street, after George Mitchell, but may be referred to as main street.


The city is serviced by rail via the Great Lakes Central Railroad. This is primarily a freight line, although passenger service is expected in the future.


The White Pine Trail's northern terminus is in Cadillac. The trail, which stretches and originates from Comstock Park, follows an abandoned railroad bed into the center of the city. The trail is paved from the village of Leroy 16 miles north to Cadillac.



Cadillac is also home to NewsNet, a national digital broadcast news channel.



</doc>
<doc id="6589" url="https://en.wikipedia.org/wiki?curid=6589" title="COINTELPRO">
COINTELPRO

COINTELPRO (portmanteau derived from COunter INTELligence PROgram) (1956–1971) was a series of covert, and at times illegal, projects conducted by the United States Federal Bureau of Investigation (FBI) aimed at surveilling, infiltrating, discrediting, and disrupting domestic political organizations. FBI records show that COINTELPRO resources targeted groups and individuals that the FBI deemed subversive, including feminist organizations, the Communist Party USA, anti–Vietnam War organizers, activists of the civil rights movement or Black Power movement (e.g. Martin Luther King Jr., the Nation of Islam, and the Black Panther Party), environmentalist and animal rights organizations, the American Indian Movement (AIM), independence movements (such as Puerto Rican independence groups like the Young Lords), and a variety of organizations that were part of the broader New Left. The program also targeted the Ku Klux Klan in 1964. 

According to Noam Chomsky, in another instance in San Diego, the FBI financed, armed, and controlled an extreme right-wing group of former members of the Minutemen anti-communist para-military organization, transforming it into a group called the Secret Army Organization that targeted groups, activists, and leaders involved in the Anti-War Movement, using both intimidation and violent acts.

The FBI has used covert operations against domestic political groups since its inception; however, covert operations under the official COINTELPRO label took place between 1956 and 1971. COINTELPRO tactics are still used to this day, and have been alleged to include discrediting targets through psychological warfare; smearing individuals and groups using forged documents and by planting false reports in the media; harassment; wrongful imprisonment; and illegal violence, including assassination. The FBI's stated motivation was "protecting national security, preventing violence, and maintaining the existing social and political order."

Beginning in 1969, leaders of the Black Panther Party were targeted by the COINTELPRO and "neutralized" by being assassinated, imprisoned, publicly humiliated or falsely charged with crimes. Some of the Black Panthers affected included Fred Hampton, Mark Clark, Zayd Shakur, Geronimo Pratt, Mumia Abu-Jamal, and Marshall Conway. Common tactics used by COINTELPRO were perjury, witness harassment, witness intimidation, and withholding of evidence.

FBI Director J. Edgar Hoover issued directives governing COINTELPRO, ordering FBI agents to "expose, disrupt, misdirect, discredit, or otherwise Neutralize" the activities of these movements and especially their leaders. Under Hoover, the agent in charge of COINTELPRO was William C. Sullivan. Attorney General Robert F. Kennedy personally authorized some of the programs. Although Kennedy only gave written approval for limited wiretapping of Martin Luther King's phones "on a trial basis, for a month or so", Hoover extended the clearance so his men were "unshackled" to look for evidence in any areas of King's life they deemed worthy.

In April 2018, the "Atlanta Black Star" characterized the FBI as still engaging in COINTELPRO behavior by surveilling the Black Lives Matter movement. Internal documents dated as late as 2017 showed that the FBI had surveilled the movement.

Centralized operations under COINTELPRO officially began in August 1956 with a program designed to "increase factionalism, cause disruption and win defections" inside the Communist Party USA (CPUSA). Tactics included anonymous phone calls, Internal Revenue Service (IRS) audits, and the creation of documents that would divide the American communist organization internally. An October 1956 memo from Hoover reclassified the FBI's ongoing surveillance of black leaders, including it within COINTELPRO, with the justification that the movement was infiltrated by communists. In 1956, Hoover sent an open letter denouncing Dr. T.R.M. Howard, a civil rights leader, surgeon, and wealthy entrepreneur in Mississippi who had criticized FBI inaction in solving recent murders of George W. Lee, Emmett Till, and other African Americans in the South. When the Southern Christian Leadership Conference (SCLC), an African-American civil rights organization, was founded in 1957, the FBI began to monitor and target the group almost immediately, focusing particularly on Bayard Rustin, Stanley Levison, and eventually Martin Luther King Jr.
After the 1963 March on Washington for Jobs and Freedom, Hoover singled out King as a major target for COINTELPRO. Under pressure from Hoover to focus on King, Sullivan wrote:

In the light of King's powerful demagogic speech. ... We must mark him now if we have not done so before, as the most dangerous Negro of the future in this nation from the standpoint of communism, the Negro, and national security.

Soon after, the FBI was systematically bugging King's home and his hotel rooms, as they were now aware that King was growing in stature daily as the most prominent leader of the civil rights movement.

In the mid-1960s, King began to publicly criticize the Bureau for giving insufficient attention to the use of terrorism by white supremacists. Hoover responded by publicly calling King the most "notorious liar" in the United States. In his 1991 memoir, "Washington Post" journalist Carl Rowan asserted that the FBI had sent at least one anonymous letter to King encouraging him to commit suicide. Historian Taylor Branch documents an anonymous November 21, 1964 "suicide package" sent by the FBI that contained audio recordings, which were obtained through tapping King's phone and placing bugs throughout various hotel rooms over the past two years was created two days after the announcement of King's impending Nobel Peace Prize. The tape, which was prepared by FBI audio technician John Matter documented a series of King's sexual indiscretions combined with a letter telling him "There is only one way out for you. You better take it before your filthy, abnormal, fraudulent self is bared to the nation". King was subsequently informed that the audio would be released to the media if he did not acquiesce and commit suicide prior to accepting his Nobel Peace Award. When King refused to satisfy their coercion tactics, FBI Associate Director, Cartha D. DeLoach, commenced a media campaign offering the surveillance transcript to various news organizations including "Newsweek" and "Newsday". And even by 1969, as has been noted elsewhere, "[FBI] efforts to 'expose' Martin Luther King Jr. had not slackened even though King had been dead for a year. [The Bureau] furnished ammunition to conservatives to attack King's memory, and...tried to block efforts to honor the slain leader."

During the same period the program also targeted Malcolm X. While an FBI spokesman has denied that the FBI was "directly" involved in Malcolm's murder in 1965, it is documented that the Bureau worked to "widen the rift" between Malcolm and Elijah Muhammad through infiltration and the "sparking of acrimonious debates within the organization," rumor-mongering, and other tactics designed to foster internal disputes, which ultimately led to Malcolm's assassination. The FBI heavily infiltrated Malcolm's Organization of Afro-American Unity in the final months of his life. The Pulitzer Prize-winning asserts that most of the men who plotted Malcolm's assassination were never apprehended and that the full extent of the FBI's involvement in his death cannot be known.

Amidst the urban unrest of July–August 1967, the FBI began "COINTELPRO–BLACK HATE", which focused on King and the SCLC as well as the Student Nonviolent Coordinating Committee (SNCC), the Revolutionary Action Movement (RAM), the Deacons for Defense and Justice, Congress of Racial Equality (CORE), and the Nation of Islam. BLACK HATE established the Ghetto Informant Program and instructed 23 FBI offices to "disrupt, misdirect, discredit, or otherwise neutralize the activities of black nationalist hate type organizations".

A March 1968 memo stated the program's goal was to "prevent the coalition of militant black nationalist groups"; to "Prevent the RISE OF A 'MESSIAH' who could unify...the militant black nationalist movement"; "to pinpoint potential troublemakers and neutralize them before they exercise their potential for violence [against authorities]."; to "Prevent militant black nationalist groups and leaders from gaining RESPECTABILITY, by discrediting them to...both the responsible community and to liberals who have vestiges of sympathy..."; and to "prevent the long-range GROWTH of militant black organizations, especially among youth." Dr. King was said to have potential to be the "messiah" figure, should he abandon nonviolence and integrationism, and Stokely Carmichael was noted to have "the necessary charisma to be a real threat in this way" as he was portrayed as someone who espoused a much more militant vision of "black power." While the FBI was particularly concerned with leaders and organizers, they did not limit their scope of target to the heads of organizations. Individuals such as writers were also listed among the targets of operations.

This program coincided with a broader federal effort to prepare military responses for urban riots, and began increased collaboration between the FBI, Central Intelligence Agency, National Security Agency, and the Department of Defense. The CIA launched its own domestic espionage project in 1967 called Operation CHAOS. A particular target was the Poor People's Campaign, a national effort organized by King and the SCLC to occupy Washington, DC. The FBI monitored and disrupted the campaign on a national level, while using targeted smear tactics locally to undermine support for the march. The Black Panther Party was another targeted organization, wherein the FBI collaborated to destroy the party from the inside out.

Overall, COINTELPRO encompassed disruption and sabotage of the Socialist Workers Party (1961), the Ku Klux Klan (1964), the Nation of Islam, the Black Panther Party (1967), and the entire New Left social/political movement, which included antiwar, community, and religious groups (1968). A later investigation by the Senate's Church Committee (see below) stated that "COINTELPRO began in 1956, in part because of frustration with Supreme Court rulings limiting the Government's power to proceed overtly against dissident groups." Official congressional committees and several court cases have concluded that COINTELPRO operations against communist and socialist groups exceeded statutory limits on FBI activity and violated constitutional guarantees of freedom of speech and association.

The program was secret until 1971, when the Citizens' Commission to Investigate the FBI burgled an FBI field office in Media, Pennsylvania, took several dossiers, and exposed the program by passing this material to news agencies. The boxing match, known as the Fight of the Century, between Muhammad Ali and Joe Frazier in March 1971 provided cover for the activist group to successfully pull off the burglary; Muhammad Ali was himself a COINTELPRO target due to his involvement with the Nation of Islam and the anti-war movement. Many news organizations initially refused to publish the information. Within the year, Director J. Edgar Hoover declared that the centralized COINTELPRO was over, and that all future counterintelligence operations would be handled on a case-by-case basis.

Additional documents were revealed in the course of separate lawsuits filed against the FBI by NBC correspondent Carl Stern, the Socialist Workers Party, and a number of other groups. In 1976 the Select Committee to Study Governmental Operations with Respect to Intelligence Activities of the United States Senate, commonly referred to as the "Church Committee" for its chairman, Senator Frank Church of Idaho, launched a major investigation of the FBI and COINTELPRO. Many released documents have been partly, or entirely, redacted.

The Final Report of the Select Committee castigated the conduct of the intelligence community in its domestic operations (including COINTELPRO) in no uncertain terms:

The Church Committee documented a history of the FBI exercising political repression as far back as World War I, through the 1920s, when agents were charged with rounding up "anarchists, communists, socialists, reformists and revolutionaries" for deportation. The domestic operations were increased against political and anti-war groups from 1936 through 1976.

The intended effect of the FBI's COINTELPRO was to "expose, disrupt, misdirect, or otherwise neutralize" groups that the FBI officials believed were "subversive" by instructing FBI field operatives to:

1. Create a negative public image for target groups by surveiling activists and then releasing negative personal information to the public.

2. Break down internal organization by creating conflicts by having agents exacerbate racial tensions, or send anonymous letters to try to create conflicts.

3. Create dissension between groups by spreading rumors that other groups were stealing money.

4. Restrict access to public resources by pressuring non-profit organizations to cut off funding or material support.

5. Restrict the ability to organize protest.

6. Restrict the ability of individuals to participate in group activities by character assassinations, false arrests, surveillance.

At its inception, the program's main target was the Communist Party.

In an interview with the BBC's Andrew Marr in February 1996, Noam Chomsky—a political activist and MIT professor of linguistics—spoke about the purpose and the targets of COINTELPRO, saying:

COINTELPRO was a program of subversion carried out not by a couple of petty crooks but by the national political police, the FBI, under four administrations... by the time it got through, I won't run through the whole story, it was aimed at the entire new left, at the women's movement, at the whole black movement, it was extremely broad. Its actions went as far as political assassination.

According to the Church Committee:
While the declared purposes of these programs were to protect the "national security" or prevent violence, Bureau witnesses admit that many of the targets were nonviolent and most had no connections with a foreign power. Indeed, nonviolent organizations and individuals were targeted because the Bureau believed they represented a "potential" for violence—and nonviolent citizens who were against the war in Vietnam were targeted because they gave "aid and comfort" to violent demonstrators by lending respectability to their cause.

The imprecision of the targeting is demonstrated by the inability of the Bureau to define the subjects of the programs. The Black Nationalist program, according to its supervisor, included "a great number of organizations that you might not today characterize as black nationalist but which were in fact primarily black." Thus, the nonviolent Southern Christian Leadership Conference was labeled as a Black Nationalist-"Hate Group."

Furthermore, the actual targets were chosen from a far broader group than the titles of the programs would imply. The CPUSA program targeted not only Communist Party members but also sponsors of the National Committee to Abolish the House Un-American Activities Committee and civil rights leaders allegedly under Communist influence or deemed to be not sufficiently "anti-Communist". The Socialist Workers Party program included non-SWP sponsors of anti-war demonstrations which were cosponsored by the SWP or the Young Socialist Alliance, its youth group. The Black Nationalist program targeted a range of organizations from the Panthers to SNCC to the peaceful Southern Christian Leadership Conference, and included every Black Student Union and many other black student groups. New Left targets ranged from the SDS to the InterUniversity Committee for Debate on Foreign Policy, from Antioch College ("vanguard of the New Left") to the New Mexico Free University and other "alternate" schools, and from underground newspapers to students' protesting university censorship of a student publication by carrying signs with four-letter words on them.

Examples of surveillance, spanning all presidents from FDR to Nixon, both legal and illegal, contained in the Church Committee report:

Groups that were known to be targets of COINTELPRO operations include:

The COINTELPRO operators targeted multiple groups at once, and encouraged splintering of these groups from within. In letter writing campaigns (wherein false letters were sent on behalf of members of parties), the FBI ensured that groups would not unite in their causes. For instance they, launched a campaign specifically to alienate the Black Panther Party from the Mau Maus, Young Lords, Young Patriots and SDS. These racially diverse groups had been building alliances, in part due to charismatic leaders such as Fred Hampton and his attempts to create a "Rainbow Coalition". The FBI was concerned with ensuring that groups could not gain traction through unity, specifically across racial lines. One of the main ways of targeting these groups was to arouse suspicion between the different parties and causes. In this way the bureau took on a divide and conquer offensive.

The COINTELPRO documents show numerous cases of the FBI's intentions to prevent and disrupt protests against the Vietnam War. Many techniques were used to accomplish this task. "These included promoting splits among antiwar forces, encouraging red-baiting of socialists, and pushing violent confrontations as an alternative to massive, peaceful demonstrations." One 1966 COINTELPRO operation tried to redirect the Socialist Workers Party from their pledge of support for the antiwar movement.

The FBI has said that it no longer undertakes COINTELPRO or COINTELPRO-like operations. However, critics have claimed that agency programs in the spirit of COINTELPRO targeted groups such as the Committee in Solidarity with the People of El Salvador, the American Indian Movement, Earth First!, and the anti-globalization movement.

According to attorney Brian Glick in his book "War at Home", the FBI used five main methods during COINTELPRO:

The FBI specifically developed tactics intended to heighten tension and hostility between various factions in the black power movement, for example between the Black Panthers and the US Organization. For instance, the FBI sent a fake letter to the US Organization exposing a supposed Black Panther plot to murder the head of the US Organization, Ron Karenga. They then intensified this by spreading falsely attributed cartoons in the black communities pitting the Black Panther Party against the US Organization. This resulted in numerous deaths, among which were San Diego Black Panther Party members John Huggins, Bunchy Carter and Sylvester Bell. Another example of the FBI's anonymous letter writing campaign is how they turned the Blackstone Rangers head, Jeff Fort, against former ally Fred Hampton, by stating that Hampton had a hit on Fort. They also were instrumental in developing the rift between Black Panther Party leaders Eldridge Cleaver and Huey Newton, as executed through false letters inciting the two leaders of the Black Panther Party.

Dhoruba Bin Wahad, a former Black Panther, reflects on how these tactics made him feel, saying he had a combat mentality and felt like he was at war with the government. When asked about why he thinks the Black Panthers were targeted he said, "In the United States, the equivalent of the military was the local police. During the early sixties, at the height of the civil rights movement, and the human rights movement, the police in the United States became increasingly militaristic. They began to train out of military bases in the United States. The Law Enforcement Assistance Act supplied local police with military technology, everything from assault rifles to army personnel carriers. In his opinion, the Counterintelligence Program went hand-in-hand with the militarization of the police in the Black community, with the militarization of police in America."

The FBI also conspired with the police departments of many U.S. cities (San Diego, Los Angeles, San Francisco, Oakland, Philadelphia, Chicago) to encourage repeated raids on Black Panther homes—often with little or no evidence of violations of federal, state, or local laws—which resulted directly in the police killing many members of the Black Panther Party, most notably Chicago Black Panther Party Chairman Fred Hampton on December 4, 1969. Before the death of Hampton, long-term infiltrator, William O'Neal, shared floor plans of his apartment with the COINTELPRO team. He then gave Hampton a dose of secobarbital that rendered Hampton unconscious during the raid on his home.

In order to eliminate black militant leaders whom they considered dangerous, the FBI is believed to have worked with local police departments to target specific individuals, accuse them of crimes they did not commit, suppress exculpatory evidence and falsely incarcerate them. Elmer "Geronimo" Pratt, a Black Panther Party leader, was incarcerated for 27 years before a California Superior Court vacated his murder conviction, ultimately freeing him. Appearing before the court, an FBI agent testified that he believed Pratt had been framed, because both the FBI and the Los Angeles Police Department knew he had not been in the area at the time the murder occurred.

Some sources claim that the FBI conducted more than 200 "black bag jobs", which were warrantless surreptitious entries, against the targeted groups and their members.

In 1969 the FBI special agent in San Francisco wrote Hoover that his investigation of the Black Panther Party had concluded that in his city, at least, the Panthers were primarily engaged in feeding breakfast to children. Hoover fired back a memo implying the agent's career goals would be directly affected by his supplying evidence to support Hoover's view that the Black Panther Party was "a violence-prone organization seeking to overthrow the Government by revolutionary means".

Hoover supported using false claims to attack his political enemies. In one memo he wrote: "Purpose of counterintelligence action is to disrupt the Black Panther Party and it is immaterial whether facts exist to substantiate the charge."

In one particularly controversial 1965 incident, white civil rights worker Viola Liuzzo was murdered by Ku Klux Klansmen, who gave chase and fired shots into her car after noticing that her passenger was a young black man; one of the Klansmen was Gary Thomas Rowe, an acknowledged FBI informant. The FBI spread rumors that Liuzzo was a member of the Communist Party and had abandoned her children to have sexual relationships with African Americans involved in the civil rights movement. FBI records show that J. Edgar Hoover personally communicated these insinuations to President Johnson.

FBI informant Rowe has also been implicated in some of the most violent crimes of the 1960s civil rights era, including attacks on the Freedom Riders and the 1963 Birmingham, Alabama 16th Street Baptist Church bombing.

The FBI also financed, armed, and controlled an extreme right-wing group of former Minutemen, transforming it into a group called the Secret Army Organization that targeted groups, activists, and leaders involved in the Anti-War Movement, using both intimidation and violent acts.

Hoover ordered preemptive action "to pinpoint potential troublemakers and neutralize them before they exercise their potential for violence."

The final report of the Church Committee concluded:

Too many people have been spied upon by too many Government agencies and too much information has been illegally collected. The Government has often undertaken the secret surveillance of citizens on the basis of their political beliefs, even when those beliefs posed no threat of violence or illegal acts on behalf of a hostile foreign power. The Government, operating primarily through secret and biased informants, but also using other intrusive techniques such as wiretaps, microphone "bugs", surreptitious mail opening, and break-ins, has swept in vast amounts of information about the personal lives, views, and associations of American citizens. Investigations of groups deemed potentially dangerous—and even of groups suspected of associating with potentially dangerous organizations—have continued for decades, despite the fact that those groups did not engage in unlawful activity.

Groups and individuals have been assaulted, repressed, harassed and disrupted because of their political views, social beliefs and their lifestyles. Investigations have been based upon vague standards whose breadth made excessive collection inevitable. Unsavory, harmful and vicious tactics have been employed—including anonymous attempts to break up marriages, disrupt meetings, ostracize persons from their professions, and provoke target groups into rivalries that might result in deaths. Intelligence agencies have served the political and personal objectives of presidents and other high officials. While the agencies often committed excesses in response to pressure from high officials in the Executive branch and Congress, they also occasionally initiated improper activities and then concealed them from officials whom they had a duty to inform.

Governmental officials—including those whose principal duty is to enforce the law—have violated or ignored the law over long periods of time and have advocated and defended their right to break the law.

The Constitutional system of checks and balances has not adequately controlled intelligence activities. Until recently the Executive branch has neither delineated the scope of permissible activities nor established procedures for supervising intelligence agencies. Congress has failed to exercise sufficient oversight, seldom questioning the use to which its appropriations were being put. Most domestic intelligence issues have not reached the courts, and in those cases when they have reached the courts, the judiciary has been reluctant to grapple with them.

While COINTELPRO was officially terminated in April 1971, domestic espionage continued. Between 1972 and 1974, it is documented that the Bureau planted over 500 bugs without a warrant and opened over 2,000 pieces of personal mail. More recent targets of covert action include the American Indian Movement (AIM), Earth First!, and Committees in Solidarity with the People of El Salvador. Documents released under the FOIA show that the FBI tracked the late David Halberstam—a Pulitzer Prize-winning journalist and author—for more than two decades. "Counterterrorism" guidelines implemented during the Reagan administration have been described as allowing a return to COINTELPRO tactics. Some radical groups accuse factional opponents of being FBI informants or assume the FBI is infiltrating the movement. COINTELPRO survivor Filiberto Ojeda Rios was killed by the FBI's hostage rescue team in 2005, his death described as an assassination by a United Nations special committee. Some authors, lawyers and academics have argued that the outlawed COINTELPRO program was reinstated in 1994 and still exists today under the U.S. Department of Justice Community Oriented Policing Program ("COPS") written and enacted in the Violent Crime Control and Law Enforcement Act of 1994 by then President Bill Clinton and then Senator Joseph Biden. The Surreptitious Reincarnation of COINTELPRO with the COPS Gang-Stalking Program

Environmentalist Eric McDavid convicted on arson charges was released after documents emerged demonstrating that the FBI informant in his Earth Liberation Front group provided crucial leadership, information, and material without which the crime could not have been committed, repeating the same pattern of behaviour of COINTELPRO. It has been claimed these sorts of practices have become widespread in FBI counter-terrorism cases targeting left wing politics and Muslims in the 2009 Bronx terrorism plot and others.

Authors such as Ward Churchill, Rex Weyler, and Peter Matthiessen allege that the federal government intended to acquire uranium deposits on the Lakota tribe's reservation land, and that this motivated a larger government conspiracy against AIM activists on the Pine Ridge reservation. Others believe COINTELPRO continues and similar actions are being taken against activist groups. Caroline Woidat says that, with respect to Native Americans, COINTELPRO should be understood within a historical context in which "Native Americans have been viewed and have viewed the world themselves through the lens of conspiracy theory." Other authors argue that while some conspiracy theories related to COINTELPRO are unfounded, the issue of ongoing government surveillance and repression is real. FBI Agent Richard G. Held is known to have increased FBI support for the Guardians of the Oglala Nation (GOON) squads accused of the assault and murder of hundreds of AIM supporters. The Bureau refused to investigate the 64 cases of homicide directly linked to GOON, but committed its resources overwhelmingly to prosecute AIM.

In April 2018, the "Atlanta Black Star" characterized the FBI as still engaging in COINTELPRO behavior by surveilling the Black Lives Matter movement. In 2014, the FBI tracked an activist of the movement using tactics which "The Intercept" found "reminiscent of a rich American history of targeting black Americans," including "FBI's notorious COINTELPRO program," which "was aimed at disrupting and infiltrating civil rights and black nationalist movements from 1956 to 1971." This practice, along with the imprisonment of black activists for their views, has been associated with the new FBI designation of "Black Identity Extremists."







</doc>
<doc id="6590" url="https://en.wikipedia.org/wiki?curid=6590" title="Cruise missile">
Cruise missile

A cruise missile is a guided missile used against terrestrial targets, that remains in the atmosphere and flies the major portion of its flight path at approximately constant speed. Cruise missiles are designed to deliver a large warhead over long distances with high precision. Modern cruise missiles are capable of travelling at supersonic or high subsonic speeds, are self-navigating, and are able to fly on a non-ballistic, extremely low-altitude trajectory.

The idea of an "aerial torpedo" was shown in the British 1909 film "The Airship Destroyer", where flying torpedoes controlled wirelessly are used to bring down airships bombing London.

In 1916, American aviator Lawrence Sperry built and patented an "aerial torpedo", the Hewitt-Sperry Automatic Airplane, a small biplane carrying a TNT charge, a Sperry autopilot and a barometric altitude control. Inspired by these experiments, the United States Army developed a similar flying bomb called the Kettering Bug. Germany had also flown trials with remote-controlled aerial gliders "(Torpedogleiter)" built by Siemens-Schuckert beginning in 1916.

In the period between the World Wars the United Kingdom developed the Larynx (Long Range Gun with Lynx Engine), which underwent a few flight tests in the 1920s.

In the Soviet Union, Sergei Korolev headed the GIRD-06 cruise missile project from 1932 to 1939, which used a rocket-powered boost-glide bomb design. The 06/III (RP-216) and 06/IV (RP-212) contained gyroscopic guidance systems. The vehicle was designed to boost to 28 km altitude and glide a distance of 280 km, but test flights in 1934 and 1936 only reached an altitude of 500 meters.

In 1944, Germany deployed the first operational cruise missiles in World War II. The V-1, often called a flying bomb, contained a gyroscope guidance system and was propelled by a simple pulsejet engine, the sound of which gave it the nickname of "buzz bomb" or "doodlebug". Accuracy was sufficient only for use against very large targets (the general area of a city), while the range of 250 km was significantly lower than that of a bomber carrying the same payload. The main advantages were speed (although not sufficient to outperform contemporary propellor-driven interceptors) and expendability. The production cost of a V-1 was only a small fraction of that of a V-2 supersonic ballistic missile, carrying a similar-sized warhead. Unlike the V-2, however, the initial deployments of the V-1 required stationary launch ramps which were susceptible to bombardment. Nazi Germany, in 1943, also developed the Mistel composite aircraft program, which can be seen as a rudimentary air-launched cruise missile, where a piloted fighter-type aircraft was mounted atop an unpiloted bomber-sized aircraft that was packed with explosives to be released while approaching the target. Bomber-launched variants of the V-1 saw limited operational service near the end of the war, with the pioneering V-1's design reverse-engineered by the Americans as the Republic-Ford JB-2 cruise missile.

Immediately after the war the United States Air Force had 21 different guided missile projects, including would-be cruise missiles. All but four were cancelled by 1948, — the Air Materiel Command BANSHEE, the SM-62 Snark, the SM-64 Navaho, and the MGM-1 Matador. The BANSHEE design was similar to Operation Aphrodite; like Aphrodite, it failed, and was cancelled in April 1949. Concurrently, the US Navy's Operation: BUMBLEBEE, was conducted at Topsail Island, North Carolina, from c. June 1, 1946, to July 28, 1948. Operation: BUMBLEBEE produced proof-of-concept technologies that influenced the US military's other missile projects.

During the Cold War period both the United States and the Soviet Union experimented further with the concept, deploying early cruise missiles from land, submarines and aircraft. The main outcome of the United States Navy submarine missile project was the SSM-N-8 Regulus missile, based upon the V-1.

The United States Air Force's first operational surface-to-surface missile was the winged, mobile, nuclear-capable MGM-1 Matador, also similar in concept to the V-1. Deployment overseas began in 1954, first to West Germany and later to the Republic of China (Taiwan) and South Korea. On 7 November 1956, U.S. Air Force deployed Matador units in West Germany, whose missiles were capable of striking targets in the Warsaw Pact, from their fixed day-to-day sites to unannounced dispersed launch locations. This alert was in response to the crisis posed by the Soviet attack on Hungary which suppressed the Hungarian Revolution of 1956.

Between 1957 and 1961 the United States followed an ambitious and well-funded program to develop a nuclear-powered cruise missile, Supersonic Low Altitude Missile (SLAM). It was designed to fly below the enemy's radar at speeds above Mach 3 and carry a number of hydrogen bombs that it would drop along its path over enemy territory. Although the concept was proven sound and the 500 megawatt engine finished a successful test run in 1961, no airworthy device was ever completed. The project was finally abandoned in favor of ICBM development.

While ballistic missiles were the preferred weapons for land targets, heavy nuclear and conventional weapon tipped cruise missiles were seen by the USSR as a primary weapon to destroy United States naval carrier battle groups. Large submarines (for example, Echo and Oscar classes) were developed to carry these weapons and shadow United States battle groups at sea, and large bombers (for example, Backfire, Bear, and Blackjack models) were equipped with the weapons in their air-launched cruise missile (ALCM) configuration.

Cruise missiles generally consist of a guidance system, payload, and aircraft propulsion system, housed in an airframe with small wings and empennage for flight control. Payloads usually consist of a conventional warhead or a nuclear warhead. Cruise missiles tend to be propelled by a jet engine, turbofan engines being preferred due to their greater efficiency at low altitude and subsonic speed.

Guidance systems also vary greatly. Low-cost systems use a radar altimeter, barometric altimeter and clock to navigate a digital strip map. More advanced systems use inertial guidance, satellite guidance and terrain contour matching (TERCOM). Use of an automatic target recognition (ATR) algorithm/device in the guidance system increases accuracy of the missile. The Standoff Land Attack Missile features an ATR unit from General Electric.

Cruise missiles can be categorized by size, speed (subsonic or supersonic), and range, and whether launched from land, air, surface ship, or submarine. Often versions of the same missile are produced for different launch platforms; sometimes air- and submarine-launched versions are a little lighter and smaller than land- and ship-launched versions.

Guidance systems can vary across missiles. Some missiles can be fitted with any of a variety of navigation systems (Inertial navigation, TERCOM, or satellite navigation). Larger cruise missiles can carry either a conventional or a nuclear warhead, while smaller ones carry only conventional warheads.

A hypersonic speed cruise missile would travel at least five times the speed of sound (Mach 5).

These missiles travel faster than the speed of sound, usually using ramjet engines. The range is typically 100–500 km, but can be greater. Guidance systems vary.

Examples:


The United States, Russia, India, United Kingdom, Israel, South Korea, Turkey, Iran, China and Pakistan have developed several long-range subsonic cruise missiles. These missiles have a range of over and fly at about . They typically have a launch weight of about and can carry either a conventional or a nuclear warhead. Earlier versions of these missiles used inertial navigation; later versions use much more accurate TERCOM and DSMAC systems. Most recent versions can use satellite navigation.

Examples:

These missiles are about the same size and weight and fly at similar speeds to the above category. Guidance systems vary.

Examples:


These are subsonic missiles which weigh around and have a range of up to .

Examples:

The most common mission for cruise missiles is to attack relatively high-value targets such as ships, command bunkers, bridges and dams. Modern guidance systems permit accurate attacks.

The United States Air Force (USAF) deploys an air-launched cruise missile, the AGM-86 ALCM. The Boeing B-52 Stratofortress is the exclusive delivery vehicle for the AGM-86 and AGM-129 ACM. Both missile types are configurable for either conventional or nuclear warheads.
The USAF adopted the AGM-86 for its bomber fleet while AGM-109 was adapted to launch from trucks and ships and adopted by the USAF and Navy. The truck-launched versions, and also the Pershing II and SS-20 Intermediate Range Ballistic Missiles, were later destroyed under the bilateral INF (Intermediate Range Nuclear Forces) treaty with the USSR.

The British Royal Navy (RN) also operates cruise missiles, specifically the U.S.-made Tomahawk, used by the RN's nuclear submarine fleet. UK conventional warhead versions were first fired in combat by the RN in 1999, during the Kosovo War (the United States fired cruise missiles in 1991). The Royal Air Force uses the Storm Shadow cruise missile on its Tornado GR4 aircraft. It is also used by France, where it is known as SCALP EG, and carried by the Armée de l'Air's Mirage 2000 and Rafale aircraft.

India and Russia have jointly developed the supersonic cruise missile BrahMos. There are three versions of the Brahmos: ship/land-launched, air-launched and sub-launched. The ship/land-launched version were operational as of late 2007. The Brahmos has the capability to attack targets on land. Russia also continues to operate other cruise missiles: the SS-N-12 Sandbox, SS-N-19 Shipwreck, SS-N-22 Sunburn and SS-N-25 Switchblade. Germany and Spain operate the Taurus missile while Pakistan has made the Babur missile, a variant of the US Tomahawk missile. Both the People's Republic of China and the Republic of China (Taiwan) have designed several cruise missile variants, such as the well-known C-802, some of which are capable of carrying biological, chemical, nuclear, and conventional warheads.

China has CJ-10 land attack cruise missile which is capable of carrying a nuclear warhead.

The French Force de Frappe nuclear forces include both land and sea-based bombers with Air-Sol Moyenne Portée high speed medium range nuclear cruise missiles. Two models are in use, ASMP and a newer ASMP-A. Approximately 60 nuclear missiles are in service, 50 land based and 10 sea-based. 

India in 2017 successfully flight-tested its indigenous Nirbhay ('Fearless') land-attack cruise missile, which can deliver nuclear warheads to a strike range of 1,000-km

The Israel Defense Forces reportedly deploy the medium-range air-launched Popeye Turbo ALCM and the Popeye Turbo SLCM medium-long range cruise missile with nuclear warheads on Dolphin class submarines. 

Pakistan currently has four cruise missile systems: the air-launched Ra'ad; the ground and underwater launched Babur; ship-launched Harbah missile and surface launched Zarb missile. Both, Ra'ad and Babur, can carry nuclear warheads between 10 and 25 kt, and deliver them to targets at a range of and respectively. Babur has been in service with the Pakistan Army since 2010.

Russia has Kh-55SM cruise missiles, with similar to United States' AGM-129 range of 3000 km, but are able to carry a more powerful warhead of 200 kt. They are equipped with a TERCOM system which allows them to cruise at an altitude lower than 110 meters at subsonic speeds while obtaining a CEP accuracy of 15 meters with an Inertial navigation system. They are air-launched from either Tupolev Tu-95s, Tupolev Tu-22Ms, or Tupolev Tu-160s, each able to carry 16 for the Tu-95, 12 for the Tu-160, and 4 for the Tu-22M. A stealth version of the missile, the Kh-101 is in development. It has similar qualities as the Kh-55, except that its range has been extended to 5,000 km, equipped with a 1,000 kg conventional warhead, and has stealth features which reduces its probability of intercept.

In the late 1950s and early 1960s, the Soviet Union was attempting to develop cruise missiles. In this short time frame, the Soviet Union was working on nearly ten different types of cruise missiles. However, due to resources, most of the initial types of cruise missiles developed by the Soviet Union were Sea- Launched Cruise Missiles or Submarine-Launched Cruise Missiles (SLCMs). The SS-N-1 cruise missile was developed to have different configurations to be fired from a submarine or a ship. However, as the time progressed, the Soviet Union began to work on air launched cruise missiles as well (ALCM). These ACLM missiles were typically delivered via bombers designated as "Blinders" or "Backfire". The missiles in this configuration were called the AS-1, and AS-2 with eventual new variants with more development time. The main purpose of Soviet-based cruise missiles was to have defense and offensive mechanisms against enemy ships; in other words most of the Soviet cruise missiles were anti-ship missiles. the 1980s the Soviet Union had developed an arsenal of cruise missiles nearing 600 platforms which consisted of land, sea, and air delivery systems.

The United States has deployed four nuclear cruise missiles at one time or another.

Currently cruise missiles are among the most expensive of single-use weapons, up to several million dollars apiece. One consequence of this is that its users face difficult choices in target allocation, to avoid expending the missiles on targets of low value. For instance, during the 2001 strikes on Afghanistan the United States attacked targets of very low monetary value with cruise missiles, which led many to question the efficiency of the weapon. However, proponents of the cruise missile counter that the same argument applies to other types of UAVs: they are cheaper than human pilots when total training and infrastructure costs are taken into account, not to mention the risk of loss of personnel. As demonstrated in Libya in 2011 and prior conflicts, cruise missiles are much more difficult to detect and intercept than other aerial assets (reduced radar cross-section, infrared and visual signature due to smaller size), suiting them to attacks against static air defense systems.




</doc>
<doc id="6591" url="https://en.wikipedia.org/wiki?curid=6591" title="Crete">
Crete

Crete (, "" ; Ancient Greek: , "Krḗtē") is the largest and most populous of the Greek islands, the 88th largest island in the world and the fifth largest island in the Mediterranean Sea, after Sicily, Sardinia, Cyprus, and Corsica. It bounds the southern border of the Aegean sea. Crete lies approximately south of the Greek mainland. With an area of and a coastline of 1,046 km (650 mi), Crete is a recognisable feature of the islands of Greece.

Crete and a number of surrounding islands and islets constitute the region of Crete (), the southernmost of the 13 top-level administrative units of Greece; the region is the fifth most populous region of Greece. Its capital and largest city is Heraklion, located on the northern shore of the island. , the region had a population of 623,065. The Dodecanese are located to the northeast of Crete, while the Cyclades are situated to northwest, separated by the Sea of Crete. The Peloponnese is to the region's northwest. 

Humans have inhabited the island before 130,000 years ago, during the Paleolithic age. Crete was the centre of Europe's first advanced civilization, the Minoans, from 2700 to 1420 BC; the Minoan civilization was overrun by the Mycenaean civilization from mainland Greece. Later, Crete would fall under Roman rule, and afterwards the Byzantines Empire, Arabs, the Venetian Republic, and the Ottoman Empire successively ruled Crete. The Cretan people, who maintained a desire to join the Greek state, achieved independence from the Ottomans in 1898 as the Cretan State and became part of Greece in December 1913.

The island is mountainous, and its character is defined by a high mountain range crossing from west to east; the range of Lefka Ori contains Crete's highest point, Mount Ida. Crete forms a significant part of the economy and cultural heritage of Greece, while retaining its own local cultural traits (such as its own poetry and music). The Nikos Kazantzakis at Heraklion and the Daskalogiannis airport at Chania serve international travellers. The palace of Knossos, a Bronze age settlement and ancient Minoan city, lies in Heraklion in Crete.

The island is first referred to as "Kaptara" in texts from the Syrian city of Mari dating from the 18th century BC, repeated later in Neo-Assyrian records and the Bible ("Caphtor"). It was also known in ancient Egyptian as "Keftiu", strongly suggesting a similar Minoan name for the island.

The current name of Crete is thought to be first attested in Mycenaean Greek texts written in Linear B, through the words "ke-re-te" (*"Krētes"; later Greek: , plural of ), "ke-re-si-jo" (*"Krēsijos"; later Greek: ), "Cretan". In Ancient Greek, the name Crete () first appears in Homer's Odyssey. Its etymology is unknown. One proposal derives it from a hypothetical Luwian word, "*kursatta" (cf. "kursawar" "island", "kursattar" "cutting, sliver"). In Latin, it became "Creta".

The original Arabic name of Crete was "Iqrīṭiš" ( < , but after the Emirate of Crete's establishment of its new capital at "Rabḍ al-Ḫandaq" (modern Iraklion), both the city and the island became known as ("Chandax") or ("Chandakas"), which gave Latin, Italian and Venetian "Candia", from which were derived French "Candie" and English "Candy" or "Candia". Under Ottoman rule, in Ottoman Turkish, Crete was called "Girit" ().

Crete is the largest island in Greece and the fifth largest island in the Mediterranean Sea. It is located in the southern part of the Aegean Sea separating the Aegean from the Libyan Sea.

The island has an elongated shape: it spans from east to west, is at its widest point, and narrows to as little as (close to Ierapetra). Crete covers an area of , with a coastline of ; to the north, it broaches the Sea of Crete (); to the south, the Libyan Sea (); in the west, the Myrtoan Sea, and toward the east the Karpathian Sea. It lies approximately south of the Greek mainland.

Crete is mountainous, and its character is defined by a high mountain range crossing from west to east, formed by three different groups of mountains:

These mountains lavished Crete with valleys, such as Amari valley, fertile plateaus, such as Lasithi plateau, Omalos and Nidha; caves, such as Gourgouthakas, Diktaion, and Idaion (the birthplace of the ancient Greek god Zeus); and a number of gorges.

The island has a number of gorges, such as the Samariá Gorge, Imbros Gorge, Kourtaliotiko Gorge, Ha Gorge, Platania Gorge, the Gorge of the Dead (at Kato Zakros, Sitia) and Richtis Gorge and (Richtis) waterfall at Exo Mouliana in Sitia.

The rivers of Crete include the Ieropotamos River, the Koiliaris, the Anapodiaris, the Almiros, the Giofyros, and Megas Potamos. There are only two freshwater lakes in Crete: Lake Kournas and Lake Agia, which are both in Chania regional unit. Lake Voulismeni at the coast, at Aghios Nikolaos, was formerly a freshwater lake but is now connected to the sea, in Lasithi. Lakes that were created by dams also exist in Crete. There are three: the lake of Aposelemis Dam, the lake of Potamos Dam, and the lake of Mpramiana Dam.

A large number of islands, islets, and rocks hug the coast of Crete. Many are visited by tourists, some are only visited by archaeologists and biologists. Some are environmentally protected. A small sample of the islands includes:

Off the south coast, the island of Gavdos is located south of Hora Sfakion and is the southernmost point of Europe.

Crete straddles two climatic zones, the Mediterranean and the North African, mainly falling within the former. As such, the climate in Crete is primarily Mediterranean. The atmosphere can be quite humid, depending on the proximity to the sea, while winter is fairly mild. Snowfall is common on the mountains between November and May, but rare in the low-lying areas. While some mountain tops are snow-capped for most of the year, near the coast snow only stays on the ground for a few minutes or hours. However, a truly exceptional cold snap swept the island in February 2004, during which period the whole island was blanketed with snow. During the Cretan summer, average temperatures reach the high 20s-low 30s Celsius (mid 80s to mid 90s Fahrenheit), with maxima touching the upper 30s-mid 40s.

The south coast, including the Mesara Plain and Asterousia Mountains, falls in the North African climatic zone, and thus enjoys significantly more sunny days and high temperatures throughout the year. There, date palms bear fruit, and swallows remain year-round rather than migrate to Africa. The fertile region around Ierapetra, on the southeastern corner of the island, is renowned for its exceptional year-round agricultural production, with all kinds of summer vegetables and fruit produced in greenhouses throughout the winter. Western Crete (Chania province) receives more rain and is more erosive compared to the Eastern part of Crete.

Crete is the most populous island in Greece with a population of more than 600,000 people. Approximately 42% live in Crete's main cities and towns whilst 45% live in rural areas.

Crete with its nearby islands form the Crete Region (, "Periféria Krítis"), one of the 13 regions of Greece which were established in the 1987 administrative reform. Under the 2010 Kallikratis plan, the powers and authority of the regions were redefined and extended. The region is based at Heraklion and is divided into four regional units (pre-Kallikratis prefectures). From west to east these are: Chania, Rethymno, Heraklion, and Lasithi. These are further subdivided into 24 municipalities.

The region's governor is, since 1 January 2011, Stavros Arnaoutakis, who was elected in the November 2010 local administration elections for the Panhellenic Socialist Movement.

Heraklion is the largest city and capital of Crete. Chania was the capital until 1971. The principal cities are:

The economy of Crete is predominantly based on services and tourism. However, agriculture also plays an important role and Crete is one of the few Greek islands that can support itself independently without a tourism industry. The economy began to change visibly during the 1970s as tourism gained in importance. Although an emphasis remains on agriculture and stock breeding, because of the climate and terrain of the island, there has been a drop in manufacturing, and an observable expansion in its service industries (mainly tourism-related). All three sectors of the Cretan economy (agriculture/farming, processing-packaging, services), are directly connected and interdependent. The island has a per capita income much higher than the Greek average, whereas unemployment is at approximately 4%, one-sixth of that of the country overall.

As in many regions of Greece, viticulture and olive groves are significant; oranges and citrons are also cultivated. Until recently there were restrictions on the import of bananas to Greece, therefore bananas were grown on the island, predominantly in greenhouses. Dairy products are important to the local economy and there are a number of speciality cheeses such as mizithra, anthotyros, and kefalotyri.

The island has three significant airports, Nikos Kazantzakis at Heraklion, the Daskalogiannis airport at Chania and a smaller one in Sitia. The first two serve international routes, acting as the main gateways to the island for travellers. There is a long-standing plan to replace Heraklion airport with a completely new airport at Kastelli, where there is presently an air force base.
The island is well served by ferries, mostly from Athens, by ferry companies such as Minoan Lines and ANEK Lines.
Although the road network leads almost everywhere, there is a lack of modern highways, although this is gradually changing with the completion of the northern coastal spine highway.
Also, during the 1930s there was a narrow-gauge industrial railway in Heraklion, from Giofyros in the west side of the city to the port. There are now no railway lines on Crete. The government is planning the construction of a line from Chania to Heraklion via Rethymno.

Newspapers have reported that the Ministry of Mercantile Marine is ready to support the agreement between Greece, South Korea, Dubai Ports World and China for the construction of a large international container port and free trade zone in southern Crete near Tympaki; the plan is to expropriate 850 ha of land. The port would handle 2 million containers per year, but the project has not been universally welcomed because of its environmental, economic and cultural impact. As of January 2013, the project has still not been confirmed, although there is mounting pressure to approve it, arising from Greece's difficult economic situation.

There are plans for underwater cables going from mainland Greece to Israel and Egypt passing by Crete and Cyprus: EuroAfrica Interconnector and EuroAsia Interconnector. They would connect Crete electrically with mainland Greece, ending energy isolation of Crete. Now Hellenic Republic covers for Crete electricity costs difference of around €300 million per year.

In 2002, the paleontologist Gerard Gierlinski discovered fossil footprints left by ancient human relatives 5,600,000 years ago.

Hominids settled in Crete at least 130,000 years ago. In the later Neolithic and Bronze Age periods, under the Minoans, Crete had a highly developed, literate civilisation. It has been ruled by various ancient Greek entities, the Roman Empire, the Byzantine Empire, the Emirate of Crete, the Republic of Venice and the Ottoman Empire. After a brief period of independence (1897–1913) under a provisional Cretan government, it joined the Kingdom of Greece. It was occupied by Nazi Germany during the Second World War.

The first human settlement in Crete dates before 130,000 years ago, during the Paleolithic age. Settlements dating to the aceramic Neolithic in the 7th millennium BC, used cattle, sheep, goats, pigs and dogs as well as domesticated cereals and legumes; ancient Knossos was the site of one of these major Neolithic (then later Minoan) sites. Other neolithic settlements include those at Kephala, Magasa, and Trapeza.

Crete was the centre of Europe's first advanced civilization, the Minoan (). This civilization wrote in the undeciphered script known as Linear A. Early Cretan history is replete with legends such as those of King Minos, Theseus and the Minotaur, passed on orally via poets such as Homer. The volcanic eruption of Thera may have been the cause of the downfall of the Minoan civilization.

In 1420 BC, the Minoan civilization was overrun by the Mycenaean civilization from mainland Greece. The oldest samples of writing in the Greek language, as identified by Michael Ventris, is the Linear B archive from Knossos, dated approximately to 1425–1375 BC.

After the Bronze Age collapse, Crete was settled by new waves of Greeks from the mainland. A number of city states developed in the Archaic period. There was very limited contact with mainland Greece, and Greek historiography shows little interest in Crete, and as a result, there are very few literary sources.

During the 6th to 4th centuries BC, Crete was comparatively free from warfare. The Gortyn code (5th century BC) is evidence for how codified civil law established a balance between aristocratic power and civil rights.

In the late 4th century BC, the aristocratic order began to collapse due to endemic infighting among the elite, and Crete's economy was weakened by prolonged wars between city states. During the 3rd century BC, Gortyn, Kydonia (Chania), Lyttos and Polyrrhenia challenged the primacy of ancient Knossos.

While the cities continued to prey upon one another, they invited into their feuds mainland powers like Macedon and its rivals Rhodes and Ptolemaic Egypt. In 220 BC the island was tormented by a war between two opposing coalitions of cities. As a result, the Macedonian king Philip V gained hegemony over Crete which lasted to the end of the Cretan War (205–200 BC), when the Rhodians opposed the rise of Macedon and the Romans started to interfere in Cretan affairs.

In the 2nd century BC Ierapytna (Ierapetra) gained supremacy on eastern Crete.

Crete was involved in the Mithridatic Wars, initially repelling an attack by Roman general Marcus Antonius Creticus in 71 BC. Nevertheless, a ferocious three-year campaign soon followed under Quintus Caecilius Metellus, equipped with three legions and Crete was finally conquered by Rome in 69 BC, earning for Metellus the title ""Creticus"". Gortyn was made capital of the island, and Crete became a Roman province, along with Cyrenaica that was called Creta et Cyrenaica. Archaeological remains suggest that Crete under Roman rule witnessed prosperity and increased connectivity with other parts of the Empire. In the 2nd century AD, at least three cities in Crete (Lyttos, Gortyn, Hierapytna) joined the Panhellenion, a league of Greek cities founded by the emperor Hadrian. When Diocletian redivided the Empire, Crete was placed, along with Cyrene, under the diocese of Moesia, and later by Constantine I to the diocese of Macedonia.

Crete was separated from Cyrenaica . It remained a province within the eastern half of the Roman Empire, usually referred to as the Eastern Roman (Byzantine) Empire after the establishment of a second capital in Constantinople by Constantine in 330. Crete was subjected to an attack by Vandals in 467, the great earthquakes of 365 and 415, a raid by Slavs in 623, Arab raids in 654 and the 670s, and again in the 8th century. In , the Emperor Leo III the Isaurian transferred the island from the jurisdiction of the Pope to that of the Patriarchate of Constantinople.

In the 820s, after 900 years as a Roman, and then Eastern Roman (Byzantine) island, Crete was captured by Andalusian Muladis led by Abu Hafs, who established the Emirate of Crete. The Byzantines launched a campaign that took most of the island back in 842 and 843 under Theoktistos. Further Byzantine campaigns in 911 and 949 failed. In 960/1, Nikephoros Phokas' campaign completely restored Crete to the Byzantine Empire, after a century and a half of Arab control.

In 961, Nikephoros Phokas returned the island to Byzantine rule after expelling the Arabs. Extensive efforts at conversion of the populace were undertaken, led by John Xenos and Nikon "the Metanoeite". The reconquest of Crete was a major achievement for the Byzantines, as it restored Byzantine control over the Aegean littoral and diminished the threat of Saracen pirates, for which Crete had provided a base of operations.

In 1204, the Fourth Crusade seized and sacked the imperial capital of Constantinople. Crete was initially granted to leading Crusader Boniface of Montferrat in the partition of spoils that followed. However, Boniface sold his claim to the Republic of Venice, whose forces made up the majority of the Crusade. Venice's rival the Republic of Genoa immediately seized the island and it was not until 1212 that Venice secured Crete as a colony.

From 1212, during Venice's rule, which lasted more than four centuries, a Renaissance swept through the island as is evident from the plethora of artistic works dating to that period. Known as The Cretan School or Post-Byzantine Art, it is among the last flowerings of the artistic traditions of the fallen empire. The most notable representatives of this Cretan renaissance were the painter El Greco and the writers Nicholas Kalliakis (1645–1707), Georgios Kalafatis (professor) (–1720), Andreas Musalus (–1721) and Vitsentzos Kornaros.

Under the rule of the Catholic Venetians, the city of Candia was reputed to be the best fortified city of the Eastern Mediterranean. The three main forts were located at Gramvousa, Spinalonga, and Fortezza at Rethymnon. Other fortifications include the Kazarma fortress at Sitia. In 1492, Jews expelled from Spain settled on the island. In 1574–77, Crete was under the rule of Giacomo Foscarini as Proveditor General, Sindace and Inquistor. According to Starr's 1942 article, the rule of Giacomo Foscarini was a dark age for Jews and Greeks. Under his rule, non-Catholics had to pay high taxes with no allowances. In 1627, there were 800 Jews in the city of Candia, about seven percent of the city's population. Marco Foscarini was the Doge of Venice during this time period.

The Ottomans conquered Crete in 1669, after the siege of Candia. Many Greek Cretans fled to other regions of the Republic of Venice after the Ottoman–Venetian Wars, some even prospering such as the family of Simone Stratigo (c. 1733 – c. 1824) who migrated to Dalmatia from Crete in 1669. Islamic presence on the island, aside from the interlude of the Arab occupation, was cemented by the Ottoman conquest. Most Cretan Muslims were local Greek converts who spoke Cretan Greek, but in the island's 19th-century political context they came to be viewed by the Christian population as Turks. Contemporary estimates vary, but on the eve of the Greek War of Independence (1830), as much as 45% of the population of the island may have been Muslim. A number of Sufi orders were widespread throughout the island, the Bektashi order being the most prevalent, possessing at least five tekkes. Many among them were crypto-Christians who converted back to Christianity in subsequent years, while many Cretan Turks fled Crete because of the unrest, settling in Turkey, Rhodes, Syria, Libya and elsewhere. By 1900, 11% of the population was Muslim. Those remaining were relocated in the 1924 Population exchange between Greece and Turkey.

During Easter of 1770, a notable revolt against Ottoman rule, in Crete, was started by Daskalogiannis, a shipowner from Sfakia who was promised support by Orlov's fleet which never arrived. Daskalogiannis eventually surrendered to the Ottoman authorities. Today, the airport at Chania is named after him.

Crete was left out of the modern Greek state by the London Protocol of 1830, and soon it was yielded to Egypt by the Ottoman sultan. Egyptian rule was short-lived and sovereignty was returned to the Ottoman Empire by the Convention of London on 3 July 1840.

Heraklion was surrounded by high walls and bastions and extended westward and southward by the 17th century. The most opulent area of the city was the northeastern quadrant where all the elite were gathered together. The city had received another name under the rule of the Ottomans, "the deserted city". The urban policy that the Ottoman applied to Candia was a two-pronged approach. The first was the religious endowments. It made the Ottoman elite contribute to building and rehabilitating the ruined city. The other method was to boost the population and the urban revenue by selling off urban properties. According to Molly Greene (2001) there were numerous records of real-estate transactions during the Ottoman rule. In the deserted city, minorities received equal rights in purchasing property. Christians and Jews were also able to buy and sell in the real-estate market.

The Cretan Revolt of 1866–1869 or Great Cretan Revolution () was a three-year uprising against Ottoman rule, the third and largest in a series of revolts between the end of the Greek War of Independence in 1830 and the establishment of the independent Cretan State in 1898. A particular event which caused strong reactions among the liberal circles of western Europe was the "Holocaust of Arkadi". The event occurred in November 1866, as a large Ottoman force besieged the Arkadi Monastery, which served as the headquarters of the rebellion. In addition to its 259 defenders, over 700 women and children had taken refuge in the monastery. After a few days of hard fighting, the Ottomans broke into the monastery. At that point, the abbot of the monastery set fire to the gunpowder stored in the monastery's vaults, causing the death of most of the rebels and the women and children sheltered there.

Following the repeated uprisings in 1841, 1858, 1889, 1895 and 1897 by the Cretan people, who wanted to join Greece, the Great Powers decided to restore order and in February 1897 sent in troops. The island was subsequently garrisoned by troops from Great Britain, France, Italy and Russia; Germany and Austro-Hungary withdrawing from the occupation in early 1898. During this period Crete was governed through a committee of admirals from the remaining four Powers. In March 1898 the Powers decreed, with the very reluctant consent of the Sultan, that the island would be granted autonomy under Ottoman suzerainty in the near future.

In September 1898 an outbreak of rioting in Candia, modern Heraklion, left over 500 Cretan Christians, and 14 British servicemen, dead. As a result, the Admirals ordered the expulsion of all Ottoman troops and administrators from the island, a move that was ultimately completed by early November. The decision to grant autonomy to the island was enforced and a High Commissioner, Prince George of Greece, appointed, arriving to take up his post in December 1898. The flag of the Cretan State was chosen by the Powers, with the white star representing the Ottoman suzenraity over the island.

In 1905, disagreements between Prince George and minister Eleftherios Venizelos 
over the question of the "enosis" (union with Greece), such as the Prince's autocratic style of government, resulted in the Theriso revolt, one of leaders of which being Eleftherios Venizelos. 

Prince George resigned as High Commissioner and was replaced by Alexandros Zaimis, a former Greek prime minister, in 1906. In 1908, taking advantage of domestic turmoil in Turkey as well as the timing of Zaimis's vacation away from the island, the Cretan deputies unilaterally declared union with Greece.

With the break out of the First Balkan War, the Greek government declared that Crete was since then part of the Greek territory. This was not recognised internationally until 1 December 1913.

During World War II, the island was the scene of the famous Battle of Crete in May 1941. The initial 11-day battle was bloody and left more than 11,000 soldiers and civilians killed or wounded. As a result of the fierce resistance from both Allied forces and civilian Cretan locals, the invasion force suffered heavy casualties, and Adolf Hitler forbade further large-scale paratroop operations for the rest of the war. During the initial and subsequent occupation, German firing squads routinely executed male civilians in reprisal for the death of German soldiers; civilians were rounded up randomly in local villages for the mass killings, such as at the Massacre of Kondomari and the Viannos massacres. Two German generals were later tried and executed for their roles in the killing of 3,000 of the island's inhabitants.

There is also a video documentary of Crete in World War II titled 

Crete was one of the most popular holiday destinations in Greece. 15% of all arrivals in Greece come through the city of Heraklion (port and airport), while charter journeys to Heraklion seven years ago made up 20% of all charter flights in Greece. Overall, more than two million tourists visited Crete some years back, when the increase in tourism was reflected in the number of hotel beds, rising by 53% in the period between 1986 and 1991.

Today, the island's tourism infrastructure caters to all tastes, including a very wide range of accommodation; the island's facilities take in large luxury hotels with their complete facilities, swimming pools, sports and recreation, smaller family-owned apartments, camping facilities and others. Visitors reach the island via two international airports in Heraklion and Chania and a smaller airport in Sitia (international charter and domestic flights starting May 2012) or by boat to the main ports of Heraklion, Chania, Rethimno, Agios Nikolaos and Sitia.

Popular tourist attractions include the archaeological sites of the Minoan civilisation, the Venetian old city and port of Chania, the Venetian castle at Rethymno, the gorge of Samaria, the islands of Chrysi, Elafonisi, Gramvousa, Spinalonga and the Palm Beach of Vai, which is the largest natural palm forest in Europe.

Crete has an extensive bus system with regular services across the north of the island and from north to south. There are two regional bus stations in Heraklion. Bus routes and timetables can be found on KTEL website.

Crete's mild climate attracts interest from northern Europeans who want a holiday home or residence on the island. EU citizens have the right to freely buy property and reside with little formality. A growing number of real estate companies cater to mainly British immigrants, followed by German, Dutch, Scandinavian and other European nationalities wishing to own a home in Crete. The British immigrants are concentrated in the western regional units of Chania and Rethymno and to a lesser extent in Heraklion and Lasithi.

There is a large number of archaeological sites which include the Minoan sites of Knossos, Malia (not to be confused with the town of the same name), Petras, and Phaistos, the classical site of Gortys, and the diverse archaeology of the island of Koufonisi which includes Minoan, Roman, and World War II ruins. The latter, however, has restricted access for the last few years due to conservation concerns so it is best to check before heading to a port.

There are a number of museums throughout Crete. The Heraklion Archaeological Museum displays most of the archaeological finds of the Minoan era and was reopened in 2014.

Crete is isolated from mainland Europe, Asia, and Africa, and this is reflected in the diversity of the fauna and flora. As a result, the fauna and flora of Crete have many clues to the evolution of species. There are no animals that are dangerous to humans on the island of Crete in contrast to other parts of Greece. Indeed, the ancient Greeks attributed the lack of large mammals such as bears, wolves, jackals, and poisonous snakes, to the labour of Hercules (who took a live Cretan bull to the Peloponnese). Hercules wanted to honor the birthplace of Zeus by removing all "harmful" and "poisonous" animals from Crete. Later, Cretans believed that the island was cleared of dangerous creatures by the Apostle Paul, who lived on the island of Crete for two years, with his exorcisms and blessings. There is a natural history museum, the Natural History Museum of Crete, operating under the direction of the University of Crete and two aquariums – Aquaworld in Hersonissos and Cretaquarium in Gournes, displaying sea creatures common in Cretan waters.

Dwarf elephants, dwarf hippopotamus, dwarf mammoths, dwarf deer, and giant flightless owls were native to Pleistocene Crete.

Mammals of Crete include the vulnerable kri-kri, "Capra aegagrus cretica" that can be seen in the national park of the Samaria Gorge and on Thodorou, Dia and Agioi Pantes (islets off the north coast), the Cretan wildcat and the Cretan spiny mouse. Other terrestrial mammals include subspecies of the Cretan marten, the Cretan weasel, the Cretan badger, the long-eared hedgehog, and the edible dormouse.

The Cretan shrew, a type of white-toothed shrew is considered endemic to the island of Crete because this species of shrew is unknown elsewhere. It is a relic species of the "crocidura" shrews of which fossils have been found that can be dated to the Pleistocene era. In the present day it can only be found in the highlands of Crete. It is considered to be the only surviving remnant of the endemic species of the Pleistocene Mediterranean islands.

Bat species include: Blasius's horseshoe bat, the lesser horseshoe bat, the greater horseshoe bat, the lesser mouse-eared bat, Geoffroy's bat, the whiskered bat, Kuhl's pipistrelle, the common pipistrelle, Savi's pipistrelle, the serotine bat, the long-eared bat, Schreibers' bat and the European free-tailed bat.

A large variety of birds includes eagles (can be seen in Lasithi), swallows (throughout Crete in the summer and all the year in the south of the island), pelicans (along the coast), and cranes (including Gavdos and Gavdopoula). The Cretan mountains and gorges are refuges for the endangered lammergeier vulture. Bird species include: the golden eagle, Bonelli's eagle, the bearded vulture or lammergeier, the griffon vulture, Eleanora's falcon, peregrine falcon, lanner falcon, European kestrel, tawny owl, little owl, hooded crow, alpine chough, red-billed chough, and the hoopoe.

Tortoises can be seen throughout the island. Snakes can be found hiding under rocks. Toads and frogs reveal themselves when it rains.

Reptiles include the aegean wall lizard, balkan green lizard, "Chamaeleo chamaeleon", ocellated skink, snake-eyed skink, moorish gecko, turkish gecko, Kotschy's gecko, spur-thighed tortoise, and the stripe-necked terrapin.

There are four species of snake on the island and these are not dangerous to humans. The four species include the leopard snake (locally known as Ochendra), the Balkan whip snake (locally called Dendrogallia), the dice snake (called Nerofido in Greek), and the only venomous snake is the nocturnal cat snake which has evolved to deliver a weak venom at the back of its mouth to paralyse geckos and small lizards, and is not dangerous to humans.

Turtles include the green turtle and the loggerhead turtle which are both endangered species. The loggerhead turtle nests and hatches on north-coast beaches around Rethymno and Chania, and south-coast beaches along the gulf of Mesara.

Amphibians include the green toad, American toad, common tree frog, and the Cretan marsh frog.

Crete has an unusual variety of insects. Cicadas, known locally as "Tzitzikia", make a distinctive repetitive "tzi tzi" sound that becomes louder and more frequent on hot summer days. Butterfly species include the swallowtail butterfly. Moth species include the hummingbird moth. There are several species of scorpion such as Euscorpius carpathicus whose venom is generally no more potent than a mosquito bite.

River crabs include the semi-terrestrial "Potamon potamios" crab. Edible snails are widespread and can cluster in the hundreds waiting for rainfall to reinvigorate them.

Apart from terrestrial mammals, the seas around Crete are rich in large marine mammals, a fact unknown to most Greeks at present, although reported since ancient times. Indeed, the Minoan frescoes depicting dolphins in Queen's Megaron at Knossos indicate that Minoans were well aware of and celebrated these creatures. Apart from the famous endangered Mediterranean monk seal, which lives in almost all the coasts of the country, Greece hosts whales, sperm whales, dolphins and porpoises. These are either permanent residents of the Mediterranean or just occasional visitors. The area south of Crete, known as the Greek Abyss, hosts many of them. Squid and octopus can be found along the coast and sea turtles and hammerhead sharks swim in the sea around the coast. The Cretaquarium and the Aquaworld Aquarium, are two of only three aquariums in the whole of Greece. They are located in Gournes and Hersonissos respectively. Examples of the local sealife can be seen there.

Some of the fish that can be seen in the waters around Crete include: scorpion fish, dusky grouper, east Atlantic peacock wrasse, five-spotted wrasse, weever fish, common stingray, brown ray, mediterranean black goby, pearly razorfish, star-gazer, painted comber, damselfish, and the flying gurnard.

Common wildflowers include: camomile, daisy, gladiolus, hyacinth, iris, poppy, cyclamen and tulip, among others. There are more than 200 different species of wild orchid on the island and this includes 14 varieties of Ophrys Cretica. Crete has a rich variety of indigenous herbs including common sage, rosemary, thyme, and oregano. Rare herbs include the endemic Cretan dittany. and ironwort, "Sideritis syriaca", known as Malotira (Μαλοτήρα). Varieties of cactus include the edible prickly pear. Common trees on the island include the chestnut, cypress, oak, olive tree, pine, plane, and tamarisk. Trees tend to be taller to the west of the island where water is more abundant.

There are a number of environmentally protected areas. One such area is located at the island of Elafonisi on the coast of southwestern Crete. Also, the palm forest of Vai in eastern Crete and the Dionysades (both in the municipality of Sitia, Lasithi), have diverse animal and plant life. Vai has a palm beach and is the largest natural palm forest in Europe. The island of Chrysi, south of Ierapetra, has the largest naturally-grown "Juniperus macrocarpa" forest in Europe. Samaria Gorge is a World Biosphere Reserve and Richtis Gorge is protected for its landscape diversity.

Crete has a rich mythology mostly connected with the ancient Greek Gods but also connected with the Minoan civilisation.

According to Greek Mythology, The Diktaean Cave at Mount Dikti was the birthplace of the god Zeus. The Paximadia islands were the birthplace of the goddess Artemis and the god Apollo. Their mother, the goddess Leto, was worshipped at Phaistos. The goddess Athena bathed in Lake Voulismeni. The ancient Greek god Zeus launched a lightning bolt at a giant lizard that was threatening Crete. The lizard immediately turned to stone and became the island of Dia. The island can be seen from Knossos and it has the shape of a giant lizard. The islets of Lefkai were the result of a musical contest between the Sirens and the Muses. The Muses were so anguished to have lost that they plucked the feathers from the wings of their rivals; the Sirens turned white and fell into the sea at Aptera ("featherless") where they formed the islands in the bay that were called Lefkai (the islands of Souda and Leon). Hercules, in one of his labors, took the Cretan bull to the Peloponnese. Europa and Zeus made love at Gortys and conceived the kings of Crete, Rhadamanthys, Sarpedon, and Minos.

The labyrinth of the Palace of Knossos was the setting for the myth of Theseus and the Minotaur in which the Minotaur was slain by Theseus. Icarus and Daedalus were captives of King Minos and crafted wings to escape. After his death King Minos became a judge of the dead in Hades, while Rhadamanthys became the ruler of the Elysian fields.

Crete has its own distinctive Mantinades poetry. The island is known for its Mantinades-based music (typically performed with the Cretan lyra and the laouto) and has many indigenous dances, the most noted of which is the Pentozali.

Cretan authors have made important contributions to Greek Literature throughout the modern period; major names include Vikentios Kornaros, creator of the 17th-century epic romance "Erotokritos" (Greek Ερωτόκριτος), and, in the 20th century, Nikos Kazantzakis. In the Renaissance, Crete was the home of the Cretan School of icon painting, which influenced El Greco and through him subsequent European painting.
Crete is also famous for its traditional cuisine. The nutritional value of the Cretan cuisine was discovered by the American epidemiologist Ancel Keys in the 1960, being later often mentioned by epidemiologists as one of the best examples of the Mediterranean diet.

Cretans are fiercely proud of their island and customs, and men often don elements of traditional dress in everyday life: knee-high black riding boots ("stivania"), "vráka" breeches tucked into the boots at the knee, black shirt and black headdress consisting of a fishnet-weave kerchief worn wrapped around the head or draped on the shoulders ("sariki"). Men often grow large mustaches as a mark of masculinity.

Cretan society is well known for notorious family and clan vendettas which persist on the island to date. Cretans also have a tradition of keeping firearms at home, a tradition lasting from the era of resistance against the Ottoman Empire. Nearly every rural household on Crete has at least one unregistered gun. Guns are subject to strict regulation from the Greek government, and in recent years a great deal of effort to control firearms in Crete has been undertaken by the Greek police, but with limited success.

Crete has many football clubs playing in the local leagues. During the 2011–12 season, OFI Crete, which plays at Theodoros Vardinogiannis Stadium (Iraklion), and Ergotelis F.C., which plays at the Pankritio Stadium (Iraklion) were both members of the Greek Superleague. During the 2012–13 season, OFI Crete, which plays at Theodoros Vardinogiannis Stadium (Iraklion), and Platanias F.C., which plays at the Perivolia Municipal Stadium, near Chania, are both members of the Greek Superleague.

Notable people from Crete include:






</doc>
<doc id="6592" url="https://en.wikipedia.org/wiki?curid=6592" title="Cyclades">
Cyclades

The Cyclades (; ) are an island group in the Aegean Sea, southeast of mainland Greece and a former administrative prefecture of Greece. They are one of the island groups which constitute the Aegean archipelago. The name refers to the islands "around" (κυκλάς) the sacred island of Delos. The largest island of the Cyclades is Naxos.

The significant Late Neolithic and Early Bronze Age Cycladic culture is best known for its schematic, flat idols carved out of the islands' pure white marble centuries before the great Middle Bronze Age Minoan civilization arose in Crete to the south. (These figures have been looted from burials to satisfy a thriving Cycladic antiquities market since the early 20th century.)

A distinctive Neolithic culture amalgamating Anatolian and mainland Greek elements arose in the western Aegean before 4000 BCE, based on emmer and wild-type barley, sheep and goats, pigs, and tuna that were apparently speared from small boats (Rutter). Excavated sites include Saliagos and Kephala (on Kea) with signs of copperworking, Each of the small Cycladic islands could support no more than a few thousand people, though Late Cycladic boat models show that fifty oarsmen could be assembled from the scattered communities (Rutter), and when the highly organized palace-culture of Crete arose, the islands faded into insignificance, with the exception of Delos, which retained its archaic reputation as a sanctuary throughout antiquity and until the emergence of Christianity.

The first archaeological excavations of the 1880s were followed by systematic work by the British School at Athens and by Christos Tsountas, who investigated burial sites on several islands in 1898–1899 and coined the term "Cycladic civilization". Interest lagged, then picked up in the mid-20th century, as collectors competed for the modern-looking figures that seemed so similar to sculpture by Jean Arp or Constantin Brâncuși. Sites were looted and a brisk trade in forgeries arose. The context for many of these Cycladic figurines has been mostly destroyed and their meaning may never be completely understood. 

Another intriguing and mysterious object is that of the Cycladic frying pans. More accurate archaeology has revealed the broad outlines of a farming and seafaring culture that had immigrated from Anatolia c. 5000 BCE. Early Cycladic culture evolved in three phases, between c. 3300 – 2000 BCE, when it was increasingly swamped in the rising influence of Minoan Crete. The culture of mainland Greece contemporary with Cycladic culture is known as the Helladic period.

In recent decades the Cyclades have become popular with European and other tourists, and as a result there have been problems with erosion, pollution, and water shortages.

The Cyclades comprise about 220 islands, the major ones being Amorgos, Anafi, Andros, Antiparos, Delos, Ios, Kea, Kimolos, Kythnos, Milos, Mykonos, Naxos, Paros, Folegandros, Serifos, Sifnos, Sikinos, Syros, Tinos, and Thira or Santoríni. There are also many minor islands including Donousa, Eschati, Gyaros, Irakleia, Koufonisia, Makronisos, Rineia, and Schoinousa. The name "Cyclades" refers to the islands forming a circle ("circular islands") around the sacred island of Delos. Most of the smaller islands are uninhabited.

Ermoupoli on Syros is the chief town and administrative center of the former prefecture.

The islands are peaks of a submerged mountainous terrain, with the exception of two volcanic islands, Milos and Santorini. The climate is generally dry and mild, but with the exception of Naxos the soil is not very fertile; agricultural produce includes wine, fruit, wheat, olive oil, and tobacco. Lower temperatures are registered in higher elevations and these areas do not usually see wintry weather.

The Cyclades are bounded to the south by the Sea of Crete.

The Cyclades Prefecture () was one of the prefectures of Greece. As a part of the 2011 Kallikratis government reform, the prefecture was abolished, and its territory was divided into nine regional units of the South Aegean region:

The prefecture was subdivided into the following municipalities and communities. These have been reorganised at the 2011 Kallikratis reform as well. 


"Note:" Provinces no longer hold any legal status in Greece.

Local specialities of the Cyclades include:






</doc>
<doc id="6596" url="https://en.wikipedia.org/wiki?curid=6596" title="Computer vision">
Computer vision

Computer vision is an interdisciplinary scientific field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.

Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, "e.g.", in the forms of decisions. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.

As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.

Sub-domains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, and image restoration.

Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. "Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding." As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.

In the late 1960s, computer vision began at universities that were pioneering artificial intelligence. It was meant to mimic the human visual system, as a stepping stone to endowing robots with intelligent behavior. In 1966, it was believed that this could be achieved through a summer project, by attaching a camera to a computer and having it "describe what it saw".

What distinguished computer vision from the prevalent field of digital image processing at that time was a desire to extract three-dimensional structure from images with the goal of achieving full scene understanding. Studies in the 1970s formed the early foundations for many of the computer vision algorithms that exist today, including extraction of edges from images, labeling of lines, non-polyhedral and polyhedral modeling, representation of objects as interconnections of smaller structures, optical flow, and motion estimation.

The next decade saw studies based on more rigorous mathematical analysis and quantitative aspects of computer vision. These include the concept of scale-space, the inference of shape from various cues such as shading, texture and focus, and contour models known as snakes. Researchers also realized that many of these mathematical concepts could be treated within the same optimization framework as regularization and Markov random fields.
By the 1990s, some of the previous research topics became more active than the others. Research in projective 3-D reconstructions led to better understanding of camera calibration. With the advent of optimization methods for camera calibration, it was realized that a lot of the ideas were already explored in bundle adjustment theory from the field of photogrammetry. This led to methods for sparse 3-D reconstructions of scenes from multiple images. Progress was made on the dense stereo correspondence problem and further multi-view stereo techniques. At the same time, variations of graph cut were used to solve image segmentation. This decade also marked the first time statistical learning techniques were used in practice to recognize faces in images (see Eigenface). Toward the end of the 1990s, a significant change came about with the increased interaction between the fields of computer graphics and computer vision. This included image-based rendering, image morphing, view interpolation, panoramic image stitching and early light-field rendering.

Recent work has seen the resurgence of feature-based methods, used in conjunction with machine learning techniques and complex optimization frameworks.

Areas of artificial intelligence deal with autonomous planning or deliberation for robotical systems to navigate through an environment. A detailed understanding of these environments is required to navigate through them. Information about the environment could be provided by a computer vision system, acting as a vision sensor and providing high-level information about the environment and the robot.

Artificial intelligence and computer vision share other topics such as pattern recognition and learning techniques. Consequently, computer vision is sometimes seen as a part of the artificial intelligence field or the computer science field in general.

Computer vision is often considered to be part of information engineering.

Solid-state physics is another field that is closely related to computer vision. Most computer vision systems rely on image sensors, which detect electromagnetic radiation, which is typically in the form of either visible or infra-red light. The sensors are designed using quantum physics. The process by which light interacts with surfaces is explained using physics. Physics explains the behavior of optics which are a core part of most imaging systems. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process. Also, various measurement problems in physics can be addressed using computer vision, for example motion in fluids.

A third field which plays an important role is neurobiology, specifically the study of the biological vision system. Over the last century, there has been an extensive study of eyes, neurons, and the brain structures devoted to processing of visual stimuli in both humans and various animals. This has led to a coarse, yet complicated, description of how "real" vision systems operate in order to solve certain vision-related tasks. These results have led to a subfield within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems, at different levels of complexity. Also, some of the learning-based methods developed within computer vision ("e.g." neural net and deep learning based image and feature analysis and classification) have their background in biology.

Some strands of computer vision research are closely related to the study of biological vision – indeed, just as many strands of AI research are closely tied with research into human consciousness, and the use of stored knowledge to interpret, integrate and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. Computer vision, on the other hand, studies and describes the processes implemented in software and hardware behind artificial vision systems. Interdisciplinary exchange between biological and computer vision has proven fruitful for both fields.

Yet another field related to computer vision is signal processing. Many methods for processing of one-variable signals, typically temporal signals, can be extended in a natural way to processing of two-variable signals or multi-variable signals in computer vision. However, because of the specific nature of images there are many methods developed within computer vision which have no counterpart in processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing as a part of computer vision.

Beside the above-mentioned views on computer vision, many of the related research topics can also be studied from a purely mathematical point of view. For example, many methods in computer vision are based on statistics, optimization or geometry. Finally, a significant part of the field is devoted to the implementation aspect of computer vision; how existing methods can be realized in various combinations of software and hardware, or how these methods can be modified in order to gain processing speed without losing too much performance. Computer vision is also used in fashion ecommerce, inventory management, patent search, furniture, and the beauty industry.

The fields most closely related to computer vision are image processing, image analysis and machine vision. There is a significant overlap in the range of techniques and applications that these cover. This implies that the basic techniques that are used and developed in these fields are similar, something which can be interpreted as there is only one field with different names. On the other hand, it appears to be necessary for research groups, scientific journals, conferences and companies to present or market themselves as belonging specifically to one of these fields and, hence, various characterizations which distinguish each of the fields from the others have been presented.

Computer graphics produces image data from 3D models, computer vision often produces 3D models from image data. There is also a trend towards a combination of the two disciplines, "e.g.", as explored in augmented reality.

The following characterizations appear relevant but should not be taken as universally accepted:


Photogrammetry also overlaps with computer vision, e.g., stereophotogrammetry vs. computer stereo vision.

Applications range from tasks such as industrial machine vision systems which, say, inspect bottles speeding by on a production line, to research into artificial intelligence and computers or robots that can comprehend the world around them. The computer vision and machine vision fields have significant overlap. Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining automated image analysis with other methods and technologies to provide automated inspection and robot guidance in industrial applications. In many computer-vision applications, the computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common. Examples of applications of computer vision include systems for:

One of the most prominent application fields is medical computer vision, or medical image processing, characterized by the extraction of information from image data to diagnose a patient. An example of this is detection of tumours, arteriosclerosis or other malign changes; measurements of organ dimensions, blood flow, etc. are another example. It also supports medical research by providing new information: "e.g.", about the structure of the brain, or about the quality of medical treatments. Applications of computer vision in the medical area also includes enhancement of images interpreted by humans—ultrasonic images or X-ray images for example—to reduce the influence of noise.

A second application area in computer vision is in industry, sometimes called machine vision, where information is extracted for the purpose of supporting a manufacturing process. One example is quality control where details or final products are being automatically inspected in order to find defects. Another example is measurement of position and orientation of details to be picked up by a robot arm. Machine vision is also heavily used in agricultural process to remove undesirable food stuff from bulk material, a process called optical sorting.

Military applications are probably one of the largest areas for computer vision. The obvious examples are detection of enemy soldiers or vehicles and missile guidance. More advanced systems for missile guidance send the missile to an area rather than a specific target, and target selection is made when the missile reaches the area based on locally acquired image data. Modern military concepts, such as "battlefield awareness", imply that various sensors, including image sensors, provide a rich set of information about a combat scene which can be used to support strategic decisions. In this case, automatic processing of the data is used to reduce complexity and to fuse information from multiple sensors to increase reliability.
One of the newer application areas is autonomous vehicles, which include submersibles, land-based vehicles (small robots with wheels, cars or trucks), aerial vehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully autonomous (unmanned) vehicles to vehicles where computer-vision-based systems support a driver or a pilot in various situations. Fully autonomous vehicles typically use computer vision for navigation, "e.g." for knowing where it is, or for producing a map of its environment (SLAM) and for detecting obstacles. It can also be used for detecting certain task specific events, "e.g.", a UAV looking for forest fires. Examples of supporting systems are obstacle warning systems in cars, and systems for autonomous landing of aircraft. Several car manufacturers have demonstrated systems for autonomous driving of cars, but this technology has still not reached a level where it can be put on the market. There are ample examples of military autonomous vehicles ranging from advanced missiles to UAVs for recon missions or missile guidance. Space exploration is already being made with autonomous vehicles using computer vision, "e.g.", NASA's Mars Exploration Rover and ESA's ExoMars Rover.

Other application areas include:


Each of the application areas described above employ a range of computer vision tasks; more or less well-defined measurement problems or processing problems, which can be solved using a variety of methods. Some examples of typical computer vision tasks are presented below.

Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, "e.g.", in the forms of decisions. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.

The classical problem in computer vision, image processing, and machine vision is that of determining whether or not the image data contains some specific object, feature, or activity. Different varieties of the recognition problem are described in the literature:


Currently, the best algorithms for such tasks are based on convolutional neural networks. An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and hundreds of object classes. Performance of convolutional neural networks, on the ImageNet tests, is now close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters (an increasingly common phenomenon with modern digital cameras). By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained classes, such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this with ease.

Several specialized tasks based on recognition exist, such as:



Several tasks relate to motion estimation where an image sequence is processed to produce an estimate of the velocity either at each points in the image or in the 3D scene, or even of the camera that produces the images . Examples of such tasks are:


Given one or (typically) more images of a scene, or a video, scene reconstruction aims at computing a 3D model of the scene. In the simplest case the model can be a set of 3D points. More sophisticated methods produce a complete 3D surface model. The advent of 3D imaging not requiring motion or scanning, and related processing algorithms is enabling rapid advances in this field. Grid-based 3D sensing can be used to acquire 3D images from multiple angles. Algorithms are now available to stitch multiple 3D images together into point clouds and 3D models.

The aim of image restoration is the removal of noise (sensor noise, motion blur, etc.) from images. The simplest possible approach for noise removal is various types of filters such as low-pass filters or median filters. More sophisticated methods assume a model of how the local image structures look, to distinguish them from noise. By first analysing the image data in terms of the local image structures, such as lines or edges, and then controlling the filtering based on local information from the analysis step, a better level of noise removal is usually obtained compared to the simpler approaches.

An example in this field is inpainting.

The organization of a computer vision system is highly application-dependent. Some systems are stand-alone applications that solve a specific measurement or detection problem, while others constitute a sub-system of a larger design which, for example, also contains sub-systems for control of mechanical actuators, planning, information databases, man-machine interfaces, etc. The specific implementation of a computer vision system also depends on whether its functionality is pre-specified or if some part of it can be learned or modified during operation. Many functions are unique to the application. There are, however, typical functions that are found in many computer vision systems.


Image-understanding systems (IUS) include three levels of abstraction as follows: low level includes image primitives such as edges, texture elements, or regions; intermediate level includes boundaries, surfaces and volumes; and high level includes objects, scenes, or events. Many of these requirements are really topics for further research.

The representational requirements in the designing of IUS for these levels are: representation of prototypical concepts, concept organization, spatial knowledge, temporal knowledge, scaling, and description by comparison and differentiation.

While inference refers to the process of deriving new, not explicitly represented facts from currently known facts, control refers to the process that selects which of the many inference, search, and matching techniques should be applied at a particular stage of processing. Inference and control requirements for IUS are: search and hypothesis activation, matching and hypothesis testing, generation and use of expectations, change and focus of attention, certainty and strength of belief, inference and goal satisfaction.

There are many kinds of computer vision systems; however, all of them contain these basic elements: a power source, at least one image acquisition device (camera, ccd, etc.), a processor, and control and communication cables or some kind of wireless interconnection mechanism. In addition, a practical vision system contains software, as well as a display in order to monitor the system. Vision systems for inner spaces, as most industrial ones, contain an illumination system and may be placed in a controlled environment. Furthermore, a completed system includes many accessories such as camera supports, cables and connectors.

Most computer vision systems use visible-light cameras passively viewing a scene at frame rates of at most 60 frames per second (usually far slower).

A few computer vision systems use image-acquisition hardware with active illumination or something other than visible light or both, such as structured-light 3D scanners, thermographic cameras, hyperspectral imagers, radar imaging, lidar scanners, magnetic resonance images, side-scan sonar, synthetic aperture sonar, etc. Such hardware captures "images" that are then processed often using the same computer vision algorithms used to process visible-light images.

While traditional broadcast and consumer video systems operate at a rate of 30 frames per second, advances in digital signal processing and consumer graphics hardware has made high-speed image acquisition, processing, and display possible for real-time systems on the order of hundreds to thousands of frames per second. For applications in robotics, fast, real-time video systems are critically important and often can simplify the processing needed for certain algorithms. When combined with a high-speed projector, fast image acquisition allows 3D measurement and feature tracking to be realised.

Egocentric vision systems are composed of a wearable camera that automatically take pictures from a first-person perspective.

As of 2016, vision processing units are emerging as a new class of processor, to complement CPUs and graphics processing units (GPUs) in this role.






</doc>
<doc id="6597" url="https://en.wikipedia.org/wiki?curid=6597" title="Curry">
Curry

Curry (plural curries) is a variety of dishes originating in the Indian subcontinent that use a complex combination of spices or herbs, usually including ground turmeric, cumin, coriander, ginger, and fresh or dried chilies. Curry is generally prepared in a sauce. Curry dishes prepared in the southern states of India, where the word also originated, may be spiced with leaves from the curry tree.

There are many varieties of dishes called 'curries'. For example, in original traditional cuisines, the precise selection of spices for each dish is a matter of national or regional cultural tradition, religious practice, and, to some extent, family preference. Such dishes are called by specific names that refer to their ingredients, spicing, and cooking methods. Spices are used both whole and ground, cooked or raw, and they may be added at different times during the cooking process to produce different results. The main spices found in most curry powders of the Indian subcontinent are coriander, cumin, and turmeric. A wide range of additional spices may be included depending on the geographic region and the foods being included (fish, lentils, red or white meat, rice, and vegetables). Curry powder, a commercially prepared mixture of spices, is largely a Western creation, dating to the 18th century. Such mixtures are commonly thought to have first been prepared by Indian merchants for sale to members of the British Colonial government and army returning to Britain.

Dishes called 'curry' may contain fish, meat, poultry, or shellfish, either alone or in combination with vegetables. Additionally, many instead are entirely vegetarian, eaten especially among those who hold ethical or religious proscriptions against eating meat or seafood.

Curries may be either 'dry' or 'wet'. Dry curries are cooked with very little liquid which is allowed to evaporate, leaving the other ingredients coated with the spice mixture. Wet curries contain significant amounts of sauce or gravy based on broth, coconut cream, coconut milk, dairy cream, legume purée, sautéed crushed onion, tomato purée or yogurt.

Curry was adopted and anglicized from the Tamil word "" meaning 'sauce' or 'relish for rice'. It is usually understood to mean vegetables or meat cooked with spices with or without a gravy, used first in English in 1747 when a curry recipe was published by Hannah Glasse.

"Cury" (from French cuire, meaning to cook) appeared in the 1390s in an English cookbook, "The Forme of Cury", and "kari" was first described in a mid-17th century Portuguese cookbook by members of the British East India Company trading with Tamil (Indian) merchants along the Coromandel Coast of southeast India, becoming known as a "spice blend used for making kari dishes ... called "kari podi" or curry powder".

Archaeological evidence dating to 2600 BCE from Mohenjo-daro suggests the use of mortar and pestle to pound spices including mustard, fennel, cumin, and tamarind pods with which they flavoured food. Black pepper is native to the Indian subcontinent and Southeast Asia and has been known to Indian cooking since at least 2000 BCE.

The establishment of the Mughal Empire, in the early 15th century, influenced some curries, especially in the north. Another influence was the establishment of the Portuguese trading centre in Goa in 1510, resulting in the introduction of chili pepper to India from the Americas, as a byproduct of the Columbian Exchange.

Curry was introduced to English cuisine starting with Anglo-Indian cooking in the 17th century as spicy sauces were added to plain boiled and cooked meats. The 1758 edition of Hannah Glasse's "The Art of Cookery" contains a recipe "To make a curry the Indian way". Curry was first served in coffee houses in Britain from 1809, and has been increasingly popular in Great Britain, with major jumps in the 1940s and the 1970s. During the 19th century, curry was also carried to the Caribbean by Indian indentured workers in the British sugar industry. Since the mid-20th century, curries of many national styles have become popular far from their origins, and increasingly become part of international fusion cuisine.

From the culinary point of view, it is useful to consider the Indian subcontinent to be the entire historical region encompassed prior to independence since August 1947; that is, the modern countries of India, Bangladesh, Pakistan and Sri Lanka. It is usual to distinguish broadly between northern and southern styles of Indian cuisine, recognising that within those categories are innumerable sub-styles and variations. The distinction is commonly made with reference to the staple starch: wheat in the form of unleavened breads in the north; rice in the east; rice and millet in the south.

Bengali cuisine, which refers to the cuisine of Bangladesh and the West Bengal state of India, includes curries, including seafood and fresh fish. Mustard seeds and mustard oil are added to many recipes, as are poppy seeds. Emigrants from the Sylhet district of Bangladesh founded the curry house industry in Britain and in Sylhet some restaurants run by expatriates specialise in British-style Indian food.

Curries are the most well-known part of Indian cuisine. Most Indian dishes are usually curry based, prepared by adding different types of vegetables, lentils or meats in the curry. The content of the curry and style of preparation varies per the region. Most curries are water based, with occasional use of dairy and coconut milk. Curry dishes are usually thick and spicy and are eaten along with steamed rice and variety of Indian breads.

Although wet curries play a smaller role in Gujarat than elsewhere, there are a number of vegetarian examples with gravies based on buttermilk or coconut milk. The main ingredient may variously be brinjal (eggplant/aubergine), potatoes, fresh corn kernels, okra, tomatoes, etc. In addition, there are several common kofta dishes which substitute vegetables for meat. Undhiyu, a Gujarati specialty, is a spicy 'wet' mixed-vegetable 'casserole' cooked in an earthenware pot, often eaten during the winter months.

The curries of Maharashtra vary from mildly spicy to very spicy and include vegetarian, mutton, chicken and fish. Coastal Maharashtrian – Konkani – curries use coconut extensively along with spices. In western Maharashtra, curries are very spicy, often with peanut powder. Vidharba's cuisine is usually spicier than that of the coastal and southern regions. The ingredients commonly used are besan (gram flour), or chickpea flour, and groundnut powder. As a result of the Mughal rule in the region, the cuisine of Aurangabad has been highly influenced by the North Indian method of cooking. Khandeshi food is very spicy and the most famous dish is shev bhaji. Others include Eggplant bharta (wangyache bhareet), (urid dal), stuffed eggplant (bharleli wangi), bhaakari with thecha etc. The majority of Maharashtrian people are farmers living in the rural areas and therefore their traditional food is very simple.

Most Punjabi dishes are prepared using "tadka", which is made with the frying of a "masala", which is a mix of ginger, garlic, onions and tomatoes with some dried spices. This is followed by the addition of other ingredients, water, and occasionally milk. Normally spicy, spice levels vary greatly depending on the household itself. Ghee and mustard oil are the most commonly used cooking fats. Many popular Punjabi dishes such as butter chicken and rajma are curry-based. These dishes are usually served with steamed rice and chapatis.

Rajasthani cuisine was influenced both by the war-like lifestyles of its inhabitants and the availability of ingredients in this arid region. Food that could last for several days and could be eaten without heating was preferred. Scarcity of water and fresh green vegetables have each had their effect on the cooking. Hence the curries in Rajasthan are usually made using dry spices and herbs and other dry items like gram flour. "Kadhi" is a popular gram flour curry, usually served with steamed rice and bread. To decrease the use of water in this desert state they use a lot of milk and milk-products to cook curries. Laal maans is a popular meat curry from Rajasthan.

The food in general from Andhra Pradesh and Telangana, both with Telugu-speaking natives, is considered the hottest in India. The state, being the leading producer of red chilli and green chilli, influences the liberal use of spices, making their curries, chutneys, savories and pickles the hottest and spiciest in taste.

Curries known as vindaloo have become well known in Great Britain, America, and elsewhere, where the name is usually used simply to indicate a fiery dish of lamb or chicken frequently including potatoes. Such dishes are far from the Goan originals.

The name "vindaloo" derives from the Portuguese "vinha d'alhos" or wine ("vinho") and garlic ("alho"), the two definitive flavour ingredients. The dish was originally made with pork, not taboo to the Christian Portuguese. The inclusion of potatoes was a later Indian addition, thought to be the result of confusion with the Hindi word for potato, "aloo". Throughout the years "vindaloo" has been altered to appeal to many people by adding spices and different wines.

The curries of Karnataka are typically vegetarian or with meat and fish around mostly coastal areas. They use a wide variety of vegetables, spices, coconut and jaggery. There are dry and sauce-based curries. Some typical sauce-based dishes include saaru, gojju, thovve, huli, majjige huli (which is similar to the "kadi" made in the north), sagu or kootu, which is eaten mixed with hot rice.

Malayali curries of Kerala typically contain shredded coconut paste or coconut milk, curry leaves, and various spices. Mustard seeds are used in almost every dish, along with onions, curry leaves, and sliced red chilies fried in hot oil. Most of the non-vegetarian dishes are heavily spiced. Kerala is known for its traditional sadya, a vegetarian meal served with boiled rice and a host of side dishes such as parippu (green gram), papadum, ghee, sambar, rasam, aviyal, kaalan, kichadi, pachadi, injipuli, Koottukari, pickles (mango, lime), thoran, one to four types of payasam, boli, olan, pulissery, moru (buttermilk), upperi, and banana chips. The sadya is customarily served on a banana leaf.

Tamil cuisine's distinctive flavour and aroma is achieved by a blend and combination of spices including curry leaves, tamarind, coriander, ginger, garlic, chili, pepper, poppy seeds, mustard seeds, cinnamon, cloves, cardamom, cumin, fennel or anise seeds, fenugreek seeds, nutmeg, coconut, turmeric root or powder, and rosewater. Lentils, vegetables and dairy products are essential accompaniments and are often served with rice. Traditionally vegetarian foods dominate the menu with a range of non-vegetarian dishes including freshwater fish and seafood cooked with spices and seasoning.

In the West, the best-known Kashmiri curry is "rogan josh", a wet curry of lamb with a brilliant red gravy whose colour is derived from a combination of Kashmiri chillies and an extract derived from the red flowers of the cockscomb plant ("mawal"). "Goshtaba" (large lamb meatballs cooked in yoghurt gravy) is another curry dish from the Wazwan tradition occasionally found in Western restaurants.
The most important curry in the cuisine of the Maldives is cooked with diced fresh tuna and is known as "mas riha". "Kukulhu riha", chicken curry, is cooked with a different mixture of spices.

Traditional vegetable curries in the Maldives include those that use "bashi" (eggplant/aubergine), "tora" ("Luffa aegyptiaca"), "barabō" (pumpkin), "chichanda" ("Trichosanthes cucumerina") and "muranga" ("Moringa oleifera"), as well as green unripe bananas and certain leaves as their main ingredients. Pieces of Maldive fish are normally added to give the vegetable curry a certain flavour.

The curries of Nepalese cuisine have been influenced by its neighbours, mainly India and Tibet. Well known Indian spices are used less. Goat is a popular meat in the Himalayan region of Nepal.

Daal bhaat (rice and lentil soup) is a staple dish of Nepal. Newa cuisine is a type of cuisine developed over centuries by the Newars of Nepal.

Pakistani curries, especially in the provinces of Punjab and Sindh are basically similar to their counterparts in northern India. Mutton and beef are common ingredients. A typical Pakistani lunch or dinner often consists of some form of bread (such as naan or roti) or rice with a meat or vegetable-based curry. Barbecue style or roasted meats are also very popular in the form of kebabs.

It is worth noting that the term "curry" is virtually never used inside the country; instead, regional words such as "salan" or "shorba" are used to denote what is known outside the country as a "curry".

Several different types of curries exist, depending on the cooking style, such as bhuna, bharta, roghan josh, qorma, qeema, and shorba. A favourite Pakistani curry is karahi, which is either mutton or chicken cooked in a cooking utensil called karahi, which is similar in shape to a wok. Lahori karahi incorporates garlic, ginger, fresh chillies, tomatoes and select spices. Peshawari karahi is another very popular version made with just meat, salt, tomatoes, and coriander.

The cuisine from the Khyber Pakhtunkhwa province of Pakistan is somewhat similar to the cuisine of neighbouring Afghanistan. Extreme winters in some areas made the supply of fresh vegetables impossible, so a lot of dried fruits and vegetables are incorporated in the cuisine. The province still produces a large amount of nuts which are used abundantly in traditional cooking, along with cereals like wheat, maize, barley, and rice. Accompanying these staples are dairy products (yoghurt, whey), various nuts, native vegetables, and fresh and dried fruits. Peshawari karahi from the provincial capital of Peshawar is a popular curry all over the country.

Cuisine in Pakistani Punjab differs from Indian Punjab on account of contents and religious diet rules. A typical Punjabi meal consists of some form of bread or rice with a "salan" (curry). Most preparations start with the frying of a masala which is a concoction of ginger, garlic, onions, tomatoes, and dried spices. Various other ingredients are then added. Spice level varies greatly depending on the sub-region as well as the household itself. A popular cooking fat is desi ghee with some dishes enriched with liberal amounts of butter and cream. There are certain dishes that are exclusive to Punjab, such as maash di dal and saron da saag (sarson ka saag). In Punjab and Kashmir, the only dish known as kardhi (curry) is a dish made of dahi (yogurt) and flour dumplings.

In Pakistan, the provinces of Sindh and Balochistan border the Arabian Sea. Due to this, the Sindhi cuisine often has abundant use of fish in curries. Among Pakistani food, the Sindhi curries generally tend to be the hottest. The daily food in most Sindhi households consists of wheat-based flatbread (phulka) and rice accompanied by two dishes, one gravy and one dry.

In Sri Lankan cuisine, rice, which is usually consumed daily, can be found at any special occasion, while spicy curries are favourite dishes for lunch and dinner. "Rice and curry" refers to a range of Sri Lankan dishes.

Burmese cuisine is based on a very different understanding of curries. The principal ingredients of almost all Burmese curries are fresh onion (which provides the gravy and main body of the curry), Indian spices and red chilies. Usually, meat and fish are the main ingredients for popular curries.

Burmese curries can be generalised into two types – the hot spicy dishes which exhibit north Indian or Pakistani influence, and the milder "sweet" curries. Burmese curries almost overwhelmingly lack coconut milk, setting them apart from most southeast Asian curries.

Regular ingredients include fresh onion, garlic and chili paste. Common spices include garam masala, dried chili powder, cumin powder, turmeric and ngapi, a fermented paste made from either fish or prawns. Burmese curries are quite oily, as the extra oil helps the food to last longer. A spaghetti equivalent called Nan gyi thohk exists, in which wheat or rice noodles are eaten with thick chicken curry.

In Indonesia curry is called "kari" or "kare". The most common type of "kari" consumed in Indonesia is "kari ayam" (chicken curry) and "kari kambing" (goat meat curry). In Aceh and North Sumatra roti cane is often eaten with "kari kambing". Other dishes such as gulai and opor are dishes based on curry. They are often highly localised and reflect the meat and vegetables available. They can therefore employ a variety of meats (chicken, beef, water buffalo and goat as in the flavoursome "gulai kambing"), seafood (such as prawn, crab, mussel, clam, and squid), fish (tuna, mackerel, carp, pangasius, catfish), or vegetables (young jackfruit, common beans, cassava leaf) dishes in a spiced sauce. They use local ingredients such as chili peppers, kaffir lime leaves, lemongrass, galangal, Indonesian bay leaves (salam leaf), candlenuts, turmeric, turmeric leaves, asam gelugur and asam kandis (sour mangosteens similar to tamarind), shrimp paste (terasi), cumin, coriander seed and coconut milk. In Aceh, curries use "daun salam koja" or "daun kari" ("Murraya koenigii") translated as "curry leaves".

One popular dish, rendang from West Sumatran cuisine, is often described as caramelised beef dry curry. In Indonesia, rendang is usually not considered to be curry since it is richer and contains less liquid than is normal for Indonesian curries. Authentic rendang uses water buffalo meat slow-cooked in thick coconut milk for a number of hours to tenderise, caramelise, and flavour the meat. Opor Ayam is another variation of curry, which tastes very similar to gulai. Opor is usually whitish in colour and uses neither cinnamon nor turmeric, while gulai may contain either or both. Opor is also often part of a family meal around Lebaran, while gulai can be commonly found in Padang restaurants.

Being at the crossroads of ancient trade routes has left a mark on Malaysian cuisine. While curry may have initially found its way to Malaysian shores via the Indian population, it has since become a staple among the Malays and Chinese. Malaysian curries differ from state to state, even within similar ethnic groupings, as they are influenced by many factors, be they cultural, religious, agricultural or economical.

Malaysian curries typically use turmeric-rich curry powders, coconut milk, shallots, ginger, belacan (shrimp paste), chili peppers, and garlic. Tamarind is also often used. Rendang is another form of curry consumed in Malaysia, Singapore, Indonesia and the Philippines; it is drier and contains mostly meat and more coconut milk than a conventional Malaysian curry. Rendang was mentioned in Malay literature Hikayat Amir Hamzah (1550s) and is popular among Indonesians, Singaporeans and Malaysians. All sorts of things are curried in Malaysia, including mutton, chicken, tofu, shrimp, cuttlefish, fish, eggplants, eggs, and vegetables.

In the Philippines, two kinds of curry traditions are seen corresponding with the cultural divide between the Hispanicised north and Indianised/Islamised south. In the northern areas, a linear range of new curry recipes could be seen. The most common is a variant of the native "ginataang manok" (chicken is cooked in coconut milk) dish with the addition of curry powder, known as the "Filipino chicken curry". This is the usual curry dish that northern Filipinos are familiar with. Similarly, other northern Filipino dishes that can be considered "curries" are usually "ginataan" (cooked with coconut milk) variants of other native meat or seafood dishes such as "adobo", "kaldereta", and "mechado", that simply add curry powder or non-native Indian spices.

In southern areas of the Visayas, Mindanao, the Sulu Archipelago and southern Palawan, various older curry recipes are seen, and owe their origins to the limited influence of the Spanish in these regions that preserved older culinary traditions; as well as closer historical ties to Malay states like the Sultanate of Brunei. These Mindanaoan curries include "kulma", synonymous with the Indian "korma"; "tiyula itum" which is a beef curry blackened with burned coconut-meat powder; and "rendang", also eaten in Indonesia and Malaysia. Meats used in these curries include beef, goat, mutton, lamb, seafood and chicken. Pork is not used, in accordance with Islamic dietary laws.

In Thai cuisine, curries are called "kaeng", and usually consist of meat, fish and/or vegetables in a sauce based on a paste made from chilies, onions or shallots, garlic, and shrimp paste. Additional spices and herbs define the type of curry. Local ingredients, such as chili peppers, kaffir lime leaves, lemon grass, galangal are used and, in central and southern Thai cuisine, coconut milk. Northern and northeastern Thai curries generally do not contain coconut milk. Due to the use of sugar and coconut milk, Thai curries tend to be sweeter than Indian curries. In the West, some of the Thai curries are described by colour; red curries use red chilies while green curries use green chilies. Yellow curry—called "kaeng kari" (by various spellings) in Thai, of which a literal translation could be "curry soup"—is more similar to Indian curries, with the use of turmeric, cumin, and other dried spices. A few stir-fried Thai dishes also use an Indian style curry powder (Thai: "phong kari").

Thai curries:

In Vietnam where curry is called "cà ri", curry features include coconut milk, potato, sweet potato, taro roots, chicken garnished with coriander, and green onion. It is more soup-like than Indian curry. The curry is usually eaten with a baguette, rice vermicelli or steamed rice. Some dishes use a curry-based stew, such as snail dishes, phá lấu, stewed frogs or eels.

Although not an integral part of Chinese cuisine, curry powder is added to some dishes in southern part of China.The curry powder sold in Chinese grocery stores is similar to Madras curry powder but with addition of Star anise and Cinnamon.

Chinese curries (咖哩, gā lǐ) typically consist of chicken, beef, fish, lamb, or other meats, green peppers, onions, large chunks of potatoes, and a variety of other ingredients and spices in a mildly spicy yellow curry sauce, and topped over steamed rice. White pepper, soy sauce, hot sauce, and/or hot chili oil may be applied to the sauce to enhance the flavour of the curry.

The most common Chinese variety of curry sauce is usually sold in powder form. The ethnic Cantonese being dominant in Kuala Lumpur, this yellow Chinese-Malaysian variety was naturally introduced to China by the Cantonese. It features typically in Hong Kong cuisine, where curry is often cooked with brisket or fish balls. Malay satay seems to have been introduced to China with wider success by the ethnic Teochew, who make up the second largest group of Chinese of Singapore and are the dominant group in Thailand.

In Hong Kong, curry fish balls are a street snack, and curried brisket is a typical main course in cha chaan teng and fast food restaurants.

 is usually eaten as "karē raisu" — curry, rice, and often pickled vegetables, served on the same plate and eaten with a spoon, a common lunchtime canteen dish. It is less spicy and seasoned than Indian and Southeast Asian curries, being more of a thick stew than a curry.

British people brought curry from the Indian colony back to Britain and introduced it to Japan during the Meiji period (1868 to 1912), after Japan ended its policy of national self-isolation ("sakoku"), and curry in Japan was categorised as a Western dish. Its spread across the country is commonly attributed to its use in the Japanese Army and Navy which adopted it extensively as convenient field and naval canteen cooking, allowing even conscripts from the remotest countryside to experience the dish. The Japan Maritime Self-Defense Force traditionally have curry every Friday for lunch and many ships have their own unique recipes.

The standard Japanese curry contains onions, carrots, potatoes, and sometimes celery, and a meat that is cooked in a large pot. Sometimes grated apples or honey are added for additional sweetness and other vegetables are sometimes used instead. For the meat, pork, beef, and chicken are the most popular, in order of decreasing popularity. In northern and eastern Japan including Tokyo, pork is the most popular meat for curry. Beef is more common in western Japan, including Osaka, and in Okinawa, chicken is favoured. Curry seasoning is commonly sold in the form of a condensed brick, similar to a bouillon cube, which dissolves in the mixture of meat and vegetables.

Sometimes the curry-rice is topped with breaded pork cutlet (tonkatsu); this is called "katsukarē". Korokke (potato croquettes) are also a common topping.

Apart from with rice, curry is also served over noodles, possibly even on top of broth in addition, in dishes such as curry udon and curry ramen. It is also used as the filling in a fried curry bread pastry.

Though curry was introduced to Korea in the 1940s, the Indian dish was only popularized decades later, when Ottogi entered the Korean food industry by launching its powder-type curry product in 1969. Korean curry, usually served with rice, is characterized by the golden yellow colour from turmeric.

Curry tteokbokki, along with curry rice, is one of the most popular curry dishes in Korea. It is made of tteok (rice cakes), eomuk (fish cakes), eggs, vegetables, and curry. Curry can be added to various Korean dishes such as bokkeumbap (fried rice), sundubujjigae (silken tofu stew), fried chicken, vegetable stir-fries, and salads. Curry is also used in Korean-style western food such as pasta and steak, as well as Korean-style Japanese food such as cream udon.

Curry is very popular in the United Kingdom, with a curry house in nearly every town. Such is the popularity of curry in the United Kingdom, it has frequently been called its "adopted national dish". It was estimated that in 2016 there were 12,000 curry houses, employing 100,000 people and with annual combined sales of approximately £4.2 billion.

In general the food offered is Indian food cooked to British taste; however, there is increasing demand for authentic Indian food. As of 2015 curry houses accounted for a fifth of the restaurant business in the U.K. but, being historically a low wage sector, they were plagued by a shortage of labour. Established Indian immigrants from South Asia were moving on to other occupations; there were difficulties in training Europeans to cook curry; and immigration restrictions, which require payment of a substantial wage to skilled immigrants, had crimped the supply of new cooks.

Historically, the word "curry" was first used in British cuisine to denote dishes of meat (often leftover lamb) in a Western-style sauce flavoured with curry powder.

The first curry recipe in Britain appeared in "The Art of Cookery made Plain and Easy" by Hannah Glasse in 1747. The first edition of her book used only black pepper and coriander seeds for seasoning of "currey". By the fourth edition of the book, other ingredients such as turmeric and ginger were called for. The use of hot spices was not mentioned, which reflected the limited use of chili in India — chili plants had only been introduced into India around the late 16th century and at that time were only popular in southern India.

Many curry recipes are contained in 19th century cookbooks such as those of Charles Elmé Francatelli and Mrs Beeton. In "Mrs Beeton's Book of Household Management", a recipe for curry powder is given that contains coriander, turmeric, cinnamon, cayenne, mustard, ginger, allspice and fenugreek; although she notes that it is more economical to purchase the powder at "any respectable shop".
According to legend, one 19th century attempt at curry resulted in the invention of Worcestershire sauce.

Throughout the 19th and early 20th centuries, curry grew increasingly popular in Britain owing to the large number of British civil servants and military personnel associated with the British Raj. Following World War II, curry became even more popular in Britain owing to the large number of immigrants from South Asia.

Curry has become an integral part of British cuisine, so much so that, since the late 1990s, chicken tikka masala has been referred to as "a true British national dish".

Other British curry derivatives include "Coronation chicken", a cold dish, often used as a sandwich filling, invented to commemorate the coronation of Queen Elizabeth II in 1953 – and curry sauce (or curry gravy), usually served warm with traditional British fast food dishes such as chips. Curry sauce occasionally includes sultanas and/or other dried fruits.

In 1810, the entrepreneur Sake Dean Mahomed, from the Bengal Presidency, opened the first Indian curry house in England: the Hindoostanee Coffee House in London. (Curry was served prior to this in some London coffee houses.)

The first modern "upscale" Indian restaurant in Britain is thought to have been The Shafi in 1915, followed by Veeraswamy in London's Regent Street, founded in 1926; the latter is still standing and is the oldest surviving Indian restaurant in Britain.

Bengalis in the UK settled in big cities with industrial employment. In London, they settled in the East End, which for centuries has been the first port of call for many immigrants working in the docks and shipping from east Bengal. Their regular stopover paved the way for food and curry outlets to be opened up catering for an all-male workforce as family migration and settlement took place some decades later. Brick Lane in the East London Borough of Tower Hamlets is famous for its many curry houses.

Until the early 1970s, more than three-quarters of Indian restaurants in Britain were identified as being owned and run by people of Bengali origin. Most were run by migrants from East Pakistan, which became Bangladesh in 1971. Bangladeshi restaurateurs overwhelmingly come from the northeastern division of Sylhet. Until 1998, as many as 85% of curry restaurants in the UK were British Bangladeshi restaurants, but in 2003 this figure declined to just over 65%. The dominance of Bangladeshi restaurants is generally declining in some parts of London and the further north one travels. In Glasgow, there are more restaurants of Punjabi origin than any other.

In the early 2010s the popularity of the curry house saw a decline. This has been attributed to the sale of this style of food in generic restaurants, increased home cooking of this style of food with easy supermarket availability of ingredients, and immigration restrictions brought in from 2008 making the availability of low-wage chefs and other staff difficult.

Regardless of the ethnic origin of a restaurant's ownership, the menu will often be influenced by the wider South Asia (sometimes including Nepalese dishes), and sometimes cuisines from further afield (such as Persian dishes). Some British variations on Indian food are now being exported from the U.K. to India. Curry restaurants of more-or-less the British style are also popular in Canada, Australia and New Zealand.

This cuisine is characterised by the use of a common base for all the sauces to which spices are added when individual dishes are prepared. The standard "feedstock" is usually a sautéed mixture of onion, garlic and fresh ginger, to which various spices are added, depending on the recipe, but which may include: cloves, cinnamon, cardamom, chilies, peppercorns, cumin and mustard seeds. Ground coriander seed is widely used as a thickening agent, and turmeric is added for colour and its digestive qualities. Fresh or canned tomatoes and bell peppers are a common addition.

Better quality restaurants will normally make up new sauces on a daily basis, using fresh ingredients wherever possible and grinding their own spices. More modest establishments are more likely to resort to frozen or dried ingredients and pre-packaged spice mixtures.

Restaurants in Great Britain have adopted a number of Indian terms to identify popular dishes. Although the names may derive from traditional dishes, often the recipes do not. Representative names include:

The tandoor was introduced into Britain in the 1960s, and tandoori and tikka chicken became popular dishes.

Other dishes may feature with varying strengths, with those of north Indian origin, such as butter chicken, tending to be mild, and recipes from the south of India tending to be hotter.

Baltis are a style of curry thought to have been developed in Birmingham, England which have spread to other western countries and are traditionally cooked and served in the same pot, typically made of cast iron, called a "balty".

African curries, Cape Malay curries and Natal curries include the traditional Natal curry, the Durban curry, bunny chow, and roti rolls. South African curries appear to have been founded in two distinct regions – one in the east (KwaZulu-Natal) and the other in the west (Western Cape) – with a variety of other curries developing across the country over the late 20th century and early 21st century to include ekasi, coloured, and Afrikaner curries.

Durban has the largest single population of Indians outside of India, who have been developing traditional Natal curries since their arrival in the late 19th century. Natal curries are mostly based on South Indian dishes and mostly consist of simple spiced lamb and chicken dishes (with large amounts of ghee and oils), but also include very complex and elaborate seafood, chicken and lamb specialties (chicken and prawn curry is a Natal favourite). Continental and British recipes have also evolved alongside Indian South African curries. Continental and British versions use mainly traditional recipes with the addition of red wine, milk, cream, vanilla or butter instead of ghee.

Bunny chow or a "set", a South African standard, has spread in popularity throughout the country and into other southern African countries and countries with large South African immigrant populations. It consists of either lamb, chicken or bean curry poured into a tunnelled-out loaf of bread to be eaten with one's fingers. The roti roll is another classic takeaway curry that could either be a curry in a flat roti bread (similar to a kebab bread) or the classic "chip, cheese and curry" roll which basically consists of fried chips with melted cheese and curry gravy rolled into a roti roll.

In the West Indies, curry is a very popular dish. The Indian indentured servants that were brought over from India by different European powers brought this dish to the West Indies. In Jamaica and Trinidad, curried goat is prominently featured. Curry can be found at both inexpensive and upscale Caribbean restaurants, and ingredients can range from chicken or vegetables to shellfish such as shrimp and scallops. Examples of curries in the West Indies include:


In Fiji curries are made in most Indian homes and are eaten with rice or roti. Roti (circle or square) is mainly eaten for breakfast with vegetable curries. Lunch is often dal and rice with some side dishes. Most working people take roti and curry for their lunch. Dinner is usually curry, rice with some chutneys. Curries are normally cooked in vegetable oil. Ghee is mainly used to fry dal, to make puris or sweets. To make a curry, spices like cumin, fenugreek, mustard, and curry leaves are added to the hot oil. Onion is chopped or sliced and garlic crushed and added to the pot. Once the onion and garlic have turned slightly golden then turmeric and garam masala are added. For every 1 tsp turmeric normally 2 tsp masala is added. Salt and chillies are added according to taste. Curry is simmered on low heat until well cooked. Water is added so that it can be mixed with rice. If coriander leaves are available then they are added for extra flavour.

Sometimes potatoes or vegetables are also added to curries to increase volume and make them more nutritious. Often coconut cream is added to seafood curries, such as prawn, crab or fish curries. Dal is often cooked with only turmeric and then fried in cumin, onion, and garlic. Sometimes carrots and leafy vegetables like "chauraiya" or "saijan" are added for extra flavor and nutrients.


Curry powder is a spice mixture of widely varying composition developed by the British during the days of the Raj as a means of approximating the taste of Indian cuisine at home. Masala refers to spices, and this is the name given to the thick and pasty sauce based on a combination of spices with ghee (clarified butter), butter, palm oil or coconut milk. Most commercial curry powders available in Britain, the U.S. and Canada rely heavily on ground turmeric, in turn producing a very yellow sauce. Lesser ingredients in these Western yellow curry powders are often coriander, cumin, fenugreek, mustard, chili, black pepper and salt. By contrast, curry powders and curry pastes produced and consumed in India are extremely diverse; some red, some yellow, some brown; some with five spices and some with as many as 20 or more. Besides the previously mentioned spices, other commonly found spices in different curry powders in India are allspice, white pepper, ground mustard, ground ginger, cinnamon, roasted cumin, cloves, nutmeg, mace, green cardamom seeds or black cardamom pods, bay leaves and coriander seeds.

Curry powder is used as an incidental ingredient in other cuisines, including for example a "curry sauce" ("sauce au curry", sometimes even "au cari") variation of the classic French béchamel.



</doc>
<doc id="6598" url="https://en.wikipedia.org/wiki?curid=6598" title="Camel">
Camel

A camel is an even-toed ungulate in the genus "Camelus" that bears distinctive fatty deposits known as "humps" on its back. Camels have long been domesticated and, as livestock, they provide food (milk and meat) and textiles (fiber and felt from hair). As working animals, camels—which are uniquely suited to their desert habitats—are a vital means of transport for passengers and cargo. There are three surviving species of camel. The one-humped dromedary makes up 94% of the world's camel population, and the two-humped Bactrian camel makes up the remainder. The Wild Bactrian camel is a separate species and is now critically endangered.

The word "camel" is derived via and ("kamēlos") from Hebrew or Phoenician: "gāmāl". Used informally, "camel" (or, more correctly, "camelid") refers to any of the seven members of the family Camelidae: the dromedary, the Bactrian, and the wild Bactrian (the true camels), plus the llama, the alpaca, the guanaco, and the vicuña (the "New World" camelids).

The dromedary ("C. dromedarius"), also known as the "Arabian camel", inhabits the Middle East and the Horn of Africa, while the Bactrian ("C. bactrianus") inhabits Central Asia, including the historical region of Bactria. The critically endangered wild Bactrian ("C. ferus") is found only in remote areas of northwest China and Mongolia. An extinct species of camel
in the separate genus "Camelops", known as "C. hesternus", lived in western North America until humans entered the continent at the end of the Pleistocene.

The average life expectancy of a camel is 40 to 50 years. A full-grown adult camel stands at the shoulder and at the hump. Camels can run at up to in short bursts and sustain speeds of up to . Bactrian camels weigh and dromedaries . The widening toes on a camel's hoof provide supplemental grip for varying soil sediments.

The male dromedary camel has an organ called a dulla in its throat, a large, inflatable sac he extrudes from his mouth when in rut to assert dominance and attract females. It resembles a long, swollen, pink tongue hanging out of the side of its mouth. Camels mate by having both male and female sitting on the ground, with the male mounting from behind. The male usually ejaculates three or four times within a single mating session. Camelids are the only ungulates to mate in a sitting position.

Camels do not directly store water in their humps; they are reservoirs of fatty tissue. Concentrating body fat in their humps minimizes the insulating effect fat would have if distributed over the rest of their bodies, helping camels survive in hot climates. When this tissue is metabolized, it yields more than one gram of water for every gram of fat processed. This fat metabolization, while releasing energy, causes water to evaporate from the lungs during respiration (as oxygen is required for the metabolic process): overall, there is a net decrease in water.

Camels have a series of physiological adaptations that allow them to withstand long periods of time without any external source of water. The dromedary camel can drink as seldom as once every 10 days even under very hot conditions, and can lose up to 30% of its body mass due to dehydration. Unlike other mammals, camels' red blood cells are oval rather than circular in shape. This facilitates the flow of red blood cells during dehydration and makes them better at withstanding high osmotic variation without rupturing when drinking large amounts of water: a camel can drink of water in three minutes.

Camels are able to withstand changes in body temperature and water consumption that would kill most other animals. Their temperature ranges from at dawn and steadily increases to by sunset, before they cool off at night again. In general, to compare between camels and the other livestock, camels lose only 1.3 liters of fluid intake every day while the other livestock lose 20 to 40 liters per day (Breulmann, et al., 2007). Maintaining the brain temperature within certain limits is critical for animals; to assist this, camels have a rete mirabile, a complex of arteries and veins lying very close to each other which utilizes countercurrent blood flow to cool blood flowing to the brain. Camels rarely sweat, even when ambient temperatures reach . Any sweat that does occur evaporates at the skin level rather than at the surface of their coat; the heat of vaporization therefore comes from body heat rather than ambient heat. Camels can withstand losing 25% of their body weight to sweating, whereas most other mammals can withstand only about 12–14% dehydration before cardiac failure results from circulatory disturbance.

When the camel exhales, water vapor becomes trapped in their nostrils and is reabsorbed into the body as a means to conserve water. Camels eating green herbage can ingest sufficient moisture in milder conditions to maintain their bodies' hydrated state without the need for drinking.
The camels' thick coats insulate them from the intense heat radiated from desert sand; a shorn camel must sweat 50% more to avoid overheating. During the summer the coat becomes lighter in color, reflecting light as well as helping avoid sunburn. The camel's long legs help by keeping its body farther from the ground, which can heat up to . Dromedaries have a pad of thick tissue over the sternum called the "pedestal". When the animal lies down in a sternal recumbent position, the pedestal raises the body from the hot surface and allows cooling air to pass under the body.

Camels' mouths have a thick leathery lining, allowing them to chew thorny desert plants. Long eyelashes and ear hairs, together with nostrils that can close, form a barrier against sand. If sand gets lodged in their eyes, they can dislodge it using their transparent third eyelid. The camels' gait and widened feet help them move without sinking into the sand.

The kidneys and intestines of a camel are very efficient at reabsorbing water. Camels' kidneys have a 1:4 cortex to medulla ratio. Thus, the medullary part of a camel's kidney occupies twice as much area as a cow's kidney. Secondly, renal corpuscles have a smaller diameter, which reduces surface area for filtration. These two major anatomical characteristics enable camels to conserve water and limit the volume of urine in extreme desert conditions. Camel urine comes out as a thick syrup, and camel faeces are so dry that they do not require drying when the Bedouins use them to fuel fires. The camels are able to live in difficult conditions without drinking water due to their ability to produce small and dry droppings as well as they use the water to maintain their body's temperature to fit with the region surrounding them (Breulmann, et al., 2007).

The camel immune system differs from those of other mammals. Normally, the Y-shaped antibody molecules consist of two heavy (or long) chains along the length of the Y, and two light (or short) chains at each tip of the Y. Camels, in addition to these, also have antibodies made of only two heavy chains, a trait that makes them smaller and more durable. These "heavy-chain-only" antibodies, discovered in 1993, are thought to have developed 50 million years ago, after camelids split from ruminants and pigs.

The karyotypes of different camelid species have been studied earlier by many groups, but no agreement on chromosome nomenclature of camelids has been reached. A 2007 study flow sorted camel chromosomes, building on the fact that camels have 37 pairs of chromosomes (2n=74), and found that the karyotype consisted of one metacentric, three submetacentric, and 32 acrocentric autosomes. The Y is a small metacentric chromosome, while the X is a large metacentric chromosome.

The hybrid camel, a hybrid between Bactrian and dromedary camels, has one hump, though it has an indentation deep that divides the front from the back. The hybrid is at the shoulder and tall at the hump. It weighs an average of and can carry around , which is more than either the dromedary or Bactrian can.

According to molecular data, the New World and Old World camelids diverged about 11 million years ago. In spite of this, these species can hybridize and produce viable offspring. The cama is a camel-llama hybrid bred by scientists to see how closely related the parent species are. Scientists collected semen from a camel via an artificial vagina and inseminated a llama after stimulating ovulation with gonadotrophin injections. The cama is halfway in size between a camel and a llama and lacks a hump. It has ears intermediate between those of camels and llamas, longer legs than the llama, and partially cloven hooves. Like the mule, camas are sterile, despite both parents having the same number of chromosomes. The wild Bactrian camel ("C. ferus") separated from the domestic Bactrian camel ("C. bactrianus") about 1 million years ago.

The earliest known camel, called "Protylopus", lived in North America 40 to 50 million years ago (during the Eocene). It was about the size of a rabbit and lived in the open woodlands of what is now South Dakota. By 35 million years ago, the "Poebrotherium" was the size of a goat and had many more traits similar to camels and llamas. The hoofed "Stenomylus", which walked on the tips of its toes, also existed around this time, and the long-necked "Aepycamelus" evolved in the Miocene.

The direct ancestor of all modern camels, "Procamelus", existed in the upper Miocene and lower Pliocene. Around 3–5 million years ago, the North American Camelidae spread to South America as part of the Great American Interchange via the newly formed Isthmus of Panama, where they gave rise to guanacos and related animals, and to Asia via the Bering land bridge. Surprising finds of fossil "Paracamelus" on Ellesmere Island beginning in 2006 in the high Canadian Arctic indicate the dromedary is descended from a larger, boreal browser whose hump may have evolved as an adaptation in a cold climate. This creature is estimated to have stood around nine feet tall.

The last camel native to North America was "Camelops hesternus", which vanished along with horses, short-faced bears, mammoths and mastodons, ground sloths, sabertooth cats, and many other megafauna, coinciding with the migration of humans from Asia.

Like horses before their extinction in their continent of origin, camels spread across the Bering land bridge, moving in the opposite direction from the Asian immigration to America. They survived in the Old World, and eventually humans domesticated them and spread them globally. Along with many other megafauna in North America, the original wild camels were wiped out during the spread of Native Americans from Asia into North America, 12,000 to 10,000 years ago.
Most camels surviving today are domesticated. Although feral populations exist in Australia, India and Kazakhstan, wild camels survive only in the wild Bactrian camel population of the Gobi Desert.

Humans may have first domesticated dromedaries in Somalia and southern Arabia around 3,000 BC, and Bactrian camels in central Asia around 2,500 BC, as at Shahr-e Sukhteh (also known as the Burnt City), Iran.

Discussions concerning camel domestication in Mesopotamia often reference mentions of camels in the Hebrew Bible. The "International Standard Bible Encyclopedia: E-J", for instance, mentions: "In accord with patriarchal traditions, cylinder seals from Middle Bronze Age Mesopotamia showed riders seated upon camels."

Martin Heide's 2010 work on the domestication of the camel tentatively concludes that humans had domesticated the Bactrian camel by at least the middle of the third millennium somewhere east of the Zagros Mountains, with the practice then moving into Mesopotamia. Heide suggests that mentions of camels "in the patriarchal narratives may refer, at least in some places, to the Bactrian camel", while noting that the camel is not mentioned in relationship to Canaan.

Recent excavations in the Timna Valley by Lidar Sapir-Hen and Erez Ben-Yosef discovered what may be the earliest domestic camel bones yet found in Israel or even outside the Arabian Peninsula, dating to around 930 BC. This garnered considerable media coverage, as it was described as evidence that the stories of Abraham, Jacob, Esau, and Joseph were written after this time.

The existence of camels in Mesopotamia - but not in the eastern Mediterranean lands - is not a new idea. The historian Richard Bulliet did not think that the occasional mention of camels in the Bible meant that the domestic camels were common in the Holy Land at that time. The archaeologist William F. Albright, writing even earlier, saw camels in the Bible as an anachronism.

The official report by Sapir-Hen and Ben-Joseph notes: The introduction of the dromedary camel (Camelus dromedarius) as a pack animal to the southern Levant ... substantially facilitated trade across the vast deserts of Arabia, promoting both economic and social change (e.g., Kohler 1984; Borowski 1998: 112–116; Jasmin 2005). This ... has generated extensive discussion regarding the date of the earliest domestic camel in the southern Levant (and beyond) (e.g., Albright 1949: 207; Epstein 1971: 558–584; Bulliet 1975; Zarins 1989; Köhler-Rollefson 1993; Uerpmann and Uerpmann 2002; Jasmin 2005; 2006; Heide 2010; Rosen and Saidel 2010; Grigson 2012). Most scholars today agree that the dromedary was exploited as a pack animal sometime in the early Iron Age (not before the 12th century [BC]) and concludes: Current data from copper smelting sites of the Aravah Valley enable us to pinpoint the introduction of domestic camels to the southern Levant more precisely based on stratigraphic contexts associated with an extensive suite of radiocarbon dates. The data indicate that this event occurred not earlier than the last third of the 10th century [BC] and most probably during this time. The coincidence of this event with a major reorganization of the copper industry of the region—attributed to the results of the campaign of Pharaoh Shoshenq I—raises the possibility that the two were connected, and that camels were introduced as part of the efforts to improve efficiency by facilitating trade.

Desert tribes and Mongolian nomads use camel hair for tents, yurts, clothing, bedding and accessories. Camels have outer guard hairs and soft inner down, and the fibers are sorted by color and age of the animal. The guard hairs can be felted for use as waterproof coats for the herdsmen, while the softer hair is used for premium goods. The fiber can be spun for use in weaving or made into yarns for hand knitting or crochet. Pure camel hair is recorded as being used for western garments from the 17th century onwards, and from the 19th century a mixture of wool and camel hair was used.

By at least 1200 BC the first camel saddles had appeared, and Bactrian camels could be ridden. The first saddle was positioned to the back of the camel, and control of the Bactrian camel was exercised by means of a stick. However, between 500 and 100 BC, Bactrian camels came into military use. New saddles, which were inflexible and bent, were put over the humps and divided the rider's weight over the animal. In the seventh century BC the military Arabian saddle evolved, which again improved the saddle design slightly.

Military forces have used camel cavalries in wars throughout Africa, the Middle East, and into the modern-day Border Security Force (BSF) of India (though as of July 2012, the BSF planned the replacement of camels with ATVs). The first documented use of camel cavalries occurred in the Battle of Qarqar in 853 BC. Armies have also used camels as freight animals instead of horses and mules.

The East Roman Empire used auxiliary forces known as "dromedarii", whom the Romans recruited in desert provinces. The camels were used mostly in combat because of their ability to scare off horses at close range (horses are afraid of the camels' scent), a quality famously employed by the Achaemenid Persians when fighting Lydia in the Battle of Thymbra (547 BC).

The United States Army established the U.S. Camel Corps, stationed in California, in the late 19th century. One may still see stables at the Benicia Arsenal in Benicia, California, where they nowadays serve as the Benicia Historical Museum. Though the experimental use of camels was seen as a success (John B. Floyd, Secretary of War in 1858, recommended that funds be allocated towards obtaining a thousand more camels), the outbreak of the American Civil War in 1861 saw the end of the Camel Corps: Texas became part of the Confederacy, and most of the camels were left to wander away into the desert.

France created a "méhariste" camel corps in 1912 as part of the Armée d'Afrique in the Sahara in order to exercise greater control over the camel-riding Tuareg and Arab insurgents, as previous efforts to defeat them on foot had failed. The Free French Camel Corps fought during World War II, and camel-mounted units remained in service until the end of French rule over Algeria in 1962.

In 1916, the British created the Imperial Camel Corps. It was originally used to fight the Senussi, but was later used in the Sinai and Palestine Campaign in World War I. The Imperial Camel Corps comprised infantrymen mounted on camels for movement across desert, though they dismounted at battle sites and fought on foot. After July 1918, the Corps began to become run down, receiving no new reinforcements, and was formally disbanded in 1919.

In World War I, the British Army also created the Egyptian Camel Transport Corps, which consisted of a group of Egyptian camel drivers and their camels. The Corps supported British war operations in Sinai, Palestine, and Syria by transporting supplies to the troops.

The Somaliland Camel Corps was created by colonial authorities in British Somaliland in 1912; it was disbanded in 1944.

Bactrian camels were used by Romanian forces during World War II in the Caucasian region.

The Bikaner Camel Corps of British India fought alongside the British Indian Army in World Wars I and II.

The "Tropas Nómadas" (Nomad Troops) were an auxiliary regiment of Sahrawi tribesmen serving in the colonial army in Spanish Sahara (today Western Sahara). Operational from the 1930s until the end of the Spanish presence in the territory in 1975, the "Tropas Nómadas" were equipped with small arms and led by Spanish officers. The unit guarded outposts and sometimes conducted patrols on camelback.

Camel milk is a staple food of desert nomad tribes and is sometimes considered a meal itself; a nomad can live on only camel milk for almost a month. Camel milk is rich in vitamins, minerals, proteins, and immunoglobulins; compared to cow's milk, it is lower in fat and lactose, and higher in potassium, iron, and vitamin C. Bedouins believe the curative powers of camel milk are enhanced if the camel's diet consists of certain desert plants. Camel milk can readily be made into a drinkable yogurt, as well as butter or cheese, though the yields for cheese tend to be low. 

Camel milk cannot be made into butter by the traditional churning method. It can be made if it is soured first, churned, and a clarifying agent is then added. Until recently, camel milk could not be made into camel cheese because rennet was unable to coagulate the milk proteins to allow the collection of curds. Developing less wasteful uses of the milk, the FAO commissioned Professor J.P. Ramet of the École Nationale Supérieure d'Agronomie et des Industries Alimentaires, who was able to produce curdling by the addition of calcium phosphate and vegetable rennet. The cheese produced from this process has low levels of cholesterol and is easy to digest, even for the lactose intolerant. The sale of camel cheese is limited owing to the small output of the few dairies producing camel cheese and the absence of camel cheese in local (West African) markets. Cheese imports from countries that traditionally breed camels are difficult to obtain due to restrictions on dairy imports from these regions.

Additionally, camel milk can be made into ice cream.

They provide food in the form of meat and milk (Tariq "et al.",2010). A camel carcass can provide a substantial amount of meat. The male dromedary carcass can weigh , while the carcass of a male Bactrian can weigh up to . The carcass of a female dromedary weighs less than the male, ranging between . The brisket, ribs and loin are among the preferred parts, and the hump is considered a delicacy. The hump contains "white and sickly fat", which can be used to make the "khli" (preserved meat) of mutton, beef, or camel. On the other hand, camel milk and meat are rich in protein, vitamins, glycogen, and other nutrients making them essential in the diet of many people. From chemical composition to meat quality, the dromedary camel is the preferred breed for meat production. It does well even in arid areas due to its unusual physiological behaviors and characteristics, which include tolerance to extreme temperatures, radiation from the sun, water paucity, rugged landscape and low vegetation. Camel meat is reported to taste like coarse beef, but older camels can prove to be very tough, although camel meat becomes more tender the more it is cooked. The Abu Dhabi Officers' Club serves a camel burger mixed with beef or lamb fat in order to improve the texture and taste. In Karachi, Pakistan, some restaurants prepare nihari from camel meat. Specialist camel butchers provide expert cuts, with the hump considered the most popular.

Camel meat has been eaten for centuries. It has been recorded by ancient Greek writers as an available dish at banquets in ancient Persia, usually roasted whole. The ancient Roman emperor Heliogabalus enjoyed camel's heel. Camel meat is mainly eaten in certain regions, including Eritrea, Somalia, Djibouti, Saudi Arabia, Egypt, Syria, Libya, Sudan, Ethiopia, Kazakhstan, and other arid regions where alternative forms of protein may be limited or where camel meat has had a long cultural history. Camel blood is also consumable, as is the case among pastoralists in northern Kenya, where camel blood is drunk with milk and acts as a key source of iron, vitamin D, salts and minerals. Camel Meat is a sample food in Djiboutian cuisine. You can have Camel Steak, Skewers and Hamburgers also Zurbyaan rice with camel meat is served in local restaurants. Camel meat is also occasionally found in Australian cuisine: for example, a camel lasagna is available in Alice Springs.

A 2005 report issued jointly by the Saudi Ministry of Health and the United States Centers for Disease Control and Prevention details cases of human bubonic plague resulting from the ingestion of raw camel liver.

Camel meat is "halal" (, 'allowed') for Muslims. However, according to some Islamic schools of thought, a state of impurity is brought on by the consumption of it. Consequently, these schools hold that Muslims must perform "wudhu" (ablution) before the next time they pray after eating camel meat. Also, some Islamic schools of thought consider it "haram" (, 'forbidden') for a Muslim to perform "Salat" in places where camels lie, as it is said to be a dwelling place of the "Shaytan" (, 'Devil'). According to Abu Yusuf, the urine of camel may be used for medical treatment if necessary, but according to Abū Ḥanīfah, the drinking of camel urine is discouraged.

The Islamic texts contain several stories featuring camels. In the story of the people of Thamud, the Prophet Salih miraculously brings forth a "naqat" (, 'she-camel') out of a rock. After the Prophet Muhammad migrated from Mecca to Medina, he allowed his she-camel to roam there; the location where the camel stopped to rest determined the location where he would build his house in Medina.

According to Jewish tradition, camel meat and milk are not kosher. Camels possess only one of the two kosher criteria; although they chew their cud, they do not possess cloven hooves: "But these you shall not eat among those that bring up the cud and those that have a cloven hoof: the camel, because it brings up its cud, but does not have a [completely] cloven hoof; it is unclean for you."

There are around 14 million camels alive , with 90% being dromedaries. Dromedaries alive today are domesticated animals (mostly living in the Horn of Africa, the Sahel, Maghreb, Middle East and South Asia). The Horn region alone has the largest concentration of camels in the world, where the dromedaries constitute an important part of local nomadic life. They provide nomadic people in Somalia and Ethiopia with milk, food, and transportation.
Around 700,000 dromedary camels are now feral in Australia, descended from those introduced as a method of transport in the 19th and early 20th centuries. This population is growing about 8% per year. Representatives of the Australian government have culled more than 100,000 of the animals in part because the camels use too much of the limited resources needed by sheep farmers.

A small population of introduced camels, dromedaries and Bactrians, wandered through Southwestern United States after having been imported in the 19th century as part of the U.S. Camel Corps experiment. When the project ended, they were used as draft animals in mines and escaped or were released. Twenty-five U.S. camels were bought and imported to Canada during the Cariboo Gold Rush.

The Bactrian camel is, , reduced to an estimated 1.4 million animals, most of which are domesticated. The Wild Bactrian camel is a separate species and is the only truly wild (as opposed to feral) camel in the world. The wild camels are critically endangered and number approximately 1400, inhabiting the Gobi and Taklamakan Deserts in China and Mongolia.





</doc>
