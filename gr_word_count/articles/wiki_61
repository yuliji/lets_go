<doc id="7966" url="https://en.wikipedia.org/wiki?curid=7966" title="Disco">
Disco

Disco is a genre of dance music and a subculture that emerged in the 1970s from the United States' urban nightlife scene.

The disco sound is typified by "four-on-the-floor" beats, syncopated basslines, and string sections, horns, electric piano, synthesizers, and electric rhythm guitars. Lead guitar features less frequently in disco than in rock. Well-known disco artists include Donna Summer, Gloria Gaynor, the Bee Gees, Chic, KC and the Sunshine Band, Thelma Houston, Village People and Michael Jackson. While performers and singers garnered public attention, record producers working behind the scenes played an important role in developing the genre. Films such as "Saturday Night Fever" (1977) and "Thank God It's Friday" (1978) contributed to disco's mainstream popularity.

Disco started as a mixture of music from venues popular with African Americans, Hispanic and Latino Americans, Italian Americans, LGBT people (especially African-American and Latino American gay men), and psychedelic hippies in Philadelphia and New York City during the late 1960s and early 1970s. Disco can be seen as a reaction by the counterculture during this period to both the dominance of rock music and the stigmatization of dance music at the time. Several dance styles were developed during the period of disco's popularity in the United States, including the Bump and the Hustle.

By the late 1970s, most major U.S. cities had thriving disco club scenes, and DJs would mix dance records at clubs such as Studio 54 in New York City, a venue popular among celebrities. Discothèque-goers often wore expensive, extravagant and sexy fashions. There was also a thriving drug subculture in the disco scene, particularly for drugs that would enhance the experience of dancing to the loud music and the flashing lights, such as cocaine and Quaaludes, the latter being so common in disco subculture that they were nicknamed "disco biscuits". Disco clubs were also associated with promiscuity as a reflection of the sexual revolution of this era in popular history.

Disco was the last popular music movement driven by the baby boom generation. It began to decline in the United States during 1979-80, and by 1982 it had lost nearly all popularity there. Disco Demolition Night, an anti-disco protest held in Chicago on July 12, 1979, remains the most well-known of several "backlash" incidents across the country that symbolized disco's declining fortune.

Disco was a key influence in the development of electronic dance music and house music. It has had several revivals, such as Madonna's highly successful 2005 album "Confessions on a Dance Floor", and more recently in the 2010s, entering the pop charts in the US and the UK.

The term "disco" is shorthand for the word "discothèque", a French word for "library of phonograph records" derived from "bibliothèque". The word "discothèque" was current in the same meaning in English in the 1950s.

"Discothèque" became in use in French as a term for a type of nightclubs in Paris after these had resorted to playing records during the Nazi occupation in the early 1940s. Some clubs used it as their proper name. In 1960 it was also used to describe a Parisian nightclub in an English magazine.

In the summer of 1964 a short sleeveless dress called "discotheque dress" was very popular in the United States for a short time. The earliest known use for the abbreviated form "disco" described this dress and has been found in the Salt Lake Tribune of 12 July 1964, but "Playboy" magazine used it soon after to describe Los Angeles nightclubs in September of the same year.

Vince Aletti was one of the first to describe disco as a sound or a music genre. He wrote the feature article "Discoteque Rock Paaaaarty" that appeared in Rolling Stone magazine in September 1973.

The music typically layered soaring, often-reverberated vocals, often doubled by horns, over a background "pad" of electric pianos and "chicken-scratch" rhythm guitars played on an electric guitar. "The 'chicken scratch' sound is achieved by lightly pressing the strings against the fretboard and then quickly releasing them just enough to get a slightly muted scratching [sound] while constantly strumming very close to the bridge." Other backing keyboard instruments include the piano, electric organ (during early years), string synth, and electromechanical keyboards such as the Fender Rhodes electric piano, Wurlitzer electric piano, and Hohner Clavinet. Synthesizers are also fairly common in disco, especially in the late 1970s.

The rhythm is laid down by prominent, syncopated basslines (with heavy use of broken octaves, that is, octaves with the notes sounded one after the other) played on the bass guitar and by drummers using a drum kit, African/Latin percussion, and electronic drums such as Simmons and Roland drum modules. The sound was enriched with solo lines and harmony parts played by a variety of orchestral instruments, such as harp, violin, viola, cello, trumpet, saxophone, trombone, clarinet, flugelhorn, French horn, tuba, English horn, oboe, flute (sometimes especially the alto flute and occasionally bass flute), piccolo, timpani and synth strings, string section or a full string orchestra.

Most disco songs have a steady four-on-the-floor beat, a quaver or semi-quaver hi-hat pattern with an open hi-hat on the off-beat, and a heavy, syncopated bass line. Other Latin rhythms such as the rhumba, the samba and the cha-cha-cha are also found in disco recordings, and Latin polyrhythms, such as a rhumba beat layered over a merengue, are commonplace. The quaver pattern is often supported by other instruments such as the rhythm guitar and may be implied rather than explicitly present.

Songs often use syncopation, which is the accenting of unexpected beats. In general, the difference between a disco, or any dance song, and a rock or popular song is that in dance music the bass drum hits "four to the floor", at least once a beat (which in 4/4 time is 4 beats per measure), whereas in rock the bass hits on one and three and lets the snare take the lead on two and four (the "backbeat"). Disco is further characterized by a 16th note division of the quarter notes as shown in the second drum pattern below, after a typical rock drum pattern.

The orchestral sound usually known as "disco sound" relies heavily on string sections and horns playing linear phrases, in unison with the soaring, often reverberated vocals or playing instrumental fills, while electric pianos and chicken-scratch guitars create the background "pad" sound defining the harmony progression. Typically, all of the doubling of parts and use of additional instruments creates a rich "wall of sound". There are, however, more minimalist flavors of disco with reduced, transparent instrumentation, pioneered by Chic.

"The [disco] DJ was central to the ritual of 1970s dance culture, but the dancing crowd was no less important, and it was the combination of these two elements that created the conditions for the dance floor dynamic." In disco parties and clubs, a "...good DJ didn't only lead dancers...[to the dance floor,] but would also feel the mood of the dance floor and select records according to this energy (which could be communicated by the vigor of the dancing, or level of the crowd's screams, or sign language of dancers directed towards the booth)." Disco-era DJs would often remix (re-edit) existing songs using reel-to-reel tape machines, and add in percussion breaks, new sections, and new sounds. DJs would select songs and grooves according to what the dancers wanted, transitioning from one song to another with a DJ mixer and using a microphone to introduce songs and speak to the audiences. Other equipment was added to the basic DJ setup, providing unique sound manipulations, such as reverb, equalization, and echo effects unit. Using this equipment, a DJ could do effects such as cutting out all but the throbbing bassline of a song, and then slowly mixing in the beginning of another song using the DJ mixer's crossfader.

The DJs played "... a smooth mix of long single records to keep people 'dancing all night long'".

Notable U.S. disco DJs include Karen Mixon Cook (the first female disco DJ in the US), Jim Burgess, Walter Gibbons, John "Jellybean" Benitez, Richie Kaczar of Studio 54, Rick Gianatos, Francis Grasso of Sanctuary, Larry Levan, Ian Levine and David Mancuso.

DJs not only played songs in clubs; they also remixed, looped and live-mixed these songs from the DJ booth, changing the ways songs sounded. For example, a DJ might use the intro or bassline from a popular disco track and beatmatch and layer the vocals from a second song over top. As well, some DJs were also record producers who created and produced disco songs in the recording studio. Larry Levan, for example, is as well known for his prolific record producer work as for his contributions as a DJ.

Because record sales were often dependent on dance floor play by DJs in leading nightclubs, DJs were also influential for the development and popularization of certain types of disco music being produced for record labels.

The "disco sound" was much more costly to produce than many of the other popular music genres from the 1970s. Unlike the simpler, four-piece-band sound of the funk, soul of the late 1960s, or the small jazz organ trios, disco music often included a large pop band, with several chordal instruments (guitar, keyboards, synthesizer), several drum or percussion instruments (drumkit, Latin percussion, electronic drums), a horn section, a string orchestra, and a variety of "classical" solo instruments (for example, flute, piccolo, and so on).

Disco songs were arranged and composed by experienced arrangers and orchestrators, and record producers added their creative touches to the overall sound using multitrack recording techniques and effects units. Recording complex arrangements with such a large number of instruments and sections required a team that included a conductor, copyists, record producers, and mixing engineers. Mixing engineers had an important role in the disco production process, because disco songs used as many as 64 tracks of vocals and instruments. Mixing engineers and record producers, under the direction of arrangers, compiled these tracks into a fluid composition of verses, bridges, and refrains, complete with orchestral builds and breaks. Mixing engineers and record producers helped to develop the "disco sound" by creating a distinctive-sounding, sophisticated disco mix.

Early records were the "standard" 3 minute version until Tom Moulton came up with a way to make songs longer. Moulton wanted to make longer songs, so that he could take a crowd of dancers at a club to another level and keep them dancing longer. He found that was impossible to make the 45-RPM vinyl discs of the time longer, as they could usually hold no more than 5 minutes of good-quality music. With the help of José Rodriguez, his remaster/mastering engineer, he pressed a single on a 10" disc instead of 7". They cut the next single on a 12" disc, the same format as a standard album. Moulton and Rodriguez discovered that these larger records could have much longer songs and remixes. Twelve-inch records, even for singles, quickly became the standard format for all DJs of the disco genre.

Powerful, bass-heavy, hi-fi sound systems were viewed as a key part of the disco club experience. "Mancuso introduced the technologies of tweeter arrays (clusters of small loudspeakers, which emit high-end frequencies, positioned above the floor) and bass reinforcements (additional sets of subwoofers positioned at ground level) at the start of the 1970s in order to boost the treble and bass at opportune moments, and by the end of the decade sound engineers such as Richard Long had multiplied the effects of these innovations in venues such as the Garage."

Typical lighting designs for disco dance floors could include multi-coloured lights that swirl around or flash to the beat, strobe light, an illuminated dance floor and a mirror ball.

In the early years, dancers in discos danced in a "hang loose" or "freestyle" approach. At first, many dancers improvised their own dance styles and dance steps. Later in the disco era, popular dance styles were developed, including the "Bump", "Penguin", "Boogaloo", "Watergate" and the "Robot". By October 1975 The Hustle reigned. It was highly stylized, sophisticated and overtly sexual. Variations included the Brooklyn Hustle, New York Hustle and Latin Hustle.

During the disco era, many nightclubs would commonly host disco dance competitions or offer free dance lessons. Some cities had disco dance instructors or dance schools, which taught people how to do popular disco dances such as ""touch dancing", ""the hustle", and "the cha cha". The pioneer of disco dance instruction was Karen Lustgarten in San Francisco in 1973. Her book "The Complete Guide to Disco Dancing" (Warner Books, 1978) was the first to name, break down and codify popular disco dances as dance forms and distinguish between disco freestyle, partner and line dances. The book topped the "New York Times" bestseller list for 13 weeks and was translated into Chinese, German and French.

In Chicago, the "Step By Step" disco dance TV show was launched with the sponsorship support of the Coca-Cola company. Produced in the same studio that Don Cornelius used for the nationally syndicated dance/music television show, "Soul Train", "Step by Step"'s audience grew and the show became a success. The dynamic dance duo of Robin and Reggie led the show. The pair spent the week teaching disco dancing to dancers in the disco clubs. The instructional show which aired on Saturday mornings had a following of dancers who would stay up all night on Fridays so they could be on the set the next morning, ready to return to the disco on Saturday night knowing with the latest personalized dance steps. The producers of the show, John Reid and Greg Roselli, routinely made appearances at disco functions with Robin and Reggie to scout out new dancing talent and promote upcoming events such as "Disco Night at White Sox Park".

Some notable professional dance troupes of the 1970s included Pan's People and Hot Gossip. For many dancers, a key source of inspiration for 1970s disco dancing was the film "Saturday Night Fever" (1977). This developed into the music and dance style of such films as "Fame" (1980), "Disco Dancer" (1982), "Flashdance" (1983), and "The Last Days of Disco" (1998). Interest in disco dancing also helped spawn dance competition TV shows such as "Dance Fever" (1979).

Disco fashions were very trendy in the late 1970s. Discothèque-goers often wore glamorous, expensive and extravagant fashions for nights out at their local disco club. Some women would wear sheer, flowing dresses, such as Halston dresses or loose, flared pants. Other women wore tight, revealing, sexy clothes, such as backless halter tops, "hot pants" or body-hugging spandex bodywear or "catsuits". Men would wear shiny polyester Qiana shirts with colorful patterns and pointy, extra wide collars, preferably open at the chest. Men often wore Pierre Cardin suits, three piece suits with a vest and double-knit polyester shirt jackets with matching trousers known as the leisure suit. Men's leisure suits were typically form-fitted in some parts of the body, such as the waist and bottom, but the lower part of the pants were flared in a bell bottom style, to permit freedom of movement.

During the disco era, men engaged in elaborate grooming rituals and spent time choosing fashion clothing, both activities that would have been considered "feminine" according to the gender stereotypes of the era. Women dancers wore glitter makeup, sequins or gold lamé clothing that would shimmer under the lights. Bold colors were popular for both genders. Platform shoes and boots for both genders and high heels for women were popular footwear. Necklaces and medallions were a common fashion accessory. Less commonly, some disco dancers wore outlandish costumes, dressed in drag, covered their bodies with gold or silver paint, or wore very skimpy outfits leaving them nearly nude; these uncommon get-ups were more likely to be seen at invitation-only New York City loft parties and disco clubs.

In addition to the dance and fashion aspects of the disco club scene, there was also a thriving club drug subculture, particularly for drugs that would enhance the experience of dancing to the loud, bass-heavy music and the flashing colored lights, such as cocaine (nicknamed "blow"), amyl nitrite "poppers", and the "... other quintessential 1970s club drug Quaalude, which suspended motor coordination and gave the sensation that one's arms and legs had turned to "Jell-O." Quaaludes were so popular at disco clubs that the drug was nicknamed "disco biscuits".

Paul Gootenberg states that "[t]he relationship of cocaine to 1970s disco culture cannot be stressed enough..." During the 1970s, the use of cocaine by well-to-do celebrities led to its "glamorization" and to the widely held view that it was a "soft drug". Cocaine was also popular because its stimulating effect "...fueled all-night parties" at disco clubs. LSD, marijuana, and "speed" (amphetamines) were also popular in disco clubs, and the use of these drugs "...contributed to the hedonistic quality of the dance floor experience." Since disco dances were typically held in liquor licensed-nightclubs and dance clubs, alcoholic drinks were also consumed by dancers; some users intentionally combined alcohol with the consumption of other drugs, such as Quaaludes, for a stronger effect.

According to Peter Braunstein, the "massive quantities of drugs ingested in discothèques produced the next cultural phenomenon of the disco era: rampant promiscuity and public sex. While the dance floor was the central arena of seduction, actual sex usually took place in the nether regions of the disco: bathroom stalls, exit stairwells, and so on. In other cases the disco became a kind of 'main course' in a hedonist's menu for a night out." At The Saint nightclub, a high percentage of the gay male dancers and patrons would have sex in the club; they typically had unprotected sex, because in 1980, HIV-AIDS had not yet been identified. At The Saint, "...dancers would elope to an un[monitored] upstairs balcony to engage in sex." The promiscuity and public sex at discos was part of a broader trend towards exploring a freer sexual expression in the 1970s, an era that is also associated with "swingers clubs, hot tubs, [and] key parties."

Disco was mostly developed from music that was popular on the dance floor in clubs that started playing records instead of having a live band. The first discotheques mostly played swing music. Later on uptempo rhythm and blues became popular in American clubs and northern soul and glam rock records in the UK.

In the early 1940s nightclubs in Paris resorted to playing (jazz) records during the Nazi occupation.

Régine Zylberberg claimed to have started the first discotheque and to have been the first club DJ in 1953 in the "Whisky à Go-go" in Paris. She installed a dance floor with coloured lights and two turntables so she could play records without having a gap in the music.

In October 1959 the owner of the Scotch Club in Aachen, West Germany chose to install a record player for the opening night instead of hiring a live band. The patrons were unimpressed until a young reporter, who happened to be covering the opening of the club, impulsively took control of the record player and introduced the records that he chose to play. Klaus Quirini later claimed to thus have been the world's first nightclub DJ.

Discotheque dancing became a European trend that was enthusiastically picked up by the American press.

The birth of disco is often claimed to be found in the private dance parties held by New York City DJ David Mancuso's home that became known as The Loft, an invitation-only non-commercial underground club that inspired many others. He organized the first major party in his Manhattan home on Valentine's Day 1970 with the name "Love Saves The Day". After some months the parties became weekly events and Mancuso continued to give regular parties into the 1990s. Mancuso required that the music played had to be soulful, rhythmic, and impart words of hope, redemption, or pride.

In the 1970s, the key counterculture of the 1960s, the hippie movement, was fading away. The economic prosperity of the previous decade had declined, and unemployment, inflation and crime rates had soared. Political issues like the backlash from the Civil Rights Movement culminating in the form of race riots, the Vietnam War, the assassinations of Dr. Martin Luther King and John F. Kennedy and the Watergate scandal left many feeling disillusioned and hopeless. The start of the ’70s was marked by a shift in the consciousness of the American people: the rise of the feminist movement, identity politics, gangs, etc. very much shaped this era. Within New York city specifically, there was a surge in immigration which led to white flight - as many of these immigrants were Asian, Latino, and Black (Afro-Caribbeans). Disco music and disco dancing provided an escape from negative social and economic issues.

In "Beautiful Things in Popular Culture", Simon Frith highlights the sociability of disco and its roots in 1960s counterculture. "The driving force of the New York underground dance scene in which disco was forged was not simply that city's complex ethnic and sexual culture but also a 1960s notion of community, pleasure and generosity that can only be described as hippie," he says. "The best disco music contained within it a remarkably powerful sense of collective euphoria."

When Mancuso threw his first informal house parties, the gay community (who comprised much of The Loft's attendee roster) was often harassed in the gay bars and dance clubs, with many gay men carrying bail money with them to gay bars. But at The Loft and many other early, private discotheques, they could dance together without fear of police action thanks to Mancuso's underground, yet legal, policies. Vince Aletti described it "like going to party, completely mixed, racially and sexually, where there wasn't any sense of someone being more important than anyone else," and Alex Rosner reiterated this saying "It was probably about sixty percent black and seventy percent gay...There was a mix of sexual orientation, there was a mix of races, mix of economic groups. A real mix, where the common denominator was music." 

Film critic Roger Ebert called the popular embrace of disco's exuberant dance moves an escape from "the general depression and drabness of the political and musical atmosphere of the late seventies."

Pauline Kael, writing about the disco-themed film "Saturday Night Fever", said the film and disco itself touched on "something deeply romantic, the need to move, to dance, and the need to be who you'd like to be. Nirvana is the dance; when the music stops, you return to being ordinary."

During the sixties, when the discotheque culture from Europe became popular in the United States, several music genres with dance-able rhythms rose to popularity and evolved into different sub-genres: rhythm and blues (originated in the 1940s), soul music (late 1950s and 1960s), funk (mid-1960s) and go-go (mid 1960s and 1970s, more than "disco" the word "go-go" originally indicated a music club). Those genres, mainly African-American ones, would influence much of early disco music .

During the sixties, the Motown record label developed a popular and influential own sound, described as having "1) simply structured songs with sophisticated melodies and chord changes, 2) a relentless four-beat drum pattern, 3) a gospel use of background voices, vaguely derived from the style of the Impressions, 4) a regular and sophisticated use of both horns and strings, 5) lead singers who were half way between pop and gospel music, 6) a group of accompanying musicians who were among the most dextrous, knowledgeable, and brilliant in all of popular music (Motown bassists have long been the envy of white rock bassists) and 7) a trebly style of mixing that relied heavily on electronic limiting and equalizing (boosting the high range frequencies) to give the overall product a distinctive sound, particularly effective for broadcast over AM radio." Motown had many hits with early disco elements by acts like the Supremes (for instance "You Keep Me Hangin' On" in 1966), Stevie Wonder (for instance "Superstition" in 1972), The Jackson 5 and Eddie Kendricks ("Keep on Truckin'" in 1973).

In the mid-1960s and early 1970s Philadelphia soul and New York soul developed as sub-genres that also had lavish percussion, lush string orchestra arrangements and expensive record production processes.

At the end of the 1960s musicians and audiences from the Black, Italian and Latino communities adopted several traits from the hippie and psychedelia subcultures. They included using music venues with a loud, overwhelming sound, free-form dancing, trippy lighting, colorful costumes, and the use of hallucinogen drugs. In addition, the perceived positivity, lack of irony, and earnestness of the hippies informed proto-disco music like MFSB's album "Love Is the Message".
Partly through the success of Jimi Hendrix, psychedelic elements that were popular in rock music of the late 1960s found their way into soul and early funk music and formed the subgenre psychedelic soul. Examples can be found in the music of the Chambers Brothers, George Clinton with his Parliament-Funkadelic collective, Sly and the Family Stone and the productions of Norman Whitfield with The Temptations.

The long instrumental introductions and detailed orchestration found in psychedelic soul tracks by the Temptations are also considered as cinematic soul. In the early 1970s Curtis Mayfield and Isaac Hayes scored hits with cinematic soul songs that were actually composed for movie soundtracks: Superfly (1972) and Theme from Shaft (1971). The latter is sometimes regarded as an early disco song.

Psychedelic soul influenced proto-disco acts such as Willie Hutch and Philadelphia soul.

In the early 1970s the Philadelphia soul productions by Gamble and Huff evolved from the simpler arrangements of the late-1960s into a style featuring lush strings, thumping basslines, and sliding hi-hat rhythms. These elements would become typical for disco music and are found in several of the hits they produced in the early 1970s:

Other early disco tracks that helped shape disco and became popular on the dance floors of (underground) discotheque clubs and parties include: 

Early disco was dominated by record producers and labels such as Salsoul Records (Ken, Stanley, and Joseph Cayre), West End Records (Mel Cheren), Casablanca (Neil Bogart), and Prelude (Marvin Schlachter), to name a few. The genre was also shaped by Tom Moulton, who wanted to extend the enjoyment of dance songs — thus creating the extended mix or "remix", going from a three-minute 45 rpm single to the much longer 12" record. Other influential DJs and remixers who helped to establish what became known as the "disco sound" included David Mancuso, Nicky Siano, Shep Pettibone, Larry Levan, Walter Gibbons, and Chicago-based Frankie Knuckles. Frankie Knuckles was not only an important disco DJ; he also helped to develop house music in the 1980s.

Disco hit the television airwaves as part of the music/dance variety show "Soul Train" in 1971 hosted by Don Cornelius, then Marty Angelo's "Disco Step-by-Step Television Show" in 1975, Steve Marcus' "Disco Magic/Disco 77", Eddie Rivera's "Soap Factory", and Merv Griffin's "Dance Fever", hosted by Deney Terrio, who is credited with teaching actor John Travolta to dance for his role in the film "Saturday Night Fever", as well as DANCE, based out of Columbia, South Carolina.

In 1974, New York City's WPIX-FM premiered the first disco radio show.

As a producer and songwriter Norman Whitfield had helped to develop the Motown sound in the 1960s with many hits for Marvin Gaye, the Velvelettes, the Temptations and Gladys Knight & The Pips. From around the production of the Temptations' album "Cloud Nine" in 1968 he incorporated some psychedelic influences and started to produce longer tracks, with more room for elaborate rhythmic instrumental parts. A clear example of such a long psychedelic soul track is "Papa Was a Rollin' Stone", which appeared as a single edit of almost 7 minutes and an approximately twelve-minute-long 12" version. By the early seventies many of his productions had evolved more and more towards funk and disco, as heard on albums by the Undisputed Truth and the 1973 album "" by The Jackson 5. After he left Motown in 1975 he produced some more disco hits, including Car Wash (1976) by Rose Royce.

In the late 1960s uptempo soul with heavy beats and some associated dance styles and fashion were picked up in the British mod scene and formed the northern soul movement. Originating at venues such as the Twisted Wheel in Manchester, it quickly spread to other UK dancehalls and nightclubs like the Chateau Impney (Droitwich), Catacombs (Wolverhampton), the Highland Rooms at Blackpool Mecca, Golden Torch (Stoke-on-Trent) and Wigan Casino. As the favoured beat became more uptempo and frantic in the early 1970s, northern soul dancing became more athletic, somewhat resembling the later dance styles of disco and break dancing. Featuring spins, flips, karate kicks and backdrops, club dancing styles were often inspired by the stage performances of touring American soul acts such as Little Anthony & the Imperials and Jackie Wilson.

In 1974 there were an estimated 25,000 mobile discos and 40,000 professional disc jockeys in the United Kingdom. Mobile discos were hired deejays that brought their own equipment to provide music for special events. Glam rock tracks were popular, with for example Gary Glitter's 1972 single Rock and Roll Part 2 becoming popular on UK dance floors while it didn't get any radio airplay.

From 1974 to 1977, disco music continued to increase in popularity as many disco songs topped the charts.
The Hues Corporation's 1974 "Rock the Boat", a US number-one single and million-seller, was another one of the early disco songs to reach number one. The same year saw the release of "Kung Fu Fighting", performed by Carl Douglas and produced by Biddu, which reached number one in both the UK and US, and became the best-selling single of the year and one of the best-selling singles of all time with eleven million records sold worldwide, helping to popularize disco to a great extent. Another notable disco success that year was George McCrae's "Rock Your Baby": it became the United Kingdom's first number one chart disco single.

In the northwestern sections of the United Kingdom, the Northern soul explosion, which started in the late 1960s and peaked in 1974, made the region receptive to disco, which the region's Disc Jockeys were bringing back from New York City. The shift by some DJs to the newer sounds coming from the U.S.A. resulted in a split in the scene, whereby some abandoned the 1960s soul and pushed a Modern soul sound which tended to be more closely aligned with disco than soul.
In 1975, Gloria Gaynor released her first side-long vinyl album, which included a remake of the Jackson 5's "Never Can Say Goodbye" (which, in fact, is also the "album title") and two other songs, "Honey Bee" and her disco version of "Reach Out (I'll Be There)", first topped the Billboard disco/dance charts in November 1974. Later in 1978 Gaynor's number-one disco song was "I Will Survive", which was seen as a symbol of female strength and a gay anthem, like her further disco hit, a 1983 remake of I Am What I Am; in 1979 she released "Let Me Know (I Have a Right)", a single which gained popularity in the Civil Rights Movements. Also in 1975, Vincent Montana Jr.'s Salsoul Orchestra contributed with their Latin-flavored orchestral dance song "Salsoul Hustle", reaching number four on the Billboard Dance Chart and their 1976 hits "Tangerine" and "Nice 'n' Naasty", the first being a cover of a 1941 song.

Songs such as Van McCoy's 1975 "The Hustle" and the humorous Joe Tex 1977 "Ain't Gonna Bump No More (With No Big Fat Woman)" gave names to the popular disco dances "the Bump" and "the Hustle". Other notable early successful disco songs include Barry White's "You're the First, the Last, My Everything" (1974), Labelle's "Lady Marmalade" (1974), Disco-Tex and the Sex-O-Lettes' "Get Dancin'" (1974), Silver Convention's "Fly, Robin, Fly" (1975), "Get Up and Boogie" (1976) and Johnny Taylor's "Disco Lady" (1976).

Formed by Harry Wayne Casey (a.k.a. "KC") and Richard Finch, Miami's KC and the Sunshine Band had a string of disco-definitive top-five singles between 1975 and 1977, including "Get Down Tonight", "That's the Way (I Like It)", "(Shake, Shake, Shake) Shake Your Booty", "I'm Your Boogie Man" and "Keep It Comin' Love". In this period, rock bands like also English Electric Light Orchestra featured in their songs a violin sound that became a staple of disco music, as in the 1975 hit "Evil Woman", although the genre was correctly described as orchestral rock.
In 1970s Munich, West Germany, music producers Giorgio Moroder and Pete Bellotte made a decisive contribution to disco music with a string of hits for Donna Summer, which became known as the "Munich Sound". In 1975, Summer suggested the lyric Love to Love You Baby to Moroder and Bellotte, who turned the lyric into a full disco song. The final product, which contained a series of simulated orgasms, initially was not intended for release, but when Moroder played it in the clubs it caused a sensation and he released it. The song became an international hit, reaching the charts in many European countries and the US (No. 2). It has been described as the arrival of the expression of raw female sexual desire in pop music. A 17-minute 12-inch single was released. The 12" single became and remains a standard in discos today.
In 1976 Donna Summer's version of "Could It Be Magic" brought disco further into the mainstream.

In 1977 Summer, Moroder and Bellotte further released "I Feel Love", as the B side of "Can't We Just Sit Down (And Talk It Over)", which revolutionized dance music with its mostly electronic production and was a massive worldwide success, spawning the Hi-NRG subgenre.

Other disco producers, most famously Tom Moulton, grabbed ideas and techniques from dub music (which came with the increased Jamaican migration to New York City in the 1970s) to provide alternatives to the "four on the floor" style that dominated. DJ Larry Levan utilized styles from dub and jazz and remixing techniques to create early versions of house music that sparked the genre.

In December 1977, the film "Saturday Night Fever" was released. It was a huge success and its soundtrack became one of the best-selling albums of all time. The idea for the film was sparked by a 1976 "New York" magazine article titled "Tribal Rites of the New Saturday Night" which supposedly chronicled the disco culture in mid-1970s New York City, but was later revealed to have been fabricated. Some critics said the film "mainstreamed" disco, making it more acceptable to heterosexual white males.

The Bee Gees used Barry Gibb's falsetto to garner hits such as "You Should Be Dancing", "Stayin' Alive", "Night Fever", "More Than A Woman" and "Love You Inside Out". Andy Gibb, a younger brother to the Bee Gees, followed with similarly styled solo singles such as "I Just Want to Be Your Everything", "(Love Is) Thicker Than Water" and "Shadow Dancing".

In 1978, Donna Summer's multi-million selling vinyl single disco version of "MacArthur Park" was number one on the "Billboard" Hot 100 chart for three weeks and was nominated for the Grammy Award for Best Female Pop Vocal Performance. The recording, which was included as part of the "MacArthur Park Suite" on her double live album Live and More, was eight minutes and forty seconds-long on the album. The shorter seven-inch vinyl single version of MacArthur Park was Summer's first single to reach number one on the Hot 100; it does not include the balladic second movement of the song, however. A 2013 remix of "MacArthur Park" by Summer topped the Billboard Dance Charts marking five consecutive decades with a number-one song on the charts. From mid-1978 to late 1979, Summer continued to release singles such as "Last Dance", "Heaven Knows" (with Brooklyn Dreams), "Hot Stuff", "Bad Girls", "Dim All the Lights" and "On the Radio", all very successful songs, landing in the top five or better, on the Billboard pop charts.

The band Chic was formed mainly by guitarist Nile Rodgers—a self-described "street hippie" from late 1960s New York—and bassist Bernard Edwards. "Le Freak" was a popular 1978 single of theirs that is regarded as an iconic song of the genre. Other successful songs by Chic include the often-sampled "Good Times" (1979) and "Everybody Dance" (1979). The group regarded themselves as the disco movement's rock band that made good on the hippie movement's ideals of peace, love, and freedom. Every song they wrote was written with an eye toward giving it "deep hidden meaning" or D.H.M.

Sylvester, a flamboyant and openly gay singer famous for his soaring falsetto voice, scored his biggest disco hit in late 1978 with "You Make Me Feel (Mighty Real)". His singing style was said to have influenced the singer Prince. At that time, disco was one of the forms of music most open to gay performers.

The Village People were a singing/dancing group created by Jacques Morali and Henri Belolo to target disco's gay audience. They were known for their onstage costumes of typically male-associated jobs and ethnic minorities and achieved mainstream success with their 1978 hit song "Macho Man". Other songs include "Y.M.C.A." (1979) and "In the Navy" (1979).

The Jackson 5 (formerly the Jackson 5) released many disco songs from 1977 to 1981, including "Blame It on the Boogie" (1978), "Shake Your Body (Down to the Ground)" (1979), "Lovely One" (1980) and "Can You Feel It" (1981): all of them were sung by Michael Jackson, whose 1979 solo album, "Off the Wall", also included several disco hits, such as the album's title song, "Rock with You", "Workin' Day and Night" and his second chart-topping solo disco hit, "Don't Stop 'Til You Get Enough".

Also noteworthy are The Trammps' "Disco Inferno" (1978, reissue due to the popularity gained from the "Saturday Night Fever" soundtrack), Cheryl Lynn's "Got to Be Real" (1978), Evelyn "Champagne" King's "Shame" (1978), Alicia Bridges' "I Love the Nightlife" (1978), Patrick Hernandez' Born to Be Alive (1978), Sister Sledge's "We Are Family" (1979), Anita Ward's "Ring My Bell" (1979), Lipps Inc.'s "Funkytown" (1979), and Walter Murphy's various attempts to bring classical music to the mainstream, most notably his disco song "A Fifth of Beethoven" (1976), which was inspired by Beethoven's fifth symphony.

At the height of its popularity, many non-disco artists recorded songs with disco elements, such as Rod Stewart with his "Da Ya Think I'm Sexy?" in 1979. Even mainstream rock artists adopted elements of disco. Progressive rock group Pink Floyd used disco-like drums and guitar in their song "Another Brick in the Wall, Part 2" (1979), which became their only number-one single in both the US and UK. The Eagles referenced disco with "One of These Nights" (1975) and "Disco Strangler" (1979), Paul McCartney & Wings with "Goodnight Tonight" (1979), Queen with "Another One Bites the Dust" (1980), the Rolling Stones with "Miss You" (1978) and "Emotional Rescue" (1980), Electric Light Orchestra with "Shine a Little Love" and "Last Train to London" (both 1979), Chicago with "Street Player" (1979), the Kinks with "(Wish I Could Fly Like) Superman" (1979), the Grateful Dead with "Shakedown Street", The Who with "Eminence Front" (1982), and the J. Geils Band with "Come Back" (1980). Even hard rock group KISS jumped in with "I Was Made For Lovin' You" (1979), and Ringo Starr's album "Ringo the 4th" (1978) features a strong disco influence.

The disco sound was also adopted by "non-pop" artists, including the 1979 U.S. number one hit "No More Tears (Enough Is Enough)" by easy listening singer Barbra Streisand in a duet with Donna Summer. In country music, artists like Connie Smith covered Andy Gibb's "I Just Want to Be Your Everything" in 1977, Bill Anderson recorded "Double S" in 1978, and Ronnie Milsap released "Get It Up" and covered blues singer Tommy Tucker's song "Hi-Heel Sneakers" in 1979.

Pre-existing non-disco songs and standards were frequently "disco-ized" in the 1970s. The rich orchestral accompaniment that became identified with the disco era conjured up the memories of the big band era—which brought out several artists that recorded and disco-ized some big-band arrangements, including Perry Como, who re-recorded his 1945 song "Temptation", in 1975, as well as Ethel Merman, who released an album of disco songs entitled "The Ethel Merman Disco Album" in 1979.

Myron Floren, second-in-command on "The Lawrence Welk Show", released a recording of the "Clarinet Polka" entitled "Disco Accordion." Similarly, Bobby Vinton adapted "The Pennsylvania Polka" into a song named "Disco Polka". Easy listening icon Percy Faith, in one of his last recordings, released an album entitled "Disco Party" (1975) and recorded a disco version of his famous "Theme from A Summer Place" in 1976. Classical music was even adapted for disco, notably Walter Murphy's "A Fifth of Beethoven" (1976, based on the first movement of Beethoven's 5th Symphony) and "Flight 76" (1976, based on Rimsky-Korsakov's "Flight of the Bumblebee"), and Louis Clark's "Hooked On Classics" series of albums and singles.

Notable disco songs based on film and television themes included a medley from "Star Wars", "Star Wars Theme/Cantina Band" (1977) by Meco, and "Twilight Zone/Twilight Tone" (1979) by the Manhattan Transfer. Even the "I Love Lucy" theme was not spared from being disco-ized. Many original television theme songs of the era also showed a strong disco influence, such as "Keep Your Eye On the Sparrow" (theme from "Baretta", performed by Sammy Davis, Jr. and later a successful single for Rhythm Heritage), "Theme from "S.W.A.T."" (from "S.W.A.T", original and single versions by Rhythm Heritage), and Mike Post's "Theme from "Magnum, P.I."".

Disco jingles also made their way into many TV commercials, including Purina's 1979 "Good Mews" cat food commercial and an "IC Light" commercial by Pittsburgh's Iron City Brewing Company.

Several parodies of the disco style were created. Rick Dees, at the time a radio DJ in Memphis, Tennessee, recorded "Disco Duck" (1976) and "Dis-Gorilla" (1977); Frank Zappa parodied the lifestyles of disco dancers in "Disco Boy" on his 1976 "Zoot Allures" album, and in "Dancin' Fool" on his 1979 "Sheik Yerbouti" album; "Weird Al" Yankovic's eponymous 1983 debut album includes a disco song called "Gotta Boogie", an extended pun on the similarity of the disco move to the American slang word "booger". Comedian Bill Cosby devoted his entire 1977 album "Disco Bill" to disco parodies. In 1980, "Mad Magazine" released a flexi-disc titled "Mad Disco" featuring six full-length parodies of the genre. Rock and roll songs critical of disco included Bob Seger's "Old Time Rock and Roll" and, especially, The Who's "Sister Disco" (both 1978)—although The Who's "Eminence Front" (four years later) had a disco feel.

By the end of the 1970s, a strong anti-disco sentiment developed among rock fans and musicians, particularly in the United States. Disco was criticized as mindless, consumerist, overproduced and escapist. The slogans "disco sucks" and "death to disco" became common. Rock artists such as Rod Stewart and David Bowie who added disco elements to their music were accused of being sell outs.

The punk subculture in the United States and United Kingdom was often hostile to disco, although in the UK, many early Sex Pistols fans such as the Bromley Contingent and Jordan quite liked disco, often congregating at nightclubs such as Louise's in Soho and the Sombrero in Kensington. The track "Love Hangover" by Diana Ross, the house anthem at the former, was cited as a particular favourite by many early UK Punks. Also, the film "The Great Rock 'n' Roll Swindle" and its soundtrack album contained a disco medley of Sex Pistols songs, entitled "Black Arabs" and credited to a group of the same name.) Jello Biafra of the Dead Kennedys, in the song "Saturday Night Holocaust", likened disco to the cabaret culture of Weimar-era Germany for its apathy towards government policies and its escapism. Mark Mothersbaugh of Devo said that disco was "like a beautiful woman with a great body and no brains", and a product of political apathy of that era. New Jersey rock critic Jim Testa wrote "Put a Bullet Through the Jukebox", a vitriolic screed attacking disco that was considered a punk call to arms. Steve Hillage, shortly prior to his transformation from a progressive rock musician into an electronic artist at the end of the 1970s with the inspiration of disco, disappointed his rockist fans by admitting his love for disco, with Hillage recalling "it's like I'd killed their pet cat."

Anti-disco sentiment was expressed in some television shows and films. A recurring theme on the show "WKRP in Cincinnati" was a hostile attitude towards disco music. In one scene of the 1980 comedy film "Airplane!", a wayward airplane slices a radio tower with its wing, knocking out an all-disco radio station.

July 12, 1979, became known as "the day disco died" because of Disco Demolition Night, an anti-disco demonstration in a baseball double-header at Comiskey Park in Chicago. Rock-station DJs Steve Dahl and Garry Meier, along with Michael Veeck, son of Chicago White Sox owner Bill Veeck, staged the promotional event for disgruntled rock fans between the games of a White Sox doubleheader. The event, which involved exploding disco records, ended with a riot, during which the raucous crowd tore out seats and pieces of turf, and caused other damage. The Chicago Police Department made numerous arrests, and the extensive damage to the field forced the White Sox to forfeit the second game to the Detroit Tigers, who had won the first game.

Six months prior to the chaotic event (in December 1978), popular progressive rock radio station WDAI (WLS-FM) had suddenly switched to an all-disco format, disenfranchising thousands of Chicago rock fans and leaving Dahl unemployed. WDAI, who despite surviving the backlash and still had good ratings at this point, continued to play disco until it flipped to a short-lived hybrid Top 40/Rock format in May 1980. Another disco outlet that also competed against WDAI at the time, WGCI-FM, would later incorporate R&B and Pop Songs into the format, eventually evolving into an Urban Contemporary outlet that it continues with today. The latter also helped bring the house music genre to the airwaves, ending the backlash somewhat with Chicago emerging as the birthplace of house.

On July 21, 1979, the top six records on the U.S. music charts were disco songs. By September 22, there were no disco songs in the US Top 10 chart, with the exception of Herb Alpert's instrumental "Rise," a smooth jazz composition with some disco overtones. Some in the media, in celebratory tones, declared disco "dead" and rock revived. Karen Mixon Cook, the first female disco DJ, stated that people still pause every July 12 for a moment of silence in honor of disco. Dahl stated in a 2004 interview that disco was "probably on its way out [at the time]. But I think it [Disco Demolition Night] hastened its demise".

The anti-disco backlash, combined with other societal and radio industry factors, changed the face of pop radio in the years following Disco Demolition Night. Starting in the 1980s, country music began a slow rise in American main pop charts. Emblematic of country music's rise to mainstream popularity was the commercially successful 1980 movie "Urban Cowboy". The continued popularity of power pop and the revival of oldies in the late 1970s was also related to the disco backlash; the 1978 film "Grease" was emblematic of this trend. Somewhat paradoxically, the star of both films was John Travolta, who in 1977 had starred in "Saturday Night Fever", which remains one of the most iconic disco films of the era.

During this period of decline in disco's popularity, several record companies folded, were reorganized, or were sold. In 1979, MCA Records purchased ABC Records, absorbed some of its artists, and then shut the label down. Midsong International Records ceased operations in 1980. RSO Records founder Robert Stigwood left the label in 1981 and TK Records closed in the same year. Salsoul Records continues to exist in the 2000s, but primarily is used as a reissue brand. Casablanca Records had been releasing fewer records in the 1980s, and was shut down in 1986 by parent company PolyGram.

Many groups that were popular during the disco period subsequently struggled to maintain their success—even those that tried to adapt to evolving musical tastes. The Bee Gees, for instance, had only one top-10 entry (1989's "One") and three more top-40 songs (despite recording and releasing far more than that and completely abandoning disco in their 1980s and 1990s songs) in the United States after the 1970s, even though numerous songs they wrote and had "other" artists perform were successful. Of the handful of groups "not" taken down by disco's fall from favor, Kool and the Gang, Donna Summer, the Jacksons—and Michael Jackson in particular—stand out: In spite of having helped "define" the disco sound early on, they continued to make popular and danceable, if more refined, songs for yet another generation of music fans in the 1980s and beyond. Earth, Wind & Fire also survived the disco backlash and continued to produce successful singles at roughly the same pace for several more years, in addition to an even longer string of R&B chart hits that lasted into the 1990s.

Factors that have been cited as leading to the decline of disco in the United States include economic and political changes at the end of the 1970s, as well as burnout from the hedonistic lifestyles led by participants. In the years since Disco Demolition Night, some social critics have described the backlash as implicitly macho and bigoted, and an attack on non-white and non-heterosexual cultures. The backlash also made its way into US politics with the election of conservative Ronald Reagan in 1980 which also led to Republican control of the United States Senate for the first time since 1954, plus the subsequent rise of the Religious Right around the same time.

In January 1979, rock critic Robert Christgau argued that homophobia, and most likely racism, were reasons behind the backlash, a conclusion seconded by John Rockwell. Craig Werner wrote: "The Anti-disco movement represented an unholy alliance of funkateers and feminists, progressives and puritans, rockers and reactionaries. Nonetheless, the attacks on disco gave respectable voice to the ugliest kinds of unacknowledged racism, sexism and homophobia." Legs McNeil, founder of the fanzine "Punk", was quoted in an interview as saying, "the hippies always wanted to be black. We were going, 'f**k the blues, f**k the black experience'." He also said that disco was the result of an "unholy" union between homosexuals and blacks.

Steve Dahl, who had spearheaded Disco Demolition Night, denied any racist or homophobic undertones to the promotion, saying, "It's really easy to look at it historically, from this perspective, and attach all those things to it. But we weren't thinking like that." It has been noted that British punk rock critics of disco were very supportive of the pro-black/anti-racist reggae genre as well as the more pro-gay new romantics movement. Christgau and Jim Testa have said that there were legitimate artistic reasons for being critical of disco.

In 1979, the music industry in the United States underwent its worst slump in decades, and disco, despite its mass popularity, was blamed. The producer-oriented sound was having difficulty mixing well with the industry's artist-oriented marketing system. Harold Childs, senior vice president at A&M Records, told the "Los Angeles Times" that "radio is really desperate for rock product" and "they're all looking for some white rock-n-roll". Gloria Gaynor argued that the music industry supported the destruction of disco because rock music producers were losing money and rock musicians were losing the spotlight.

However, disco music remained "relatively" successful in the early 1980s, with songs like Irene Cara's "Flashdance... What a Feeling" (theme to "Flashdance" film) and the theme song to the film "Fame" (later re-sung by Erica Gimpel for the TV show of the same name), Michael Jackson's "Thriller" and "Wanna Be Startin' Somethin'", K.C. and the Sunshine Band's last major single, "Give It Up", and Madonna's first album–all which had strong disco influences. Record producer Giorgio Moroder's soundtracks to "American Gigolo", "Flashdance" and "Scarface" (which also had a heavy disco influence) proved that the style was still very much embraced. Queen's 1982 album, "Hot Space" was inspired by the genre as well. Nevertheless, the "word" "disco" had become unfashionable to use when describing new music.

In the 1990s, disco and its legacy became more accepted by music artists and listeners alike, as more songs and films were released that referenced disco. Examples of songs during this time that were influenced by disco included Deee-Lite's "Groove Is in the Heart" (1990), U2's "Lemon" (1993), Blur's "Girls & Boys" (1994) & "Entertain Me" (1995), Pulp's "Disco 2000" (1995), and Jamiroquai's "Canned Heat" (1999), while films such as "Boogie Nights" (1997) and "The Last Days of Disco" (1998) featured primarily disco soundtracks.

In the early 2000s, an updated genre of disco called "nu-disco" began breaking into the mainstream. A few examples like Daft Punk's "One More Time" and Kylie Minogue's "Love At First Sight" and "Can't Get You Out of My Head" became club favorites and commercial successes. Several nu-disco songs were crossovers with funky house, such as Spiller's "Groovejet (If This Ain't Love)" and Modjo's "Lady (Hear Me Tonight)", both songs sampling older disco songs and both reaching number one on the UK Singles Chart in 2000. Robbie Williams' disco single "Rock DJ" was the UK's fourth best-selling single the same year. Rock band Manic Street Preachers released a disco song, "Miss Europa Disco Dancer", in 2001. The song's disco influence, which appears on "Know Your Enemy", was described as being "much-discussed". In 2005, Madonna immersed herself in the disco music of the 1970s, and released her album "Confessions on a Dance Floor" to rave reviews. In addition to that, her song "Hung Up" became a major top-10 song and club staple, and sampled ABBA's 1979 song "Gimme! Gimme! Gimme! (A Man After Midnight)". In addition to her disco-influenced attire to award shows and interviews, her Confessions Tour also incorporated various elements of the 1970s, such as disco balls, a mirrored stage design, and the roller derby.

The success of the "nu-disco" revival of the early 2000s was described by music critic Tom Ewing as more interpersonal than the pop music of the 1990s: "The revival of disco within pop put a spotlight on something that had gone missing over the 90s: a sense of music not just for dancing, but for dancing with someone. Disco was a music of mutual attraction: cruising, flirtation, negotiation. Its dancefloor is a space for immediate pleasure, but also for promises kept and otherwise. It’s a place where things start, but their resolution, let alone their meaning, is never clear. All of 2000s great disco number ones explore how to play this hand. Madison Avenue look to impose their will upon it, to set terms and roles. Spiller is less rigid. 'Groovejet' accepts the night’s changeability, happily sells out certainty for an amused smile and a few great one-liners."

In 2013, several 1970s-style disco and funk songs charted, and the pop charts had more dance songs than at any other point since the late 1970s. The biggest disco song of the year as of June was "Get Lucky" by Daft Punk, featuring Nile Rodgers on guitar. "Random Access Memories" also ended up winning Album of the Year at the 2014 Grammys. Other disco-styled songs that made it into the top 40 were Robin Thicke's "Blurred Lines" (number one), Justin Timberlake's "Take Back the Night" (number 29), Bruno Mars' "Treasure" (number five) and Michael Jackson's posthumous release "Love Never Felt So Good" (number nine). In addition, Arcade Fire's "Reflektor" featured strong disco elements. In 2014, disco music could be found in Lady Gaga's "Artpop" and Katy Perry's "Birthday". Other disco songs from 2014 include "I Want It All" By Karmin and 'Wrong Club" by the Ting Tings.

Other top-10 entries from 2015 like Mark Ronson's disco groove-infused "Uptown Funk", Maroon 5's "Sugar", the Weeknd's "Can't Feel My Face" and Jason Derulo's "Want To Want Me" also ascended the charts and have a strong disco influence. Disco mogul and producer Giorgio Moroder also re-appeared with his new album "Déjà Vu" in 2015 which has proved to be a modest success. Other songs from 2015 like "I Don't Like It, I Love It" by Flo Rida, "Adventure of a Lifetime" by Coldplay, "Back Together" by Robin Thicke and "Levels" by Nick Jonas feature disco elements as well. In 2016, disco songs or disco-styled pop songs are showing a strong presence on the music charts as a possible backlash to the 1980s-styled synthpop, electro house and dubstep that have been dominating the current charts. Justin Timberlake's 2016 song "Can't Stop the Feeling!", which shows strong elements of disco, became the 26th song to debut at number-one on the "Billboard" Hot 100 in the history of the chart. "The Martian", a 2015 film, extensively uses disco music as a soundtrack, although for the main character, astronaut Mark Watney, there's only one thing worse than being stranded on Mars: it's being stranded on Mars with nothing but disco music. "Kill the Lights", featured on an episode of the HBO television series "Vinyl" (2016) and with Nile Rodgers' guitar licks, hit number one on the US Dance chart in July 2016.

Diana Ross was one of the first Motown artists to embrace the disco sound with her successful 1976 outing "Love Hangover" from her self-titled album. Her 1980 dance classics "Upside Down" and "I'm Coming Out" were written and produced by Nile Rogers and Bernard Edwards of the group Chic. The Supremes, the group that made Ross famous, scored a handful of hits in the disco clubs without Ross, most notably 1976's "I'm Gonna Let My Heart Do the Walking" and, their last charted single before disbanding, 1977's "You're My Driving Wheel".

At the request of Motown that he produce songs in the disco genre, Marvin Gaye released "Got to Give It Up" in 1978, despite his dislike of disco. He vowed not to record any songs in the genre, and actually wrote the song as a parody. However, several of Gaye's songs have disco elements, including I Want You (1975). Stevie Wonder released the disco single "Sir Duke" in 1977 as a tribute to Duke Ellington, the influential jazz legend who had died in 1974. Smokey Robinson left the Motown group the Miracles for a solo career in 1972 and released his third solo album "A Quiet Storm" in 1975, which spawned and lent its name to the "Quiet Storm" musical programming format and subgenre of R&B. It contained the disco single "Baby That's Backatcha". Other Motown artists who scored disco hits include: Robinson's former group, the Miracles, with "Love Machine" (1975), Eddie Kendricks with "Keep On Truckin'" (1973), the Originals with "Down to Love Town" (1976) and Thelma Houston with her cover of the Harold Melvin and the Blue Notes song "Don't Leave Me This Way" (1976). The label continued to release successful disco songs into the 1980s with Rick James' "Super Freak" (1981), and the Commodores' "Lady (You Bring Me Up)" (1981).

Several of Motown's solo artists who left the label went on to have successful disco songs. Mary Wells, Motown's first female superstar with her signature song "My Guy" (written by Smokey Robinson), abruptly left the label in 1964. She briefly reappeared on the charts with the disco song "Gigolo" in 1980. Jimmy Ruffin, the elder brother of the Temptations lead singer David Ruffin, was also signed to Motown, and released his most successful and well-known song "What Becomes of the Brokenhearted" as a single in 1966. Ruffin eventually left the record label in the mid-1970s, but saw success with the 1980 disco song "Hold On (To My Love)", which was written and produced by Robin Gibb of the Bee Gees, for his album "Sunrise". Edwin Starr, known for his Motown protest song "War" (1970), reentered the charts in 1979 with a pair of disco songs, "Contact" and "H.A.P.P.Y. Radio".

Kiki Dee became the first white British singer to sign with Motown in the US, and released one album, "Great Expectations" (1970), and two singles "The Day Will Come Between Sunday and Monday" (1970) and "Love Makes the World Go Round" (1971), the latter giving her first ever chart entry (number 87 on the US Chart). She soon left the company and signed with Elton John's The Rocket Record Company, and in 1976 had her biggest and best-known single, "Don't Go Breaking My Heart", a disco duet with John. The song was intended as an affectionate disco-style pastiche of the Motown sound, in particular the various duets recorded by Marvin Gaye with Tammi Terrell and Kim Weston. Michael Jackson released many successful solo singles under the Motown label, like "Got To Be There" (1971), "Ben" (1972) and a cover of Bobby Day's "Rockin' Robin" (1972). He went on to score hits in the disco genre with "Rock with You" (1979), "Don't Stop 'Til You Get Enough" (1979) and "Billie Jean" (1983) for Epic Records.

Many Motown groups who had left the record label charted with disco songs. Michael Jackson was the lead singer of the Jackson 5, one of Motown's premier acts in the early 1970s. They left the record company in 1975 (Jermaine Jackson, however, remained with the label) after successful songs like "I Want You Back" (1969) and "ABC" (1970), and even the disco song "Dancing Machine" (1974). Renamed as 'the Jacksons' (as Motown owned the name 'the Jackson 5'), they went on to find success with disco songs like "Blame It on the Boogie" (1978), "Shake Your Body (Down to the Ground)" (1979) and "Can You Feel It?" (1981) on the Epic label. the Isley Brothers, whose short tenure at the company had produced the song "This Old Heart of Mine (Is Weak for You)" in 1966, went on release successful disco songs like "That Lady" (1973) and "It's a Disco Night (Rock Don't Stop)" (1979). Gladys Knight and the Pips, who recorded the most successful version of "I Heard It Through the Grapevine" (1967) before Marvin Gaye, scored commercially successful singles such as "Baby, Don't Change Your Mind" (1977) and "Bourgie, Bourgie" (1980) in the disco era.

The Detroit Spinners were also signed to the Motown label and saw success with the Stevie Wonder-produced song "It's a Shame" in 1970. They left soon after, on the advice of fellow Detroit native Aretha Franklin, to Atlantic Records, and there had disco songs like "The Rubberband Man" (1976). In 1979, they released a successful cover of Elton John's "Are You Ready for Love", as well as a medley of the Four Seasons' song "Working My Way Back to You" and Michael Zager's "Forgive Me, Girl". The Four Seasons themselves were briefly signed to Motown's MoWest label, a short-lived subsidiary for R&B and soul artists based on the West Coast, and there the group produced one album, "Chameleon" (1972) – to little commercial success in the US. However, one single, "The Night", was released in Britain in 1975, and thanks to popularity from the Northern Soul circuit, reached number seven on the UK Singles Chart. The Four Seasons left Motown in 1974 and went on to have a disco hit with their song "December, 1963 (Oh, What a Night)" (1975) for Warner Curb Records.

Norman Whitfield was a producer at Motown, renowned for creating innovative "psychedelic soul" songs. The genre later developed into funk, and from there into disco. The Undisputed Truth, a Motown recording act assembled by Whitfield to experiment with his psychedelic soul production techniques, found success with their 1971 song "Smiling Faces Sometimes". The disco single "You + Me = Love" (number 43) in 1976, which also made number 2 on the US Dance Charts. In 1977, singer, songwriter and producer Willie Hutch signed with Whitfield's new label. He had been signed to Motown since 1970, scored a successful disco single with his song "In and Out". The group Rose Royce produced the to the 1976 film "Car Wash", which contained the commercially successful song of the same name.

Singer Stacy Lattisaw signed with Motown "after" achieving success in the disco genre. In 1980, she released her album "Let Me Be Your Angel", which spawned the disco singles "Dynamite" and "Jump to the Beat" on the Cotillion label. Lattisaw continued to enjoy success as a contemporary R&B/pop artist throughout the 1980s. She signed with Motown in 1986, and achieved most success when teaming up with Johnny Gill, releasing the 1989 song "Where Do We Go From Here?" from her last ever album, "What You Need", before retiring. In addition, her first ever single, back in 1979, was a disco cover of "When You're Young and in Love", which was most famously recorded by Motown female group the Marvelettes in 1967.

Additionally, the debut single of Shalamar, the group originally created as a disco-driven vehicle by "Soul Train" creator Don Cornelius, was "Uptown Festival" (1977), a medley of 10 classic Motown songs sung over a 1970s disco beat.

As disco's popularity sharply declined in the United States, abandoned by major U.S. record labels and producers, European disco continued evolving within the broad mainstream pop music scene. European acts Silver Convention, Love and Kisses, Munich Machine, and American acts Donna Summer and the Village People, were acts that defined the late 1970s Euro disco sound. Producers Giorgio Moroder, whom AllMusic described as "one of the principal architects of the disco sound" with the Donna Summer song "I Feel Love" (1977), and Jean-Marc Cerrone were involved with Euro disco. The German group Kraftwerk also had an influence on Euro disco.
By far the most successful Euro disco act was ABBA. This Swedish quartet, which sang in English, found success with singles such as "Waterloo" (1974), "Fernando" (1976), "Take a Chance on Me" (1978), "Gimme! Gimme! Gimme! (A Man After Midnight)" (1979), and their signature smash hits "Dancing Queen" (1976)—ranks as the eighth best-selling act of all time. Other prominent European pop and disco groups were Luv' from the Netherlands, and Boney M., a group of four West Indian singers and dancers masterminded by West German record producer Frank Farian. Boney M. charted worldwide with such songs as "Daddy Cool", "Ma Baker" and "Rivers Of Babylon". Another Euro disco act was the French diva Amanda Lear, where Euro disco sound is most heard in "Enigma (Give a Bit of Mmh to Me)" (1978).

In France, Dalida released "J'attendrai" ("I Will Wait"), which also became successful in Canada, Europe and Japan. Dalida successfully adjusted herself to disco era and released at least a dozen of songs that charted among top number 10 in whole Europe and wider.
Claude François, who re-invented himself as the king of French disco, released "La plus belle chose du monde", a French version of the Bee Gees song "Massachusetts", which became successful in Canada and Europe and "Alexandrie Alexandra" was posthumously released on the day of his burial and became a worldwide success. Cerrone's early songs, "Love in C Minor", "Give Me Love" and "Supernature" were successful in the US and Europe.

In Italy Raffaella Carrà is the most successful disco act. Her greatest international single was "Tanti Auguri" ("Best Wishes"), which has become a popular song with gay audiences. The song is also known under its Spanish title "Para hacer bien el amor hay que venir al sur" (which refers to Southern Europe, since the song was recorded and taped in Spain). The Estonian version of the song "Jätke võtmed väljapoole" was performed by Anne Veski. "A far l'amore comincia tu" ("To make love, your move first") was another success for her internationally, known in Spanish as "En el amor todo es empezar", in German as "Liebelei", in French as "Puisque tu l'aimes dis le lui", and in English as "Do It, Do It Again". It was her only entry to the UK Singles Chart, reaching number 9, where she remains a one-hit wonder. In 1977, she recorded another successful single, "Fiesta" ("The Party" in English) originally in Spanish, but then recorded it in French and Italian after the song hit the charts. "A far l'amore comincia tu" has also been covered in Turkish by a Turkish popstar Ajda Pekkan as "Sakın Ha" in 1977.
Recently, Carrà has gained new attention for her appearance as the female dancing soloist in a 1974 TV performance of the experimental gibberish song "Prisencolinensinainciusol" (1973) by Adriano Celentano. A remixed video featuring her dancing went viral on the internet in 2008.
In 2008 a video of a performance of her only successful UK single, "Do It, Do It Again", was featured in the "Doctor Who" episode "Midnight". Rafaella Carrà worked with Bob Sinclar on the new single "Far l'Amore" which was released on YouTube on March 17, 2011. The song charted in different European countries.

By the late 1970s most major US cities had thriving disco club scenes, but the largest scenes were in San Francisco, Miami, and most notably New York City. The scene was centered on discotheques, nightclubs, and private loft parties.

In the 1970s, notable discos included Crisco Disco, "Leviticus" and "Paradise Garage" in New York, "Artemis" in Philadelphia, "Studio One" in Los Angeles, "Dugan's Bistro" in Chicago, and "The Library" in Atlanta.

In the late 70s, Studio 54 in New York City was arguably the most well known nightclub in the world. This club played a major formative role in the growth of disco music and nightclub culture in general. It was operated by Steve Rubell and Ian Schrager and was notorious for the hedonism that went on within; the balconies were known for sexual encounters, and drug use was rampant. Its dance floor was decorated with an image of the "Man in the Moon" that included an animated cocaine spoon.

The Copacabana, another New York nightclub dating to the 1940s, had a revival in the late 1970s when it embraced disco; it would become the setting of a Barry Manilow song of the same name.

The transition from the late-1970s disco styles to the early-1980s dance styles was marked primarily by the change from complex arrangements performed by large ensembles of studio session musicians (including a horn section and an orchestral string section), to a leaner sound, in which one or two singers would perform to the accompaniment of synthesizer keyboards and drum machines.

In addition, dance music during the 1981–83 period borrowed elements from blues and jazz, creating a style different from the disco of the 1970s. This emerging music was still known as disco for a short time, as the word had become associated with any kind of dance music played in discothèques. Examples of early-1980s' dance sound performers include D. Train, Kashif, and Patrice Rushen. These changes were influenced by some of the notable R&B and jazz musicians of the 1970s, such as Stevie Wonder, Kashif and Herbie Hancock, who had pioneered "one-man-band"-type keyboard techniques. Some of these influences had already begun to emerge during the mid-1970s, at the height of disco's popularity.

During the first years of the 1980s, the disco sound began to be phased out, and faster tempos and synthesized effects, accompanied by guitar and simplified backgrounds, moved dance music toward the funk and pop genres. This trend can be seen in singer Billy Ocean's recordings between 1979 and 1981. Whereas Ocean's 1979 song "American Hearts" was backed with an orchestral arrangement played by the Los Angeles Symphony Orchestra, his 1981 song ""One of Those Nights (Feel Like Gettin' Down)"" had a more bare, stripped-down sound, with no orchestration or symphonic arrangements. This drift from the original disco sound is called post-disco. In this music scene there are rooted subgenres, such as Italo disco, techno, house, dance-pop, boogie, and early alternative dance. During the early 1980s, dance music dropped the complicated song structure and orchestration that typified the disco sound.

During the 1970s, many TV theme songs were produced (or older themes updated) with disco influenced music. Examples include "S.W.A.T." (1975), "Wonder Woman" (1975), "Charlie's Angels" (1976), "NBC Saturday Night At The Movies" (1976), "The Love Boat" (1977), "The Donahue Show" (1977), "CHiPs" (1977), "The Professionals" (1977), "Dallas" (1978), NBC Sports broadcasts (1978), "Kojak" (1977), "The Hollywood Squares" (1979). The British science fiction program "" (1975) also featured a soundtrack strongly influenced by disco, especially in the show's second season.

The rising popularity of disco came in tandem with developments in the role of the DJ. DJing developed from the use of multiple record turntables and DJ mixers to create a continuous, seamless mix of songs, with one song transitioning to another with no break in the music to interrupt the dancing. The resulting DJ mix differed from previous forms of dance music in the 1960s, which were oriented towards live performances by musicians. This in turn affected the arrangement of dance music, since songs in the disco era typically contained beginnings and endings marked by a simple beat or riff that could be easily used to transition to a new song. The development of DJing was also influenced by new turntablism techniques, such as beatmatching, a process facilitated by the introduction of new turntable technologies such as the Technics SL-1200 MK 2, first sold in 1978, which had a precise variable pitch control and a direct drive motor. DJs were often avid record collectors, who would hunt through used record stores for obscure soul records and vintage funk recordings. DJs helped to introduce rare records and new artists to club audiences.

In the 1970s, individual DJs became more prominent, and some DJs, such as Larry Levan, the resident at Paradise Garage, Jim Burgess, Tee Scott and Francis Grasso became famous in the disco scene. Levan, for example, developed a cult following among club-goers, who referred to his DJ sets as "Saturday Mass". Some DJs would use reel to reel tape recorders to make remixes and tape edits of songs. Some DJs who were making remixes made the transition from the DJ booth to becoming a record producer, notably Burgess. Scott developed several innovations. He was the first disco DJ to use three turntables as sound sources, the first to simultaneously play two beat matched records, the first user of electronic effects units in his mixes and an innovator in mixing dialogue in from well-known movies into his mixes, typically over a percussion break. These mixing techniques were also applied to radio DJs, such as Ted Currier of WKTU and WBLS. Grasso is particularly notable for taking the DJ “profession out of servitude and [making] the DJ the musical head chef”. Once he entered the scene, the DJ was no longer responsible for waiting on the crowd hand and foot, meeting their every song request. Instead, with increased agency and visibility, the DJ was now able to use his own technical and creative skills to whip up a nightly special of innovative mixes, refining his personal sound and aesthetic, and building his own reputation. Known as the first DJ to create a take his audience on a narrative, musical journey, Grasso discovered that music could effectively shift the energy of the crowd, and even more, that he had all this power at his fingertips.

About five years after the disco era came to a close in the late 1970s, rave culture began to emerge from the acid house scene. Rave culture incorporated disco culture's same love of dance music played by DJs over powerful sound systems, recreational drug and club drug exploration, sexual promiscuity, and hedonism. Although disco culture started out underground, it eventually thrived in the mainstream by the late 1970s, and major labels commodified and packaged the music for mass consumption. In contrast, the rave culture started out underground and stayed underground. In part this was to avoid the animosity that was still surrounding disco and dance music. The rave scene also stayed underground to avoid law enforcement attention that was directed at the rave culture due to its use of secret, unauthorized warehouses for some dance events and its association with illegal club drugs like Ecstasy.

The disco sound had a strong influence on early hip hop. Most of the early hip hop songs were created by isolating existing disco bass-guitar lines and dubbing over them with MC rhymes. The Sugarhill Gang used Chic's "Good Times" as the foundation for their 1979 song "Rapper's Delight", generally considered to be the song that first popularized rap music in the United States and around the world. In 1982, Afrika Bambaataa released the single "Planet Rock", which incorporated electronica elements from Kraftwerk's "Trans-Europe Express" and "Numbers" as well as YMO's "Riot in Lagos".

The Planet Rock sound also spawned a hip hop electronic dance trend, electro music, which included songs such as Planet Patrol's "Play at Your Own Risk" (1982), C Bank's "One More Shot" (1982), Cerrone's "Club Underworld" (1984), Shannon's "Let the Music Play" (1983), Freeez's "I.O.U." (1983), Midnight Star's "Freak-a-Zoid" (1983), Chaka Khan's "I Feel For You" (1984).

House music is a genre of electronic dance music that originated in Chicago in the early 1980s. It was initially popularized in Chicago, circa 1984. House music quickly spread to other American cities such as Detroit, New York City, and Newark – all of which developed their own regional scenes. In the mid- to late 1980s, house music became popular in Europe as well as major cities in South America, and Australia. Early house music commercial success in Europe saw songs such as "Pump Up The Volume" by MARRS (1987), "House Nation" by House Master Boyz and the Rude Boy of House (1987), "Theme from S'Express" by S'Express (1988) and "Doctorin' the House" by Coldcut (1988) in the pop charts. Since the early to mid-1990s, house music has been infused in mainstream pop and dance music worldwide.

Early house music was generally dance-based music characterized by repetitive four on the floor beats, rhythms mainly provided by drum machines, off-beat hi-hat cymbals, and synthesized basslines. While house displayed several characteristics similar to disco music, it was more electronic and minimalist, and the repetitive rhythm of house was more important than the song itself. As well, house did not use the lush string sections that were a key part of the disco sound. House music in the 2010s, while keeping several of these core elements, notably the prominent kick drum on every beat, varies widely in style and influence, ranging from the soulful and atmospheric deep house to the more minimalist microhouse. House music has also fused with several other genres creating fusion subgenres, such as euro house, tech house, electro house and jump house.

The post-punk movement that originated in the late 1970s both supported punk rock's rule breaking while rejecting its move back to raw rock music. Post-punk's mantra of constantly moving forward lent itself to both openness to and experimentation with elements of disco and other styles. Public Image Limited is considered the first post-punk group. The group's second album "Metal Box" fully embraced the "studio as instrument" methodology of disco. The group's founder John Lydon, the former lead singer for the Sex Pistols, told the press that disco was the only music he cared for at the time.

No wave was a subgenre of post-punk centered in New York City. For shock value, James Chance, a notable member of the no wave scene, penned an article in the "East Village Eye" urging his readers to move uptown and get "trancin' with some superadioactive disco voodoo funk". His band James White and the Blacks wrote a disco album titled "Off White". Their performances resembled those of disco performers (horn section, dancers and so on). In 1981 ZE Records led the transition from no wave into the more subtle mutant disco (post-disco/punk) genre. Mutant disco acts such as Kid Creole and the Coconuts, Was Not Was, ESG and Liquid Liquid influenced several British post-punk acts such as New Order, Orange Juice and A Certain Ratio.

In the early 2000s the dance-punk (new rave in the United Kingdom) emerged as a part of a broader post punk revival. It fused elements of punk-related rock with different forms of dance music including disco. Klaxons, LCD Soundsystem, Death From Above 1979, the Rapture and Shitdisco were among acts associated with the genre.

Nu-disco is a 21st-century dance music genre associated with the renewed interest in 1970s and early 1980s disco, mid-1980s Italo disco, and the synthesizer-heavy Euro disco aesthetics. The moniker appeared in print as early as 2002, and by mid-2008 was used by record shops such as the online retailers Juno and Beatport. These vendors often associate it with re-edits of original-era disco music, as well as with music from European producers who make dance music inspired by original-era American disco, electro and other genres popular in the late 1970s and early 1980s. It is also used to describe the music on several American labels that were previously associated with the genres electroclash and French house.




</doc>
<doc id="7970" url="https://en.wikipedia.org/wiki?curid=7970" title="Darwin">
Darwin

Darwin most often refers to:


Darwin may also refer to:












</doc>
<doc id="7973" url="https://en.wikipedia.org/wiki?curid=7973" title="Donegal fiddle tradition">
Donegal fiddle tradition

The Donegal fiddle tradition is the way of playing the fiddle that is traditional in County Donegal, Ireland. It is one of the distinct fiddle traditions within Irish traditional music.

The distinctness of the Donegal tradition developed due to the close relations between Donegal and Scotland, and the Donegal repertoire and style has influences from Scottish fiddle music. For example, in addition to the standard tune types such as Jigs and Reels, the Donegal tradition also has Highlands (influenced by the Scottish Strathspey). The distinctiveness of the Donegal tradition led to some conflict between Donegal players and representatives of the mainstream tradition when Irish traditional music was organised in the 1960s.

The tradition has several distinguishing traits compared to other fiddle traditions such as the Sliabh Luachra style of southern ireland, most of which involves styles of bowing and the ornamentation of the music, and rhythm. Due to the frequency of double stops and the strong bowing it is often compared to the Cape Breton tradition. Another characteristic of the style is the rapid pace at which it tends to proceed. Modern players, such as the fiddle group Altan, continue to be popular due to a variety of reasons.

Among the most famous Donegal style players are John Doherty from the early twentieth century and James Byrne, Paddy Glackin, Tommy Peoples and Mairéad Ní Mhaonaigh in recent decades.

The fiddle has ancient roots in Ireland, the first report of bowed instruments similar to the violin being in the Book of Leinster (ca. 1160). The modern violin was ubiquitous in Ireland by the early 1700s. However the first mention of the fiddle being in use in Donegal is from the blind harper Arthur O'Neill who in his 1760 memoirs described a wedding in Ardara as having "plenty of pipers and fiddlers". Donegal fiddlers participated in the development of the Irish music tradition in the 18th century during which jigs and slipjigs and later reels and hornpipes became the dominant musical forms. However, Donegal musicians, many of them being fishermen, also frequently travelled to Scotland, where they acquired tune types from the Scottish repertoire such as the Strathspey which was integrated into the Donegal tradition as "Highland" tunes. The Donegal tradition derives much of its unique character from the synthesis of Irish and Scottish stylistic features and repertoires. Aoidh notes however that while different types of art music were commonly played among the upper classes of Scottish society in the 18th century, the Donegal tradition drew exclusively from the popular types of Scottish music. Like some Scottish fiddlers (who, like Donegal fiddlers, tend to use a short bow and play in a straight-ahead fashion), some Donegal fiddlers worked at imitating the sound of the bagpipes. Workers from Donegal would bring their music to Scotland and also bring back Scottish tunes with them such music of J. Scott Skinner and Mackenzie Murdoch. Lilting, unaccompanied singing of wordless tunes, was also an important part of the Donegal musical tradition often performed by women in social settings. Describing the musical life of Arranmore Island in the late 19th century singer Róise Rua Nic Gríanna describes the most popular dances: "The Sets, the Lancers, the Maggie Pickie [i.e., Maggie Pickins] the Donkey, the Mazurka and the Barn dances". Among the travelling fiddlers of the late 19th century players such as John Mhosaí McGinley, Anthony Hilferty, the McConnells and the Dohertys are best known. As skill levels increased through apprenticeships several fiddle masters appeared such as the Cassidy's, Connie Haughey, Jimmy Lyons and Miock McShane of Teelin and Francie Dearg and Mickey Bán Byrne of Kilcar. These virtuosos played unaccompanied listening pieces in addition to the more common dance music.

The influences between Scotland and Donegal went both ways and were furthered by a wave of immigration from Donegal to Scotland in the 19th century (the regions share common names of dances), as can be heard in the volume of strathspeys, schottisches, marches, and Donegal's own strong piping tradition, has influenced and been influenced by music, and by the sounds, ornaments, and repertoire of the Píob Mhór, the traditional bagpipes of Ireland and Scotland. There are other differences between the Donegal style and the rest of Ireland. Instruments such as the tin whistle, flute, concertina and accordion were very rare in Donegal until modern times. Traditionally the píob mór and the fiddle were the only instruments used and the use of pipe or fiddle music was common in old wedding customs. Migrant workers carried their music to Scotland and also brought back a number of tunes of Scottish origin. The Donegal fiddlers may well have been the route by which Scottish tunes such as Lucy Campbell, Tarbolton Lodge (Tarbolton) and The Flagon (The Flogging Reel), that entered the Irish repertoire. These players prided themselves on their technical abilities, which included playing in higher positions (fairly uncommon among traditional Irish fiddlers), and sought out material which would demonstrate their skills.

As Irish music was consolidated and organised under the Comhaltas Ceoltóirí Éireann movement in the 1960s, both strengthened the interest in traditional music but sometimes conflicted with the Donegal tradition and its social conventions. The rigidly organised sessions of the Comhaltas reflected the traditions of Southern Ireland and Donegal fiddlers like John Doherty considered the National repertoire with its strong focus on reels to be less diverse than that of Donegal with its varied rhythms. Other old fiddlers dislike the ways comhaltas sessions were organised with a committee player, often not himself a musician, in charge. Sometimes Comhaltas representatives would even disparage the Donegal tradition, with its Scottish flavour, as being un-Irish, and prohibit them from playing local tunes with Scottish genealogies such as the "Highlands" at Comhaltas sessions. This sometimes cause antagonism between Donegal players and the main organisation of traditional music in ireland.

Outside of the Comhaltas movement however, Donegal fiddling stood strong with Paddy Glackin of Ceoltorí Laighean and the Bothy Band and later Tommy Peoples also with the Bothy Band and Mairead Ni Mhaonaigh with Altan, who all drew attention and prestige to the Donegal tradition within folk music circles throughout Ireland.

The Donegal style of fiddling is a label often applied to music from this area, though one also might plausibly identify several different, but related, styles within the county. To the extent to which there is one common style in the county, it is characterised by a rapid pace; a tendency to be more un-swung in the playing of the fast dance tune types (reel and jigs); short (non-slurred), aggressive bowing, sparse ornamentation, the use of bowed triplets more often than trills as ornaments, the use of double stops and droning; and the occurrence of "playing the octave", with one player playing the melody and the other playing the melody an octave lower. None of these characteristics are universal, and there is some disagreement as to the extent to which there is a common style at all. In general, however, the style is rather aggressive.

Another feature of Donegal fiddling that makes it distinctive among Irish musical traditions is the variety of rare tune types that are played. Highlands, a type of tune in time with some similarities to Scottish strathspeys, which are also played in Donegal, are one of the most commonly played types of tune in the county. Other tune types common solely in the county include barndances, also called "Germans," and mazurkas.

There are a number of different strands to the history of fiddle playing in County Donegal. Perhaps the best-known and, in the last half of the twentieth century, the most influential has been that of the Doherty family. Hugh Doherty is the first known musician of this family. Born in 1790, he headed an unbroken tradition of fiddlers and pipers in the Doherty family until the death, in 1980, of perhaps the best-known Donegal fiddler, John Doherty. John, a travelling tinsmith, was known for his extremely precise and fast finger- and bow-work and vast repertoire, and is considered to be one of the greatest Irish fiddlers ever recorded. John's older brother, Mickey, was also recorded and, though Mickey was another of the great Irish fiddlers, his reputation has been overshadowed by John's.

There is no single Donegal style but several distinctive styles. These styles traditionally come from the geographical isolated regions of Donegal including Inishowen, eastern Donegal, The Rosses and Gweedore, Croaghs, Teelin, Kilcar, Glencolmcille, Ballyshannon and Bundoran. Even with improved communications and transport, these regions still have recognisably different ways of fiddle playing. Notable deceased players of the older Donegal styles include Neillidh ("Neilly") Boyle, Francie Byrne, Con Cassidy,Frank Cassidy, James Byrne (1946–2008), P.V. O'Donnell (2011), and Tommy Peoples (1948–2018). Currently living Donegal fiddlers, include, Vincent Campbell, John Gallagher, Paddy Glackin, and Danny O'Donnell.

Fiddle playing continues to be popular in Donegal. The three fiddlers of the Donegal "supergroup" Altan, Mairéad Ní Mhaonaigh, Paul O'Shaughnessy, and Ciarán Tourish, are generally admired within Donegal. An example of another fiddler-player from Donegal is Liz Doherty.
Another well regarded fiddle player hailing from Donegal is Aidan O'Donnell. TG4 Young Musician of the Year 2010 Aidan O'Donnell has been described as one of the finest young Irish musicians at present. He began his music making at the age of 12, and since then has performed with some of traditional music's finest artists, including Donal Lunny, Micheal Ó'Suilleabháin and the Chieftains. In 2007, he won the prestigious ‘Oireachtas na Geailge' fiddle title, and has been a regular tutor at the Irish World Academy of Music and Dance, at the University of Limerick for the past number of years.

The fiddle, and traditional music in general, remained popular in Donegal not only because of the international coverage of certain artists but because of local pride in the music. Traditional music "Seisiúns" are still common place both in pubs and in houses. The Donegal fiddle music has been influenced by recorded music, but this is claimed to have had a positive impact on the tradition. Modern Donegal fiddle music is often played in concerts and recorded on albums.



</doc>
<doc id="7975" url="https://en.wikipedia.org/wiki?curid=7975" title="Double-barreled shotgun">
Double-barreled shotgun

A double-barreled shotgun is a shotgun with two parallel barrels, allowing two shots to be fired in quick succession.

Modern double-barreled shotguns, often known as "doubles", are almost universally break open actions, with the barrels tilting up at the rear to expose the breech ends of the barrels for unloading and reloading. Since there is no reciprocating action needed to eject and reload the shells, doubles are more compact than repeating designs such as pump action or lever-action shotguns.

Double-barreled shotguns come in two basic configurations: the side-by-side shotgun (SxS) and the over/under shotgun ("over and under", O/U, etc.), indicating the arrangement of barrels. The original double-barreled guns were nearly all SxS designs, which was a more practical design of muzzle-loading firearms. Early cartridge shotguns also used the SxS action, because they kept the exposed hammers of the earlier muzzle-loading shotguns from which they evolved. When hammerless designs started to become common, the O/U design was introduced, and most modern sporting doubles are O/U designs.

One significant advantage that doubles have over single barrel repeating shotguns is the ability to provide access to more than one choke at a time. Some shotgun sports, such as skeet, use crossing targets presented in a narrow range of distance, and only require one level of choke. Others, like sporting clays, give the shooter targets at differing ranges, and targets that might approach or recede from the shooter, and so must be engaged at differing ranges. Having two barrels lets the shooter use a more open choke for near targets, and a tighter choke for distant targets, providing the optimal shot pattern for each distance.

Their disadvantage lies in the fact that the barrels of a double-barreled shotgun, whether "O/U" or "SxS", are not parallel, but slightly angled, so that shots from the barrels converge, usually at "40 yards out". For the "SxS" configuration, the shotstring continues on its path to the opposite side of the rib after the converging point; for example, the left barrel's discharge travels on the left of the rib till it hits dead center at 40 yards out, after that, the discharge continues on to the right. In the "O/U" configuration with a parallel rib, both barrels' discharges will keep to the dead center, but the discharge from the "under" barrel will shoot higher than the discharge from the "over" barrel after 40 yards. Thus, double-barreled shotguns are accurate only at practical shotgun ranges, though the range of their ammunition easily exceeds four to six times that distance.

"SxS" shotguns are often more expensive, and may take more practice to aim effectively than a "O/U". The off-center nature of the recoil in a "SxS" gun may make shooting the body-side barrel slightly more painful by comparison to an "O/U", single-shot, or pump/lever action shotgun. Gas-operated, and to a lesser extent recoil-operated, designs will recoil less than either. More "SxS" than "O/U" guns have traditional 'cast-off' stocks, where the end of the buttstock veers slightly to the right, allowing a right-handed user to point the gun more easily.

Double shotguns are also inherently more safe, as whether the shotgun is loaded or can be fired can be ascertained by anyone present if the action is broken open, for instance on a skeet, trap or hunting clays course when another shooter is firing; if the action is open, the gun cannot fire. Similarly, doubles are more easily examined to see if loaded than pump or semi-automatic shotguns, whose bolt must be opened and chamber closely examined or felt to make sure it is unloaded; with a double gun (or a break-action single gun), whether the gun is loaded, i.e., has cartridges in any chamber, is easily and immediately seen with a glance (and just as easily unloaded).

The early doubles used two triggers, one for each barrel. These were located front to back inside the trigger guard, the index finger being used to pull either trigger, as having two fingers inside the trigger guard can cause a very undesirable recoil induced double-discharge. Double trigger designs are typically set up for right-handed users. In double trigger designs, it is often possible to pull both triggers at once, firing both barrels simultaneously, though this is generally not recommended as it doubles the recoil, battering both shotgun and shooter, particularly if it was unanticipated or unintended. Discharging both barrels at the same time has long been a hunting trick employed by hunters using 8 gauge "elephant" shotguns, firing the two two-ounce slugs for sheer stopping power at close range.

Later models use a single trigger that alternately fires both barrels, called a "single selective trigger" or "SST". The SST does not allow firing both barrels at once, since the single trigger must be pulled twice in order to fire both barrels. The change from one barrel to the other may be done by a clockwork type system, where a cam alternates between barrels, or by an inertial system where the recoil of firing the first barrel toggles the trigger to the next barrel. A double-barreled shotgun with an inertial trigger works best with full power shotshells; shooting low recoil shotshells often will not reliably toggle the inertial trigger, causing an apparent failure to fire occasionally when attempting to depress the trigger a second time to fire the second barrel (this also can happen if the first shell fails to fire). Generally there is a method of selecting the order in which the barrels of an SST shotgun fire; commonly this is done through manipulation of the safety, pushing to one side to select top barrel first and the other side to select bottom barrel first. In the event that an inertial trigger does not toggle to the second barrel when firing low recoil shotshells, manually selecting the order to the second barrel will enable the second barrel to fire when the trigger is depressed again.

One of the advantages of the double, with double triggers or SST, is that a second shot can be taken almost immediately after the first, without removing the gun from the firing position on the shoulder and without any other action than a second trigger pull, utilizing different chokes for the two shots. (Assuming, of course, that full power shotshells are fired, at least for a double-barreled shotgun with an inertial type SST, as needed to toggle the inertial trigger.) This can be noticeably faster than a pump shotgun, which requires pumping to eject and reload for the second shot, and may be faster, or not slower, than a semi-automatic action. Note, however, in neither the pump or semi-automatic will the second shot be a different choke pattern from the first shot, whereas for a double, the two shots are usually with different chokes. Thus, depending on the nature of the hunt, the appropriate choke for the shot is always at hand. For example, while field hunting flushing birds, the first shot is usually closer than the second because the bird flies away from the shooter; so, the more open choke (and barrel) would be better for the first shot, and if a second shot is needed, as the bird is flying away, the more closed (and thus longer distance of an effective shot pattern) choke (and barrel) is then appropriate. Conversely, on a driven hunt, where the birds are driven towards the shooter, the closed (longer effective distance) choke (and barrel) should be fired first, saving the open (closer effective distance) choke (and barrel) for the now-closer incoming bird. None of this is possible with single-barrel shotguns, only with a double, whether SxS or O/U.

"Regulation" is a term used for multi-barreled firearms that indicates how close to the same point of aim the barrels will shoot. Regulation is very important, because a poorly regulated gun may hit consistently with one barrel, but miss consistently with the other, making the gun nearly useless for anything requiring two shots. However, the short ranges and spread of shot provide a significant overlap, so a small error in regulation in a double is often too small to be noticed. Generally the shotguns are regulated to hit the point of aim at a given distance, usually the maximum expected range since that is the range at which a full choke is used, and where precise regulation matters most.

The double-barreled shotgun is seen as a weapon of prestige and authority in rural parts of India, where it is known as "Dunali" (literally "two pipes"). It is especially common in Bihar(munger), Purvanchal, Uttar Pradesh, Haryana and Punjab.



</doc>
<doc id="7976" url="https://en.wikipedia.org/wiki?curid=7976" title="Dessert">
Dessert

Dessert () is a course that concludes a meal. The course usually consists of sweet foods, such as confections dishes or fruit, and possibly a beverage such as dessert wine or liqueur, however in the United States it may include coffee, cheeses, nuts, or other savory items regarded as a separate course elsewhere. In some parts of the world, such as much of central and western Africa, and most parts of China, there is no tradition of a dessert course to conclude a meal.

The term "dessert" can apply to many confections, such as biscuits, cakes, cookies, custards, gelatins, ice creams, pastries, pies, puddings, and sweet soups, and tarts. Fruit is also commonly found in dessert courses because of its naturally occurring sweetness. Some cultures sweeten foods that are more commonly savory to create desserts.

The word "dessert" originated from the French word "desservir," meaning "to clear the table." Its first known use was in 1600, in a health education manual entitled "Naturall and artificial Directions for Health", written by William Vaughan. In his "A History of Dessert" (2013), Michael Krondl explains it refers to the fact dessert was served after the table had been cleared of other dishes. The term dates from the 14th century but attained its current meaning around the beginning of the 20th century when "service à la française" (setting a variety of dishes on the table at the same time) was replaced with "service à la russe" (presenting a meal in courses.)"

The word "dessert" is most commonly used for this course in Australia, Canada, Ireland, New Zealand, and the United States, while "pudding", "sweet", or more colloquially, "afters" are also used in the United Kingdom and some other Commonwealth countries, including Hong Kong and India.

Sweets were fed to the gods in ancient Mesopotamia and ancient India and other ancient civilizations. Dried fruit and honey were probably the first sweeteners used in most of the world, but the spread of sugarcane around the world was essential to the development of dessert.

Sugarcane was grown and refined in India before 500 BC and was crystallized, making it easy to transport, by 500 AD. Sugar and sugarcane were traded, making sugar available to Macedonia by 300 BC and China by 600 AD. In the Indian subcontinent, the Middle East, and China, sugar has been a staple of cooking and desserts for over a thousand years. Sugarcane and sugar were little known and rare in Europe until the twelfth century or later, when the Crusades and then colonization spread its use.

Herodotus mentions that, as opposed to the Greeks, the main Persian meal was simple, but they would eat many desserts afterwards.

Europeans began to manufacture sugar in the Middle Ages, and more sweet desserts became available. Even then sugar was so expensive usually only the wealthy could indulge on special occasions. The first apple pie recipe was published in 1381. The earliest documentation of the term "cupcake" was in "Seventy-five Receipts for Pastry, Cakes, and Sweetmeats" in 1828 in Eliza Leslie's "Receipts" cookbook.

The Industrial Revolution in Europe and later America caused desserts (and food in general) to be mass-produced, processed, preserved, canned, and packaged. Frozen foods, including desserts, became very popular starting in the 1920s when freezing emerged. These processed foods became a large part of diets in many industrialized nations. Many countries have desserts and foods distinctive to their nations or region.

Sweet desserts usually contain cane sugar, palm sugar, honey or some types of syrup such as molasses, maple syrup, treacle, or corn syrup. Other common ingredients in Western-style desserts are flour or other starches, Cooking fats such as butter or lard, dairy, eggs, salt, acidic ingredients such as lemon juice, and spices and other flavoring agents such as chocolate, peanut butter, fruits, and nuts. The proportions of these ingredients, along with the preparation methods, play a major part in the consistency, texture, and flavor of the end product.

Sugars contribute moisture and tenderness to baked goods. Flour or starch components serves as a protein and gives the dessert structure. Fats contribute moisture and can enable the development of flaky layers in pastries and pie crusts. The dairy products in baked goods keep the desserts moist. Many desserts also contain eggs, in order to form custard or to aid in the rising and thickening of a cake-like substance. Egg yolks specifically contribute to the richness of desserts. Egg whites can act as a leavening agent or provide structure. Further innovation in the healthy eating movement has led to more information being available about vegan and gluten-free substitutes for the standard ingredients, as well as replacements for refined sugar.

Desserts can contain many spices and extracts to add a variety of flavors. Salt and acids are added to desserts to balance sweet flavors and create a contrast in flavors. Some desserts are coffee-flavored, for example an iced coffee soufflé or coffee biscuits. Alcohol can also be used as an ingredient, to make alcoholic desserts.

Dessert consist of variations of flavors, textures, and appearances. Desserts can be defined as a usually sweeter course that concludes a meal. This definition includes a range of courses ranging from fruits or dried nuts to multi-ingredient cakes and pies. Many cultures have different variations of dessert. In modern times the variations of desserts have usually been passed down or come from geographical regions. This is one cause for the variation of desserts. These are some major categories in which desserts can be placed.

Biscuits, (from the Old French word "bescuit" originally meaning "twice-baked" in Latin, also known as "cookies" in North America, are flattish bite-sized or larger short pastries generally intended to be eaten out of the hand. Biscuits can have a texture that is crispy, chewy, or soft. Examples include layered bars, crispy meringues, and soft chocolate chip cookies.

Cakes are sweet tender breads made with sugar and delicate flour. Cakes can vary from light, airy sponge cakes to dense cakes with less flour. Common flavorings include dried, candied or fresh fruit, nuts, cocoa or extracts. They may be filled with fruit preserves or dessert sauces (like pastry cream), iced with buttercream or other icings, and decorated with marzipan, piped borders, or candied fruit. Cake is often served as a celebratory dish on ceremonial occasions, for example weddings, anniversaries, and birthdays. Small-sized cakes have become popular, in the form of cupcakes and petits fours.

Chocolate is a typically sweet, usually brown, food preparation of "Theobroma cacao" seeds, roasted, ground, and often flavored. Pure, unsweetened chocolate contains primarily cocoa solids and cocoa butter in varying proportions. Much of the chocolate currently consumed is in the form of sweet chocolate, combining chocolate with sugar. Milk chocolate is sweet chocolate that additionally contains milk powder or condensed milk. White chocolate contains cocoa butter, sugar, and milk, but no cocoa solids. Dark chocolate is produced by adding fat and sugar to the cacao mixture, with no milk or much less than milk chocolate.
Candy, also called sweets or lollies, is a confection that features sugar as a principal ingredient. Many candies involve the crystallization of sugar which varies the texture of sugar crystals. Candies comprise many forms including caramel, marshmallows, and taffy.

These kinds of desserts usually include a thickened dairy base. Custards are cooked and thickened with eggs. Baked custards include crème brûlée and flan. Puddings are thickened with starches such as corn starch or tapioca. Custards and puddings are often used as ingredients in other desserts, for instance as a filling for pastries or pies.

Many cuisines include a dessert made of deep-fried starch-based batter or dough. In many countries, a doughnut is a flour-based batter that has been deep-fried. It is sometimes filled with custard or jelly. Fritters are fruit pieces in a thick batter that have been deep fried. Gulab jamun is an Indian dessert made of milk solids kneaded into a dough, deep-fried, and soaked in honey. Churros are a deep-fried and sugared dough that is eaten as dessert or a snack in many countries. Doughnuts are most famous for being a trademark favorite of fictional character Homer Simpson from the animated television series "The Simpsons".

Ice cream, gelato, sorbet and shaved-ice desserts fit into this category. Ice cream is a cream base that is churned as it is frozen to create a creamy consistency. Gelato uses a milk base and has less air whipped in than ice cream, making it denser. Sorbet is made from churned fruit and is not dairy based. Shaved-ice desserts are made by shaving a block of ice and adding flavored syrup or juice to the ice shavings.

Jellied desserts are made with a sweetened liquid thickened with gelatin or another thickening agent. They are traditional in many cultures. Grass jelly and annin tofu are Chinese jellied desserts. Yōkan is a Japanese jellied dessert. In English-speaking countries, many dessert recipes are based on gelatin with fruit or whipped cream added.

 Pastries are sweet baked pastry products. Pastries can either take the form of light and flaky bread with an airy texture, such as a croissant or unleavened dough with a high fat content and crispy texture, such as shortbread. Pastries are often flavored or filled with fruits, chocolate, nuts, and spices. Pastries are sometimes eaten with tea or coffee as a breakfast food.

Pies and cobblers are a crust with a filling. The crust can be either made from either a pastry or crumbs. Pie fillings range from fruits to puddings; cobbler fillings are generally fruit-based. Clafoutis are a batter with fruit-based filling poured over the top before baking.

Tong sui, literally translated as "sugar water" and also known as tim tong, is a collective term for any sweet, warm soup or custard served as a dessert at the end of a meal in Cantonese cuisine. "Tong sui" are a Cantonese specialty and are rarely found in other regional cuisines of China. Outside of Cantonese-speaking communities, soupy desserts generally are not recognized as a distinct category, and the term "tong sui" is not used.

Dessert wines are sweet wines typically served with dessert. There is no simple definition of a dessert wine. In the UK, a dessert wine is considered to be any sweet wine drunk with a meal, as opposed to the white fortified wines (fino and amontillado sherry) drunk before the meal, and the red fortified wines (port and madeira) drunk after it. Thus, most fortified wines are regarded as distinct from dessert wines, but some of the less strong fortified white wines, such as Pedro Ximénez sherry and Muscat de Beaumes-de-Venise, are regarded as honorary dessert wines. In the United States, by contrast, a dessert wine is legally defined as any wine over 14% alcohol by volume, which includes all fortified wines - and is taxed at higher rates as a result. Examples include Sauternes and Tokaji Aszú.

Throughout much of central and western Africa, there is no tradition of a dessert course following a meal. Fruit or fruit salad would be eaten instead, which may be spiced, or sweetened with a sauce. In some former colonies in the region, the colonial power has influenced desserts – for example, the Angolan "cocada amarela" (yellow coconut) resembles baked desserts in Portugal.

In Asia, desserts are often eaten between meals as snacks rather than as a concluding course. There is widespread use of rice flour in East Asian desserts, which often include local ingredients such as coconut milk, palm sugar, and tropical fruit. In India, where sugarcane has been grown and refined since before 500 BCE, desserts have been an important part of the diet for thousands of years; types of desserts include burfis, halvahs, jalebis, and laddus.

Dessert nowadays are made into drinks as well, such as Bubble Tea. It is originated in Taiwan, which locates in East Asia. Bubble tea is a kind of dessert made with flavor tea or milk with tapioca. It is well-known across the world.

In Ukraine and Russia, breakfast foods such as nalysnyky or blintz or oladi (pancake), and syrniki are served with honey and jam as desserts.

European colonization of the Americas yielded the introduction of a number of ingredients and cooking styles. The various styles continued expanding well into the 19th and 20th centuries, proportional to the influx of immigrants.

Dulce de leche is a very common confection in Argentina. In Bolivia, sugarcane, honey and coconut are traditionally used in desserts. "Tawa tawa" is a Bolivian sweet fritter prepared using sugar cane, and "helado de canela" is a dessert that is similar to sherbet which is prepared with cane sugar and cinnamon. Coconut tarts, puddings cookies and candies are also consumed in Bolivia. Brazil has a variety of candies such as brigadeiros (chocolate fudge balls), cocada (a coconut sweet), beijinhos (coconut truffles and clove) and romeu e julieta (cheese with a guava jam known as goiabada). Peanuts are used to make paçoca, rapadura and pé-de-moleque. Local common fruits are turned in juices and used to make chocolates, ice pops and ice cream. In Chile, "kuchen" has been described as a "trademark dessert." Several desserts in Chile are prepared with "manjar", (caramelized milk), including "alfajor", "flan", "cuchufli" and "arroz con leche". Desserts consumed in Colombia include dulce de leche, waffle cookies, puddings, nougat, coconut with syrup and thickened milk with sugarcane syrup. Desserts in Ecuador tend to be simple, and desserts are a moderate part of the cuisine. Desserts consumed in Ecuador include tres leches cake, flan, candies and various sweets.

Desserts are typically eaten in Australia, and most daily meals "end with simple desserts," which can include various fruits. More complex desserts include cakes, pies and cookies, which are sometimes served during special occasions.

The market for desserts has grown over the last few decades, which was greatly increased by the commercialism of baking desserts and the rise of food productions. Desserts are present in most restaurants as the popularity has increased. Many commercial stores have been established as solely desserts stores. Ice cream parlors have been around since before 1800. Many businesses started advertising campaigns focusing solely on desserts. The tactics used to market desserts are very different depending on the audience for example desserts can be advertised with popular movie characters to target children. The rise of companies like Food Network has marketed many shows which feature dessert and their creation. Shows like these have displayed extreme desserts and made a game show atmosphere which made desserts a more competitive field.

Desserts are a standard staple in restaurant menus, with different degrees of variety. Pie and cheesecake were among the most popular dessert courses ordered in U.S. restaurants in 2012.

Dessert foods often contain relatively high amounts of sugar and fats and, as a result, higher calorie counts per gram than other foods. Fresh or cooked fruit with minimal added sugar or fat is an exception.




</doc>
<doc id="7978" url="https://en.wikipedia.org/wiki?curid=7978" title="Data Encryption Standard">
Data Encryption Standard

The Data Encryption Standard (DES ) is a symmetric-key algorithm for the encryption of electronic data. Although its short key length of 56 bits, criticized from the beginning, makes it too insecure for most current applications, it was highly influential in the advancement of modern cryptography.

Developed in the early 1970s at IBM and based on an earlier design by Horst Feistel, the algorithm was submitted to the National Bureau of Standards (NBS) following the agency's invitation to propose a candidate for the protection of sensitive, unclassified electronic government data. In 1976, after consultation with the National Security Agency (NSA), the NBS eventually selected a slightly modified version (strengthened against differential cryptanalysis, but weakened against brute-force attacks), which was published as an official Federal Information Processing Standard (FIPS) for the United States in 1977.

The publication of an NSA-approved encryption standard simultaneously resulted in its quick international adoption and widespread academic scrutiny. Controversies arose out of classified design elements, a relatively short key length of the symmetric-key block cipher design, and the involvement of the NSA, nourishing suspicions about a backdoor. Today it is known that the S-boxes that had raised those suspicions were in fact designed by the NSA to actually remove a backdoor they secretly knew (differential cryptanalysis). However, the NSA also ensured that the key size was drastically reduced such that they could break it by brute force attack. The intense academic scrutiny the algorithm received over time led to the modern understanding of block ciphers and their cryptanalysis.

DES, as stated above, is insecure. This is mainly due to the 56-bit key size being too small. In January 1999, distributed.net and the Electronic Frontier Foundation collaborated to publicly break a DES key in 22 hours and 15 minutes (see chronology). There are also some analytical results which demonstrate theoretical weaknesses in the cipher, although they are infeasible to mount in practice. The algorithm is believed to be practically secure in the form of Triple DES, although there are theoretical attacks. This cipher has been superseded by the Advanced Encryption Standard (AES). Furthermore, DES has been withdrawn as a standard by the National Institute of Standards and Technology.

Some documentation makes a distinction between DES as a standard and as an algorithm, referring to the algorithm as the DEA (Data Encryption Algorithm).

The origins of DES go back to the early 1970s. In 1972, after concluding a study on the US government's computer security needs, the US standards body NBS (National Bureau of Standards)—now named NIST (National Institute of Standards and Technology)—identified a need for a government-wide standard for encrypting unclassified, sensitive information. Accordingly, on 15 May 1973, after consulting with the NSA, NBS solicited proposals for a cipher that would meet rigorous design criteria. None of the submissions, however, turned out to be suitable. A second request was issued on 27 August 1974. This time, IBM submitted a candidate which was deemed acceptable—a cipher developed during the period 1973–1974 based on an earlier algorithm, Horst Feistel's Lucifer cipher. The team at IBM involved in cipher design and analysis included Feistel, Walter Tuchman, Don Coppersmith, Alan Konheim, Carl Meyer, Mike Matyas, Roy Adler, Edna Grossman, Bill Notz, Lynn Smith, and Bryant Tuckerman.

On 17 March 1975, the proposed DES was published in the "Federal Register". Public comments were requested, and in the following year two open workshops were held to discuss the proposed standard. There was some criticism from various parties, including from public-key cryptography pioneers Martin Hellman and Whitfield Diffie, citing a shortened key length and the mysterious "S-boxes" as evidence of improper interference from the NSA. The suspicion was that the algorithm had been covertly weakened by the intelligence agency so that they—but no-one else—could easily read encrypted messages. Alan Konheim (one of the designers of DES) commented, "We sent the S-boxes off to Washington. They came back and were all different." The United States Senate Select Committee on Intelligence reviewed the NSA's actions to determine whether there had been any improper involvement. In the unclassified summary of their findings, published in 1978, the Committee wrote:

However, it also found that

Another member of the DES team, Walter Tuchman, stated "We developed the DES algorithm entirely within IBM using IBMers. The NSA did not dictate a single wire!"
In contrast, a declassified NSA book on cryptologic history states:

and
Some of the suspicions about hidden weaknesses in the S-boxes were allayed in 1990, with the independent discovery and open publication by Eli Biham and Adi Shamir of differential cryptanalysis, a general method for breaking block ciphers. The S-boxes of DES were much more resistant to the attack than if they had been chosen at random, strongly suggesting that IBM knew about the technique in the 1970s. This was indeed the case; in 1994, Don Coppersmith published some of the original design criteria for the S-boxes. According to Steven Levy, IBM Watson researchers discovered differential cryptanalytic attacks in 1974 and were asked by the NSA to keep the technique secret. Coppersmith explains IBM's secrecy decision by saying, "that was because [differential cryptanalysis] can be a very powerful tool, used against many schemes, and there was concern that such information in the public domain could adversely affect national security." Levy quotes Walter Tuchman: "[t]hey asked us to stamp all our documents confidential... We actually put a number on each one and locked them up in safes, because they were considered U.S. government classified. They said do it. So I did it". Bruce Schneier observed that "It took the academic community two decades to figure out that the NSA 'tweaks' actually improved the security of DES."

Despite the criticisms, DES was approved as a federal standard in November 1976, and published on 15 January 1977 as FIPS PUB 46, authorized for use on all unclassified data. It was subsequently reaffirmed as the standard in 1983, 1988 (revised as FIPS-46-1), 1993 (FIPS-46-2), and again in 1999 (FIPS-46-3), the latter prescribing "Triple DES" (see below). On 26 May 2002, DES was finally superseded by the Advanced Encryption Standard (AES), following a public competition. On 19 May 2005, FIPS 46-3 was officially withdrawn, but NIST has approved Triple DES through the year 2030 for sensitive government information.

The algorithm is also specified in ANSI X3.92 (Today X3 is known as INCITS and ANSI X3.92 as ANSI INCITS 92), NIST SP 800-67 and ISO/IEC 18033-3 (as a component of TDEA).

Another theoretical attack, linear cryptanalysis, was published in 1994, but it was the Electronic Frontier Foundation's DES cracker in 1998 that demonstrated that DES could be attacked very practically, and highlighted the need for a replacement algorithm. These and other methods of cryptanalysis are discussed in more detail later in this article.

The introduction of DES is considered to have been a catalyst for the academic study of cryptography, particularly of methods to crack block ciphers. According to a NIST retrospective about DES,

DES is the archetypal block cipher—an algorithm that takes a fixed-length string of plaintext bits and transforms it through a series of complicated operations into another ciphertext bitstring of the same length. In the case of DES, the block size is 64 bits. DES also uses a key to customize the transformation, so that decryption can supposedly only be performed by those who know the particular key used to encrypt. The key ostensibly consists of 64 bits; however, only 56 of these are actually used by the algorithm. Eight bits are used solely for checking parity, and are thereafter discarded. Hence the effective key length is 56 bits.

The key is nominally stored or transmitted as 8 bytes, each with odd parity. According to ANSI X3.92-1981 (Now, known as ANSI INCITS 92-1981), section 3.5:

Like other block ciphers, DES by itself is not a secure means of encryption, but must instead be used in a mode of operation. FIPS-81 specifies several modes for use with DES. Further comments on the usage of DES are contained in FIPS-74.

Decryption uses the same structure as encryption, but with the keys used in reverse order. (This has the advantage that the same hardware or software can be used in both directions.)

The algorithm's overall structure is shown in Figure 1: there are 16 identical stages of processing, termed "rounds". There is also an initial and final permutation, termed "IP" and "FP", which are inverses (IP "undoes" the action of FP, and vice versa). IP and FP have no cryptographic significance, but were included in order to facilitate loading blocks in and out of mid-1970s 8-bit based hardware.

Before the main rounds, the block is divided into two 32-bit halves and processed alternately; this criss-crossing is known as the Feistel scheme. The Feistel structure ensures that decryption and encryption are very similar processes—the only difference is that the subkeys are applied in the reverse order when decrypting. The rest of the algorithm is identical. This greatly simplifies implementation, particularly in hardware, as there is no need for separate encryption and decryption algorithms.

The ⊕ symbol denotes the exclusive-OR (XOR) operation. The "F-function" scrambles half a block together with some of the key. The output from the F-function is then combined with the other half of the block, and the halves are swapped before the next round. After the final round, the halves are swapped; this is a feature of the Feistel structure which makes encryption and decryption similar processes.

The F-function, depicted in Figure 2, operates on half a block (32 bits) at a time and consists of four stages:


The alternation of substitution from the S-boxes, and permutation of bits from the P-box and E-expansion provides so-called "confusion and diffusion" respectively, a concept identified by Claude Shannon in the 1940s as a necessary condition for a secure yet practical cipher.

Figure 3 illustrates the "key schedule" for encryption—the algorithm which generates the subkeys. Initially, 56 bits of the key are selected from the initial 64 by "Permuted Choice 1" ("PC-1")—the remaining eight bits are either discarded or used as parity check bits. The 56 bits are then divided into two 28-bit halves; each half is thereafter treated separately. In successive rounds, both halves are rotated left by one or two bits (specified for each round), and then 48 subkey bits are selected by "Permuted Choice 2" ("PC-2")—24 bits from the left half, and 24 from the right. The rotations (denoted by "«<" in the diagram) mean that a different set of bits is used in each subkey; each bit is used in approximately 14 out of the 16 subkeys.

The key schedule for decryption is similar—the subkeys are in reverse order compared to encryption. Apart from that change, the process is the same as for encryption. The same 28 bits are passed to all rotation boxes.

Although more information has been published on the cryptanalysis of DES than any other block cipher, the most practical attack to date is still a brute-force approach. Various minor cryptanalytic properties are known, and three theoretical attacks are possible which, while having a theoretical complexity less than a brute-force attack, require an unrealistic number of known or chosen plaintexts to carry out, and are not a concern in practice.

For any cipher, the most basic method of attack is brute force—trying every possible key in turn. The length of the key determines the number of possible keys, and hence the feasibility of this approach. For DES, questions were raised about the adequacy of its key size early on, even before it was adopted as a standard, and it was the small key size, rather than theoretical cryptanalysis, which dictated a need for a replacement algorithm. As a result of discussions involving external consultants including the NSA, the key size was reduced from 128 bits to 56 bits to fit on a single chip.

In academia, various proposals for a DES-cracking machine were advanced. In 1977, Diffie and Hellman proposed a machine costing an estimated US$20 million which could find a DES key in a single day. By 1993, Wiener had proposed a key-search machine costing US$1 million which would find a key within 7 hours. However, none of these early proposals were ever implemented—or, at least, no implementations were publicly acknowledged. The vulnerability of DES was practically demonstrated in the late 1990s. In 1997, RSA Security sponsored a series of contests, offering a $10,000 prize to the first team that broke a message encrypted with DES for the contest. That contest was won by the DESCHALL Project, led by Rocke Verser, Matt Curtin, and Justin Dolske, using idle cycles of thousands of computers across the Internet. The feasibility of cracking DES quickly was demonstrated in 1998 when a custom DES-cracker was built by the Electronic Frontier Foundation (EFF), a cyberspace civil rights group, at the cost of approximately US$250,000 (see EFF DES cracker). Their motivation was to show that DES was breakable in practice as well as in theory: ""There are many people who will not believe a truth until they can see it with their own eyes. Showing them a physical machine that can crack DES in a few days is the only way to convince some people that they really cannot trust their security to DES."" The machine brute-forced a key in a little more than 2 days' worth of searching.

The next confirmed DES cracker was the COPACOBANA machine built in 2006 by teams of the Universities of Bochum and Kiel, both in Germany. Unlike the EFF machine, COPACOBANA consists of commercially available, reconfigurable integrated circuits. 120 of these field-programmable gate arrays (FPGAs) of type XILINX Spartan-3 1000 run in parallel. They are grouped in 20 DIMM modules, each containing 6 FPGAs. The use of reconfigurable hardware makes the machine applicable to other code breaking tasks as well. One of the more interesting aspects of COPACOBANA is its cost factor. One machine can be built for approximately $10,000. The cost decrease by roughly a factor of 25 over the EFF machine is an example of the continuous improvement of digital hardware—see Moore's law. Adjusting for inflation over 8 years yields an even higher improvement of about 30x. Since 2007, SciEngines GmbH, a spin-off company of the two project partners of COPACOBANA has enhanced and developed successors of COPACOBANA. In 2008 their COPACOBANA RIVYERA reduced the time to break DES to less than one day, using 128 Spartan-3 5000's. SciEngines RIVYERA held the record in brute-force breaking DES, having utilized 128 Spartan-3 5000 FPGAs. Their 256 Spartan-6 LX150 model has further lowered this time.

In 2012, David Hulton and Moxie Marlinspike announced a system with 48 Xilinx Virtex-6 LX240T FPGAs, each FPGA containing 40 fully pipelined DES cores running at 400 MHz, for a total capacity of 768 gigakeys/sec. The system can exhaustively search the entire 56-bit DES key space in about 26 hours and this service is offered for a fee online.

There are three attacks known that can break the full 16 rounds of DES with less complexity than a brute-force search: differential cryptanalysis (DC), linear cryptanalysis (LC), and Davies' attack. However, the attacks are theoretical and are generally considered infeasible to mount in practice; these types of attack are sometimes termed certificational weaknesses.


There have also been attacks proposed against reduced-round versions of the cipher, that is, versions of DES with fewer than 16 rounds. Such analysis gives an insight into how many rounds are needed for safety, and how much of a "security margin" the full version retains.

Differential-linear cryptanalysis was proposed by Langford and Hellman in 1994, and combines differential and linear cryptanalysis into a single attack. An enhanced version of the attack can break 9-round DES with 2 chosen plaintexts and has a 2 time complexity (Biham and others, 2002).

DES exhibits the complementation property, namely that
where formula_2 is the bitwise complement of formula_3 formula_4 denotes encryption with key formula_5 formula_6 and formula_7 denote plaintext and ciphertext blocks respectively. The complementation property means that the work for a brute-force attack could be reduced by a factor of 2 (or a single bit) under a chosen-plaintext assumption. By definition, this property also applies to TDES cipher.

DES also has four so-called "weak keys". Encryption ("E") and decryption ("D") under a weak key have the same effect (see involution):
There are also six pairs of "semi-weak keys". Encryption with one of the pair of semiweak keys, formula_10, operates identically to decryption with the other, formula_11:
It is easy enough to avoid the weak and semiweak keys in an implementation, either by testing for them explicitly, or simply by choosing keys randomly; the odds of picking a weak or semiweak key by chance are negligible. The keys are not really any weaker than any other keys anyway, as they do not give an attack any advantage.

DES has also been proved not to be a group, or more precisely, the set formula_14 (for all possible keys formula_15) under functional composition is not a group, nor "close" to being a group. This was an open question for some time, and if it had been the case, it would have been possible to break DES, and multiple encryption modes such as Triple DES would not increase the security, because encryption under one key would be equivalent to decryption under another key.

Simplified DES (SDES) was designed for educational purposes only, to help students learn about modern cryptanalytic techniques.
SDES has similar properties and structure as DES, but has been simplified to make it much easier to perform encryption and decryption by hand with pencil and paper.
Some people feel that learning SDES gives insight into DES and other block ciphers, and insight into various cryptanalytic attacks against them.

Concerns about security and the relatively slow operation of DES in software motivated researchers to propose a variety of alternative block cipher designs, which started to appear in the late 1980s and early 1990s: examples include RC5, Blowfish, IDEA, NewDES, SAFER, CAST5 and FEAL. Most of these designs kept the 64-bit block size of DES, and could act as a "drop-in" replacement, although they typically used a 64-bit or 128-bit key. In the Soviet Union the GOST 28147-89 algorithm was introduced, with a 64-bit block size and a 256-bit key, which was also used in Russia later.

DES itself can be adapted and reused in a more secure scheme. Many former DES users now use Triple DES (TDES) which was described and analysed by one of DES's patentees (see FIPS Pub 46-3); it involves applying DES three times with two (2TDES) or three (3TDES) different keys. TDES is regarded as adequately secure, although it is quite slow. A less computationally expensive alternative is DES-X, which increases the key size by XORing extra key material before and after DES. GDES was a DES variant proposed as a way to speed up encryption, but it was shown to be susceptible to differential cryptanalysis.

On January 2, 1997, NIST announced that they wished to choose a successor to DES. In 2001, after an international competition, NIST selected a new cipher, the Advanced Encryption Standard (AES), as a replacement. The algorithm which was selected as the AES was submitted by its designers under the name Rijndael. Other finalists in the NIST AES competition included RC6, Serpent, MARS, and Twofish.




</doc>
<doc id="7983" url="https://en.wikipedia.org/wiki?curid=7983" title="Double-hulled tanker">
Double-hulled tanker

A double-hulled tanker refers to an oil tanker which has a double hull. They reduce the likelihood of leaks occurring compared to single-hulled tankers, and their ability to prevent or reduce oil spills led to double hulls being standardized for oil tankers and other types of ships including by the International Convention for the Prevention of Pollution from Ships or MARPOL Convention. After the Exxon Valdez oil spill disaster in Alaska in 1989, the US Government required all new oil tankers built for use between US ports to be equipped with a full double hull.

A number of manufacturers have embraced oil tankers with a double hull because it strengthens the hull of ships, reducing the likelihood of oil disasters in low-impact collisions and groundings over single-hull ships. They reduce the likelihood of leaks occurring at low speed impacts in port areas when the ship is under pilotage. Research of impact damage of ships has revealed that double-hulled tankers are unlikely to perforate both hulls in a collision, preventing oil from seeping out. However, for smaller tankers, U shaped tanks might be susceptible to "free flooding" across the double bottom and up to the outside water level each side of the cargo tank. Salvors prefer to salvage doubled-hulled tankers because they permit the use of air pressure to vacuum out the flood water. In the 1960s, collision proof double hulls for nuclear ships were extensively investigated, due to escalating concerns over nuclear accidents.

The ability of double-hulled tankers to prevent or reduce oil spills led to double hulls being standardized for other types of ships including oil tankers by the International Convention for the Prevention of Pollution from Ships or MARPOL Convention. In 1992, MARPOL was amended, making it "mandatory for tankers of 5,000 dwt and more ordered after 6 July 1993 to be fitted with double hulls, or an alternative design approved by IMO". However, in the aftermath of the Erika incident of the coast off France in December 1999, members of IMO adopted a revised schedule for the phase-out of single-hull tankers, which came into effect on 1 September 2003, with further amendments validated on 5 April 2005.

After the Exxon Valdez oil spill disaster, when that ship grounded on Bligh Reef outside the port of Valdez, Alaska in 1989, the US Government required all new oil tankers built for use between US ports to be equipped with a full double hull. However, the damage to the Exxon Valdez penetrated sections of the hull (the slops oil tanks, or slop tanks) that were protected by a double bottom, or partial double hull.

Although double-hulled tankers reduce the likelihood of ships grazing rocks and creating holes in the hull, a double hull does not protect against major, high-energy collisions or groundings which cause the majority of oil pollution, despite this being the reason that the double hull was mandated by United States legislation. Double-hulled tankers, if poorly designed, constructed, maintained and operated can be as problematic, if not more problematic than their single-hulled counterparts. Double-hulled tankers have a more complex design and structure than their single-hulled counterparts, which means that they require more maintenance and care in operating, which if not subject to responsible monitoring and policing, may cause problems. Double hulls often result in the weight of the hull increasing by at least 20%, and because the steel weight of doubled-hulled tanks should not be greater than that of single-hulled ships, the individual hull walls are typically thinner and theoretically less resistant to wear. Double hulls by no means eliminate the possibility of the hulls breaking apart. Due to the air space between the hulls, there is also a potential problem with volatile gases seeping out through worn areas of the internal hull, increasing the risk of an explosion.

Although several international conventions against pollution are in place, as of 2003 there was still no formal body setting international mandatory standards, although the International Safety Guide for Oil Tankers and Terminals (ISGOTT) does provide guidelines giving advice on optimum use and safety, such as recommending that ballast tanks are not entered while loaded with cargo, and that weekly samples are made of the atmosphere inside for hydrocarbon gas. Due to the difficulties of maintenance, ship builders have been competitive in producing double-hulled ships which are easier to inspect, such as ballast and cargo tanks which are easily accessible and easier to spot corrosion in the hull. The Tanker Structure Cooperative Forum (TSCF) published the "Guide to Inspection and Maintenance of Double-Hull Tanker Structures" in 1995 giving advice based on experience of operating double-hulled tankers.



</doc>
<doc id="7984" url="https://en.wikipedia.org/wiki?curid=7984" title="Drink">
Drink

A drink (or beverage) is a liquid intended for human consumption. In addition to their basic function of satisfying thirst, drinks play important roles in human culture. Common types of drinks include plain drinking water, milk, coffee, tea, hot chocolate, juice and soft drinks. In addition, alcoholic drinks such as wine, beer, and liquor, which contain the drug ethanol, have been part of human culture for more than 8,000 years.

Non-alcoholic drinks often signify drinks that would normally contain alcohol, such as beer and wine, but are made with less than .5 percent alcohol by volume. The category includes drinks that have undergone an alcohol removal process such as non-alcoholic beers and de-alcoholized wines.

When the human body becomes dehydrated, it experiences thirst. This craving of fluids results in an instinctive need to drink. Thirst is regulated by the hypothalamus in response to subtle changes in the body's electrolyte levels, and also as a result of changes in the volume of blood circulating. The complete elimination of drinks, that is, water, from the body will result in death faster than the removal of any other substance. Water and milk have been basic drinks throughout history. As water is essential for life, it has also been the carrier of many diseases.

As society developed, techniques were discovered to create alcoholic drinks from the plants that were available in different areas. The earliest archaeological evidence of wine production yet found has been at sites in Georgia ( BCE) and Iran ( BCE). Beer may have been known in Neolithic Europe as far back as 3000 BCE, and was mainly brewed on a domestic scale. The invention of beer (and bread) has been argued to be responsible for humanity's ability to develop technology and build civilization. Tea likely originated in Yunnan, China during the Shang Dynasty (1500 BCE–1046 BCE) as a medicinal drink.

Drinking has been a large part of socialising throughout the centuries. In Ancient Greece, a social gathering for the purpose of drinking was known as a symposium, where watered down wine would be drunk. The purpose of these gatherings could be anything from serious discussions to direct indulgence. In Ancient Rome, a similar concept of a "convivium" took place regularly.

Many early societies considered alcohol a gift from the gods, leading to the creation of gods such as Dionysus. Other religions forbid, discourage, or restrict the drinking of alcoholic drinks for various reasons. In some regions with a dominant religion the production, sale, and consumption of alcoholic drinks is forbidden to everybody, regardless of religion.

Toasting is a method of honouring a person or wishing good will by taking a drink. Another tradition is that of the loving cup, at weddings or other celebrations such as sports victories a group will share a drink in a large receptacle, shared by everyone until empty.

In East Africa and Yemen, coffee was used in native religious ceremonies. As these ceremonies conflicted with the beliefs of the Christian church, the Ethiopian Church banned the secular consumption of coffee until the reign of Emperor Menelik II. The drink was also banned in Ottoman Turkey during the 17th century for political reasons and was associated with rebellious political activities in Europe.

A drink is a form of liquid which has been prepared for human consumption. The preparation can include a number of different steps, some prior to transport, others immediately prior to consumption.

Water is the chief constituent in all drinks, and the primary ingredient in most. Water is purified prior to drinking. Methods for purification include filtration and the addition of chemicals, such as chlorination. The importance of purified water is highlighted by the World Health Organization, who point out 94% of deaths from diarrhea – the third biggest cause of infectious death worldwide at 1.8 million annually – could be prevented by improving the quality of the victim's environment, particularly safe water.

Pasteurisation is the process of heating a liquid for a period of time at a specified temperature, then immediately cooling. The process reduces the growth of microorganisms within the liquid, thereby increasing the time before spoilage. It is primarily used on milk, which prior to pasteurisation is commonly infected with pathogenic bacteria and therefore is more likely than any other part of the common diet in the developed world to cause illness.

The process of extracting juice from fruits and vegetables can take a number of forms. Simple crushing of most fruits will provide a significant amount of liquid, though a more intense pressure can be applied to get the maximum amount of juice from the fruit. Both crushing and pressing are processes used in the production of wine.

Infusion is the process of extracting flavours from plant material by allowing the material to remain suspended within water. This process is used in the production of teas, herbal teas and can be used to prepare coffee (when using a coffee press).

The name is derived from the word "percolate" which means "to cause (a solvent) to pass through a permeable substance especially for extracting a soluble constituent".
In the case of coffee-brewing the solvent is water, the permeable substance is the coffee grounds, and the soluble constituents are the chemical compounds that give coffee its color, taste, aroma, and stimulating properties.

Carbonation is the process of dissolving carbon dioxide into a liquid, such as water.

Fermentation is a metabolic process that converts sugar to ethanol. Fermentation has been used by humans for the production of drinks since the Neolithic age. In winemaking, grape juice is combined with yeast in an anaerobic environment to allow the fermentation. The amount of sugar in the wine and the length of time given for fermentation determine the alcohol level and the sweetness of the wine.

When brewing beer, there are four primary ingredients – water, grain, yeast and hops. The grain is encouraged to germinate by soaking and drying in heat, a process known as malting. It is then milled before soaking again to create the sugars needed for fermentation. This process is known as mashing. Hops are added for flavouring, then the yeast is added to the mixture (now called wort) to start the fermentation process.

Distillation is a method of separating mixtures based on differences in volatility of components in a boiling liquid mixture. It is one of the methods used in the purification of water. It is also a method of producing spirits from milder alcoholic drinks.

An alcoholic mixed drink that contains two or more ingredients is referred to as a cocktail. Cocktails were originally a mixture of spirits, sugar, water, and bitters. The term is now often used for almost any mixed drink that contains alcohol, including mixers, mixed shots, etc. A cocktail today usually contains one or more kinds of spirit and one or more mixers, such as soda or fruit juice. Additional ingredients may be sugar, honey, milk, cream, and various herbs.

A non-alcoholic drink is one that contains little or no alcohol. This category includes low-alcohol beer, non-alcoholic wine, and apple cider if they contain less than 0.5% alcohol by volume. The term "soft drink" specifies the absence of alcohol in contrast to "hard drink" and "drink". The term "drink" is theoretically neutral, but often is used in a way that suggests alcoholic content. Drinks such as soda pop, sparkling water, iced tea, lemonade, root beer, fruit punch, milk, hot chocolate, tea, coffee, milkshakes, and tap water and energy drinks are all soft drinks.

Water is the world's most consumed drink, however, 97% of water on Earth is non-drinkable salt water. Fresh water is found in rivers, lakes, wetlands, groundwater, and frozen glaciers. Less than 1% of the Earth's fresh water supplies are accessible through surface water and underground sources which are cost effective to retrieve.

In western cultures, water is often drunk cold. In the Chinese culture, it is typically drunk hot.

Regarded as one of the "original" drinks, milk is the primary source of nutrition for babies. In many cultures of the world, especially the Western world, humans continue to consume dairy milk beyond infancy, using the milk of other animals (especially cattle, goats and sheep) as a drink. Plant milk, a general term for any milk-like product that is derived from a plant source, also has a long history of consumption in various countries and cultures. The most popular varieties internationally are soy milk, almond milk, rice milk and coconut milk.

Carbonated drinks refer to drinks which have carbon dioxide dissolved into them. This can happen naturally through fermenting and in natural water spas or artificially by the dissolution of carbon dioxide under pressure. The first commercially available artificially carbonated drink is believed to have been produced by Thomas Henry in the late 1770s.
Cola, orange, various roots, ginger, and lemon/lime are commonly used to create non-alcoholic carbonated drinks; sugars and preservatives may be added later.

The most consumed carbonated soft drinks are produced by three major global brands: Coca-Cola, PepsiCo and the Dr Pepper Snapple Group.

Fruit juice is a natural product that contains few or no additives. Citrus products such as orange juice and tangerine juice are familiar breakfast drinks, while grapefruit juice, pineapple, apple, grape, lime, and lemon juice are also common. Coconut water is a highly nutritious and refreshing juice. Many kinds of berries are crushed; their juices are mixed with water and sometimes sweetened. Raspberry, blackberry and currants are popular juices drinks but the percentage of water also determines their nutritive value. Grape juice allowed to ferment produces wine.

Fruits are highly perishable so the ability to extract juices and store them was of significant value. Some fruits are highly acidic and mixing them with water and sugars or honey was often necessary to make them palatable. Early storage of fruit juices was labor-intensive, requiring the crushing of the fruits and the mixing of the resulting pure juices with sugars before bottling.

Vegetable juices are usually served warm or cold. Different types of vegetables can be used to make vegetable juice such as carrots, tomatoes, cucumbers, celery and many more. Some vegetable juices are mixed with some fruit juice to make the vegetable juice taste better. Many popular vegetable juices, particularly ones with high tomato content, are high in sodium, and therefore consumption of them for health must be carefully considered. Some vegetable juices provide the same health benefits as whole vegetables in terms of reducing risks of cardiovascular disease and cancer.

A sleep beverage, nightcap or relaxation drink are considered consumable liquids taken shortly before bedtime to induce sleep. They are often formulated to help reduce stress, alleviate anxiety, improve focus, and promote better overall sleep. For example, a small alcoholic drink or a cup of warm milk can supposedly promote a good night's sleep. These consumable sleep supplements are an anomaly or antithesis of energy drinks and have found a niche in the beverage industry. Originally, a nightcap was understood to be an alcoholic liquid with purpose of warming the drinker up and helping them sleep. That changed in 1930, when the nonalcoholic
drink, Ovaltine, was advertised as "the world's best 'night-cap' to ensure sound, natural sleep." An ingredient of Ovaltine is magnesium which helps to induce relaxation. Likewise, warm milk is often recommended as a nightcap for inducing sleep, because it contains both tryptophan and calcium. Then, the flavor of the warm milk was improved by adding a small amount of liqueur which may promote sleep as well. Alternatively, honey or vanilla can improve the flavor too. The effectiveness of warm milk for inducing sleep is disputed. Other drinks touted for inducing sleep and being effective sleep aids are hops tea, cherry juice (contains melatonin), coconut water (contains magnesium), lemon balm tea, decaffeinated green tea (contains theanine), valerian tea, and chamomile tea. Today, however, most sleep beverages, nightcaps and relaxation drinks are generally non-alcoholic beverages containing calming ingredients normally found in nature. They are considered functional beverages which serve to relax a person. Unlike other calming beverages, such as tea, warm milk or milk with honey; sleep drinks almost universally contain more than one active ingredient. Melatonin is a common ingredient found in relaxation drinks which also carries some negative connotations due to the controversial effects from long term use. Sleep beverages, nightcaps, and relaxation drinks have been known to contain other natural ingredients and are usually free of caffeine and alcohol but some have claimed to contain marijuana. Sleep beverages, nightcaps and relaxation drinks started to reappear in Japan at the beginning of the 21st century and then began to make their way to the US. One major brand was called Drank, a reference to an illicit concoction made out of cold medication. Others had names like Purple Stuff and Lean, which also hinted at vaguely narcotic effects. These brands were marketed towards a partying crowd, yet never managed to break into the mainstream. In the US, the Food & Drug Administration also moved in, shutting down brands for false health claims.

A drink is considered "alcoholic" if it contains ethanol, commonly known as alcohol (although in chemistry the definition of "alcohol" includes many other compounds). Beer has been a part of human culture for 8,000 years.

In many countries, imbibing alcoholic drinks in a local bar or pub is a cultural tradition.

Beer is an alcoholic drink produced by the saccharification of starch and fermentation of the resulting sugar. The starch and saccharification enzymes are often derived from malted cereal grains, most commonly malted barley and malted wheat. Most beer is also flavoured with hops, which add bitterness and act as a natural preservative, though other flavourings such as herbs or fruit may occasionally be included. The preparation of beer is called brewing. Beer is the world's most widely consumed alcoholic drink, and is the third-most popular drink overall, after water and tea. It is said to have been discovered by goddess Ninkasi around 5300 BCE, when she accidentally discovered yeast after leaving grain in jars that were later rained upon and left for several days. Women have been the chief creators of beer throughout history due to its association with domesticity and it, throughout much of history, being brewed in the home for family consumption. Only in recent history have men began to dabble in the field. It is thought by some to be the oldest fermented drink.

Some of humanity's earliest known writings refer to the production and distribution of beer: the Code of Hammurabi included laws regulating beer and beer parlours, and "The Hymn to Ninkasi", a prayer to the Mesopotamian goddess of beer, served as both a prayer and as a method of remembering the recipe for beer in a culture with few literate people. Today, the brewing industry is a global business, consisting of several dominant multinational companies and many thousands of smaller producers ranging from brewpubs to regional breweries.

Cider is a fermented alcoholic drink made from fruit juice, most commonly and traditionally apple juice, but also the juice of peaches, pears ("Perry" cider) or other fruit. Cider may be made from any variety of apple, but certain cultivars grown solely for use in cider are known as cider apples. The United Kingdom has the highest per capita consumption of cider, as well as the largest cider-producing companies in the world, , the U.K. produces 600 million litres of cider each year (130 million imperial gallons).

Wine is an alcoholic drink made from fermented grapes or other fruits. The natural chemical balance of grapes lets them ferment without the addition of sugars, acids, enzymes, water, or other nutrients. Yeast consumes the sugars in the grapes and converts them into alcohol and carbon dioxide. Different varieties of grapes and strains of yeasts produce different styles of wine. The well-known variations result from the very complex interactions between the biochemical development of the fruit, reactions involved in fermentation, terroir and subsequent appellation, along with human intervention in the overall process. The final product may contain tens of thousands of chemical compounds in amounts varying from a few percent to a few parts per billion.

Wines made from produce besides grapes are usually named after the product from which they are produced (for example, rice wine, pomegranate wine, apple wine and elderberry wine) and are generically called fruit wine. The term "wine" can also refer to starch-fermented or fortified drinks having higher alcohol content, such as barley wine, huangjiu, or sake.

Wine has a rich history dating back thousands of years, with the earliest production so far discovered having occurred  BC in Georgia. It had reached the Balkans by  BC and was consumed and celebrated in ancient Greece and Rome.

From its earliest appearance in written records, wine has also played an important role in religion. Red wine was closely associated with blood by the ancient Egyptians, who, according to Plutarch, avoided its free consumption as late as the 7th-century BC Saite dynasty, "thinking it to be the blood of those who had once battled against the gods". The Greek cult and mysteries of Dionysus, carried on by the Romans in their Bacchanalia, were the origins of western theater. Judaism incorporates it in the Kiddush and Christianity in its Eucharist, while alcohol consumption was forbidden in Islam.

Spirits are distilled beverages that contain no added sugar and have at least 20% alcohol by volume (ABV). Popular spirits include borovička, brandy, gin, rum, slivovitz, tequila, vodka, and whisky. Brandy is a spirit created by distilling wine, whilst vodka may be distilled from any starch- or sugar-rich plant matter; most vodka today is produced from grains such as sorghum, corn, rye or wheat.

Coffee is a brewed drink prepared from the roasted seeds of several species of an evergreen shrub of the genus "Coffea". The two most common sources of coffee beans are the highly regarded "Coffea arabica", and the "robusta" form of the hardier "Coffea canephora". Coffee plants are cultivated in more than 70 countries. Once ripe, coffee "berries" are picked, processed, and dried to yield the seeds inside. The seeds are then roasted to varying degrees, depending on the desired flavor, before being ground and brewed to create coffee.

Coffee is slightly acidic (pH 5.0–5.1) and can have a stimulating effect on humans because of its caffeine content. It is one of the most popular drinks in the world. It can be prepared and presented in a variety of ways. The effect of coffee on human health has been a subject of many studies; however, results have varied in terms of coffee's relative benefit.

Coffee cultivation first took place in southern Arabia; the earliest credible evidence of coffee-drinking appears in the middle of the 15th century in the Sufi shrines of Yemen.

Hot chocolate, also known as drinking chocolate or cocoa, is a heated drink consisting of shaved chocolate, melted chocolate or cocoa powder, heated milk or water, and usually a sweetener. Hot chocolate may be topped with whipped cream. Hot chocolate made with melted chocolate is sometimes called drinking chocolate, characterized by less sweetness and a thicker consistency.

The first chocolate drink is believed to have been created by the Mayans around 2,500-3,000 years ago, and a cocoa drink was an essential part of Aztec culture by 1400 AD, by which they referred to as xocōlātl. The drink became popular in Europe after being introduced from Mexico in the New World and has undergone multiple changes since then. Until the 19th century, hot chocolate was even used medicinally to treat ailments such as liver and stomach diseases.

Hot chocolate is consumed throughout the world and comes in multiple variations, including the spiced "chocolate para mesa" of Latin America, the very thick "cioccolata calda" served in Italy and "chocolate a la taza" served in Spain, and the thinner hot cocoa consumed in the United States. Prepared hot chocolate can be purchased from a range of establishments, including cafeterias, fast food restaurants, coffeehouses and teahouses. Powdered hot chocolate mixes, which can be added to boiling water or hot milk to make the drink at home, are sold at grocery stores and online.

Tea, the second most consumed drink in the world, is produced from infusing dried leaves of the "camellia sinensis" shrub, in boiling water. There are many ways in which tea is prepared for consumption: lemon or milk and sugar are among the most common additives worldwide. Other additions include butter and salt in Bhutan, Nepal, and Tibet; bubble tea in Taiwan; fresh ginger in Indonesia, Malaysia and Singapore; mint in North Africa and Senegal; cardamom in Central Asia; rum to make Jagertee in Central Europe; and coffee to make yuanyang in Hong Kong. Tea is also served differently from country to country: in China and Japan tiny cups are used to serve tea; in Thailand and the United States tea is often served cold (as "iced tea") or with a lot of sweetener; Indians boil tea with milk and a blend of spices as masala chai; tea is brewed with a samovar in Iran, Kashmir, Russia and Turkey; and in the Australian Outback it is traditionally brewed in a billycan.
Tea leaves can be processed in different ways resulting in a drink which appears and tastes different. Chinese yellow and green tea are steamed, roasted and dried; Oolong tea is semi-oxidised and appears green-black and black teas are fully oxidised.

Around the world, people refer to other herbal infusions as "teas"; it is also argued that these were popular long before the "Camellia sinensis" shrub was used for tea making. Leaves, flowers, roots or bark can be used to make a herbal infusion and can be bought fresh, dried or powdered.

Throughout history, people have come together in establishments to socialise whilst drinking. This includes cafés and coffeehouses, focus on providing hot drinks as well as light snacks. Many coffee houses in the Middle East, and in West Asian immigrant districts in the Western world, offer "shisha" ("nargile" in Turkish and Greek), flavored tobacco smoked through a hookah. Espresso bars are a type of coffeehouse that specialize in serving espresso and espresso-based drinks.

In China and Japan, the establishment would be a tea house, were people would socialise whilst drinking tea. Chinese scholars have used the teahouse for places of sharing ideas.

Alcoholic drinks are served in drinking establishments, which have different cultural connotations. For example, pubs are fundamental to the culture of Britain, Ireland, Australia, Canada, New England, Metro Detroit, South Africa and New Zealand. In many places, especially in villages, a pub can be the focal point of the community. The writings of Samuel Pepys describe the pub as the heart of England. Many pubs are controlled by breweries, so cask ale or keg beer may be a better value than wines and spirits.

In contrast, types of bars range from seedy bars or nightclubs, sometimes termed "dive bars", to elegant places of entertainment for the elite. Bars provide stools or chairs that are placed at tables or counters for their patrons. The term "bar" is derived from the specialized counter on which drinks are served. Some bars have entertainment on a stage, such as a live band, comedians, go-go dancers, or strippers. Patrons may sit or stand at the bar and be served by the bartender, or they may sit at tables and be served by cocktail servers.

Food and drink are often paired together to enhance the taste experience. This primarily happens with wine and a culture has grown up around the process. Weight, flavors and textures can either be contrasted or complemented. In recent years, food magazines began to suggest particular wines with recipes and restaurants would offer multi-course dinners matched with a specific wine for each course.

Different drinks have unique receptacles for their consumption. This is sometimes purely for presentations purposes, such as for cocktails. In other situations, the drinkware has practical application, such as coffee cups which are designed for insulation or brandy snifters which are designed to encourage evaporation but trap the aroma within the glass.

Many glasses include a stem, which allows the drinker to hold the glass without affecting the temperature of the drink. In champagne glasses, the bowl is designed to retain champagne's signature carbonation, by reducing the surface area at the opening of the bowl. Historically, champagne has been served in a champagne coupe, the shape of which allowed carbonation to dissipate even more rapidly than from a standard wine glass.

An important export commodity, coffee was the top agricultural export for twelve countries in 2004,
and it was the world's seventh-largest legal agricultural export by value in 2005. Green (unroasted) coffee is one of the most traded agricultural commodities in the world.

For the calendar year 2016, the United States beverage industry was valued at $24.1 billion with single-serve bottled water accounting for $900 million of the total. Carbonated beverages accounted for $81.6 billion in annual sales in the U.S.

Some drinks, such as wine, can be used as an alternative investment. This can be achieved by either purchasing and reselling individual bottles or cases of particular wines, or purchasing shares in an investment wine fund that pools investors' capital.




</doc>
<doc id="7985" url="https://en.wikipedia.org/wiki?curid=7985" title="Dill">
Dill

Dill ("Anethum graveolens") is an annual herb in the celery family Apiaceae. It is the only species in the genus "Anethum". Dill is grown widely in Eurasia where its leaves and seeds are used as a herb or spice for flavouring food.

Dill grows up to , with slender hollow stems and alternate, finely divided, softly delicate leaves long. The ultimate leaf divisions are broad, slightly broader than the similar leaves of fennel, which are threadlike, less than broad, but harder in texture. The flowers are white to yellow, in small umbels diameter. The seeds are long and thick, and straight to slightly curved with a longitudinally ridged surface.

The word "dill" and its close relatives are found in most of the Germanic languages; its ultimate origin is unknown. The generic name "Anethum" is the Latin form of the Greek ἄνῑσον / ἄνησον / ἄνηθον / ἄνητον, which meant both "dill" and "anise". The form "anīsum" came to be used for anise, "anēthum" for dill. The Latin word is the origin of dill's names in the Western Romance languages ("anet", "aneldo", etc.), and also of the obsolete English "anet". Most Slavic language names come from Proto-Slavic "*koprъ".

Fresh and dried dill leaves (sometimes called "dill weed" to distinguish it from dill seed) are widely used as herbs in Europe and central Asia.

Like caraway, the fernlike leaves of dill are aromatic and are used to flavor many foods such as gravlax (cured salmon) and other fish dishes, borscht, and other soups, as well as pickles (where the dill flower is sometimes used). Dill is best when used fresh, as it loses its flavor rapidly if dried, however, freeze-dried dill leaves retain their flavor relatively well for a few months.

Dill oil is extracted from the leaves, stems and seeds of the plant. The oil from the seeds is distilled and used in the manufacturing of soaps.

Dill is the eponymous ingredient in dill pickles.

In central, eastern Europe, Scandinavia, Baltic states, Ukraine, Russia, and Finland dill is a popular culinary herb used in the kitchen along with chives or parsley. Fresh, finely cut dill leaves are used as a topping in soups, especially the hot red borsht and the cold borsht mixed with curds, kefir, yogurt, or sour cream, which is served during hot summer weather and is called okroshka. It also is popular in summer to drink fermented milk (curds, kefir, yogurt, or buttermilk) mixed with dill (and sometimes other herbs).

In the same way, prepared dill is used as a topping for boiled potatoes covered with fresh butter – especially in summer when there are so-called "new", or young, potatoes. The dill leaves may be mixed with butter, making a dill butter, to serve the same purpose. Dill leaves mixed with tvorog, form one of the traditional cheese spreads used for sandwiches. Fresh dill leaves are used throughout the year as an ingredient in salads, "e.g.", one made of lettuce, fresh cucumbers, and tomatoes, as basil leaves are used in Italy and Greece.

Russian cuisine is known as <nowiki> 


</doc>
<doc id="7988" url="https://en.wikipedia.org/wiki?curid=7988" title="Dual space">
Dual space

In mathematics, any vector space "V" has a corresponding dual vector space (or just dual space for short) consisting of all linear functionals on "V", together with the vector space structure of pointwise addition and scalar multiplication by constants.

The dual space as defined above is defined for all vector spaces, and to avoid ambiguity may also be called the "algebraic dual space". When defined for a topological vector space, there is a subspace of the dual space, corresponding to continuous linear functionals, called the "continuous dual space".

Dual vector spaces find application in many branches of mathematics that use vector spaces, such as in tensor analysis with finite-dimensional vector spaces. When applied to vector spaces of functions (which are typically infinite-dimensional), dual spaces are used to describe measures, distributions, and Hilbert spaces. Consequently, the dual space is an important concept in functional analysis.

Given any vector space "V" over a field "F", the (algebraic) dual space "V" (alternatively denoted by formula_1 or formula_2) is defined as the set of all linear maps (linear functionals). Since linear maps are vector space homomorphisms, the dual space is also sometimes denoted by Hom("V", "F"). The dual space "V" itself becomes a vector space over "F" when equipped with an addition and scalar multiplication satisfying:
for all "φ" and , , and . Elements of the algebraic dual space "V" are sometimes called covectors or one-forms.

The pairing of a functional "φ" in the dual space "V" and an element "x" of "V" is sometimes denoted by a bracket: 
or . This pairing defines a nondegenerate bilinear mapping called the natural pairing.

If "V" is finite-dimensional, then "V" has the same dimension as "V". Given a basis in "V", it is possible to construct a specific basis in "V", called the dual basis. This dual basis is a set of linear functionals on "V", defined by the relation
for any choice of coefficients . In particular, letting in turn each one of those coefficients be equal to one and the other coefficients zero, gives the system of equations
where formula_6 is the Kronecker delta symbol. This property is referred to as "biorthogonality property".

For example, if "V" is R, let its basis be chosen as . Note that the basis vectors are not orthogonal to each other. Then, e and e are one-forms (functions that map a vector to a scalar) such that , , , and . (Note: The superscript here is the index, not an exponent). We can express this system of equations using matrix notation as
Solving this equation, we find the dual basis to be . Recalling that e and e are functionals, we can rewrite them as e("x", "y") = 2"x" and e("x", "y") = −"x" + "y". In general, when "V" is R, if E = (e, ..., e) is a matrix whose columns are the basis vectors and Ê = (e, ..., e) is a matrix whose columns are the dual basis vectors, then 
where I is an identity matrix of order "n". The biorthogonality property of these two basis sets allows us to represent any point x in "V" as 
even when the basis vectors are not orthogonal to each other.

In particular, if we interpret R as the space of columns of "n" real numbers, its dual space is typically written as the space of "rows" of "n" real numbers. Such a row acts on R as a linear functional by ordinary matrix multiplication. One way to see this is that a functional maps every "n"-vector "x" into a real number "y". Then, seeing this functional as a matrix "M", and "x", "y" as a matrix and a matrix (trivially, a real number) respectively, if we have , then, by dimension reasons, "M" must be a matrix, i.e., "M" must be a row vector.

If "V" consists of the space of geometrical vectors in the plane, then the level curves of an element of "V" form a family of parallel lines in "V", because the range is 1-dimensional, so that every point in the range is a multiple of any one nonzero element. So an element of "V" can be intuitively thought of as a particular family of parallel lines covering the plane. To compute the value of a functional on a given vector, one needs only to determine which of the lines the vector lies on. Or, informally, one "counts" how many lines the vector crosses. More generally, if "V" is a vector space of any dimension, then the level sets of a linear functional in "V" are parallel hyperplanes in "V", and the action of a linear functional on a vector can be visualized in terms of these hyperplanes.

If "V" is not finite-dimensional but has a basis e indexed by an infinite set "A", then the same construction as in the finite-dimensional case yields linearly independent elements e () of the dual space, but they will not form a basis.

Consider, for instance, the space R, whose elements are those sequences of real numbers that contain only finitely many non-zero entries, which has a basis indexed by the natural numbers N: for , e is the sequence consisting of all zeroes except in the "i"-th position, which is "1". The dual space of R is (isomorphic to) R, the space of "all" sequences of real numbers: such a sequence ("a") is applied to an element ("x") of R to give the number 

which is a finite sum because there are only finitely many nonzero "x". The dimension of R is countably infinite, whereas R does not have a countable basis.

This observation generalizes to any infinite-dimensional vector space "V" over any field "F": a choice of basis identifies "V" with the space ("F") of functions such that is nonzero for only finitely many , where such a function "f" is identified with the vector

in "V" (the sum is finite by the assumption on "f", and any may be written in this way by the definition of the basis).

The dual space of "V" may then be identified with the space "F" of "all" functions from "A" to "F": a linear functional "T" on "V" is uniquely determined by the values it takes on the basis of "V", and any function (with ) defines a linear functional "T" on "V" by

Again the sum is finite because "f" is nonzero for only finitely many "α".

Note that ("F") may be identified (essentially by definition) with the direct sum of infinitely many copies of "F" (viewed as a 1-dimensional vector space over itself) indexed by "A", i.e., there are linear isomorphisms

On the other hand, "F" is (again by definition), the direct product of infinitely many copies of "F" indexed by "A", and so the identification

is a special case of a general result relating direct sums (of modules) to direct products.

Thus if the basis is infinite, then the algebraic dual space is "always" of larger dimension (as a cardinal number) than the original vector space. This is in contrast to the case of the continuous dual space, discussed below, which may be isomorphic to the original vector space even if the latter is infinite-dimensional.

If "V" is finite-dimensional, then "V" is isomorphic to "V". But there is in general no natural isomorphism between these two spaces. Any bilinear form on "V" gives a mapping of "V" into its dual space via

where the right hand side is defined as the functional on "V" taking each to . In other words, the bilinear form determines a linear mapping

defined by

If the bilinear form is nondegenerate, then this is an isomorphism onto a subspace of "V". If "V" is finite-dimensional, then this is an isomorphism onto all of "V". Conversely, any isomorphism formula_18 from "V" to a subspace of "V" (resp., all of "V" if "V" is finite dimensional) defines a unique nondegenerate bilinear form on "V" by

Thus there is a one-to-one correspondence between isomorphisms of "V" to subspaces of (resp., all of) "V" and nondegenerate bilinear forms on "V".

If the vector space "V" is over the complex field, then sometimes it is more natural to consider sesquilinear forms instead of bilinear forms. In that case, a given sesquilinear form determines an isomorphism of "V" with the complex conjugate of the dual space

The conjugate space "V" can be identified with the set of all additive complex-valued functionals such that

There is a natural homomorphism formula_22 from formula_23 into the double dual formula_24, defined by formula_25 for all formula_26. In other words, if formula_27 is the evaluation map defined by formula_28, then we define formula_29 as the map formula_30. This map formula_22 is always injective; it is an isomorphism if and only if formula_23 is finite-dimensional. Indeed, the isomorphism of a finite-dimensional vector space with its double dual is an archetypal example of a natural isomorphism. Note that infinite-dimensional Hilbert spaces are not a counterexample to this, as they are isomorphic to their continuous duals, not to their algebraic duals.

If is a linear map, then the "transpose" (or "dual") is defined by
for every . The resulting functional "f"("φ") in "V" is called the "pullback" of "φ" along "f".

The following identity holds for all and :
where the bracket [·,·] on the left is the natural pairing of "V" with its dual space, and that on the right is the natural pairing of "W" with its dual. This identity characterizes the transpose, and is formally similar to the definition of the adjoint.

The assignment produces an injective linear map between the space of linear operators from "V" to "W" and the space of linear operators from "W" to "V"; this homomorphism is an isomorphism if and only if "W" is finite-dimensional. If then the space of linear maps is actually an algebra under composition of maps, and the assignment is then an antihomomorphism of algebras, meaning that . In the language of category theory, taking the dual of vector spaces and the transpose of linear maps is therefore a contravariant functor from the category of vector spaces over "F" to itself. Note that one can identify ("f") with "f" using the natural injection into the double dual.

If the linear map "f" is represented by the matrix "A" with respect to two bases of "V" and "W", then "f" is represented by the transpose matrix "A" with respect to the dual bases of "W" and "V", hence the name. Alternatively, as "f" is represented by "A" acting on the left on column vectors, "f" is represented by the same matrix acting on the right on row vectors. These points of view are related by the canonical inner product on R, which identifies the space of column vectors with the dual space of row vectors.

Let "S" be a subset of "V". The annihilator of "S" in "V", denoted here "S", is the collection of linear functionals such that for all . That is, "S" consists of all linear functionals such that the restriction to "S" vanishes: . Within finite dimensional vector spaces, the annihilator is dual to (isomorphic to) the orthogonal complement.

The annihilator of a subset is itself a vector space. In particular, the annihilator of the zero vector is the whole dual space: formula_35, and the annihilator of the whole space is just the zero covector: formula_36. Furthermore, the assignment of an annihilator to a subset of "V" reverses inclusions, so that if , then

Moreover, if "A" and "B" are two subsets of "V", then
and equality holds provided "V" is finite-dimensional. If "A" is any family of subsets of "V" indexed by "i" belonging to some index set "I", then
In particular if "A" and "B" are subspaces of "V", it follows that

If "V" is finite-dimensional, and "W" is a vector subspace, then
after identifying "W" with its image in the second dual space under the double duality isomorphism . Thus, in particular, forming the annihilator is a Galois connection on the lattice of subsets of a finite-dimensional vector space.

If "W" is a subspace of "V" then the quotient space "V"/"W" is a vector space in its own right, and so has a dual. By the first isomorphism theorem, a functional factors through "V"/"W" if and only if "W" is in the kernel of "f". There is thus an isomorphism
As a particular consequence, if "V" is a direct sum of two subspaces "A" and "B", then "V" is a direct sum of "A" and "B".

When dealing with topological vector spaces, one is typically only interested in the continuous linear functionals from the space into the base field formula_43 (or formula_44). This gives rise to the notion of the "continuous dual space" or "topological dual" which is a linear subspace of the algebraic dual space formula_45, denoted by formula_2. For any "finite-dimensional" normed vector space or topological vector space, such as Euclidean "n-"space, the continuous dual and the algebraic dual coincide. This is however false for any infinite-dimensional normed space, as shown by the example of discontinuous linear maps. Nevertheless, in the theory of topological vector spaces the terms "continuous dual space" and "topological dual space" are often replaced by "dual space", since there is no serious need to consider discontinuous maps in this field.

For a topological vector space formula_23 its "continuous dual space", or "topological dual space", or just "dual space" (in the sense of the theory of topological vector spaces) formula_2 is defined as the space of all continuous linear functionals formula_49.

There is a standard construction for introducing a topology on the continuous dual formula_2 of a topological vector space formula_23. Fix a collection formula_52 of bounded subsets of formula_23. Then one has the topology on formula_23 of uniform convergence on sets from formula_55 or what is the same thing, the topology generated by seminorms of the form 

where formula_57 is a continuous linear functional on formula_23, and formula_59 runs over the class formula_52.

This means that a net of functionals formula_61 tends to a functional formula_57 in formula_2 if and only if 

Usually (but not necessarily) the class formula_52 is supposed to satisfy the following conditions:




If these requirements are fulfilled then the corresponding topology on formula_2 is Hausdorff and the sets 

form its local base.

Here are the three most important special cases.




Each of these three choices of topology on formula_2 leads to a variant of reflexivity property for topological vector spaces.

Let 1 < "p" < ∞ be a real number and consider the Banach space "ℓ" of all sequences for which

Define the number "q" by . Then the continuous dual of "ℓ" is naturally identified with "ℓ": given an element , the corresponding element of is the sequence ("φ"(e)) where e denotes the sequence whose "n-"th term is 1 and all others are zero. Conversely, given an element , the corresponding continuous linear functional "φ" on is defined by 

for all (see Hölder's inequality).

In a similar manner, the continuous dual of is naturally identified with (the space of bounded sequences). Furthermore, the continuous duals of the Banach spaces "c" (consisting of all convergent sequences, with the supremum norm) and "c" (the sequences converging to zero) are both naturally identified with .

By the Riesz representation theorem, the continuous dual of a Hilbert space is again a Hilbert space which is anti-isomorphic to the original space. This gives rise to the bra–ket notation used by physicists in the mathematical formulation of quantum mechanics.

By the Riesz–Markov–Kakutani representation theorem, the continuous dual of certain spaces of continuous functions can be described using measures.

If is a continuous linear map between two topological vector spaces, then the (continuous) transpose is defined by the same formula as before:

The resulting functional is in. The assignment produces a linear map between the space of continuous linear maps from "V" to "W" and the space of linear maps from to . When "T" and "U" are composable continuous linear maps, then

When "V" and "W" are normed spaces, the norm of the transpose in is equal to that of "T" in. Several properties of transposition depend upon the Hahn–Banach theorem. For example, the bounded linear map "T" has dense range if and only if the transpose is injective.

When "T" is a compact linear map between two Banach spaces "V" and "W", then the transpose is compact. This can be proved using the Arzelà–Ascoli theorem.

When "V" is a Hilbert space, there is an antilinear isomorphism "i" from "V" onto its continuous dual. For every bounded linear map "T" on "V", the transpose and the adjoint operators are linked by

When "T" is a continuous linear map between two topological vector spaces "V" and "W", then the transpose is continuous when and are equipped with"compatible" topologies: for example when, for and , both duals have the strong topology of uniform convergence on bounded sets of "X", or both have the weak-∗ topology of pointwise convergence on "X". The transpose is continuous from to , or from to .

Assume that "W" is a closed linear subspace of a normed space "V", and consider the annihilator of "W" in,

Then, the dual of the quotient can be identified with "W", and the dual of "W" can be identified with the quotient . Indeed, let "P" denote the canonical surjection from "V" onto the quotient ; then, the transpose is an isometric isomorphism from into, with range equal to "W". If "j" denotes the injection map from "W" into "V", then the kernel of the transpose is the annihilator of "W":
and it follows from the Hahn–Banach theorem that induces an isometric isomorphism

If the dual of a normed space "V" is separable, then so is the space "V" itself. The converse is not true: for example the space is separable, but its dual is not.

The topology of "V" and the topology of real or complex numbers can be used to induce on "V′" a dual space topology.

In analogy with the case of the algebraic double dual, there is always a naturally defined continuous linear operator from a normed space "V" into its continuous double dual , defined by

As a consequence of the Hahn–Banach theorem, this map is in fact an isometry, meaning for all "x" in "V". Normed spaces for which the map Ψ is a bijection are called reflexive.

When "V" is a topological vector space, one can still define Ψ("x") by the same formula, for every , however several difficulties arise. First, when "V" is not locally convex, the continuous dual may be equal to {0} and the map Ψ trivial. However, if "V" is Hausdorff and locally convex, the map Ψ is injective from "V" to the algebraic dual of the continuous dual, again as a consequence of the Hahn–Banach theorem.

Second, even in the locally convex setting, several natural vector space topologies can be defined on the continuous dual , so that the continuous double dual is not uniquely defined as a set. Saying that Ψ maps from "V" to , or in other words, that Ψ("x") is continuous on for every , is a reasonable minimal requirement on the topology of , namely that the evaluation mappings

be continuous for the chosen topology on . Further, there is still a choice of a topology on , and continuity of Ψ depends upon this choice. As a consequence, defining reflexivity in this framework is more involved than in the normed case.




</doc>
<doc id="7989" url="https://en.wikipedia.org/wiki?curid=7989" title="Dianetics">
Dianetics

Dianetics (from Greek "dia", meaning "through", and "nous", meaning "mind") is a set of ideas and practices regarding the metaphysical relationship between the mind and body created by science fiction writer L. Ron Hubbard. Dianetics is practiced by followers of Scientology, the Nation of Islam (as of 2010), and independent Dianeticist groups.

Dianetics divides the mind into three parts: the conscious "analytical mind", the subconscious "reactive mind", and the somatic mind. The goal of Dianetics is to erase the content of the "reactive mind", which Scientologists believe interferes with a person's ethics, awareness, happiness, and sanity. The Dianetics procedure to achieve this erasure is called "auditing". In auditing, the Dianetic auditor asks a series of questions (or commands) and elicits answers to help a person locate and deal with painful experiences of the past, which Scientologists believe to be the content of the "reactive mind".

Practitioners of Dianetics believe that "the basic principle of existence is to survive" and that the basic personality of humans is sincere, intelligent, and good. The drive for goodness and survival is distorted and inhibited by aberrations "ranging from simple neuroses to different psychotic states to various kinds of sociopathic behavior patterns." Hubbard developed Dianetics, claiming that it could eradicate these aberrations.

When Hubbard formulated Dianetics, he described it as "a mix of Western technology and Oriental philosophy". He said that Dianetics "forms a bridge between" cybernetics and general semantics (a set of ideas about education originated by Alfred Korzybski, which received much attention in the science fiction world in the 1940s)—a claim denied by scholars of General Semantics, including S. I. Hayakawa, who expressed strong criticism of Dianetics as early as 1951. Hubbard claimed that Dianetics could increase intelligence, eliminate unwanted emotions and alleviate a wide range of illnesses he believed to be psychosomatic. Among the conditions purportedly treated were arthritis, allergies, asthma, some coronary difficulties, eye trouble, ulcers, migraine headaches, "sexual deviation" (which for Hubbard included homosexuality), and even death. Hubbard asserted that "memories of painful physical and emotional experiences accumulate in a specific region of the mind, causing illness and mental problems." He taught that "once these experiences have been purged through cathartic procedures he developed, a person can achieve superior health and intelligence." Hubbard also variously defined Dianetics as "a spiritual healing technology" and "an organized science of thought."

Dianetics is strongly related to the ideas of Sigmund Freud (psychoanalysis) and the ideas of William Sargant (abreaction therapy). Hubbard borrowed ideas heavily also from Carl Jung, Spiegel (hypnoanalysis), Korzybski (theory of identity), Nandor Fodor (prenatal and birth trauma), Otto Rank, and others.

Dianetics predates Hubbard's classification of Scientology as an "applied religious philosophy". Early in 1951, he expanded his writings to include teachings related to the soul, or "thetan". Dianetics is practiced by several independent Dianetics-only groups not connected with Scientology, and also Free Zone or Independent Scientologists. The Church of Scientology has prosecuted a number of people in court for unauthorized publication of Scientology and Dianetics copyrighted material.

L. Ron Hubbard published Dianetics on May 9, 1950, as a "branch of self-help psychology". In Dianetics, Hubbard introduced the "phenomena known as 'engrams'" as the source of "all psychological pain, which in turn harmed mental and physical health." He also claimed that individuals could reach the state of "clear", or a state of "exquisite clarity and mental liberation, by exorcising their engrams to an 'auditor,' or listener acting as therapist."
While not accepted by the medical and scientific establishment, in the first two years of its publication, over 100,000 copies of the book were sold. Many enthusiasts emerged to form groups to study and practice Dianetics. The atmosphere from which Dianetics was written about in this period was one of "excited experimentation". Roy Wallis writes that Hubbard's work was regarded as an "initial exploration" for further development. Hubbard wrote an additional six books in 1951, drawing the attention of a significant fan base.

Hubbard always claimed that his ideas of Dianetics originated in the 1920s and 1930s. By his own account, he had been injured by the premature detonation of a primer mechanism on a small depth charge that had become stuck in the launch rack aboard the navy ship he was assigned to in 1941. His injuries were mainly flash burns to his eyes and so was despatched ashore and he spent a great deal of his recovery time in the Oak Knoll Naval Hospital's library, (despite claiming in his authorised biography that he was blinded). LRH encountered the work of Thompson, Korzybski, Jung, Freud, Perls and other psychoanalysts.

In his 1955 Phoenix Lectures Series, Hubbard himself, explains that he took the opportunity to enter an office where research papers on the US Naval Medical Research Division's work on PTSD were kept in a filing cabinet and he spent the lunch hour free to read the notes left lying on the desk of the Naval Medical Officer involved. Much of what he learned then, along with his recent mastery of hypnotherapy technique by mail order, was influential in his later development of ideas and concepts for Dianetics Therapy from 1947 onwards. All he needed was medical and scientific testing and approval from any source. However, his several attempts were blocked by several luminaries of the (AMA) American Medical Association in the years 1948–1958, such as Professors Duncan Cameron and Allan Whyte (White), who both were senior authorities within the AMA-funded Psychiatric Research Department, then conducting their own research into drug therapies and controversial psycho-surgical techniques on severely traumatised war veterans.

Hubbard claimed in his several public lectures during the 1950s to have "undertaken clinical research at several of the institutions" they, Cameron and Whyte, had directed. Historical AMA records show that LRH was never officially involved in any approved clinical trials or research into PTSD. It is thought that Hubbard simply privately visited patients and conducted unauthorised interviews with several war veterans suffering from Trauma, Psychosomatic illness and practiced some of the newly identified PTSD techniques being clinically tested by several AMA medical institutions after WW2. (from personal Interviews with Joseph A. Winter, in Peoria,1959).

In April 1950, Hubbard, and several others, (Marjorie Cameron, De Mille, Art Ceppos, AE Van Vogt, Joseph A. Winter, MD.), established the Hubbard Dianetic Research Foundation in Elizabeth, New Jersey to coordinate work related to the forthcoming publication of DMSMH by Random House in May 1950 in NYC. Through the marketing efforts of Hubbard's friend and mentor John W. Campbell Jnr., (editor of "Astounding Science Fiction" of Street and Smith fame), Hubbard's articles on Dianetics hit the newsstands in NYC and became an overnight sensation among the usual readers with almost 350,000 copies sold of the May 1950 issue. (See interviews with John Campbell in his published 1978 biography.)

Hubbard first introduced Dianetics to the public in the article "" published in the May 1950 issue of the magazine "Astounding Science Fiction". Hubbard wrote "" at that time, allegedly completing the 180,000-word book in six weeks. The introduction of the book was the subject of an Associated Press article on 29 March 1950, with the lead "Discovery of a sub-mind is claimed in a new book entitled "Dianetics"".

When "Dianetics" was published in 1950, Hubbard announced in the opening pages, "The first contribution of Dianetics is the discovery that the problems of thought and mental function can be resolved within the bounds of the finite universe, which is to say that all data needful to the solution of mental action and Man's endeavor can be measured, sensed and experienced as scientific truths independent of mysticism or metaphysics." This was in line with Hubbard's initial presentation of Dianetics as a science, almost four years before he founded Scientology.

Publication of "Dianetics: The Modern Science of Mental Health" brought in a flood of money, which Hubbard used to establish Dianetics foundations in six major American cities. Dianetics shared The New York Times best-seller list with other self-help writings, including Norman Vincent Peale's "The Art of Happiness" and Henry Overstreet's "The Mature Mind". Scholar Hugh B. Urban asserted that the initial success of Dianetics was reflective of Hubbard's "remarkable entrepreneurial skills." Posthumously, Publisher's Weekly awarded Hubbard a plaque to acknowledge Dianetics appearing on its bestseller list for one hundred weeks, consecutively.

Some of the initial strongest supporters of Dianetics in the 1950s were John W. Campbell, editor of Astounding Science Fiction and Joseph Augustus Winter, a writer and medical physician. Campbell published some of Hubbard's short stories and Winter hoped that his colleagues would likewise be attracted to Hubbard's Dianetics system.

In January 1951, the New Jersey Board of Medical Examiners instituted proceedings against the Hubbard Dianetic Research Foundation in Elizabeth for 'teaching medicine without a licence', which was quickly resolved when the courts were made aware that the HDRF deputy director Winter was registered as an MD in the state of Michigan and New York. . 

Sociologist Roy Wallis says it was Dianetics popularity as a lay psychotherapy that contributed to the Foundation's downfall. It was the craze of 1950-51, but the fad was dead by 1952. Most people read the book, tried it out, then put it down. The remaining practitioners had no ties to the Foundation and resisted its control. Because there were no trained Dianetics professionals, factions formed. The followers challenged Hubbard's movement and his authority. Wallis suggests Hubbard learned an implicit lesson from this experience. He would not make the same mistake when creating Scientology.
The Foundation closed its doors when Hubbard ditched the Foundation, causing the proceedings to be vacated, but its creditors began to demand settlement of its outstanding debts. Don Purcell, a millionaire Dianeticist from Wichita, Kansas, offered a brief respite from bankruptcy, but the Wichita Foundation's finances soon failed again in 1952 when Hubbard ran off to Phoenix with all his Dianetics materials to avoid the court bailiffs sent in by Don Purcell, who had paid a considerable amount of money to Hubbard for the copyrights to Dianetics in an effort to keep Hubbard from bankruptcy again.

In 1954, Hubbard defined Scientology as a religion focused on the spirit, differentiating it from Dianetics, and subsequently Dianetics Auditing Therapy, which he defined as a counseling based science that addressed the physical being. He stated, "Dianetics is a science which applies to man, a living organism; and Scientology is a religion." When Hubbard morphed Dianetics therapy into the religion of Scientology, Jesper Aagaard Petersen of Oxford University surmises that it could have been for the benefits from establishing it is a religion as much as it could have been from the result of Hubbard's "discovery of past life experiences and his exploration of the thetan." The reason being to avoid copyright infringement issues with use of the name Dianetics then held by Don Purcell. Purcell later donated the copyright ownership back (to Hubbard) after Winter and Van Vogt had independently negotiated charitable debt relief with the disenchanted oil millionaire Purcell.

With the temporary sale of assets resulting from the HDRF's bankruptcy, Hubbard no longer owned the rights to the name "Dianetics", but its philosophical framework still provided the seed for Scientology to grow. Scientologists refer to the book "Dianetics: The Modern Science of Mental Health" as "Book One." In 1952, Hubbard published a new set of teachings as "Scientology, a religious philosophy." Scientology did not replace Dianetics but extended it to cover new areas: Where the goal of Dianetics is to rid the individual of his reactive mind engrams, the stated goal of Scientology is to rehabilitate the individual's spiritual nature so that he may reach his full potential.

In 1963 and again in May 1969, Hubbard reorganized the material in Dianetics, the auditing commands, and original Volney Mathieson invented E-meter use, naming the package "Standard Dianetics." In a 1969 bulletin, "This bulletin combines HCOB 27 April 1969 'R-3-R Restated' with those parts of HCOB 24 June 1963 'Routine 3-R' used in the new Standard Dianetic Course and its application. This gives the complete steps of Routine 3-R Revised."

In 1978, Hubbard released "New Era Dianetics" (NED), a revised version supposed to produce better results in a shorter period of time. The course consists of 11 rundowns and requires a specifically trained auditor. It is similar to Standard Dianetics, but the person being audited is encouraged to find the decision or "postulate" he made during or as a result of the incident. ("Postulate" in Dianetics and Scientology has the meaning of "a conclusion, decision or resolution made by the individual himself; to conclude, decide or resolve a problem or to set a pattern for the future or to nullify a pattern of the past" in contrast to its conventional meanings.)

In the Church of Scientology, OTs study several levels of before reaching the highest level.

In the book, "", Hubbard describes techniques that he suggests can rid individuals of fears and psychosomatic illnesses. A basic idea in Dianetics is that the mind consists of two parts: the "analytical mind" and the "reactive mind." The "reactive mind", the mind which operates when a person is physically unconscious, acts as a record of shock, trauma, pain, and otherwise harmful memories. Experiences such as these, stored in the "reactive mind" are dubbed "engrams". Dianetics is proposed as a method to erase these engrams in the reactive mind to achieve a state of clear.

Hubbard described Dianetics as "an organized science of thought built on definite axioms: statements of natural laws on the order of those of the physical sciences". In April 1950, before the public release of Dianetics, he wrote: "To date, over two hundred patients have been treated; of those two hundred, two hundred cures have been obtained."

In Dianetics, the unconscious or reactive mind is described as a collection of "mental image pictures," which contain the recorded experience of past moments of unconsciousness, including all sensory perceptions and feelings involved, ranging from pre-natal experiences, infancy and childhood, to even the traumatic feelings associated with events from past lives and extraterrestrial cultures. The type of mental image picture created during a period of unconsciousness involves the exact recording of a painful experience. Hubbard called this phenomenon an engram, and defined it as "a complete recording of a moment of unconsciousness containing physical pain or painful emotion and all perceptions."

Hubbard said that in Dianetics, it was the analytical mind and not the reactive mind that was the most important because the analytical mind "computes decisions" even when these are dictated by the reactive mind. The damage and aberration caused by the reactive mind would not be possible without the analytic mind. Hubbard stated, "the analytical is so important to the intelligent being and the somatic mind so important to the athlete that Dianetics processing can be said to consist of deintensifying the reactive mind so that the analytical and somatic minds can be free to function properly."

Hubbard proposed that painful physical or emotional traumas caused "aberrations" (deviations from rational thinking) in the mind, which produced lasting adverse physical and emotional effects, similar to conversion disorders. When the analytical (conscious) mind shut down during these moments, events and perceptions of this period were stored as engrams in the unconscious or reactive mind. (In Hubbard's earliest publications on the subject, engrams were variously referred to as "Norns", "Impediments," and "comanomes" before "engram" was adapted from its existing usage at the suggestion of Joseph Augustus Winter, MD.) Some commentators noted Dianetics's blend of science fiction and occult orientations at the time.

Hubbard claimed that these engrams are the cause of almost all psychological and physical problems. In addition to physical pain, engrams could include words or phrases spoken in the vicinity while the patient was unconscious. For instance, Winter cites the example of a patient with a persistent headache supposedly tracing the problem to a doctor saying, "Take him now," during the patient's birth. Hubbard similarly claimed that leukemia is traceable to "an engram containing the phrase 'It turns my blood to water.'" While it is sometimes claimed that the Church of Scientology no longer stands by Hubbard's claims that Dianetics can treat physical conditions, it still publishes them: "... when the knee injuries of the past are located and discharged, the arthritis ceases, no other injury takes its place and the person is finished with arthritis of the knee." "[The reactive mind] can give a man arthritis, bursitis, asthma, allergies, sinusitis, coronary trouble, high blood pressure ... And it is the only thing in the human being which can produce these effects ... Discharge the content of [the reactive mind] and the arthritis vanishes, myopia gets better, heart illness decreases, asthma disappears, stomachs function properly and the whole catalog of ills goes away and stays away."

Hubbard defined the third mind, or the somatic mind, as "that mind which, directed by the analytical or reactive mind, places solution into effect on the physical level." If an individual is not suffering from aberration or engrams are not restimulated, thus causing the person to relive pain, the analytical mind controls the somatic mind, in turn controlling blood flow, the heartbeat and endocrines. When a person is "aberrated," the reactive mind controls the somatic mind.

Some of the psychometric ideas in Dianetics, in particular the E-meter, can be traced to Carl Jung. Basic concepts, including conversion disorder, are derived from Sigmund Freud, whom Hubbard credited as an inspiration and source. Freud had speculated 40 years previously that traumas with similar content join together in "chains," embedded in the unconscious mind, to cause irrational responses in the individual. Such a chain would be relieved by inducing the patient to remember the earliest trauma, "with an accompanying expression of emotion."

According to Bent Corydon, Hubbard created the illusion that Dianetics was the first psychotherapy to address traumatic experiences in their own time, but others had done so as standard procedure.

One treatment method Hubbard drew from in developing Dianetics was abreaction therapy. Abreaction is a psychoanalytical term that means bringing to consciousness, and thus adequate expression, material that has been unconscious. "It includes not only the recollection of forgotten memories and experience, but also their reliving with appropriate emotional display and discharge of effect. This process is usually facilitated by the patient's gaining awareness of the causal relationship between the previously undischarged emotion and his symptoms."

According to Hubbard, before Dianetics psychotherapists had dealt with very light and superficial incidents (e.g. an incident that reminds the patient of a moment of loss), but with Dianetic therapy, the patient could actually erase moments of pain and unconsciousness. He emphasized: "The discovery of the engram is entirely the property of Dianetics. Methods of its erasure are also owned entirely by Dianetics..."

While 1950 style Dianetics was in some respects similar to older therapies, with the development of New Era Dianetics in 1978, the similarity vanished. New Era Dianetics uses an E-Meter and a rote procedure for running "chains" of related traumatic incidents.

Dianetics clarifies the understanding of psychosomatic illness in terms of "predisposition", "precipitation", and "prolongation".

With the use of Dianetics techniques, Hubbard claimed, the reactive mind could be processed and all stored engrams could be refiled as experience. The central technique was "auditing," a two-person question-and-answer therapy designed to isolate and dissipate engrams (or "mental masses"). An auditor addresses questions to a subject, observes and records the subject's responses, and returns repeatedly to experiences or areas under discussion that appear painful until the troubling experience has been identified and confronted. Through repeated applications of this method, the reactive mind could be "cleared" of its content having outlived its usefulness in the process of evolution; a person who has completed this process would be "Clear".

The benefits of going Clear, according to Hubbard, were dramatic. A Clear would have no compulsions, repressions, psychoses or neuroses, and would enjoy a near-perfect memory as well as a rise in IQ of as much as 50 points. He also claimed that "the atheist is activated by engrams as thoroughly as the zealot". He further claimed that widespread application of Dianetics would result in "A world without insanity, without criminals and without war."

One of the key ideas of Dianetics, according to Hubbard, is the fundamental existential command to survive. According to Hugh B. Urban, this would serve as the foundation of a big part of later Scientology.

According to the Scientology journal "The Auditor", the total number of "Clears" as of May 2006 stands at 50,311.

When Hubbard presented Dianetics, he did so in terms of "terra incognita," or to Scientologists the human mind. Hubbard wrote, “Dianetics is an adventure. It is an exploration of terra incognita, the human mind, the vast and hitherto unknown realm half an inch back of our foreheads." According to "Scientology in Popular Culture," Hubbard set out to colonize terra incognita, where in the “practice of empire was auditing, the new technology of empire was the E-meter. This exploration of the human mind “would become a defining feature of Scientology because it provided the portal through which he could conquer many enemy thetans.”

The procedure of Dianetics therapy (known as "auditing") is a two-person activity. One person, the "auditor", guides the other person, the "pre-clear". The pre-Clear's job is to look at the mind and talk to the auditor. The auditor acknowledges what the pre-Clear says and controls the process so the pre-Clear may put his full attention on his work.

The auditor and pre-Clear sit down in chairs facing each other. The process then follows in eleven distinct steps:


Auditing sessions are supposedly kept confidential. A few transcripts of auditing sessions with confidential information removed have been published as demonstration examples. Some extracts can be found in J.A. Winter's book "". Other, more comprehensive, transcripts of auditing sessions carried out by Hubbard himself can be found in volume 1 of the "Research & Discovery Series" (Bridge Publications, 1980). Examples of public group processing sessions can be found throughout the "Congresses" lecture series.

According to Hubbard, auditing enables the pre-Clear to "contact" and "release" engrams stored in the reactive mind, relieving him of the physical and mental aberrations connected with them. The pre-Clear is asked to inspect and familiarize himself with the exact details of his own experience; the auditor may not tell him anything about his case or evaluate any of the information the pre-Clear finds.

Hubbard's original book on Dianetics attracted highly critical reviews from science and medical writers and organizations. The American Psychological Association passed a resolution in 1950 calling "attention to the fact that these claims are not supported by empirical evidence of the sort required for the establishment of scientific generalizations." Subsequently, Dianetics has achieved no acceptance as a scientific theory, and scientists cite Dianetics as an example of a pseudoscience.

In August 1950, amidst the success of "", Hubbard held a demonstration in Los Angeles' Shrine Auditorium where he presented a young woman called Sonya Bianca (a pseudonym) to a large audience including many reporters and photographers as 'the world's first Clear." Despite Hubbard's claim that she had "full and perfect recall of every moment of her life", Bianca proved unable to answer questions from the audience testing her memory and analytical abilities, including the question of the color of Hubbard's tie. Hubbard explained Bianca's failure to display her promised powers of recall to the audience by saying that he had used the word "now" in calling her to the stage, and thus inadvertently froze her in "present time," which blocked her abilities. Later, in the late 1950s, Hubbard would claim that several people had reached the state of Clear by the time he presented Bianca as the world's first; these others, Hubbard said, he had successfully cleared in the late 1940s while working "incognito" in Hollywood posing as a swami. In 1966, Hubbard declared South African Scientologist John McMaster to be the first true Clear.

Few scientific investigations into the effectiveness of Dianetics have been published. Professor John A. Lee states in his 1970 evaluation of Dianetics:

The MEDLINE database records two independent scientific studies on Dianetics, both conducted in the 1950s under the auspices of New York University. Harvey Jay Fischer tested Dianetics therapy against three claims made by proponents and found it does not effect any significant changes in intellectual functioning, mathematical ability, or the degree of personality conflicts; Jack Fox tested Hubbard's thesis regarding recall of engrams, with the assistance of the Dianetic Research Foundation, and could not substantiate it.

Hubbard claimed, in an interview with "The New York Times" in November 1950, that "he had already submitted proof of claims made in the book to a number of scientists and associations." He added that the public as well as proper organizations were entitled to such proof and that he was ready and willing to give such proof in detail. In January 1951, the Hubbard Dianetic Research Foundation of Elizabeth, NJ published "Dianetic Processing: A Brief Survey of Research Projects and Preliminary Results", a booklet providing the results of psychometric tests conducted on 88 people undergoing Dianetics therapy. It presents case histories and a number of X-ray plates to support claims that Dianetics had cured "aberrations" including manic depression, asthma, arthritis, colitis and "overt homosexuality," and that after Dianetic processing, test subjects experienced significantly increased scores on a standardized IQ test. The report's subjects are not identified by name, but one of them is clearly Hubbard himself ("Case 1080A, R. L.").

The authors provide no qualifications, although they are described in Hubbard's book "Science of Survival" (where some results of the same study were reprinted) as psychotherapists. Critics of Dianetics are skeptical of this study, both because of the bias of the source and because the researchers appear to ascribe all physical benefits to Dianetics without considering possible outside factors; in other words, the report lacks any scientific controls. J.A. Winter, M.D., originally an associate of Hubbard and an early adopter of Dianetics, had by the end of 1950 cut his ties with Hubbard and written an account of his personal experiences with Dianetics. He described Hubbard as "absolutistic and authoritarian", and criticized the Hubbard Dianetic Research Foundation for failing to undertake "precise scientific research into the functioning of the mind". He also recommended that auditing be done by experts only and that it was dangerous for laymen to audit each other. Hubbard writes: "Again, Dianetics is not being released to a profession, for no profession could encompass it."

Commentators from a variety of backgrounds have described Dianetics as an example of pseudoscience. For example, philosophy professor Robert Carroll points to Dianetics' lack of empirical evidence:

W. Sumner Davis similarly comments that

The validity and practice of auditing have been questioned by a variety of non-Scientologist commentators. Commenting on the example cited by Winter, the science writer Martin Gardner asserts that "nothing could be clearer from the above dialogue than the fact that the dianetic explanation for the headache existed only in the mind of the therapist, and that it was with considerable difficulty that the patient was maneuvered into accepting it."

Other critics and medical experts have suggested that Dianetic auditing is a form of hypnosis, although the Church of Scientology has strongly denied that hypnosis forms any part of Dianetics. To the contrary, L. Ron Hubbard expressly warns not to use any hypnosis or hypnosis-like methods, because a person under hypnosis would be receptive to suggestions. This would decrease his self-determinism instead of increasing it, which is one of the prime goals of Dianetics. Winter [1950] comments that the leading nature of the questions asked of a pre-Clear "encourage fantasy", a common issue also encountered with hypnosis, which can be used to form false memories. The auditor is instructed not to make any assessment of a recalled memory's reality or accuracy, but instead to treat it as if it were objectively real. Professor Richard J. Ofshe, a leading expert on false memories, suggests that the feeling of well-being reported by pre-Clear at the end of an auditing session may be induced by post-hypnotic suggestion. Other researchers have identified quotations in Hubbard's work suggesting evidence that false memories were created in "Dianetics," specifically in the form of birth and pre-birth memories.

According to an article by Martin Gumpert, “Hubbard’s concept of psychosomatic disease is definitely wrong. Psychosomatic ailments are not simply caused by emotional disturbances: they are diseases in which the emotional and the organic factor are closely involved and interdependent.”

According to Hubbard, the majority of the people interested in the subject believed they could accomplish therapy alone. "It cannot be done" and he adds: "If a patient places himself in autohypnosis and regresses himself in an effort to reach illness or birth or prenatals, the only thing he will get is ill".





</doc>
<doc id="7990" url="https://en.wikipedia.org/wiki?curid=7990" title="Data warehouse">
Data warehouse

In computing, a data warehouse (DW or DWH), also known as an enterprise data warehouse (EDW), is a system used for reporting and data analysis, and is considered a core component of business intelligence. DWs are central repositories of integrated data from one or more disparate sources. They store current and historical data in one single place that are used for creating analytical reports for workers throughout the enterprise.

The data stored in the warehouse is uploaded from the operational systems (such as marketing or sales). The data may pass through an operational data store and may require data cleansing for additional operations to ensure data quality before it is used in the DW for reporting.

The typical extract, transform, load (ETL)-based data warehouse uses staging, data integration, and access layers to house its key functions. The staging layer or staging database stores raw data extracted from each of the disparate source data systems. The integration layer integrates the disparate data sets by transforming the data from the staging layer often storing this transformed data in an operational data store (ODS) database. The integrated data are then moved to yet another database, often called the data warehouse database, where the data is arranged into hierarchical groups, often called dimensions, and into facts and aggregate facts. The combination of facts and dimensions is sometimes called a star schema. The access layer helps users retrieve data.

The main source of the data is cleansed, transformed, catalogued, and made available for use by managers and other business professionals for data mining, online analytical processing, market research and decision support. However, the means to retrieve and analyze data, to extract, transform, and load data, and to manage the data dictionary are also considered essential components of a data warehousing system. Many references to data warehousing use this broader context. Thus, an expanded definition for data warehousing includes business intelligence tools, tools to extract, transform, and load data into the repository, and tools to manage and retrieve metadata.

A data warehouse maintains a copy of information from the source transaction systems. This architectural complexity provides the opportunity to:

The environment for data warehouses and marts includes the following:


In regards to source systems listed above, R. Kelly Rainer states, "A common source for the data in data warehouses is the company's operational databases, which can be relational databases".

Regarding data integration, Rainer states, "It is necessary to extract data from source systems, transform them, and load them into a data mart or warehouse".

Rainer discusses storing data in an organization's data warehouse or data marts.

Metadata are data about data. "IT personnel need information about data sources; database, table, and column names; refresh schedules; and data usage measures".

Today, the most successful companies are those that can respond quickly and flexibly to market changes and opportunities. A key to this response is the effective and efficient use of data and information by analysts and managers. A "data warehouse" is a repository of historical data that are organized by subject to support decision makers in the organization. Once data are stored in a data mart or warehouse, they can be accessed.

A data mart is a simple form of a data warehouse that is focused on a single subject (or functional area), hence they draw data from a limited number of sources such as sales, finance or marketing. Data marts are often built and controlled by a single department within an organization. The sources could be internal operational systems, a central data warehouse, or external data. Denormalization is the norm for data modeling techniques in this system. Given that data marts generally cover only a subset of the data contained in a data warehouse, they are often easier and faster to implement.

Types of data marts include dependent, independent, and hybrid data marts.

Online analytical processing (OLAP) is characterized by a relatively low volume of transactions. Queries are often very complex and involve aggregations. For OLAP systems, response time is an effectiveness measure. OLAP applications are widely used by Data Mining techniques. OLAP databases store aggregated, historical data in multi-dimensional schemas (usually star schemas). OLAP systems typically have data latency of a few hours, as opposed to data marts, where latency is expected to be closer to one day. The OLAP approach is used to analyze multidimensional data from multiple sources and perspectives. The three basic operations in OLAP are : Roll-up (Consolidation), Drill-down and Slicing & Dicing.

Online transaction processing (OLTP) is characterized by a large number of short on-line transactions (INSERT, UPDATE, DELETE). OLTP systems emphasize very fast query processing and maintaining data integrity in multi-access environments. For OLTP systems, effectiveness is measured by the number of transactions per second. OLTP databases contain detailed and current data. The schema used to store transactional databases is the entity model (usually 3NF). Normalization is the norm for data modeling techniques in this system.

Predictive analytics is about finding and quantifying hidden patterns in the data using complex mathematical models that can be used to predict future outcomes. Predictive analysis is different from OLAP in that OLAP focuses on historical data analysis and is reactive in nature, while predictive analysis focuses on the future. These systems are also used for customer relationship management (CRM).

The concept of data warehousing dates back to the late 1980s when IBM researchers Barry Devlin and Paul Murphy developed the "business data warehouse". In essence, the data warehousing concept was intended to provide an architectural model for the flow of data from operational systems to decision support environments. The concept attempted to address the various problems associated with this flow, mainly the high costs associated with it. In the absence of a data warehousing architecture, an enormous amount of redundancy was required to support multiple decision support environments. In larger corporations, it was typical for multiple decision support environments to operate independently. Though each environment served different users, they often required much of the same stored data. The process of gathering, cleaning and integrating data from various sources, usually from long-term existing operational systems (usually referred to as legacy systems), was typically in part replicated for each environment. Moreover, the operational systems were frequently reexamined as new decision support requirements emerged. Often new requirements necessitated gathering, cleaning and integrating new data from "data marts" that was tailored for ready access by users.

Key developments in early years of data warehousing:


A fact is a value, or measurement, which represents a fact about the managed entity or system.

Facts, as reported by the reporting entity, are said to be at raw level; e.g., in a mobile telephone system, if a BTS (base transceiver station) receives 1,000 requests for traffic channel allocation, allocates for 820, and rejects the remaining, it would report three facts or measurements to a management system:

Facts at the raw level are further aggregated to higher levels in various dimensions to extract more service or business-relevant information from it. These are called aggregates or summaries or aggregated facts.

For instance, if there are three BTS in a city, then the facts above can be aggregated from the BTS to the city level in the network dimension. For example:


There are three or more leading approaches to storing data in a data warehouse — the most important approaches are the dimensional approach and the normalized approach.

The dimensional approach refers to Ralph Kimball's approach in which it is stated that the data warehouse should be modeled using a Dimensional Model/star schema. The normalized approach, also called the 3NF model (Third Normal Form) refers to Bill Inmon's approach in which it is stated that the data warehouse should be modeled using an E-R model/normalized model.

In a dimensional approach, transaction data are partitioned into "facts", which are generally numeric transaction data, and "dimensions", which are the reference information that gives context to the facts. For example, a sales transaction can be broken up into facts such as the number of products ordered and the total price paid for the products, and into dimensions such as order date, customer name, product number, order ship-to and bill-to locations, and salesperson responsible for receiving the order.

A key advantage of a dimensional approach is that the data warehouse is easier for the user to understand and to use. Also, the retrieval of data from the data warehouse tends to operate very quickly. Dimensional structures are easy to understand for business users, because the structure is divided into measurements/facts and context/dimensions. Facts are related to the organization's business processes and operational system whereas the dimensions surrounding them contain context about the measurement (Kimball, Ralph 2008). Another advantage offered by dimensional model is that it does not involve a relational database every time. Thus, this type of modeling technique is very useful for end-user queries in data warehouse.

The model of facts and dimensions can also be understood as data cube. Where the dimensions are the categorical coordinates in a multi-dimensional cube, while the fact is a value corresponding to the coordinates.

The main disadvantages of the dimensional approach are the following:

In the normalized approach, the data in the data warehouse are stored following, to a degree, database normalization rules. Tables are grouped together by "subject areas" that reflect general data categories (e.g., data on customers, products, finance, etc.). The normalized structure divides data into entities, which creates several tables in a relational database. When applied in large enterprises the result is dozens of tables that are linked together by a web of joins. Furthermore, each of the created entities is converted into separate physical tables when the database is implemented (Kimball, Ralph 2008).
The main advantage of this approach is that it is straightforward to add information into the database. Some disadvantages of this approach are that, because of the number of tables involved, it can be difficult for users to join data from different sources into meaningful information and to access the information without a precise understanding of the sources of data and of the data structure of the data warehouse.

Both normalized and dimensional models can be represented in entity-relationship diagrams as both contain joined relational tables. The difference between the two models is the degree of normalization (also known as Normal Forms). These approaches are not mutually exclusive, and there are other approaches. Dimensional approaches can involve normalizing data to a degree (Kimball, Ralph 2008).

In "Information-Driven Business", Robert Hillard proposes an approach to comparing the two approaches based on the information needs of the business problem. The technique shows that normalized models hold far more information than their dimensional equivalents (even when the same fields are used in both models) but this extra information comes at the cost of usability. The technique measures information quantity in terms of information entropy and usability in terms of the Small Worlds data transformation measure.

In the "bottom-up" approach, data marts are first created to provide reporting and analytical capabilities for specific business processes. These data marts can then be integrated to create a comprehensive data warehouse. The data warehouse bus architecture is primarily an implementation of "the bus", a collection of conformed dimensions and conformed facts, which are dimensions that are shared (in a specific way) between facts in two or more data marts.

The "top-down" approach is designed using a normalized enterprise data model. "Atomic" data, that is, data at the greatest level of detail, are stored in the data warehouse. Dimensional data marts containing data needed for specific business processes or specific departments are created from the data warehouse.

Data warehouses (DW) often resemble the hub and spokes architecture. Legacy systems feeding the warehouse often include customer relationship management and enterprise resource planning, generating large amounts of data. To consolidate these various data models, and facilitate the extract transform load process, data warehouses often make use of an operational data store, the information from which is parsed into the actual DW. To reduce data redundancy, larger systems often store the data in a normalized way. Data marts for specific reports can then be built on top of the data warehouse.

A hybrid DW database is kept on third normal form to eliminate data redundancy. A normal relational database, however, is not efficient for business intelligence reports where dimensional modelling is prevalent. Small data marts can shop for data from the consolidated warehouse and use the filtered, specific data for the fact tables and dimensions required. The DW provides a single source of information from which the data marts can read, providing a wide range of business information. The hybrid architecture allows a DW to be replaced with a master data management repository where operational, not static information could reside.

The data vault modeling components follow hub and spokes architecture. This modeling style is a hybrid design, consisting of the best practices from both third normal form and star schema. The data vault model is not a true third normal form, and breaks some of its rules, but it is a top-down architecture with a bottom up design. The data vault model is geared to be strictly a data warehouse. It is not geared to be end-user accessible, which when built, still requires the use of a data mart or star schema based release area for business purposes.

There are basic features that define the data in the data warehouse that include subject orientation, data integration, time-variant, nonvolatile data, and data granularity.

Unlike the operational systems, the data in the data warehouse revolves around subjects of the enterprise (database normalization). Subject orientation can be really useful for decision making.
Gathering the required objects is called subject oriented.

The data found within the data warehouse is integrated. Since it comes from several operational systems, all inconsistencies must be removed. Consistencies include naming conventions, measurement of variables, encoding structures, physical attributes of data, and so forth.

While operational systems reflect current values as they support day-to-day operations, data warehouse data represents data over a long time horizon (up to 10 years) which means it stores historical data. It is mainly meant for data mining and forecasting, If a user is searching for a buying pattern of a specific customer, the user needs to look at data on the current and past purchases.

The data in the data warehouse is read-only which means it cannot be updated, created, or deleted.

In the data warehouse, data is summarized at different levels.The user may start looking at the total sale units of a product in an entire region. Then the user looks at the states in that region. Finally, they may examine the individual stores in a certain state. Therefore, typically, the analysis starts at a higher level and moves down to lower levels of details.

The different methods used to construct/organize a data warehouse specified by an organization are numerous. The hardware utilized, software created and data resources specifically required for the correct functionality of a data warehouse are the main components of the data warehouse architecture. All data warehouses have multiple phases in which the requirements of the organization are modified and fine tuned.

Operational systems are optimized for preservation of data integrity and speed of recording of business transactions through use of database normalization and an entity-relationship model. Operational system designers generally follow Codd's 12 rules of database normalization to ensure data integrity. Fully normalized database designs (that is, those satisfying all Codd rules) often result in information from a business transaction being stored in dozens to hundreds of tables. Relational databases are efficient at managing the relationships between these tables. The databases have very fast insert/update performance because only a small amount of data in those tables is affected each time a transaction is processed. To improve performance, older data are usually periodically purged from operational systems.

Data warehouses are optimized for analytic access patterns. Analytic access patterns generally involve selecting specific fields and rarely if ever 'select *' as is more common in operational databases. Because of these differences in access patterns, operational databases (loosely, OLTP) benefit from the use of a row-oriented DBMS whereas analytics databases (loosely, OLAP) benefit from the use of a column-oriented DBMS. Unlike operational systems which maintain a snapshot of the business, data warehouses generally maintain an infinite history which is implemented through ETL processes that periodically migrate data from the operational systems over to the data warehouse.

These terms refer to the level of sophistication of a data warehouse:




</doc>
<doc id="7991" url="https://en.wikipedia.org/wiki?curid=7991" title="Disperser">
Disperser

A disperser is a one-sided extractor. Where an extractor requires that every event gets the same probability under the uniform distribution and the extracted distribution, only the latter is required for a disperser. So for a disperser, an event formula_1 we have:
formula_2

Definition (Disperser): "A" formula_3"-disperser is a function"

formula_4

"such that for every distribution" formula_5 "on" formula_6 "with" formula_7 "the support of the distribution" formula_8 "is of size at least" formula_9.

An ("N", "M", "D", "K", "e")-disperser is a bipartite graph with "N" vertices on the left side, each with degree "D", and "M" vertices on the right side, such that every subset of "K" vertices on the left side is connected to more than (1 − "e")"M" vertices on the right.

An extractor is a related type of graph that guarantees an even stronger property; every ("N", "M", "D", "K", "e")-extractor is also an ("N", "M", "D", "K", "e")-disperser.

A disperser is a high-speed mixing device used to disperse or dissolve pigments and other solids into a liquid.



</doc>
<doc id="7992" url="https://en.wikipedia.org/wiki?curid=7992" title="Devonian">
Devonian

The Devonian is a geologic period and system of the Paleozoic, spanning 60 million years from the end of the Silurian, million years ago (Mya), to the beginning of the Carboniferous, Mya. It is named after Devon, England, where rocks from this period were first studied.

The first significant adaptive radiation of life on dry land occurred during the Devonian. Free-sporing vascular plants began to spread across dry land, forming extensive forests which covered the continents. By the middle of the Devonian, several groups of plants had evolved leaves and true roots, and by the end of the period the first seed-bearing plants appeared. Various terrestrial arthropods also became well-established.

Fish reached substantial diversity during this time, leading the Devonian to often be dubbed the "Age of Fishes." The first ray-finned and lobe-finned bony fish appeared, while the placoderms began dominating almost every known aquatic environment. The ancestors of all four-limbed vertebrates (tetrapods) began adapting to walking on land, as their strong pectoral and pelvic fins gradually evolved into legs. In the oceans, primitive sharks became more numerous than in the Silurian and Late Ordovician.

The first ammonites, species of molluscs, appeared. Trilobites, the mollusc-like brachiopods and the great coral reefs, were still common. The Late Devonian extinction which started about 375 million years ago severely affected marine life, killing off all placodermi, and all trilobites, save for a few species of the order Proetida.

The palaeogeography was dominated by the supercontinent of Gondwana to the south, the continent of Siberia to the north, and the early formation of the small continent of Euramerica in between.

The period is named after Devon, a county in southwestern England, where a controversial argument in the 1830s over the age and structure of the rocks found distributed throughout the county was eventually resolved by the definition of the Devonian period in the geological timescale. The Great Devonian Controversy was a long period of vigorous argument and counter-argument between the main protagonists of Roderick Murchison with Adam Sedgwick against Henry De la Beche supported by George Bellas Greenough. Murchison and Sedgwick won the debate and named the period they proposed as the Devonian System.

While the rock beds that define the start and end of the Devonian period are well identified, the exact dates are uncertain. According to the International Commission on Stratigraphy, the Devonian extends from the end of the Silurian Mya, to the beginning of the Carboniferous Mya—in North America, the beginning of the Mississippian subperiod of the Carboniferous.

In nineteenth-century texts the Devonian has been called the "Old Red Age", after the red and brown terrestrial deposits known in the United Kingdom as the Old Red Sandstone in which early fossil discoveries were found. Another common term is "Age of the Fishes", referring to the evolution of several major groups of fish that took place during the period. Older literature on the Anglo-Welsh basin divides it into the Downtonian, Dittonian, Breconian and Farlovian stages, the latter three of which are placed in the Devonian.

The Devonian has also erroneously been characterised as a "greenhouse age", due to sampling bias: most of the early Devonian-age discoveries came from the strata of western Europe and eastern North America, which at the time straddled the Equator as part of the supercontinent of Euramerica where fossil signatures of widespread reefs indicate tropical climates that were warm and moderately humid but in fact the climate in the Devonian differed greatly during its epochs and between geographic regions. For example, during the Early Devonian, arid conditions were prevalent through much of the world including Siberia, Australia, North America, and China, but Africa and South America had a warm temperate climate. In the Late Devonian, by contrast, arid conditions were less prevalent across the world and temperate climates were more common.

The Devonian Period is formally broken into Early, Middle and Late subdivisions. The rocks corresponding to those epochs are referred to as belonging to the Lower, Middle and Upper parts of the Devonian System.

The Early Devonian lasted from and began with the Lochkovian stage , which was followed by the Pragian from and then by the Emsian, which lasted until the Middle Devonian began, . 
During this time, the first ammonoids appeared, descending from bactritoid nautiloids. Ammonoids during this time period were simple and differed little from their nautiloid counterparts. These ammonoids belong to the order Agoniatitida, which in later epochs evolved to new ammonoid orders, for example Goniatitida and Clymeniida. This class of cephalopod molluscs would dominate the marine fauna until the beginning of the Mesozoic era.

The Middle Devonian comprised two subdivisions: first the Eifelian, which then gave way to the Givetian .
During this time the jawless agnathan fishes began to decline in diversity in freshwater and marine environments partly due to drastic environmental changes and partly due to the increasing competition, predation and diversity of jawed fishes. The shallow, warm, oxygen-depleted waters of Devonian inland lakes, surrounded by primitive plants, provided the environment necessary for certain early fish to develop such essential characteristics as well developed lungs, and the ability to crawl out of the water and onto the land for short periods of time.

Finally, the Late Devonian started with the Frasnian, , during which the first forests took shape on land. The first tetrapods appeared in the fossil record in the ensuing Famennian subdivision, the beginning and end of which are marked with extinction events. This lasted until the end of the Devonian, .

The Devonian was a relatively warm period, and probably lacked any glaciers. The temperature gradient from the equator to the poles was not as large as it is today. The weather was also very arid, mostly along the equator where it was the driest. Reconstruction of tropical sea surface temperature from conodont apatite implies an average value of in the Early Devonian. levels dropped steeply throughout the Devonian period as the burial of the newly evolved forests drew carbon out of the atmosphere into sediments; this may be reflected by a Mid-Devonian cooling of around . The Late Devonian warmed to levels equivalent to the Early Devonian; while there is no corresponding increase in concentrations, continental weathering increases (as predicted by warmer temperatures); further, a range of evidence, such as plant distribution, points to a Late Devonian warming. The climate would have affected the dominant organisms in reefs; microbes would have been the main reef-forming organisms in warm periods, with corals and stromatoporoid sponges taking the dominant role in cooler times. The warming at the end of the Devonian may even have contributed to the extinction of the stromatoporoids.

The Devonian period was a time of great tectonic activity, as Euramerica and Gondwana drew closer together.

The continent Euramerica (or Laurussia) was created in the early Devonian by the collision of Laurentia and Baltica, which rotated into the natural dry zone along the Tropic of Capricorn, which is formed as much in Paleozoic times as nowadays by the convergence of two great air-masses, the Hadley cell and the Ferrel cell. In these near-deserts, the Old Red Sandstone sedimentary beds formed, made red by the oxidised iron (hematite) characteristic of drought conditions.

Near the equator, the plate of Euramerica and Gondwana were starting to meet, beginning the early stages of the assembling of Pangaea. This activity further raised the northern Appalachian Mountains and formed the Caledonian Mountains in Great Britain and Scandinavia.

The west coast of Devonian North America, by contrast, was a passive margin with deep silty embayments, river deltas and estuaries, found today in Idaho and Nevada; an approaching volcanic island arc reached the steep slope of the continental shelf in Late Devonian times and began to uplift deep water deposits, a collision that was the prelude to the mountain-building episode at the beginning of the Carboniferous called the Antler orogeny.

Sea levels were high worldwide, and much of the land lay under shallow seas, where tropical reef organisms lived. The deep, enormous Panthalassa (the "universal ocean") covered the rest of the planet. Other minor oceans were the Paleo-Tethys Ocean, Proto-Tethys Ocean, Rheic Ocean, and Ural Ocean (which was closed during the collision with Siberia and Baltica).

During the Devonian, Chaitenia, an island arc, accreted to Patagonia.

Sea levels in the Devonian were generally high. Marine faunas continued to be dominated by bryozoa, diverse and abundant brachiopods, the enigmatic hederellids, microconchids and corals. Lily-like crinoids (animals, their resemblance to flowers notwithstanding) were abundant, and trilobites were still fairly common. Among vertebrates, jawless armored fish (ostracoderms) declined in diversity, while the jawed fish (gnathostomes) simultaneously increased in both the sea and fresh water. Armored placoderms were numerous during the lower stages of the Devonian Period and became extinct in the Late Devonian, perhaps because of competition for food against the other fish species. Early cartilaginous (Chondrichthyes) and bony fishes (Osteichthyes) also become diverse and played a large role within the Devonian seas. The first abundant genus of shark, "Cladoselache", appeared in the oceans during the Devonian Period. The great diversity of fish around at the time has led to the Devonian being given the name "The Age of Fish" in popular culture.

The first ammonites also appeared during or slightly before the early Devonian Period around 400 Mya.

A now dry barrier reef, located in present-day Kimberley Basin of northwest Australia, once extended a thousand kilometres, fringing a Devonian continent. Reefs in general are built by various carbonate-secreting organisms that have the ability to erect wave-resistant frameworks close to sea level. The main contributors of the Devonian reefs were unlike modern reefs, which are constructed mainly by corals and calcareous algae. They were composed of calcareous algae and coral-like stromatoporoids, and tabulate and rugose corals, in that order of importance.

By the Devonian Period, life was well underway in its colonisation of the land. The moss forests and bacterial and algal mats of the Silurian were joined early in the period by primitive rooted plants that created the first stable soils and harbored arthropods like mites, scorpions, trigonotarbids and myriapods (although arthropods appeared on land much earlier than in the Early Devonian and the existence of fossils such as "Climactichnites" suggest that land arthropods may have appeared as early as the Cambrian). Also the first possible fossils of insects appeared around 416 Mya in the Early Devonian. Evidence for the earliest tetrapods takes the form of trace fossils in shallow lagoon environments within a marine carbonate platform/shelf during the Middle Devonian, although these traces have been questioned and an interpretation as fish feeding traces (Piscichnus) has been advanced.

Many Early Devonian plants did not have true roots or leaves like extant plants although vascular tissue is observed in many of those plants. Some of the early land plants such as "Drepanophycus" likely spread by vegetative growth and spores. The earliest land plants such as "Cooksonia" consisted of leafless, dichotomous axes and terminal sporangia and were generally very short-statured, and grew hardly more than a few centimetres tall. By far the largest land organism during this period was the enigmatic "Prototaxites", which was possibly the fruiting body of an enormous fungus, rolled liverwort mat, or another organism of uncertain affinities that stood more than 8 metres tall, and towered over the low, carpet-like vegetation. By the Middle Devonian, shrub-like forests of primitive plants existed: lycophytes, horsetails, ferns, and progymnosperms had evolved. Most of these plants had true roots and leaves, and many were quite tall. The earliest-known trees, from the genus "Wattieza", appeared in the Late Devonian around 385 Mya. In the Late Devonian, the tree-like ancestral Progymnosperm "Archaeopteris" which had conifer-like true wood and fern-like foliage and the cladoxylopsids grew. (See also: lignin.) These are the oldest-known trees of the world's first forests. By the end of the Devonian, the first seed-forming plants had appeared. This rapid appearance of so many plant groups and growth forms has been called the "Devonian Explosion".

The 'greening' of the continents acted as a carbon sink, and atmospheric concentrations of carbon dioxide may have dropped. This may have cooled the climate and led to a massive extinction event. See Late Devonian extinction.

Primitive arthropods co-evolved with this diversified terrestrial vegetation structure. The evolving co-dependence of insects and seed-plants that characterised a recognisably modern world had its genesis in the Late Devonian period. The development of soils and plant root systems probably led to changes in the speed and pattern of erosion and sediment deposition. The rapid evolution of a terrestrial ecosystem that contained copious animals opened the way for the first vertebrates to seek out a terrestrial living. By the end of the Devonian, arthropods were solidly established on the land.

A major extinction occurred at the beginning of the last phase of the Devonian period, the Famennian faunal stage (the Frasnian-Famennian boundary), about Mya, when all the fossil agnathan fishes, save for the psammosteid heterostraci, suddenly disappeared. A second strong pulse closed the Devonian period. The Late Devonian extinction was one of five major extinction events in the history of the Earth's biota, and was more drastic than the familiar extinction event that closed the Cretaceous.

The Devonian extinction crisis primarily affected the marine community, and selectively affected shallow warm-water organisms rather than cool-water organisms. The most important group to be affected by this extinction event were the reef-builders of the great Devonian reef systems.

Amongst the severely affected marine groups were the brachiopods, trilobites, ammonites, conodonts, and acritarchs, as well as jawless fish, and all placoderms. Land plants as well as freshwater species, such as our tetrapod ancestors, were relatively unaffected by the Late Devonian extinction event (there is a counterargument that the Devonian extinctions nearly wiped out the tetrapods).

The reasons for the Late Devonian extinctions are still unknown, and all explanations remain speculative. Canadian paleontologist Digby McLaren suggested in 1969 that the Devonian extinction events were caused by an asteroid impact. However, while there were Late Devonian collision events (see the Alamo bolide impact), little evidence supports the existence of a large enough Devonian crater.

Categories:




</doc>
<doc id="7993" url="https://en.wikipedia.org/wiki?curid=7993" title="Dungeon Master (disambiguation)">
Dungeon Master (disambiguation)

A Dungeon Master is the organizer of a "Dungeons & Dragons" role-playing game.

Dungeon Master may also refer to:






</doc>
<doc id="7994" url="https://en.wikipedia.org/wiki?curid=7994" title="David Thompson (explorer)">
David Thompson (explorer)

David Thompson (30 April 1770 – 10 February 1857) was a British-Canadian fur trader, surveyor, and map-maker, known to some native peoples as "Koo-Koo-Sint" or "the Stargazer". Over Thompson's career, he travelled some across North America, mapping of North America along the way. For this historic feat, Thompson has been described as the "greatest land geographer who ever lived."

David Thompson was born in Westminster, Middlesex, to recent Welsh migrants David and Ann Thompson. When Thompson was two, his father died. Due to the financial hardship with his mother without resources, Thompson, 29 April 1777, the day before his seventh birthday , and his older brother were placed in the Grey Coat Hospital, a school for the disadvantaged of Westminster. Thompson graduated to the Grey Coat mathematical school, where he had received an education for the Royal Navy: including mathematics of trigonometry and geometry, practical navigation including using of nautical instruments, finding latitudes and longitudes and making navigational calculations from observing the sun, moon and tides and the drawing of maps and charts, taking land measurements and sketching landscapes. He later built on these to make his career. In 1784, at the age of 14, the Grey Coat treasurer paid the Hudson's Bay Company for the sum of five pounds, upon which Thompson became the company’s indentured servant for a period of seven years to be trained as a clerk. He set sail on 28 May of that year, and left England for North America.

On 2 September 1784, Thompson arrived in Churchill (now in Manitoba) and was put to work as a clerk/secretary, copying the personal papers of the governor of Fort Churchill, Samuel Hearne. The next year he was transferred to nearby York Factory, and over the next few years spent time as a secretary at Cumberland House, Saskatchewan, and South Branch House before arriving at Manchester House in 1787. During those years he learned to keep accounts and other records, calculate values of furs (It was noted that he also had several expensive beaver pelts at that time even when a secretary's job would not pay terribly well), track supplies and other duties.

On 23 December 1788, Thompson seriously fractured his tibia, forcing him to spend the next two winters at Cumberland House convalescing. It was during this time that he greatly refined and expanded his mathematical, astronomical, and surveying skills under the tutelage of Hudson's Bay Company surveyor Philip Turnor. It was also during this time that he lost sight in his right eye.

In 1790, with his apprenticeship nearing its end, Thompson requested a set of surveying tools in place of the typical parting gift of fine clothes offered by the company to those completing their indenture. He received both. He entered the employ of the Hudson's Bay Company as a fur trader. In 1792 he completed his first significant survey, mapping a route to Lake Athabasca (where today's Alberta/Saskatchewan border is located). In recognition of his map-making skills, the company promoted Thompson to surveyor in 1794. He continued working for the Hudson's Bay Company until 23 May 1797 when, frustrated with the Hudson's Bay Company's policies over promoting the use of alcohol with indigenous people in the fur trade, he left. He walked in the snow in order to enter the employ of the competition, the North West Company. There he continued to work as a fur trader and surveyor.

Thompson's decision to defect to the North West Company (NWC) in 1797 without providing the customary one-year notice was not well received by his former employers. But the North West Company was more supportive of Thompson pursuing his interest in surveying and work on mapping the interior of what was to become Canada, as they judged it in the company's long-term interest. In 1797, Thompson was sent south by his employers to survey part of the Canada-US boundary along the water routes from Lake Superior to Lake of the Woods to satisfy unresolved questions of territory arising from the Jay Treaty between Great Britain and the United States after the American Revolutionary War.

By 1798 Thompson had completed a survey of from Grand Portage, through Lake Winnipeg, to the headwaters of the Assiniboine and Mississippi rivers, as well as two sides of Lake Superior. In 1798, the company sent him to Red Deer Lake (Lac La Biche in present-day Alberta) to establish a trading post. (The English translation of Lac la Biche: Red Deer Lake, was first recorded on the Mackenzie map of 1793.) Thompson spent the next few seasons trading based in Fort George (now in Alberta), and during this time led several expeditions into the Rocky Mountains.

On 10 July 1804, at the annual meeting of the North West Company in Kaministiquia, Thompson was made a full partner of the company. He became a ‘wintering partner’, who was based in the field rather than Montreal, with two of the 92 NWC’s shares worth more than £4,000. He spent the next few seasons based there managing the fur trading operations but still finding time to expand his surveys of the waterways around Lake Superior. At the 1806 company meeting, officers decided to send Thompson back out into the interior. Concern over the American-backed expedition of Lewis and Clark prompted the North West Company to charge Thompson with the task of finding a route to the Pacific to open up the lucrative trading territories of the Pacific Northwest.

After the general meeting in 1806, Thompson travelled to Rocky Mountain House and prepared for an expedition to follow the Columbia River to the Pacific. In June 1807 Thompson crossed the Rocky Mountains and spent the summer surveying the Columbia basin; he continued to survey the area over the next few seasons. Thompson mapped and established trading posts in Northwestern Montana, Idaho, Washington, and Western Canada. Trading posts he founded included Kootenae House, Kullyspell House and Saleesh House; the latter two were the first trading posts west of the Rockies in Idaho and Montana, respectively. These posts established by Thompson extended North West Company fur trading territory into the Columbia Basin drainage area. The maps he made of the Columbia River basin east of the Cascade Mountains were of such high quality and detail that they continued to be regarded as authoritative well into the mid-20th century.

In early 1810, Thompson was returning eastward toward Montreal but, while en route at Rainy Lake, received orders to return to the Rocky Mountains and establish a route to the mouth of the Columbia. The North West Company was responding to the plans of American John Jacob Astor to send a ship around the Americas to establish a fur trading post of the Pacific Fur Company on the Pacific Coast. During his return, Thompson was delayed by an angry group of Peigan natives at Howse Pass. He was ultimately forced to seek a new route across the Rocky Mountains and found one through the Athabasca Pass.

David Thompson was the first European to navigate the full length of the Columbia River. During Thompson's 1811 voyage down the Columbia River, he camped at the junction with the Snake River on 9 July 1811. There he erected a pole and a notice claiming the country for Great Britain and stating the intention of the North West Company to build a trading post at the site. This notice was found later that year by Astor company workers looking to establish an inland fur post, contributing to their selection of a more northerly site at Fort Okanogan. The North West Company established its post of Fort Nez Percés near the Snake River confluence several years later. Continuing down the Columbia, Thompson passed the barrier of The Dalles with much less difficulty than that undergone by Lewis and Clark, as high water carried his boat over Celilo Falls and many of the rapids. On 14 July 1811, Thompson reached the partially constructed Fort Astoria at the mouth of the Columbia, arriving two months after the Pacific Fur Company's ship, the "Tonquin".

Before returning upriver and across the mountains, Thompson hired Naukane, a Native Hawaiian Takane labourer brought to Fort Astoria by the Pacific Fur Company's ship "Tonquin". Naukane, known as Coxe to Thompson, accompanied Thompson across the continent to Lake Superior before journeying on to England.

Thompson wintered at Saleesh House before beginning his final journey back to Montreal in 1812, where the North West Company was based.

In his published journals, Thompson recorded seeing large footprints near what is now Jasper, Alberta, in 1811. It has been suggested that these prints were similar to what has since been called the sasquatch. However, Thompson noted that these tracks showed "a small Nail at the end of each [toe]", and stated that these tracks "very much resembles a large Bear's Track".

In 1820, the English geologist, John Jeremiah Bigsby, attended a dinner party given by The Hon. William McGillivray at his home, Chateau St. Antoine, one of the early estates in Montreal's Golden Square Mile. He describes the party and some of the guests in his entertaining book "The Shoe and Canoe", giving an excellent description of David Thompson:

On 10 June 1799 at Île-à-la-Crosse, Thompson married Charlotte Small, a thirteen-year-old Métis daughter of Scottish fur trader Patrick Small and a Cree mother. Their marriage was formalised thirteen years later at the Scotch Presbyterian Church in Montreal on 30 October 1812. He and Charlotte had 13 children together; five of them were born before he left the fur trade. The family did not adjust easily to life in Eastern Canada; they lived in Montreal while he was traveling. Two of the children, John (aged 5) and Emma (aged 7), died of round worms, a common parasite. By the time of Thompson's death, the couple had been married 57 years, the longest marriage known in Canada pre-Confederation.

Upon his arrival back in Montreal, Thompson retired with a generous pension from the North West Company. He settled in nearby Terrebonne and worked on completing his great map, a summary of his lifetime of exploring and surveying the interior of North America. The map covered the wide area stretching from Lake Superior to the Pacific, and was given by Thompson to the North West Company. Thompson's 1814 map, his greatest achievement, was so accurate that 100 years later it was still the basis for many of the maps issued by the Canadian government. It now resides in the Archives of Ontario.

In 1815, Thompson moved his family to Williamstown, Upper Canada, and a few years later was employed to survey the newly established borders with the United States from Lake of the Woods to the Eastern Townships of Quebec, established by Treaty of Ghent after the War of 1812. In 1843 Thompson completed his atlas of the region from Hudson Bay to the Pacific Ocean.

Afterwards, Thompson returned to a life as a land owner, but soon financial misfortune would ruin him. By 1831 he was so deeply in debt he was forced to take up a position as a surveyor for the British American Land Company to provide for his family. His luck continued to worsen and he was forced to move in with his daughter and son-in-law in 1845. He began work on a manuscript chronicling his life exploring the continent, but this project was left unfinished when his sight failed him completely in 1851.

The land mass mapped by Thompson amounted to of wilderness (one-fifth of the continent). His contemporary, the great explorer Alexander Mackenzie, remarked that Thompson did more in ten months than he would have thought possible in two years.

Despite these significant achievements, Thompson died in Montreal in near obscurity on February 10, 1857, his accomplishments almost unrecognised. He never finished the book of his 28 years in the fur trade, based on his 77 field notebooks, before he died. In the 1890s geologist J.B. Tyrrell resurrected Thompson's notes and in 1916 published them as "David Thompson's Narrative", as part of the General Series of the Champlain Society. Further editions and re-examinations of Thompson's life and works were published in 1962 by Richard Glover, in 1971 by Victor Hopwood, and in 2015 by William Moreau.
Thompson's body was interred in Montreal's Mount Royal Cemetery in an unmarked grave. It was not until 1926 that efforts by J.B. Tyrrell and the Canadian Historical Society resulted in the placing of a tombstone to mark his grave. The next year, Thompson was named a National Historic Person by the federal government, one of the earliest such designations. A federal plaque reflecting that status is located at Jasper National Park, Alberta. Meantime, Thompson's achievements are central reasons for other national historic designations:

In 1957, one hundred years after his death, Canada's post office department honoured him with his image on a postage stamp. The David Thompson Highway in Alberta was named in his honour, along with David Thompson High School situated on the side of the highway near Leslieville, Alberta. His prowess as a geographer is now well-recognized. He has been called "the greatest land geographer that the world has produced."

There is a monument dedicated to David Thompson (maintained by the state of North Dakota) near the former town site of the ghost town, Verendrye, North Dakota, located approximately north and west of Karlsruhe, North Dakota. Thompson Falls, Montana, and British Columbia's Thompson River are also named after the explorer.
The year 2007 marked the 150th year of Thompson's death and the 200th anniversary of his first crossing of the Rocky Mountains. Commemorative events and exhibits were planned across Canada and the United States from 2007 to 2011 as a celebration of his accomplishments.

In 2007, a commemorative plaque was placed on a wall at the Grey Coat Hospital, the school for the disadvantaged of Westminster David Thompson attended as a boy, by English author and TV presenter Ray Mears.

Thompson was the subject of a 1964 National Film Board of Canada short film "David Thompson: The Great Mapmaker ", as well as the BBC2 programme "Ray Mears' Northern Wilderness" (Episode 5), broadcast in November 2009.

He is referenced in the 1981 folk song "Northwest Passage" by Stan Rogers.

The national park service, Parks Canada, announced in 2018 that it had named its new research vessel , to be used for underwater archaeology, including sea floor mapping, and for marine science in the Pacific, Atlantic, Arctic Oceans, and the Great Lakes. It will be the main platform for research on the Wrecks of HMS "Erebus" and HMS "Terror" National Historic Site.







</doc>
<doc id="7995" url="https://en.wikipedia.org/wiki?curid=7995" title="Dioscoreales">
Dioscoreales

The Dioscoreales are an order of monocotyledonous flowering plants in modern classification systems, such as the Angiosperm Phylogeny Group and the Angiosperm Phylogeny Web. Within the monocots Dioscoreales are grouped in the lilioid monocots where they are in a sister group relationship with the Pandanales. Of necessity the Dioscoreales contain the family Dioscoreaceae which includes the yam ("Dioscorea") that is used as an important food source in many regions around the globe. Older systems tended to place all lilioid monocots with reticulate veined leaves (such as Smilacaceae and Stemonaceae together with Dioscoraceae) in Dioscoreales. As currently circumscribed by phylogenetic analysis using combined morphology and molecular methods, Dioscreales contains many reticulate veined vines in Dioscoraceae, it also includes the myco-heterotrophic Burmanniaceae and the autotrophic Nartheciaceae. The order consists of three families, 22 genera and about 850 species.

Dioscoreales are vines or herbaceous forest floor plants. They may be achlorophyllous or saprophytic. Synapomorphies include tuberous roots, glandular hairs, seed coat characteristics and the presence of calcium oxalate crystals. Other characteristics of the order include the presence of saponin steroids, annular vascular bundles that are found in both the stem and leaf. The leaves are often unsheathed at the base, have a distinctive petiole and reticulate veined lamina. Alternatively they may be small and scale-like with a sheathed base. The flowers are actinomorphic, and may be bisexual or dioecious, while the flowers or inflorescence bear glandular hairs. The perianth may be conspicuous or reduced and the style is short with well developed style branches. The tepals persist in the development of the fruit, which is a dry capsule or berry. In the seed, the endotegmen is tanniferous and the embryo short.

All of the species except the genera placed in Nartheciaceae express simultaneous microsporogenesis. Plants in Nartheciaceae show successive microsporogenesis which is one of the traits indicating that the family is sister to all the other members included in the order.

For the early history from Lindley (1853) onwards, see Caddick "et al." (2000) Table 1, Caddick et al. (2002a) Table 1 and Table 2 in Bouman (1995). The taxonomic classification of Dioscoreales has been complicated by the presence of a number of morphological features reminiscent of the dicotyledons, leading some authors to place the order as intermediate between the monocotyledons and the dicotyledons.
While Lindley did not use the term "Dioscoreales", he placed the family Dioscoraceae together with four other families in what he referred to as an Alliance (the equivalent of the modern Order) called Dictyogens. He reflected the uncertainty as to the place of this Alliance by placing it as a class of its own between Endogens (monocots) and Exogens (dicots) The botanical authority is given to von Martius (1835) by APG for his description of the Dioscoreae family or "Ordo", while other sources cite Hooker (Dioscoreales Hook.f.) for his use of the term "Dioscorales" in 1873 with a single family, Dioscoreae. However, in his more definitive work, the "Genera plantara" (1883), he simply placed Dioscoraceae in the Epigynae "Series".

Although Charles Darwin's Origin of Species (1859) preceded Bentham and Hooker's publication, the latter project was commenced much earlier and George Bentham was initially sceptical of Darwinism. The new phyletic approach changed the way that taxonomists considered plant classification, incorporating evolutionary information into their schemata, but this did little to further define the circumscription of Dioscoreaceae. The major works in the late nineteenth and early twentieth century employing this approach were in the German literature. Authors such as Eichler, Engler and Wettstein placed this family in the Liliiflorae, a major subdivision of monocotyledons. it remained to Hutchinson (1926) to resurrect the Dioscoreales to group Dioscoreaceae and related families together. Hutchinson's circumscription of Dioscoreales included three other families in addition to Dioscoreaceae, Stenomeridaceae, Trichopodaceae and Roxburghiaceae. Of these only Trichopodaceae was included in the Angiosperm Phylogeny Group (APG) classification (see below), but was subsumed into Dioscoraceae. Stenomeridaceae, as "Stenomeris" was also included in Dioscoreaceae as subfamily Stenomeridoideae, the remaining genera being grouped in subfamily Dioscoreoideae. Roxburghiaceae on the other hand was segregated in the sister order Pandanales as Stemonaceae. Most taxonomists in the twentieth century (the exception was the 1981 Cronquist system which placed most such plants in order Liliales, subclass Liliidae, class Liliopsida=monocotyledons, division Magnoliophyta=angiosperms) recognised Dioscoreales as a distinct order, but demonstrated wide variations in its composition.

Dahlgren, in the second version of his taxonomic classification (1982) raised the Liliiflorae to a superorder and placed Dioscoreales as an order within it. In his system, Dioscoreales contained only three families, Dioscoreaceae, Stemonaceae ("i.e." Hutchinson's Roxburghiaceae) and Trilliaceae. The latter two families had been treated as a separate order (Stemonales, or Roxburghiales) by other authors, such as Huber (1969). The APG would later assign these to Pandanales and Liliales respectively. Dahlgren's construction of Dioscoreaceae included the Stenomeridaceae and Trichopodaceae, doubting these were distinct, and Croomiaceae in Stemonaceae. Furthermore, he expressed doubts about the order's homogeneity, especially Trilliaceae. The Dioscoreales at that time were marginally distinguishable from the Asparagales. In his examination of Huber's Stemonales, he found that the two constituent families had as close an affinity to Dioscoreaceae as to each other, and hence included them. He also considered closely related families and their relationship to Dioscoreales, such as the monogeneric Taccaceae, then in its own order, Taccales. Similar considerations were discussed with respect to two Asparagales families, Smilacaceae and Petermanniaceae.

In Dahlgren's third and final version (1985) that broader circumscription of Dioscoreales was created within the superorder Lilianae, subclass Liliidae (monocotyledons), class Magnoliopsida (angiosperms) and comprised the seven families Dioscoreaceae, Petermanniaceae, Smilacaceae, Stemonaceae, Taccaceae, Trichopodaceae and Trilliaceae. Thismiaceae has either been treated as a separate family closely related to Burmanniaceae or as a tribe (Thismieae) within a more broadly defined Burmanniaceae, forming a separate Burmanniales order in the Dahlgren system. The related Nartheciaceae were treated as tribe Narthecieae within the Melanthiaceae in a third order, the Melanthiales, by Dahlgren. Dahlgren considered the Dioscoreales to most strongly resemble the ancestral monocotyledons, and hence sharing "dicotyledonous" characteristics, making it the most central monocotyledon order. Of these seven families, Bouman considered Dioscoreaceae, Trichopodaceae, Stemonaceae and Taccaceae to represent the "core" families of the order. However, that study also indicated both a clear delineation of the order from other orders particularly Asparagales, and a lack of homogeneity within the order.

The increasing availability of molecular phylogenetics methods in addition to morphological characteristics in the 1990s led to major reconsiderations of the relationships within the monocotyledons. In that large multi-institutional examination of the seed plants using the plastid gene "rbc"L the authors used Dahlgren's system as their basis, but followed Thorne (1992) in altering the suffixes of the superorders from ""-iflorae"" to ""-anae"". This demonstrated that the Lilianae comprised three lineages corresponding to Dahlgren's
Dioscoreales, Liliales, and Asparagales orders.

Under the Angiosperm Phylogeny Group system of 1998, which took Dahlgren's system as a basis, the order was placed in the monocot clade and comprised the five families Burmanniaceae, Dioscoreaceae, Taccaceae, Thismiaceae and Trichopodaceae.

In APG II (2003), a number of changes were made to Dioscoreales, as a result of an extensive study by Caddick and colleagues (2002), using an analysis of three genes, "rbc"L, "atp"B and 18S rDNA, in addition to morphology. These studies resulted in a re-examination of the relationships between most of the genera within the order. Thismiaceae was shown to be a sister group to Burmanniaceae, and so was included in it. The monotypic families Taccaceae and Trichopodaceae were included in Dioscoreaceae, while Nartheciaceae could also be grouped within Dioscoreales. APG III (2009) did not change this, so the order now comprises three families Burmanniaceae, Dioscoreaceae and Nartheciaceae.

Although further research on the deeper relationships within Dioscoreales continues, the APG IV (2016) authors felt it was still premature to propose a restructuring of the order. Specifically these issues involve conflicting information as to the relationship between "Thismia" and Burmanniaceae, and hence whether Thismiaceae should be subsumed in the latter, or reinstated.

Molecular phylogenetics in Dioscoreales poses special problems due to the absence of plastid genes in mycoheterotrophs. Dioscoreales is monophyletic and is placed as a sister order to Pandanales, as shown in Cladogram I.

The data for the evolution of the order is collected from molecular analyses since there are no such fossils found. It is estimated that Dioscoreales and its sister clade Pandanales split up around 121 millions of years ago during Early Cretaceous when the stem group was formed. Then it took 3 to 6 millions of years for the crown group to differentiate in Mid Cretaceous.

The three families of Dioscreales constitutes about 22 genera and about 849 species making it one of the smaller monocot orders. Of these, the largest group is "Dioscorea" (yams) with about 450 species. By contrast the second largest genus is "Burmannia" with about 60 species, and most have only one or two.

Some authors, preferring the original APG (1998)families, continue to treat Thismiaceae separately from Burmanniaceae and Taccaceae from Dioscoreaceae. But in the 2015 study of Hertwerk and colleagues, seven genera representing all three families were examined with an eight gene dataset. Dioscoreales was monophyletic and three subclades were represented corresponding to the APG families. Dioscoreaceae and Burmanniaceae were in a sister group relationship.

Named after the type genus "Dioscorea", which in turn was named by Linnaeus in 1753 to honour the Greek physician and botanist Dioscorides.

Species from this order are distributed across all of the continents except Antarctica. They are mainly tropical or subtropical representatives but however there are members of Dioscoreaceae and Nartheciaceae families found in cooler regions of Europe and North America. Order Dioscoreales contains plants that are able to form an underground organ for reservation of nutritions as many other monocots. An exception is the family Burmanniaceae which is entirely myco-heterotrophic and contains species that lack photosynthetic abilities.

The three families included in order Dioscoreales also represent three different ecological groups of plants. Dioscoreaceae contains mainly vines ("Dioscorea") and other crawling species ("Epipetrum"). Nartheciaceae on the other hand is a family composed of herbaceous plants with a rather lily-like appearance ("Aletris") while Burmanniaceae is entirely myco-heterotrophic group.

Many members of Dioscoreaceae produce tuberous starchy roots (yams) which form staple foods in tropical regions. They have also been the source of steroids for the pharmaceutical industry, including the production of oral contraceptives.







</doc>
<doc id="8000" url="https://en.wikipedia.org/wiki?curid=8000" title="Default">
Default

Default may refer to:






</doc>
<doc id="8002" url="https://en.wikipedia.org/wiki?curid=8002" title="Deposition">
Deposition

Deposition may refer to:







</doc>
<doc id="8005" url="https://en.wikipedia.org/wiki?curid=8005" title="Dentistry">
Dentistry

Dentistry, also known as Dental and Oral Medicine, is a branch of medicine that consists of the study, diagnosis, prevention, and treatment of diseases, disorders, and conditions of the oral cavity, commonly in the dentition but also the oral mucosa, and of adjacent and related structures and tissues, particularly in the maxillofacial (jaw and facial) area. Although primarily associated with teeth among the general public, the field of dentistry or dental medicine is not limited to teeth but includes other aspects of the craniofacial complex including the temporomandibular joint and other supporting, muscular, lymphatic, nervous, vascular, and anatomical structures.

Dentistry is often also understood to subsume the now largely defunct medical specialty of stomatology (the study of the mouth and its disorders and diseases) for which reason the two terms are used interchangeably in certain regions.

Dental treatments are carried out by a dental team, which often consists of a dentist and dental auxiliaries (dental assistants, dental hygienists, dental technicians, as well as dental therapists). Most dentists either work in private practices (primary care), dental hospitals or (secondary care) institutions (prisons, armed forces bases, etc.).

The history of dentistry is almost as ancient as the history of humanity and civilization with the earliest evidence dating from 7000 BC. Remains from the early Harappan periods of the Indus Valley Civilization ( BC) show evidence of teeth having been drilled dating back 9,000 years. It is thought that dental surgery was the first specialization from medicine.

The term dentistry comes from "dentist", which comes from French "dentiste", which comes from the French and Latin words for tooth. The term for the associated scientific study of teeth is odontology (from Ancient Greek ὀδούς (odoús, "tooth")) – the study of the structure, development, and abnormalities of the teeth.

Dentistry usually encompasses practices related to the oral cavity. According to the World Health Organization, oral diseases are major public health problems due to their high incidence and prevalence across the globe, with the disadvantaged affected more than other socio-economic groups.

The majority of dental treatments are carried out to prevent or treat the two most common oral diseases which are dental caries (tooth decay) and periodontal disease (gum disease or pyorrhea). Common treatments involve the restoration of teeth, extraction or surgical removal of teeth, scaling and root planing and endodontic root canal treatment.

All dentists in the United States undergo at least three years of undergraduate studies, but nearly all complete a bachelor's degree. This schooling is followed by four years of dental school to qualify as a "Doctor of Dental Surgery" (DDS) or "Doctor of Dental Medicine" (DMD). Dentists need to complete additional qualifications or continuing education to carry out more complex treatments such as sedation, oral and maxillofacial surgery, and dental implants.

By nature of their general training they can carry out the majority of dental treatments such as restorative (fillings, crowns, bridges), prosthetic (dentures), endodontic (root canal) therapy, periodontal (gum) therapy, and extraction of teeth, as well as performing examinations, radiographs (x-rays), and diagnosis. Dentists can also prescribe medications such as antibiotics, sedatives, and any other drugs used in patient management.

Dentists also encourage prevention of oral diseases through proper hygiene and regular, twice yearly, checkups for professional cleaning and evaluation. Oral infections and inflammations may affect overall health and conditions in the oral cavity may be indicative of systemic diseases, such as osteoporosis, diabetes, celiac disease or cancer. Many studies have also shown that gum disease is associated with an increased risk of diabetes, heart disease, and preterm birth. The concept that oral health can affect systemic health and disease is referred to as "oral-systemic health".

Dr. John M. Harris started the world's first dental school in Bainbridge, Ohio, and helped to establish dentistry as a health profession. It opened on 21 February 1828, and today is a dental museum. The first dental college, Baltimore College of Dental Surgery, opened in Baltimore, Maryland, US in 1840. The second in the United States was the Ohio College of Dental Surgery, established in Cincinnati, Ohio, in 1845. The Philadelphia College of Dental Surgery followed in 1852. In 1907, Temple University accepted a bid to incorporate the school.

Studies show that dentists that graduated from different countries, or even from different dental schools in one country, may make different clinical decisions for the same clinical condition. For example, dentists that graduated from Israeli dental schools may recommend the removal of asymptomatic impacted third molar (wisdom teeth) more often than dentists that graduated from Latin American or Eastern European dental schools.

In the United Kingdom, the 1878 British Dentists Act and 1879 Dentists Register limited the title of "dentist" and "dental surgeon" to qualified and registered practitioners. However, others could legally describe themselves as "dental experts" or "dental consultants". The practice of dentistry in the United Kingdom became fully regulated with the 1921 Dentists Act, which required the registration of anyone practising dentistry. The British Dental Association, formed in 1880 with Sir John Tomes as president, played a major role in prosecuting dentists practising illegally. Dentists in the United Kingdom are now regulated by the General Dental Council.

In Korea, Taiwan, Japan, Finland, Sweden, Brazil, Chile, the United States, and Canada, a dentist is a healthcare professional qualified to practice dentistry after graduating with a degree of either Doctor of Dental Surgery (DDS) or Doctor of Dental Medicine (DMD). This is equivalent to the Bachelor of Dental Surgery/Baccalaureus Dentalis Chirurgiae (BDS, BDent, BChD, BDSc) that is awarded in the UK and British Commonwealth countries. In most western countries, to become a qualified dentist one must usually complete at least four years of postgraduate study; within the European Union the education has to be at least five years. Dentists usually complete between five and eight years of post-secondary education before practising. Though not mandatory, many dentists choose to complete an internship or residency focusing on specific aspects of dental care after they have received their dental degree.

Some dentists undertake further training after their initial degree in order to specialize. Exactly which subjects are recognized by dental registration bodies varies according to location. Examples include:


Tooth decay was low in pre-agricultural societies, but the advent of farming society about 10,000 years ago correlated with an increase in tooth decay (cavities). An infected tooth from Italy partially cleaned with flint tools, between 13,820 and 14,160 years old, represents the oldest known dentistry, although a 2017 study suggests that 130,000 years ago the Neanderthals already used rudimentary dentistry tools. The Indus Valley Civilization (IVC) has yielded evidence of dentistry being practised as far back as 7000 BC. An IVC site in Mehrgarh indicates that this form of dentistry involved curing tooth related disorders with bow drills operated, perhaps, by skilled bead crafters. The reconstruction of this ancient form of dentistry showed that the methods used were reliable and effective. The earliest dental filling, made of beeswax, was discovered in Slovenia and dates from 6500 years ago. Dentistry was practiced in prehistoric Malta, as evidenced by a skull which had an abscess lanced from the root of a tooth dating back to around 2500 BC.

An ancient Sumerian text describes a "tooth worm" as the cause of dental caries. Evidence of this belief has also been found in ancient India, Egypt, Japan, and China. The legend of the worm is also found in the writings of Homer, and as late as the 14th century AD the surgeon Guy de Chauliac still promoted the belief that worms cause tooth decay.

Recipes for the treatment of toothache, infections and loose teeth are spread throughout the Ebers Papyrus, Kahun Papyri, Brugsch Papyrus, and Hearst papyrus of Ancient Egypt. The Edwin Smith Papyrus, written in the 17th century BC but which may reflect previous manuscripts from as early as 3000 BC, discusses the treatment of dislocated or fractured jaws. In the 18th century BC, the Code of Hammurabi referenced dental extraction twice as it related to punishment. Examination of the remains of some ancient Egyptians and Greco-Romans reveals early attempts at dental prosthetics. However, it is possible the prosthetics were prepared after death for aesthetic reasons.

Ancient Greek scholars Hippocrates and Aristotle wrote about dentistry, including the eruption pattern of teeth, treating decayed teeth and gum disease, extracting teeth with forceps, and using wires to stabilize loose teeth and fractured jaws. Some say the first use of dental appliances or bridges comes from the Etruscans from as early as 700 BC. In ancient Egypt, Hesy-Ra is the first named "dentist" (greatest of the teeth). The Egyptians bound replacement teeth together with gold wire. Roman medical writer Cornelius Celsus wrote extensively of oral diseases as well as dental treatments such as narcotic-containing emollients and astringents. The earliest dental amalgams were first documented in a Tang Dynasty medical text written by the Chinese physician Su Kung in 659, and appeared in Germany in 1528.

During the Islamic Golden Age Dentistry was discussed in several famous books of medicine such as The Canon in medicine written by Avicenna and Al-Tasreef by Al-Zahrawi who is considered the greatest surgeon of the Middle ages, Avicenna said that jaw fracture should be reduced according to the occlusal guidance of the teeth; this principle is still valid in modern times. while Al-Zahrawi made a lot of surgical tools that resemble the modern tools.

Historically, dental extractions have been used to treat a variety of illnesses. During the Middle Ages and throughout the 19th century, dentistry was not a profession in itself, and often dental procedures were performed by barbers or general physicians. Barbers usually limited their practice to extracting teeth which alleviated pain and associated chronic tooth infection. Instruments used for dental extractions date back several centuries. In the 14th century, Guy de Chauliac most probably invented the dental pelican (resembling a pelican's beak) which was used to perform dental extractions up until the late 18th century. The pelican was replaced by the dental key which, in turn, was replaced by modern forceps in the 19th century.

The first book focused solely on dentistry was the "Artzney Buchlein" in 1530, and the first dental textbook written in English was called "Operator for the Teeth" by Charles Allen in 1685.

In the United Kingdom there was no formal qualification for the providers of dental treatment until 1859 and it was only in 1921 that the practice of dentistry was limited to those who were professionally qualified. The Royal Commission on the National Health Service in 1979 reported that there were then more than twice as many registered dentists per 10,000 population in the UK than there were in 1921.

It was between 1650 and 1800 that the science of modern dentistry developed. The English physician Thomas Browne in his "A Letter to a Friend" ( pub. 1690) made an early dental observation with characteristic humour:

The French surgeon Pierre Fauchard became known as the "father of modern dentistry". Despite the limitations of the primitive surgical instruments during the late 17th and early 18th century, Fauchard was a highly skilled surgeon who made remarkable improvisations of dental instruments, often adapting tools from watchmakers, jewelers and even barbers, that he thought could be used in dentistry. He introduced dental fillings as treatment for dental cavities. He asserted that sugar derivate acids like tartaric acid were responsible for dental decay, and also suggested that tumors surrounding the teeth and in the gums could appear in the later stages of tooth decay.

Fauchard was the pioneer of dental prosthesis, and he discovered many methods to replace lost teeth. He suggested that substitutes could be made from carved blocks of ivory or bone. He also introduced dental braces, although they were initially made of gold, he discovered that the teeth position could be corrected as the teeth would follow the pattern of the wires. Waxed linen or silk threads were usually employed to fasten the braces. His contributions to the world of dental science consist primarily of his 1728 publication Le chirurgien dentiste or The Surgeon Dentist. The French text included "basic oral anatomy and function, dental construction, and various operative and restorative techniques, and effectively separated dentistry from the wider category of surgery".

After Fauchard, the study of dentistry rapidly expanded. Two important books, "Natural History of Human Teeth" (1771) and "Practical Treatise on the Diseases of the Teeth" (1778), were published by British surgeon John Hunter. In 1763 he entered into a period of collaboration with the London-based dentist James Spence. He began to theorise about the possibility of tooth transplants from one person to another. He realised that the chances of an (initially, at least) successful tooth transplant would be improved if the donor tooth was as fresh as possible and was matched for size with the recipient. These principles are still used in the transplantation of internal organs. Hunter conducted a series of pioneering operations, in which he attempted a tooth transplant. Although the donated teeth never properly bonded with the recipients' gums, one of Hunter's patients stated that he had three which lasted for six years, a remarkable achievement for the period.

Major advances were made in the 19th century, and dentistry evolved from a trade to a profession. The profession came under government regulation by the end of the 19th century. In the UK the Dentist Act was passed in 1878 and the British Dental Association formed in 1879. In the same year, Francis Brodie Imlach was the first ever dentist to be elected President of the Royal College of Surgeons (Edinburgh), raising dentistry onto a par with clinical surgery for the first time.

Long term occupational noise exposure can contribute to permanent hearing loss, which is referred to as noise-induced hearing loss (NIHL) and tinnitus. Noise exposure can cause excessive stimulation of the hearing mechanism, which damages the delicate structures of the inner ear. NIHL can occur when an individual is exposed to sound levels above 90 dBA according to the Occupational Safety and Health Administration (OSHA). Regulations state that the permissible noise exposure levels for individuals is 90 dBA. For the National Institute for Occupational Safety and Health (NIOSH), exposure limits are set to 85 dBA. Exposures below 85 dBA are not considered to be hazardous. Time limits are placed on how long an individual can stay in an environment above 85 dBA before it causes hearing loss. OSHA places that limitation at 8 hours for 85 dBA. The exposure time becomes shorter as the dBA level increases.

Within the field of dentistry, a variety of cleaning tools are used including piezoelectric and sonic scalers, and ultrasonic scalers and cleaners. While a majority of the tools do not exceed 75 dBA, prolonged exposure over many years can lead to hearing loss or complaints of tinnitus. Few dentists have reported using personal hearing protective devices, which could offset any potential hearing loss or tinnitus.

Dentistry has been criticized for the lack of evidence or scientific principles behind its practices. Although medical schools are the center of medical research, many dental schools are not involved in research of any kind. In areas where research has been done, common practice often runs counter to the scientific conclusion. For example, evidence since 1977 has shown that seeing a dentist every six months, as is standard in the United States, is not associated with improved dental or oral health.. Many dentists agree that adults with good oral hygiene need to have a routine dental exam only once every 12 to 16 months.

Another problem is the relative overrepresentation of fraudulent dentistry practices when compared to similar fields. Patients often do not question information given them by a dentist, and dentists have taken advantage of this to treat patients with unneeded costly procedures. Some of the largest dentistry companies in the United States have been subject to class action lawsuits for their fraudulent practices. Dentists operate with very little oversight, compounding this problem. Evidence of fraudulent dental treatments date back to the 18th century.



</doc>
<doc id="8007" url="https://en.wikipedia.org/wiki?curid=8007" title="Diameter">
Diameter

In geometry, a diameter of a circle is any straight line segment that passes through the center of the circle and whose endpoints lie on the circle. It can also be defined as the longest chord of the circle. Both definitions are also valid for the diameter of a sphere.

In more modern usage, the length of a diameter is also called the diameter. In this sense one speaks of "the" diameter rather than "a" diameter (which refers to the line itself), because all diameters of a circle or sphere have the same length, this being twice the radius r.

For a convex shape in the plane, the diameter is defined to be the largest distance that can be formed between two opposite parallel lines tangent to its boundary, and the "width" is often defined to be the smallest such distance. Both quantities can be calculated efficiently using rotating calipers. For a curve of constant width such as the Reuleaux triangle, the width and diameter are the same because all such pairs of parallel tangent lines have the same distance.

For an ellipse, the standard terminology is different. A diameter of an ellipse is any chord passing through the center of the ellipse. For example, conjugate diameters have the property that a tangent line to the ellipse at the endpoint of one of them is parallel to the other one. The longest diameter is called the major axis.

The word "diameter" is derived from Greek διάμετρος ("diametros"), "diameter of a circle", from διά ("dia"), "across, through" and μέτρον ("metron"), "measure". It is often abbreviated DIA, dia, d, or ⌀.

The definitions given above are only valid for circles, spheres and convex shapes. However, they are special cases of a more general definition that is valid for any kind of "n"-dimensional convex or non-convex object, such as a hypercube or a set of scattered points. The diameter of a subset of a metric space is the least upper bound of the set of all distances between pairs of points in the subset. So, if "A" is the subset, the diameter is
If the distance function d is viewed here as having codomain R (the set of all real numbers), this implies that the diameter of the empty set (the case ) equals −∞ (negative infinity). Some authors prefer to treat the empty set as a special case, assigning it a diameter equal to 0, which corresponds to taking the codomain of d to be the set of nonnegative reals.

For any solid object or set of scattered points in n-dimensional Euclidean space, the diameter of the object or set is the same as the diameter of its convex hull. In medical parlance concerning a lesion or in geology concerning a rock, the diameter of an object is the supremum of the set of all distances between pairs of points in the object.

In differential geometry, the diameter is an important global Riemannian invariant.

In plane geometry, a diameter of a conic section is typically defined as any chord which passes through the conic's centre; such diameters are not necessarily of uniform length, except in the case of the circle, which has eccentricity "e" = 0.

The symbol or variable for diameter, ⌀, is similar in size and design to ø, the Latin small letter o with stroke. In Unicode it is defined as . On an Apple Macintosh, the diameter symbol can be entered via the character palette (this is opened by pressing in most applications), where it can be found in the Technical Symbols category.

The character will sometimes not display correctly, however, since many fonts do not include it. In many situations the letter ø (the Latin small letter o with stroke) is an acceptable substitute, which in Unicode is . It can be obtained in UNIX-like operating systems using a Compose key by pressing, in sequence, and on a Macintosh by pressing (the letter o, not the number 0).

In Microsoft Word the diameter symbol can be acquired by typing 2300 and then pressing Alt+X.

In LaTeX the diameter symbol can be obtained with the command codice_1 from the wasysym package.

The diameter symbol ⌀ is distinct from the empty set symbol ∅, from an (italic) uppercase phi "Φ", and from the Nordic vowel Ø. See also slashed zero.

In German, the diameter symbol (German "") is also used as an average symbol ("Durchschnittszeichen").


</doc>
<doc id="8008" url="https://en.wikipedia.org/wiki?curid=8008" title="Direct examination">
Direct examination

The direct examination or examination-in-chief is one stage in the process of adducing evidence from witnesses in a court of law. Direct examination is the questioning of a witness by the party who called him or her, in a trial. Direct examination is usually performed to elicit evidence in support of facts which will satisfy a required element of a party's claim or defense.

In direct examination, one is generally prohibited from asking leading questions. This prevents a lawyer from feeding answers to a favorable witness. An exception to this rule occurs if one side has called a witness, but it is either understood, or becomes clear, that the witness is hostile to the questioner's side of the controversy. The lawyer may then ask the court to declare the person he or she has called to the stand a hostile witness. If the court does so, the lawyer may thereafter ask witness leading questions during direct examination.

The techniques of direct examination are taught in courses on trial advocacy. Each direct examination is integrated with the overall case strategy through either a theme and theory or, with more advanced strategies, a line of effort.


Nig


</doc>
<doc id="8011" url="https://en.wikipedia.org/wiki?curid=8011" title="Alcohol intoxication">
Alcohol intoxication

Alcohol intoxication, also known as drunkenness or alcohol poisoning, is the negative behavior and physical effects due to the recent drinking of ethanol (alcohol). Symptoms at lower doses may include mild sedation and poor coordination. At higher doses, there may be slurred speech, trouble walking, and vomiting. Extreme doses may result in a decreased effort to breathe (respiratory depression), coma, or death. Complications may include seizures, aspiration pneumonia, injuries including suicide, and low blood sugar.
Alcohol intoxication typically begins after two or more alcoholic drinks. Risk factors include a social situation where heavy drinking is common and a person having an impulsive personality. Diagnosis is usually based on the history of events and physical examination. Verification of events by the people a person was with may be useful. Legally, alcohol intoxication is often defined as a blood alcohol concentration (BAC) of greater than 5.4-17.4 mmol/L (25–80 mg/dL or 0.025-0.080%). This can be measured by blood or breath testing. Alcohol is then broken down at a rate of about 3.3 mmol/L (15 mg/dL) per hour.
Management of alcohol intoxication involves supportive care. Typically this includes putting the person in the recovery position, keeping them warm, and making sure they are breathing sufficiently. Gastric lavage and activated charcoal have not been found to be useful. Repeated assessments may be required to rule out other potential causes of a person's symptoms.
Alcohol intoxication is very common, especially in the Western world. Most people who drink alcohol have at some time been intoxicated. In the United States acute intoxication directly results in about 2,200 deaths per year, and indirectly more than 30,000 deaths per year. Acute intoxication has been documented throughout history and alcohol remains one of the world's most widespread recreational drugs. Some religions consider alcohol intoxication to be a sin.

Alcohol intoxication is the negative health effects due to the recent drinking of ethanol (alcohol). When severe it may become a medical emergency. Some effects of alcohol intoxication, such as euphoria and lowered social inhibition, are central to alcohol's desirability.

The signs and symptoms of acute alcohol poisoning include:


Alcohol is metabolized by a normal liver at the rate of about 8 grams of pure ethanol per hour. 8 grams or is one British standard unit. An "abnormal" liver with conditions such as hepatitis, cirrhosis, gall bladder disease, and cancer is likely to result in a slower rate of metabolism.
Ethanol is metabolised to acetaldehyde by alcohol dehydrogenase (ADH), which is found in many tissues, including the gastric mucosa. Acetaldehyde is metabolised to acetate by acetaldehyde dehydrogenase (ALDH), which is found predominantly in liver mitochondria. Acetate is used by the muscle cells to produce acetyl-CoA using the enzyme acetyl-CoA synthetase, and the acetyl-CoA is then used in the citric acid cycle.

Ethanol's acute effects are due largely to its nature as a central nervous system depressant, and are dependent on blood alcohol concentrations:


As drinking increases, people become sleepy, or fall into a stupor. After a very high level of consumption, the respiratory system becomes depressed and the person will stop breathing. Comatose patients may aspirate their vomit (resulting in vomitus in the lungs, which may cause "drowning" and later pneumonia if survived). CNS depression and impaired motor co-ordination along with poor judgment increases the likelihood of accidental injury occurring. It is estimated that about one-third of alcohol-related deaths are due to accidents and another 14% are from intentional injury.

In addition to respiratory failure and accidents caused by effects on the central nervous system, alcohol causes significant metabolic derangements. Hypoglycaemia occurs due to ethanol's inhibition of gluconeogenesis, especially in children, and may cause lactic acidosis, ketoacidosis, and acute renal failure. Metabolic acidosis is compounded by respiratory failure. Patients may also present with hypothermia.

In the past, alcohol was believed to be a non-specific pharmacological agent affecting many neurotransmitter systems in the brain. However, molecular pharmacology studies have shown that alcohol has only a few primary targets. In some systems, these effects are facilitatory and in others inhibitory.

Among the neurotransmitter systems with enhanced functions are: GABA, 5-HT receptor agonism (responsible for GABAergic (GABA receptor PAM), glycinergic, and cholinergic effects), nicotinic acetylcholine receptors.

Among those that are inhibited are: NMDA, dihydropyridine-sensitive L-type Ca2+ channels and G-protein-activated inwardly rectifying K+ channels.

The result of these direct effects is a wave of further indirect effects involving a variety of other neurotransmitter and neuropeptide systems, leading finally to the behavioural or symptomatic effects of alcohol intoxication.

Many of the effects of activating GABA receptors have the same effects as that of ethanol consumption. Some of these effects include anxiolytic, anticonvulsant, sedative, and hypnotic effects, cognitive impairment, and motor incoordination. This correlation between activating GABA receptors and the effects of ethanol consumption has led to the study of ethanol and its effects on GABA receptors. It has been shown that ethanol does in fact exhibit positive allosteric binding properties to GABA receptors. However, its effects are limited to pentamers containing the δ-subunit rather than the γ-subunit. GABA receptors containing the δ-subunit have been shown to be located exterior to the synapse and are involved with tonic inhibition rather than its γ-subunit counterpart, which is involved in phasic inhibition. The δ-subunit has been shown to be able to form the allosteric binding site which makes GABA receptors containing the δ-subunit more sensitive to ethanol concentrations, even to moderate social ethanol consumption levels (30mM). While it has been shown by Santhakumar et al. that GABA receptors containing the δ-subunit are sensitive to ethanol modulation, depending on subunit combinations receptors, could be more or less sensitive to ethanol. It has been shown that GABA receptors that contain both δ and β3-subunits display increased sensitivity to ethanol. One such receptor that exhibits ethanol insensitivity is α3-β6-δ GABA. It has also been shown that subunit combination is not the only thing that contributes to ethanol sensitivity. Location of GABA receptors within the synapse may also contribute to ethanol sensitivity.

Definitive diagnosis relies on a blood test for alcohol, usually performed as part of a toxicology screen. Law enforcement officers in the United States and other countries often use breathalyzer units and field sobriety tests as more convenient and rapid alternatives to blood tests. There are also various models of breathalyzer units that are available for consumer use. Because these may have varying reliability and may produce different results than the tests used for law-enforcement purposes, the results from such devices should be conservatively interpreted.

Many informal intoxication tests exist, which, in general, are unreliable and not recommended as deterrents to excessive intoxication or as indicators of the safety of activities such as motor vehicle driving, heavy equipment operation, machine tool use, etc.

For determining whether someone is intoxicated by alcohol by some means other than a blood-alcohol test, it is necessary to rule out other conditions such as hypoglycemia, stroke, usage of other intoxicants, mental health issues, and so on. It is best if his / her behavior has been observed while the subject is sober to establish a baseline. Several well-known criteria can be used to establish a probable diagnosis. For a physician in the acute-treatment setting, acute alcohol intoxication can mimic other acute neurological disorders, or is frequently combined with other recreational drugs that complicate diagnosis and treatment.

Acute alcohol poisoning is a medical emergency due to the risk of death from respiratory depression or aspiration of vomit if vomiting occurs while the person is unresponsive. Emergency treatment strives to stabilize and maintain an open airway and sufficient breathing, while waiting for the alcohol to metabolize. This can be done by removal of any vomitus or, if the person is unconscious or has impaired gag reflex, intubation of the trachea.

Other measures may include
Additional medication may be indicated for treatment of nausea, tremor, and anxiety.

A normal liver detoxifies the blood of alcohol over a period of time that depends on the initial level and the patient's overall physical condition. An abnormal liver will take longer but still succeeds, provided the alcohol does not cause liver failure.

People having drunk heavily for several days or weeks may have withdrawal symptoms after the acute intoxication has subsided.

A person consuming a dangerous amount of alcohol persistently can develop memory blackouts and idiosyncratic intoxication or pathological drunkenness symptoms.

Long-term persistent consumption of excessive amounts of alcohol can cause liver damage and have other deleterious health effects.

Alcohol intoxication is a risk factor in some cases of catastrophic injury, in particular for unsupervised recreational activity. A study in the province of Ontario based on epidemiological data from 1986, 1989, 1992, and 1995 states that 79.2% of the 2,154 catastrophic injuries recorded for the study were preventable, of which 346 involved alcohol consumption. The activities most commonly associated with alcohol-related catastrophic injury were snowmobiling (124), fishing (41), diving (40), boating (31) and canoeing (7), swimming (31), riding an all-terrain vehicle (24), and cycling (23). These events are often associated with unsupervised young males, often inexperienced in the activity, and many result in drowning. Alcohol use is also associated with unsafe sex.

Laws on drunkenness vary. In the United States, it is a criminal offense for a person to be drunk while driving a motorized vehicle, except in Wisconsin, where it is only a fine for the first offense. It is also a criminal offense to fly an aircraft or (in some American states) to assemble or operate an amusement park ride while drunk. Similar laws also exist in the United Kingdom and most other countries.

In some countries, it is also an offense to serve alcohol to an already-intoxicated person, and, often, alcohol can be sold only by persons qualified to serve responsibly through alcohol server training.

The (BAC) for legal operation of a vehicle is typically measured as a percentage of a unit volume of blood. This percentage ranges from 0.00% in Romania and the United Arab Emirates; to 0.05% in Australia, South Africa, Germany, Scotland and New Zealand (0.00% for underage individuals); to 0.08% in England and Wales, the United States (0.00% for underaged individuals) and Canada.

The United States Federal Aviation Administration prohibits crew members from performing their duties within eight hours of consuming an alcoholic beverage, while under the influence of alcohol, or with a BAC greater than 0.04%.

In the United States, the United Kingdom, and Australia, public intoxication is a crime (also known as "being drunk and disorderly" or "being drunk and incapable").

In some countries, there are special facilities, sometimes known as "drunk tanks", for the temporary detention of persons found to be drunk.

Some religious groups permit the consumption of alcohol. Some permit consumption but prohibit intoxication, while others prohibit alcohol consumption altogether. Many Christian denominations such as Catholic, Orthodox, and Lutheran use wine as a part of the Eucharist and permit the drinking of alcohol but consider it sinful to become intoxicated.

In the Bible, the Book of Proverbs contains several chapters dealing with the bad effects of drunkenness and warning to stay away from intoxicating beverages. The book of Leviticus tells of Nadab and Abihu, Aaron the Priest's eldest sons, who were killed for serving in the temple after drinking wine, presumably while intoxicated. The book continues to discuss monasticism where drinking wine is prohibited. The story of Samson in the Book of Judges tells of a monk from the tribe of Dan who is prohibited from cutting his hair and drinking wine. Romans 13:13–14, 1 Corinthians 6:9–11, Galatians 5:19–21, and Ephesians 5:18 are among a number of other Bible passages that speak against drunkenness. While Proverbs 31:4, warns against kings and rulers drinking wine and strong drink, Proverbs 31:6–7 promotes giving strong drink to the perishing and wine to those whose lives are bitter, to forget their poverty and troubles.

Some Protestant Christian denominations prohibit the drinking of alcohol based upon Biblical passages that condemn drunkenness, but others allow moderate use of alcohol. In some Christian groups, a small amount of wine is part of the rite of communion.

In the Church of Jesus Christ of Latter-day Saints, alcohol consumption is forbidden, and teetotalism has become a distinguishing feature of its members. Jehovah's Witnesses allow moderate alcohol consumption among its members.

In the Qur'an, there is a prohibition on the consumption of grape-based alcoholic beverages, and intoxication is considered as an abomination in the Hadith. Islamic schools of law (Madh'hab) have interpreted this as a strict prohibition of the consumption of all types of alcohol and declared it to be haraam ("forbidden"), although other uses may be permitted.

In Buddhism, in general, the consumption of intoxicants is discouraged for both monastics and lay followers. Many followers of Buddhism observe a code of conduct known as the five precepts, of which the fifth precept is an undertaking to refrain from the consumption of intoxicating substances (except for medical reasons). In the "bodhisattva" vows of the "Brahma Net Sūtra", observed by Mahāyāna Buddhist communities, distribution of intoxicants is likewise discouraged, as well as consumption.

In the branch of Hinduism known as Gaudiya Vaishnavism, one of the four regulative principles forbids the taking of intoxicants, including alcohol.

In Judaism, in accordance with the biblical stance against drinking, wine drinking was not permitted for priests and monks The biblical command to sanctify the Sabbath day and other holidays has been interpreted as having three ceremonial meals which include drinking of wine, the Kiddush. The Jewish marriage ceremony ends with the bride and groom drinking a shared cup of wine after reciting seven blessings, and according to western "Ashkenazi" traditions, after a fast day. But it has been customary and in many cases even mandated to drink moderately so as to stay sober, and only after the prayers are over.

During the Seder night on Passover (Pesach) there is an obligation to drink 4 ceremonial cups of wine, while reciting the Haggadah. It has been assumed as the source for the wine drinking ritual at the communion in some Christian groups. During Purim there is an obligation to become intoxicated, although, as with many other decrees, in many communities this has been avoided, by allowing sleep during the day to replace it.

In the 1920s due to the new beverages law, a rabbi from the Reform Judaism movement proposed using grape-juice for the ritual instead of wine. Although refuted at first, the practice became widely accepted by orthodox Jews as well.

At the Cave of the Patriarchs in Hebron—the Ibrahimi Mosque as it is called by the Muslims, the Jewish wine drinking rituals during weddings, the Sabbath day and holidays, are a cause for tension with the Muslims who unwillingly share the site under Israeli authority.

In the movie "Animals are Beautiful People", an entire section was dedicated to showing many different animals including monkeys, elephants, hogs, giraffes, and ostriches, eating over-ripe marula tree fruit causing them to sway and lose their footing in a manner similar to human drunkenness. Birds may become intoxicated with fermented berries and some die colliding with hard objects when flying under the influence.

In elephant warfare, practiced by the Greeks during the Maccabean revolt and by Hannibal during the Punic wars, it has been recorded that the elephants would be given wine before the attack, and only then would they charge forward after being agitated by their driver.

It is a regular practice to give small amounts of beer to race horses in Ireland. Ruminant farm animals have natural fermentation occurring in their stomach, and adding alcoholic beverages in small amounts to their drink will generally do them no harm, and will not cause them to become drunk.




</doc>
<doc id="8013" url="https://en.wikipedia.org/wiki?curid=8013" title="Data compression">
Data compression

In signal processing, data compression, source coding, or bit-rate reduction involves encoding information using fewer bits than the original representation. Compression can be either lossy or lossless. Lossless compression reduces bits by identifying and eliminating statistical redundancy. No information is lost in lossless compression. Lossy compression reduces bits by removing unnecessary or less important information.

The process of reducing the size of a data file is often referred to as data compression. In the context of data transmission, it is called source coding; encoding done at the source of the data before it is stored or transmitted. Source coding should not be confused with channel coding, for error detection and correction or line coding, the means for mapping data onto a signal.

Compression is useful because it reduces resources required to store and transmit data. Computational resources are consumed in the compression process and, usually, in the reversal of the process (decompression). Data compression is subject to a space–time complexity trade-off. For instance, a compression scheme for video may require expensive hardware for the video to be decompressed fast enough to be viewed as it is being decompressed, and the option to decompress the video in full before watching it may be inconvenient or require additional storage. The design of data compression schemes involves trade-offs among various factors, including the degree of compression, the amount of distortion introduced (when using lossy data compression), and the computational resources required to compress and decompress the data.

Lossless data compression algorithms usually exploit statistical redundancy to represent data without losing any information, so that the process is reversible. Lossless compression is possible because most real-world data exhibits statistical redundancy. For example, an image may have areas of color that do not change over several pixels; instead of coding "red pixel, red pixel, ..." the data may be encoded as "279 red pixels". This is a basic example of run-length encoding; there are many schemes to reduce file size by eliminating redundancy.

The Lempel–Ziv (LZ) compression methods are among the most popular algorithms for lossless storage. DEFLATE is a variation on LZ optimized for decompression speed and compression ratio, but compression can be slow. In the mid-1980s, following work by Terry Welch, the Lempel–Ziv–Welch (LZW) algorithm rapidly became the method of choice for most general-purpose compression systems. LZW is used in GIF images, programs such as PKZIP, and hardware devices such as modems. LZ methods use a table-based compression model where table entries are substituted for repeated strings of data. For most LZ methods, this table is generated dynamically from earlier data in the input. The table itself is often Huffman encoded. Grammar-based codes like this can compress highly repetitive input extremely effectively, for instance, a biological data collection of the same or closely related species, a huge versioned document collection, internet archival, etc. The basic task of grammar-based codes is constructing a context-free grammar deriving a single string. Other practical grammar compression algorithms include Sequitur and Re-Pair.

The strongest modern lossless compressors use probabilistic models, such as prediction by partial matching. The Burrows–Wheeler transform can also be viewed as an indirect form of statistical modelling. In a further refinement of the direct use of probabilistic modelling, statistical estimates can be coupled to an algorithm called arithmetic coding. Arithmetic coding is a more modern coding technique that uses the mathematical calculations of a finite-state machine to produce a string of encoded bits from a series of input data symbols. It can achieve superior compression compared to other techniques such as the better-known Huffman algorithm. It uses an internal memory state to avoid the need to perform a one-to-one mapping of individual input symbols to distinct representations that use an integer number of bits, and it clears out the internal memory only after encoding the entire string of data symbols. Arithmetic coding applies especially well to adaptive data compression tasks where the statistics vary and are context-dependent, as it can be easily coupled with an adaptive model of the probability distribution of the input data. An early example of the use of arithmetic coding was in an optional (but not widely used) feature of the JPEG image coding standard. It has since been applied in various other designs including H.263, H.264/MPEG-4 AVC and HEVC for video coding.

In the late 1980s, digital images became more common, and standards for lossless image compression emerged. In the early 1990s, lossy compression methods began to be widely used. In these schemes, some loss of information is accepted as dropping nonessential detail can save storage space. There is a corresponding trade-off between preserving information and reducing size. Lossy data compression schemes are designed by research on how people perceive the data in question. For example, the human eye is more sensitive to subtle variations in luminance than it is to the variations in color. JPEG image compression works in part by rounding off nonessential bits of information. A number of popular compression formats exploit these perceptual differences, including psychoacoustics for sound, and psychovisuals for images and video.

Lossy image compression is used in digital cameras, to increase storage capacities. Similarly, DVDs, Blu-ray and streaming video use the lossy video coding format.

In lossy audio compression, methods of psychoacoustics are used to remove non-audible (or less audible) components of the audio signal. Compression of human speech is often performed with even more specialized techniques; speech coding is distinguished as a separate discipline from general-purpose audio compression. Speech coding is used in internet telephony, for example, audio compression is used for CD ripping and is decoded by the audio players.

The theoretical background of compression is provided by information theory (which is closely related to algorithmic information theory) for lossless compression and rate–distortion theory for lossy compression. These areas of study were essentially created by Claude Shannon, who published fundamental papers on the topic in the late 1940s and early 1950s. Coding theory is also related to this. The idea of data compression is also deeply connected with statistical inference.

There is a close connection between machine learning and compression: a system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution) while an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for "general intelligence."

However a new, alternative view can show compression algorithms implicitly map strings into implicit feature space vectors, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponds to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.

Data compression can be viewed as a special case of data differencing: Data differencing consists of producing a "difference" given a "source" and a "target," with patching producing a "target" given a "source" and a "difference," while data compression consists of producing a compressed file given a target, and decompression consists of producing a target given only a compressed file. Thus, one can consider data compression as data differencing with empty source data, the compressed file corresponding to a "difference from nothing." This is the same as considering absolute entropy (corresponding to data compression) as a special case of relative entropy (corresponding to data differencing) with no initial data.

When one wishes to emphasize the connection, one may use the term "differential compression" to refer to data differencing.

Audio data compression, not to be confused with dynamic range compression, has the potential to reduce the transmission bandwidth and storage requirements of audio data. Audio compression algorithms are implemented in software as audio codecs. Lossy audio compression algorithms provide higher compression at the cost of fidelity and are used in numerous audio applications. These algorithms almost all rely on psychoacoustics to eliminate or reduce fidelity of less audible sounds, thereby reducing the space required to store or transmit them.

In both lossy and lossless compression, information redundancy is reduced, using methods such as coding, pattern recognition, and linear prediction to reduce the amount of information used to represent the uncompressed data.

The acceptable trade-off between loss of audio quality and transmission or storage size depends upon the application. For example, one 640 MB compact disc (CD) holds approximately one hour of uncompressed high fidelity music, less than 2 hours of music compressed losslessly, or 7 hours of music compressed in the MP3 format at a medium bit rate. A digital sound recorder can typically store around 200 hours of clearly intelligible speech in 640 MB.

Lossless audio compression produces a representation of digital data that decompress to an exact digital duplicate of the original audio stream, unlike playback from lossy compression techniques such as Vorbis and MP3. Compression ratios are around 50–60% of original size, which is similar to those for generic lossless data compression. Lossless compression is unable to attain high compression ratios due to the complexity of waveforms and the rapid changes in sound forms. Codecs like FLAC, Shorten, and TTA use linear prediction to estimate the spectrum of the signal. Many of these algorithms use convolution with the filter [-1 1] to slightly whiten or flatten the spectrum, thereby allowing traditional lossless compression to work more efficiently. The process is reversed upon decompression.

When audio files are to be processed, either by further compression or for editing, it is desirable to work from an unchanged original (uncompressed or losslessly compressed). Processing of a lossily compressed file for some purpose usually produces a final result inferior to the creation of the same compressed file from an uncompressed original. In addition to sound editing or mixing, lossless audio compression is often used for archival storage, or as master copies.

A number of lossless audio compression formats exist. Shorten was an early lossless format. Newer ones include Free Lossless Audio Codec (FLAC), Apple's Apple Lossless (ALAC), MPEG-4 ALS, Microsoft's Windows Media Audio 9 Lossless (WMA Lossless), Monkey's Audio, TTA, and WavPack. See list of lossless codecs for a complete listing.

Some audio formats feature a combination of a lossy format and a lossless correction; this allows stripping the correction to easily obtain a lossy file. Such formats include MPEG-4 SLS (Scalable to Lossless), WavPack, and OptimFROG DualStream.

Other formats are associated with a distinct system, such as:

Lossy audio compression is used in a wide range of applications. In addition to the direct applications (MP3 players or computers), digitally compressed audio streams are used in most video DVDs, digital television, streaming media on the internet, satellite and cable radio, and increasingly in terrestrial radio broadcasts. Lossy compression typically achieves far greater compression than lossless compression (5–20% of the original size, rather than 50–60%), by discarding less-critical data.

The innovation of lossy audio compression was to use psychoacoustics to recognize that not all data in an audio stream can be perceived by the human auditory system. Most lossy compression reduces perceptual redundancy by first identifying perceptually irrelevant sounds, that is, sounds that are very hard to hear. Typical examples include high frequencies or sounds that occur at the same time as louder sounds. Those sounds are coded with decreased accuracy or not at all.

Due to the nature of lossy algorithms, audio quality suffers when a file is decompressed and recompressed (digital generation loss). This makes lossy compression unsuitable for storing the intermediate results in professional audio engineering applications, such as sound editing and multitrack recording. However, they are very popular with end users (particularly MP3) as a megabyte can store about a minute's worth of music at adequate quality.

To determine what information in an audio signal is perceptually irrelevant, most lossy compression algorithms use transforms such as the modified discrete cosine transform (MDCT) to convert time domain sampled waveforms into a transform domain. Once transformed, typically into the frequency domain, component frequencies can be allocated bits according to how audible they are. Audibility of spectral components calculated using the absolute threshold of hearing and the principles of simultaneous masking—the phenomenon wherein a signal is masked by another signal separated by frequency—and, in some cases, temporal masking—where a signal is masked by another signal separated by time. Equal-loudness contours may also be used to weight the perceptual importance of components. Models of the human ear-brain combination incorporating such effects are often called psychoacoustic models.

Other types of lossy compressors, such as the linear predictive coding (LPC) used with speech, are source-based coders. These coders use a model of the sound's generator (such as the human vocal tract with LPC) to whiten the audio signal (i.e., flatten its spectrum) before quantization. LPC may be thought of as a basic perceptual coding technique: reconstruction of an audio signal using a linear predictor shapes the coder's quantization noise into the spectrum of the target signal, partially masking it.

Lossy formats are often used for the distribution of streaming audio or interactive applications (such as the coding of speech for digital transmission in cell phone networks). In such applications, the data must be decompressed as the data flows, rather than after the entire data stream has been transmitted. Not all audio codecs can be used for streaming applications, and for such applications a codec designed to stream data effectively will usually be chosen.

Latency results from the methods used to encode and decode the data. Some codecs will analyze a longer segment of the data to optimize efficiency, and then code it in a manner that requires a larger segment of data at one time to decode. (Often codecs create segments called a "frame" to create discrete data segments for encoding and decoding.) The inherent latency of the coding algorithm can be critical; for example, when there is a two-way transmission of data, such as with a telephone conversation, significant delays may seriously degrade the perceived quality.

In contrast to the speed of compression, which is proportional to the number of operations required by the algorithm, here latency refers to the number of samples that must be analysed before a block of audio is processed. In the minimum case, latency is zero samples (e.g., if the coder/decoder simply reduces the number of bits used to quantize the signal). Time domain algorithms such as LPC also often have low latencies, hence their popularity in speech coding for telephony. In algorithms such as MP3, however, a large number of samples have to be analyzed to implement a psychoacoustic model in the frequency domain, and latency is on the order of 23 ms (46 ms for two-way communication)).

Speech encoding is an important category of audio data compression. The perceptual models used to estimate what a human ear can hear are generally somewhat different from those used for music. The range of frequencies needed to convey the sounds of a human voice are normally far narrower than that needed for music, and the sound is normally less complex. As a result, speech can be encoded at high quality using a relatively low bit rate.

If the data to be compressed is analog (such as a voltage that varies with time), quantization is employed to digitize it into numbers (normally integers). This is referred to as analog-to-digital (A/D) conversion. If the integers generated by quantization are 8 bits each, then the entire range of the analog signal is divided into 256 intervals and all the signal values within an interval are quantized to the same number. If 16-bit integers are generated, then the range of the analog signal is divided into 65,536 intervals.

This relation illustrates the compromise between high resolution (a large number of analog intervals) and high compression (small integers generated). This application of quantization is used by several speech compression methods. This is accomplished, in general, by some combination of two approaches:

Perhaps the earliest algorithms used in speech encoding (and audio data compression in general) were the A-law algorithm and the µ-law algorithm.

A literature compendium for a large variety of audio coding systems was published in the IEEE Journal on Selected Areas in Communications (JSAC), February 1988. While there were some papers from before that time, this collection documented an entire variety of finished, working audio coders, nearly all of them using perceptual (i.e. masking) techniques and some kind of frequency analysis and back-end noiseless coding. Several of these papers remarked on the difficulty of obtaining good, clean digital audio for research purposes. Most, if not all, of the authors in the JSAC edition were also active in the MPEG-1 Audio committee.

The world's first commercial broadcast automation audio compression system was developed by Oscar Bonello, an engineering professor at the University of Buenos Aires. In 1983, using the psychoacoustic principle of the masking of critical bands first published in 1967, he started developing a practical application based on the recently developed IBM PC computer, and the broadcast automation system was launched in 1987 under the name Audicom. Twenty years later, almost all the radio stations in the world were using similar technology manufactured by a number of companies.

Video compression is a practical implementation of source coding in information theory. In practice, most video codecs are used alongside audio compression techniques to store the separate but complementary data streams as one combined package using so-called "container formats".

Uncompressed video requires a very high data rate. Although lossless video compression codecs perform at a compression factor of 5 to 12, a typical H.264 lossy compression video has a compression factor between 20 and 200.

Video data may be represented as a series of still image frames. Such data usually contains abundant amounts of spatial and temporal redundancy. Video compression algorithms attempt to reduce redundancy and store information more compactly.

Most video compression formats and codecs exploit both spatial and temporal redundancy (e.g. through difference coding with motion compensation). Similarities can be encoded by only storing differences between e.g. temporally adjacent frames (inter-frame coding) or spatially adjacent pixels (intra-frame coding).
Inter-frame compression (a temporal delta encoding) is one of the most powerful compression techniques. It (re)uses data from one or more earlier or later frames in a sequence to describe the current frame. Intra-frame coding, on the other hand, uses only data from within the current frame, effectively being still-image compression.

A class of specialized formats used in camcorders and video editing use less complex compression schemes that restrict their prediction techniques to intra-frame prediction.

Usually video compression additionally employs lossy compression techniques like quantization that reduce aspects of the source data that are (more or less) irrelevant to the human visual perception by exploiting perceptual features of human vision. For example, small differences in color are more difficult to perceive than are changes in brightness. Compression algorithms can average a color across these similar areas to reduce space, in a manner similar to those used in JPEG image compression. As in all lossy compression, there is a trade-off between video quality and bit rate, cost of processing the compression and decompression, and system requirements. Highly compressed video may present visible or distracting artifacts.

Other methods than the prevalent DCT-based transform formats, such as fractal compression, matching pursuit and the use of a discrete wavelet transform (DWT), have been the subject of some research, but are typically not used in practical products (except for the use of wavelet coding as still-image coders without motion compensation). Interest in fractal compression seems to be waning, due to recent theoretical analysis showing a comparative lack of effectiveness of such methods.

Inter-frame coding works by comparing each frame in the video with the previous one. Individual frames of a video sequence are compared from one frame to the next, and the video compression codec sends only the differences to the reference frame. If the frame contains areas where nothing has moved, the system can simply issue a short command that copies that part of the previous frame into the next one. If sections of the frame move in a simple manner, the compressor can emit a (slightly longer) command that tells the decompressor to shift, rotate, lighten, or darken the copy. This longer command still remains much shorter than intraframe compression. Usually the encoder will also transmit a residue signal which describes the remaining more subtle differences to the reference imagery. Using entropy coding, these residue signals have a more compact representation than the full signal. In areas of video with more motion, the compression must encode more data to keep up with the larger number of pixels that are changing. Commonly during explosions, flames, flocks of animals, and in some panning shots, the high-frequency detail leads to quality decreases or to increases in the variable bitrate.

Today, nearly all commonly used video compression methods (e.g., those in standards approved by the ITU-T or ISO) share the same basic architecture that dates back to H.261 which was standardized in 1988 by the ITU-T. They mostly rely on the DCT, applied to rectangular blocks of neighboring pixels, and temporal prediction using motion vectors, as well as nowadays also an in-loop filtering step.

In the prediction stage, various deduplication and difference-coding techniques are applied that help decorrelate data and describe new data based on already transmitted data.

Then rectangular blocks of (residue) pixel data are transformed to the frequency domain to ease targeting irrelevant information in quantization and for some spatial redundancy reduction. The discrete cosine transform (DCT) that is widely used in this regard was introduced by N. Ahmed, T. Natarajan and K. R. Rao in 1974.

In the main lossy processing stage that data gets quantized in order to reduce information that is irrelevant to human visual perception.

In the last stage statistical redundancy gets largely eliminated by an entropy coder which often applies some form of arithmetic coding.

In an additional in-loop filtering stage various filters can be applied to the reconstructed image signal. By computing these filters also inside the encoding loop they can help compression because they can be applied to reference material before it gets used in the prediction process and they can be guided using the original signal. The most popular example are deblocking filters that blur out blocking artefacts from quantization discontinuities at transform block boundaries.

All basic algorithms of today's dominant video codec architecture have been invented before 1979.
In 1950, the Bell Labs filed the patent on DPCM which soon was applied to video coding. Entropy coding started in the 1940s with the introduction of Shannon–Fano coding on which the widely used Huffman coding is based that was developed in 1950; the more modern context-adaptive binary arithmetic coding (CABAC) was published in the early 1990s. Transform coding (using the Hadamard transform) was introduced in 1969, the popular discrete cosine transform (DCT) appeared in 1974 in scientific literature.
The ITU-T's standard H.261 from 1988 introduced the prevalent basic architecture of video compression technology.

Genetics compression algorithms are the latest generation of lossless algorithms that compress data (typically sequences of nucleotides) using both conventional compression algorithms and genetic algorithms adapted to the specific datatype. In 2012, a team of scientists from Johns Hopkins University published a genetic compression algorithm that does not use a reference genome for compression. HAPZIPPER was tailored for HapMap data and achieves over 20-fold compression (95% reduction in file size), providing 2- to 4-fold better compression and in much faster time than the leading general-purpose compression utilities. For this, Chanda, Elhaik, and Bader introduced MAF based encoding (MAFE), which reduces the heterogeneity of the dataset by sorting SNPs by their minor allele frequency, thus homogenizing the dataset. Other algorithms in 2009 and 2013 (DNAZip and GenomeZip) have compression ratios of up to 1200-fold—allowing 6 billion basepair diploid human genomes to be stored in 2.5 megabytes (relative to a reference genome or averaged over many genomes). For a benchmark in genetics/genomics data compressors, see 

It is estimated that the total amount of data that is stored on the world's storage devices could be further compressed with existing compression algorithms by a remaining average factor of 4.5:1. It is estimated that the combined technological capacity of the world to store information provides 1,300 exabytes of hardware digits in 2007, but when the corresponding content is optimally compressed, this only represents 295 exabytes of Shannon information.



</doc>
<doc id="8022" url="https://en.wikipedia.org/wiki?curid=8022" title="History of the Democratic Republic of the Congo">
History of the Democratic Republic of the Congo

The earliest discovered human remains in the DR Congo, were discovered in the 1990s and have been dated to approximately 90,000 years ago. The first real states, such as the Kongo, the Lunda, the Luba and Kuba, appeared south of the equatorial forest on the savannah from the 14th century onwards. 

The Kingdom of Kongo controlled much of western and central Africa including what is now the western portion of the DR Congo between the 14th and the early 19th centuries. At its peak it had has many as 500,000 people, and its capital was known as Mbanza-Kongo (south of Matadi, modern day Angola). In the late 15th century, Portuguese sailors arrived in the Kingdom of Kongo, and this led to a period of great prosperity and consolidation, with the king's power being founded on Portuguese trade. King Afonso I (1506-43) had raids carried out on neighbouring districts in response to Portuguese requests for slaves. After his death, the kingdom underwent a deep crisis. 

The Atlantic slave traded occurred from approximately 1500 to 1850, with the entire west coast of Africa targeted, but the region around the mouth of the Congo suffered the most intensive enslavement. Over a strip of coastline about 400 kilometres long, about 4 million people were enslaved and sent across the Atlantic to sugar plantations in Brazil, the US and the Caribbean. From 1780 onwards, there was higher demand for slaves in the US which led to more people being enslaved. By 1780, more than 15,000 people were shipped annually from the Loango Coast, north of the Congo. 

In 1870, explorer Henry Morton Stanley arrived in and explored what is now the DR Congo. Belgian colonization of the DR Congo began in 1885 when King Leopold II founded and ruled the Congo Free State. However, de facto control of such as huge area took decades to achieve. Many outposts were built to extend the power of the state over such a vast territory. In 1885, the Force Publique was set up, a colonial army with white officers and black soldiers. In 1886, Leopold made Camille Jansen, the 1st Belgian governor-general of Congo. Over the late 19th century, various Christian (including Catholic and Protestant) missionaries arrived intending to convert the local population. A railway between Matadi and Stanley Pool was built in the 1890s.

Reports of widespread murder, torture and other abuses in the rubber plantations led to international and Belgian outrage and the Belgian government transferred control of the region from Leopold II and established Belgian Congo in 1908. 

After an uprising by the Congolese people, Belgium surrendered and this led to the independence of the Congo in 1960. However, Congo remained unstable because regional leaders had more power than the central government, with Katanga attempting to gain independence with Belgian support. Prime Minister Patrice Lumumba tried to restore order with the aid of the Soviet Union as part of the Cold War, causing the United States to support a coup led by Colonel Joseph Mobutu in 1965. Mobutu quickly seized complete power of the Congo and renamed the country Zaire. He sought to Africanize the country, changing his own name to Mobutu Sese Seko, and demanded that African citizens change their Western names to traditional African names. Mobutu sought to repress any opposition to his rule, which he successfully did throughout the 1980s. However, with his regime weakened in the 1990s, Mobutu was forced to agree to a power-sharing government with the opposition party. Mobutu remained the head of state and promised elections within the next two years that never took place. 

During the First Congo War, Rwanda invaded Zaire; Mobutu lost his power during this process. Laurent-Desire Kabila took power in 1997 and renamed the country the Democratic Republic of the Congo. Afterwards, the Second Congo War broke out, resulting in a regional war in which many different African nations took part and in which millions of people were killed or displaced. Kabila was assassinated by his bodyguard in 2001, and his son, Joseph, succeeded him and was later elected president by the Congolese government in 2006. Joseph Kabila quickly sought peace. Foreign soldiers remained in the Congo for a few years and a power-sharing government between Joseph Kabila and the opposition party was set up. Joseph Kabila later resumed complete control over the Congo and was re-elected in a disputed election in 2011. In 2018, Félix Tshisekedi was elected President; in the first peaceful transfer of power since independence.

The area now known as the Democratic Republic of the Congo was populated as early as 80,000 years ago, as shown by the 1988 discovery of the Semliki harpoon at Katanda, one of the oldest barbed harpoons ever found, which is believed to have been used to catch giant river catfish. During its recorded history, the area has also been known as "Congo", "Congo Free State", "Belgian Congo", and "Zaire". 

The Kingdom of Kongo existed from the 14th to the early 19th century. Until the arrival of the Portuguese it was the dominant force in the region along with the Kingdom of Luba, the Kingdom of Lunda, the Mongo people and the Anziku Kingdom.

The Congo Free State was a corporate state privately controlled by Leopold II of Belgium through the "Association internationale africaine", a non-governmental organization. Leopold was the sole shareholder and chairman. The state included the entire area of the present Democratic Republic of the Congo. Under Leopold II, the Congo Free State became one of the most infamous international scandals of the turn of the twentieth century. The report of the British Consul Roger Casement led to the arrest and punishment of white officials who had been responsible for cold-blooded killings during a rubber-collecting expedition in 1900, including a Belgian national who caused the shooting of at least 122 Congolese natives. Estimates of the total death toll vary considerably. The first census was only done in 1924, so it is even more difficult to quantify the population loss of the period. Roger Casement's famous 1904 report estimated ten million people. According to Casement's report, indiscriminate "war", starvation, reduction of births and tropical diseases caused the country's depopulation. European and U.S. press agencies exposed the conditions in the Congo Free State to the public in 1900. By 1908 public and diplomatic pressure had led Leopold II to annex the Congo as the Belgian Congo colony.

On 15 November 1908 King Leopold II of Belgium formally relinquished personal control of the Congo Free State. The renamed Belgian Congo was put under the direct administration of the Belgian government and its Ministry of Colonies.

Belgian rule in the Congo was based around the "colonial trinity" ("trinité coloniale") of state, missionary and private company interests. The privileging of Belgian commercial interests meant that large amounts of capital flowed into the Congo and that individual regions became specialised. The interests of the government and private enterprise became closely tied; the state helped companies break strikes and remove other barriers imposed by the indigenous population. The country was split into nesting, hierarchically organised administrative subdivisions, and run uniformly according to a set "native policy" ("politique indigène")—in contrast to the British and the French, who generally favoured the system of indirect rule whereby traditional leaders were retained in positions of authority under colonial oversight. There was also a high degree of racial segregation. Large numbers of white immigrants who moved to the Congo after the end of World War II came from across the social spectrum, but were nonetheless always treated as superior to blacks.

During the 1940s and 1950s, the Congo experienced an unprecedented level of urbanisation and the colonial administration began various development programmes aimed at making the territory into a "model colony". Notable advances were made in treating diseases such as African trypanosomiasis. One of the results of these measures was the development of a new middle class of Europeanised African "évolués" in the cities. By the 1950s the Congo had a wage labour force twice as large as that in any other African colony. The Congo's rich natural resources, including uranium—much of the uranium used by the U.S. nuclear programme during World War II was Congolese—led to substantial interest in the region from both the Soviet Union and the United States as the Cold War developed.

During the latter stages of World War II a new social stratum emerged in the Congo, known as the "évolué"s. Forming an African middle class in the colony, they held skilled positions (such as clerks and nurses) made available by the economic boom. While there were no universal criteria for determining "évolué status", it was generally accepted that one would have "a good knowledge of French, adhere to Christianity, and have some form of post-primary education." Early on in their history, most "évolué"s sought to use their unique status to earn special privileges in the Congo. Since opportunities for upward mobility through the colonial structure were limited, the "évolué" class institutionally manifested itself in elite clubs through which they could enjoy trivial privileges that made them feel distinct from the Congolese "masses". Additional groups, such as labour unions, alumni associations, and ethnic syndicates, provided other Congolese the means of organisation. Among the most important of these was the Alliance des Bakongo (ABAKO), representing the Kongo people of the Lower Congo. However, they were restricted in their actions by the administration. While white settlers were consulted in the appointment of certain officials, the Congolese had no means of expressing their beliefs through the governing structures. Though native chiefs held legal authority in some jurisdictions, in practice they were used by the administration to further its own policies.

Up into the 1950s most "évolué"s were concerned only with social inequalities and their treatment by the Belgians. Questions of self-government were not considered until 1954, when ABAKO requested that the administration consider a list of suggested candidates for a Léopoldville municipal post. That year the association was taken over by Joseph Kasa-Vubu, and under his leadership it became increasingly hostile to the colonial authority and sought autonomy for the Kongo regions in the Lower Congo. In 1956 a group of Congolese intellectuals under the tutelage of several European academics issued a manifesto calling for a transition to independence over the course of 30 years. The ABAKO quickly responded with a demand for "immediate independence". The Belgian government was not prepared to grant the Congo independence and even when it started realising the necessity of a plan for decolonisation in 1957, it was assumed that such a process would be solidly controlled by Belgium. In December 1957 the colonial administration instituted reforms that permitted municipal elections and the formation of political parties. Some Belgian parties attempted to establish branches in the colony, but these were largely ignored by the population in favour of Congolese-initiated groups. Nationalism fermented in 1958 as more "évolué"s began interacting with others outside of their own locales and started discussing the future structures of a post-colonial Congolese state. Nevertheless, most political mobilisation occurred along tribal and regional divisions. In Katanga, various tribal groups came together to form the Confédération des associations tribales du Katanga (CONAKAT) under the leadership of Godefroid Munongo and Moïse Tshombe. Hostile to immigrant peoples, it advocated provincial autonomy and close ties with Belgium. Most of its support was rooted in individual chiefs, businessmen, and European settlers of southern Katanga. It was opposed by Jason Sendwe's Association Générale des Baluba du Katanga (BALUBAKAT).
In October 1958 a group of Léopoldville "évolués" including Patrice Lumumba, Cyrille Adoula and Joseph Iléo established the Mouvement National Congolais (MNC). Diverse in membership, the party sought to peacefully achieve Congolese independence, promote the political education of the populace, and eliminate regionalism. The MNC drew most of its membership from the residents of the eastern city of Stanleyville, where Lumumba was well known, and from the population of the Kasai Province, where efforts were directed by a Muluba businessman, Albert Kalonji. Belgian officials appreciated its moderate and anti-separatist stance and allowed Lumumba to attend the All-African Peoples' Conference in Accra, Ghana, in December 1958 (Kasa-Vubu was informed that the documents necessary for his travel to the event were not in order and was not permitted to go). Lumumba was deeply impressed by the Pan-Africanist ideals of Ghanaian President Kwame Nkrumah and returned to the Congo with a more radical party programme. He reported on his trip during a widely-attended rally in Léopoldville and demanded the country's "genuine" independence.

Fearing that they were being overshadowed by Lumumba and the MNC, Kasa-Vubu and the ABAKO leadership announced that they would be hosting their own rally in the capital on 4 January 1959. The municipal government (under Belgian domination) was given short notice, and communicated that only a "private meeting" would be authorised. On the scheduled day of the rally the ABAKO leadership told the crowd that had gathered that the event was postponed and that they should disperse. The mass was infuriated and instead began hurling stones at the police and pillaging European property, initiating three days of violent and destructive riots. The Force Publique, the colonial army, was called into service and suppressed the revolt with considerable brutality. In wake of the riots Kasa-Vubu and his lieutenants were arrested. Unlike earlier expressions of discontent, the grievances were conveyed primarily by uneducated urban residents, not "évolué"s. Popular opinion in Belgium was one of extreme shock and surprise. An investigative commission found the riots to be the culmination of racial discrimination, overcrowding, unemployment, and wishes for more political self-determination. On 13 January the administration announced several reforms, and the Belgian King, Baudouin, declared that independence would be granted to the Congo in the future.

Meanwhile, discontent surfaced among the MNC leadership, who were bothered by Lumumba's domination over the party's politics. Relations between Lumumba and Kalonji also grew tense, as the former was upset with how the latter was transforming the Kasai branch into an exclusively Luba group and antagonising other tribes. This culminated into the split of the party into the MNC-Lumumba/MNC-L under Lumumba and the MNC-Kalonji/MNC-K under Kalonji and Iléo. The latter began advocating federalism. Adoula left the organisation. Alone to lead his own faction and facing competition from ABAKO, Lumumba became increasingly strident in his demands for independence. Following an October riot in Stanleyville he was arrested. Nevertheless, the influence of himself and the MNC-L continued to grow rapidly. The party advocated for a strong unitary state, nationalism, and the termination of Belgian rule and began forming alliances with regional groups, such as the Kivu-based Centre du Regroupement Africain (CEREA). Though the Belgians supported a unitary system over the federal models suggested by ABAKO and CONAKAT, they and more moderate Congolese were unnerved by Lumumba's increasingly extremist attitudes. With the implicit support of the colonial administration, the moderates formed the Parti National du Progrès (PNP) under the leadership of Paul Bolya and Albert Delvaux. It advocated centralisation, respect for traditional elements, and close ties with Belgium. In southern Léopoldville Province, a socialist-federalist party, the Parti Solidaire Africain (PSA) was founded. Antoine Gizenga served as its president, and Cléophas Kamitatu was in charge of the Léopoldville Province chapter.

Following the riots in Leopoldville 4–7 January 1959, and in Stanleyville on 31 October 1959, the Belgians realised they could not maintain control of such a vast country in the face of rising demands for independence. Belgian and Congolese political leaders held a Round Table Conference in Brussels beginning on 18 January 1960. 

At the end of the conference, on 27 January 1960, it was announced that elections would be held in the Congo on 22 May 1960, and full independence granted on 30 June 1960. The elections produced the nationalist Patrice Lumumba as prime minister, and Joseph Kasavubu as president.
On independence the country adopted the name "Republic of the Congo" (République du Congo). The French colony of Middle Congo (Moyen Congo) also chose the name Republic of Congo upon its independence, so the two countries are more commonly known as Congo-Léopoldville and Congo-Brazzaville, after their capital cities. 

In 1960, the country was very unstable—regional tribal leaders held far more power than the central government—and with the departure of the Belgian administrators, almost no skilled bureaucrats remained in the country. The first Congolese graduated from university only in 1956, and very few in the new nation had any idea how to manage a country of such size.

On 5 July 1960, a military mutiny by Congolese soldiers against their European officers broke out in the capital and rampant looting began. On 11 July 1960 the richest province of the country, Katanga, seceded under Moise Tshombe. The United Nations sent 20,000 peacekeepers to protect Europeans in the country and try to restore order. Western paramilitaries and mercenaries, often hired by mining companies to protect their interests, also began to pour into the country. In this period Congo's second richest province, Kasai, also announced its independence on 8 August 1960.

After trying to get help from the United States and the United Nations, Prime Minister Lumumba turned to the USSR for assistance. Nikita Khrushchev agreed to help, offering advanced weaponry and technical advisors. The United States viewed the Soviet presence as an attempt to take advantage of the situation and gain a proxy state in sub-Saharan Africa. UN forces were ordered to block any shipments of arms into the country. The United States also looked for a way to replace Lumumba as leader. President Kasavubu had clashed with Prime Minister Lumumba and advocated an alliance with the West rather than the Soviets. The U.S. sent weapons and CIA personnel to aid forces allied with Kasavubu and combat the Soviet presence. On 14 September 1960, with U.S. and CIA support, Colonel Joseph Mobutu overthrew the government and arrested Lumumba. A technocratic government, the College of Commissioners-General, was established.

On 17 January 1961 Mobutu sent Lumumba to Élisabethville (now Lubumbashi), capital of Katanga. In full view of the press he was beaten and forced to eat copies of his own speeches. For three weeks afterward, he was not seen or heard from. Then Katangan radio announced implausibly that he had escaped and been killed by villagers. It was soon clear that in fact he had been tortured and killed along with two others shortly after his arrival. In 2001, a Belgian inquiry established that he had been shot by Katangan gendarmes in the presence of Belgian officers, under Katangan command. Lumumba was beaten, placed in front of a firing squad with two allies, cut up, buried, dug up and what remained was dissolved in acid.

In Stanleyville, those loyal to the deposed Lumumba set up a rival government under Antoine Gizenga which lasted from 31 March 1961 until it was reintegrated on 5 August 1961. After some reverses, UN and Congolese government forces succeeded in recapturing the breakaway provinces of South Kasai on 30 December 1961, and Katanga on 15 January 1963.

A new crisis erupted in the Simba Rebellion of 1964-1965 which saw half the country taken by the rebels. European mercenaries, US, and Belgian troops were called in by the Congolese government to defeat the rebellion.

Unrest and rebellion plagued the government until November 1965, when Lieutenant General Joseph-Desire Mobutu, by then commander in chief of the national army, seized control of the country and declared himself president for five years. Mobutu quickly consolidated his power, despite the Stanleyville mutinies of 1966 and 1967, and was elected unopposed as president in 1970. 

Embarking on a campaign of cultural awareness, President Mobutu renamed the country the Republic of Zaire in 1971 and required citizens to adopt African names and drop their French-language ones. The name comes from Portuguese, adapted from the Kongo word nzere or nzadi ("river that swallows all rivers"). Among other changes, Leopoldville became Kinshasa and Katanga Shaba.

Relative peace and stability prevailed until 1977 and 1978 when Katangan Front for Congolese National Liberation rebels, based in Angola, launched the Shaba I and II invasions into the southeast Shaba region. These rebels were driven out with the aid of French and Belgian paratroopers plus Moroccan troops. An Inter-African Force remained in the region for some time afterwards.

Zaire remained a one-party state in the 1980s. Although Mobutu successfully maintained control during this period, opposition parties, most notably the Union pour la Démocratie et le Progrès Social (UDPS), were active. Mobutu's attempts to quell these groups drew significant international criticism.

As the Cold War came to a close, internal and external pressures on Mobutu increased. In late 1989 and early 1990, Mobutu was weakened by a series of domestic protests, by heightened international criticism of his regime's human rights practices, by a faltering economy, and by government corruption, most notably his own massive embezzlement of government funds for personal use.

In April 1990, Mobutu declared the Third Republic, agreeing to a limited multi-party system with elections and a constitution. As details of the reforms were delayed, soldiers in September 1991 began looting Kinshasa to protest their unpaid wages. Two thousand French and Belgian troops, some of whom were flown in on U.S. Air Force planes, arrived to evacuate the 20,000 endangered foreign nationals in Kinshasa.

In 1992, after previous similar attempts, the long-promised Sovereign National Conference was staged, encompassing over 2,000 representatives from various political parties. The conference gave itself a legislative mandate and elected Archbishop Laurent Monsengwo Pasinya as its chairman, along with Étienne Tshisekedi wa Mulumba, leader of the UDPS, as prime minister. By the end of the year Mobutu had created a rival government with its own prime minister. The ensuing stalemate produced a compromise merger of the two governments into the High Council of Republic-Parliament of Transition (HCR-PT) in 1994, with Mobutu as head of state and Kengo Wa Dondo as prime minister. Although presidential and legislative elections were scheduled repeatedly over the next two years, they never took place.

By 1996, tensions from the war and genocide in neighboring Rwanda had spilled over into Zaire. Rwandan Hutu militia forces (Interahamwe) who had fled Rwanda following the ascension of a Tutsi-led government had been using Hutu refugee camps in eastern Zaire as bases for incursions into Rwanda. In October 1996
Rwandan forces attacked refugee camps in the Rusizi River plain near the intersection of the Congolese, Rwandan and Burundi borders meet, scattering refugees. They took Uvira, then Bukavu, Goma and Mugunga.

Hutu militia forces soon allied with the Zairian armed forces (FAZ) to launch a campaign against Congolese ethnic Tutsis in eastern Zaire. In turn, these Tutsis formed a militia to defend themselves against attacks. When the Zairian government began to escalate the massacres in November 1996, Tutsi militias erupted in rebellion against Mobutu.

The Tutsi militia was soon joined by various opposition groups and supported by several countries, including Rwanda and Uganda. This coalition, led by Laurent-Desire Kabila, became known as the Alliance des Forces Démocratiques pour la Libération du Congo-Zaïre (AFDL). The AFDL, now seeking the broader goal of ousting Mobutu, made significant military gains in early 1997. Various Zairean politicians who had unsuccessfully opposed the dictatorship of Mobutu for many years now saw an opportunity for them in the invasion of Zaire by two of the region's strongest military forces. Following failed peace talks between Mobutu and Kabila in May 1997, Mobutu left the country on 16 May. The AFDL entered Kinshasa unopposed a day later, and Kabila named himself president, reverting the name of the country to the Democratic Republic of the Congo. He marched into Kinshasa on 20 May and consolidated power around himself and the AFDL.

Kabila demonstrated little ability to manage the problems of his country, and lost his allies. To counterbalance the power and influence of Rwanda in DRC, Ugandan troops created another rebel movement called the Movement for the Liberation of Congo (MLC), led by the Congolese warlord Jean-Pierre Bemba. They attacked in August 1998, backed by Rwandan and Ugandan troops. Soon afterwards, Angola, Namibia, and Zimbabwe became involved militarily in the Congo, with Angola and Zimbabwe supporting the government. While the six African governments involved in the war signed a ceasefire accord in Lusaka in July 1999, the Congolese rebels did not and the ceasefire broke down within months. 

Kabila was assassinated in 2001 by a bodyguard called Rashidi Kasereka, 18, who was then shot dead, according to Justice Minister Mwenze Kongolo. Another account of the assassination says that the real killer escaped.

Kabila was succeeded by his son, Joseph. Upon taking office, Kabila called for multilateral peace talks to end the war. Kabila partly succeeded when a further peace deal was brokered between him, Uganda, and Rwanda leading to the apparent withdrawal of foreign troops.

Currently, the Ugandans and the MLC still hold a wide section of the north of the country; Rwandan forces and its front, the Rassemblement Congolais pour la Démocratie (RCD) control a large section of the east; and government forces or their allies hold the west and south of the country. There were reports that the conflict is being prolonged as a cover for extensive looting of the substantial natural resources in the country, including diamonds, copper, zinc, and coltan. The conflict was reignited in January 2002 by ethnic clashes in the northeast and both Uganda and Rwanda then halted their withdrawal and sent in more troops. Talks between Kabila and the rebel leaders, held in Sun City, lasted a full six weeks, beginning in April 2002. In June, they signed a peace accord under which Kabila would share power with former rebels. By June 2003, all foreign armies except those of Rwanda had pulled out of Congo. 

Few people in the Congo have been unaffected by the conflict. A survey conducted in 2009 by the ICRC and Ipsos shows that three quarters (76%) of the people interviewed have been affected in some way–either personally or due to the wider consequences of armed conflict.

The response of the international community has been incommensurate with the scale of the disaster resulting from the war in the Congo. Its support for political and diplomatic efforts to end the war has been relatively consistent, but it has taken no effective steps to abide by repeated pledges to demand accountability for the war crimes and crimes against humanity that were routinely committed in Congo. 
The United Nations Security Council and the U.N. Secretary-General have frequently denounced human rights abuses and the humanitarian disaster that the war unleashed on the local population, but have shown little will to tackle the responsibility of occupying powers for the atrocities taking place in areas under their control, areas where the worst violence in the country took place. In particular Rwanda and Uganda have escaped any significant sanction for their role.

DR Congo had a transitional government in July 2003 until the election was over. A constitution was approved by voters and on 30 July 2006 the Congo held its first multi-party elections since independence in 1960. Joseph Kabila took 45% of the votes and his opponent Jean-Pierre Bemba 20%. That was the origin of a fight between the two parties from 20–22 August 2006 in the streets of the capital, Kinshasa. Sixteen people died before policemen and MONUC took control of the city. A new election was held on 29 October 2006, which Kabila won with 70% of the vote. Bemba has decried election "irregularities." On 6 December 2006 Joseph Kabila was sworn in as President.

In December 2011, Joseph Kabila was re-elected for a second term as president. After the results were announced on 9 December, there was violent unrest in Kinshasa and Mbuji-Mayi, where official tallies showed that a strong majority had voted for the opposition candidate Etienne Tshisekedi. Official observers from the Carter Center reported that returns from almost 2,000 polling stations in areas where support for Tshisekedi was strong had been lost and not included in the official results. They described the election as lacking credibility. On 20 December, Kabila was sworn in for a second term, promising to invest in infrastructure and public services. However, Tshisekedi maintained that the result of the election was illegitimate and said that he intended also to "swear himself in" as president.

On 19 January 2015 protests led by students at the University of Kinshasa broke out. The protests began following the announcement of a proposed law that would allow Kabila to remain in power until a national census can be conducted (elections had been planned for 2016). By Wednesday 21 January clashes between police and protesters had claimed at least 42 lives (although the government claimed only 15 people had been killed).

Similarly, in September 2016, violent protests were met with brutal force by the police and Republican Guard soldiers. Opposition groups claim 80 dead, including the Students' Union leader. From Monday 19 September Kinshasa residents, as well as residents elsewhere in Congo, where mostly confined to their homes. Police arrested anyone remotely connected to the opposition as well as innocent onlookers. Government propaganda, on television, and actions of covert government groups in the streets, acted against opposition as well as foreigners. The president's mandate was due to end on 19 December 2016, but no plans were made to elect a replacement at that time and this caused further protests. 

On December 30, 2018 the presidential election to determine the successor to Kabila was held. On January 10, 2019, the electoral commission announced opposition candidate Félix Tshisekedi as the winner of the vote. He was officially sworn in as President on January 24, 2019. in the ceremony of taking of the office Félix Tshisekedi appointed Vital Kamerhe as his chief of staff.

The inability of the state and the world's largest United Nations peacekeeping force to provide security throughout the vast country has led to the emergence of up to 70 armed groups around 2016, perhaps the largest number in the world. By 2018, the number of armed groups had increased to about 120. 

Armed groups are often accused of being proxies or being supported by regional governments interested in Eastern Congo’s vast mineral wealth. Some argue that much of the lack of security by the national army is strategic on the part of the government, who let the army profit from illegal logging and mining operations in return for loyalty. Different rebel groups often target civilians by ethnicity as they cannot tell who is a rebel or who they are providing support to and militias often become oriented around ethnicity.

Laurent Nkunda with other soldiers from RCD-Goma who were integrated into the army defected and called themselves the National Congress for the Defence of the People (CNDP). Starting in 2004, CNDP, believed to be backed by Rwanda as a way to tackle the Hutu group Democratic Forces for the Liberation of Rwanda (FDLR), rebelled against the government, claiming to protect the Banyamulenge (Congolese Tutsis). In 2009, after a deal between the DRC and Rwanda, Rwandan troops entered the DRC and arrested Nkunda and were allowed to pursue FDLR militants. The CNDP signed a peace treaty with the government where its soldiers would be integrated into the national army.

In April 2012, the leader of the CNDP, Bosco Ntaganda and troops loyal to him mutinied, claiming a violation of the peace treaty and formed a rebel group, the March 23 Movement (M23), which was believed to be backed by Rwanda. On 20 November 2012, M23 took control of Goma, a provincial capital with a population of one million people. The UN authorized the Force Intervention Brigade (FIB), which was the first UN peacekeeping force with a mandate to neutralize opposition rather than a defensive mandate, and the FIB quickly defeated M23. The FIB was then to fight the FDLR but were hampered by the efforts of the Congolese government, who some believe tolerate the FDLR as a counterweight to Rwandan interests. Since 2017, fighters from M23, most of whom had fled into Uganda and Rwanda (both were believed to have supported them), started crossing back into DRC with the rising crisis over Kabila's extension of his term limit. DRC claimed of clashes with M23.

The Allied Democratic Forces has been waging an insurgency in the Democratic Republic of the Congo and is blamed for the Beni massacre in 2016. While the Congolese army maintains that the ADF is an Islamist insurgency, most observers feel that they are only a criminal group interested in gold mining and logging.

In June 2017, the group, mostly based in South Kivu, called the National People’s Coalition for the Sovereignty of Congo (CNPSC) led by William Yakutumba was formed and became the strongest rebel group in the east, even briefly capturing a few strategic towns. The rebel group is one of three alliances of various Mai-Mai militias and has been referred to as the Alliance of Article 64, a reference to Article 64 of the constitution, which says the people have an obligation to fight the efforts of those who seek to take power by force, in reference to President Kabila. Bembe warlord Yakutumba's Mai-Mai Yakutumba is the largest component of the CNPSC and has had friction with the Congolese Tutsis who often make up commanders in army units.

In 2012, the Congolese army in its attempt to crush the Rwandan backed and Tutsi-dominated CNDP and M23 rebels, empowered and used Hutu groups such as the FDLR and a Hutu dominated Mai-Mai group called Nyatura as proxies in its fight. The Nyatura and FDLR even arbitrarily executed up to 264 mostly Tembo civilians in 2012. In 2015, the army then launched an offensive against the FDLR militia. The FDLR are accused of killing at least 14 Nande people in January 2016 and of killing 10 Nandes and burning houses in July 2016 while an FDLR allied group Maï Maï Nyatura are also accused of killing Nandes. The Nande-dominate UPDI militia, a Nande militia called Mai-Mai Mazembe and a militia dominated by Nyanga people, the "Nduma Defense of Congo" (NDC), also called Maï-Maï Sheka and led by Gédéon Kyungu Mutanga, are accused of attacking Hutus. In North Kivu, in 2017, an alliance of Mai-Mai groups called the National Movement of Revolutionaries (MNR) began attacks in June 2017 includes Nande Mai-Mai leaders from groups such as Corps du Christ and Mai-Mai Mazembe. Another alliance of Mai-Mai groups is CMC which brings together Hutu militia Nyatura and are active along the border between North Kivu and South Kivu.

In Northern Katanga Province starting in 2013, the Pygmy Batwa people, whom the Luba people often exploit and allegedly enslave, rose up into militias, such as the "Perci" militia, and attacked Luba villages. A Luba militia known as "Elements" or "Elema" attacked back, notably killing at least 30 people in the "Vumilia 1" displaced people camp in April 2015. Since the start of the conflict, hundreds have been killed and tens of thousands have been displaced from their homes. The weapons used in the conflict are often arrows and axes, rather than guns.

Elema also began fighting the government mainly with machetes, bows and arrows in Congo’s Haut Katanga and Tanganyika provinces. The government forces fought alongside a tribe known as the Abatembo and targeting civilians of the Luba and the Tabwa tribes who were believed to be sympathetic to the Elema.

In the Kasaï-Central province, starting in 2016, the largely Luba Kamwina Nsapu militia led by Kamwina Nsapu attacked state institutions. The leader was killed by authorities in August 2016 and the militia reportedly took revenge by attacking civilians. By June 2017, more than 3,300 people had been killed and 20 villages have been completely destroyed, half of them by government troops. The militia has expanded to the neighboring Kasai-Oriental area, Kasaï and Lomami.

A traditional chief critical of Kabila was killed by security forces, precipitating conflict
that has killed more than 3,000 people since.

The UN discovered dozens of mass graves. Rebels and government forces are accused of human rights abuses, as well as a state-linked militia called Bana Mura, which shares a name with the hill in the east where presidential guards train.

The Ituri conflict involved fighting between the agriculturalist Lendu and pastoralist Hema ethnic groups in the Ituri region of the north-eastern DRC. While "Ituri conflict" often refers to the major fighting from 1999 to 2003, fighting has existed before and continues since that time. In 2018, with the deterioration in security over Kabila's extending his stay in power, more than 100 people were killed, hundreds of homes burnt and 200,000 people were forced to flee. In June 2019, 240 people were killed in a wave of violence that lead to more than 300,000 people fleeing.

In October 2009 a new conflict started in Dongo, Sud-Ubangi District where clashes had broken out over access to fishing ponds.

Nearly 900 people were killed between December 16-17, 2018 around Yumbi, a few weeks before the Presidential election, when mostly those of the Batende tribe massacred mostly those of the Banunu tribe. About 16,000 fled to neighboring Republic of Congo. It was alleged that it was a carefully planned massacre, involving elements of the national military.





</doc>
<doc id="8023" url="https://en.wikipedia.org/wiki?curid=8023" title="Geography of the Democratic Republic of the Congo">
Geography of the Democratic Republic of the Congo

The Democratic Republic of the Congo forms part of the Congo River Basin, which covers an area of almost . The country's only outlet to the Atlantic Ocean is a narrow strip of land on the north bank of the Congo River.

The vast, low-lying central area is a plateau-shaped basin sloping toward the west, covered by tropical rainforest and criss-crossed by rivers, a large area of this has been categorized by the World Wildlife Fund as the Central Congolian lowland forests ecoregion. The forest center is surrounded by mountainous terraces in the west, plateaus merging into savannas in the south and southwest. 

Dense grasslands extend beyond the Congo River in the north. High mountains of the Ruwenzori Range (some above ) are found on the eastern borders with Rwanda and Uganda (see Albertine Rift montane forests for a description of this area).

The Democratic Republic of the Congo lies on the equator, with one-third of the country to the north and two-thirds to the south. The climate is hot and humid in the river basin and cool and dry in the southern highlands, with a cold, alpine climate in the Rwenzori Mountains. 

South of the equator, the rainy season lasts from October to May and north of the Equator, from April to November. Along the Equator, rainfall is fairly regular throughout the year. During the wet season, thunderstorms often are violent but seldom last more than a few hours. The average rainfall for the entire country is about .

Location of Congo:
Central Africa, northeast of Angola

Geographic coordinates: 

Continent:
Africa

Area:
"total:"
2,344,858 km
"land:"
2,267,048 km
"water:"
77,810 km

Area - comparative:
slightly less than one-fourth the size of the US

Land boundaries:
"total:"
10,481 km
"border countries:"
Angola 2,646 km, Burundi 236 km, Central African Republic 1,747 km, Republic of the Congo 1,229 km, Rwanda 221 km, South Sudan 714 km, Tanzania 479 km, Uganda 877 km, Zambia 2,332 km

Coastline:

Maritime claims:
"territorial sea:"

"exclusive economic zone:"
boundaries with neighbors

Climate:
tropical; hot and humid in equatorial river basin; cooler and drier in southern highlands; cooler-cold and wetter in eastern highlands and the Ruwenzori Range; north of Equator - wet season April to October, dry season December to February; south of Equator - wet season November to March, dry season April to October
Terrain:
vast central plateau covered by tropical rainforest, surrounded by mountains in the west, plains and savanna in the south/southwest, and grasslands in the north. The high mountains of the Ruwenzori Range on the eastern borders.

Elevation extremes:
"lowest point:"
Atlantic Ocean 0 m
"highest point:"
Pic Marguerite on Mont Ngaliema (Mount Stanley) 5,110 m

Natural resources:
cobalt, copper, niobium, petroleum, industrial and gem diamonds, gold, silver, zinc, manganese, tin, uranium, coal, hydropower, timber

Land use:
"arable land:"
3.09% 
"permanent crops:"
0.36%
96.55 (2012 est.)

Irrigated land:
105 km (2003)

Total renewable water resources:
1,283 km (2011)

Freshwater withdrawal (domestic/industrial/agricultural):
"total:"
0.68 km/yr (68%/21%/11%)
"per capita:"
11.25 m/yr (2005)

Natural hazards:
periodic droughts in south; Congo River floods (seasonal); in the east, in the Albertine Rift, there are active volcanoes

Environment - current issues:
Poaching threatens wildlife populations (for example, the painted hunting dog, "Lycaon pictus", is now considered extirpated from the Congo due to human overpopulation and poaching); water pollution; deforestation (chiefly due to land conversion to agriculture by indigenous farmers); refugees responsible for significant deforestation, soil erosion, and wildlife poaching; mining of minerals (coltan — a mineral used in creating capacitors, diamonds, and gold) causing environmental damage

Environment - international agreements:
"party to:"
Biodiversity, Climate Change, Desertification, Endangered Species, Hazardous Wastes, Law of the Sea, Marine Dumping, Nuclear Test Ban, Ozone Layer Protection, Tropical Timber 83, Tropical Timber 94, Wetlands
"signed, but not ratified:"
Environmental Modification

Geography:
D.R. Congo is one of six African states that straddles the equator; it's the largest African state that has the equator passing through it. Very narrow strip of land that controls the lower Congo River and is the only outlet to South Atlantic Ocean; dense tropical rainforest in central river basin and eastern highlands.

This is a list of the extreme points of the Democratic Republic of the Congo, the points that are farther north, south, east or west than any other location.




</doc>
<doc id="8024" url="https://en.wikipedia.org/wiki?curid=8024" title="Demographics of the Democratic Republic of the Congo">
Demographics of the Democratic Republic of the Congo

This article is about the demographic features of the population of the Democratic Republic of the Congo, including ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.

As many as 250 ethnic groups have been distinguished and named. The most numerous people are the Luba, Mongo, and Bakongo.

Although 700 local languages and dialects are spoken, the linguistic variety is bridged both by the use of French and the intermediary languages Kongo, Luba-Kasai, Swahili, and Lingala.

According to the total population was in , compared to only 12,184,000 in 1950. The proportion of children below the age of 15 in 2010 was 46.3%, 51.1% was between 15 and 65 years of age, while 2.7% was 65 years or older

Structure of the population (DHS 2013-2014) (Males 45 548, Females 49 134 = 94 682) :

Registration of vital events in the Democratic Republic of the Congo is incomplete. The Population Departement of the United Nations prepared the following estimates.

Total Fertility Rate (TFR) (Wanted Fertility Rate) and Crude Birth Rate (CBR):

Fertility data as of 2013-2014 (DHS Program):

More than 250 ethnic groups have been identified and named of which the majority are Bantu. The four largest groups - Mongo, Luba, Kongo (all Bantu), and the Mangbetu-Azande make up about 45% of the population. The country has also 60,000 White Congolese most of Belgian ancestry who remained after independence.
Bantu peoples (80%):

Central Sudanic/Ubangian :

Nilotic peoples :

Pygmy peoples :
More than 600,000 pygmies (around 1% of the total population) are believed to live in the DR Congo's huge forests, where they survive by hunting wild animals and gathering fruits.

The four major languages in the DRC are French (official), Lingala (a lingua franca trade language), Kingwana (a dialect of Swahili), Kikongo, and Tshiluba. There are over 200 ethnic languages.

French is generally the medium of instruction in schools. English is taught as a compulsory foreign language in Secondary and High School around the country. It is a required subject in the Faculty of Economics at major universities around the country and there are numerous language schools in the country that teach it. In the town of Beni, for instance, there is a Bilingual University that offer courses in both French and English. President Kabila himself is fluent in both English and French, as was his father.

A survey conducted by the Demographic and Health Surveys program in 2013-2014 indicated that Christians constituted 93.7% of the population (Catholics 29.7%, Protestants 26.8%, and other Christians 37.2%). An indigenous religion, Kimbanguism, has the adherence of 2.8%, while Muslims make up 1.2%.

Another estimate found Christianity was followed by 95.8% of the population, according to the Pew Research Center in 2010.

The CIA The World Factbook states: Roman Catholic 50%, Protestant 20%, Kimbanguist 10%, Islam 10%, Other (includes Syncretic Sects and Indigenous beliefs) 10%.

Joshua Project figures: Roman Catholic 43.9%, Protestant 24.8%, Other Christian 23.7%, Muslim 1.6%, Non-religious 0.6%, Hindu 0.1% other syncretic sects and indigenous beliefs 5.3%.

Demographic statistics according to the World Population Review in 2019.


The following demographic statistics are from the CIA World Factbook.

"note": fighting between the Congolese Government and Uganda- and Rwanda-backed Congolese rebels spawned a regional war in DRC in August 1998, which left 2.33 million Congolese internally displaced and caused 412,000 Congolese refugees to flee to surrounding countries (2011 est.)

Given the situation in the country and the condition of state structures, it is extremely difficult to obtain reliable data however evidence suggests that DRC continues to be a destination country for immigrants in spite of recent declines. Immigration is seen to be very diverse in nature, with refugees and asylum-seekers - products of the numerous and violent conflicts in the Great Lakes Region - constituting an important subset of the population in the country.

Additionally, the country’s large mine operations attract migrant workers from Africa and beyond and there is considerable migration for commercial activities from other African countries and the rest of the world, but these movements are not well studied. Transit migration towards South Africa and Europe also plays a role. Immigration in the DRC has decreased steadily over the past two decades, most likely as a result of the armed violence that the country has experienced.

According to the International Organization for Migration, the number of immigrants in the DRC has declined from just over 1 million in 1960, to 754,000 in 1990, to 480,000 in 2005, to an estimated 445,000 in 2010. Valid figures are not available on migrant workers in particular, partly due to the predominance of the informal economy in the DRC. Data are also lacking on irregular immigrants, however given neighbouring country ethnic links to nationals of the DRC, irregular migration is assumed to be a significant phenomenon in the country.

Figures on the number of Congolese nationals abroad vary greatly depending on the source, from 3 to 6 million. This discrepancy is due to a lack of official, reliable data. Emigrants from the DRC are above all long-term emigrants, the majority of which live within Africa and to a lesser extent in Europe; 79.7% and 15.3% respectively, according to estimates on 2000 data. Most Congolese emigrants however, remain in Africa, with new destination countries including South Africa and various points en route to Europe.

In addition to being a host country, the DRC has also produced a considerable number of refugees and asylum-seekers located in the region and beyond. These numbers peaked in 2004 when, according to UNHCR, there were more than 460,000 refugees from the DRC; in 2008, Congolese refugees numbered 367,995 in total, 68% of which were living in other African countries.

The table below shows DRC born people who have emigrated abroad in selected Western countries (although it excludes their descendants).
These are only estimates and do not account for Congolese migrants residing illegally in these and other countries. 





</doc>
<doc id="8025" url="https://en.wikipedia.org/wiki?curid=8025" title="Economy of the Democratic Republic of the Congo">
Economy of the Democratic Republic of the Congo

Sparsely populated in relation to its area, the Democratic Republic of the Congo is home to a vast potential of natural resources and mineral wealth. Despite this, the economy has declined drastically since the mid-1980s.

At the time of its independence in 1960, the Democratic Republic of the Congo was the second most industrialized country in Africa after South Africa. It boasted a thriving mining sector and its agriculture sector was relatively productive. Since then, corruption, war and political instability have been a severe detriment to further growth, today leaving DRC with a GDP per capita among the world's lowest.

Despite this the DRC is quickly modernizing having tied with Malaysia for the largest positive change in HDI development in 2016. And projects which include strengthening the health system for maternal and child health, expansion of electricity access, water supply reconstructions, and urban and social rehabilitation programs.

The two recent conflicts (the First and Second Congo Wars), which began in 1996, have dramatically reduced national output and government revenue, have increased external debt, and have resulted in deaths of more than five million people from war, and associated famine and disease. Malnutrition affects approximately two thirds of the country's population.

Agriculture is the mainstay of the economy, accounting for 57.9% of GDP in 1997. In 1996, agriculture employed 66% of the work force.

Rich in minerals, the Democratic Republic of the Congo has a difficult history of predatory mineral extraction, which has been at the heart of many struggles within the country for many decades, but particularly in the 1990s. The economy of the third largest country in Africa relies heavily on mining. However, much economic activity occurs in the informal sector and is not reflected in GDP data.

In 2006 Transparency International ranked the Democratic Republic of the Congo 156 out of 163 countries in the Corruption Perception Index, tying Bangladesh, Chad, and Sudan with a 2.0 rating. President Joseph Kabila established the Commission of Repression of Economic Crimes upon his ascension to power in 2001.

The conflicts in the DRC were over water, minerals, and other resources. Political agendas have worsened the economy, as in times of crisis, the elite benefit while the general populace suffers. This is worsened as a result of corrupt national and international corporations. The corporations instigate and allow the fighting for resources because they benefit from it. A large proportion of fatalities in the country are attributed to a lack of basic services. The influx of refugees since the war in 1998 only serves to worsen the issue of poverty. Money of the taxpayers in the DRC is often misappropriated by the corrupt leaders of the country, who use the money to benefit themselves instead of the citizens of the DRC. The DRC is consistently rated the lowest on the UN Human Development Index.

Forced labor was important for the rural sector. The corporations that dominated the economy were mostly owned by Belgium, but British capital also played an important role. The 1950s were a period of rising income and expectations. Congo was said to have the best public health system in Africa, but there was also a huge wealth disparity. Belgian companies favored workers in certain areas more and exported them to work in different areas, restricting opportunities for others. Favored groups also received better education and were able to secure jobs for people in the same ethnic group which increased tensions. In 1960 there were only 16 university graduates out of a population of 20 million. Belgium still had economic power and independence gave little opportunity for improvement. Common refrains included "no elite, no trouble" and "before independence = after independence". When the Belgians left, most of the government officials and educated residents left with them. Before independence there were just 3 out of 5000 government jobs held by Congolese people. The resulting loss of institutional knowledge and human capital crippled the government.

After the Congo crisis, Mobutu arose as the country's sole ruler and stabilized the country politically. Economically, however, the situation continued to decline, and by 1979, the purchasing power was only 4% of that from 1960. Starting in 1976 the IMF provided stabilizing loans to the dictatorship. Much of the money was embezzled by Mobutu and his circle. This was not a secret as the 1982 report by IMF's envoy Erwin Blumenthal documented. He stated, it is "alarmingly clear that the corruptive system in Zaire with all its wicked and ugly manifestations, its mismanagement and fraud will destroy all endeavors of international institutions, of friendly governments, and of the commercial banks towards recovery and rehabilitation of Zaire’s economy". Blumenthal indicated that there was "no chance" that creditors would ever recover their loans. Yet the IMF and the World Bank continued to lend money that was either embezzled, stolen, or "wasted on elephant projects". "Structural adjustment programmes" implemented as a condition of IMF loans cut support for health care, education, and infrastructure.

International Bank for Reconstruction and Development (IBRD) Trust Fund for the Congo.
Poor infrastructure, an uncertain legal framework, corruption, and lack of openness in government economic policy and financial operations remain a brake on investment and growth. A number of International Monetary Fund (IMF) and World Bank missions have met with the new government to help it develop a coherent economic plan but associated reforms are on hold.

Faced with continued currency depreciation, the government resorted to more drastic measures and in January 1999 banned the widespread use of U.S. dollars for all domestic commercial transactions, a position it later adjusted. The government has been unable to provide foreign exchange for economic transactions, while it has resorted to printing money to finance its expenditure. Growth was negative in 2000 because of the difficulty of meeting the conditions of international donors, continued low prices of key exports, and post-coup instability.
Although depreciated, congolese francs have been stable for few years (Ndonda, 2014)

Conditions improved in late 2002 with the withdrawal of a large portion of the invading foreign troops. A number of IMF and World Bank missions have met with the government to help it develop a coherent economic plan, and President Kabila has begun implementing reforms.

The DRC is embarking on the establishment of special economic zones (SEZ) to encourage the revival of its industry. The first SEZ was planned to come into being in 2012 in N'Sele, a commune of Kinshasa, and will focus on agro-industries. The Congolese authorities also planned to open another zone dedicated to mining (Katanga) and a third dedicated to cement (in the Bas-Congo). There are three phases to the program that each have their own objectives. Phase I was the precursor to the actual investment in the Special Economic Zone where policymakers agreed to the framework, the framework was studied for its establishment, and to predict the potential market demand for the land. Stage one of Phase II involved submitting laws for the Special Economic Zone, finding good sites for businesses, and currently there is an effort to help the government attract foreign investment. Stage two of Phase II hasn't been started yet and it involves assisting the government in creating framework for the country, creating an overall plan for the site, figuring out what the environmental impact of the project will be, and guessing how much it will cost and what the return can be made on the investment. Phase III involves the World Bank creating a transaction phase that will keep everything competitive. The program is looking for options to hand over the program to the World Bank which could be very beneficial for the western part of the country.

The following table shows the main economic indicators in 1980–2017.
Ongoing conflicts dramatically reduced government revenue and increased external debt. As Reyntjens wrote, "Entrepreneurs of insecurity are engaged in extractive activities that would be impossible in a stable state environment. The criminalization context in which these activities occur offers avenues for considerable factional and personal enrichment through the trafficking of arms, illegal drugs, toxic products, mineral resources and dirty money." Ethnic rivalries were made worse because of economic interests and looting and coltan smuggling took place. Illegal monopolies formed in the country where they used forced labor for children to mine or work as soldiers. National parks were overrun with people looking to exploit minerals and resources. Increased poverty and hunger from the war and that increased the hunting of rare wildlife. Education was denied when the country was under foreign control and very few people make money off the minerals in the country. The national resources are not the root cause for the continued fighting in the region, however, the competition has become an incentive to keep fighting.[1] The DRC's level of economic freedom is one of the lowest in the world, putting it in the repressed category. The armed militias fight with the government in the eastern section of the country over the mining sector or the corruption of the government, and weak policies lead to the instability of the economy. Human rights abuses also ruin economic activity; the DRC has a 7% unemployment rate, but still has one of the lowest GDP's per capita in the world. A major problem for people trying to start their own companies is that the minimum amount of capital needed to launch the company is 5 times the average annual income, and prices are regulated by the government, which almost forces people to have to work for the larger, more corrupt businesses; otherwise, they won't have work. It is hard for the DRC to encourage foreign trade because of the regulatory barriers.

International Bank for Reconstruction and Development (IBRD) Trust Fund for the Congo.
Poor infrastructure, an uncertain legal framework, corruption, and lack of openness in government economic policy and financial operations remain a brake on investment and growth. A number of International Monetary Fund (IMF) and World Bank missions have met with the new government to help it develop a coherent economic plan but associated reforms are on hold.

Faced with continued currency depreciation, the government resorted to more drastic measures and in January 1999 banned the widespread use of U.S. dollars for all domestic commercial transactions, a position it later adjusted. The government has been unable to provide foreign exchange for economic transactions, while it has resorted to printing money to finance its expenditure. Growth was negative in 2000 because of the difficulty of meeting the conditions of international donors, continued low prices of key exports, and post-coup instability. 125 companies in 2003 contributed to the conflict in DRC showing the corruption.

With the help of the International Development Association the DRC has worked toward the reestablishment of social services. This is done by giving 15 million people access to basic health services and giving bed nets to prevent malaria from spreading to people. With the Emergency Demobilization and Reintegration Program more than 107,000 adults and 34,000 child soldiers stood down their militarized posture. The travel time from Lubumbashi to Kasomeno in Katanga went down from seven days to two hours because of the improved roads which led to the decrease of prices of main goods by 60%. With the help of the IFC, KfW, and the EU the DRC improved its businesses by reducing the time it took to create a business by 51%, reducing the time it took to get construction permits by 54%, and reducing the number of taxes from 118 to 30. Improvements in health have been noticeable specifically that deliveries attended by trained staff jumped from 47 to 80%. In education 14 million textbooks were provided to children, completion rates of school have increased, and higher education was made available to students that chose to pursue it.

The Democratic Republic of Congo ranks 183 on the low end of the ease of doing business scale as ranked by the World Bank. This measures the difficulties of starting a business, enforcing contracts, paying taxes, resolving insolvency, protecting investors, trading across borders, getting credit, getting electricity, dealing with construction permits and registering property (World Bank 2014:8).

The IMF plans on giving the DRC a $1 billion loan after its two-year suspension after it failed to give details about a mining deal from one of its state owned mines and an Israeli billionaire, Dan Gertler. The loan may be necessary for the country because there will be elections in December 2016 for the next president and the cost of funding this would range around $1.1 billion. The biggest problem with the vote is getting a country of 68 million people the size of Western Europe to polling stations with less than 1,860 miles of paved roads.

Agriculture is the mainstay of the economy, accounting for 57.9% of the GDP in 1997. Main cash crops include coffee, palm oil, rubber, cotton, sugar, tea, and cocoa. Food crops include cassava, plantains, maize, groundnuts, and rice. In 1996, agriculture employed 66% of the work force.

The Democratic Republic of Congo also possesses 50 percent of Africa's forests and a river system that could provide hydro-electric power to the entire continent, according to a United Nations report on the country's strategic significance and its potential role as an economic power in central Africa. Fish are the single most important source of animal protein in the DRC. Total production of marine, river, and lake fisheries in 2003 was estimated at 222,965 tons, all but 5,000 tons from inland waters. PEMARZA, a state agency, carries on marine fishing.

Forests cover 60 percent of the total land area. There are vast timber resources, and commercial development of the country's 61 million hectares (150 million acres) of exploitable wooded area is only beginning. The Mayumbe area of Bas-Congo was once the major center of timber exploitation, but forests in this area were nearly
depleted. The more extensive forest regions of the central cuvette and of the Ubangi River valley have increasingly been tapped.

Roundwood removals were estimated at 72,170,000 m in 2003, about 95 percent for fuel. Some 14 species are presently being harvested. Exports of forest products in 2003 totalled $25.7 million. Foreign capital is necessary in order for forestry to expand, and the government recognizes that changes in tax structure and export procedures will be needed to facilitate economic growth.

Rich in minerals, the DRC has a difficult history of predatory mineral extraction, which has been at the heart of many struggles within the country for many decades, but particularly in the 1990s. Although the economy of the Democratic Republic of the Congo, the second largest country in Africa who has historically relied heavily on mining, is no longer reflected in the GDP data as the mining industry has suffered from long-term "uncertain legal framework, corruption, and a lack of transparency in government policy." The informal sector .

In her book entitled "The Real Economy of Zaire", MacGaffey described a second, often illegal economy, "system D," which is outside the official economy (MacGaffey 1991:27). and therefore is not reflected in the GDP.

exploitation of mineral substances as MIBA EMAXON and De Beers 
The economy of the second largest country in Africa relies heavily on mining. The Congo is the world's largest producer of cobalt ore, and a major producer of copper and industrial diamonds. The Congo has 70% of the world's coltan, and more than 30% of the world's diamond reserves., mostly in the form of small, industrial diamonds. The coltan is a major source of tantalum, which is used in the fabrication of electronic components in computers and mobile phones. In 2002, tin was discovered in the east of the country, but, to date, mining has been on a small scale.

Smuggling of the conflict minerals, coltan and cassiterite (ores of tantalum and tin, respectively), has helped fuel the war in the Eastern Congo.

Katanga Mining Limited, a London-based company, owns the Luilu Metallurgical Plant, which has a capacity of 175,000 tonnes of copper and 8,000 tonnes of cobalt per year, making it the largest cobalt refinery in the world. After a major rehabilitation program, the company restarted copper production in December 2007 and cobalt production in May 2008.

Much economic activity occurs in the informal sector and is not reflected in GDP data.

Ground transport in the Democratic Republic of Congo has always been difficult. The terrain and climate of the Congo Basin present serious barriers to road and rail construction, and the distances are enormous across this vast country. Furthermore, chronic economic mismanagement and internal conflict has led to serious under-investment over many years.

On the other hand, the Democratic Republic of Congo has thousands of kilometres of navigable waterways, and traditionally water transport has been the dominant means of moving around approximately two-thirds of the country.




</doc>
<doc id="8026" url="https://en.wikipedia.org/wiki?curid=8026" title="Politics of the Democratic Republic of the Congo">
Politics of the Democratic Republic of the Congo

Politics of the Democratic Republic of Congo take place in a framework of a republic in transition from a civil war to a semi-presidential republic.

On 18 and 19 December 2005, a successful nationwide referendum was carried out on a draft constitution, which set the stage for elections in 2006. The voting process, though technically difficult due to the lack of infrastructure, was facilitated and organized by the Congolese Independent Electoral Commission with support from the UN mission to the Congo (MONUC). Early UN reports indicate that the voting was for the most part peaceful, but spurred violence in many parts of the war-torn east and the Kasais.

In 2006, many Congolese complained that the constitution was a rather ambiguous document and were unaware of its contents. This is due in part to the high rates of illiteracy in the country. However, interim President Kabila urged Congolese to vote 'Yes', saying the constitution is the country's best hope for peace in the future. 25 million Congolese turned out for the two-day balloting. According to results released in January 2006, the constitution was approved by 84% of voters. The new constitution also aims to decentralize authority, dividing the vast nation into 25 semi-autonomous provinces, drawn along ethnic and cultural lines.

The country's first democratic elections in four decades were held on 30 July 2006.

From the day of the arguably ill-prepared independence of the Democratic Republic of the Congo, the tensions between the powerful leaders of the political elite, such as Joseph Kasa Vubu, Patrice Lumumba, Moise Tshombe, Joseph Mobutu and others, jeopardize the political stability of the new state. From Tshombe's secession of the Katanga, to the assassination of Lumumba, to the two coups d'état of Mobutu, the country has known periods of true nationwide peace, but virtually no period of genuine democratic rule.

The Regime of Marshall Mobutu Sese Seko lasted 32 years (1965–1997), during which all but the first seven years the country was named Zaire. The dictatorial regime operated as a one-party-state, which saw most of the powers concentrated between President Mobutu, who was simultaneously the head of the state-party (Popular Movement of the Revolution), and a series of essentially rubber-stamping institutions.

One particularity of the Regime was the claim to be thriving for an "authentic" system, different from Western, or Soviet influences. This lasted roughly between the establishment of Zaire in 1971, and the official beginning of the transition towards democracy, on 24 April 1990. This was true at the regular people's level as everywhere else. People were ordered by law to drop their Western Christian names; the titles Mr. and Mrs. were abandoned for the male and female versions of the French word for "citizen"; Men were forbidden to wear suits, and women to wear pants. At the institutional level, many of the institutions also changed denominations, but the end result was a system that borrowed from both systems:


Every corporation, whether financial or union, as well as every division of the administration, were set up as branches of the party, the CEOs, Union leaders, and division directors being sworn-in as section presidents of the party. Every aspect of life was regulated to some degree by the party, and the will of its founding-president, Mobutu Sese Seko.

Most of the petty aspects of the regime disappeared after 1990, and the beginning of the democratic transition. The latter was intended to be fairly short-lived, but Mobutu's power plays dragged it in length, to ultimately 1997, when the forces-led by Laurent Kabila eventually toppled the regime, after a 9-month-long successful military campaign.

The government of former president Mobutu Sese Seko was toppled by a rebellion led by Laurent Kabila in May 1997, with the support of Rwanda and Uganda. They were later to turn against Kabila and backed a rebellion against him in August 1998. Troops from Zimbabwe, Angola, Namibia, Chad, and Sudan intervened to support the Kinshasa regime. A cease-fire was signed on 10 July 1999 by the DROC, Zimbabwe, Angola, Uganda, Namibia, Rwanda, and Congolese armed rebel groups, but fighting continued.

Under Laurent Kabila's regime, all executive, legislative, and military powers were first vested in the President, Laurent-Désiré Kabila. The judiciary was independent, with the president having the power to dismiss or appoint. The president was first head of a 26-member cabinet dominated by the Alliance of Democratic Forces for the Liberation of Congo (ADFL). Towards the end of the 90s, Laurent Kabila created and appointed a Transitional Parliament, with a seat in the buildings of the former Katanga Parliament, in the southern town of Lubumbashi, in a move to unite the country, and to legitimate his regime. Kabila was assassinated on 16 January 2001 and his son Joseph Kabila was named head of state ten days later.

The younger Kabila continued with his father's Transitional Parliament, but overhauled his entire cabinet, replacing it with a group of technocrats, with the stated aim of putting the country back on the track of development, and coming to a decisive end of the Second Congo War. In October 2002, the new president was successful in getting occupying Rwandan forces to withdraw from eastern Congo; two months later, an agreement was signed by all remaining warring parties to end the fighting and set up a Transition Government, the make-up of which would allow representation for all negotiating parties. Two founding documents emerged from this: The , and the Global and Inclusive Agreement, both of which describe and determine the make-up and organization of the Congolese institutions, until planned elections in July 2006, at which time the provisions of the new constitution, democratically approved by referendum in December 2005, will take full effect and that is how it happened.

Under the Global and All-Inclusive Agreement, signed on 17 December 2002, in Pretoria, there was to be one President and four Vice-Presidents, one from the government, one from the Rally for Congolese Democracy, one from the MLC, and one from civil society. The position of Vice-President expired after the 2006 elections.

After being for three years (2003–06) in the interregnum between two constitutions, the Democratic Republic of the Congo is now under the regime of the Constitution of the Third Republic. The constitution, adopted by referendum in 2005, and promulgated by President Joseph Kabila in February 2006, establishes a decentralized semi-presidential republic, with a separation of powers between the three branches of government - executive, legislative and judiciary, and a distribution of prerogatives between the central government and the provinces.

As of 8 August 2017 there are 54 political parties legally operating in the Congo.

On 15 December 2018 US State Department announced it had decided to evacuate its employees’ family members from Democratic Republic of Congo just before the Congolese elections to choose a successor to President Joseph Kabila.

Since the July 2006 elections, the country is led by a semi-presidential, strongly-decentralized state. The executive at the central level, is divided between the President, and a Prime Minister appointed by him/her from the party having the majority of seats in Parliament. Should there be no clear majority, the President can appoint a "government former" that will then have the task to win the confidence of the National Assembly. The President appoints the government members (ministers) at the proposal of the Prime Minister. In coordination, the President and the government have the charge of the executive. The Prime minister and the government are responsible to the lower-house of Parliament, the National Assembly.

At the province level, the Provincial legislature (Provincial Assembly) elects a governor, and the governor, with his government of up to 10 ministers, is in charge of the provincial executive. Some domains of government power are of the exclusive provision of the Province, and some are held concurrently with the Central government. This is not a Federal state however, simply a decentralized one, as the majority of the domains of power are still vested in the Central government. The governor is responsible to the Provincial Assembly.

The semi-presidential system has been described by some as "conflictogenic" and "dictatogenic", as it ensures frictions, and a reduction of pace in government life, should the President and the Prime Minister be from different sides of the political arena. This was seen several times in France, a country that shares the semi-presidential model. It was also, arguably, in the first steps of the Congo into independence, the underlying cause of the crisis between Prime Minister Patrice Lumumba and President Joseph Kasa Vubu, who ultimately dismissed each other, in 1960.

In January 2015 the 2015 Congolese protests broke out in the country's capital following the release of a draft law that would extend the presidential term limits and allow Joseph Kabila to run again for office.

The Inter-Congolese dialogue, that set-up the transitional institutions, created a bicameral parliament, with a National Assembly and Senate, made up of appointed representatives of the parties to the dialogue. These parties included the preceding government, the rebel groups that were fighting against the government, with heavy Rwandan and Ugandan support, the internal opposition parties, and the Civil Society. At the beginning of the transition, and up until recently, the National Assembly is headed by the MLC with Speaker Hon. Olivier Kamitatu, while the Senate is headed by a representative of the Civil Society, namely the head of the Church of Christ in Congo, Mgr. Pierre Marini Bodho. Hon. Kamitatu has since left both the MLC and the Parliament to create his own party, and ally with current President Joseph Kabila. Since then, the position of Speaker is held by Hon. Thomas Luhaka, of the MLC.

Aside from the regular legislative duties, the Senate had the charge to draft a new constitution for the country. That constitution was adopted by referendum in December 2005, and decreed into law on 18 February 2006.

The Parliament of the third republic is also bicameral, with a National Assembly and a Senate. Members of the National Assembly, the lower - but the most powerful - house, are elected by direct suffrage. Senators are elected by the legislatures of the 26 provinces.

The Congolese Judicial Branch Consists of a Supreme Court, which handles federal crimes.

10 provinces (provinces, singular - province) and one city* (ville): Bandundu, Bas-Congo, Équateur, Kasai-Occidental, Kasai-Oriental, Katanga, Kinshasa*, Maniema, North Kivu, Orientale.

Each province is divided into districts.

25 provinces (provinces, singular - province) and city* (ville): Bas-Uele | Équateur | Haut-Lomami | Haut-Katanga | Haut-Uele | Ituri | Kasaï | Kasaï oriental | Kongo central | Kwango | Kwilu | Lomami | Lualaba | Lulua | Mai-Ndombe | Maniema | Mongala | North Kivu | Nord-Ubangi | Sankuru | South Kivu | Sud-Ubangi | Tanganyika | Tshopo | Tshuapa | Kinshasa*

ACCT, ACP, AfDB, AU, CEEAC, CEPGL, ECA, FAO, G-19, G-24, G-77, IAEA, IBRD, ICAO, ICC, ICRM, IDA, IFAD, IFC, IFRCS, IHO, ILO, IMF, UN, UNCTAD, UNESCO, UNHCR, UNIDO, UPU, WCO WFTU, WHO, WIPO, WMO, WToO, WTrO


</doc>
<doc id="8027" url="https://en.wikipedia.org/wiki?curid=8027" title="Telecommunications in the Democratic Republic of the Congo">
Telecommunications in the Democratic Republic of the Congo

Telecommunications in the Democratic Republic of the Congo include radio, television, fixed and mobile telephones, and the Internet.


Radio is the dominant medium; a handful of stations, including state-run Radio-Télévision Nationale Congolaise (RTNC), broadcast across the country. The United Nations Mission (MONUSCO) and a Swiss-based NGO, Fondation Hirondelle, operate one of country's leading stations, Radio Okapi. The network employs mostly-Congolese staff and aims to bridge political divisions. Radio France Internationale (RFI), which is widely available on FM, is the most popular news station. The BBC broadcasts on FM in Kinshasa (92.7), Lubumbashi (92.0), Kisangani (92.0), Goma (93.3) and Bukavu (102.2).







</doc>
<doc id="8028" url="https://en.wikipedia.org/wiki?curid=8028" title="Transport in the Democratic Republic of the Congo">
Transport in the Democratic Republic of the Congo

Ground transport in the Democratic Republic of Congo (DRC) has always been difficult. The terrain and climate of the Congo Basin present serious barriers to road and rail construction, and the distances are enormous across this vast country. Furthermore, chronic economic mismanagement and internal conflict has led to serious under-investment over many years.

On the other hand, the DRC has thousands of kilometres of navigable waterways, and traditionally water transport has been the dominant means of moving around approximately two-thirds of the country.

As an illustration of transport difficulties in the DRC, even before wars damaged the infrastructure, the so-called "national" route, used to get supplies to Bukavu from the seaport of Matadi, consisted of the following:
In other words, goods had to be loaded and unloaded eight times and the total journey would take many months.

Many of the routes listed below are in poor condition and may be operating at only a fraction of their original capacity (if at all), despite recent attempts to make improvements. Up to 2006 the United Nations Joint Logistics Centre (UNJLC) had an operation in Congo to support humanitarian relief agencies working there, and its bulletins and maps about the transport situation are archived on ReliefWeb.

The First and Second Congo Wars saw great destruction of transport infrastructure from which the country has not yet recovered. Many vehicles were destroyed or commandeered by militias, especially in the north and east of the country, and the fuel supply system was also badly affected. Consequently, outside of Kinshasa, Matadi and Lubumbashi, private and commercial road transport is almost non-existent and traffic is scarce even where roads are in good condition. The few vehicles in use outside these cities are run by the United Nations, aid agencies, the DRC government, and a few larger companies such as those in the mining and energy sectors. High-resolution satellite photos on the Internet show large cities such as Bukavu, Butembo and Kikwit virtually devoid of traffic, compared to similar photos of towns in neighbouring countries.

Air transport is the only effective means of moving between many places within the country. The Congolese government, the United Nations, aid organisations and large companies use air rather than ground transport to move personnel and freight. The UN operates a large fleet of aircraft and helicopters, and compared to other African countries the DRC has a large number of small domestic airlines and air charter companies. The transport (and smuggling) of minerals with a high value for weight is also carried out by air, and in the east, some stretches of paved road isolated by destroyed bridges or impassable sections have been turned into airstrips.

For the ordinary citizen though, especially in rural areas, often the only options are to cycle, walk or go by dugout canoe.

Some parts of the DRC are more accessible from neighbouring countries than from Kinshasa. For example, Bukavu itself and Goma and other north-eastern towns are linked by paved road from the DRC border to the Kenyan port of Mombasa, and most goods for these cities have been brought via this route in recent years. Similarly, Lubumbashi and the rest of Katanga Province is linked to Zambia, through which the paved highway and rail networks of Southern Africa can be accessed. Such links through neighbouring countries are generally more important for the east and south-east of the country, and are more heavily used, than surface links to the capital.

In 2007 China agreed to lend the DRC US$5bn for two major transport infrastructure projects to link mineral-rich Katanga, specifically Lubumbashi, by rail to an ocean port (Matadi) and by road to the Kisangani river port, and to improve its links to the transport network of Southern Africa in Zambia. The two projects would also link the major parts of the country not served by water transport, and the main centres of the economy. Loan repayments will be from concessions for raw materials which China desperately needs: copper, cobalt, gold and nickel, as well as by toll revenues from the road and railway. In the face of reluctance by the international business community to invest in DRC, this represents a revitalisation of DRC's infrastructure much needed by its government.

The China Railway Seventh Group Co. Ltd will be in charge of the contract, under signed by the China Railway Engineering Corporation, with construction to be started from June 2008.

The Democratic Republic of the Congo has fewer all-weather paved highways than any country of its population and size in Africa — a total of 2250 km, of which only 1226 km is in good condition (see below). To put this in perspective, the road distance across the country in any direction is more than 2500 km (e.g. Matadi to Lubumbashi, 2700 km by road). The figure of 2250 km converts to 35 km of paved road per 1,000,000 of population. Comparative figures for Zambia and Botswana are 721 km and 3427 km respectively.

The road network is theoretically divided into four categories (national roads, priority regional roads, secondary regional roads and local roads), however, the United Nations Joint Logistics Centre (UNJLC) reports that this classification is of little practical use because some roads simply do not exist. For example, National Road 9 is not operational and cannot be detected by remote sensing methods.

The two principal highways are:

The total road network in 2005, according to the UNJLC, consisted of:


The UNJLC also points out that the pre-Second Congo War network no longer exists, and is dependent upon 20,000 bridges and 325 ferries, most of which are in need of repair or replacement. In contrast, a Democratic Republic of the Congo government document shows that, also in 2005, the network of main highways in good condition was as follows:

The 2000 Michelin "Motoring and Tourist Map 955 of Southern and Central Africa", which categorizes roads as "surfaced", "improved" (generally unsurfaced but with gravel added and graded), "partially improved" and "earth roads" and "tracks" shows that there were 2694 km of paved highway in 2000. These figures indicate that, compared to the more recent figures above, there has been a deterioration this decade, rather than improvement.

Three routes in the Trans-African Highway network pass through DR Congo:

The DRC has more navigable rivers and moves more passengers and goods by boat and ferry than any other country in Africa. Kinshasa, with 7 km of river frontage occupied by wharfs and jetties, is the largest inland waterways port on the continent. However, much of the infrastructure — vessels and port handling facilities — has, like the railways, suffered from poor maintenance and internal conflict.

The total length of waterways is estimated at 15,000 km including the Congo River, its tributaries, and unconnected lakes.

The 1000-kilometre Kinshasa-Kisangani route on the Congo River is the longest and best-known. It is operated by river tugs pushing several barges lashed together, and for the hundreds of passengers and traders these function like small floating towns. Rather than mooring at riverside communities along the route, traders come out by canoe and small boat alongside the river barges and transfer goods on the move.

Most waterway routes do not operate to regular schedules. It is common for an operator to moor a barge at a riverside town and collect freight and passengers over a period of weeks before hiring a river tug to tow or push the barge to its destination.


The middle Congo River and its tributaries from the east are the principal domestic waterways in the DRC. The two principal river routes are:
See the diagrammatic transport map above for other river waterways.

The most-used domestic lake waterways are:

Most large Congo river ferry boats were destroyed during the civil war. Only smaller boats are running and they are irregular.





petroleum products 390 km

1 petroleum tanker

Due to the lack of roads, operating railroads and ferry transportation many people traveling around the country fly on aircraft. As of 2016 the country does not have an international passenger airline and relies on foreign-based airlines for international connections. Congo Airways provides domestic flights and are based at Kinshasa's N'djili Airport which serves as the country's main international airport. Lubumbashi International Airport in the country's south-east is also serviced by several international airlines. 

<br>"total:"
24
<br>"over 3,047 m:"
4
<br>"2,438 to 3,047 m:"
2
<br>"1,524 to 2,437 m:"
16
<br>"914 to 1,523 m:"
2 (2002 est.)

<br>"total:"
205
<br>"1,524 to 2,437 m:"
19
<br>"914 to 1,523 m:"
95
<br>"under 914 m:"
91 (2002 est.)

All air carriers certified by the Democratic Republic of the Congo have been banned from operating at airports in the European Community by the European Commission because of inadequate safety standards.





The Democratic Republic of the Congo has a rocketry program called Troposphere.




</doc>
<doc id="8029" url="https://en.wikipedia.org/wiki?curid=8029" title="Armed Forces of the Democratic Republic of the Congo">
Armed Forces of the Democratic Republic of the Congo

The Armed Forces of the Democratic Republic of the Congo ( [FARDC]) is the state organisation responsible for defending the Democratic Republic of the Congo. The FARDC was rebuilt patchily as part of the peace process which followed the end of the Second Congo War in July 2003.

The majority of FARDC members are land forces, but it also has a small air force and an even smaller navy. In 2010–11 the three services may have numbered between 144,000 and 159,000 personnel. In addition, there is a presidential force called the Republican Guard, but it and the Congolese National Police (PNC) are not part of the Armed Forces.

The government in the capital city Kinshasa, the United Nations, the European Union, and bilateral partners which include Angola, South Africa, and Belgium are attempting to create a viable force with the ability to provide the Democratic Republic of Congo with stability and security. However, this process is being hampered by corruption, inadequate donor coordination, and competition between donors. The various military units now grouped under the FARDC banner are some of the most unstable in Africa after years of war and underfunding.

To assist the new government, since February 2000 the United Nations has had the United Nations Mission in the Democratic Republic of Congo (now called MONUSCO), which currently has a strength of over 16,000 peacekeepers in the country. Its principal tasks are to provide security in key areas, such as the South Kivu and North Kivu in the east, and to assist the government in reconstruction. Foreign rebel groups are also in the Congo, as they have been for most of the last half-century. The most important is the Democratic Forces for the Liberation of Rwanda (FDLR), against which Laurent Nkunda's troops were fighting, but other smaller groups such as the anti-Ugandan Lord's Resistance Army are also present.

The legal standing of the FARDC was laid down in the Transitional Constitution, articles 118 and 188. This was then superseded by provisions in the 2006 Constitution, articles 187 to 192. Law 04/023 of 12 November 2004 establishes the General Organisation of Defence and the Armed Forces. In mid-2010, the Congolese Parliament was debating a new defence law, provisionally designated Organic Law 130.

The first organised Congolese troops, known as the , were created in 1888 when King Leopold II of Belgium, who held the Congo Free State as his private property, ordered his Secretary of the Interior to create military and police forces for the state. In 1908, under international pressure, Leopold ceded administration of the colony to the government of Belgium as the Belgian Congo. It remained under the command of a Belgian officer corps through to the independence of the colony in 1960. The "Force Publique" saw combat in Cameroun, and successfully invaded and conquered areas of German East Africa, notably present day Rwanda, during World War I. Elements of the "Force Publique" were also used to form Belgian colonial units that fought in the East African Campaign during World War II.

At independence on 30 June 1960, the army suffered from a dramatic deficit of trained leaders, particularly in the officer corps. This was because the "Force Publique" had always only been officered by Belgian or other expatriate whites. The Belgian Government made no effort to train Congolese commissioned officers until the very end of the colonial period, and in 1958, only 23 African cadets had been admitted even to the military secondary school. The highest rank available to Congolese was adjutant, which only four soldiers achieved before independence. Though 14 Congolese cadets were enrolled in the Royal Military Academy in Brussels in May, they were not scheduled to graduate as second lieutenants until 1963. Ill-advised actions by Belgian officers led to an enlisted ranks' rebellion on 5 July 1960, which helped spark the Congo Crisis. Lieutenant General Émile Janssens, the "Force Publique" commander, wrote during a meeting of soldiers that 'Before independence=After Independence', pouring cold water on the soldiers' desires for an immediate raise in their status.

Vanderstraeten says that on the morning of 8 July 1960, following a night during which all control had been lost over the soldiers, numerous ministers arrived at Camp Leopold with the aim of calming the situation. Both Prime Minister Patrice Lumumba and President Joseph Kasa-Vubu eventually arrived, and the soldiers listened to Kasa-Vubu "religiously." After his speech, Kasa-Vubu and the ministers present retired into the camp canteen to hear a delegation from the soldiers. Vanderstraeten says that, according to Joseph Ileo, their demands ("revendications") included the following:
The "laborious" discussions which then followed were later retrospectively given the label of an "extraordinary ministerial council." Gérald-Libois writes that '..the special meeting of the council of ministers took steps for the immediate Africanisation of the officer corps and named Victor Lundula, who was born in Kasai and was burgomaster of Jadotville, as Commander-in-Chief of the ANC; Colonel Joseph-Désiré Mobutu as chief of staff; and the Belgian, Colonel Henniquiau, as chief advisor to the ANC.' Thus General Janssens was dismissed. Both Lundula and Mobutu were former sergeants of the "Force Publique". 

On 8–9 July 1960, the soldiers were invited to appoint black officers, and 'command of the army passed securely into the hands of former sergeants,' as the soldiers in general chose the most-educated and highest-ranked Congolese army soldiers as their new officers. Most of the Belgian officers were retained as advisors to the new Congolese hierarchy, and calm returned to the two main garrisons at Leopoldville and Thysville. The "Force Publique" was renamed the "Armée nationale congolaise" (ANC), or Congolese National Armed Forces. However, in Katanga Belgian officers resisted the Africanisation of the army.

On 9 July 1960, there was a "Force Publique" mutiny at Camp Massart at Elizabethville; five or seven Europeans were killed. The army revolt and resulting rumours caused severe panic across the country, and Belgium despatched troops and the naval Task Group 218.2 to protect its citizens. Belgian troops intervened in Elisabethville and Luluabourg (10 July), Matadi (11 July), Leopoldville (13 July) and elsewhere. There were immediate suspicions that Belgium planned to re-seize the country while doing so. Large numbers of Belgian colonists fled the country. At the same time, on 11 July, Moise Tshombe declared the independence of Katanga Province in the south-east, closely backed by remaining Belgian administrators and soldiers.
On 14 July 1960, in response to requests by Prime Minister Lumumba, the UN Security Council adopted United Nations Security Council Resolution 143. This called upon Belgium to remove its troops and for the UN to provide 'military assistance' to the Congolese forces to allow them 'to meet fully their tasks'. Lumumba demanded that Belgium remove its troops immediately, threatening to seek help from the Soviet Union if they did not leave within two days. The UN reacted quickly and established the United Nations Operation in the Congo (ONUC). The first UN troops arrived the next day but there was instant disagreement between Lumumba and the UN over the new force's mandate. Because the Congolese army had been in disarray since the mutiny, Lumumba wanted to use the UN troops to subdue Katanga by force. Lumumba became extremely frustrated with the UN's unwillingness to use force against Tshombe and his secession. He cancelling a scheduled meeting with Secretary General Hammarskjöld on August 14 and wrote a series of angry letters instead. To Hammarskjöld, the secession of Katanga was an internal Congolese matter and the UN was forbidden to intervene by Article 2 of the United Nations Charter. Disagreements over what the UN force could and could not do continued throughout its deployment.

By 20 July 1960, 3,500 troops for ONUC had arrived in the Congo. The first contingent of Belgian forces had left Leopoldville on 16 July upon the arrival of the United Nations troops. Following assurances that contingents of the Force would arrive in sufficient numbers, the Belgian authorities agreed to withdraw all their forces from the Leopoldville area by 23 July. The last Belgian troops left the country by 23 July, as United Nations forces continued to deploy throughout the Congo. The build of ONUC continued, its strength increasing to over 8,000 by 25 July and to over 11,000 by 31 July 1960. A basic agreement between the United Nations and the Congolese Government on the operation of the Force was agreed by 27 July. On 9 August, Albert Kalonji proclaimed the independence of South Kasai.
During the crucial period of July–August 1960, Mobutu built up "his" national army by channeling foreign aid to units loyal to him, by exiling unreliable units to remote areas, and by absorbing or dispersing rival armies. He tied individual officers to him by controlling their promotion and the flow of money for payrolls. Researchers working from the 1990s have concluded that money was directly funnelled to the army by the U.S. Central Intelligence Agency, the UN, and Belgium. Despite this, by September 1960, following the four-way division of the country, there were four separate armed forces: Mobotu's ANC itself, numbering about 12,000, the South Kasai Constabulary loyal to Albert Kalonji (3,000 or less), the Katanga Gendarmerie which were part of Moise Tshombe's regime (totalling about 10,000), and the Stanleyville dissident ANC loyal to Antoine Gizenga (numbering about 8,000).

In August 1960, due to rejection of requests to the UN for aid to suppress the South Kasai and Katanga revolts, Lumumba's government decided to request Soviet help. de Witte writes that 'Leopoldville asked the Soviet Union for planes, lorries, arms, and equipment. ... Shortly afterwards, on 22 or 23 August, about 1,000 soldiers left for Kasai.' de Witte goes on to write that on 26–27 August, the ANC seized Bakwanga, Albert Kalonji's capital in South Kasai, without serious resistance. "In the next two days it temporarily put an end to the secession of Kasai."

The Library of Congress Country Study for the Congo says at this point that:
"[On 5 September 1960] Kasavubu also appointed Mobutu as head of the ANC. Joseph Ileo was chosen as the new prime minister and began trying to form a new government. Lumumba and his cabinet responded by accusing Kasa-Vubu of high treason and voted to dismiss him. Parliament refused to confirm the dismissal of either Lumumba or Kasavubu and sought to bring about a reconciliation between them. After a week's deadlock, Mobutu announced on September 14 that he was assuming power until 31 December 1960, in order to "neutralize" both Kasavubu and Lumumba." Mobutu formed the College of Commissioners-General, a technocratic government of university graduates.

In early January 1961, ANC units loyal to Lumumba invaded northern Katanga to support a revolt of Baluba tribesmen against Tshombe's secessionist regime. On 23 January 1961, Kasa-Vubu promoted Mobutu to major-general; De Witte argues that this was a political move, "aimed to strengthen the army, the president's sole support, and Mobutu's position within the army."

United Nations Security Council Resolution 161 of 21 February 1961, called for the withdrawal of Belgian officers from command positions in the ANC, and the training of new Congolese officers with UN help. ONUC made a number of attempts to retrain the ANC from August 1960 to June 1963, often been set back by political changes. By March 1963 however, after the visit of Colonel Michael Greene of the United States Army, and the resulting "Greene Plan", the pattern of bilaterally agreed military assistance to various Congolese military components, instead of a single unified effort, was already taking shape.
In early 1964, a new crisis broke out as Congolese rebels calling themselves "Simba" (Swahili for "Lion") rebelled against the government. They were led by Pierre Mulele, Gaston Soumialot and Christophe Gbenye who were former members of Gizenga's Parti Solidaire Africain (PSA). The rebellion affected Kivu and Eastern (Orientale) provinces. By August they had captured Stanleyville and set up a rebel government there. As the rebel movement spread, discipline became more difficult to maintain, and acts of violence and terror increased. Thousands of Congolese were executed, including government officials, political leaders of opposition parties, provincial and local police, school teachers, and others believed to have been Westernised. Many of the executions were carried out with extreme cruelty, in front of a monument to Lumumba in Stanleyville. Tshombe decided to use foreign mercenaries as well as the ANC to suppress the rebellion. Mike Hoare was employed to create the English-speaking 5 Commando ANC at Kamina, with the assistance of a Belgian officer, Colonel Frederic Vanderwalle, while 6 Commando ANC was French-speaking and originally under the command of a Belgian Army colonel, Lamouline. By August 1964, the mercenaries, with the assistance of other ANC troops, were making headway against the Simba rebellion. Fearing defeat, the rebels started taking hostages of the local white population in areas under their control. These hostages were rescued in Belgian airdrops (Dragon Rouge and Dragon Noir) over Stanleyville and Paulis airlift sed by U.S. aircraft. The operation coincided with the arrival of mercenary units (seemingly including the hurriedly formed 5th Mechanised Brigade) at Stanleyville which was quickly captured. It took until the end of the year to completely put down the remaining areas of rebellion.

After five years of turbulence, in 1965 Mobutu used his position as ANC Chief of Staff to seize power in the 1965 Democratic Republic of the Congo coup d'état. Although Mobutu succeeded in taking power, his position was soon threatened by the Stanleyville mutinies, also known as the Mercenaries' Mutinies, which were eventually suppressed.

As a general rule, since that time, the armed forces have not intervened in politics as a body, rather being tossed and turned as ambitious men have shaken the country. In reality, the larger problem has been the misuse and sometimes abuse of the military and police by political and ethnic leaders.

On 16 May 1968 a parachute brigade of two regiments (each of three battalions) was formed which eventually was to grow in size to a full division.

The country was renamed Zaire in 1971 and the army was consequently designated the (FAZ). In 1971 the army's force consisted of the 1st Groupement at Kananga, with one guard battalion, two infantry battalions, and a gendarmerie battalion attached, and the 2nd Groupement (Kinshasa), the 3rd Groupement (Kisangani), the 4th Groupement (Lubumbashi), the 5th Groupement (Bukavu), the 6th Groupement (Mbandaka), and the 7th Groupement (Boma). Each was about the size of a brigade, and commanded by aging generals who have had no military training, and often not much positive experience, since they were NCOs in the Belgian Force Publique.' By the late 1970s the number of groupements reached nine, one per administrative region. The parachute division (Division des Troupes Aéroportées Renforcées de Choc, DITRAC) operated semi-independently from the rest of the army.

In July 1972 a number of the aging generals commanding the "groupements" were retired. Général d'armée Louis Bobozo, and Generaux de Corps d'Armée Nyamaseko Mata Bokongo, Nzoigba Yeu Ngoli, Muke Massaku, Ingila Grima, Itambo Kambala Wa Mukina, Tshinyama Mpemba, and General de Division Yossa Yi Ayira, the last having been commander of the Kamina base, were all retired on 25 July 1972. Taking over as military commander-in-chief, now titled Captain General, was newly promoted General de Division Bumba Moaso, former commander of the parachute division.

A large number of countries supported the FAZ in the early 1970s. Three hundred Belgian personnel were serving as staff officers and advisors throughout the Ministry of Defence, Italians were supporting the Air Force, Americans were assisting with transport and communications, Israelis with airborne forces training, and there were British advisors with the engineers. In 1972 the state-sponsored political organization, the Mouvement Populaire de la Révolution (MPR), resolved at a party congress to form activist cells in each military unit. The decision caused consternation among the officer corps, as the army had been apolitical (and even anti-political) since before independence.

On 11 June 1975 several military officers were arrested in what became known as the "coup monté et manqué." Amongst those arrested were Générals Daniel Katsuva wa Katsuvira, Land Forces Chief of Staff, Utshudi Wembolenga, Commandant of the 2nd Military Region at Kalemie; Fallu Sumbu, Military Attaché of Zaïre in Washington, Colonel Mudiayi wa Mudiayi, the military attaché of Zaïre in Paris, the military attache in Brussels, a paracommando battalion commander, and several others. The regime alleged these officers and others (including Mobutu's "secrétaire particulier") had plotted the assassination of Mobutu, high treason, and disclosure of military secrets, among other offences. The alleged coup was investigated by a revolutionary commission headed by Boyenge Mosambay Singa, at that time head of the Gendarmerie. Writing in 1988, Michael Schatzberg said the full details of the coup had yet to emerge. Meitho, writing many years later, says the officers were accused of trying to raise Mobutu's "secrétaire particulier", Colonel Omba Pene Djunga, from Kasai, to power.
In late 1975, Mobutu, in a bid to install a pro-Kinshasa government in Angola and thwart the Marxist Popular Movement for the Liberation of Angola (MPLA)'s drive for power, deployed FAZ armoured cars, paratroopers, and three infantry battalions to Angola in support of the National Liberation Front of Angola (FNLA).
On 10 November 1975, an anti-Communist force made up of 1,500 FNLA fighters, 100 Portuguese Angolan soldiers, and two FAZ battalions passed near the city of Quifangondo, only north of Luanda, at dawn on 10 November. The force, supported by South African aircraft and three 140 mm artillery pieces, marched in a single line along the Bengo River to face an 800-strong Cuban force across the river. Thus the Battle of Quifangondo began. The Cubans and MPLA fighters bombarded the FNLA with mortar and 122 mm rockets, destroying most of the FNLA's armoured cars and six Jeeps carrying antitank rockets in the first hour of fighting.

Mobutu's support for the FNLA policy backfired when the MPLA won in Angola. The MPLA, then, acting ostensibly at least as the Front for Congolese National Liberation, occupied Zaire's southeastern Katanga Province, then known as Shaba, in March 1977, facing little resistance from the FAZ. This invasion is sometimes known as Shaba I. Mobutu had to request assistance, which was provided by Morocco in the form of regular troops who routed the MPLA and their Cuban advisors out of Katanga. Also important were Egyptian pilots who flew Zaire's Mirage 5 combat aircraft. The humiliation of this episode led to civil unrest in Zaire in early 1978, which the FAZ had to put down.
The poor performance of Zaire's military during Shaba I gave evidence of chronic weaknesses. One problem was that some of the Zairian soldiers in the area had not received pay for extended periods. Senior officers often kept the money intended for the soldiers, typifying a generally disreputable and inept senior leadership in the FAZ. As a result, many soldiers simply deserted rather than fight. Others stayed with their units but were ineffective. During the months following the Shaba invasion, Mobutu sought solutions to the military problems that had contributed to the army's dismal performance. He implemented sweeping reforms of the command structure, including wholesale firings of high-ranking officers. He merged the military general staff with his own presidential staff and appointed himself chief of staff again, in addition to the positions of minister of defence and supreme commander that he already held. He also redeployed his forces throughout the country instead of keeping them close to Kinshasa, as had previously been the case. The Kamanyola Division, at the time considered the army's best formation, and considered the president's own, was assigned permanently to Shaba. In addition to these changes, the army's strength was reduced by 25 percent. Also, Zaire's allies provided a large influx of military equipment, and Belgian, French, and American advisers assisted in rebuilding and retraining the force.

Despite these improvements, a second invasion by the former Katangan gendarmerie, known as Shaba II in May–June 1978, was only dispersed with the despatch of the French 2e régiment étranger de parachutistes and a battalion of the Belgian Paracommando Regiment. Kamanyola Division units collapsed almost immediately. French units fought the Battle of Kolwezi to recapture the town from the FLNC. The U.S. provided logistical assistance.

In July 1975, according to the IISS Military Balance, the FAZ was made up of 14 infantry battalions, seven "Guard" battalions, and seven other infantry battalions variously designated as "parachute" (or possibly "commando"; probably the units of the new parachute brigade originally formed in 1968). There were also an armoured car regiment and a mechanised infantry battalion. Organisationally, the army was made up of seven brigade groups and one parachute division. In addition to these units, a tank battalion was reported to have formed by 1979.

In January 1979 "General de Division" Mosambaye Singa Boyenge was named as both military region commander and Region Commissioner for Shaba.

In 1984, a militarised police force, the Civil Guard, was formed. It was eventually commanded by Général d'armée Kpama Baramoto Kata.

Thomas Turner wrote in the late 1990s that "[m]ajor acts of violence, such as the killings that followed the "Kasongo uprising" in Bandundu Region in 1978, the killings of diamond miners in Kasai-Oriental Region in 1979, and, more recently, the massacre of students in Lubumbashi in 1990, continued to intimidate the population."

The authors of the Library of Congress Country Study on Zaire commented in 1992–93 that: "The maintenance status of equipment in the inventory has traditionally varied, depending on a unit's priority and the presence or absence of foreign advisers and technicians. A considerable portion of military equipment is not operational, primarily as a result of shortages of spare parts, poor maintenance, and theft. For example, the tanks of the 1st Armoured Brigade often have a nonoperational rate approaching 70 to 80 percent. After a visit by a Chinese technical team in 1985, most of the tanks operated, but such an improved status generally has not lasted long beyond the departure of the visiting team. Several factors complicate maintenance in Zairian units. Maintenance personnel often lack the training necessary to maintain modern military equipment. Moreover, the wide variety of military equipment and the staggering array of spare parts necessary to maintain it not only clog the logistic network but also are expensive.

The most important factor that negatively affects maintenance is the low and irregular pay that soldiers receive, resulting in the theft and sale of spare parts and even basic equipment to supplement their meager salaries. When not stealing spare parts and equipment, maintenance personnel often spend the better part of their duty day looking for other ways to profit. American maintenance teams working in Zaire found that providing a free lunch to the work force was a good, sometimes the only, technique to motivate personnel to work at least half of the duty day.

The army's logistics corps [was tasked].. to provide logistic support and conduct direct, indirect, and depot-level maintenance for the FAZ. But because of Zaire's lack of emphasis on maintenance and logistics, a lack of funding, and inadequate training, the corps is understaffed, underequipped, and generally unable to accomplish its mission. It is organised into three battalions assigned to Mbandaka, Kisangani, and Kamina, but only the battalion at Kamina is adequately staffed; the others are little more than skeleton" units.

The poor state of discipline of the Congolese forces became apparent again in 1990. Foreign military assistance to Zaire ceased following the end of the Cold War and Mobutu deliberately allowed the military's condition to deteriorate so that it did not threaten his hold on power. Protesting low wages and lack of pay, paratroopers began looting Kinshasa in September 1991 and were only stopped after intervention by French ('Operation Baumier') and Belgian ('Operation Blue Beam') forces.

In 1993, according to the Library of Congress Country Studies, the 25,000-member FAZ ground forces consisted of one infantry division (with three infantry brigades); one airborne brigade (with three parachute battalions and one support battalion); one special forces (commando/counterinsurgency) brigade; the Special Presidential Division; one independent armoured brigade; and two independent infantry brigades (each with three infantry battalions, one support battalion). These units were deployed throughout the country, with the main concentrations in Shaba Region (approximately half the force). The Kamanyola Division, consisting of three infantry brigades operated generally in western Shaba Region; the 21st Infantry Brigade was located in Lubumbashi; the 13th Infantry Brigade was deployed throughout eastern Shaba; and at least one battalion of the 31st Airborne Brigade stayed at Kamina. The other main concentration of forces was in and around Kinshasa: the 31st Airborne Brigade was deployed at N'djili Airport on the outskirts of the capital; the Special Presidential Division (DSP) resided adjacent to the presidential compound; and the 1st Armoured Brigade was at Mbanza-Ngungu (in Bas-Congo, approximately southwest of Kinshasa). Finally the 41st Commando Brigade was at Kisangani.

This superficially impressive list of units overstates the actual capability of the armed forces at the time. Apart from privileged formations such as the Presidential Division and the 31st Airborne Brigade, most units were poorly trained, divided and so badly paid that they regularly resorted to looting. What operational abilities the armed forces had were gradually destroyed by politicisation of the forces, tribalisation, and division of the forces, included purges of suspectedly disloyal groups, intended to allow Mobutu to divide and rule. All this occurred against the background of increasing deterioration of state structures under the kleptocratic Mobutu regime.

Much of the origins of the recent conflict in what is now the Democratic Republic of the Congo stems from the turmoil following the Rwandan genocide of 1994, which then led to the Great Lakes refugee crisis. Within the largest refugee camps, beginning in Goma in Nord-Kivu, were Rwandan Hutu fighters, who were eventually organised into the Rassemblement Démocratique pour le Rwanda, who launched repeated attacks into Rwanda. Rwanda eventually backed Laurent-Désiré Kabila and his quickly organised Alliance of Democratic Forces for the Liberation of Congo (AFDL) in invading Zaire, aiming to stop the attacks on Rwanda in the process of toppling Mobutu's government. When the militias rebelled, backed by Rwanda, the FAZ, weakened as is noted above, proved incapable of mastering the situation and preventing the overthrow of Mobutu in 1997. Elements of the Mobutu-loyal FAZ managed to retreat into northern Congo, and from there into Sudan while attempting to escape the AFDL. Allying themselves with the Sudanese government which was fighting its own civil war at the time, these FAZ troops were destroyed by the Sudan People's Liberation Army during Operation Thunderbolt near Yei in March 1997.

When Kabila took power in 1997, the country was renamed the Democratic Republic of the Congo and so the name of the national army changed once again, to the "Forces armées congolaises" (FAC). Tanzania sent six hundred military advisors to train Kabila's new army in May 1997. (Prunier says that the instructors were still at the Kitona base when the Second Congo War broke out, and had to be quickly returned to Tanzania. Prunier said "South African aircraft carried out the evacuation after a personal conversation between President Mkapa and not-yet-president Thabo Mbeki. Command over the armed forces in the first few months of Kabila's rule was vague. Gérard Prunier writes that "there was no minister of defence, no known chief of staff, and no ranks; all officers were Cuban-style 'commanders' called 'Ignace', 'Bosco', Jonathan', or 'James', who occupied connecting suites at the Intercontinental Hotel and had presidential list cell-phone numbers. None spoke French or Lingala, but all spoke Kinyarwanda, Swahili, and, quite often, English." On being asked by Belgian journalist Colette Braeckman what was the actual army command structure apart from himself, Kabila answered 'We are not going to expose ourselves and risk being destroyed by showing ourselves openly... . We are careful so that the true masters of the army are not known. It is strategic. Please, let us drop the matter.' Kabila's new "Forces armées congolaises" were riven with internal tensions. The new FAC had Banyamulenge fighters from South Kivu, "kadogo" child soldiers from various eastern tribes, such as Thierry Nindaga, Safari Rwekoze, etc... [the mostly] Lunda Katangese Tigers of the former FNLC, and former FAZ personnel. Mixing these disparate and formerly warring elements together led to mutiny. On 23 February 1998, a mostly Banyamulenge unit mutiniued at Bukavu after its officers tried to disperse the soldiers into different units spread all around the Congo. By mid-1998, formations on the outbreak of the Second Congo War included the Tanzanian-supported 50th Brigade, headquartered at Camp Kokolo in Kinshasa, and the 10th Brigade — one of the best and largest units in the army — stationed in Goma, as well as the 12th Brigade in Bukavu. The declaration of the 10th Brigade's commander, former DSP officer Jean-Pierre Ondekane, on 2 August 1998 that he no longer recognised Kabila as the state's president was one of the factors in the beginning of the Second Congo War.

The FAC performed poorly throughout the Second Congo War and "demonstrated little skill or recognisable military doctrine". At the outbreak of the war in 1998 the Army was ineffective and the DRC Government was forced to rely on assistance from Angola, Chad, Namibia and Zimbabwe. As well as providing expeditionary forces, these countries unsuccessfully attempted to retrain the DRC Army. North Korea and Tanzania also provided assistance with training. During the first year of the war the Allied forces defeated the Rwandan force which had landed in Bas-Congo and the rebel forces south-west of Kinshasa and eventually halted the rebel and Rwandan offensive in the east of the DRC. These successes contributed to the Lusaka Ceasefire Agreement which was signed in July 1999. Following the Lusaka Agreement, in mid-August 1999 President Kabila issued a decree dividing the country into eight military regions. The first military region, Congolese state television reported, would consist of the two Kivu provinces, Orientale Province would form the second region, and Maniema and Kasai-Oriental provinces the third. Katanga and Équateur would fall under the fourth and fifth regions, respectively, while Kasai-Occidental and Bandundu would form the sixth region. Kinshasa and Bas-Congo would form the seventh and eighth regions, respectively. In November 1999 the Government attempted to form a 20,000-strong paramilitary force designated the People's Defence Forces. This force was intended to support the FAC and national police but never became effective.

The Lusaka Ceasefire Agreement was not successful in ending the war, and fighting resumed in September 1999. The FAC's performance continued to be poor and both the major offensives the Government launched in 2000 ended in costly defeats. President Kabila's mismanagement was an important factor behind the FAC's poor performance, with soldiers frequently going unpaid and unfed while the Government purchased advanced weaponry which could not be operated or maintained. The defeats in 2000 are believed to have been the cause of President Kabila's assassination in January 2001. Following the assassination, Joseph Kabila assumed the presidency and was eventually successful in negotiating an end to the war in 2002–2003.

The December 2002 Global and All-Inclusive Agreement devoted Chapter VII to the armed forces. It stipulated that the armed forces chief of staff, and the chiefs of the army, air force, and navy were not to come from the same warring faction. The new "national, restructured and integrated" army would be made up from Kabila's government forces (the FAC), the RCD, and the MLC. Also stipulated in VII(b) was that the RCD-N, RCD-ML, and the Mai-Mai would become part of the new armed forces. An intermediate mechanism for physical identification of the soldiers, and their origin, date of enrolment, and unit was also called for (VII(c)). It also provided for the creation of a Conseil Superieur de la Defense (Superior Defence Council) which would declare states of siege or war and give advice on security sector reform, disarmament/demobilization, and national defence policy.

A decision on which factions were to name chiefs of staff and military regional commanders was announced on 19 August 2003 as the first move in military reform, superimposed on top of the various groups of fighters, government and former rebels. Kabila was able to name the armed forces chief of staff, Lieutenant General Liwanga Mata, who previously served as navy chief of staff under Laurent Kabila. Kabila was able to name the air force commander (John Numbi), the RCD-Goma received the Land Force commander's position (Sylvain Buki) and the MLC the navy (Dieudonne Amuli Bahigwa). Three military regional commanders were nominated by the former Kinshasa government, two commanders each by the RCD-Goma and the MLC, and one region commander each by the RCD-K/ML and RCD-N. However these appointments were announced for Kabila's "Forces armées congolaises" (FAC), not the later FARDC. Another report however says that the military region commanders were only nominated in January 2004, and that the troop deployment on the ground did not change substantially until the year afterward.
On 24 January 2004, a decree created the "Structure Militaire d'Intégration" (SMI, Military Integration Structure). Together with the SMI, CONADER also was designated to manage the combined "tronc commun" DDR element and military reform programme. The first post-Sun City military law appears to have been passed on 12 November 2004, which formally created the new national Forces Armées de la République Démocratique du Congo (FARDC). Included in this law was article 45, which recognised the incorporation of a number of armed groups into the FARDC, including the former government army Forces Armées Congolaises (FAC), ex-FAZ personnel also known as former President Mobutu's 'les tigres', the RCD-Goma, RCD-ML, RCD-N, MLC, the Mai-Mai, as well as other government-determined military and paramilitary groups.

Turner writes that the two most prominent opponents of military integration ("brassage") were Colonel Jules Mutebusi, a Munyamulenge from South Kivu, and Laurent Nkunda, a Rwandaphone Tutsi who Turner says was allegedly from Rutshuru in North Kivu. In May–June 2004 Mutebusi led a revolt against his superiors from Kinshasa in South Kivu. Nkunda began his long series of revolts against central authority by helping Mutebusi in May–June 2004. In November 2004 a Rwandan government force entered North Kivu to attack the FDLR, and, it seems, reinforced and resupplied RCD-Goma (ANC) at the same time. Kabila despatched 10,000 government troops to the east in response, launching an attack that was called "Operation Bima". In the midst of this tension, Nkunda's men launched attacks in North Kivu in December 2004.

There was another major personnel reshuffle on 12 June 2007. FARDC chief General Kisempia Sungilanga Lombe was replaced with General Dieudonne Kayembe Mbandankulu. General Gabriel Amisi Kumba retained his post as Land Forces commander. John Numbi, a trusted member of Kabila's inner circle, was shifted from air force commander to Police Inspector General. U.S. diplomats reported that the former Naval Forces Commander Maj. General Amuli Bahigua (ex-MLC) became the FARDC's Chief of Operations; former FARDC Intelligence Chief General Didier Etumba (ex-FAC) was promoted to Vice Admiral and appointed Commander of Naval Forces; Maj. General Rigobert Massamba (ex-FAC), a former commander of the Kitona air base, was appointed as Air Forces Commander; and Brig. General Jean-Claude Kifwa, commander of the Republican Guard, was appointed as a regional military commander.

Due to significant delays in the DDR and integration process, of the eighteen brigades, only seventeen have been declared operational, over two and a half years after the initial target date. Responding to the situation, the Congolese Minister of Defence presented a new defence reform master plan to the international community in February 2008. Essentially the three force tiers all had their readiness dates pushed back: the first, territorial forces, to 2008–12, the mobile force to 2008–10, and the main defence force to 2015.

Much of the east of the country remains insecure, however. In the far northeast this is due primarily to the Ituri conflict. In the area around Lake Kivu, primarily in North Kivu, fighting continues among the Democratic Forces for the Liberation of Rwanda and between the government FARDC and Laurent Nkunda's troops, with all groups greatly exacerbating the issues of internal refugees in the area of Goma, the consequent food shortages, and loss of infrastructure from the years of conflict. In 2009, several United Nations officials stated that the army is a major problem, largely due to corruption that results in food and pay meant for soldiers being diverted and a military structure top-heavy with colonels, many of whom are former warlords. In a 2009 report itemizing FARDC abuses, Human Rights Watch urged the UN to stop supporting government offensives against eastern rebels until the abuses ceased.

Caty Clement wrote in 2009:
"One of the most notable [FARDC corruption] schemes was known as ‘Opération Retour’ (Operation Return). Senior officers ordered the soldiers’ pay to be sent from Kinshasa to the commanders in the field, who took their cut and returned the remainder to their commander in Kinshasa instead of paying the soldiers. To ensure that foot soldiers would be paid their due, in late 2005, EUSEC suggested separating the chain of command from the chain of payment. The former remained within Congolese hands, while the EU mission delivered salaries directly to the newly ‘integrated’ brigades. Although efficient in the short term, this solution raises the question of sustainability and ownership in the long term. Once soldiers’ pay could no longer be siphoned off via ‘Opération Retour’, however, two other budgetary lines, the ‘fonds de ménage’ and logistical support to the brigades, were soon diverted."

In 2010, thirty FARDC officers were given scholarships to study in Russian military academies. This is part of a greater effort by Russia to help improve the FARDC. A new military attaché and other advisers from Russia visited the DRC.

On 22 November 2012, Gabriel Amisi Kumba was suspended from his position in the Forces Terrestres by president Joseph Kabila due to an inquiry into his alleged role in the sale of arms to various rebel groups in the eastern part of the country, which may have implicated the rebel group M23. In December 2012 it was reported that members of Army units in the north east of the country are often not paid due to corruption, and these units rarely made against villages by the Lord's Resistance Army.

The FARDC deployed 850 soldiers and 150 PNC police officers as part of an international force in the Central African Republic, which the DRC borders to the north. The country had been in a state of civil war since 2012, when the president was ousted by rebel groups. The DRC was urged by French president François Hollande to keep its troops in CAR.

In July 2014, the Congolese army carried out a joint operation with UN troops in the Masisi and Walikale territories of the North Kivu province. In the process, they liberated over 20 villages and a mine from the control of two rebel groups, the Mai Mai Cheka and the Alliance for the Sovereign and Patriotic Congo.

In October 2017 the UN published a report announcing that the FARDC no longer employed child soldiers but was still listed under militaries that committed sexual violations against children.

Troops operating with MONUSCO in North Kiuv were attacked by likely rebels from the Allied Democratic Forces on December 8, 2017. After a protracted firefight the troops suffered 5 dead along with 14 dead among the UN force.

The President, Major General Joseph Kabila is the Commander-in-Chief of the Armed Forces. The Minister of Defence, formally Ministers of Defence, Disarmament, and Veterans (Ancien Combattants), with the French acronym MDNDAC, is Alexandre Luba Ntambo.

The Colonel Tshatshi Military Camp in the Kinshasa suburb of Ngaliema hosts the defence department and the Chiefs of Staff central command headquarters of the FARDC. Jane's data from 2002 appears inaccurate; there is at least one ammunition plant in Katanga.

Below the Chief of Staff, the current organisation of the FARDC is not fully clear. There is known to be a Military Intelligence branch – Service du Renseignement militaire (SRM), the former DEMIAP. The FARDC is known to be broken up into the Land Forces ("Forces Terrestres"), Navy and Air Force. The Land Forces are distributed around ten military regions, up from the previous eight, following the ten provinces of the country. There is also a training command, the Groupement des Écoles Supérieurs Militaires (GESM) or Group of Higher Military Schools, which, in January 2010, was under the command of Major General Marcellin Lukama. The Navy and Air Forces are composed of various "groupments" (see below). There is also a central logistics base.

It should be made clear also that Joseph Kabila does not trust the military; the Republican Guard is the only component he trusts. Major General John Numbi, former Air Force chief, now inspector general of police, ran a parallel chain of command in the east to direct the 2009 Eastern Congo offensive, Operation Umoja Wetu; the regular chain of command was by-passed. Previously Numbi negotiated the agreement to carry out the "mixage" process with Laurent Nkunda. Commenting on a proposed vote of no confidence in the Minister of Defence in September 2012, Baoudin Amba Wetshi of "lecongolais.cd" described Ntolo as a "scapegoat". Wetshi said that all key military and security questions were handled in total secrecy by the President and other civil and military personalities trusted by him, such as John Numbi, Gabriel Amisi Kumba ('Tango Four'), Delphin Kahimbi, and others such as Kalev Mutond and Pierre Lumbi Okongo.

The available information on armed forces' Chiefs of Staff is incomplete and sometimes contradictory. In addition to armed forces chiefs of staff, in 1966 Lieutenant Colonel Ferdinand Malila was listed as Army Chief of Staff.

Virtually all officers have now changed positions, but this list gives an outline of the structure in January 2005. Despite the planned subdivision of the country into more numerous provinces, the actual splitting of the former provinces has not taken place.

In September 2014, President Kabila reshuffled the command structure and in addition to military regions created three new 'defense zones' which would be subordinated directly to the general staff. The defense zones essentially created a new layer between the general staff and the provincial commanders. The military regions themselves were reorganized and do not correspond with the ones that existed prior to the reshuffle. New commanders of branches were also appointed: A Congolese military analyst based in Brussels, Jean-Jacques Wondo, provided an outline of the updated command structure of the FARDC following the shake up of the high command:


Regional commanders:

The following changes were announced in July 2018.


The land forces are made up of about 14 integrated brigades of fighters from all the former warring factions who have gone through a "brassage" integration process (see next paragraph) and a not-publicly known number of non-integrated brigades that remain solely made up of single factions (the Congolese Rally for Democracy (RCD)'s "Armée national congolaise", the ex-government former Congolese Armed Forces (FAC), the ex-RCD KML, the ex-Movement for the Liberation of Congo, the armed groups of the Ituri conflict (the Mouvement des Révolutionnaires Congolais (MRC), Forces de Résistance Patriotique d'Ituri (FRPI), and the Front Nationaliste Intégrationniste (FNI)), and the Mai-Mai).

It appears that about the same time that Presidential Decree 03/042 of 18 December 2003 established the National Commission for Demobilisation and Reinsertion (CONADER), "..all ex-combatants were officially declared as FARDC soldiers and the then FARDC brigades [were to] rest deployed until the order to leave for "brassage.""
The reform plan adopted in 2005 envisaged the formation of eighteen integrated brigades through the "brassage" process as its first of three stages. The process consists firstly of regroupment, where fighters are disarmed. Then they are sent to orientation centres, run by CONADER, where fighters take the choice of either returning to civilian society or remaining in the armed forces. Combatants who choose demobilisation receive an initial cash payment of US $110. Those who choose to stay within the FARDC are then transferred to one of six integration centres for a 45-day training course, which aims to build integrated formations out of factional fighters previously heavily divided along ethnic, political and regional lines. The centres are spread out around the country at Kitona, Kamina, Kisangani, Rumangabo and Nyaleke (within the Virunga National Park) in Nord-Kivu, and Luberizi (on the border with Burundi) in South Kivu. The process has suffered severe difficulties due to construction delays, administration errors, and the amount of travel former combatants have to do, as the three stages' centres are widely separated. Following the first 18 integrated brigades, the second goal is the formation of a ready reaction force of two to three brigades, and finally, by 2010 when MONUC is anticipated to have withdrawn, the creation of a Main Defence Force of three divisions.

In February 2008, then Defence Minister Chikez Diemu described the reform plan at the time as:
"The short term, 2008–2010, will see the setting in place of a Rapid Reaction Force; the medium term, 2008–2015, with a Covering Force; and finally the long term, 2015–2020, with a Principal Defence Force." Diemu added that the reform plan rests on a programme of synergy based on the four pillars of dissuasion, production, reconstruction and excellence. "The Rapid Reaction Force is expected to focus on dissuasion, through a Rapid Reaction Force of 12 battalions, capable of aiding MONUC to secure the east of the country and to realise constitutional missions."
Amid the other difficulties in building new armed forces for the DRC, in early 2007 the integration and training process was distorted as the DRC government under Kabila attempted to use it to gain more control over the dissident general Laurent Nkunda. A hastily negotiated verbal agreement in Rwanda saw three government FAC brigades integrated with Nkunda's former ANC 81st and 83rd Brigades in what was called "mixage". "Mixage" brought multiple factions into composite brigades, but without the 45-day retraining provided by "brassage", and it seems that actually, the process was limited to exchanging battalions between the FAC and Nkunda brigades in North Kivu, without further integration. Due to Nkunda's troops having greater cohesion, Nkunda effectively gained control of all five brigades, which was not the intention of the DRC central government. However, after Nkunda used the "mixage" brigades to fight the FDLR, strains arose between the FARDC and Nkunda-loyalist troops within the brigades and they fell apart in the last days of August 2007. The International Crisis Group says that "by 30 August [2007] Nkunda's troops had left the mixed brigades and controlled a large part of the Masisi and Rutshuru territories" (of North Kivu).

Both formally integrated brigades and the non-integrated units continue to conduct arbitrary arrests, rapes, robbery, and other crimes and these human rights violations are "regularly" committed by both officers and members of the rank and file. Members of the Army also often strike deals to gain access to resources with the militias they are meant to be fighting.

The various brigades and other formations and units number at least 100,000 troops. The status of these brigades has been described as "pretty chaotic." A 2007 disarmament and repatriation study said "army units that have not yet gone through the process of brassage are usually much smaller than what they ought to be. Some non-integrated brigades have only 500 men (and are thus nothing more than a small battalion) whereas some battalions may not even have the size of a normal company (over a 100 men)."

A number of outside donor countries are also carrying out separate training programmes for various parts of the Forces du Terrestres (Land Forces). The People's Republic of China has trained Congolese troops at Kamina in Katanga from at least 2004 to 2009, and the Belgian government is training at least one "rapid reaction" battalion. When Kabila visited U.S. President George W. Bush in Washington D.C., he also asked the U.S. Government to train a battalion, and as a result, a private contractor, Protection Strategies Incorporated, started training a FARDC battalion at Camp Base, Kisangani, in February 2010. The company was supervised by United States Special Operations Command Africa. Three years later, the battalion broke and ran in the face of M23, raping women and young girls, looting, and carrying out arbitrary executions. The various international training programmes are not well integrated.

Attempting to list the equipment available to the DRC's land forces is difficult; most figures are unreliable estimates based on known items delivered in the past. The figures below are from the IISS Military Balance 2014. Much of the Army's equipment is non-operational due to insufficient maintenance—in 2002 only 20 percent of the Army's armoured vehicles were estimated as being serviceable.

In addition to these 2014 figures, in March 2010, it was reported that the DRC's land forces had ordered USD $80 million worth of military equipment from Ukraine which included 20 T-72 main battle tanks, 100 trucks and various small arms. Tanks have been used in the Kivus in the 2005–09 period.

In February 2014, Ukraine revealed that it had achieved the first export order for the T-64 tank to the DRC Land Forces for 50 T-64BV-1s.

In June 2015 it was reported that Georgia had sold 12 of its Didgori-2 to the DRC for $4 million. The vehicles were specifically designed for reconnaissance and special operations. Two of the vehicles are a recently developed conversion to serve for medical field evacuation.

The United Nations confirmed in 2011, both from sources in the Congolese military and from officials of the Commission nationale de contrôle des armes légères et de petit calibre et de réduction de la violence armée, that the ammunition plant called Afridex in Likasi, Katanga Province, manufactures ammunition for small arms and light weapons.

In addition to the other land forces, President Joseph Kabila also has a Republican Guard presidential force ("Garde Républicaine" or GR), formerly known as the Special Presidential Security Group (GSSP). FARDC military officials state that the Garde Républicaine is not the responsibility of FARDC, but of the Head of State. Apart from Article 140 of the Law on the Army and Defence, no legal stipulation on the DRC's Armed Forces makes provision for the GR as a distinct unit within the national army. In February 2005 President Joseph Kabila passed a decree which appointed the GR's commanding officer and "repealed any previous provisions contrary" to that decree. The GR, more than 10,000 strong (the ICG said 10,000 to 15,000 in January 2007), has better working conditions and is paid regularly, but still commits rapes and robberies in the vicinity of its bases.

In an effort to extend his personal control across the country, Joseph Kabila has deployed the GR at key airports, ostensibly in preparation for an impending presidential visit. there were Guards deployed in the central prison of Kinshasa, N'djili Airport, Bukavu, Kisangani, Kindu, Lubumbashi, Matadi, and Moanda, where they appear to answer to no local commander and have caused trouble with MONUC troops there.

The GR is also supposed to undergo the integration process, but in January 2007, only one battalion had been announced as having been integrated. Formed at a brassage centre in the Kinshasa suburb of Kibomango, the battalion included 800 men, half from the former GSSP and half from the MLC and RCD Goma.

Up until June 2016, the GR comprised three brigades, the 10th Brigade at Camp Tshatshi and the 11th at Camp Kimbembe, both in Kinshasa, and the 13th Brigade at Camp Simi Simi in Kisangani. It was reorganised on the basis of eight fighting regiments, the 14th Security and Honor Regiment, an artillery regiment, and a command brigade/regiment from that time.

There are currently large numbers of United Nations troops stationed in the DRC. The United Nations Organization Stabilization Mission in the Democratic Republic of the Congo (MONUSCO), on had a strength of over 19,000 peacekeepers (including 16,998 military personnel) and has a mission of assisting Congolese authorities maintain security. The UN and foreign military aid missions, the most prominent being EUSEC RD Congo, are attempting to assist the Congolese in rebuilding the armed forces, with major efforts being made in trying to assure regular payment of salaries to armed forces personnel and also in military justice. Retired Canadian Lieutenant General Marc Caron also served for a time as Security Sector Reform advisor to the head of MONUC.

Groups of anti-Rwandan government rebels like the FDLR, and other foreign fighters remain inside the DRC. The FDLR which is the greatest concern, was some 6,000 strong, in July 2007. By late 2010 the FDLR's strength however was estimated at 2,500. The other groups are smaller: the Ugandan Lord's Resistance Army, the Ugandan rebel group the Allied Democratic Forces in the remote area of Mt Rwenzori, and the Burundian Parti pour la Libération du Peuple Hutu—Forces Nationales de Liberation (PALIPEHUTU-FNL).

Finally there is a government paramilitary force, created in 1997 under President Laurent Kabila. The National Service is tasked with providing the army with food and with training the youth in a range of reconstruction and developmental activities. There is not much further information available, and no internet-accessible source details the relationship of the National Service to other armed forces bodies; it is not listed in the constitution. President Kabila, in one of the few comments available, says National Service will provide a gainful activity for street children. Obligatory civil service administered through the armed forces was also proposed under the Mobutu regime during the "radicalisation" programme of December 1974 – January 1975; the FAZ was opposed to the measure and the plan "took several months to die."

All military aircraft in the DRC are operated by the Air Force. Jane's World Air Forces states that the Air Force has an estimated strength of 1,800 personnel and is organised into two Air Groups. These Groups command five wings and nine squadrons, of which not all are operational. 1 Air Group is located at Kinshasa and consists of Liaison Wing, Training Wing and Logistical Wing and has a strength of five squadrons. 2 Tactical Air Group is located at Kaminia and consists of Pursuit and Attack Wing and Tactical Transport Wing and has a strength of four squadrons. Foreign private military companies have reportedly been contracted to provide the DRC's aerial reconnaissance capability using small propeller aircraft fitted with sophisticated equipment. Jane's states that National Air Force of Angola fighter aircraft would be made available to defend Kinshasa if it came under attack.

Like the other services, the Congolese Air Force is not capable of carrying out its responsibilities. Few of the Air Force's aircraft are currently flyable or capable of being restored to service and it is unclear whether the Air Force is capable of maintaining even unsophisticated aircraft. Moreover, Jane's states that the Air Force's Ecole de Pilotage is 'in near total disarray' though Belgium has offered to restart the Air Force's pilot training program.

Before the downfall of Mobutu, a small navy operated on the Congo river. One of its installations was at the village of N'dangi near the presidential residence in Gbadolite. The port at N'dangi was the base for several patrol boats, helicopters and the presidential yacht. The 2002 edition of "Jane's Sentinel" described the Navy as being "in a state of near total disarray" and stated that it did not conduct any training or have operating procedures. The Navy shares the same discipline problems as the other services. It was initially placed under command of the MLC when the transition began,so the current situation is uncertain.

The 2007 edition of "Jane's Fighting Ships" states that the Navy is organised into four commands, based at Matadi, near the coast; the capital Kinshasa, further up the Congo river; Kalemie, on Lake Tanganyika; and Goma, on Lake Kivu. The International Institute for Strategic Studies, in its 2007 edition of the "Military Balance", confirms the bases listed in "Jane's" and adds a fifth base at Boma, a coastal city near Matadi. Various sources also refer to numbered Naval Regions. Operations of the 1st Naval Region have been reported in Kalemie, the 4th near the northern city of Mbandaka, and the 5th at Goma.

The IISS lists the Navy at 1,000 personnel and a total of eight patrol craft, of which only one is operational, a Shanghai II Type 062 class gunboat designated "102". There are five other 062s as well as two Swiftships which are not currently operational, though some may be restored to service in the future. According to "Jane's", the Navy also operates barges and small craft armed with machine guns.

As of 2012, the Navy on paper consisted of about 6,700 personnel and up to 23 patrol craft. In reality there was probably around 1,000 service members, and only 8 of the boats were 50 ft in length or larger, the sole operational vessel being a Shanghai II Type 062 class gunboat. The service maintains bases in Kinshasa, Boma, Matadi, Boma, and on Lake Tanganyika.





</doc>
<doc id="8032" url="https://en.wikipedia.org/wiki?curid=8032" title="Geography of Denmark">
Geography of Denmark

Denmark is a Nordic country located in Northern Europe. It consists of the Jutland peninsula and several islands in the Baltic sea, referred to as the Danish Archipelago. Denmark is located southwest of Sweden and due south of Norway and is bordered by the German state (and former possession) Schleswig-Holstein to the south, on Denmark's only land border, 68 kilometers (42 miles) long.

Denmark borders both the Baltic and North Seas along its tidal shoreline. Denmark's general coastline is much shorter, at , as it would not include most of the 1,419 offshore islands (each defined as exceeding 100 square meters in area) and the 180 km long Limfjorden, which separates Denmark's second largest island, North Jutlandic Island, 4,686 km in size, from the rest of Jutland. No location in Denmark is further from the coast than . The size of the land area of Denmark cannot be stated exactly since the ocean constantly erodes and adds material to the coastline, and because of human land reclamation projects (to counter erosion). On the southwest coast of Jutland, the tide is between , and the tideline moves outward and inward on a stretch.

A circle enclosing the same area as Denmark would be 742 km (461 miles) long. Denmark has 443 named islands (1,419 islands above 100 m²), of which 72 are inhabited (, Statistics Denmark). The largest islands are Zealand "(Sjælland)" and Funen "(Fyn)". The island of Bornholm is located east of the rest of the country, in the Baltic Sea. Many of the larger islands are connected by bridges; the Øresund Bridge connects Zealand with Sweden; the Great Belt Bridge connects Funen with Zealand; and the Little Belt Bridge connects Jutland with Funen. Ferries or small aircraft connect to the smaller islands. Main cities are the capital Copenhagen on Zealand; Århus, Aalborg and Esbjerg in Jutland; and Odense on Funen.

Denmark experiences a temperate climate. This means that the winters are mild and windy and the summers are cool. The local terrain is generally flat with a few gently rolling plains. The territory of Denmark includes the island of Bornholm in the Baltic Sea and the rest of metropolitan Denmark, but excludes the Faroe Islands and Greenland. Its position gives Denmark complete control of the Danish Straits (Skagerrak and Kattegat) linking the Baltic and North Seas. The country's natural resources include petroleum, natural gas, fish, salt, limestone, chalk, stone, gravel and sand.

Irrigated land: 4,354 km² (2007)

Total renewable water resources: 6 km (2011)

Freshwater withdrawal (domestic/industrial/agricultural):
<br>"total:" 0.66 km/yr (58%/5%/36%)
<br> "per capita:" 118.4 m/yr (2009)







</doc>
<doc id="8033" url="https://en.wikipedia.org/wiki?curid=8033" title="Demographics of Denmark">
Demographics of Denmark

This article is about the demographic features of the population of Denmark, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.

Since 1980, the number of Danes has remained constant at around 5 million in Denmark and nearly all the population growth from 5.1 up to the 2018 total of 5.8 million was due to immigration.

According to 2017 figures from Statistics Denmark, 86.9% of Denmark’s population of over 5,760,694 was of Danish descent, defined as having at least one parent who was born in Denmark and has Danish citizenship. The remaining 13.1% were of a foreign background, defined as immigrants or descendants of recent immigrants. With the same definition, the most common countries of origin were Poland, Turkey, Germany, Iraq, Romania, Syria, Somalia, Iran, Afghanistan, and Yugoslavia and its successor states.
More than 752 618 individuals (13.1%) are migrants and their descendants (146 798 second generation migrants born in Denmark).

Of these 752 618 immigrants and their descendants:

Non-Scandinavian ethnic minorities include:

Ethnic minorities in Denmark include a handful of groups:


The total fertility rate is the number of children born per woman. It is based on fairly good data for the entire period. Sources: Our World In Data and Gapminder Foundation.

Data according to Statistics Denmark, which collects the official statistics for Denmark.




Sources: Our World In Data and the United Nations.

1775-1950

1950-2015

Source: "UN World Population Prospects"

The Church of Denmark () is state-supported and, according to statistics from January 2019, accounts for about 74.7% of Denmark's religious affiliation. Denmark has had religious freedom guaranteed since 1849 by the Constitution, and numerous other religions are officially recognised, including several Christian denominations, Muslim, Jewish, Buddhist, Hindu and other congregations as well as Forn Siðr, a revival of Scandinavian pagan tradition. The Department of Ecclesiastical Affairs recognises roughly a hundred religious congregations for tax and legal purposes such as conducting wedding ceremonies.

Islam is the second largest religion in Denmark.

For historical reasons, there is a formal distinction between 'approved' ("godkendte") and 'recognised' ("anerkendte") congregations of faith. The latter include 11 traditional denominations, such as Roman Catholics, the Reformed Church, the Mosaic Congregation, Methodists and Baptists, some of whose privileges in the country date hundreds of years back. These have the additional rights of having priests appointed by royal resolution and to christen/name children with legal effect.

Denmark's population from 1769 to 2007.

Demographic statistics according to the World Population Review in 2019.


Demographic statistics according to the CIA World Factbook, unless otherwise indicated.











note: data represent population by ancestry











</doc>
<doc id="8035" url="https://en.wikipedia.org/wiki?curid=8035" title="Economy of Denmark">
Economy of Denmark

The economy of Denmark is a modern market economy with comfortable living standards, a high level of government services and transfers, and a high dependence on foreign trade. The economy is dominated by the service sector with 80% of all jobs, whereas about 11% of all employees work in manufacturing and 2% in agriculture. Nominal gross national income per capita was the tenth-highest in the world at $55,220 in 2017. Correcting for purchasing power, per capita income was Int$52,390 or 16th-highest globally. Income distribution is relatively equal, but inequality has increased somewhat during the last decades, however, due to both a larger spread in gross incomes and various economic policy measures. In 2017, Denmark had the seventh-lowest Gini coefficient (a measure of economic inequality) of the 28 European Union countries. With 5,789,957 inhabitants (1 July 2018), Denmark has the 39th largest national economy in the world measured by nominal gross domestic product (GDP) and 60th largest in the world measured by purchasing power parity (PPP).

As a small open economy, Denmark generally advocates a liberal trade policy, and its exports as well as imports make up circa 50% of GDP. Since 1990 Denmark has consistently had a current account surplus, with the sole exception of 1998. As a consequence, the country has become a considerable creditor nation, having acquired a net international investment position amounting to 65% of GDP in 2018. A decisive reason for this are the widespread compulsory funded labour market pensions schemes which have caused a considerable increase in private savings rates and today play an important role for the economy.

Denmark has a very long tradition of adhering to a fixed exchange-rate system and still does so today. It is unique among OECD countries to do so while maintaining an independent currency: The Danish krone, which is pegged to the euro. Though eligible to join the EMU, the Danish voters in a referendum in 2000 rejected exchanging the krone for the euro. Whereas Denmark's neighbours like Norway, Sweden, Poland and United Kingdom generally follow inflation targeting in their monetary policy, the priority of Denmark's central bank is to maintain exchange rate stability. Consequently, the central bank has no role in domestic stabilization policy. Since February 2015, the central bank has maintained a negative interest rate in order to contain an upward exchange rate pressure.

In an international context a relatively large proportion of the population is part of the labour force, in particular because the female participation rate is very high. In 2017 78.8% of all 15-64-year-old people were active on the labour market, the sixth-highest number among all OECD countries. Unemployment is relatively low among European countries; in October 2018 4.8% of the Danish labour force were unemployed as compared to an average of 6.7% for all EU countries. There is no legal minimum wage in Denmark. The labour market is traditionally characterized by a high degree of union membership rates and collective agreement coverage. The concept of flexicurity has been important historically.

Denmark is an example of the Nordic model, characterized by an internationally high tax level, and a correspondingly high level of government-provided services (e.g. health care, child care and education services) and income transfers to various groups like retired or disabled people, unemployed persons, students, etc. Altogether, taxes paid in 2017 amounted to 46.1% of GDP. Danish fiscal policy is generally considered healthy. Net government debt is very close to zero, amounting to 1.3% of GDP in 2017. Danish fiscal policy is characterized by a long-term outlook, taking into account likely future fiscal demands. During the 2000s a challenge was perceived to government expenditures in future decades and hence ultimately fiscal sustainability from demographic development, in particular higher longevity. Responding to this, age eligibility rules for receiving public age-related transfers were changed. From 2012 calculations of future fiscal challenges from the government as well as independent analysts have generally perceived Danish fiscal policy to be sustainable - indeed in recent years overly sustainable.

Denmark's long-term economic development has largely followed the same pattern as other Northwestern European countries. In most of recorded history Denmark has been an agricultural country with most of the population living on a subsistence level. Since the 19th century Denmark has gone through an intense technological and institutional development. The material standard of living has experienced formerly unknown rates of growth, and the country has been industrialized and later turned into a modern service society.

Almost all of the land area of Denmark is arable. Unlike most of its neighbours, Denmark has not had extractable deposits of minerals or fossile fuels, except for the deposits of oil and natural gas in the North Sea, which started playing an economic role only during the 1980s. On the other hand, Denmark has had a logistic advantage through its long coastal line and the fact that you are nowhere more than 50 kilometers from the sea - an important fact for the whole period before the industrial revolution when sea transport was cheaper than land transport. Consequently, foreign trade has always been very important for the economic development of Denmark. 
Already during the Stone Age there was some foreign trade, and even though trade has made up only a very modest share of total Danish value added until the 19th century, it has been decisive for economic development, both in terms of procuring vital import goods (like metals) and because new knowledge and technological skills have often come to Denmark as a byproduct of goods exchange with other countries. The emerging trade implied specialization which created demand for means of payments, and the earliest known Danish coins date from the time of Svend Tveskæg around 995.

According to economic historian Angus Maddison, Denmark was the sixth-most prosperous country in the world around 1600. The population size relative to arable agricultural land was small so that the farmers were relatively affluent, and Denmark was geographically close to the most dynamic and economically leading European areas since the 16th century: the Netherlands, the northern parts of Germany, and Britain. Still, 80 to 85% of the population lived in small villages on a subsistence level.

Mercantilism was the leading economic doctrine during the 17th and 18th century in Denmark, leading to the establishment of monopolies like Asiatisk Kompagni, development of physical and financial infrastructure like the first Danish bank Kurantbanken in 1736 and the first "kreditforening" (a kind of building society) in 1797, and the acquisition of some minor Danish colonies like Tranquebar.

At the end of the 18th century major agricultural reforms took place that entailed decisive structural changes. Politically, mercantilism was gradually replaced by liberal thoughts among the ruling elite. Following a monetary reform after the Napoleonic wars, the present Danish central bank Danmarks Nationalbank was founded in 1818.

There exist national accounting data for Denmark from 1820 onwards thanks to the pioneering work of Danish economic historian Svend Aage Hansen. They find that there has been a substantial and permanent, though fluctuating, economic growth all the time since 1820. The period 1822-94 saw on average an annual growth in factor incomes of 2% (0.9% per capita) From around 1830 the agricultural sector experienced a major boom lasting several decades, producing and exporting grains, not least to Britain after 1846 when British grain import duties were abolished. When grain production became less profitable in the second half of the century, the Danish farmers made an impressive and uniquely successful change from vegetarian to animal production leading to a new boom period. Parallelly industrialization took off in Denmark from the 1870s. At the turn of the century industry (including artisanry) fed almost 30% of the population.

During the 20th century agriculture slowly dwindled in importance relative to industry, but agricultural employment was only during the 1950s surpassed by industrial employment. The first half of the century was marked by the two world wars and the Great Depression during the 1930s. After World War II Denmark took part in the increasingly close international cooperation, joining OEEC/OECD, IMF, GATT/WTO, and from 1972 the European Economic Community, later European Union. Foreign trade increased heavily relative to GDP. The economic role of the public sector increased considerably, and the country was increasingly transformed from an industrial country to a country dominated by production of services. The years 1958-73 were an unprecedented high-growth period. The 1960s are the decade with the highest registered real per capita growth in GDP ever, i.e. 4.5% annually.
During the 1970s Denmark was plunged into a crisis, initiated by the 1973 oil crisis leading to the hitherto unknown phenomenon stagflation. For the next decades the Danish economy struggled with several major so-called "balance problems": High unemployment, current account deficits, inflation, and government debt. From the 1980s economic policies have increasingly been oriented towards a long-term perspective, and gradually a series of structural reforms have solved these problems. In 1994 active labour market policies were introduced that via a series of labour market reforms have helped reducing structural unemployment considerably. A series of tax reforms from 1987 onwards, reducing tax deductions on interest payments, and the increasing importance of compulsory labour market-based funded pensions from the 1990s have increased private savings rates considerably, consequently transforming secular current account deficits to secular surpluses. The announcement of a consistent and hence more credible fixed exchange rate in 1982 has helped reducing the inflation rate.

In the first decade of the 21st century new economic policy issues have emerged. A growing awareness that future demographic changes, in particular increasing longevity, could threaten fiscal sustainability, implying very large fiscal deficits in future decades, led to major political agreements in 2006 and 2011, both increasing the future eligibility age of receiving public age-related pensions. Mainly because of these changes, from 2012 onwards the Danish fiscal sustainability problem is generally considered to be solved. Instead, issues like decreasing productivity growth rates and increasing inequality in income distribution and consumption possibilities are prevalent in the public debate.

The global Great Recession during the late 2000s, the accompanying Euro area debt crisis and their repercussions marked the Danish economy for several years. Until 2017, unemployment rates have generally been considered to be above their structural level, implying a relatively stagnating economy from a business-cycle point of view. From 2017/18 this is no longer considered to be the case, and attention has been redirected to the need of avoiding a potential overheating situation.

Average per capita income is high in an international context. According to the World Bank, gross national income per capita was the tenth-highest in the world at $55,220 in 2017. Correcting for purchasing power, income was Int$52,390 or 16th-highest among the 187 countries.

During the last three decades household saving rates in Denmark have increased considerably. This is to a large extent caused by two major institutional changes: A series of tax reforms from 1987 to 2009 considerably reduced the effective subsidization of private debt implicit in the rules for tax deductions of household interest payments. Secondly, compulsory funded pension schemes became normal for most employees from the 1990s. Over the years, the wealth of the Danish pension funds have accumulated so that in 2016 it constituted twice the size of Denmark's GDP. The pension wealth consequently is a very important both for the life-cycle of a typical individual Danish household and for the national economy. A large part of the pension wealth is invested abroad, thus giving rise to a fair amount of foreign capital income. In 2015, average household assets were more than 600% of their disposable income, among OECD countries second only to the Netherlands. At the same time, average household gross debt was almost 300% of disposable income, which is also at the highest level in OECD. Household balance sheets are consequently very large in Denmark compared to most other countries. Danmarks Nationalbank, the Danish central bank, has attributed this to a well-developed financial system.

Income inequality has traditionally been low in Denmark. According to OECD figures, in 2000 Denmark had the lowest Gini coefficient of all countries. However, inequality has increased during the last decades. According to data from Statistics Denmark, the Gini coefficient for disposable income has increased from 22.1 in 1987 to 29.3 in 2017. The Danish Economic Council found in an analysis from 2016 that the increasing inequality in Denmark is due to several components: Pre-tax labour income is more unequally distributed today than before, capital income, which is generally less equally distributed than labour income, has increased as share of total income, and economic policy is less redistributive today, both because public income transfers play a smaller role today and because the tax system has become less progressive.

In international comparisons, Denmark has a relatively equal income distribution. According to the CIA World Factbook, Denmark had the twentieth-lowest Gini coefficient (29.0) of 158 countries in 2016. According to data from Eurostat, Denmark was the EU country with the seventh-lowest Gini coefficient in 2017. Slovakia, Slovenia, Czechia, Finland, Belgium and the Netherlands had a lower Gini coefficient for disposable income than Denmark.

The Danish labour market is characterized by a high degree of union membership rates and collective agreement coverage dating back from "Septemberforliget" (The September Settlement) in 1899 when the Danish Confederation of Trade Unions and the Confederation of Danish Employers recognized each other's right to organise and negotiate. The labour market is also traditionally characterized by a high degree of flexicurity, i.e. a combination of labour market flexibility and economic security for workers. The degree of flexibility is in part maintained through active labour market policies. The effective compensation rate for unemployed workers has been declining for the last decades, however. Unlike in most Western countries there is no legal minimum wage in Denmark.

A relatively large proportion of the population is active on the labour market, not least because of a very high female participation rate. The total participation rate for people aged 15 to 64 years was 78.8% in 2017. This was the 6th-highest number among OECD countries, only surpassed by Iceland, Switzerland, Sweden, New Zealand and the Netherlands. The average for all OECD countries together was 72.1%.

According to Eurostat, the unemployment rate was 5.7% in 2017. This places unemployment in Denmark somewhat below the EU average, which was 7.6%. 10 EU member countries had a lower unemployment rate than Denmark in 2017.

Altogether, total employment in 2017 amounted to 2,919,000 people according to Statistics Denmark.

The share of employees leaving jobs every year (for a new job, retirement or unemployment) in the private sector is around 30% - a level also observed in the U.K. and U.S.- but much higher than in continental Europe, where the corresponding figure is around 10%, and in Sweden. This attrition can be very costly, with new and old employees requiring half a year to return to old productivity levels, but with attrition bringing the number of people that have to be fired down.

As a small open economy, Denmark is very dependent on its foreign trade. In 2017, the value of total exports of goods and services made up 55% of GDP, whereas the value of total imports amounted to 47% of GDP. Trade in goods made up slightly more than 60% of both exports and imports, and trade in services the remaining close to 40%.

Machinery, chemicals and related products like medicine and agricultural products were the largest groups of export goods in 2017. Service exports were dominated by freight sea transport services from the Danish merchant navy. Most of Denmark's most important trading partners are neighbouring countries. The five main importers of Danish goods and services in 2017 were Germany, Sweden, United Kingdom, United States and Norway. The five countries from which Denmark imported most goods and services in 2017 were Germany, Sweden, the Netherlands, China and United Kingdom.

After having almost consistently an external balance of payments current account deficit since the beginning of the 1960s, Denmark has maintained a surplus on its BOP current account for every year since 1990, with the single exception of 1998. In 2017, the current account surplus amounted to approximately 8% of GDP. Consequently, Denmark has changed from a net debtor to a net creditor country. By 1 July 2018, the net foreign wealth or net international investment position of Denmark was equal to 64.6% of GDP, Denmark thus having the largest net foreign wealth relative to GDP of any EU country.

As the annual current account is equal to the value of domestic saving minus total domestic investment, the change from a structural deficit to a structural surplus is due to changes in these two national account components. In particular, the Danish national saving rate in financial assets increased by 11 per cent of GDP from 1980 to 2015. Two main reasons for this large change in domestic saving behaviour were the growing importance of large-scale compulsory pension schemes and several Danish fiscal policy reforms during the period which considerably decreased tax deductions of household interest expense, thus reducing the tax subsidy to private debt.

The Danish currency is the Danish krone, subdivided into 100 øre. The krone and øre were introduced in 1875, replacing the former rigsdaler and skilling. Denmark has a very long tradition of maintaining a fixed exchange-rate system, dating back to the period of the gold standard during the time of the Scandinavian Monetary Union from 1873 to 1914. After the breakdown of the international Bretton Woods system in 1971, Denmark devalued the krone repeatedly during the 1970s and the start of the 1980s, effectively maintaining a policy of "fixed, but adjustable" exchange rates. Rising inflation led to Denmark declaring a more consistent fixed exchange-rate policy in 1982. At first, the krone was pegged to the European Currency Unit or ECU, from 1987 to the Deutschmark, and from 1999 to the euro.

Although eligible, Denmark chose not to join the European Monetary Union when it was founded. In 2000, the Danish government advocated Danish EMU membership and called a referendum to settle the issue. With a turn-out of 87.6%, 53% of the voters rejected Danish membership. Occasionally, the question of calling another referendum on the issue has been discussed, but since the Financial crisis of 2007–2008 opinion polls have shown a clear majority against Denmark joining the EMU, and the question is not high on the political agenda presently.

Maintenance of the fixed exchange rate is the responsibility of Danmarks Nationalbank, the Danish central bank. As a consequence of the exchange rate policy, the bank must always adjust its interest rates in order to ensure a stable exchange rate and consequently cannot at the same time conduct monetary policy in order to stabilize e.g. domestic inflation or unemployment rates. This makes the conduct of stabilization policy fundamentally different from the situation in Denmark's neighbouring countries like Norway, Sweden, Poland og United Kingdom, in which the central banks have a central stabilizing role. Denmark is presently the only OECD member country maintaining an independent currency with a fixed exchange rate. Consequently, the Danish krone is the only currency in the European Exchange Rate Mechanism II (ERM II).

In the first months of 2015, Denmark experienced the largest pressure against the fixed exchange rate for many years because of very large capital inflows, causing a tendency for the Danish krone to appreciate. Danmarks Nationalbank reacted in various ways, chiefly by lowering its interest rates to record low levels. On 6 February 2015 the certificates of deposit rate, one of the four official Danish central bank rates, was lowered to -0.75%. In January 2016 the rate was raised to -0.65%, at which level it has been maintained since then.

Inflation in Denmark as measured by the official consumer price index of Statistics Denmark was 1.1% in 2017. Inflation has generally been low and stable for the last decades. Whereas in 1980 annual inflation was more than 12%, in the period 2000-2017 the average inflation rate was 1.8%.

Since a local-government reform in 2007, the general government organization in Denmark is carried out on three administrative levels: central government, regions, and municipalities. Regions administer mainly health care services, whereas municipalities administer primary education and social services. Municipalities in principle independently levy income and property taxes, but the scope for total municipal taxation and expenditure is closely regulated by annual negotiations between the municipalities and the Finance Minister of Denmark. At the central government level, the Ministry of Finance carries out the coordinating role of conducting economic policy. In 2012, the Danish parliament passed a Budget Law (effective from January 2014) which governs the over-all fiscal framework, stating among other things that the structural deficit must never exceed 0.5% of GDP, and that Danish fiscal policy is required to be sustainable, i.e. have a non-negative fiscal sustainability indicator. The Budget Law also assigned the role of independent fiscal institution (IFI, informally known as "fiscal watchdog") to the already-existing independent advisory body of the Danish Economic Councils.

Danish fiscal policy is generally considered healthy. Government net debt was close to zero at the end of 2017, amounting to DKK 27.3 billion, or 1.3% of GDP. The government sector having a fair amount of financial assets as well as liabilities, government gross debt amounted to 36.1% of GDP at the same date. The gross EMU-debt as percentage of GDP was the sixth-lowest among all 28 EU member countries, only Estonia, Luxembourg, Bulgaria, the Czech Republic and Romania having a lower gross debt. Denmark had a government budget surplus of 1.1% of GDP in 2017.

Long-run annual fiscal projections from the Danish government as well as the independent Danish Economic Council, taking into account likely future fiscal developments caused by demographic developments etc. (e.g. a likely ageing of the population caused by a considerable expansion of life expectancy), consider the Danish fiscal policy to be overly sustainable in the long run. In Spring 2018, the so-called Fiscal Sustainability Indicator was calculated to be 1.2 (by the Danish government) respectively 0.9% (by the Danish Economic Council) of GDP. This implies that under the assumptions employed in the projections, fiscal policy could be permanently loosened (via more generous public expenditures and/or lower taxes) by ca. 1% of GDP while still maintaining a stable government debt-to-GDP ratio in the long run.

The tax level as well as the government expenditure level in Denmark ranks among the highest in the world, which is traditionally ascribed to the Nordic model of which Denmark is an example, including the welfare state principles which historically evolved during the 20th century. In 2017, the official Danish tax level amounted to 46.1% of GDP. The all-record highest Danish tax level was 49.8% of GDP, reached in 2014 because of high extraordinary one-time tax revenues caused by a reorganization of the Danish-funded pension system. The Danish tax-to-GDP-ratio of 46% was the second-highest among all OECD countries, second only to France. The OECD average was 34.2%. The tax structure of Denmark (the relative weight of different taxes) also differs from the OECD average, as the Danish tax system in 2015 was characterized by substantially higher revenues from taxes on personal income, whereas on the other hand, no revenues at all derive from social security contributions. A lower proportion of revenues in Denmark derive from taxes on corporate income and gains and property taxes than in OECD generally, whereas the proportion deriving from payroll taxes, VAT, and other taxes on goods and services correspond to the OECD average.

In 2016, the average marginal tax rate on labour income for all Danish tax-payers was 38.9%. The average marginal tax on personal capital income was 30.7%.

Professor of Economics at Princeton University Henrik Kleven has suggested that three distinct policies in Denmark and its Scandinavian neighbours imply that the high tax rates cause only relatively small distortions to the economy: widespread use of third-party information reporting for tax collection purposes (ensuring a low level of tax evasion), broad tax bases (ensuring a low level of tax avoidance), and a strong subsidization of goods that are complementary to working (ensuring a high level of labour force participation).

Parallel to the high tax level, government expenditures make up a large part of GDP, and the government sector carries out many different tasks. By September 2018, 831,000 people worked in the general government sector, corresponding to 29.9% of all employees. In 2017, total government expenditure amounted to 50.9% of GDP. Government consumption took up precisely 25% of GDP (e.g. education and health care expenditure), and government investment (infrastructure etc.) expenditure another 3.4% of GDP. Personal income transfers (for e.g. elderly or unemployed people) amounted to 16.8% of GDP.

Denmark has an unemployment insurance system called the A-kasse ("arbejdsløshedskasse"). This system requires a paying membership of a state-recognized unemployment fund. Most of these funds are managed by trade unions, and part of their expenses are financed through the tax system. Members of an A-kasse are not obliged to be members of a trade union. Not every Danish citizen or employee qualifies for a membership of an unemployment fund, and membership benefits will be terminated after 2 years of unemployment. A person that is not a member of an A-kasse cannot receive unemployment benefits. Unemployment funds do not pay benefits to sick members, who will be transferred to a municipal social support system instead. Denmark has a countrywide, but municipally administered social support system against poverty, securing that qualified citizens have a minimum living income. All Danish citizens above 18 years of age can apply for some financial support if they cannot support themselves or their family. Approval is not automatic, and the extent of this system has generally been diminished since the 1980s. Sick people can receive some financial support throughout the extent of their illness. Their ability to work will be re-evaluated by the municipality after 5 months of illness.

The welfare system related to the labor market has experienced several reforms and financial cuts since the late 1990s due to political agendas for increasing the labor supply. Several reforms of the rights of the unemployed have followed up, partially inspired by the Danish Economic Council. Halving the time unemployment benefits can be received from four to two years, and making it twice as hard to regain this right, was implemented in 2010 for example.

Disabled people can apply for permanent social pensions. The extent of the support depends on the ability to work, and people below 40 can not receive social pension unless they are deemed incapable of any kind of work.

Agriculture was once the most important industry in Denmark. Nowadays, it is of minor economic importance. In 2016, 62,000 people, or 2.5% of all employed people worked in agriculture and horticulture. Another 2,000 people worked in fishing. As value added per person is relatively low, the share of national value added is somewhat lower. Total gross value added in agriculture, forestry and fishing amounted to 1.6% of total output in Denmark (in 2017). Despite this, Denmark is still home to various types of agricultural production. Within animal husbandry, it includes dairy and beef cattle, pigs, poultry and fur animals (primarily mink) - all sectors that produce mainly for export. Regarding vegetable production, Denmark is a leading producer of grass-, clover- and horticultural seeds. The agriculture and food sector as a whole represented 25% of total Danish commodity exports in 2015.

63% of the land area of Denmark is used for agricultural production - the highest share in the world according to a report from University of Copenhagen in 2017. The Danish agricultural industry is historically characterized by freehold and family ownership, but due to structural development farms have become fewer and larger. In 2017 the number of farms was approximately 35,000, of which approximately 10,000 were owned by full-time farmers.

The tendency toward fewer and larger farms has been accompanied by an increase in animal production, using fewer resources per produced unit.

The number of dairy farmers has reduced to about 3,800 with an average herd size of 150 cows. The milk quota is 1,142 tonnes. Danish dairy farmers are among the largest and most modern producers in Europe. More than half of the cows live in new loose-housing systems. Export of dairy products accounts for more than 20 percent of the total Danish agricultural export. The total number of cattle in 2011 was approximately 1.5 million. Of these, 565,000 were dairy cows and 99,000 were suckler cows. The yearly number of slaughtering of beef cattle is around 550,000.

For more than 100 years the production of pigs and pig meat was a major source of income in Denmark. The Danish pig industry is among the world's leaders in areas such as breeding, quality, food safety, animal welfare and traceability creating the basis for Denmark being among the world's largest pig meat exporters. Approximately 90 percent of the production is exported. This accounts for almost half of all agricultural exports and for more than 5 percent of Denmark's total exports. About 4,200 farmers produce 28 million pigs annually. Of these, 20.9 million are slaughtered in Denmark.

Fur animal production on an industrial scale started in the 1930s in Denmark. Denmark is now the world's largest producer of mink furs, with 1,400 mink farmers fostering 17.2 million mink and producing around 14 million furs of the highest quality every year. Approximately 98 percent of the skins sold at Kopenhagen Fur Auction are exported. Fur ranks as Danish agriculture's third largest export article, at more than DKK 7 billion annually. The number of farms peaked in the late 1980s at more than 5,000 farms, but the number has declined steadily since, as individual farms grew in size. Danish mink farmers claim their business to be sustainable, feeding the mink food industry waste and using all parts of the dead animal as meat, bone meal and biofuel. Special attention is given to the welfare of the mink, and regular "Open Farm" arrangements are made for the general public. Mink thrive in, but are not a native to Denmark, and it is considered an invasive species. American Mink are now widespread in Denmark and continues to cause problems for the native wildlife, in particular waterfowl. Denmark also has a small production of fox, chinchilla and rabbit furs.

Two hundred professional producers are responsible for the Danish egg production, which was 66 million kg in 2011. Chickens for slaughter are often produced in units with 40,000 broilers. In 2012, 100 million chickens were slaughtered. In the minor productions of poultry, 13 million ducks, 1.4 million geese and 5.0 million turkeys were slaughtered in 2012.

Organic farming and production has increased considerably and continuously in Denmark since 1987 when the first official regulations of this particular agricultural method came into effect. In 2017, the export of organic products reached DK 2.95 billion, a 153% increase from 2012 five years earlier, and a 21% increase from 2016. The import of organic products has always been higher than the exports though and reached DK 3.86 billion in 2017. After some years of stagnation, close to 10% of the cultivated land is now categorized as organically farmed, and 13.6% for the dairy industry, as of 2017.

Denmark has the highest retail consumption share for organic products in the world. In 2017, the share was at 13.3%, accounting for a total of DKK 12.1 billion.

Denmark has some sources of oil and natural gas in the North Sea with Esbjerg being the main city for the oil and gas industry. Production has decreased in recent years, though. Whereas in 2006 output (measured as gross value added or GVA) in mining and quarrying industries made up more than 4% of Denmarks's total GVA, in 2017 it amounted to 1.2%. The sector is very capital-intensive, so the share of employment is much lower: About 2,000 persons worked in the oil and gas extraction sector in 2016, and another 1,000 persons in extraction of gravel and stone, or in total about 0.1% of total employment in Denmark.

In 2017 total output (gross value added) in manufacturing industries amounted to 14.4% of total output in Denmark. 325,000 people or a little less than 12% of all employed persons worked in manufacturing (including utilities, mining and quarrying) in 2016. Main sub-industries are manufacture of pharmaceuticals, machinery, and food products.

In 2017 total output (gross value added) in service industries amounted to 75.2% of total output in Denmark, and 79.9% of all employed people worked here (in 2016). Apart from public administration, education and health services, main service sub-industries were trade and transport services, and business services.

Significant investment has been made in building road and rail links between Copenhagen and Malmö, Sweden (the Øresund Bridge), and between Zealand and Funen (the Great Belt Fixed Link). The Copenhagen Malmö Port was also formed between the two cities as the common port for the cities of both nations.

The main railway operator is Danske Statsbaner (Danish State Railways) for passenger services and DB Schenker Rail for freight trains. The railway tracks are maintained by Banedanmark. Copenhagen has a small Metro system, the Copenhagen Metro and the greater Copenhagen area has an extensive electrified suburban railway network, the S-train.
Private vehicles are increasingly used as a means of transport. New cars are taxed by means of a registration tax (85% to 150%) and VAT (25%). The motorway network now covers 1,300 km.

Denmark is in a strong position in terms of integrating fluctuating and unpredictable energy sources such as wind power in the grid. It is this knowledge that Denmark now aims to exploit in the transport sector by focusing on intelligent battery systems (V2G) and plug-in vehicles.

Denmark has changed its energy consumption from 99% fossil fuels (92% oil (all imported) and 7% coal) and 1% biofuels in 1972 to 73% fossil fuels (37% oil (all domestic), 18% coal and 18% natural gas (all domestic)) and 27% renewables (largely biofuels) in 2015. The goal is a full independence of fossil fuels by 2050. This drastic change was initially inspired largely by the discovery of Danish oil and gas reserves in the North Sea in 1972 and the 1973 oil crisis. The course took a giant leap forward in 1984, when the Danish North Sea oil and gas fields, developed by native industry in close cooperation with the state, started major productions. In 1997, Denmark became self-sufficient with energy and the overall CO2 emission from the energy sector began to fall by 1996. Wind energy contribution to the total energy consumption has risen from 1% in 1997 to 5% in 2015.

Since 2000, Denmark has increased gross domestic product (GDP) and at the same time decreased energy consumption. Since 1972, the overall energy consumption has dropped by 6%, even though the GDP has doubled in the same period. Denmark had the 6th best energy security in the world in 2014. Denmark has had relatively high energy taxation to encourage careful use of energy since the oil crises in the 1970s, and Danish industry has adapted to this and gained a competitive edge. The so-called "green taxes" have been broadly criticised partly for being higher than in other countries, but also for being more of a tool for gathering government revenue than a method of promoting "greener" behaviour.

Denmark has low electricity costs (including costs for cleaner energy) in EU, but general taxes (11.7 billion DKK in 2015) make the electricity price for households the highest in Europe. , Denmark has no environment tax on electricity.

Denmark is a long time leader in wind energy and a prominent exporter of Vestas and Siemens wind turbines, and Denmark derives 3.1% of its gross domestic product from renewable (clean) energy technology and energy efficiency, or around €6.5 billion ($9.4 billion). It has integrated fluctuating and less predictable energy sources such as wind power into the grid. Wind produced the equivalent of 43% of Denmark's total electricity consumption in 2017. The share of total energy production is smaller: In 2015, wind accounted for 5% of total Danish energy production.

Energinet.dk is the Danish national transmission system operator for electricity and natural gas. The electricity grids of western Denmark and eastern Denmark were not connected until 2010 when the 600MW Great Belt Power Link went into operation.

Cogeneration plants are the norm in Denmark, usually with district heating which serves 1.6 million households.

Waste-to-energy incinerators produce mostly heating and hot water. in Glostrup Municipality operates Denmark's largest incinerator, a cogeneration plant which supplies electricity to 80,000 households and heating equivalent to the consumption in 63,000 households (2016). Amager Bakke is an example of a new incinerator being built.

In addition to Denmark proper, the Kingdom of Denmark comprises two autonomous constituent countries in the North Atlantic Ocean: Greenland and the Faroe Islands. Both use the Danish krone as their currency, but form separate economies, having separate national accounts etc. Both countries receive an annual fiscal subsidy from Denmark which amounts to about 25% of Greenland's GDP and 11% of Faroese GDP. For both countries, fishing industry is a major economic activity.

Neither Greenland nor the Faroe Islands are members of the European Union. Greenland left the European Economic Community in 1986, and the Faroe Islands declined membership in 1973, when Denmark joined.

The following table shows the main economic indicators in 1980–2017. Inflation under 2% is in green.
Denmark has fostered and is home to many multi-national companies. Many of the largest are interdisciplinary with business - and sometimes research activities - in several fields. The most notable companies include:








Many of the largest food producers are also engaged in biotechnology and research. Notable companies dedicated to the pharmaceutical and biotechnology sector, includes:




Denmark has a long tradition for cooperative production and trade on a large scale. The most notable cooperative societies today includes the agricultural coop of Dansk Landbrugs Grovvareselskab (DLG), dairy producer Arla Foods and the retail cooperative Coop Danmark. Coop Danmark started out as ""Fællesforeningen for Danmarks Brugsforeninger"" (FDB) in 1896 and now has around 1.4 million members in Denmark as of 2017. It is part of the larger multi-sector cooperative Coop amba which has 1.7 million members in that same year.

The cooperative structure also extends to both the housing and banking sector. Arbejdernes Landsbank, founded in 1919, is the largest bank cooperative and it is currently the 6th largest bank in the country as of 2018. The municipality of Copenhagen alone holds a total of 153 housing cooperatives and ""Arbejdernes Andelsboligforening Århus"" (AAB Århus) is the largest individual housing cooperative in Denmark, with 23,000 homes in Aarhus.




</doc>
<doc id="8037" url="https://en.wikipedia.org/wiki?curid=8037" title="Transport in Denmark">
Transport in Denmark

Transport in Denmark is developed and modern. The motorway network covers 1,111 km while the railway network totals 2,667 km of operational track. The Great Belt Fixed Link (opened in 1997) connecting the islands of Zealand and Funen and the New Little Belt Bridge (opened in 1970) connecting Funen and Jutland greatly improved the traffic flow across the country on both motorways and rail. The two largest airports of Copenhagen and Billund provide a variety of domestic and international connections, while ferries provide services to the Faroe Islands, Greenland, Iceland, Germany, Sweden, and Norway, as well as domestic routes servicing most Danish islands.

In 2011, a total of appr. 28 million passengers used Danish airports.

Copenhagen Airport is the largest airport in Scandinavia, handling approximately 29m passengers per year (2016). It is located at Kastrup, 8 km south-east of central Copenhagen. It is connected by train to Copenhagen Central Station and beyond as well as to Malmö and other towns in Sweden.

For the west of the country, the major airport is Billund (3m passengers in 2016) although both Aalborg (1.4m passengers in 2011) and Aarhus (591.000 passengers in 2011) have smaller airports with regular connections to Copenhagen.

Denmark's main airports are:


Other airports include: 

Being an island state with a long coastline and always close to the sea, maritime transport has always been important in Denmark. From the primitive dugouts of the Stone Age to the complex designs of the Viking ships in the Viking Age, often built to exactly facilitate large scale cargo and passenger transportation. Denmark also engaged in the large scale cargo freights and slave transports of the European colonization endeavours in the Middle Ages and operated several smaller colonies of its own across the globe by the means of seafaring.

Today Denmark's ports handle some 48 million passengers and 109 million tonnes of cargo per year.

Passenger traffic is made up partly of ferry crossings within Denmark, partly of international ferry crossings and partly of cruise ship passengers. Some short ferry routes are being electrified and several more may be eligible, as in Norway.

Among the most important ports for passenger traffic (thousands of passengers per year in 2007) are:

In 2007, 288 cruise ships visited Copenhagen, rising to 376 in 2011 before returning to around 300 the following years. Around 800,000 cruise passengers and 200,000 crew visit Copenhagen each year.

Among the most important ports for cargo traffic (millions of tonnes per year in 2007) are:

Waterways have historically and traditionally been crucial to local transportation in Denmark proper. Especially the Gudenå river-system in central Jutland, has played an important role. The waterways were navigated by wooden barges and later on steamboats. A few historical steamboats are still in operation, like the SS Hjejlen from 1861 at Silkeborg.

There is a 160 km natural canal through the shallow Limfjorden in northern Jutland, linking the North Sea to the Kattegat.

Many waterways has formerly been redirected and led through manmade canals in the 1900s, but mainly for agricultural purposes and not to facilitate transportation on any major scale. Several cities have manmade canals used for transportation and traffic purposes. Of special mention are the and the Odense Canal, ferrying large numbers of both tourists and local citizens.

Denmark has a large merchant fleet relative to its size. In 2018, the fleet surpassed 20 million gt as the government sought to repatriate Danish-owned tonnage registered abroad, with measures including removal of the registration fee.

Denmark has created its own international register, called the Danish International Ship register (DIS), open to commercial vessels only. DIS ships do not have to meet Danish manning regulations.

The largest railway operator in Denmark is Danske Statsbaner (DSB) — Danish State Railways. Arriva operates some routes in Jutland, and several other smaller operators provide local services.

The total length of operational track is 2,667 km, 640 km electrified at 25 kV AC, 946 km double track (2008). 508 km is privately owned and operated. Track is standard gauge.

The railway system is connected to Sweden by bridge in Copenhagen and ferry in Helsingør and Frederikshavn, by land to Germany in Padborg and ferry in Rødby and to Norway by ferry in Hirtshals.

The road network in 2008 totalled 73,197 km of paved road, including 1,111 km of motorway. Motorways are toll-free except for the Great Belt Bridge joining Zealand and Funen and the Øresund Bridge linking Copenhagen to Malmö in Sweden.

Bicycling in Denmark is a common and popular utilitarian and recreational activity. Bicycling infrastructure is a dominant feature of both city and countryside infrastructure, with bicycle paths and bicycle ways in many places and an extensive network of bicycle routes, extending more than nationwide. In comparison, Denmark's coastline is . As a unique feature, Denmark has a VIN-system for bicycles which is mandatory by law. Often bicycling and bicycle-culture in Denmark is compared to the Netherlands as a bicycle-nation.

Figures for 2007:




</doc>
<doc id="8038" url="https://en.wikipedia.org/wiki?curid=8038" title="Danish Defence">
Danish Defence

Danish Defence (, , ) is the unified armed forces of the Kingdom of Denmark, charged with the defence of Denmark and its constituent, self-governing nations Greenland and the Faroe Islands. The Defence also promote Denmark's wider interests, support international peacekeeping efforts and provide humanitarian aid.

Since the creation of a standing military in 1510, the armed forces have seen action in many wars, most involving Sweden, but also involving the world's great powers, including the Thirty Years' War, the Great Northern War, and the Napoleonic Wars.

Today, Danish Defence consists of: the Royal Danish Army, Denmark's principal land warfare branch; the Royal Danish Navy, a blue-water navy with a fleet of 20 commissioned ships; and the Royal Danish Air Force, an air force with an operational fleet consisting of both fixed-wing and rotary aircraft. The Defence also include the Home Guard. Under the Danish Defence Law the Minister of Defence serves as the commander of Danish Defence (through the Chief of Defence and the Defence Command) and the Danish Home Guard (through the Home Guard Command). De facto the Danish Cabinet is the commanding authority of the Defence, though it cannot mobilize the armed forces, for purposes that are not strictly defence oriented, without the consent of parliament.

The modern Danish military can be traced back to 1510, with the creation of the Royal Danish Navy. During this time, the Danish Kingdom held considerable territories, including Schleswig-Holstein, Norway, and colonies in Africa and the Americans.

Following the defeat in the Second Schleswig War, the military became a political hot-button issue, with many wanting the disarm the military. 
Denmark managed to maintain its neutrality during the First World War, with a relative strong military force. However, following the Interwar period, a more pacifistic government came to power, decreasing the size of the military. This resulted in Denmark having a limited military, when Denmark was invaded in 1940.
After World War II, the different branches were reorganized, and collected under "Danish Defence". This was to ensure a unified command when conducting joint operations, as learned from the War.

With the defeat in 1864, Denmark had adopted a policy of neutrality. This was however abandoned after World War Two, when Denmark decided to support the UN peacekeeping forces and become a member of NATO. During the Cold War, Denmark began to rebuild its military and to prepare for possible attacks by the Soviet Union and its Warsaw Pact allies. During this time Denmark participated in a number of UN peacekeeping missions including UNEF and UNFICYP.

Following the end of the Cold War, Denmark began a more active foreign policy, deciding to participate in international operations. This began with the participation in the Bosnian War, where the Royal Danish Army served as part of the United Nations Protection Force and were in two skirmishes. This was the first time the Danish Army was a part of a combat operation since World War 2. On April 29, 1994, the Royal Danish Army, while on an operation to relieve an observation post as part of the United Nations Protection Force, the Jutland Dragoon Regiment came under artillery fire from the town of Kalesija. The United Nations Protection Force quickly returned fire and eliminated the artillery positions. On October 24, 1994, the Royal Danish Army, while on an operation to reinforce an observation post in the town of Gradačac, were fired upon by a T-55 Bosnian Serb tank. One of the three Danish Leopard 1 tanks experienced slight damage, but all returned fired and put the T-55 tank out of action.

With the September 11 attacks, Denmark joined US forces in the War on terror, participating in both the War in Afghanistan and the Iraq War. In Afghanistan, 37 soldiers have been killed in various hostile engagements or as a result of friendly fire, and 6 have been killed in non-combat related incidents, bringing the number of Danish fatalities to 43, being the highest loss per capita within the coalition forces. Denmark has since participated in Operation Ocean Shield, the 2011 military intervention in Libya and the American-led intervention in the Syrian Civil War.

The purpose and task of the armed forces of Denmark is defined in Law no. 122 of February 27, 2001 and in force since March 1, 2001. It defines three purposes and six tasks.

Its primary purpose is to prevent conflicts and war, preserve the sovereignty of Denmark, secure the continuing existence and integrity of the independent Kingdom of Denmark and further a peaceful development in the world with respect to human rights.

Its primary tasks are: NATO participation in accordance with the strategy of the alliance, detect and repel any sovereignty violation of Danish territory (including Greenland and the Faroe Islands), defence cooperation with non-NATO members, especially Central and East European countries, international missions in the area of conflict prevention, crises-control, humanitarian, peacemaking, peacekeeping, participation in "Total Defence" in cooperation with civilian resources and finally maintenance of a sizable force to execute these tasks at all times.

Total Defence () is "the use of all resources in order to maintain an organized and functional society, and to protect the population and values of society". This is achieved by combining the military, Home Guard, Danish Emergency Management Agency and elements of the police. The concept of total defence was created following Word War 2, where it was clear that the defence of the country could not only rely on the military, but there also need to be other measures to ensure a continuation of society. As a part of the Total Defence, all former conscripts can be recalled to duty, in order to serve in cases of emergency.

Since 1988, Danish defence budgets and security policy have been set by multi-year white paper agreements supported by a wide parliamentary majority including government and opposition parties. However, public opposition to increases in defence spending—during periods of economic constraints require reduced spending for social welfare — has created differences among the political parties regarding a broadly acceptable level of new defence expenditure.

The latest Defence agreement ("Defence Agreement 2018–23") was signed 28 January 2018, and calls for an increase in spending, cyber security and capabilities to act in international operations and international stabilization efforts. The reaction speed is increased, with an entire brigade on standby readiness; the military retains the capability to continually deploy 2,000 soldiers in international service or 5,000 over a short time span. The standard mandatory conscription is expanded to include 500 more, with some of these having a longer service time, with more focus on national challenges.

In 2006 the Danish military budget was the fifth largest single portion of the Danish Government's total budget, significantly less than that of the Ministry of Social Affairs (≈110 billion DKK), Ministry of Employment (≈67 billion DKK), Ministry of the Interior and Health (≈66 billion DKK) and Ministry of Education (≈30 billion DKK) and only slightly larger than that of the Ministry of Science, Technology and Innovation (≈14 billion DKK). This list lists the complete expenditures for the Danish Ministry of Defence.

The Danish Defence Force, counting all branches and all departments, itself has an income equal to about 1–5% of its expenditures, depending on the year. They are not deducted in this listing.

Approximately 95% of the budget goes directly to running the Danish military including the Home guard. Depending on year, 50–53% accounts for payment to personnel, roughly 14–21% on acquiring new material, 2–8% for larger ships, building projects or infrastructure and about 24–27% on other items, including purchasing of goods, renting, maintenance, services and taxes.

The remaining 5% is special expenditures to NATO, branch shared expenditures, special services and civil structures, here in including running the Danish Maritime Safety Administration, Danish national rescue preparedness and the Administration of Conscientious Objectors (Militærnægteradministrationen).

Because Denmark has a small and highly specialized military industry, the vast majority of Danish Defence's equipment is imported from NATO and the Nordic countries.

Danish Defence expenditures (1949–1989)
Danish Defence expenditures (1990–)
The Danish Royal Army () consists of 2 brigades, organised into 3 regiments, and a number of support centres, all commanded through the Army Staff. The army is a mixture of Mechanized infantry and Armoured cavalry with a limited capabilities in Armoured warfare.

The army also provides protection for the Danish royal family, in the form of the Royal Guard Company and the Guard Hussar Regiment Mounted Squadron.

The Royal Danish Navy () consists of frigates, patrol vessels, mine-countermeasure vessels, and other miscellaneous vessels, many of which are issued with the modular mission payload system StanFlex. The navy's chief responsibility is maritime defence and maintaining the sovereignty of Danish, Greenlandic and Faroese territorial waters.

A submarine service existed within the Royal Danish Navy for 95 years.

The Royal Danish Air Force () consists of both fixed-wing and rotary aircraft.

The Home Guard is voluntary service responsible for defence of the country, but has since 2008 also supported the army, in Afghanistan and Kosovo.



Current deployment of Danish forces, per 10-03-2016:





Women in the military can be traced back to 1946, with the creation of "Lottekorpset". This corps allowed women to serve, however, without entering with the normal armed forces, and they were not allowed to carry weapons. In 1962, women were allowed in the military.

Currently 1,122 or 7.3% of all personnel in the armed forces are women. Women do not have to serve conscription in Denmark, since 1998, it is however possible to serve under ""conscription like circumstances"". 17% of those serve conscription or conscription like circumstances are women. Between 1991 and 31 December 2017, 1,965 women have been deployed to different international missions. Of those 3 women have lost their lives. In 1998, Police Constable Gitte Larsen, was killed in Hebron on the West Bank. In 2003, "Overkonstabel" Susanne Lauritzen was killed in a traffic accident in Kosovo. In 2010, the first woman was killed in a combat situation, when "Konstabel" Sophia Bruun was killed by an IED in Afghanistan.

In 2005, Line Bonde, became the first fighter pilot in Denmark. In 2016, Lone Træholt became the first female general. She was the only female general in the Danish armed forces until the army promoted Jette Albinus to the rank of brigadier general on 11 September 2017.
In May 2018, the Royal Life Guards was forced to lower the height requirements for women, as the Danish Institute of Human Rights decided it was discrimination.

Technically all Danish 18-year-old males are conscripts (37,897 in 2010, of whom 53% were considered suitable for duty). Due to the large number of volunteers, 96-99% of the number required in the past three years, the number of men actually called up is relatively low (4200 in 2012). There were additionally 567 female volunteers in 2010, who pass training on "conscript-like" conditions.

Conscripts to Danish Defence (army, navy and air force) generally serve four months, except:

There has been a right of conscientious objection since 1917.





</doc>
<doc id="8039" url="https://en.wikipedia.org/wiki?curid=8039" title="Foreign relations of Denmark">
Foreign relations of Denmark

The foreign policy of Denmark is based on its identity as a sovereign state in Europe, the Arctic and the North Atlantic. As such its primary foreign policy focus is on its relations with other nations as a sovereign state compromising the three constituent countries: Denmark, Greenland and the Faroe Islands. Denmark has long had good relations with other nations.
It has been involved in coordinating Western assistance to the Baltic states (Estonia, Latvia, and Lithuania). The country is a strong supporter of international peacekeeping. Danish forces were heavily engaged in the former Yugoslavia in the UN Protection Force (UNPROFOR), with IFOR, and now SFOR. Denmark also strongly supported American operations in Afghanistan and has contributed both monetarily and materially to the ISAF. These initiatives are a part of the "active foreign policy" of Denmark. Instead of the traditional adaptative foreign policy of The unity of the Realm, Kingdom of Denmark is today pursuing an active foreign policy, where human rights, democracy and other crucial values is to be defended actively. In recent years, Greenland and the Faroe Islands have been guaranteed a say in foreign policy issues, such as fishing, whaling and geopolitical concerns.

Following World War II, Denmark ended its two-hundred-year-long policy of neutrality. Denmark has been a member of NATO since its founding in 1949, and membership in NATO remains highly popular. There were several serious confrontations between the U.S. and Denmark on security policy in the so-called "footnote era" (1982–88), when an alternative parliamentary majority forced the government to adopt specific national positions on nuclear and arms control issues. The alternative majority in these issues was because the Social liberal Party (Radikale Venstre) supported the governing majority in economic policy issues, but was against certain NATO policies and voted with the left in these issues. The conservative led Centre-right government accepted this variety of "minority parliamentarism", that is, without making it a question of the government's parliamentary survival.
With the end of the Cold War, however, Denmark has been supportive of U.S. policy objectives in the Alliance.

Danes have a reputation as "reluctant" Europeans. When they rejected ratification of the Maastricht Treaty on 2 June 1992, they put the EC's plans for the European Union on hold. In December 1992, the rest of the EC agreed to exempt Denmark from certain aspects of the European Union, including a common defense, a common currency, EU citizenship, and certain aspects of legal cooperation. The Amsterdam Treaty was approved in the referendum of 28 May 1998. In the autumn of 2000, Danish citizens rejected membership of the Euro currency group in a referendum. The Lisbon treaty was ratified by the Danish parliament alone. It was not considered a surrendering of national sovereignty, which would have implied the holding of a referendum according to article 20 of the constitution.





</doc>
<doc id="8041" url="https://en.wikipedia.org/wiki?curid=8041" title="History of Djibouti">
History of Djibouti

Djibouti is a country in the Horn of Africa. It is bordered by Somalia to the southeast, Eritrea and the Red Sea to the north and northeast, Ethiopia to the west and south, and the Gulf of Aden to the east.

In antiquity, the territory was part of the Land of Punt. The Djibouti area, along with other localities in the Horn region, was later the seat of the medieval Adal and Ifat Sultanates. In the late 19th century, the colony of French Somaliland was established following treaties signed by the ruling Somali and Afar Sultans with the French. It was subsequently renamed to the French Territory of the Afars and the Issas in 1967. A decade later, the Djiboutian people voted for independence, officially marking the establishment of the Republic of Djibouti.

The Djibouti area has been inhabited since at least the Neolithic 12,000 years ago. Pottery predating the mid-2nd millennium BC has been found at Asa Koma, an inland lake area on the Gobaad Plain. The site's ware is characterized by punctate and incision geometric designs, which bear a similarity to the Sabir culture phase 1 ceramics from Ma'layba in Southern Arabia. Long-horned humpless cattle bones have also been discovered at Asa Koma, suggesting that domesticated cattle was present by around 3,500 years ago. Rock art of what appear to be antelopes and a giraffe are likewise found at Dorra and Balho. A team of archaeologists discovered funds stone houses, the walls of a rectangular edifice with orienteer recess to Mecca. They have also updated shards of ceramics, chipped stone tools and a glass bead. The oldest engravings discovered to date are from the fourth or third millennium BC in the pre-Islamic period, the most famous is the site of Handoga there where the ruins of a village squares subcircular dry stone delivered different objects. An old settlement, Handoga is the site of numerous ancient ruins and buildings, many of obscure origins, including ceramic shards, matching vases used brazier , containers that can hold water, several choppers and microliths, blades, drills, trenchers basalt, rhyolite or obsidian. A team of archaeologists discovered an elephant 1.6 million years BC near the area. They also found a pearl orange coralline, three glass paste , but there were no metal objects discovered. 

Together with northern Somalia, Eritrea and the Red Sea coast of Sudan, Djibouti is considered the most likely location of the land known to the ancient Egyptians as "Punt" (or "Ta Netjeru", meaning "God's Land"). The old territory's first mention dates to the 25th century BC. The Puntites were a nation of people that had close relations with Ancient Egypt during the times of Pharaoh Sahure of the fifth dynasty and Queen Hatshepsut of the eighteenth dynasty. They "traded not only in their own produce of incense, ebony and short-horned cattle, but also in goods from other neighbouring regions, including gold, ivory and animal skins." According to the temple reliefs at Deir el-Bahari, the Land of Punt at the time of Hatshepsut was ruled by King Parahu and Queen Ati.

Islam was introduced to the area early on from the Arabian peninsula, shortly after the hijra. Zeila's two-mihrab Masjid al-Qiblatayn dates to the 7th century, and is the oldest mosque in the city. In the late 9th century, Al-Yaqubi wrote that Muslims were living along the northern Horn seaboard. He also mentioned that the Adal kingdom had its capital in Zeila, a port city in the northwestern Awdal region abutting Djibouti. This suggests that the Adal Sultanate with Zeila as its headquarters dates back to at least the 9th or 10th century. According to I.M. Lewis, the polity was governed by local dynasties consisting of Somalized Arabs or Arabized Somalis, who also ruled over the similarly-established Sultanate of Mogadishu in the Benadir region to the south. Adal's history from this founding period forth would be characterized by a succession of battles with neighbouring Abyssinia. At its height, the Adal kingdom controlled large parts of modern-day Djibouti, Somalia, Eritrea and Ethiopia. Between Djibouti City and Loyada are a number of anthropomorphic and phallic stelae. The structures are associated with graves of rectangular shape flanked by vertical slabs, as also found in Tiya, central Ethiopia. The Djibouti-Loyada stelae are of uncertain age, and some of them are adorned with a T-shaped symbol. Additionally, archaeological excavations at Tiya have yielded tombs. As of 1997, 118 stelae were reported in the area. Along with the stelae in the Hadiya Zone, the structures are identified by local residents as "Yegragn Dingay" or "Gran's stone", in reference to Imam Ahmad ibn Ibrahim al-Ghazi (Ahmad "Gurey" or "Gran"), ruler of the Adal Sultanate.

The Ifat Sultanate was a medieval kingdom in the Horn of Africa. Founded in 1285 by the Walashma dynasty, it was centered in Zeila. Ifat established bases in Djibouti and northern Somalia, and from there expanded southward to the Ahmar Mountains. Its Sultan Umar Walashma (or his son Ali, according to another source) is recorded as having conquered the Sultanate of Shewa in 1285. Taddesse Tamrat explains Sultan Umar's military expedition as an effort to consolidate the Muslim territories in the Horn, in much the same way as Emperor Yekuno Amlak was attempting to unite the Christian territories in the highlands during the same period. These two states inevitably came into conflict over Shewa and territories further south. A lengthy war ensued, but the Muslim sultanates of the time were not strongly unified. Ifat was finally defeated by Emperor Amda Seyon I of Ethiopia in 1332, and withdrew from Shewa.

Governor Abou Baker ordered the Egyptian garrison at Sagallo to retire to Zeila. The cruiser Seignelay reached Sagallo shortly after the Egyptians had departed. French troops occupied the fort despite protests from the British Agent in Aden, Major Frederick Mercer Hunter, who dispatched troops to safeguard British and Egyptian interests in Zeila and prevent further extension of French influence in that direction.
On the 14 April 1884 the Commander of the patrol sloop L’Inferent reported on the Egyptian occupation in the Gulf of Tadjoura. The Commander of the patrol sloop Le Vaudreuil reported that the Egyptians were occupying the interior between Obock and Tadjoura. Emperor Johannes IV of Ethiopia signed an accord with the United Kingdom to cease fighting the Egyptians and to allow the evacuation of Egyptian forces from Ethiopia and the Somali Coast ports.
The Egyptian garrison was withdrawn from Tadjoura. Léonce Lagarde deployed a patrol sloop to Tadjoura the following night.

It was Rochet d'Hericourt's exploration into Shoa (1839–42) that marked the beginning of French interest in the Djiboutian coast of the Red Sea. Further exploration by Henri Lambert, French Consular Agent at Aden, and Captain Fleuriot de Langle led to a treaty of friendship and assistance between France and the sultans of Raheita, Tadjoura, and Gobaad, from whom the French purchased the anchorage of Obock in 1862.

Growing French interest in the area took place against a backdrop of British activity in Egypt and the opening of the Suez Canal in 1869. Between 1883-87, France signed various treaties with the then ruling Somali and Afar Sultans, which allowed it to expand the protectorate to include the Gulf of Tadjoura. Léonce Lagarde was subsequently installed as the protectorate's governor. In 1894, he established a permanent French administration in the city of Djibouti and named the region "Côte française des Somalis" (French Somaliland), a name which continued until 1967. The territory's border with Ethiopia, marked out in 1897 by France and Emperor Menelik II of Ethiopia, was later reaffirmed by agreements with Emperor Haile Selassie I of Ethiopia in 1945 and 1954.

In 1889, a Russian by the name of Nikolay Ivanovitch Achinov (b. 1856), arrived with settlers, infantry and an Orthodox priest to Sagallo on the Gulf of Tadjoura. The French considered the presence of the Russians as a violation of their territorial rights and dispatched two gunboats. The Russians were bombarded and after some loss of life, surrendered. The colonists were deported to Odessa and the dream of Russian expansion in East Africa came to an end in less than one year.
The administrative capital was moved from Obock in 1896. The city of Djibouti, which had a harbor with good access that attracted trade caravans crossing East Africa, became the new administrative capital. The Franco-Ethiopian railway, linking Djibouti to the heart of Ethiopia, began in 1897 and reached Addis Ababa in June 1917, increasing the volume of trade passing through the port.

After the Italian invasion and occupation of Ethiopia in the mid-1930s, constant border skirmishes occurred between French forces in French Somaliland and Italian forces in Italian East Africa. In June 1940, during the early stages of World War II, France fell and the colony was then ruled by the pro-Axis Vichy (French) government.

British and Commonwealth forces fought the neighboring Italians during the East African Campaign. In 1941, the Italians were defeated and the Vichy forces in French Somaliland were isolated. The Vichy French administration continued to hold out in the colony for over a year after the Italian collapse. In response, the British blockaded the port of Djibouti City but it could not prevent local French from providing information on the passing ship convoys. In 1942, about 4,000 British troops occupied the city. A local battalion from French Somaliland participated in the Liberation of Paris in 1944.

In 1958, on the eve of neighboring Somalia's independence in 1960, a referendum was held in Djibouti to decide whether or not to join the Somali Republic or to remain with France. The referendum turned out in favour of a continued association with France, partly due to a combined yes vote by the sizable Afar ethnic group and resident Europeans. There were also reports of widespread vote rigging, with the French expelling thousands of Somalis before the referendum reached the polls. The majority of those who voted no were Somalis who were strongly in favour of joining a united Somalia as had been proposed by Mahmoud Harbi, Vice President of the Government Council. Harbi died in a plane crash two years later under mysterious circumstances.

In 1960, with the fall of the ruling Dini administration, Ali Aref Bourhan, a Harbist politician, assumed the seat of Vice President of the Government Council of French Somaliland, representing the UNI party. He would hold that position until 1966.

That same year, France rejected the United Nations' recommendation that it should grant French Somaliland independence. In August, an official visit to the territory by then French President, General Charles de Gaulle, was also met with demonstrations and rioting. In response to the protests, de Gaulle ordered another referendum.

On 19 March 1967, a second plebiscite was held to determine the fate of the territory. Initial results supported a continued but looser relationship with France. Voting was also divided along ethnic lines, with the resident Somalis generally voting for independence, with the goal of eventual reunion with Somalia, and the Afars largely opting to remain associated with France. However, the referendum was again marred by reports of vote rigging on the part of the French authorities, with some 10,000 Somalis deported under the pretext that they did not have valid identity cards. According to official figures, although the territory was at the time inhabited by 58,240 Somali and 48,270 Afar, only 14,689 Somali were allowed to register to vote versus 22,004 Afar. Somali representatives also charged that the French had simultaneously imported thousands of Afar nomads from neighboring Ethiopia to further tip the odds in their favor, but the French authorities denied this, suggesting that Afars already greatly outnumbered Somalis on the voting lists. Announcement of the plebiscite results sparked civil unrest, including several deaths. France also increased its military force along the frontier.

In 1967, shortly after the second referendum was held, the former "Côte française des Somalis" (French Somaliland) was renamed to "Territoire français des Afars et des Issas". This was both in acknowledgement of the large Afar constituency and to downplay the significance of the Somali composition (the Issa being a Somali sub-clan).

The French Territory of Afars and Issas also differed from French Somaliland in terms of government structure, as the position of governor changed to that of high commissioner. A nine-member council of government was also implemented.

With a steadily enlarging Somali population, the likelihood of a third referendum appearing successful had grown even more dim. The prohibitive cost of maintaining the colony and the fact that after 1975, France fount itself to be the last remaining colonial power in Africa was another factor that compelled observers to doubt that the French would attempt to hold on to the territory.

On June 27, 1977, a third vote took place. A landslide 98.8% of the electorate supported disengagement from France, officially marking Djibouti's independence. Hassan Gouled Aptidon, a Somali politician who had campaigned for a yes vote in the referendum of 1958, eventually became the nation's first president (1977–1999).

In 1981, Aptidon turned the country into a one party state by declaring that his party, the Rassemblement Populaire pour le Progrès (RPP) (People's Rally for Progress), was the sole legal one. A civil war broke out in 1991, between the government and a predominantly Afar rebel group, the Front for the Restoration of Unity and Democracy (FRUD). The FRUD signed a peace accord with the government in December 1994, ending the conflict. Two FRUD members were made cabinet members, and in the presidential elections of 1999 the FRUD campaigned in support of the RPP.

Aptidon resigned as president 1999, at the age of 83, after being elected to a fifth term in 1997. His successor was his nephew, Ismail Omar Guelleh.

On May 12, 2001, President Ismail Omar Guelleh presided over the signing of what is termed the final peace accord officially ending the decade-long civil war between the government and the armed faction of the FRUD, led by Ahmed Dini Ahmed, an Afar nationalist and former Gouled political ally. The peace accord successfully completed the peace process begun on February 7, 2000 in Paris. Ahmed Dini Ahmed represented the FRUD.

In the presidential election held April 8, 2005, Ismail Omar Guelleh was re-elected to a second 6-year term at the head of a multi-party coalition that included the FRUD and other major parties. A loose coalition of opposition parties again boycotted the election. Currently, political power is shared by a Somali president and an Afar prime minister, with an Afar career diplomat as Foreign Minister and other cabinet posts roughly divided. However, Issas are predominate in the government, civil service, and the ruling party. That, together with a shortage of non-government employment, has bred resentment and continued political competition between the Issa Somalis and the Afars. In March 2006, Djibouti held its first regional elections and began implementing a decentralization plan. The broad pro-government coalition, including FRUD candidates, again ran unopposed when the government refused to meet opposition preconditions for participation. In the 2008 elections, the opposition Union for a Presidential Majority (UMP) party boycotted the election, leaving all 65 seats to the ruling RPP. Voter turnout figures were disputed. Guelleh was re-elected in the 2011 presidential election.

Due to its strategic location at the mouth of the Bab el Mandeb gateway to the Red Sea and the Suez Canal, Djibouti also hosts various foreign military bases. Camp Lemonnier is a United States Naval Expeditionary Base, situated at Djibouti-Ambouli International Airport and home to the Combined Joint Task Force - Horn of Africa (CJTF-HOA) of the U.S. Africa Command (USAFRICOM). In 2011, Japan also opened a local naval base staffed by 180 personnel to assist in marine defense. This initiative is expected to generate $30 million in revenue for the Djiboutian government.




</doc>
<doc id="8042" url="https://en.wikipedia.org/wiki?curid=8042" title="Geography of Djibouti">
Geography of Djibouti

Djibouti is a country in the Horn of Africa. It is bordered by Eritrea in the north, Ethiopia in the west and south, and Somalia in the southeast. To the east is its coastline on the Red Sea and the Gulf of Aden. Rainfall is sparse, and most of the territory has a semi-arid to arid environment. Lake Assal is a saline lake which lies 155 m (509 ft) below sea level, making it the lowest point on land in Africa and the third-lowest point on Earth after the Sea of Galilee and the Dead Sea. Djibouti has the fifth smallest population in Africa. Djibouti's major settlements include the capital Djibouti City, the port towns of Tadjoura and Obock, and the southern cities of Ali Sabieh and Dikhil. It is the 147st largest country in the world by land area, covering a total of 23,200 km, of which 23,180 km is land and 20 km is water.

Djibouti shares of border with Eritrea, with Ethiopia, and with Somalia (total ). It has a strategic location on the Horn of Africa and the Bab el Mandeb, along a route through the Red Sea and Suez Canal. Djibouti's coastline serves as a commercial gateway between the Arabian Peninsula and the Horn region's interior. The country is also the terminus of rail traffic into Ethiopia.

Djibouti can be divided into four physiographic regions
A great arc of mountains, consisting of the Mousa Ali, Goda Mountains, and Arrei Mountains surrounds Djibouti.

Djibouti has eight mountain ranges with peaks of over 1,000 m (3,281 ft).


The Grand Bara Desert covers parts of southern Djibouti in the Arta Region, Ali Sabieh Region and Dikhil Region. The majority of the Grand Bara Desert lies at a relatively low elevation, below 1,700 feet (560 m). Home of the popular Grand Bara footrace.

Most of Djibouti has been described as part of the Ethiopian xeric grasslands and shrublands ecoregion. The exception is a strip along the Red Sea coast, which is part of the Eritrean coastal desert; it is noted as an important migration route for birds of prey.
The area of the regions of Djibouti is set out in the table below.

There is not much seasonal variation in Djibouti's climate. Hot conditions prevail year-round along with winter rainfall. Mean daily maximum temperatures range from 32 to 41 °C (90 to 106 °F), except at high elevations. In Djibouti City, for instance, afternoon highs in April typically range from 28 °C (82 °F) to 34 °C (93 °F) in April. Nationally, mean daily minima generally vary between sites from about 15 to 30 °C (59 to 86 °F). The greatest range in climate occurs in eastern Djibouti, where temperatures sometimes surpass 41 °C (106 °F) in July on the littoral plains and fall below freezing point during December in the highlands. In this region, relative humidity ranges from about 40% in the mid-afternoon to 85% at night, changing somewhat according to the season.
Djibouti has either a hot semi-arid climate ("BSh") or a hot desert climate ("BWh"), although temperatures are much moderated at the high elevations. On the coastal seaboard, annual rainfall is less than 5 inches (131 mm); in the highlands, it is about 8 to 16 inches (200 to 400 mm). Although the coastal regions are hot and humid throughout the year, the hinterland is typically hot and dry. The climate conditions are highly variable within the country and vary locally by altitude. Summers are very humid along the coast but dry in the highlands. Heat waves are frequent. Annual precipitation amounts vary greatly from one year to another. In general, rain falls more frequently and extensively in the mountains. Sudden and brutal storms are also known to occur. Wadis turn for a few hours into raging torrents tearing everything in their path, and their course is regularized. Rainwater serves as an additional water supply for livestock and plants alongside seasonal watercourses. The highlands have temperate climate throughout out the year. The climate of most lowland zones is arid and semiarid.

The climate of the interior shows notable differences from the coastline. Especially in the mornings, the temperature is pleasant: it is so in Arta, Randa and Day (where temperatures of 10 degrees Celsius have been recorded).

Graphically the seasons can be represented this way:

Lake Assal is the lowest point in Africa.

Land use:
"arable land:" 0.1%
<br>"permanent pasture:" 73.3%
<br>"forest:" 0.2% 
<br>"other:" 26.4% (2011)

Irrigated land: (2012)

Water is becoming a scarce resource in Djibouti due to climate change, which leads to different rainfall patterns as well as to inefficient methods of distribution within the country. Most of Djibouti’s rainfall is in the four months, but over the last 25 years, the Djibouti's Ministry of Environment estimates that rainfall has decreased overall between 5 and 20 percent. It is predicted that in future years, there will be higher temperatures, lower rainfall, and longer droughts, leading to even less access to water. Moreover, seawater intrusion or fossil saltwater contamination of the limited freshwater aquifers due to groundwater overexploitation affect those who live close to the coastline.

In recent years, population growth has increased rapidly with the addition of many refugees.

Unlike much of the Horn of Africa and Middle East which is rich in lucrative crude oil, Djibouti has limited natural resources. These include potential geothermal power, gold, clay, granite, limestone, marble, salt, diatomite, gypsum, pumice, petroleum.

Natural hazards include earthquakes, drought, and occasional cyclonic disturbances from the Indian Ocean, which bring heavy rains, and flash floods. Natural resources include geothermal energy. Inadequate supplies of potable water, limited arable land and desertification are current issues.

Djibouti is a party to international agreements on biodiversity, climate change, desertification, endangered species, Law of the Sea, ozone layer protection, ship pollution, and wetlands.

Djibouti has a coastline which measures about 314 kilometres (195 mi). Much of the coastline is accessible and quite varied in geography and habitats.



As of 2015, the population of Djibouti is 846 thousand.

For statistical purposes, the country has three areas; Djibouti City (population 529,000), Ali Sabieh (population 55,000), and Dikhil (population 54,000). Djibouti's population is diverse demographically; 60% Somali, 35% Afar, and 3% Arabs. In terms of religion, 94% Muslim, 6% Christian.

This is a list of the extreme points of Djibouti, the points that are farther north, south, east or west than any other location.



</doc>
<doc id="8043" url="https://en.wikipedia.org/wiki?curid=8043" title="Demographics of Djibouti">
Demographics of Djibouti

This article is about the demographics of Djibouti, including population density, ethnicity, education level, health, economic status, religious affiliations and other aspects of the population.

Djibouti is a multiethnic country. As of 2018, it has a population of around 884,017 inhabitants. Djibouti's population grew rapidly during the latter half of the 20th century, increasing from about 69,589 in 1955 to around 869,099 by 2015.

The two largest ethnic groups are the Somali (60%) and the Afar (35%). The Somali clan component is mainly composed of the Issas, a sub-clan of the larger Dir. The remaining 5% of Djibouti's population primarily consists of Arabs, Ethiopians and Europeans (French and Italians). Approximately 76% of local residents are urban dwellers; the remainder are pastoralists.

Djibouti is a multilingual nation. The majority of local residents speak Somali (524,000 speakers) and Afar (306,000 speakers) as a first language. These idioms are the mother tongues of the Somali and Afar ethnic groups, respectively. Both languages belong to the larger Afroasiatic family. There are three official languages in Djibouti: Somali, Arabic and French.

Arabic is of religious importance. In formal settings, it consists of Modern Standard Arabic. Colloquially, about 59,000 local residents speak the Ta'izzi-Adeni Arabic dialect, also known as "Djibouti Arabic". French serves as a statutory national language. It was inherited from the colonial period, and is the primary language of instruction. Around 17,000 Djiboutians speak it as a first language. Immigrant languages include Omani Arabic (38,900 speakers), Amharic (1,400 speakers), Greek (1,000 speakers) and Hindi (600 speakers).

According to , the total population was in compared to 62,000 in 1950. The proportion of children below the age of 15 in 2010 was 35.8%, 60.9% was between 15 and 65 years of age, while 3.3% was 65 years or older.
The following are UN medium variant projections; numbers are in thousands:

Registration of vital events in Djibouti is incomplete. The Population Department of the United Nations prepared the following estimates.
Births and deaths 
Demographic statistics according to the World Population Review in 2019.


The following demographic statistics are from the CIA World Factbook.

note: "highly pathogenic H5N1 avian influenza has been identified in this country; it poses a negligible risk with extremely rare cases possible among US citizens who have close contact with birds (2013)"

Afar 35%, Somali 60% and Arab 2%

The religious adherents of Djibouti are:

The languages of Djibouti are:


</doc>
<doc id="8044" url="https://en.wikipedia.org/wiki?curid=8044" title="Politics of Djibouti">
Politics of Djibouti

Politics of Djibouti takes place in a framework of a presidential representative democratic republic, whereby the executive power is exercised by the President and the Government. Legislative power is vested in both the Government and the National Assembly. The party system and legislature are dominated by the socialist People's Rally for Progress. In April 2010, a new constitutional amendment was approved. The President serves as both the head of state and head of government, and is directly elected for single six-year term. Government is headed by the President, who appoints the Prime Minister and the Council of Ministers on the proposal of the latter. There is also a 65-member chamber of deputies, where representatives are popularly elected for terms of five years. Administratively, the country is divided into five regions and one city, with eleven additional district subdivisions. Djibouti is also part of various international organisations, including the United Nations and Arab League.

In 1958, on the eve of neighboring Somalia's independence in 1960, a referendum was held in Djibouti to decide whether to join the Somali Republic or to remain with France. The referendum turned out in favour of a continued association with France, partly due to a combined "yes" vote by the sizeable Afar ethnic group and resident Europeans. There was also widespread vote rigging, with the French expelling thousands of Somalis before the referendum reached the polls. The majority of those who had voted "no" were Somalis who were strongly in favour of joining a united Somalia as had been proposed by Mahmoud Harbi, Vice President of the Government Council. Harbi was killed in a plane crash two years later.

In 1967, a second plebiscite was held to determine the fate of the territory. Initial results supported a continued but looser relationship with France. Voting was also divided along ethnic lines, with the resident Somalis generally voting for independence, with the goal of eventual union with Somalia, and the Afars largely opting to remain associated with France. However, the referendum was again marred by reports of vote rigging on the part of the French authorities. Shortly after the referendum was held, the former "Côte française des Somalis" (French Somaliland) was renamed to "Territoire français des Afars et des Issas".

In 1977, a third referendum took place. A landslide 98.8% of the electorate supported disengagement from France, officially marking Djibouti's independence.

Hassan Gouled Aptidon, a Somali politician who had campaigned for a "yes" vote in the referendum of 1958, eventually wound up as the nation's first president (1977–1999). He was re-elected, unopposed, to a second 6-year term in April 1987 and to a third 6-year term in May 1993 multiparty elections. The electorate approved the current constitution in September 1992. Many laws and decrees from before independence remain in effect.

In early 1992, the government decided to permit multiple party politics and agreed to the registration of four political parties. By the time of the national assembly elections in December 1992, only three had qualified. They are the "Rassemblement Populaire Pour le Progres" (People's Rally for Progress) (RPP) which was the only legal party from 1981 until 1992, the "Parti du Renouveau Démocratique" (The Party for Democratic Renewal) (PRD), and the "Parti National Démocratique" (National Democratic Party) (PND). Only the RPP and the PRD contested the national assembly elections, and the PND withdrew, claiming that there were too many unanswered questions on the conduct of the elections and too many opportunities for government fraud. The RPP won all 65 seats in the national assembly, with a turnout of less than 50% of the electorate.

In 1999, President Aptidon's chief of staff, head of security, and key adviser for over 20 years, Ismail Omar Guelleh was elected to the Presidency as the RPP candidate. He received 74% of the vote, the other 26% going to opposition candidate Moussa Ahmed Idriss, of the Unified Djiboutian Opposition (ODU). For the first time since independence, no group boycotted the election. Moussa Ahmed Idriss and the ODU later challenged the results based on election "irregularities" and the assertion that "foreigners" had voted in various districts of the capital; however, international and locally based observers considered the election to be generally fair, and cited only minor technical difficulties. Guelleh took the oath of office as the second President of the Republic of Djibouti on May 8, 1999, with the support of an alliance between the RPP and the government-recognised section of the Afar-led FRUD.

Currently, political power is shared by a Somali Issa president and an Afar prime minister, with cabinet posts roughly divided. However, it is the Issas who dominate the government, civil service, and the ruling party, a situation that has bred resentment and political competition between the Somali Issas and the Afars.

The government is dominated by the Somali Issa Mamasen, who enjoy the support of the Somali clans, especially the Isaaq (the clan of the current president's wife) and the Gadabuursi Dir (who are the second most prominent Somali clan in Djibouti politics). In early November 1991, civil war erupted in Djibouti between the government and a predominantly Afar rebel group, the Front for the Restoration of Unity and Democracy (FRUD). The FRUD signed a peace accord with the government in December 1994, ending the conflict. Two FRUD members were subsequently made cabinet members, and in the presidential elections of 1999 the FRUD campaigned in support of the RPP. In February 2000, another branch of FRUD signed a peace accord with the government. On 12 May 2001, President Ismail Omar Guelleh presided over the signing of what is termed the final peace accord officially ending the decade-long civil war between the government and the armed faction of the FRUD. The treaty successfully completed the peace process begun on 7 February 2000 in Paris, with Ahmed Dini Ahmed representing the FRUD.

On 8 April 2005, President Guelleh was sworn in for his second six-year term after a one-man election. He took 100% of the votes in a 78.9% turnout.

In early 2011, the Djiboutian citizenry took part in a series of protests against the long-serving government, which were associated with the larger Arab Spring demonstrations. Guelleh was re-elected to a third term later that year, with 80.63% of the vote in a 75% turnout. Although opposition groups boycotted the ballot over changes to the constitution permitting Guelleh to run again for office, international observers generally described the election as free and fair.

On 31 March 2013, Guelleh replaced long-serving Prime Minister Dilleita Mohamed Dilleita with former president of the Union for a Presidential Majority (UMP) Abdoulkader Kamil Mohamed.

The President is directly elected by popular vote for a six-year term. The Prime Minister is appointed by the President, and the Council of Ministers is solely responsible to the President, as specified in .

Djibouti is sectioned into five administrative regions and one city:

Ali Sabieh Region, Arta Region, Dikhil Region, Djibouti Region, Obock Region and Tadjourah Region.

The country is further sub-divided into eleven districts.

ACCT,
ACP,
AfDB,
AFESD,
AL,
AMF,
ECA,
FAO,
G-77,
IBRD,
ICAO,
ICC,
ICRM,
IDA,
IDB,
IFAD,
IFC,
IFRCS,
IGAD,
ILO,
IMF,
IMO,
Intelsat (nonsignatory user),
Interpol,
IOC,
ITU,
ITUC,
NAM,
OAU,
OIC,
OPCW,
UN,
UNCTAD,
UNESCO,
UNIDO,
UPU,
WFTU,
WHO,
WMO,
WToO,
WTrO


</doc>
<doc id="8045" url="https://en.wikipedia.org/wiki?curid=8045" title="Economy of Djibouti">
Economy of Djibouti

The economy of Djibouti is derived in large part from its strategic location on the Red Sea. Djibouti is mostly barren, with little development in the agricultural and industrial sectors. The country has a harsh climate, a largely unskilled labour force, and limited natural resources. The country’s most important economic asset is its strategic location connecting the Red Sea and the Gulf of Aden. As such, Djibouti’s economy is commanded by the services sector, providing services as both a transit port for the region and as an international transshipment and refueling centre.

From 1991 to 1994, Djibouti experienced a civil war which had devastating effects on the economy. Since then, the country has benefited from political stability. In recent years, Djibouti has seen significant improvement in macroeconomic stability, with its annual gross domestic product improving at an average of over 3 percent since 2003. This comes after a decade of negative or low growth. This is attributed to fiscal adjustment measures aimed at improving public financing, as well as reforms in port management.

Despite the recent modest and stable growth, Djibouti is faced with many economic challenges, particularly job creation and poverty reduction. With an average annual population growth rate of 2.5 percent, the economy cannot significantly benefit national income per capita growth. Unemployment is extremely high at over 43 percent and is a major contributor to widespread poverty. Efforts are needed in creating conditions that will enhance private sector development and accumulate human capital. These conditions can be achieved through improvements in macroeconomic and fiscal framework, public administration, and labour market flexibility.

Djibouti was ranked the 177th safest investment destination in the world in the March 2011 Euromoney Country Risk rankings.

Djibouti has experienced stable economic growth in recent years as a result of achievements in macroeconomic adjustment efforts. Fiscal adjustment measures included downsizing the civil service, implementing a pension reform that placed the system on a much stronger financial footing, and strengthening public expenditure institutions. From 2003 to 2005, annual real GDP growth averaged 3.1 percent driven by good performance in the services sector and strong consumption. Inflation has been kept low (only 1 percent in 2004, compared with 2.2 percent in 2003), due to the fixed peg of the Djibouti franc to the US dollar. However, as mentioned above, unemployment has remained high at over 40 percent in recent years. Djibouti's gross domestic product expanded by an average of more than 6 percent per year, from US$341 million in 1985 to US$1.5 billion in 2015.

The government fiscal balance is in deficit because the government has not been able to raise sufficient tax revenues to cover expenses. In 2004, a substantial increase in expenditure resulted in a deterioration of the fiscal position. As a result, the government deficit increased to US$17 million in 2004 from US$7 million in 2003. But improvement in expenditure management brought down the fiscal deficit to US$11 million in 2005.

Djibouti’s merchandise trade balance has shown a large deficit. This is due to the country's enormous need for imports and narrow base of exports. Although Djibouti runs a substantial surplus in its services balance, the surplus has been smaller than the deficit in the merchandise trade balance. As a result, Djibouti's current account balance has been in deficit. There is very limited information for Djibouti’s current account; the country’s merchandise trade deficit was estimated at US$737 million in 2004.

Positioned on a primary shipping lane between the Gulf of Aden and the Red Sea, Djibouti holds considerable strategic value in the international trade and shipping industries. The facilities of the Port of Djibouti are important to sea transportation companies for fuel bunkering and refuelling. Its transport facilities are used by several landlocked African countries for the re-export of their goods. Djibouti earns transit taxes and harbour fees from this trade, these form the bulk of government revenue. Threats of pirates patrolling the Gulf of Aden, off the coast of Somalia, with the intentions of capturing large cargo ships, oil, and chemical tankers has created the need for larger nations such as the United States, France, and Japan to embed logistics bases or military camps from which they can defend their freight from piracy. The port of Djibouti functions as a small French naval facility, and the United States has also stationed hundreds of troops in Camp Lemonnier, Djibouti, its only African base, in an effort to counter terrorism in the region. Recently China has stated they are in talks to build “logistics facilities” in Obock to provide support peacekeeping and anti-piracy missions near Somalia and the Gulf of Aden. Additional international presence will increase both Djibouti’s economic value as well its strategic importance in the region.

This is a chart of trend of gross domestic product of Djibouti at market prices estimated by the International Monetary Fund with figures in millions of Djiboutian francs.
For purchasing power parity comparisons, the US dollar is exchanged at 76.03 Djiboutian francs. Mean wages were $1.30 per person-hour in 2009.

The following table shows the main economic indicators in 1980–2017.

Djibouti’s economy is based on service activities connected with the country's strategic location and status as a free trade zone in the Horn of Africa. Two-thirds of inhabitants live in the capital and the remainder of the populace is mostly nomadic herders. Low amounts of rainfall limit crop production to fruits and vegetables, and requiring most food to be imported. The government provides services as both a transit port for the region and an international transshipment and refueling centre. Djibouti has few natural resources and little industry. All of these factors contribute to its heavy dependence on foreign assistance to help support its balance of payments and to finance development projects.

An unemployment rate of 50 percent continues to be a major problem. Inflation is not a concern, however, because of the fixed tie of the franc to the US dollar. Per capita consumption dropped an estimated 35 percent over the last seven years because of recession, civil war, and a high population growth rate. Faced with a multitude of economic difficulties, the government has fallen in arrears on long-term external debt and has been struggling to meet the stipulations of foreign aid donors.

The government of Djibouti welcomes all foreign direct investment. Djibouti's assets include a strategic geographic location, an open trade regime, a stable currency, substantial tax breaks and other incentives. Potential areas of investment include Djibouti's port and the telecommunications sectors. President Ismail Omar Guellehh first elected in 1999, has named privatization, economic reform, and increased foreign investment as top priorities for his government. The president pledged to seek the help of the international private sector to develop the country's infrastructure.

Djibouti has no major laws that would discourage incoming foreign investment. In principle there is no screening of investment or other discriminatory mechanisms. That said, certain sectors, most notably public utilities, are state owned and some parts are not currently open to investors. Conditions of the structural adjustment agreement recently signed by Djibouti and the International Monetary Fund stipulate increased privatization of parastatal and government-owned monopolies. There are no patent laws in Djibouti.

As in most African nations, access to licenses and approvals is complicated not so much by law as by administrative procedures. In Djibouti, the administrative process has been characterized as a form of 'circular dependency.' For example, the finance ministry will issue a license only if an investor possesses an approved investor visa, while the interior ministry will only issue an investor visa to a licensed business. The Djiboutian government is increasingly realizing the importance of establishing a one-stop shop to facilitate the investment process.

Principal exports from the region transiting Djibouti are coffee, salt, hides, dried beans, cereals, other agricultural products, chalk, and wax. Djibouti itself has few exports, and the majority of its imports come from France. Most imports are consumed in Djibouti and the remainder goes to Ethiopia and Somalia. Djibouti's unfavourable balance of trade is offset partially by invisible earnings such as transit taxes and harbour dues. In 1999, U.S. exports to Djibouti totalled $26.7 million while U.S. imports from Djibouti were less than $1 million. The City of Djibouti has the only paved airport in the republic.

In 2013, 63,000 foreign tourists visited Djibouti, Djibouti City is the principal tourist destination for visitors, revenues from tourism fell just US$43 million in 2013.



</doc>
<doc id="8047" url="https://en.wikipedia.org/wiki?curid=8047" title="Transport in Djibouti">
Transport in Djibouti

Transport in Djibouti includes highways, airports, railways and seaports.

The country's first railway, Ethio-Djibouti Railway, was a metre gauge railway that connected Ethiopia to Djibouti. It was built between 1894 and 1917 by the French who ruled the country at the time as French Somaliland. The railway is no longer operational.

Currently (2018), Djibouti has 93 km of railways. The new Addis Ababa-Djibouti Railway, an electrified standard gauge railway built by two Chinese government firms, began regular operations in January 2018. Its main purpose is to facilitate freight services between the Ethiopian hinterland and the Djiboutian Port of Doraleh. Railway services are provided by the "Ethio-Djibouti Standard Gauge Rail Transport Share Company", a bi-national company between Ethiopia and Djibouti, which operates all commuter and freight railway services in the country. Djibouti has a total of four railway stations, of which three (Nagad, Holhol and Ali Sabieh) can handle passenger traffic.

The Djiboutian highway system is named according to the road classification. Roads that are considered primary roads are those that are fully asphalted (throughout their entire length) and in general they connect all the major towns in Djibouti. There is a total of of roads, with paved and unpaved, according to a 2000 estimate.

Djibouti has an improved natural harbor that consists of a roadstead, outer harbor, and inner harbor, known as the Port of Djibouti. The roadstead is well protected by reefs and by the configuration of the land. 95% of Ethiopia’s imports and exports move through Djiboutian ports. Car ferries pass the Gulf of Tadjoura from Djibouti City to Tadjoura.

For decades, the Port of Djibouti was Djibouti's only freight port. It is now in the process of being replaced by the Port of Doraleh west of Djibouti City. In addition to the Port of Doraleh, which handles general cargo and oil imports, Djibouti currently (2018) has three other major ports for the import and export of bulk goods and livestock, the Port of Tadjourah (potash), the Damerjog Port (livestock) and the Port of Goubet (salt).

Djibouti had one ship of over 1,000 GT: 1,369 GT/ according to a 1999 estimate.

In 2004, there were an estimated 13 airports, only 3 of which had paved runways as of 2005. Djibouti–Ambouli International Airport, which is situated about 6 km from the city of Djibouti, is the country's international air terminal. There are also local airports at Tadjoura and Obock. Beginning in 1963, the state-owned Air Djibouti also provided domestic service to various domestic centers and flew to many overseas destinations. The national carrier discontinued operations in 2002. Daallo Airlines, a Somali-owned private carrier, has also offered air transportation since its foundation in 1991. With its hub at the Djibouti–Ambouli International Airport, the airline provides flights to a number of domestic and overseas destinations.

"total:"
3
<br>"over 3,047 m:"
1
<br>"1,524 to 3,047 m:"
2 (2013 est.)

"total:"
10
<br>"1,524 to 2,437 m:"
1
<br>"914 to 1,523 m:"
7
<br>"under 914 m:"
2 (2013 est.)



</doc>
<doc id="8048" url="https://en.wikipedia.org/wiki?curid=8048" title="Djibouti Armed Forces">
Djibouti Armed Forces

The Djibouti Armed Forces (DJAF) (, ) are the military forces of Djibouti. They consist of the Djiboutian Army and its sub-branches the Djibouti Air Force and Djiboutian Navy. As of 2018, the Djibouti Armed Forces consists of 20,470 (2018 est.) ground troops, which are divided into several regiments and battalions garrisoned in various areas throughout the country. Djibouti Armed Forces are an important player in the Bab-el-Mandeb and Red Sea.

In 2015 General Zakaria Chiek Imbrahim was "chief d'etat-major general" (chief of staff) of the "Forces Armees Djiboutiennes". He assumed command in November 2013.

Djibouti has always been a very active member in the African Union and the Arab League.

Historically, Somali society accorded prestige to the warrior ("waranle") and rewarded military prowess. Except for men of religion ("wadaad"), who were few in number, all Somali males were considered potential warriors.
Djibouti's many Sultanates each maintained regular troops. In the early Middle Ages, the conquest of Shewa by the Ifat Sultanate ignited a rivalry for supremacy with the Solomonic Dynasty.

Many similar battles were fought between the succeeding Sultanate of Adal and the Solomonids, with both sides achieving victory and suffering defeat. During the protracted Ethiopian-Adal War (1529–1559), Imam Ahmad ibn Ibrihim al-Ghazi defeated several Ethiopian Emperors and embarked on a conquest referred to as the "Futuh Al-Habash" ("Conquest of Abyssinia"), which brought three-quarters of Christian Abyssinia under the power of the Muslim Adal Sultanate. Al-Ghazi's forces and their Ottoman allies came close to extinguishing the ancient Ethiopian kingdom, but the Abyssinians managed to secure the assistance of Cristóvão da Gama's Portuguese troops and maintain their domain's autonomy. However, both polities in the process exhausted their resources and manpower, which resulted in the contraction of both powers and changed regional dynamics for centuries to come.

The Ogaden War (13 July 1977 – 15 March 1978) was a conflict fought between the Ethiopian government and Somali government. The Djibouti government supported Somalia with military intelligence. In a notable illustration of the nature of Cold War alliances, the Soviet Union switched from supplying aid to Somalia to supporting Ethiopia, which had previously been backed by the United States. This in turn prompted the U.S. to later start supporting Somalia. The war ended when Somali forces retreated back across the border and a truce was declared.

The first war which involved the Djiboutian armed forces was the Djiboutian Civil War between the Djiboutian government, supported by France, and the Front for the Restoration of Unity and Democracy ("FRUD"). The war lasted from 1991 to 2001, although most of the hostilities ended when the moderate factions of FRUD signed a peace treaty with the government after suffering an extensive military setback when the government forces captured most of the rebel-held territory. A radical group continued to fight the government, but signed its own peace treaty in 2001. The war ended in a government victory, and FRUD became a political party.
Djibouti has fought in clashes against Eritrea over the Ras Doumeira peninsula, which both countries claim to be under their sovereignty. The first clash occurred in 1996 after a nearly two-months stand-off. In 1999, a political crisis occurred when both sides accused each other for supporting its enemies. In 2008, the countries clashed again when Djibouti refused to return Eritrean deserters and Eritrea responded by firing at the Djiboutian forces. In the following battles, some 44 Djiboutian troops and some estimated 100 Eritreans were killed.

In 2011, Djibouti troops also joined the African Union Mission to Somalia.

As of 2013, the Djibouti Armed Forces (DJAF) are composed of three branches: the Djibouti National Army, which consists of the Coastal Navy, the Djiboutian Air Force (Force Aerienne Djiboutienne, FAD), and the National Gendarmerie (GN). The Army is by far the largest, followed by the Air Force and Navy. The Commander-in-Chief of the DJAF is the President of Djibouti and the Minister of Defence oversees the DJAF on a day-to-day basis.

The Djiboutian Army is the largest branch of the Djibouti Armed Forces. Djibouti maintains a modest military force of approximately 20,470 troops; the army is made of 18,600 troops (IISS 2018). The latter are divided into several regiments and battalions garrisoned in various areas throughout the country. The Army has four military districts (the Tadjourah, Dikhil, Ali-Sabieh and Obock districts). Clashes with the Military of Eritrea, in 2008, demonstrated the superior nature of the Djiboutian forces’ training and skills, but also highlighted the fact that the small military would be unable to counter the larger, if less well-equipped forces of its neighbours. The army has concentrated on mobility in its equipment purchases, suitable for patrol duties and counterattacks but ill-suited for armoured warfare. The 2008 border clashes at least temporarily swelled the ranks of the Djiboutian army, with retired personnel being recalled, but the military’s size and capabilities are much reduced since the 1990s. The army to address more effectively its major defense disadvantage: lack of strategic depth. Thus in the early 2000s it looked outward for a model of army organization that would best advance defensive capabilities by restructuring forces into smaller, more mobile units instead of traditional divisions. The official tasks of the armed forces include strengthening the country against external attack, and maintaining border security. Djiboutian troops continue to monitor its borders with Eritrea, in the case of an attack. The Djiboutian Army is one of the small professional advanced armies in East Africa.
Its maneuver units are:

Italy delivered 10 howitzers M-109L (in 2013), tens IVECO trucks (ACM90, cranes, tankers, etc.), some IVECO armoured car Puma 4X4 and IVECO utility vehicles VM90.

In reforming the Djiboutian Army, most of the available financial resources have been directed to the development of the Land Forces. Over the years, Djiboutian Army has established partnerships with militaries in France, Egypt, Saudi Arabia, Morocco and the United States. Currently, the amount allocated to defense represents the largest single entry in the country’s budget.

As of 2018, Djibouti Armed Forces were reported to have 18,000–20,000 active personnel, 10,500–11,000 reserve personnel.

The Djiboutian Navy is the naval service branch of the Djibouti Armed Forces. The Djiboutian Navy has about 1,000 regular personnel as of 2013, to protect national maritime rights and to support the nation's foreign policies. It is responsible for securing Djibouti's territorial waters and 314 km seaboard. The force was launched two years after Djibouti gained its independence in 1977. Initially, it comprised the remnants of the Gendarmerie and was focused on port safety and traffic monitoring. This is an area known to have considerable fish stocks, sustaining an active fisheries industry. The acquisition of several boats from the US in 2006 considerably increased the navy's ability to patrol over longer distances and to remain at sea for several days at a time. Cooperation with the US and Yemeni navies is also increasing in an effort to protect and maintain the safety and security of the Sea Lanes of Communication (SLOC). In 2004
Italy delivered 2 former Italian Coast Guard "" patrol boats (ex CP 230 and CP 234 ) and 2 new type "CP 500" motorboats.

The Djiboutian Air Force (DAF) (French: Force Aérienne du Djibouti (FADD) was established as part of the Djibouti Armed Forces after the country obtained its independence on June 27, 1977. Its first aircraft included three Nord N.2501 Noratlas transport aircraft and an Allouette II helicopter presented to it by the French. In 1982, the Djibouti Air Force was augmented by two Aerospatiale AS.355F Ecureuil 2 helicopters and a Cessna U206G Stationair, this was followed in 1985 by a Cessna 402C Utiliner. In 1985, the Allouette II was withdrawn from use and put on display at Ambouli Air Base at Djibouti's airport. In 1987, the three N.2501 Noratlas were also retired and subsequently returned to France. New equipment came, in 1991, in the form of a Cessna 208 Caravan, followed by Russian types in the early nineties. These included four Mil Mi 2, six Mil Mi 8 and two Mil Mi 17 helicopters and a single Antonov An 28 light transport aircraft. Pilot training for the 360 men of the DAF, if necessary, is conducted in France with continued on type flight training at home. The DAF has no units of its own and forms in whole a part of the Army, its sole base is Ambouli.

The main doctrine consists of the following principles:


The size and structure of the Djibouti Armed Forces is continually evolving.
Djibouti has committed to strengthening international action through the African Union to achieve collective security and uphold the goals enshrined in the Purposes and Principles of the UN Charter and the Constitutive Act of the African Union. Deployed in 2 countries in Somalia and Sudan. Djibouti’s first contribution to UN peacekeeping was in 2010 in the Darfur, Sudan.

The Chinese naval support base in Djibouti began construction in 2016 and was officially opened in 2017.

France's 5e RIAOM are currently stationed in Djibouti.

The Italian "Base Militare Nazionale di Supporto" (National Support Military Base) is capable to host 300 troops and some UAVs.

The Japan Self-Defense Force Base Djibouti was established in 2011. The "Deployment Airforce for Counter-Piracy Enforcement" (DAPE): Established in 2011 with approximately 600 deployed personnel from the Japan Maritime Self-Defense Force, on a rotational basis, operating naval vessels and maritime patrol aircraft. Japan reportedly pays $30 million per year for the military facilities, from which it conducts anti-piracy operations in the region. The base also acts as a hub for operations throughout the East African coastline.

There is also Combined Joint Task Force - Horn of Africa, a U.S. force of more than 3,500, currently deployed in the country at Camp Lemonnier.


</doc>
<doc id="8051" url="https://en.wikipedia.org/wiki?curid=8051" title="History of Dominica">
History of Dominica

The History of Dominica concerns the history of this Caribbean island.

The Arawaks were guided to Dominica, and other islands of the Caribbean, by the South Equatorial Current from the waters of the Orinoco River. These descendants of the early Taínos were overthrown by the Kalinago tribe of the Caribs. The Caribs, who settled here in the 14th century, called the island "Wai‘tu kubuli", which means "Tall is her body."

 Christopher Columbus named the island after the day of the week on which he spotted it - a Sunday ('Doménica' in Italian) - which fell on 3 November 1493 on his second voyage.

Daunted by fierce resistance from the Caribs and discouraged by the absence of gold, the Spanish did not settle the island. Many of the remaining Carib people live in Dominica's Carib Territory, a district on Dominica's east coast.

In 1632, the French Compagnie des Îles de l'Amérique claimed Dominica along with all the other 'Petite Antilles' but no settlement was attempted. Between 1642 and 1650 a French missionary Raymond Breton became the first regular European visitor to the island. In 1660 the French and English agreed that both Dominica and St. Vincent should not be settled, but instead left to the Caribs as neutral territory. Dominica was officially neutral for the next century, but the attraction of its resources remained; rival expeditions of English and French foresters were harvesting timber by the start of the 18th century.

Spain had little to no success in colonizing Dominica and in 1690, the French established their first permanent settlements in Dominica. French woodcutters from Martinique and Guadeloupe begin to set up timber camps to supply the French islands with wood and gradually become permanent settlers. They brought the first enslaved people from West Africa to Dominica. In 1715, a revolt of "poor white" smallholders in the north of Martinique, known as La Gaoulé, caused an exodus of them to southern Dominica. They set up smallholdings. Meanwhile, French families and others from Guadeloupe settled in the north. In 1727, the first French commander, M. Le Grand, took charge of the island with a basic French government; Dominica formally became a colony of France, and the island was divided into districts or "quarters". Already installed in Martinique and Guadeloupe and cultivating sugar cane, the French gradually developed plantations in Dominica for coffee. They imported African slaves to fill the labor demands replacing the less cooperative indigenous Caribs.

In 1761, during the Seven Years' War a British expedition against Dominica led by Lord Rollo was successful and the island was conquered along with several other Caribbean islands. After France was defeated by Britain in the Seven Years' War, it ceded the island to the British under the Treaty of Paris (1763). In 1778, during the American Revolutionary War, the French mounted a successful invasion with the active cooperation of the population. The 1783 Treaty of Paris, which ended the war, returned the island to Britain. French invasions in 1795 and 1805 ended in failure.

As part of the 1763 Treaty of Paris that ended the Seven Years' War, the island became a British possession. In 1778, during the American War of Independence, the French mounted a successful invasion with the active cooperation of the population, which was largely French. The 1783 Treaty of Paris, which ended the war, returned the island to Britain. French invasions in 1795 and 1805 ended in failure. The 1805 invasion burned much of Roseau to the ground.

In 1763, the British established a legislative assembly, representing only the white population. In 1831, reflecting a liberalization of official British racial attitudes, the Brown Privilege Bill conferred political and social rights on free nonwhites. Three Blacks were elected to the legislative assembly the following year. The abolition of slavery in 1834 enabled Dominica by 1838 to become the only British Caribbean colony to have a Black-controlled legislature in the 19th century. Most Black legislators were small holders or merchants who held economic and social views diametrically opposed to the interests of the small, wealthy English planter class. Reacting to a perceived threat, the planters lobbied for more direct British rule.

In 1865, after much agitation and tension, the colonial office replaced the elective assembly with one composed of one-half elected members and one-half appointed. The elected legislators were outmaneuvered on numerous occasions by planters allied with colonial administrators. In 1871, Dominica became part of the Leeward Island Federation. The power of the Black population progressively eroded. Crown Colony government was re-established in 1896.

Following World War I, an upsurge of political consciousness throughout the Caribbean led to the formation of the representative government association. Marshaling public frustration with the lack of a voice in the governing of Dominica, this group won one-third of the popularly elected seats of the legislative assembly in 1924 and one-half in 1936. Shortly thereafter, Dominica was transferred from the Leeward Island Administration and was governed as part of the Windwards until 1958, when it joined the short-lived West Indies Federation.

In 1961, a Dominica Labor Party government led by Edward Oliver LeBlanc was elected. After the federation dissolved, Dominica became an associated state of the United Kingdom on February 27, 1967 and formally took responsibility for its internal affairs. LeBlanc retired in 1974 and was replaced by Patrick John who became the islands' first Prime Minister.

In August 1979, Hurricane David, packing winds of , struck the island with devastating force. Forty-two people were killed and 75% of the islanders' homes were destroyed or severely damaged. Hurricane David was the most powerful and devastating hurricane ever recorded in Dominica until Hurricane Maria struck in 2017.

On November 3, 1978, the Commonwealth of Dominica was granted independence by the United Kingdom.

Independence did little to solve problems stemming from centuries of economic underdevelopment, and in mid-1979, political discontent led to the formation of an interim government, led by Oliver Seraphin. It was replaced after the 1980 elections by a government led by the Dominica Freedom Party under Prime Minister Eugenia Charles, the Caribbean's first female prime minister. Within a year of her inauguration she survived two unsuccessful coups and in October 1983, as chairperson of the Organisation of East Caribbean States, endorsed the US Invasion of Grenada.

Chronic economic problems were compounded by the severe impact of hurricanes in 1979 and in 1980. By the end of the 1980s, the economy had made a healthy recovery, which weakened in the 1990s due to a decrease in banana prices.

In 1995 the government was defeated in elections by the United Workers Party of Edison James. James became prime minister, serving until the February 2000 elections, when the Dominica United Workers Party (DUWP) was defeated by the Dominica Labour Party (DLP), led by Rosie Douglas. He was a former socialist activist, and many feared that his approach to politics might be impractical. However, these were somewhat quieted when he formed a coalition with the more conservative Dominica Freedom Party. Douglas died suddenly after only eight months in office, on October 1, 2000, and was replaced by Pierre Charles, also of the DLP. In 2003, Nicholas Liverpool was elected and sworn in as president, succeeding Vernon Shaw. On January 6, 2004, Prime Minister Pierre Charles, who had been suffering from heart problems since 2003, died. He became the second consecutive prime minister of Dominica to die in office of a heart attack. The foreign minister, Osborne Riviere immediately became prime minister, but the education minister, Roosevelt Skerrit succeeded him as prime minister and became the new leader of the Dominica Labour Party. Elections were held on May 5, 2005, with the ruling coalition maintaining power.





</doc>
<doc id="8052" url="https://en.wikipedia.org/wiki?curid=8052" title="Geography of Dominica">
Geography of Dominica

Dominica is an island in the Caribbean Sea, located about halfway between the French islands of Guadeloupe (to the north) and Martinique (to the south). Its coordinates are 15 25 N, 61 20 W. It is known as "The Nature Island of the Caribbean" due to its spectacular, lush, and varied flora and fauna, which is protected by an extensive natural park system. It is the fourth largest island in the Eastern Caribbean with a population of people mainly of African descent.

The lowest point in the country is at sea level along the coast, and the highest is Morne Diablotins (). The extreme southwestern coast of the island includes a large collapsed submarine caldera. Portions of the exposed rim of this caldera form the southwestern tip of the island at Scott's Head. Natural resources include farming, hydropower and timber.

Geographically, Dominica is distinctive in many ways. The country has one of the most rugged landscapes in the Caribbean, covered by a largely unexploited, multi-layered rain forest. It is also among the Earth's most rain-drenched lands, and the water runoff forms cascading rivers and natural pools. The island, home to rare species of wildlife, is considered by many as a beautiful, unspoiled tropical preserve. According to a popular West Indian belief, Dominica is the only New World territory that Columbus would still recognize.

Dominica is the largest and most northerly of the Windward Islands. The island faces the Atlantic Ocean to the east and the Caribbean Sea to the west. Its nearest neighbors are the French islands of Guadeloupe, some north, and Martinique, about south. Oblong-shaped and slightly smaller than New York City, Dominica is in area, in length, and in width. Roseau, the nation's capital and major port, is favorably situated on the sheltered, southwestern coast.

The island's climate is tropical, moderated by northeast trade winds and heavy rainfall.

Dominica has a tropical rainforest climate and some areas bordering on a tropical monsoon climate with characteristically warm temperatures and heavy rainfall. Excessive heat and humidity are tempered somewhat by a steady flow of the northeast trade winds, which periodically develop into hurricanes during the Northern Hemisphere's summer. The steep interior slopes also alter temperatures and winds. Because of the moderating effects of the surrounding ocean temperature ranges are slight. Average daytime temperatures generally vary from in January to in June. Diurnal ranges are usually no greater than in most places, but temperatures dipping to on the highest peaks are not uncommon.

Most of the island's ample supply of water is brought by the trade winds. Although amounts vary with the location, rain is possible throughout the year, with the greatest monthly totals recorded from June through October. Average yearly rainfall along the windward east coast frequently exceeds , and exposed mountainsides receive up to , among the highest accumulations in the Caribbean and the world. Totals on the leeward west coast, however, are only about per year. Humidities are closely tied to rainfall patterns, with the highest values occurring on windward slopes and the lowest in sheltered areas. Relative humidity readings between 70 percent and 90 percent have been recorded in Roseau.

Hurricanes and severe winds, most likely to occur during the wettest months, occasionally are devastating. The most recent hurricanes of note were David, Maria, and Frederic in August 1979 and Allen in August 1980. The 1979 hurricanes caused over 40 deaths, 2,500 injuries, and extensive destruction of housing and crops. Many agricultural commodities were destroyed during the 1980 storm, and about 25 percent of the banana crop was destroyed by strong winds in 1984.

Dominica is especially vulnerable to hurricanes as the island is located in what is referred to as the hurricane region. In 1979, Dominica was hit directly by Category 5 Hurricane David, causing widespread and extreme damage. On August 17, 2007, Hurricane Dean, a Category 1 at the time, hit the island. A mother and her seven-year-old son died when a landslide caused by the heavy rains fell onto their house. In another incident two people were injured when a tree fell on their house. Prime Minister Roosevelt Skerrit estimated that 100 to 125 homes were damaged, and that the agriculture sector was extensively damaged, in particular the banana crop.

Below is the climate data for Roseau, the capital city located on the western side of Dominica partially shielded from the trade winds by the mountains.

Bays are as follows from the northern tip of the island in a clockwise direction:

Agoucha Bay,
Sandwich Bay,
Grand Baptiste Bay,
Petit Bapitiste Bay, 
La Taille Bay, Rough Bay,
Marigot Bay,
Walker's Rest Bay,
Sophia Bay,
Londonderry Bay, 
Mango Hole Bay,
Middle Bay,
Panto Hole Bay,
Petite Soufriere Bay, 
Soufriere Bay, 
Woodbridge Bay,
Prince Rupert Bay,
Douglas Bay.

Dominica was the last island to be formed in the Caribbean. The island was created by volcanic action about 26 million years ago. It lies upon two opposing tectonic plates. This explains why an island a bit bigger than Martha's Vineyard has mountains approaching .

Geologically, Dominica is part of the rugged Lesser Antilles volcanic arc. The country's central spine, a northwest-southeast axis of steep volcanic slopes and deep gorges, generally varies in elevation from above sea level. Several east-west trending mountain spurs extend to the narrow coastal plain, which is studded with sea cliffs and has level stretches no wider than . The highest peak is Morne Diablotins, at ; Morne Trois Pitons, with an elevation of , lies farther south and is the site of the national park.

The interior features rugged mountains of volcanic origin. Volcanism is still quite evident on the island, the most popular examples being Dominica's Boiling Lake and "valley of desolation." The boiling lake (the world's second largest) is within a crater and is fed by a waterfall - the boiling is believed to be caused by the heat of a magma chamber beneath the lake. The valley of desolation is a sulfurous valley of volcanic vents and hot springs that inhibits significant plant growth - in stark contrast to the surrounding rain forest. Technically dormant today, this caldera last erupted in 1880. The area that exploded on 4 January 1880 was reported to be "fully nine square miles".
Dominica's rugged surface is marked by its volcanic past. Rock formations are mainly volcanic andesite and rhyolite, with fallen boulders and sharp-edged protrusions peppering slope bases. The light- to dark-hued clay and sandy soils, derived from the rocks and decomposed vegetation, are generally fertile and porous. Only a few interior valleys and coastal strips are flat enough for soil accumulations of consequence, however. Although scores of mostly mild seismic shocks were recorded in 1986, volcanic eruptions ceased thousands of years ago. Sulfuric springs and steam vents, largely concentrated in the central and southern parts of the island, remain active, however. One of the largest springs, Boiling Lake, is located in the national park.

Dominica is water-rich with swift-flowing highland streams, which cascade into deep gorges and form natural pools and crater lakes. The streams are not navigable, but many are sources of hydroelectric power. Trafalgar Falls, located near the national park, is one of the most spectacular sites on the island. The falls consists of twin waterfalls known as the mother and father or the Mama and the Papa. At the base of each waterfall are natural pools. Locals and tourists alike come here to enjoy the water. At the base of the Papa fall a natural hot spring can also be found which heats a portion of its pool. The principal rivers flowing westward are the Layou and the Roseau, and the major one emptying eastward is the Toulaman. The largest crater lake, called Boeri, is located in the national park. There are 83 "significant" waterways on the island out of a total of 365 with also includes rills and brooks.

There are 172 species of birds, including four species of hummingbird, broad-winged hawks, yellow-crowned night herons, and the brown trembler. Some plants and animals thought to be extinct on surrounding islands can still be found in Dominica's forests.

The sisserou parrot is Dominica's national bird and is indigenous to its mountain forests.

The Caribbean Sea offshore of the island of Dominica is home to many cetaceans. Most notably a small group of sperm whales live in this area year round. These are shy animals, but there is a good chance of seeing them if you go out on a calm day. Other cetaceans commonly seen in the area include pilot whale, Fraser's dolphin, pantropical spotted dolphin and bottlenose dolphin. Less commonly seen animals include Cuvier's beaked whale, false killer whale, pygmy sperm whale, dwarf sperm whale, Risso's dolphin, common dolphin, humpback whale and Bryde's whale. This makes Dominica a destination for tourists interested in whale-watching.

Map references:
Central America and the Caribbean

Area:
"total:"
751 km
"land:"
751 km

Coastline:
148 km

Maritime claims:
"territorial sea:"

"contiguous zone:"

"exclusive economic zone:"
Land use:
"arable land:"
8%
"permanent crops:"
24%
"other:"
68% (2012 est.)

Irrigated land:
NA km

Freshwater withdrawal (domestic/industrial/agricultural):
"total:" 0.02 km/yr
"per capita:" 244.1 m/yr (2004)

Natural hazards:
Flash floods are a constant threat; destructive hurricanes can be expected during the late summer months

Environment - international agreements:

"Party to:"
Biodiversity, Climate Change, Desertification, Endangered Species, Environmental Modification, Hazardous Wastes, Law of the Sea, Ozone Layer Protection, Ship Pollution, Whaling




</doc>
<doc id="8053" url="https://en.wikipedia.org/wiki?curid=8053" title="Demographics of Dominica">
Demographics of Dominica

This article is about the demographic features of the population of Dominica, including population density, ethnicity, religious affiliations and other aspects of the population.

According to the preliminary 2011 census results Dominica has a population of 71,293. The population growth rate is very low, due primarily to emigration to more prosperous Caribbean Islands, the United Kingdom, the United States, and Canada. The estimated mid-year population of is ().

Structure of the population (31.12.2006) (Estimates) :

The vast majority of Dominicans are of African descent (75% at the 2014 census). There is a significant mixed population (19%) at the 2014 census due to intermarriage, along with a small European origin minority (0.8%; descendants of French, British, and Irish colonists), East Indians (0.1%) groups, and there are small numbers of Lebanese/Syrians (0.1%) and Asians.

Dominica is the only Eastern Caribbean island that still has a population of pre-Columbian native Caribs (also known as Kalinago), who were exterminated, driven from neighbouring islands, or mixed with Africans and/or Europeans. According to the 2001 census there are only 2,001 Caribs remaining (2.9% of the total population). A considerable growth occurred since the 1991 census when 1,634 Caribs were counted (2.4% of the total population). 
The Caribs live in eight villages on the east coast of Dominica. This special Carib Territory was granted by the British Crown in 1903.
The present number of Kalinago is estimated at 4% more than 3,000.

English is the official language and universally understood; however, because of historic French domination, Antillean Creole, a French-lexified creole language, is also widely spoken.

According to the 2001 census, 91.2% percent of the population of Dominica is considered Christian, 1.6% has a non-Christian religion and 6.1% has no religion or did not state a religion (1.1%).

Roughly two thirds of Christians are Roman Catholics (61.4% of the total population), a reflection of early French influence on the island, and one third are Protestant. The Evangelicals constitute the largest Protestant group, with 6.7% of the population. Seventh-day Adventists are the second largest group (6.1%). The next largest group are Pentecostals (5.6% of the population), followed by Baptists (4.1%). Other Christians include Methodists (3.7%), Church of God (1.2%), Jehovah's Witnesses (1.2%), Anglicanism (0.6%) and Brethren Christian (0.3%).
During the past decades the number of Roman Catholics and Anglicans has decreased, while the number of other Protestants has increased, especially Evangelicals, Seventh-day Adventists, Pentecostals (5.6% of the population) and Baptists).

The number of non-Christians is small. These religious groups include the Rastafarian Movement (1.3% of the population), Hinduism (0.1%) and Muslims (0.2%).

The following demographic statistics are from The World Factbook, unless otherwise indicated





</doc>
<doc id="8054" url="https://en.wikipedia.org/wiki?curid=8054" title="Politics of Dominica">
Politics of Dominica

The politics of Dominica takes place in a framework of a parliamentary representative democratic republic, whereby the Prime Minister of Dominica is the head of government, and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and the House of Assembly. The Judiciary is independent of the executive and the legislature.

A president and prime minister make up the executive branch. Nominated by the prime minister in consultation with the leader of the opposition party, the president is elected for a 5-year term by the parliament. The president appoints as prime minister the person who command the majority of elected representatives in the parliament and also appoints, on the prime minister's recommendation, members of the parliament as cabinet ministers. The prime minister and cabinet are responsible to the parliament and can be removed on a no-confidence vote.

The House of Assembly has 32 members. Twenty-one members are elected for a five-year term in single-seat constituencies. Nine members are senators appointed by the President; 5 on the advice of the Prime Minister and 4 on the advice of the leader of the opposition. The Speaker is elected by the elected members after an election. There is also 1 ex-official member, the clerk of the house. The head of state - the president -is elected by the House of Assembly. The regional representatives decide whether senators are to be elected or appointed. If appointed, five are chosen by the president with the advice of the prime minister and four with the advice of the opposition leader. If elected, it is by vote of the regional representatives. Elections for representatives and senators must be held at least every 5 years, although the prime minister can call elections any time.

Dominica has a two-party system, which means that there are two dominant political parties, with extreme difficulty for anybody to achieve electoral success under the banner of any other party. Dominica was once a three-party system, but in the past few years the Dominica Labour Party and the greatly diminished Dominica Freedom Party have built a coalition.

Dominica's legal system is based on English common law. There are three magistrate's courts and a High Court of Justice. Appeals can be made to the Eastern Caribbean Court of Appeal and, ultimately, to the Caribbean Court of Justice.

The Court of Appeal of the Eastern Caribbean Supreme Court is headquartered in Saint Lucia, but at least one of its 16 High Court judges must reside in Dominica and preside over the High Court of Justice. Dominica's current High Court judges are The Hon. Brian Cottle and The Hon. M. E. Birnie Stephenson-Brooks.

Councils elected by universal suffrage govern most towns. Supported largely by property taxation, the councils are responsible for the regulation of markets and sanitation and the maintenance of secondary roads and other municipal amenities. The island also is divided into 10 parishes, whose governance is unrelated to the town governments: Saint Andrew, Saint David, Saint George, Saint John, Saint Joseph, Saint Luke, Saint Mark, Saint Patrick, Saint Paul, and Saint Peter.

ACP, ALBA, Caricom, CDB, CELAC, Commonwealth of Nations, ECLAC, FAO, G-77, IBRD, ICC, ICRM, IDA, IFAD, IFC, IFRCS, ILO, IMF, IMO, Interpol, IOC, ITU, ITUC, NAM (observer), OAS, OIF, OECS, OPANAL, OPCW, UN, UNCTAD, UNESCO, UNIDO, UPU, WHO, WIPO, WMO, WTrO



</doc>
<doc id="8056" url="https://en.wikipedia.org/wiki?curid=8056" title="Telecommunications in Dominica">
Telecommunications in Dominica

Telecommunications in Dominica comprises of telephone, radio, television and internet services. The primary regulatory authority is the National Telecommunication Regulatory Commission which regulates all related industries in order to comply with The Telecommunications Act 8 of 2000. 

Calls from Dominica to the US, Canada, and other NANP Caribbean nations, are dialed as 1 + NANP area code + 7-digit number. Calls from Dominica to non-NANP countries are dialed as 011 + country code + phone number with local area code.




AM 0, FM 15, shortwave 0 (2007)

46,000 (1997)

0 (however, there are three cable television companies, Dominica Broadcast, Marpin Telecoms and Digicel Play - a merger of Digicel and SAT Telecommunications Ltd.)

11,000 (2007)




</doc>
<doc id="8058" url="https://en.wikipedia.org/wiki?curid=8058" title="Military of Dominica">
Military of Dominica

There is no standing army in Dominica since 1981. Defense is the responsibility of Regional Security System (RSS).

The civil Commonwealth of Dominica Police Force includes a Special Service Unit, Coast Guard. In the event of war or other emergency, if proclaimed by the authorities, the Police Force shall be a military force which may be employed for State defence ("Police Act", Chapter 14:01).


</doc>
<doc id="8059" url="https://en.wikipedia.org/wiki?curid=8059" title="Foreign relations of Dominica">
Foreign relations of Dominica

Like its Eastern Caribbean neighbors, the main priority of Dominica's foreign relations is economic development. The country maintains missions in Washington, New York, London, and Brussels and is represented jointly with other Organisation of Eastern Caribbean States (OECS) members in Canada. Dominica is also a member of the Caribbean Development Bank (CDB), and the Commonwealth of Nations. It became a member of the United Nations and the International Monetary Fund (IMF) in 1978 and of the World Bank and Organization of American States (OAS) in 1979.

As a member of CARICOM, in July 1994 Dominica strongly backed efforts by the United States to implement United Nations Security Council Resolution 940, designed to facilitate the departure of Haiti's de facto authorities from power. The country agreed to contribute personnel to the multinational force, which restored the democratically elected government of Haiti in October 1994.

In May 1997, Prime Minister James joined 14 other Caribbean leaders, and President Clinton, during the first-ever U.S.-regional summit in Bridgetown, Barbados. The summit strengthened the basis for regional cooperation on justice and counternarcotics issues, finance and development, and trade. Dominica previously maintained official relations with the Republic of China (commonly known as "Taiwan") instead of the People's Republic of China, but on 23 March 2004, a joint communique was signed in Beijing, paving the way for diplomatic recognition of the People's Republic. Beijing responded to Dominica's severing relations with the Republic of China by giving them a $12 million aid package, which includes $6 million in budget support for the year 2004 and $1 million annually for six years.

Dominica is also a member of the International Criminal Court with a Bilateral Immunity Agreement of protection for the US-military (as covered under Article 98).

Dominica claims Venezuelan controlled Isla Aves (Known in Dominica as Bird Rock) located roughly 90 km. west of Dominica.

The Commonwealth of Dominica has been a member of the Commonwealth of Nations since 1978, when it became an independent Commonwealth republic from the United Kingdom.

Dominica's highest court of appeal is the Caribbean Court of Justice, in effect from 6 March 2015. Previously, the nation's ultimate court of appeal was London's Judicial Committee of the Privy Council.

The Commonwealth of Dominica has been a member of Organisation internationale de la Francophonie since 1979.

As a French and then British colony; Antillean Creole, a French-based creole language, is spoken by 90% of the population. The Commonwealth of Dominica is nestled between two insular overseas outer regions of France, Guadeloupe (situated to the north), and Martinique (situated to the south). A number of links exist between Dominica and its French neighbors to north and south.




</doc>
<doc id="8060" url="https://en.wikipedia.org/wiki?curid=8060" title="Dominican Republic">
Dominican Republic

The Dominican Republic ( ; , ) is a country located in the island of Hispaniola, in the Greater Antilles archipelago of the Caribbean region. It occupies the eastern five-eighths of the island, which it shares with the nation of Haiti, making Hispaniola one of two Caribbean islands, along with Saint Martin, that are shared by two sovereign states. The Dominican Republic is the second-largest Caribbean nation by area (after Cuba) at , and third by population with approximately 10 million people, of whom approximately three million live in the metropolitan area of Santo Domingo, the capital city.

Christopher Columbus landed on the island on December 5, 1492, which the native Taíno people had inhabited since the 7th century. The colony of Santo Domingo became the site of the first permanent European settlement in the Americas, the oldest continuously inhabited city, and the first seat of the Spanish colonial rule in the New World. After more than three hundred years of Spanish rule the Dominican people declared independence in November 1821. The leader of the independence movement José Núñez de Cáceres, intended the Dominican nation to unite with the country of Gran Colombia, but no longer under Spain's custody the newly independent Dominicans were forcefully annexed by Haiti in February 1822. Independence came 22 years later after victory in the Dominican War of Independence in 1844. Over the next 72 years the Dominican Republic experienced mostly internal conflicts and a brief return to colonial status before permanently ousting Spanish rule during the Dominican War of Restoration of 1863–1865. A United States occupation lasted eight years between 1916 and 1924, and a subsequent calm and prosperous six-year period under Horacio Vásquez was followed by the dictatorship of Rafael Leónidas Trujillo until 1961. A civil war in 1965, the country's last, was ended by U.S. military occupation and was followed by the authoritarian rule of Joaquín Balaguer (1966–1978 and 1986–1996), the rules of Antonio Guzmán (1972–1978) and Salvador Jorge Blanco (1982–1986). Since 1996, the Dominican Republic has moved toward representative democracy and has been led by Leonel Fernández for most of the time since 1996. Danilo Medina, the Dominican Republic's current president, succeeded Fernandez in 2012, winning 51% of the electoral vote over his opponent ex-president Hipólito Mejía.

The Dominican Republic has the ninth-largest economy in Latin America and is the largest economy in the Caribbean and Central American region. Over the two decades to 2012, the Dominican Republic has had one of the fastest-growing economies in the Americas – with an average real GDP growth rate of 5.4% between 1992 and 2014. GDP growth in 2014 and 2015 reached 7.3 and 7.0%, respectively, the highest in the Western Hemisphere. In the first half of 2016 the Dominican economy grew 7.4% continuing its trend of rapid economic growth. Recent growth has been driven by construction, manufacturing, tourism, and mining. The country is the site of the second largest gold mine in the world, the Pueblo Viejo mine. Private consumption has been strong, as a result of low inflation (under 1% on average in 2015), job creation, and a high level of remittances.

The Dominican Republic is the most visited destination in the Caribbean. The year-round golf courses are major attractions. A geographically diverse nation, the Dominican Republic is home to both the Caribbean's tallest mountain peak, Pico Duarte, and the Caribbean's largest lake and point of lowest elevation, Lake Enriquillo. The island has an average temperature of and great climatic and biological diversity. The country is also the site of the first cathedral, castle, monastery, and fortress built in the Americas, located in Santo Domingo's Colonial Zone, a World Heritage Site. Music and sport are of great importance in the Dominican culture, with Merengue and Bachata as the national dance and music, and baseball as the favorite sport.

The "Dominican" word comes from the Latin "Dominicus", meaning Sunday. However, the island has this name by Santo Domingo de Guzmán, founder of the Order of the Dominicans.

The Dominicans established a house of high studies in the island of Santo Domingo that today is known as the Universidad Autónoma de Santo Domingo and dedicated themselves to the protection of the native taínos of the island, who were subjected to slavery, and to the education of the inhabitants of the island.

For most of its history, up until independence, the country was known as —the name of its present capital and patron saint, Saint Dominic—and continued to be commonly known as such in English until the early 20th century. The residents were called "Dominicans" (), which is the adjective form of "Domingo", and the revolutionaries named their newly independent country "Dominican Republic" ().

In the national anthem of the Dominican Republic (), the term "Dominicans" does not appear. The author of its lyrics, Emilio Prud'Homme, consistently uses the poetic term "Quisqueyans" (). The word "Quisqueya" derives from a native tongue of the Taino Indians and means "Mother of the lands" (). It is often used in songs as another name for the country. The name of the country is often shortened to "the D.R." ()

The Arawakan-speaking Taíno moved into Hispaniola from the north east region of what is now known as South America, displacing earlier inhabitants, c. AD 650. They engaged in farming and fishing and hunting and gathering. The fierce Caribs drove the Taíno to the northeastern Caribbean during much of the 15th century. The estimates of Hispaniola's population in 1492 vary widely, including one hundred thousand, three hundred thousand, and four hundred thousand to two million. Determining precisely how many people lived on the island in pre-Columbian times is next to impossible, as no accurate records exist. By 1492 the island was divided into five Taíno chiefdoms. The Taíno name for the entire island was either "Ayiti" or "Quisqueya".

The Spaniards arrived in 1492. After initially friendly relationships, the Taínos resisted the conquest, led by the female Chief Anacaona of Xaragua and her ex-husband Chief Caonabo of Maguana, as well as Chiefs Guacanagaríx, Guamá, Hatuey, and Enriquillo. The latter's successes gained his people an autonomous enclave for a time on the island. Within a few years after 1492, the population of Taínos had declined drastically, due to smallpox, measles, and other diseases that arrived with the Europeans, and from other causes discussed below.

The first recorded smallpox outbreak in the Americas occurred on Hispaniola in 1507. The last record of pure Taínos in the country was from 1864. Still, Taíno biological heritage survived to an important extent, due to intermixing. Census records from 1514 reveal that 40% of Spanish men in Santo Domingo were married to Taino women, and some present-day Dominicans have Taíno ancestry. Remnants of the Taino culture include their cave paintings, as well as pottery designs which are still used in the small artisan village of Higüerito, Moca.

Christopher Columbus arrived on the island on December 5, 1492, during the first of his four voyages to the Americas. He claimed the land for Spain and named it "La Española" due to its diverse climate and terrain which reminded him of the Spanish landscape. Traveling further east Columbus came across the Yaque del Norte River in the Cibao region, which he named Rio de Oro after discovering gold deposits nearby. On Columbus's return during his second voyage he established the settlement of La Isabela in what is now Puerto Plata on Jan. 1494, while he sent Alonso de Ojeda to search for gold in the region.

In 1496 Bartholomew Columbus, Christopher's brother, built the city of Santo Domingo, Western Europe's first permanent settlement in the "New World." The colony thus became the springboard for the further Spanish conquest of the Americas and for decades the headquarters of Spanish colonial power in the hemisphere. Soon after the largest discovery of gold in the island was made in the cordillera central region, which led to a mining boom. By 1501, Columbus's cousin Giovanni Columbus, had also discovered gold near Buenaventura, the deposits were later known as Minas Nuevas. Two major mining areas resulted, one along San Cristóbal-Buenaventura, and another in Cibao within the La Vega-Cotuy-Bonao triangle, while Santiago de los Caballeros, Concepcion, and Bonao became mining towns. The gold rush of 1500–1508 ensued. Ferdinand II of Aragon "ordered gold from the richest mines reserved for the Crown." Thus, Ovando expropriated the gold mines of Miguel Diaz and Francisco de Garay in 1504, as pit mines became royal mines, though placers were open to private prospectors. Furthermore, Ferdinand wanted the "best Indians" working his royal mines, and kept 967 in the San Cristóbal mining area supervised by salaried miners.

Under Nicolás de Ovando y Cáceres' governorship, the Indians were made to work in the gold mines, "where they were grossly overworked, mistreated, and underfed," according to Pons. By 1503, the Spanish Crown legalized the distribution of Indians to work the mines as part of the encomienda system. According to Pons, "Once the Indians entered the mines, hunger and disease literally wiped them out." By 1508 the Indian population of about 400,000 was reduced to 60,000, and by 1514, only 26,334 remained. About half were located in the mining towns of Concepción, Santiago, Santo Domingo, and Buenaventura. The repartimiento of 1514 accelerated emigration of the Spanish colonists, coupled with the exhaustion of the mines. In 1516, a smallpox epidemic killed an additional 8,000, of the remaining 11,000 Indians, in one month. By 1519, according to Pons, "Both the gold economy and the Indian population became extinct at the same time."

The southern city of Santo Domingo served as a springboard for military expeditions pushing across to the mainland of the Americas. In 1501, the colony began to import African slaves. After its conquest of the Aztecs and Incas, Spain neglected its Caribbean holdings. The slaves remained and became the basis for the Dominican population. Following royal orders, in 1605 Governor Antonio Osorio ignored "cabildo" protests and had the settlements at Puerto Plata, Montecristi, La Yaguana, and Bayaja burned to stop smuggling. Some rebelled and were defeated while others fled to Cuba. Only 2,000 livestock out of 110,000 survived in the new pasture. One third of the people from La Yaguana and Bayaja who were settled at Bayaguana died of hunger and disease by 1609.

The French were envious of Spain's possessions in the Americas, and thus sent colonists to settle the northwestern coast of Hispaniola. In order to domesticate the buccaneers, the French supplied them with women who had been taken from prisons, accused of prostitution and thieving. After decades of armed struggles with the French, Spain ceded the western coast of the island to France with the 1697 Treaty of Ryswick, whilst the Central Plateau remained under Spanish domain. France created a wealthy colony there, while the Spanish colony suffered an economic decline.

On April 17, 1655, the English landed on nearby Hispaniola and marched 30 miles overland to Santo Domingo, the main Spanish stronghold on the island. The sweltering heat soon felled many of the northern European invaders. The Spanish defenders, having had time to prepare an ambush for the aimlessly thrashing, mosquito-swatting newcomers, sprang on them with mounted lancers, sending them careening back toward the beach in utter confusion. Their commander, Venables, hid behind a tree where, in the words of one disgusted observer, he was “so much possessed with terror that he could hardly speak.” The elite defenders of Santo Domingo were amply rewarded with titles from the Spanish Crown.

The French attacked Santiago in 1667, and this was followed by a devastating hurricane the next year and a smallpox epidemic that killed about 1,500 in 1669. In 1687 the Spaniards captured the fort at Petit-Goave, but the French fought back and hanged their leaders. Two years later Louis XIV was at war and ordered the French to invade the Spaniards, and Tarin de Cussy sacked Santiago. In 1691 the Spaniards attacked the north and sacked Cap-François. Island tensions subsided once peace was restored and Spain's last Habsburg monarch—the deformed invalid Charles II—died on 30 November 1700, being succeeded by the sixteen-year-old French Bourbon princeling Philip of Anjou.

The House of Bourbon replaced the House of Habsburg in Spain in 1700 and introduced economic reforms that gradually began to revive trade in Santo Domingo. The crown progressively relaxed the rigid controls and restrictions on commerce between Spain and the colonies and among the colonies. The last "flotas" sailed in 1737; the monopoly port system was abolished shortly thereafter. By the middle of the century, the population was bolstered by emigration from the Canary Islands, resettling the northern part of the colony and planting tobacco in the Cibao Valley, and importation of slaves was renewed. The colony of Santo Domingo saw a population increase during the 17th century, as it rose to about 91,272 in 1750. Of this number approximately 38,272 were white landowners, 38,000 were free mixed people of color, and some 15,000 were slaves. This contrasted sharply with the population of the French colony of Saint-Domingue (present-day Haiti) – the wealthiest colony in the Caribbean and whose population of one-half a million was 90% enslaved and overall seven times as numerous as the Spanish colony of Santo Domingo.. The 'Spanish' settlers, whose blood by now was mixed with that of Tainos, Africans and Canary Guanches, proclaimed: 'It does not matter if the French are richer than us, we are still the true inheritors of this island. In our veins runs the blood of the heroic "conquistadores" who won this island of ours with sword and blood.'
When the War of Jenkins' Ear between Spain and Britain broke out in 1739, Spanish privateers, particularly from Santo Domingo, began to troll the Caribbean Sea, a development that lasted until the end of the eighteenth century. During this period, Spanish privateers from Santo Domingo sailed into enemy ports looking for ships to plunder, thus harming commerce with Britain and New York. As a result, the Spanish obtained stolen merchandise—foodstuffs, ships, enslaved persons—that were sold in Hispaniola's ports, with profits accruing to individual sea raiders. The revenue acquired in these acts of piracy was invested in the economic expansion of the colony and led to repopulation from Europe. As restrictions on colonial trade were relaxed, the colonial elites of St. Domingue offered the principal market for Santo Domingo's exports of beef, hides, mahogany, and tobacco. With the outbreak of the Haitian Revolution in 1791, the rich urban families linked to the colonial bureaucracy fled the island, while most of the rural "hateros" (cattle ranchers) remained, even though they lost their principal market. Although the population of Spanish Santo Domingo was perhaps one-fourth that of French Saint-Domingue, this did not prevent the Spanish king from launching an invasion of the French side of the island in 1793, attempting to take advantage of the chaos sparked by the French Revolution. French forces checked Spanish progress toward Port-au-Prince in the south, but the Spanish pushed rapidly through the north, most of which they occupied by 1794.

Although the Spanish military effort went well on Hispaniola, it did not so in Europe (see War of the Pyrenees). As a consequence, Spain was forced to cede Santo Domingo to the French under the terms of the Treaty of Basel (July 22, 1795) in order to get the French to withdraw from Spain.

In 1801, Toussaint Louverture, who at least in theory represented imperial France, marched into Santo Domingo from Saint-Domingue to enforce the terms of the treaty. Toussaint's army committed numerous atrocities; as a consequence, the Spanish population fled from Santo Domingo in exodus proportions. French control of the former Spanish colony passed from Toussaint Louverture to Gen. Charles Leclerc when he seized the city of Santo Domingo in early 1802. Following the defeat of the French under Gen. Donatien de Rochembeau at Le Cap in November 1803 by the Haitians, their new leader, Dessalines, attempted to drive the French out of Santo Domingo. He invaded the Spanish side of the island, defeated the French-led Spanish colonials at River Yaque del Sur, and besieged the capital on March 5, 1805. At the same time, the Haitian General Christophe marched north through Cibao, capturing Santiago where he massacred prominent individuals who had sought refuge in a church. The arrival of small French squadrons off the Haitian coast at Goncaives and at Santo Domingo forced the Haitians to withdraw. As Christophe retreated across the island, he slaughtered and burned. In October 1808 the landowner Juan Sánchez Ramírez began a rebellion against the French colonial government in Santo Domingo and the insurgents were aided by Puerto Rico and British Jamaica. The British ejected the French and returned Santo Domingo to the Spaniards in 1809. The Spaniards not only tried to re-establish slavery in Santo Domingo, but many of them also mounted raiding expeditions into Haiti to capture blacks and enslave them as well.

After a dozen years of discontent and failed independence plots by various opposing groups, Santo Domingo's former Lieutenant-Governor (top administrator), José Núñez de Cáceres, declared the colony's independence from the Spanish crown as Spanish Haiti, on November 30, 1821. This period is also known as the Ephemeral independence.

The newly independent republic ended two months later under the Haitian government led by Jean-Pierre Boyer.

As Toussaint Louverture had done two decades earlier, the Haitians abolished slavery. In order to raise funds for the huge indemnity of 150 million francs that Haiti agreed to pay the former French colonists, and which was subsequently lowered to 60 million francs, the Haitian government imposed heavy taxes on the Dominicans. Since Haiti was unable to adequately provision its army, the occupying forces largely survived by commandeering or confiscating food and supplies at gunpoint. Attempts to redistribute land conflicted with the system of communal land tenure ("terrenos comuneros"), which had arisen with the ranching economy, and some people resented being forced to grow cash crops under Boyer and Joseph Balthazar Inginac's "Code Rural". In the rural and rugged mountainous areas, the Haitian administration was usually too inefficient to enforce its own laws. It was in the city of Santo Domingo that the effects of the occupation were most acutely felt, and it was there that the movement for independence originated.

Haiti's constitution forbade white elites from owning land, and Dominican major landowning families were forcibly deprived of their properties. Many emigrated to Cuba, Puerto Rico (these two being Spanish possessions at the time), or Gran Colombia, usually with the encouragement of Haitian officials who acquired their lands. The Haitians associated the Roman Catholic Church with the French slave-masters who had exploited them before independence and confiscated all church property, deported all foreign clergy, and severed the ties of the remaining clergy to the Vatican.

All levels of education collapsed; the university was shut down, as it was starved both of resources and students, with young Dominican men from 16 to 25 years old being drafted into the Haitian army. Boyer's occupation troops, who were largely Dominicans, were unpaid and had to "forage and sack" from Dominican civilians. Haiti imposed a "heavy tribute" on the Dominican people.

Many whites fled Santo Domingo for Puerto Rico and Cuba (both still under Spanish rule), Venezuela, and elsewhere. In the end, the economy faltered and taxation became more onerous. Rebellions occurred even by Dominican freedmen, while Dominicans and Haitians worked together to oust Boyer from power. Anti-Haitian movements of several kinds – pro-independence, pro-Spanish, pro-French, pro-British, pro-United States – gathered force following the overthrow of Boyer in 1843.

In 1838 Juan Pablo Duarte founded a secret society called La Trinitaria, which sought the complete independence of Santo Domingo without any foreign intervention. Also Francisco del Rosario Sánchez and Ramon Matias Mella, despite not being among the founding members of La Trinitaria, were decisive in the fight for independence. Duarte, Mella, and Sánchez are considered the three Founding Fathers of the Dominican Republic.

The "Trinitarios" took advantage of a Haitian rebellion against the dictator Jean-Pierre Boyer. They rose up on January 27, 1843, ostensibly in support of the Haitian Charles Hérard who was challenging Boyer for the control of Haiti. However, the movement soon discarded its pretext of support for Hérard and now championed Dominican independence. After overthrowing Boyer, Hérard executed some Dominicans, and threw many others into prison; Duarte escaped. After subduing the Dominicans, Hérard, a mulatto, faced a rebellion by blacks in Port-au-Prince. Haiti had formed two regiments composed of Dominicans from the city of Santo Domingo; these were used by Hérard to suppress the uprising.

On February 27, 1844, the surviving members of "La Trinitaria" declared the independence from Haiti. They were backed by Pedro Santana, a wealthy cattle rancher from El Seibo, who became general of the army of the nascent republic. The Dominican Republic's first Constitution was adopted on November 6, 1844, and was modeled after the United States Constitution. The decades that followed were filled with tyranny, factionalism, economic difficulties, rapid changes of government, and exile for political opponents. Archrivals Santana and Buenaventura Báez held power most of the time, both ruling arbitrarily. They promoted competing plans to annex the new nation to another power: Santana favored Spain, and Báez the United States.

Threatening the nation's independence were renewed Haitian invasions. On 19 March 1844, the Haitian Army, under the personal command of President Hérard, invaded the eastern province from the north and progressed as far as Santiago, but was soon forced to withdraw after suffering disproportionate losses. According to José María Imbert's (the General defending Santiago) report of April 5, 1844 to Santo Domingo, “in Santiago, the enemy did not leave behind in the battlefield less than six hundred dead and…the number of wounded was very superior…[while on] our part we suffered not one casualty.”

The Dominicans repelled the Haitian forces, on both land and sea, by December 1845. The Haitians invaded again in 1849 after France recognized the Dominican Republic as an independent nation. In an overwhelming onslaught, the Haitians seized one frontier town after another. Santana being called upon to assume command of the troops, met the enemy at Ocoa, April 21, 1849, with only 400 men, and succeeded in utterly defeating the Haitian army. In November 1849 Báez launched a naval offensive against Haiti to forestall the threat of another invasion. His seamen under the French adventurer, Fagalde, raided the Haitian coasts, plundered seaside villages, as far as Cape Dame Marie, and butchered crews of captured enemy ships. In 1855, Haiti invaded again, but its forces were repulsed at the bloodiest clashes in the history of the Dominican–Haitian wars, the Battle of Santomé in December 1855 and the Battle of Sabana Larga in January 1856.

The Dominican Republic's first constitution was adopted on November 6, 1844. The state was commonly known as Santo Domingo in English until the early 20th century. It featured a presidential form of government with many liberal tendencies, but it was marred by Article 210, imposed by Pedro Santana on the constitutional assembly by force, giving him the privileges of a dictatorship until the war of independence was over. These privileges not only served him to win the war but also allowed him to persecute, execute and drive into exile his political opponents, among which Duarte was the most important. In Haiti after the fall of Boyer, black leaders had ascended to the power once enjoyed exclusively by the mulatto elite.

Without adequate roads, the regions of the Dominican Republic developed in isolation from one another. In the south, also known at the time as Ozama, the economy was dominated by cattle-ranching (particularly in the southeastern savannah) and cutting mahogany and other hardwoods for export. This region retained a semi-feudal character, with little commercial agriculture, the hacienda as the dominant social unit, and the majority of the population living at a subsistence level. In the north (better-known as Cibao), the nation's richest farmland, peasants supplemented their subsistence crops by growing tobacco for export, mainly to Germany. Tobacco required less land than cattle ranching and was mainly grown by smallholders, who relied on itinerant traders to transport their crops to Puerto Plata and Monte Cristi. Santana antagonized the Cibao farmers, enriching himself and his supporters at their expense by resorting to multiple peso printings that allowed him to buy their crops for a fraction of their value. In 1848, he was forced to resign and was succeeded by his vice-president, Manuel Jimenes.

After defeating a new Haitian invasion in 1849, Santana marched on Santo Domingo and deposed Jimenes in a coup d'état. At his behest, Congress elected Buenaventura Báez as President, but Báez was unwilling to serve as Santana's puppet, challenging his role as the country's acknowledged military leader. In 1853 Santana was elected president for his second term, forcing Báez into exile. Three years later, after repulsing another Haitian invasion, he negotiated a treaty leasing a portion of Samaná Peninsula to a U.S. company; popular opposition forced him to abdicate, enabling Báez to return and seize power. With the treasury depleted, Báez printed eighteen million uninsured pesos, purchasing the 1857 tobacco crop with this currency and exporting it for hard cash at immense profit to himself and his followers. Cibao tobacco planters, who were ruined when hyperinflation ensued, revolted and formed a new government headed by José Desiderio Valverde and headquartered in Santiago de los Caballeros. In July 1857 General Juan Luis Franco Bidó besieged Santo Domingo. The Cibao-based government declared an amnesty to exiles and Santana returned and managed to replace Franco Bidó in September 1857. After a year of civil war, Santana captured Santo Domingo in June 1858, overthrew both Báez and Valverde and installed himself as president.

In 1861, after imprisoning, silencing, exiling, and executing many of his opponents and due to political and economic reasons, Santana signed a pact with the Spanish Crown and reverted the Dominican nation to colonial status. This action was supported by the cattlemen of the south while the northern elites opposed it. Spanish rule finally came to an end with the War of Restoration in 1865, after four years of conflict between Dominican nationalists and Spanish sympathizers.

Political strife again prevailed in the following years; warlords ruled, military revolts were extremely common, and the nation amassed debt. In 1869, President Ulysses S. Grant ordered U.S. Marines to the island for the first time. Pirates operating from Haiti had been raiding U.S. commercial shipping in the Caribbean, and Grant directed the Marines to stop them at their source. Following the virtual takeover of the island, Báez offered to sell the country to the United States. Grant desired a naval base at Samaná and also a place for resettling newly freed Blacks. The treaty, which included U.S. payment of $1.5 million for Dominican debt repayment, was defeated in the United States Senate in 1870 on a vote of 28–28, two-thirds being required.

Báez was toppled in 1874, returned, and was toppled for good in 1878. A new generation was thence in charge, with the passing of Santana (he died in 1864) and Báez from the scene. Relative peace came to the country in the 1880s, which saw the coming to power of General Ulises Heureaux.

"Lilís," as the new president was nicknamed, enjoyed a period of popularity. He was, however, "a consummate dissembler," who put the nation deep into debt while using much of the proceeds for his personal use and to maintain his police state. Heureaux became rampantly despotic and unpopular. In 1899 he was assassinated. However, the relative calm over which he presided allowed improvement in the Dominican economy. The sugar industry was modernized, and the country attracted foreign workers and immigrants.

From 1902 on, short-lived governments were again the norm, with their power usurped by caudillos in parts of the country. Furthermore, the national government was bankrupt and, unable to pay Heureaux's debts, faced the threat of military intervention by France and other European creditor powers.

United States President Theodore Roosevelt sought to prevent European intervention, largely to protect the routes to the future Panama Canal, as the canal was already under construction. He made a small military intervention to ward off European powers, to proclaim his famous Roosevelt Corollary to the Monroe Doctrine, and also to obtain his 1905 Dominican agreement for U.S. administration of Dominican customs, which was the chief source of income for the Dominican government. A 1906 agreement provided for the arrangement to last 50 years. The United States agreed to use part of the customs proceeds to reduce the immense foreign debt of the Dominican Republic and assumed responsibility for said debt.
After six years in power, President Ramón Cáceres (who had himself assassinated Heureaux) was assassinated in 1911. The result was several years of great political instability and civil war. U.S. mediation by the William Howard Taft and Woodrow Wilson administrations achieved only a short respite each time. A political deadlock in 1914 was broken after an ultimatum by Wilson telling the Dominicans to choose a president or see the U.S. impose one. A provisional president was chosen, and later the same year relatively free elections put former president (1899–1902) Juan Isidro Jimenes Pereyra back in power. To achieve a more broadly supported government, Jimenes named opposition individuals to his cabinet. But this brought no peace and, with his former Secretary of War Desiderio Arias maneuvering to depose him and despite a U.S. offer of military aid against Arias, Jimenes resigned on May 7, 1916.

Wilson thus ordered the U.S. occupation of the Dominican Republic. U.S. Marines landed on May 16, 1916, and had control of the country two months later. The military government established by the U.S., led by Vice Admiral Harry Shepard Knapp, was widely repudiated by the Dominicans, with many factions within the country leading guerrilla campaigns against U.S. forces. The occupation regime kept most Dominican laws and institutions and largely pacified the general population. The occupying government also revived the Dominican economy, reduced the nation's debt, built a road network that at last interconnected all regions of the country, and created a professional National Guard to replace the warring partisan units.

Vigorous opposition to the occupation continued, nevertheless, and after World War I it increased in the U.S. as well. There, President Warren G. Harding (1921–23), Wilson's successor, worked to put an end to the occupation, as he had promised to do during his campaign. The U.S. government's rule ended in October 1922, and elections were held in March 1924.

The victor was former president (1902–03) Horacio Vásquez, who had cooperated with the U.S. He was inaugurated on July 13, and the last U.S. forces left in September. In six years, the Marines were involved in at least 467 engagements, with 950 insurgents killed or wounded in action. Vásquez gave the country six years of stable governance, in which political and civil rights were respected and the economy grew strongly, in a relatively peaceful atmosphere.

During the government of Horacio Vásquez, Rafael Trujillo held the rank of lieutenant colonel and was chief of police. This position helped him launch his plans to overthrow the government of Vásquez. Trujillo had the support of Carlos Rosario Peña, who formed the Civic Movement, which had as its main objective to overthrow the government of Vásquez.

In February 1930, when Vásquez attempted to win another term, his opponents rebelled in secret alliance with the commander of the National Army (the former National Guard), General Rafael Leonidas Trujillo Molina. Trujillo secretly cut a deal with rebel leader Rafael Estrella Ureña; in return for letting Ureña take power, Trujillo would be allowed to run for president in new elections. As the rebels marched toward Santo Domingo, Vásquez ordered Trujillo to suppress them. However, feigning "neutrality," Trujillo kept his men in barracks, allowing Ureña's rebels to take the capital virtually uncontested. On March 3, Ureña was proclaimed acting president with Trujillo confirmed as head of the police and the army.

As per their agreement, Trujillo became the presidential nominee of the newly formed Patriotic Coalition of Citizens (Spanish: Coalición patriotica de los ciudadanos), with Ureña as his running mate. During the election campaign, Trujillo used the army to unleash his repression, forcing his opponents to withdraw from the race. Trujillo stood to elect himself, and in May he was elected president virtually unopposed after a violent campaign against his opponents, ascending to power on August 16, 1930.

There was considerable economic growth during Rafael Trujillo's long and iron-fisted regime, although a great deal of the wealth was taken by the dictator and other regime elements. There was progress in healthcare, education, and transportation, with the building of hospitals and clinics, schools, and roads and harbors. Trujillo also carried out an important housing construction program and instituted a pension plan. He finally negotiated an undisputed border with Haiti in 1935 and achieved the end of the 50-year customs agreement in 1941, instead of 1956. He made the country debt-free in 1947.

This was accompanied by absolute repression and the copious use of murder, torture, and terrorist methods against the opposition. Trujillo renamed Santo Domingo to "Ciudad Trujillo" (Trujillo City), the nation's – and the Caribbean's – highest mountain "La Pelona Grande" (Spanish for: The Great Bald) to "Pico Trujillo" (Spanish for: Trujillo Peak), and many towns and a province. Some other places he renamed after members of his family. By the end of his first term in 1934 he was the country's wealthiest person, and one of the wealthiest in the world by the early 1950s; near the end of his regime his fortune was an estimated $800 million. He used the secret police extensively to eliminate political opposition and to prevent several coup attempts during and after World War II. The secret police allegedly murdered more than 500,000 people during the Trujillo era.

Although one-quarter Haitian, Trujillo promoted propaganda against them. In 1937, he ordered what became known as the Parsley Massacre or, in the Dominican Republic, as "El Corte" (The Cutting), directing the army to kill Haitians living on the Dominican side of the border. The army killed an estimated 17,000 to 35,000 Haitian men, women, and children over six days, from the night of October 2, 1937, through October 8, 1937. To avoid leaving evidence of the army's involvement, the soldiers used edged weapons rather than guns. The soldiers were said to have interrogated anyone with dark skin, using the shibboleth "perejil" (parsley) to distinguish Haitians from Afro-Dominicans when necessary; the 'r' of "perejil" was of difficult pronunciation for Haitians. As a result of the massacre, the Dominican Republic agreed to pay Haiti US$750,000, later reduced to US$525,000. In 1938, reports from the Dominican Republic revealed hundreds more Haitians had been killed and thousands deported.

On November 25, 1960, Trujillo killed three of the four Mirabal sisters, nicknamed "Las Mariposas" (The Butterflies). The victims were Patria Mercedes Mirabal (born on February 27, 1924), Argentina Minerva Mirabal (born on March 12, 1926), and Antonia María Teresa Mirabal (born on October 15, 1935). Along with their husbands, the sisters were conspiring to overthrow Trujillo in a violent revolt. The Mirabals had communist ideological leanings as did their husbands. The sisters have received many honors posthumously and have many memorials in various cities in the Dominican Republic. Salcedo, their home province, changed its name to Provincia Hermanas Mirabal (Mirabal Sisters Province). The International Day for the Elimination of Violence against Women is observed on the anniversary of their deaths.

For a long time, the U.S. and the Dominican elite supported the Trujillo government. This support persisted despite the assassinations of political opposition, the massacre of Haitians, and Trujillo's plots against other countries. The U.S. believed Trujillo was the lesser of two or more evils. The U.S. finally broke with Trujillo in 1960, after Trujillo's agents attempted to assassinate the Venezuelan president, Rómulo Betancourt, a fierce critic of Trujillo.

Trujillo had become expendable. Dissidents inside the Dominican Republic argued that assassination was the only certain way to remove Trujillo.

According to Chester Bowles, the U.S. Undersecretary of State, internal Department of State discussions in 1961 on the topic were vigorous. Richard N. Goodwin, Assistant Special Counsel to the President, who had direct contacts with the rebel alliance, argued for intervention against Trujillo. Quoting Bowles directly: "The next morning I learned that in spite of the clear decision against having the dissident group request our assistance Dick Goodwin following the meeting sent a cable to CIA people in the Dominican Republic without checking with State or CIA; indeed, with the protest of the Department of State. The cable directed the CIA people in the Dominican Republic to get this request at any cost. When Allen Dulles found this out the next morning, he withdrew the order. We later discovered it had already been carried out."

Trujillo was assassinated on May 30, 1961. Trujillo was murdered with weapons supplied by the United States Central Intelligence Agency (CIA).

In February 1963, a democratically elected government under leftist Juan Bosch took office but it was overthrown in September. On April 24, 1965, after 19 months of military rule, a pro-Bosch revolt broke out.

Days later U.S. President Lyndon Johnson, concerned that Communists might take over the revolt and create a "second Cuba," sent the Marines, followed immediately by the U.S. Army's 82nd Airborne Division and other elements of the XVIIIth Airborne Corps, in Operation Powerpack. "We don't propose to sit here in a rocking chair with our hands folded and let the Communist set up any government in the western hemisphere," Johnson said. The forces were soon joined by comparatively small contingents from the Organization of American States. All these remained in the country for over a year and left after supervising elections in 1966 won by Joaquín Balaguer. He had been Trujillo's last puppet-president.

The Dominican death toll for the entire period of civil war and occupation totaled more than three thousand, many of them black civilians killed when the US-backed military junta engaged in a campaign of ethnic cleansing in the northern (also the industrial) part of Santo Domingo.

Balaguer remained in power as president for 12 years. His tenure was a period of repression of human rights and civil liberties, ostensibly to keep pro-Castro or pro-communist parties out of power; 11,000 persons were killed. His rule was criticized for a growing disparity between rich and poor. It was, however, praised for an ambitious infrastructure program, which included the construction of large housing projects, sports complexes, theaters, museums, aqueducts, roads, highways, and the massive Columbus Lighthouse, completed in 1992 during a later tenure.

In 1978, Balaguer was succeeded in the presidency by opposition candidate Antonio Guzmán Fernández, of the Dominican Revolutionary Party (PRD). Another PRD win in 1982 followed, under Salvador Jorge Blanco. Under the PRD presidents, the Dominican Republic enjoyed a period of relative freedom and basic human rights.

Balaguer regained the presidency in 1986 and was re-elected in 1990 and 1994, this last time just defeating PRD candidate José Francisco Peña Gómez, a former mayor of Santo Domingo. The 1994 elections were flawed, bringing on international pressure, to which Balaguer responded by scheduling another presidential contest in 1996. Balaguer was not a candidate. The PSRC candidate was his Vice President Jacinto Peynado Garrigosa.

In the 1996 presidential election, Leonel Fernández achieved the first-ever win for the Dominican Liberation Party (PLD), which Bosch had founded in 1973 after leaving the PRD (which he also had founded). Fernández oversaw a fast-growing economy: growth averaged 7.7% per year, unemployment fell, and there were stable exchange and inflation rates.

In 2000 the PRD's Hipólito Mejía won the election. This was a time of economic troubles. Mejía was defeated in his re-election effort in 2004 by Leonel Fernández of the PLD. In 2008, Fernández was as elected for a third term. Fernández and the PLD are credited with initiatives that have moved the country forward technologically, such as the construction of the Metro Railway ("El Metro"). On the other hand, his administrations have been accused of corruption.

Danilo Medina of the PLD was elected president in 2012 and re-elected in 2016. On the other hand, a significant increase in crime, government corruption and a weak justice system threaten to overshadow their administrative period.

The Dominican Republic has the ninth-largest economy in Latin America and is the largest economy in the Caribbean and Central American region. Over the last two decades, the Dominican Republic has had one of the fastest-growing economies in the Americas – with an average real GDP growth rate of 5.4% between 1992 and 2014. GDP growth in 2014 and 2015 reached 7.3 and 7.0%, respectively, the highest in the Western Hemisphere. In the first half of 2016 the Dominican economy grew 7.4% continuing its trend of rapid economic growth. Recent growth has been driven by construction, manufacturing, tourism, and mining. Private consumption has been strong, as a result of low inflation (under 1% on average in 2015), job creation, as well as a high level of remittances.

The Dominican Republic is situated on the eastern part of the second largest island in the Greater Antilles, Hispaniola. It shares the island roughly at a 2:1 ratio with Haiti. The country's area is reported variously as (by the embassy in the United States) and , making it the second largest country in the Antilles, after Cuba. The Dominican Republic's capital and largest metropolitan area Santo Domingo is on the southern coast.

There are many small offshore islands and cays that are part of the Dominican territory. The two largest islands near shore are Saona, in the southeast, and Beata, in the southwest. To the north, at distances of , are three extensive, largely submerged banks, which geographically are a southeast continuation of the Bahamas: Navidad Bank, Silver Bank, and Mouchoir Bank. Navidad Bank and Silver Bank have been officially claimed by the Dominican Republic.

The Dominican Republic has four important mountain ranges. The most northerly is the "Cordillera Septentrional" ("Northern Mountain Range"), which extends from the northwestern coastal town of Monte Cristi, near the Haitian border, to the Samaná Peninsula in the east, running parallel to the Atlantic coast. The highest range in the Dominican Republic – indeed, in the whole of the West Indies – is the "Cordillera Central" ("Central Mountain Range"). It gradually bends southwards and finishes near the town of Azua, on the Caribbean coast.

In the Cordillera Central are the four highest peaks in the Caribbean: Pico Duarte ( above sea level), La Pelona (), La Rucilla (), and Pico Yaque (). In the southwest corner of the country, south of the Cordillera Central, there are two other ranges. The more northerly of the two is the "Sierra de Neiba", while in the south the "Sierra de Bahoruco" is a continuation of the Massif de la Selle in Haiti. There are other, minor mountain ranges, such as the "Cordillera Oriental" ("Eastern Mountain Range"), "Sierra Martín García", "Sierra de Yamasá", and "Sierra de Samaná".

Between the Central and Northern mountain ranges lies the rich and fertile Cibao valley. This major valley is home to the cities of Santiago and La Vega and most of the farming areas in the nation. Rather less productive are the semi-arid San Juan Valley, south of the Central Cordillera, and the Neiba Valley, tucked between the Sierra de Neiba and the Sierra de Bahoruco. Much of the land in the Enriquillo Basin is below sea level, with a hot, arid, desert-like environment. There are other smaller valleys in the mountains, such as the Constanza, Jarabacoa, Villa Altagracia, and Bonao valleys.

The "Llano Costero del Caribe" ("Caribbean Coastal Plain") is the largest of the plains in the Dominican Republic. Stretching north and east of Santo Domingo, it contains many sugar plantations in the savannahs that are common there. West of Santo Domingo its width is reduced to as it hugs the coast, finishing at the mouth of the Ocoa River. Another large plain is the "Plena de Azua" ("Azua Plain"), a very arid region in Azua Province. A few other small coastal plains are on the northern coast and in the Pedernales Peninsula.

Four major rivers drain the numerous mountains of the Dominican Republic. The Yaque del Norte is the longest and most important Dominican river. It carries excess water down from the Cibao Valley and empties into Monte Cristi Bay, in the northwest. Likewise, the Yuna River serves the Vega Real and empties into Samaná Bay, in the northeast. Drainage of the San Juan Valley is provided by the San Juan River, tributary of the Yaque del Sur, which empties into the Caribbean, in the south. The Artibonito is the longest river of Hispaniola and flows westward into Haiti.

There are many lakes and coastal lagoons. The largest lake is Enriquillo, a salt lake at below sea level, the lowest point in the Caribbean. Other important lakes are Laguna de Rincón or Cabral, with fresh water, and Laguna de Oviedo, a lagoon with brackish water.

The Dominican Republic is located near fault action in the Caribbean. In 1946 it suffered a magnitude 8.1 earthquake off the northeast coast. This triggered a tsunami that killed about 1,800, mostly in coastal communities. The wave was also recorded at Daytona Beach, Florida, and Atlantic City, New Jersey. The area remains at risk. Caribbean countries and the United States have collaborated to create tsunami warning systems and are mapping risk in low-lying areas.

The Dominican Republic has a tropical rainforest climate in the coastal and lowland areas. Due to its diverse topography, Dominican Republic's climate shows considerable variation over short distances and is the most varied of all the Antilles. The annual average temperature is . At higher elevations the temperature averages while near sea level the average temperature is . Low temperatures of are possible in the mountains while high temperatures of are possible in protected valleys. January and February are the coolest months of the year while August is the hottest month. Snowfall can be seen in rare occasions on the summit of Pico Duarte.

The wet season along the northern coast lasts from November through January. Elsewhere the wet season stretches from May through November, with May being the wettest month. Average annual rainfall is countrywide, with individual locations in the Valle de Neiba seeing averages as low as while the Cordillera Oriental averages . The driest part of the country lies in the west.

Tropical cyclones strike the Dominican Republic every couple of years, with 65% of the impacts along the southern coast. Hurricanes are most likely between August and October. The last major hurricane that struck the country was Hurricane Georges in 1998.

The Dominican Republic is a representative democracy or democratic republic, with three branches of power: executive, legislative, and judicial. The president of the Dominican Republic heads the executive branch and executes laws passed by the congress, appoints the cabinet, and is commander in chief of the armed forces. The president and vice-president run for office on the same ticket and are elected by direct vote for 4-year terms. The national legislature is bicameral, composed of a senate, which has 32 members, and the Chamber of Deputies, with 178 members.

Judicial authority rests with the Supreme Court of Justice's 16 members. They are appointed by a council composed of the president, the leaders of both houses of Congress, the President of the Supreme Court, and an opposition or non–governing-party member. The court "alone hears actions against the president, designated members of his Cabinet, and members of Congress when the legislature is in session."

The Dominican Republic has a multi-party political system. Elections are held every two years, alternating between the presidential elections, which are held in years evenly divisible by four, and the congressional and municipal elections, which are held in even-numbered years not divisible by four. "International observers have found that presidential and congressional elections since 1996 have been generally free and fair." The Central Elections Board (JCE) of nine members supervises elections, and its decisions are unappealable. Starting from 2016, elections will be held jointly, after a constitutional reform.

The three major parties are the conservative Social Christian Reformist Party (), in power 1966–78 and 1986–96; the social democratic Dominican Revolutionary Party (), in power in 1963, 1978–86, and 2000–04; and the centrist liberal and reformist Dominican Liberation Party (), in power 1996–2000 and since 2004.

The presidential elections of 2008 were held on May 16, 2008, with incumbent Leonel Fernández winning 53% of the vote. He defeated Miguel Vargas Maldonado, of the PRD, who achieved a 40.48% share of the vote. Amable Aristy, of the PRSC, achieved 4.59% of the vote. Other minority candidates, which included former Attorney General Guillermo Moreno from the Movement for Independence, Unity and Change (), and PRSC former presidential candidate and defector Eduardo Estrella, obtained less than 1% of the vote.

In the 2012 presidential elections the incumbent president Leonel Fernández (PLD) declined his aspirations and instead the PLD elected Danilo Medina as its candidate. This time the PRD presented ex-president Hipolito Mejia as its choice. The contest was won by Medina with 51.21% of the vote, against 46.95% in favor of Mejia. Candidate Guillermo Moreno obtained 1.37% of the votes.

In 2014 the Modern Revolutionary Party () was created by a faction of leaders from the PRD and has since become the predominant opposition party, polling in second place for the upcoming May 2016 general elections.

The Dominican Republic has a close relationship with the United States and with the other states of the Inter-American system. The Dominican Republic has very strong ties and relations with Puerto Rico.

The Dominican Republic's relationship with neighbouring Haiti is strained over mass Haitian migration to the Dominican Republic, with citizens of the Dominican Republic blaming the Haitians for increased crime and other social problems. The Dominican Republic is a regular member of the Organisation Internationale de la Francophonie.

The Dominican Republic has a Free Trade Agreement with the United States, Costa Rica, El Salvador, Guatemala, Honduras and Nicaragua via the Dominican Republic-Central America Free Trade Agreement. And an Economic Partnership Agreement with the European Union and the Caribbean Community via the Caribbean Forum.

Congress authorizes a combined military force of 44,000 active duty personnel. Actual active duty strength is approximately 32,000. Approximately 50% of those are used for non-military activities such as security providers for government-owned non-military facilities, highway toll stations, prisons, forestry work, state enterprises, and private businesses. The commander in chief of the military is the president.

The army is larger than the other services combined with approximately 20,000 active duty personnel, consisting of six infantry brigades, a combat support brigade, and a combat service support brigade. The air force operates two main bases, one in the southern region near Santo Domingo and one in the northern region near Puerto Plata. The navy operates two major naval bases, one in Santo Domingo and one in Las Calderas on the southwestern coast, and maintains 12 operational vessels. The Dominican Republic has the second largest military in the Caribbean region after Cuba.

The armed forces have organized a Specialized Airport Security Corps (CESA) and a Specialized Port Security Corps (CESEP) to meet international security needs in these areas. The secretary of the armed forces has also announced plans to form a specialized border corps (CESEF). The armed forces provide 75% of personnel to the National Investigations Directorate (DNI) and the Counter-Drug Directorate (DNCD).

The Dominican National Police force contains 32,000 agents. The police are not part of the Dominican armed forces but share some overlapping security functions. Sixty-three percent of the force serve in areas outside traditional police functions, similar to the situation of their military counterparts.

The Dominican Republic is divided into 31 provinces. Santo Domingo, the capital, is designated Distrito Nacional (National District). The provinces are divided into municipalities ("municipios"; singular "municipio"). They are the second-level political and administrative subdivisions of the country. The president appoints the governors of the 31 provinces. Mayors and municipal councils administer the 124 municipal districts and the National District (Santo Domingo). They are elected at the same time as congressional representatives.

The Dominican Republic is the largest economy (according to the U.S. State Department and the World Bank) in the Caribbean and Central American region. It is an upper middle-income developing country, with a 2015 GDP per capita of US$14,770, in PPP terms. Over the last two decades, the Dominican Republic have been standing out as one of the fastest-growing economies in the Americas – with an average real GDP growth rate of 5.4% between 1992 and 2014. GDP growth in 2014 and 2015 reached 7.3 and 7.0%, respectively, the highest in the Western Hemisphere. In the first half of 2016 the Dominican economy grew 7.4%. , the average wage in nominal terms is US$392 per month (RD$17,829). The country is the site of the second largest gold mine in the world, the Pueblo Viejo mine.

During the last three decades, the Dominican economy, formerly dependent on the export of agricultural commodities (mainly sugar, cocoa and coffee), has transitioned to a diversified mix of services, manufacturing, agriculture, mining, and trade. The service sector accounts for almost 60% of GDP; manufacturing, for 22%; tourism, telecommunications and finance are the main components of the service sector; however, none of them accounts for more than 10% of the whole. The Dominican Republic has a stock market, Bolsa de Valores de la Republica Dominicana (BVRD). and advanced telecommunication system and transportation infrastructure. Nevertheless, government corruption, and inconsistent electric service remain major problems. The country also has "marked income inequality." International migration affects the Dominican Republic greatly, as it receives and sends large flows of migrants. Mass illegal Haitian immigration and the integration of Dominicans of Haitian descent are major issues. A large Dominican diaspora exists, mostly in the United States, contributes to development, sending billions of dollars to Dominican families in remittances.

Remittances in Dominican Republic increased to US$4571.30 million in 2014 from US$3333 million in 2013 (according to data reported by the Inter-American Development Bank). Economic growth takes place in spite of a chronic energy shortage, which causes frequent blackouts and very high prices. Despite a widening merchandise trade deficit, tourism earnings and remittances have helped build foreign exchange reserves. Following economic turmoil in the late 1980s and 1990, during which the gross domestic product (GDP) fell by up to 5% and consumer price inflation reached an unprecedented 100%, the Dominican Republic entered a period of growth and declining inflation until 2002, after which the economy entered a recession.

This recession followed the collapse of the second-largest commercial bank in the country, Baninter, linked to a major incident of fraud valued at US$3.5 billion. The Baninter fraud had a devastating effect on the Dominican economy, with GDP dropping by 1% in 2003 as inflation ballooned by over 27%. All defendants, including the star of the trial, Ramón Báez Figueroa (the great-grandson of President Buenaventura Báez), were convicted.

According to the 2005 Annual Report of the United Nations Subcommittee on Human Development in the Dominican Republic, the country is ranked No. 71 in the world for resource availability, No. 79 for human development, and No. 14 in the world for resource mismanagement. These statistics emphasize national government corruption, foreign economic interference in the country, and the rift between the rich and poor.

The Dominican Republic has a noted problem of child labor in its coffee, rice, sugarcane, and tomato industries. The labor injustices in the sugarcane industry extend to forced labor according to the U.S. Department of Labor. Three large groups own 75% of the land: the State Sugar Council (Consejo Estatal del Azúcar, CEA), Grupo Vicini, and Central Romana Corporation.

According to the 2016 Global Slavery Index, an estimated 104,800 people are enslaved in the modern day Dominican Republic, or 1.00% of the population. Some slaves in the Dominican Republic are held on sugar plantations, guarded by men on horseback with rifles, and forced to work.

The Dominican peso (abbreviated $ or RD$; ISO 4217 code is "DOP") is the national currency, with the United States dollar, the Euro, the Canadian dollar and the Swiss franc also accepted at most tourist sites. The exchange rate to the U.S. dollar, liberalized by 1985, stood at 2.70 pesos per dollar in August 1986, 14.00 pesos in 1993, and 16.00 pesos in 2000. the rate was 50.08 pesos per dollar.

The Dominican Republic is the most visited destination in the Caribbean. The year-round golf courses are major attractions. A geographically diverse nation, the Dominican Republic is home to both the Caribbean's tallest mountain peak, Pico Duarte, and the Caribbean's largest lake and point of lowest elevation, Lake Enriquillo. The island has an average temperature of and great climatic and biological diversity. The country is also the site of the first cathedral, castle, monastery, and fortress built in the Americas, located in Santo Domingo's Colonial Zone, a World Heritage Site.

Tourism is one of the fueling factors in the Dominican Republic's economic growth. The Dominican Republic is the most popular tourist destination in the Caribbean. With the construction of projects like Cap Cana, San Souci Port in Santo Domingo, Casa De Campo and the Hard Rock Hotel & Casino (ancient Moon Palace Resort) in Punta Cana, the Dominican Republic expects increased tourism activity in the upcoming years.

Ecotourism has also been a topic increasingly important in this nation, with towns like Jarabacoa and neighboring Constanza, and locations like the Pico Duarte, Bahia de las Aguilas, and others becoming more significant in efforts to increase direct benefits from tourism. Most residents from other countries are required to get a tourist card, depending on the country they live in. In the last 10 years the Dominican Republic has become one of the worlds notably progressive states in terms of recycling and waste disposal. A UN report cited there was a 221.3% efficiency increase in the previous 10 years. Notably due to the opening of the largest open air landfill site located in the north 10 km from the Haitian boarder.

The country has three national trunk highways, which connect every major town. These are DR-1, DR-2, and DR-3, which depart from Santo Domingo toward the northern (Cibao), southwestern (Sur), and eastern (El Este) parts of the country respectively. These highways have been consistently improved with the expansion and reconstruction of many sections. Two other national highways serve as spur (DR-5) or alternative routes (DR-4).

In addition to the national highways, the government has embarked on an expansive reconstruction of spur secondary routes, which connect smaller towns to the trunk routes. In the last few years the government constructed a 106-kilometer toll road that connects Santo Domingo with the country's northeastern peninsula. Travelers may now arrive in the Samaná Peninsula in less than two hours. Other additions are the reconstruction of the DR-28 (Jarabacoa – Constanza) and DR-12 (Constanza – Bonao). Despite these efforts, many secondary routes still remain either unpaved or in need of maintenance. There is currently a nationwide program to pave these and other commonly used routes. Also, the Santiago light rail system is in planning stages but currently on hold.

There are two main bus transportation services in the Dominican Republic: one controlled by the government, through the Oficina Técnica de Transito Terrestre (OTTT) and the Oficina Metropolitana de Servicios de Autobuses (OMSA), and the other controlled by private business, among them, Federación Nacional de Transporte La Nueva Opción (FENATRANO) and the Confederacion Nacional de Transporte (CONATRA). The government transportation system covers large routes in metropolitan areas such as Santo Domingo and Santiago.

There are many privately owned bus companies, such as Metro Servicios Turísticos and Caribe Tours, that run daily routes.

The Dominican Republic has a rapid transit system in Santo Domingo, the country's capital. It is the most extensive metro system in the insular Caribbean and Central American region by length and number of stations. The Santo Domingo Metro is part of a major "National Master Plan" to improve transportation in Santo Domingo as well as the rest of the nation. The first line was planned to relieve traffic congestion in the Máximo Gómez and Hermanas Mirabal Avenue. The second line, which opened in April 2013, is meant to relieve the congestion along the Duarte-Kennedy-Centenario Corridor in the city from west to east. The current length of the Metro, with the sections of the two lines open , is . Before the opening of the second line, 30,856,515 passengers rode the Santo Domingo Metro in 2012. With both lines opened, ridership increased to 61,270,054 passengers in 2014.

The Dominican Republic has a well developed telecommunications infrastructure, with extensive mobile phone and landline services. Cable Internet and DSL are available in most parts of the country, and many Internet service providers offer 3G wireless internet service. The Dominican Republic became the second country in Latin America to have 4G LTE wireless service. The reported speeds are from 1 Mbit/s up to 100 Mbit/s for residential services.

For commercial service there are speeds from 256 kbit/s up to 154 Mbit/s. (Each set of numbers denotes downstream/upstream speed; that is, to the user/from the user.) Projects to extend Wi-Fi hot spots have been made in Santo Domingo. The country's commercial radio stations and television stations are in the process of transferring to the digital spectrum, via HD Radio and HDTV after officially adopting ATSC as the digital medium in the country with a switch-off of analog transmission by September 2015. The telecommunications regulator in the country is INDOTEL ("Instituto Dominicano de Telecomunicaciones").

The largest telecommunications company is Claro – part of Carlos Slim's América Móvil – which provides wireless, landline, broadband, and IPTV services. In June 2009 there were more than 8 million phone line subscribers (land and cell users) in the D.R., representing 81% of the country's population and a fivefold increase since the year 2000, when there were 1.6 million. The communications sector generates about 3.0% of the GDP. There were 2,439,997 Internet users in March 2009.

In November 2009, the Dominican Republic became the first Latin American country to pledge to include a "gender perspective" in every information and communications technology (ICT) initiative and policy developed by the government. This is part of the regional eLAC2010 plan. The tool the Dominicans have chosen to design and evaluate all the public policies is the APC Gender Evaluation Methodology (GEM).

Electric power service has been unreliable since the Trujillo era, and as much as 75% of the equipment is that old. The country's antiquated power grid causes transmission losses that account for a large share of billed electricity from generators. The privatization of the sector started under a previous administration of Leonel Fernández. The recent investment in a 345 kilovolt "Santo Domingo–Santiago Electrical Highway" with reduced transmission losses, is being heralded as a major capital improvement to the national grid since the mid-1960s.

During the Trujillo regime electrical service was introduced to many cities. Almost 95% of usage was not billed at all. Around half of the Dominican Republic's 2.1 million houses have no meters and most do not pay or pay a fixed monthly rate for their electric service.

Household and general electrical service is delivered at 110 volts alternating at 60 Hz. Electrically powered items from the United States work with no modifications. The majority of the Dominican Republic has access to electricity. Tourist areas tend to have more reliable power, as do business, travel, healthcare, and vital infrastructure. Concentrated efforts were announced to increase efficiency of delivery to places where the collection rate reached 70%. The electricity sector is highly politicized. Some generating companies are undercapitalized and at times unable to purchase adequate fuel supplies.

The Dominican Republic's population was in . In 2010 31.2% of the population was under 15 years of age, with 6% of the population over 65 years of age. There were 103 males for every 100 females in 2007. The annual population growth rate for 2006–2007 was 1.5%, with the projected population for the year 2015 being 10,121,000.

The population density in 2007 was 192 per km² (498 per sq mi), and 63% of the population lived in urban areas. The southern coastal plains and the Cibao Valley are the most densely populated areas of the country. The capital city Santo Domingo had a population of 2,907,100 in 2010.

Other important cities are Santiago de los Caballeros ( 745,293), La Romana (pop. 214,109), San Pedro de Macorís (pop. 185,255), Higüey (153,174), San Francisco de Macorís (pop. 132,725), Puerto Plata (pop. 118,282), and La Vega (pop. 104,536). Per the United Nations, the urban population growth rate for 2000–2005 was 2.3%.

The Dominican Republic's population is 70% of racially mixed origin, 16% Black, and 14% White. Ethnic immigrant groups in the country include West Asians—mostly Lebanese, Syrians, and Palestinians. East Asians, primarily ethnic Chinese and Japanese, can also be found. Europeans are represented mostly by Spanish whites but also with smaller populations of German Jews, Italians, Portuguese, British, Dutch, Danes, and Hungarians. Some converted Sephardic Jews from Spain were part of early expeditions; only Catholics were allowed to come to the New World. Later there were Jewish migrants coming from the Iberian peninsula and other parts of Europe in the 1700s. Some managed to reach the Caribbean as refugees during and after the Second World War. Some Sephardic Jews reside in Sosúa while others are dispersed throughout the country. Self-identified Jews number about 3,000; other Dominicans may have some Jewish ancestry because of marriages among converted Jewish Catholics and other Dominicans since the colonial years. Some Dominicans born in the United States now reside in the Dominican Republic, creating a kind of expatriate community.

The population of the Dominican Republic is mostly Spanish-speaking. The local variant of Spanish is called Dominican Spanish, which closely resembles other Spanish vernaculars in the Caribbean and the Canarian Spanish. In addition, it has influences from African languages and borrowed words from indigenous Caribbean languages particular to the island of Hispaniola. Schools are based on a Spanish educational model; English and French are mandatory foreign languages in both private and public schools, although the quality of foreign languages teaching is poor. Some private educational institutes provide teaching on other languages, notably Italian, Japanese, and Mandarin.

Haitian Creole is the largest minority language in the Dominican Republic and is spoken by Haitian immigrants and their descendants. There is a community of a few thousand people whose ancestors spoke Samaná English in the Samaná Peninsula. They are the descendants of formerly enslaved African Americans who arrived in the nineteenth century, but only a few elders speak the language today. Tourism, American pop culture, the influence of Dominican Americans, and the country's economic ties with the United States motivate other Dominicans to learn English. The Dominican Republic is ranked 2nd in Latin America and 23rd in the World on English proficiency.

95.0% Christians 
2.6% No religion 
2.2% Other religions 

, 57% of the population (5.7 million) identified themselves as Roman Catholics and 23% (2.3 million) as Protestants (in Latin American countries, Protestants are often called "Evangelicos" because they emphasize personal and public evangelising and many are Evangelical Protestant or of a Pentecostal group). From 1896 to 1907 missionaries from the Episcopal, Free Methodist, Seventh-day Adventist and Moravians churches began work in the Dominican Republic. Three percent of the 10.63 million Dominican Republic population are Seventh-day Adventists. Recent immigration as well as proselytizing efforts have brought in other religious groups, with the following shares of the population: Spiritist: 2.2%, The Church of Jesus Christ of Latter-day Saints: 1.1%, Buddhist: 0.1%, Bahá'í: 0.1%, Chinese Folk Religion: 0.1%, Islam: 0.02%, Judaism: 0.01%.

The Catholic Church began to lose its strong dominance in the late 19th century. This was due to a lack of funding, priests, and support programs. During the same time, Protestant Evangelicalism began to gain a wider support "with their emphasis on personal responsibility and family rejuvenation, economic entrepreneurship, and biblical fundamentalism". The Dominican Republic has two Catholic patroness saints: "Nuestra Señora de la Altagracia" (Our Lady Of High Grace) and "Nuestra Señora de las Mercedes" (Our Lady Of Mercy).

The Dominican Republic has historically granted extensive religious freedom. According to the United States Department of State, "The constitution specifies that there is no state church and provides for freedom of religion and belief. A concordat with the Vatican designates Catholicism as the official religion and extends special privileges to the Catholic Church not granted to other religious groups. These include the legal recognition of church law, use of public funds to underwrite some church expenses, and complete exoneration from customs duties." In the 1950s restrictions were placed upon churches by the government of Trujillo. Letters of protest were sent against the mass arrests of government adversaries. Trujillo began a campaign against the Catholic Church and planned to arrest priests and bishops who preached against the government. This campaign ended before it was put into place, with his assassination.

During World War II a group of Jews escaping Nazi Germany fled to the Dominican Republic and founded the city of Sosúa. It has remained the center of the Jewish population since.

In the 20th century, many Arabs (from Lebanon, Syria, and Palestine), Japanese, and, to a lesser degree, Koreans settled in the country as agricultural laborers and merchants. The Chinese companies found business in telecom, mining, and railroads. The Arab community is rising at an increasing rate and is estimated at 80,000.

In addition, there are descendants of immigrants who came from other Caribbean islands, including St. Kitts and Nevis, Antigua, St. Vincent, Montserrat, Tortola, St. Croix, St. Thomas, and Guadeloupe. They worked on sugarcane plantations and docks and settled mainly in the cities of San Pedro de Macorís and Puerto Plata. Puerto Rican, and to a lesser extent, Cuban immigrants fled to the Dominican Republic from the mid-1800s until about 1940 due to a poor economy and social unrest in their respective home countries. Many Puerto Rican immigrants settled in Higüey, among other cities, and quickly assimilated due to similar culture. Before and during World War II, 800 Jewish refugees moved to the Dominican Republic.

Numerous immigrants have come from other Caribbean countries, as the country has offered economic opportunities. There are about 32,000 Jamaicans living in the Dominican Republic. There is an increasing number of Puerto Rican immigrants, especially in and around Santo Domingo; they are believed to number around 10,000. There are over 700,000 people of Haitian descent, including a generation born in the Dominican Republic.

Haiti is the neighboring nation to the Dominican Republic and is considerably poorer, less developed and is additionally the least developed country in the western hemisphere. In 2003, 80% of all Haitians were poor (54% living in abject poverty) and 47.1% were illiterate. The country of nine million people also has a fast growing population, but over two-thirds of the labor force lack formal jobs. Haiti's per capita GDP (PPP) was $1,300 in 2008, or less than one-sixth of the Dominican figure.

As a result, hundreds of thousands of Haitians have migrated to the Dominican Republic, with some estimates of 800,000 Haitians in the country, while others put the Haitian-born population as high as one million. They usually work at low-paying and unskilled jobs in building construction and house cleaning and in sugar plantations. There have been accusations that some Haitian immigrants work in slavery-like conditions and are severely exploited.

Due to the lack of basic amenities and medical facilities in Haiti a large number of Haitian women, often arriving with several health problems, cross the border to Dominican soil. They deliberately come during their last weeks of pregnancy to obtain medical attention for childbirth, since Dominican public hospitals do not refuse medical services based on nationality or legal status. Statistics from a hospital in Santo Domingo report that over 22% of childbirths are by Haitian mothers.

Haiti also suffers from severe environmental degradation. Deforestation is rampant in Haiti; today less than 4 percent of Haiti's forests remain, and in many places the soil has eroded right down to the bedrock. Haitians burn wood charcoal for 60% of their domestic energy production. Because of Haiti running out of plant material to burn, some Haitian bootleggers have created an illegal market for charcoal on the Dominican side. Conservative estimates calculate the illegal movement of 115 tons of charcoal per week from the Dominican Republic to Haiti. Dominican officials estimate that at least 10 trucks per week are crossing the border loaded with charcoal.

In 2005, Dominican President Leonel Fernández criticized collective expulsions of Haitians as having taken place "in an abusive and inhuman way." After a UN delegation issued a preliminary report stating that it found a profound problem of racism and discrimination against people of Haitian origin, Dominican Foreign Minister Carlos Morales Troncoso issued a formal statement denouncing it, asserting that "our border with Haiti has its problems[;] this is our reality and it must be understood. It is important not to confuse national sovereignty with indifference, and not to confuse security with xenophobia."

The children of Haitian immigrants are eligible for Haitian nationality, are denied it by Haiti because of a lack of proper documents or witnesses.

The first of three late-20th century emigration waves began in 1961 after the assassination of dictator Trujillo, due to fear of retaliation by Trujillo's allies and political uncertainty in general. In 1965 the United States began a military occupation of the Dominican Republic to end a civil war. Upon this, the U.S. eased travel restrictions, making it easier for Dominicans to obtain U.S. visas. From 1966 to 1978, the exodus continued, fueled by high unemployment and political repression. Communities established by the first wave of immigrants to the U.S. created a network that assisted subsequent arrivals.

In the early 1980s, underemployment, inflation, and the rise in value of the dollar all contributed to a third wave of emigration from the Dominican Republic. Today, emigration from the Dominican Republic remains high. In 2012 there were approximately 1.7 million people of Dominican descent in the U.S., counting both native- and foreign-born. There was also a growing Dominican immigration to Puerto Rico, with nearly 70,000 Dominicans living there . Although that number is slowly decreasing and immigration trends have reversed because of Puerto Rico's economic crisis .

In 2007 the Dominican Republic had a birth rate of 22.91 per 1000 and a death rate of 5.32 per 1000. Youth in the Dominican Republic is the healthiest age group.

See Health in the Dominican Republic

Primary education is regulated by the Ministry of Education, with education being a right of all citizens and youth in the Dominican Republic.

Preschool education is organized in different cycles and serves the 2–4 age group and the 4–6 age group. Preschool education is not mandatory except for the last year. Basic education is compulsory and serves the population of the 6–14 age group. Secondary education is not compulsory, although it is the duty of the state to offer it for free. It caters to the 14–18 age group and is organized in a common core of four years and three modes of two years of study that are offered in three different options: general or academic, vocational (industrial, agricultural, and services), and artistic.

The higher education system consists of institutes and universities. The institutes offer courses of a higher technical level. The universities offer technical careers, undergraduate and graduate; these are regulated by the Ministry of Higher Education, Science and Technology.

In 2012 the Dominican Republic had a murder rate of 22.1 per 100,000 population. There was a total of 2,268 murders in the Dominican Republic in 2012.

The Dominican Republic has become a trans-shipment point for Colombian drugs destined for Europe as well as the United States and Canada. Money-laundering via the Dominican Republic is favored by Colombian drug cartels for the ease of illicit financial transactions. In 2004 it was estimated that 8% of all cocaine smuggled into the United States had come through the Dominican Republic. The Dominican Republic responded with increased efforts to seize drug shipments, arrest and extradite those involved, and combat money-laundering.

The often light treatment of violent criminals has been a continuous source of local controversy. In April 2010, five teenagers, aged 15 to 17, shot and killed two taxi drivers and killed another five by forcing them to drink drain-cleaning acid. On September 24, 2010, the teens were sentenced to prison terms of three to five years, despite the protests of the taxi drivers' families.

Due to cultural syncretism, the culture and customs of the Dominican people have a European cultural basis, influenced by both African and native Taíno elements, although endogenous elements have emerged within Dominican culture; culturally the Dominican Republic is among the most-European countries in Spanish America, alongside Puerto Rico, Cuba, Central Chile, Argentina, and Uruguay. Spanish institutions in the colonial era were able to predominate in the Dominican culture's making-of as a relative success in the acculturation and cultural assimilation of African slaves diminished African cultural influence in comparison to other Caribbean countries.

Music and sport are of great importance in the Dominican culture, with Merengue and Bachata as the national dance and music, and baseball as the favorite sport.

Dominican art is perhaps most commonly associated with the bright, vibrant colors and images that are sold in every tourist gift shop across the country. However, the country has a long history of fine art that goes back to the middle of the 1800s when the country became independent and the beginnings of a national art scene emerged.

Historically, the painting of this time were centered around images connected to national independence, historical scenes, portraits but also landscapes and images of still life. Styles of painting ranged between neoclassicism and romanticism. Between 1920 and 1940 the art scene was influenced by styles of realism and impressionism. Dominican artists were focused on breaking from previous, academic styles in order to develop more independent and individual styles.

The architecture in the Dominican Republic represents a complex blend of diverse cultures. The deep influence of the European colonists is the most evident throughout the country. Characterized by ornate designs and baroque structures, the style can best be seen in the capital city of Santo Domingo, which is home to the first cathedral, castle, monastery, and fortress in all of the Americas, located in the city's Colonial Zone, an area declared as a World Heritage Site by UNESCO. The designs carry over into the villas and buildings throughout the country. It can also be observed on buildings that contain stucco exteriors, arched doors and windows, and red tiled roofs.

The indigenous peoples of the Dominican Republic have also had a significant influence on the architecture of the country. The Taíno people relied heavily on the mahogany and guano (dried palm tree leaf) to put together crafts, artwork, furniture, and houses. Utilizing mud, thatched roofs, and mahogany trees, they gave buildings and the furniture inside a natural look, seamlessly blending in with the island's surroundings.

Lately, with the rise in tourism and increasing popularity as a Caribbean vacation destination, architects in the Dominican Republic have now begun to incorporate cutting-edge designs that emphasize luxury. In many ways an architectural playground, villas and hotels implement new styles, while offering new takes on the old. This new style is characterized by simplified, angular corners and large windows that blend outdoor and indoor spaces. As with the culture as a whole, contemporary architects embrace the Dominican Republic's rich history and various cultures to create something new. Surveying modern villas, one can find any combination of the three major styles: a villa may contain angular, modernist building construction, Spanish Colonial-style arched windows, and a traditional Taino hammock in the bedroom balcony.

Dominican cuisine is predominantly , Taíno, and African. The typical cuisine is quite similar to what can be found in other Latin American countries. One breakfast dish consists of eggs and "mangú" (mashed, boiled plantain). Heartier versions of "mangú" are accompanied by deep-fried meat (Dominican salami, typically), cheese, or both. Lunch, generally the largest and most important meal of the day, usually consists of rice, meat, beans, and salad. "La Bandera" (literally "The Flag") is the most popular lunch dish; it consists of meat and red beans on white rice. "Sancocho" is a stew often made with seven varieties of meat.
Meals tend to favor meats and starches over dairy products and vegetables. Many dishes are made with "sofrito", which is a mix of local herbs used as a wet rub for meats and sautéed to bring out all of a dish's flavors. Throughout the south-central coast, bulgur, or whole wheat, is a main ingredient in "quipes" or "tipili" (bulgur salad). Other favorite Dominican foods include "chicharrón", "yuca", "casabe", "pastelitos" (empanadas), "batata", yam, "pasteles en hoja", "chimichurris", and "tostones".

Some treats Dominicans enjoy are "arroz con leche" (or "arroz con dulce"), "bizcocho dominicano" (lit. Dominican cake), "habichuelas con dulce", flan, "frío frío" (snow cones), dulce de leche, and "caña" (sugarcane). The beverages Dominicans enjoy are "Morir Soñando", rum, beer, "Mama Juana", "batida" (smoothie), jugos naturales (freshly squeezed fruit juices), "mabí", coffee, and "chaca" (also called "maiz caqueao/casqueado", "maiz con dulce" and "maiz con leche"), the last item being found only in the southern provinces of the country such as San Juan.

Musically, the Dominican Republic is known for the world popular musical style and genre called "merengue", a type of lively, fast-paced rhythm and dance music consisting of a tempo of about 120 to 160 beats per minute (though it varies) based on musical elements like drums, brass, chorded instruments, and accordion, as well as some elements unique to the Spanish-speaking Caribbean, such as the "tambora" and "güira".

Its syncopated beats use Latin percussion, brass instruments, bass, and piano or keyboard. Between 1937 and 1950 merengue music was promoted internationally by Dominican groups like Billo's Caracas Boys, Chapuseaux and Damiron "Los Reyes del Merengue," Joseito Mateo, and others. Radio, television, and international media popularized it further. Some well known merengue performers are Wilfrido Vargas, Johnny Ventura, singer-songwriter Los Hermanos Rosario, Juan Luis Guerra, Fernando Villalona, Eddy Herrera, Sergio Vargas, Toño Rosario, Milly Quezada, and Chichí Peralta.

Merengue became popular in the United States, mostly on the East Coast, during the 1980s and 1990s, when many Dominican artists residing in the U.S. (particularly New York) started performing in the Latin club scene and gained radio airplay. They included Victor Roque y La Gran Manzana, Henry Hierro, Zacarias Ferreira, Aventura, and Milly Jocelyn Y Los Vecinos. The emergence of "bachata", along with an increase in the number of Dominicans living among other Latino groups in New York, New Jersey, and Florida, has contributed to Dominican music's overall growth in popularity.

Bachata, a form of music and dance that originated in the countryside and rural marginal neighborhoods of the Dominican Republic, has become quite popular in recent years. Its subjects are often romantic; especially prevalent are tales of heartbreak and sadness. In fact, the original name for the genre was "amargue" ("bitterness," or "bitter music,"), until the rather ambiguous (and mood-neutral) term "bachata" became popular. Bachata grew out of, and is still closely related to, the pan-Latin American romantic style called "bolero". Over time, it has been influenced by merengue and by a variety of Latin American guitar styles.

Palo is an Afro-Dominican sacred music that can be found throughout the island. The drum and human voice are the principal instruments. Palo is played at religious ceremonies—usually coinciding with saints' religious feast days—as well as for secular parties and special occasions. Its roots are in the Congo region of central-west Africa, but it is mixed with European influences in the melodies.

Salsa music has had a great deal of popularity in the country. During the late 1960s Dominican musicians like Johnny Pacheco, creator of the Fania All Stars, played a significant role in the development and popularization of the genre.

Dominican rock is also popular. Many, if not the majority, of its performers are based in Santo Domingo and Santiago.

The country boasts one of the ten most important design schools in the region, La Escuela de Diseño de Altos de Chavón, which is making the country a key player in the world of fashion and design. Noted fashion designer Oscar de la Renta was born in the Dominican Republic in 1932, and became a US citizen in 1971. He studied under the leading Spaniard designer Cristóbal Balenciaga and then worked with the house of Lanvin in Paris. By 1963, he had designs bearing his own label. After establishing himself in the US, de la Renta opened boutiques across the country. His work blends French and Spaniard fashion with American styles. Although he settled in New York, de la Renta also marketed his work in Latin America, where it became very popular, and remained active in his native Dominican Republic, where his charitable activities and personal achievements earned him the Juan Pablo Duarte Order of Merit and the Order of Cristóbal Colón. De la Renta died of complications from cancer on October 20, 2014.

Some of the Dominican Republic's important symbols are the flag, the coat of arms, and the national anthem, titled "Himno Nacional". The flag has a large white cross that divides it into four quarters. Two quarters are red and two are blue. Red represents the blood shed by the liberators. Blue expresses God's protection over the nation. The white cross symbolizes the struggle of the liberators to bequeath future generations a free nation. An alternative interpretation is that blue represents the ideals of progress and liberty, whereas white symbolizes peace and unity among Dominicans.

In the center of the cross is the Dominican coat of arms, in the same colors as the national flag. The coat of arms pictures a red, white, and blue flag-draped shield with a Bible, a gold cross, and arrows; the shield is surrounded by an olive branch (on the left) and a palm branch (on the right). The Bible traditionally represents the truth and the light. The gold cross symbolizes the redemption from slavery, and the arrows symbolize the noble soldiers and their proud military. A blue ribbon above the shield reads, "Dios, Patria, Libertad" (meaning "God, Fatherland, Liberty"). A red ribbon under the shield reads, "República Dominicana" (meaning "Dominican Republic"). Out of all the flags in the world, the depiction of a Bible is unique to the Dominican flag.

The national flower is the Bayahibe Rose and the national tree is the West Indian Mahogany. The national bird is the "Cigua Palmera" or Palmchat ("Dulus dominicus").

The Dominican Republic celebrates Dia de la Altagracia on January 21 in honor of its patroness, Duarte's Day on January 26 in honor of one of its founding fathers, Independence Day on February 27, Restoration Day on August 16, "Virgen de las Mercedes" on September 24, and Constitution Day on November 6.

Baseball is by far the most popular sport in the Dominican Republic. The country has a baseball league of six teams. Its season usually begins in October and ends in January. After the United States, the Dominican Republic has the second highest number of Major League Baseball (MLB) players. Ozzie Virgil, Sr. became the first Dominican-born player in the MLB on September 23, 1956. Juan Marichal, Pedro Martínez, and Vladimir Guerrero are the only Dominican-born players in the Baseball Hall of Fame. Other notable baseball players born in the Dominican Republic are José Bautista, Adrián Beltré, George Bell, Robinson Canó, Rico Carty, Bartolo Colón, Nelson Cruz, Edwin Encarnación, Ubaldo Jiménez, Francisco Liriano, David Ortiz, Plácido Polanco, Albert Pujols, Hanley Ramírez, Manny Ramírez, José Reyes, Sammy Sosa, and Miguel Tejada. Felipe Alou has also enjoyed success as a manager and Omar Minaya as a general manager. In 2013, the Dominican team went undefeated "en route" to winning the World Baseball Classic.

In boxing, the country has produced scores of world-class fighters and several world champions, such as Carlos Cruz, his brother Leo, Juan Guzman, and Joan Guzman. Basketball also enjoys a relatively high level of popularity. Tito Horford, his son Al, Felipe Lopez, and Francisco Garcia are among the Dominican-born players currently or formerly in the National Basketball Association (NBA). Olympic gold medalist and world champion hurdler Félix Sánchez hails from the Dominican Republic, as does NFL defensive end Luis Castillo.

Other important sports are volleyball, introduced in 1916 by U.S. Marines and controlled by the Dominican Volleyball Federation, taekwondo, in which Gabriel Mercedes won an Olympic silver medal in 2008, and judo.





</doc>
<doc id="8062" url="https://en.wikipedia.org/wiki?curid=8062" title="Deutsches Institut für Normung">
Deutsches Institut für Normung

Founded in 1917 as the ' (NADI, "Standardisation Committee of German Industry"), the NADI was renamed ' (DNA, "German Standardisation Committee") in 1926 to reflect that the organization now dealt with standardization issues in many fields; viz., not just for industrial products. In 1975 it was renamed again to "", or 'DIN' and is recognized by the German government as the official national-standards body, representing German interests at the international and European levels.

The acronym, 'DIN' is often incorrectly expanded as ' ("German Industry Standard"). This is largely due to the historic origin of the DIN as "NADI". The NADI indeed published their standards as ' ('). For example, the first published standard was " (about tapered pins) in 1918. Many people still mistakenly associate DIN with the old ' naming convention.

One of the earliest, and probably the best known, is DIN 476 — the standard that introduced the A-series paper sizes in 1922 — adopted in 1975 as International Standard ISO 216. Common examples in modern technology include DIN and mini-DIN connectors for electronics, and the DIN rail.

The designation of a DIN standard shows its origin (# denotes a number):





</doc>
<doc id="8063" url="https://en.wikipedia.org/wiki?curid=8063" title="History of the Dominican Republic">
History of the Dominican Republic

The recorded history of the Dominican Republic began when the Genoa-born navigator Christopher Columbus, working for the Spanish Crown, happened upon a large island in the region of the western Atlantic Ocean that later came to be known as the Caribbean. It was inhabited by the Taíno, an Arawakan people, who variously called their island Ayiti, Bohio, or Quisqueya (Kiskeya). Columbus promptly claimed the island for the Spanish Crown, naming it La Isla Española ("the Spanish Island"), later Latinized to Hispaniola. What would become the Dominican Republic was the Spanish Captaincy General of Santo Domingo until 1821, except for a time as a French colony from 1795 to 1809. It was then part of a unified Hispaniola with Haiti from 1822 until 1844. In 1844, Dominican independence was proclaimed and the republic, which was often known as Santo Domingo until the early 20th century, maintained its independence except for a short Spanish occupation from 1861 to 1865 and occupation by the United States from 1916 to 1924.

The Taíno people called the island "Quisqueya" (mother of all lands) and "Ayiti" (land of high mountains). At the time of Columbus' arrival in 1492, the island's territory consisted of five chiefdoms: Marién, Maguá, Maguana, Jaragua, and Higüey. These were ruled respectively by "caciques" Guacanagarix, Guarionex, Caonabo, Bohechío, and Cayacoa.

Christopher Columbus reached the island of Hispañola on his first voyage, in December 1492. On Columbus' second voyage in 1493, the colony of La Isabela was built on the northeast shore. Isabela nearly failed because of hunger and disease. In 1496 Santo Domingo was built and became the new capital. Here the New World's first cathedral was erected, and for a few decades, Santo Domingo was also the administrative heart of the expanding empire. Before they embarked on their prosperous endeavors, men like Hernán Cortés and Francisco Pizarro lived and worked in Santo Domingo.

Caonabo, the cacique, (leader or chief), of Maguana, one of five Taino geographical divisions on Hispaniola, attacked Columbus on January 13, 1493. Shooting arrows and wounding a few Spaniards, the Tainos halted the invaders' collection of provisions for Columbus's return trip to Spain. Caonabo struck again when his forces attacked and burned a fort built by Columbus, killing forty Spaniards. During the last trip of Christopher Columbus, in 1495, the Taino leader Guarionex, supported by Caonabo and other Taino leaders, staged the battle of La Vega Real against the Spanish in 1495. But while more than ten thousand Tainos fought against the Spanish, they succumbed to the power of the Spanish weaponry.

When Guarionex attacked the Spanish again, in 1497, both he and Caonabo were caught by the Spanish and both shipped to Spain; on the journey Caonabo died—according to legend, of rage—and Guarionex drowned. His wife, Anacaona, moved to the Xaragua division, where her brother, Bohechio, was cacique. After Bohechio's death, she became cacique and subsequently extended refuge and assistance to runaway enslaved Tainos and Africans.

100,000 Tainos died from 1494–96, half of them by their own hand through self-starvation, poison, leaps from cliffs, etc. The conquistador-turned-priest Bartolomé de las Casas wrote an eyewitness history of the Spanish incursion into the island of Hispaniola that reported the conquistadors' almost feral misconduct:
Hundreds of thousands of Tainos living on the island were enslaved to work in gold mines. As a consequence of disease, forced labor, famine, and mass killings, by 1508, only 60,000 were still alive. In 1501, the Spanish monarchs, Ferdinand I and Isabella, first granted permission to the colonists of the Caribbean to import African slaves, who began arriving to the island in 1503. The first enslaved blacks were purchased in Lisbon, Portugal. Some had been transported there from the West African Guinea coast, and others had been born and raised in Portugal or Spain. Southern Spain and Portugal were multiethnic and multiracial regions long before the “discovery” of the New World, and many Africans, free and enslaved, participated in the Iberian Peninsula's conquest and colonization of the Americas.

In 1510, the first sizable shipment, consisting of 250 Black Ladinos, arrived in Hispaniola from Spain. Eight years later African-born slaves arrived in the West Indies. Many of the Africans brutally jammed into the slave ships had been the losers in Africa's endemic and endless wars. Others were kidnapped from the coast or taken from villages inland. The Colony of Santo Domingo was organized as the Royal Audiencia of Santo Domingo in 1511. Sugar cane was introduced to Hispaniola from the Canary Islands, and the first sugar mill in the New World was established in 1516, on Hispaniola. The need for a labor force to meet the growing demands of sugar cane cultivation led to an exponential increase in the importation of slaves over the following two decades. The sugar mill owners soon formed a new colonial elite and convinced the Spanish king to allow them to elect the members of the Real Audiencia from their ranks. Poorer colonists subsisted by hunting the herds of wild cattle that roamed throughout the island and selling their hides. The enslaved population numbered between twenty and thirty thousand in the mid-sixteenth century and included mine, plantation, cattle ranch, and domestic laborers. A small Spanish ruling class of about twelve hundred monopolized political and economic power, and it used "ordenanzas" (laws) and violence to control the population of color.

In 1517, a guerrilla war between the colonizers and Taino and African forces was initiated by the Taino leader Enriquillo. Descending from the Bahoruco Mountains with his troops, Enriquillo killed Spaniards, devastated farms and property, and took Africans back with him. The crown appointed General , a veteran of many battles in Spain, as captain to lead the war against Enriquillo. Barrionuevo opted to negotiate, realizing that violence had not worked and that resources for more armed actions were scarce. In 1533 he met Enriquillo on what is today's Cabrito Island, in the middle of Lake Jaragua (now Enriquillo Lake) and reached a peace agreement that granted Enriquillo and his troops freedom and land.

The first known armed rebellion of enslaved Africans occurred in 1521. On Christmas Eve two hundred enslaved workers fled the plantation of Diego Columbus, located on the Isabela River near Santo Domingo, and headed south toward Azua. Others from plantations in Nigua, San Cristóbal, and Baní joined them on the march, burning plantations and killing several Spaniards. According to official records, they stopped next at the Ocoa plantation, with the intention of killing more whites and recruiting more enslaved blacks and Indians, then moved on to Azua. After being informed of the insurrection, Columbus recruited a small army, which, mounted on horseback and shouting their battle cry “Santiago,” headed south in pursuit. In the meantime, the rebels entered the plantation of Melchor de Castro near the Nizao River where they killed one Spaniard, sacked the house, and freed more enslaved persons, including Indians. Columbus's army confronted the rebels at the Nizao, the Spanish shooting at them with guns and the rebels responding by throwing stones and logs. Five days later the Spanish attacked again. They caught several rebels, whom they executed by lynching along the colonial road, but many more had escaped to face later attacks, in which more were killed or apprehended.

By the mid-sixteenth century, there were an estimated seven thousand maroons (runaway slaves) beyond Spanish control on Hispaniola. The Bahoruco Mountains were their main area of concentration, although Africans had escaped to other areas of the island as well. From their refuges, they descended to attack the Spanish. In 1546 the slave Diego de Guzman led an insurrection that swept through the San Juan de la Maguana area, after which he escaped to the Bahoruco Mountains. After his capture, de Guzman was savagely killed and some of his fellow rebels were burned alive, others burned with branding irons, others hung, and others had their feet cut off. The most extended insurrection was led by Sebastián Lemba. For fifteen years Lemba attacked Spanish towns, plantations, and farms with an army of four hundred Africans. Lemba was eventually caught and was executed in 1548. His head was mounted on the door that connected the Fort of San Gil (today Fort Ozama) to Fort Conde, and for centuries it was called “the Lemba door.” Insurrections continued to burden the colony's tranquility and economy. From 1548 to the end of the sixteenth century, maroons attacked farms, plantations, and villages. By 1560 the colony was unable to recruit and pay troops to pursue the rebels.

While sugar cane dramatically increased Spain's earnings on the island, large numbers of the newly imported slaves fled into the nearly impassable mountain ranges in the island's interior, joining the growing communities of "cimarrónes"—literally, 'wild animals'. By the 1530s, "cimarrón" bands had become so numerous that in rural areas the Spaniards could only safely travel outside their plantations in large armed groups. Beginning in the 1520s, the Caribbean Sea was raided by increasingly numerous French pirates. In 1541 Spain authorized the construction of Santo Domingo's fortified wall, and in 1560 decided to restrict sea travel to enormous, well-armed convoys. In another move, which would destroy Hispaniola's sugar industry, in 1561 Havana, more strategically located in relation to the Gulf Stream, was selected as the designated stopping point for the merchant "flotas," which had a royal monopoly on commerce with the Americas. In 1564, the island's main inland cities Santiago de los Caballeros and Concepción de la Vega were destroyed by an earthquake. In the 1560s English pirates joined the French in regularly raiding Spanish shipping in the Americas.

With the conquest of the American mainland, Hispaniola quickly declined. Most Spanish colonists left for the silver-mines of Mexico and Peru, while new immigrants from Spain bypassed the island. Agriculture dwindled, new imports of slaves ceased, and white colonists, free blacks, and slaves alike lived in poverty, weakening the racial hierarchy and aiding "intermixing," resulting in a population of predominantly mixed Spaniard, African, and Taíno descent. Except for the city of Santo Domingo, which managed to maintain some legal exports, Dominican ports were forced to rely on contraband trade, which, along with livestock, became the sole source of livelihood for the island dwellers.

In 1586, Sir Francis Drake captured the city of Santo Domingo, collecting a ransom for its return to Spanish rule. A third of the city lay in ruins and almost all of its civic, military and religious buildings had been either damaged or destroyed. During his occupation of Santo Domingo, Drake sent a black boy with a message to the governor. A Hidalgo who was standing by considered this an insult and ran the boy through with his sword. The English commander, infuriated, proceeded to the spot where the murder had been committed and had two friars hanged. He told the governor that he would hang two more friars every day until the murderer had been executed. The murderer was hanged by his own countrymen.

In 1592, Christopher Newport attacked the town of Azua on the bay of Ocoa, which was taken and plundered. In 1595 the Spanish, frustrated by the twenty-year rebellion of their Dutch subjects, closed their home ports to rebel shipping from the Netherlands cutting them off from the critical salt supplies necessary for their herring industry. The Dutch responded by sourcing new salt supplies from Spanish America where colonists were more than happy to trade. So large numbers of Dutch traders/pirates joined their English and French brethren on the Spanish main.

In 1605, Spain was infuriated that Spanish settlements on the northern and western coasts of the island were carrying out large scale and illegal trade with the Dutch, who were at that time fighting a war of independence against Spain in Europe, and the English, a very recent enemy state, and so decided to forcibly resettle their inhabitants closer to the city of Santo Domingo. This action, known as the "Devastaciones de Osorio", proved disastrous; more than half of the resettled colonists died of starvation or disease, over 100,000 cattle were abandoned, and many slaves escaped. Five of the existing thirteen settlements on the island were brutally razed by Spanish troops – many of the inhabitants fought, escaped to the jungle, or fled to the safety of passing Dutch ships. The settlements of La Yaguana, and Bayaja, on the west and north coasts respectively of modern-day Haiti were burned, as were the settlements of Monte Cristi and Puerto Plata on the north coast and San Juan de la Maguana in the southwestern area of the modern-day Dominican Republic.

The withdrawal of the colonial government from the northern coastal region opened the way for French buccaneers, who had a base on Tortuga Island, off the northwest coast of present-day Haiti, to settle on Hispaniola in the mid-seventeenth century. Although the Spanish destroyed the buccaneers' settlements several times, the determined French would not be deterred or expelled. The creation of the French West India Company in 1664 signalled France's intention to colonize western Hispaniola. Intermittent warfare went on between French and Spanish settlers over the next three decades; however, Spain, hard-pressed by warfare in Europe, could not maintain a garrison in Santo Domingo sufficient to secure the entire island against encroachment. In 1697, under the Treaty of Ryswick, Spain ceded the western third of the island to France.

In 1655, Oliver Cromwell dispatched a fleet, commanded by Admiral Sir William Penn, to conquer Santo Domingo. A Spanish defending force of perhaps 400–600 men, mostly militia, repulsed a landing force of 9,000 men. Yet although the English had failed to overrun the island, they nevertheless seized nearby Jamaica, and other foreign strongholds subsequently began multiplying throughout the West Indies. Madrid sought to contest such encroachments by using Santo Domingo as an advance military base, but Spanish power was by now too depleted to expel the rival colonies. The city itself was furthermore subjected to a smallpox epidemic, cacao blight, and hurricane in 1666; another storm two years later; a second epidemic in 1669; a third hurricane in September 1672; plus an earthquake in May 1673 that killed two dozen residents.

During this seventeenth “century of misery,” the Spanish on Hispaniola continued to persecute maroons living peacefully in the island's interior mountains and valleys. With little to show for it, this policy of armed harassment added more public expense to a weak colonial economy, and the financial recovery of the Spanish colony in the eighteenth century led to increased slave insurrections and marronage.

The House of Bourbon replaced the House of Habsburg in Spain in 1700 and introduced economic reforms that gradually began to revive trade in Santo Domingo. The crown progressively relaxed the rigid controls and restrictions on commerce between Spain and the colonies and among the colonies. The last "flotas" sailed in 1737; the monopoly port system was abolished shortly thereafter. By the middle of the century, the population was bolstered by emigration from the Canary Islands, resettling the northern part of the colony and planting tobacco in the Cibao Valley, and importation of slaves was renewed. The population of Santo Domingo grew from about 6,000 in 1737 to approximately 125,000 in 1790. Of this number, about 40,000 were white landowners, about 25,000 were mulatto freedmen, and some 60,000 were slaves. However, it remained poor and neglected, particularly in contrast with its western, French neighbor Saint-Domingue, which became the wealthiest colony in the New World and had half a million inhabitants. The 'Spanish' settlers, whose blood by now was mixed with that of Tainos, Africans and Canary Guanches, said to themselves: 'It does not matter if the French are richer than us, we are still the true inheritors of this island. In our veins runs the blood of the heroic "conquistadores" who won this island of ours with sword and blood.'

When the War of Jenkins' Ear between Spain and Britain broke out in 1739, Spanish privateers, particularly from Santo Domingo, began to troll the Caribbean Sea, a development that lasted until the end of the eighteenth century. During this period, Spanish privateers from Santo Domingo sailed into enemy ports looking for ships to plunder, thus harming commerce with Britain and New York. As a result, the Spanish obtained stolen merchandise—foodstuffs, ships, enslaved persons—that were sold in Hispaniola's ports, with profits accruing to individual sea raiders. These practices of human traffic and terror facilitated capital accumulation. The revenue acquired in these acts of piracy was invested in the economic expansion of the colony and led to repopulation from Europe.

Dominicans constituted one of the many diverse units which fought alongside Spanish forces under Bernardo de Gálvez during the conquest of British West Florida (1779–81).

As restrictions on colonial trade were relaxed, the colonial elites of St. Domingue offered the principal market for Santo Domingo's exports of beef, hides, mahogany, and tobacco. With the outbreak of the Haitian Revolution in 1791, the rich urban families linked to the colonial bureaucracy fled the island, while most of the rural "hateros" (cattle ranchers) remained, even though they lost their principal market. Although the population of Spanish Santo Domingo was perhaps one-fourth that of French Saint-Domingue, this did not prevent the Spanish king from launching an invasion of the French side of the island in 1793, attempting to take advantage of the chaos sparked by the French Revolution. French forces checked Spanish progress toward Port-au-Prince in the south, but the Spanish pushed rapidly through the north, most of which they occupied by 1794.

Although the Spanish military effort went well on Hispaniola, it did not so in Europe. The Spanish colony was ceded first to France in 1795 as part of the Treaty of Basel between the defeated Spanish and the French, then it was invaded by the British in 1796. Five years later, black slaves in rebellion invaded from Saint-Domingue. The devastated Spanish-speaking colony was then occupied by the French in 1802, in spite of the dramatic defeat of Napoleon's forces at the hands of the former French slaves who proclaimed the independent Republic of Haiti in 1804. Santo Domingo was invaded again by Haitians in 1805 and then yet again by the British in 1809. The Spanish reclaimed it later that year but found the colony in economic ruins and demographic decline.

The population of the new Spanish colony stood at approximately 104,000. Of this number, about 30,000 were slaves, and the rest a mixture of white, Indian, and black. The European Spaniards were few, and consisted principally of Catalans. In 1812, a group of blacks and mulattoes staged a rebellion, with the goal of annexation to the Republic of Haiti. On August 15 and 16, mulattoes José Leocadio, Pedro Seda, and Pedro Henriquez, with other conspirators, attacked the Mendoza hacienda in Mojarra in the municipality of Guerra near the capital. Seda and Henriquez were apprehended and executed; Leocadio was captured within days, hanged, dismembered, and boiled in oil. A year later enslaved laborers in the rural community El Chavón also rebelled, but they were quickly caught and executed.

Spain's hold over Santo Domingo remained precarious. The arrival of the fugitive Simón Bolívar and his followers in Haiti in 1815 alarmed the Spanish authorities in Santo Domingo. Following the rebellion of the Army in Spain during 1820, which restored the liberal constitution, some of the colonial administrators in Santo Domingo broke with the mother country; and on December 1, 1821, the Spanish Lieutenant Governor, José Núñez de Cáceres, proclaimed the independence of "Spanish Haiti."

Dominican leaders—recognizing their vulnerability both to Spanish and to Haitian attack and also seeking to maintain their slaves as property—attempted to annex themselves to Gran Colombia. While this request was in transit, Jean-Pierre Boyer, the ruler of Haiti, invaded Santo Domingo on February 9 with a 10,000-man army. Having no capacity to resist, Núñez de Cáceres surrendered the capital on February 9, 1822.

The twenty-two-year Haitian occupation that followed is recalled by Dominicans as a period of brutal military rule, though the reality is more complex. It led to large-scale land expropriations and failed efforts to force production of export crops, impose military services, restrict the use of the Spanish language, and eliminate traditional customs such as cockfighting. It reinforced Dominicans' perceptions of themselves as different from Haitians in "language, race, religion and domestic customs." Yet, this was also a period that definitively ended slavery as an institution in the eastern part of the island.

Haiti's constitution forbade whites from owning land, and the major landowning families were forcibly deprived of their properties. Most emigrated to the Spanish colonies of Cuba and Puerto Rico, or to independent Gran Colombia, usually with the encouragement of Haitian officials, who acquired their lands. The Haitians, who associated the Catholic Church with the French slave-masters who had exploited them before independence, confiscated all church property, deported all foreign clergy, and severed the ties of the remaining clergy to the Vatican. Santo Domingo’s university, the oldest in the Western Hemisphere, lacking students, teachers, and resources, closed down. In order to receive diplomatic recognition from France, Haiti was forced to pay an indemnity of 150 million francs to the former French colonists, which was subsequently lowered to 60 million francs, and Haiti imposed heavy taxes on the eastern part of the island. Since Haiti was unable to adequately provision its army, the occupying forces largely survived by commandeering or confiscating food and supplies at gunpoint.

Attempts to redistribute land conflicted with the system of communal land tenure ("terrenos comuneros"), which had arisen with the ranching economy, and newly emancipated slaves resented being forced to grow cash crops under Boyer's "Code Rural". In rural areas, the Haitian administration was usually too inefficient to enforce its own laws. It was in the city of Santo Domingo that the effects of the occupation were most acutely felt, and it was there that the movement for independence originated.

On July 16, 1838, Juan Pablo Duarte together with , Juan Isidro Pérez, Felipe Alfau, Benito González, Félix María Ruiz, Juan Nepumoceno Ravelo and Jacinto de la Concha founded a secret society called "La Trinitaria" to win independence from Haiti. A short time later, they were joined by Ramón Matías Mella, and Francisco del Rosario Sánchez. In 1843 they allied with a Haitian movement in overthrowing Boyer. Because they had revealed themselves as revolutionaries working for Dominican independence, the new Haitian president, Charles Rivière-Hérard, exiled or imprisoned the leading "Trinitarios" (Trinitarians). At the same time, Buenaventura Báez, an Azua mahogany exporter and deputy in the Haitian National Assembly, was negotiating with the French Consul-General for the establishment of a French protectorate. In an uprising timed to preempt Báez, on February 27, 1844, the Trinitarios declared independence from Haiti, backed by Pedro Santana, a wealthy cattle-rancher from El Seibo who commanded a private army of peons who worked on his estates.

The Dominican Republic's first constitution was adopted on November 6, 1844. The state was commonly known as Santo Domingo in English until the early 20th century. It featured a presidential form of government with many liberal tendencies, but it was marred by Article 210, imposed by Pedro Santana on the constitutional assembly by force, giving him the privileges of a dictatorship until the war of independence was over. These privileges not only served him to win the war but also allowed him to persecute, execute and drive into exile his political opponents, among which Duarte was the most important. In Haiti after the fall of Boyer, black leaders had ascended to the power once enjoyed exclusively by the mulatto elite.
Hérard sent three columns of Haitian troops, each numbering 10,000 men, to reestablish his authority. In the south, Santana defeated Hérard at the Battle of Azua on March 19. Dominican forces suffered no casualties in the battle, while the Haitians sustained over 300 casualties. In the north, Dominican Gen. José María Imbert defeated the Haitian column led by Jean-Louis Pierrot at the Battle of Santiago. Over 600 Haitians were killed while the Dominicans suffered no casualties. Events at sea also went poorly for the Haitians. Three Dominican schooners under the command of Juan Bautista Cambiaso intercepted a Haitian brigantine and two schooners which were bombarding shore targets. In the ensuing engagement, all three Haitian vessels were sunk, ensuring Dominican naval superiority for the rest of the war. On August 6, 1845, the new Haitian president, Luis Pierrot, launched a new invasion. On September 17, Dominican Gen. José Joaquín Puello defeated the Haitian vanguard near the frontier at Estrelleta where the Dominican "square" repulsed with bayonets a Haitian cavalry charge. The Dominicans suffered no deaths during the battle and only three wounded. On September 27, 1845, Dominican Gen. Francisco Antonio Salcedo defeated the Haitian army at the Battle of Beler. Salcedo was supported by Adm. Juan Bautista Cambiaso's squadron of three schooners, which blockaded the Haitian port of Cap-Haïtien. Haitian losses were 350 killed and 10 captured; the Dominicans lost 16 killed.

Santana used the ever-present threat of Haitian invasion as a justification for consolidating dictatorial powers. For the Dominican elite—mostly landowners, merchants and priests—the threat of re-annexation by more populous Haiti was sufficient to seek protection from a foreign power. Offering the deepwater harbor of Samaná bay as bait, over the next two decades, negotiations were made with Britain, France, the United States and Spain to declare a protectorate over the country.

The constant threat and fear of renewed Haitian intervention required all men of fighting age to take up arms in defense against the Haitian military. Theoretically, fighting age was generally defined as between fifteen and eighteen years of age to forty or fifty years. Despite wide, popular glorification of military service, many in the ranks of the Liberation Army were mutinous and desertion rates were high despite penalties as severe as death for shirking the obligation of military service.

Without adequate roads, the regions of the Dominican Republic developed in isolation from one another. In the south, the economy was dominated by cattle-ranching (particularly in the southeastern savannah) and cutting mahogany and other hardwoods for export. This region retained a semi-feudal character, with little commercial agriculture, the "hacienda" as the dominant social unit, and the majority of the population living at a subsistence level. In the Cibao Valley, the nation's richest farmland, peasants supplemented their subsistence crops by growing tobacco for export, mainly to Germany. Tobacco required less land than cattle ranching and was mainly grown by smallholders, who relied on itinerant traders to transport their crops to Puerto Plata and Monte Cristi. Santana antagonized the Cibao farmers, enriching himself and his supporters at their expense by resorting to multiple peso printings that allowed him to buy their crops for a fraction of their value. In 1848, he was forced to resign and was succeeded by his vice-president, Manuel Jimenes.

After returning to lead Dominican forces against a new Haitian invasion in 1849, Santana marched on Santo Domingo, deposing Jimenes. At his behest, Congress elected Buenaventura Báez as President, but Báez was unwilling to serve as Santana's puppet, challenging his role as the country's acknowledged military leader. Báez determined to take the offensive against Haiti. His seamen under the French adventurer, Fagalde, raided the Haitian coasts, plundered seaside villages, as far as Cape Dame Marie, and butchered crews of captured enemy ships. In 1853 Santana was elected president for his second term, forcing Báez into exile. Three years later, after repulsing the last Haitian invasion, he negotiated a treaty leasing a portion of Samaná Peninsula to a U.S. company; popular opposition forced him to abdicate, enabling Báez to return and seize power. With the treasury depleted, Báez printed eighteen million uninsured pesos, purchasing the 1857 tobacco crop with this currency and exporting it for hard cash at immense profit to himself and his followers. The Cibanian tobacco planters, who were ruined when inflation ensued, revolted, recalling Santana from exile to lead their rebellion. After a year of civil war, Santana seized Santo Domingo and installed himself as president.

In 1860, a group of Americans tried unsuccessfully to take over the small Dominican island of Alto Velo off the southwestern border coast of Hispaniola.

Pedro Santana inherited a bankrupt government on the brink of collapse. Having failed in his initial bids to secure annexation by the U.S. or France, Santana initiated negotiations with Queen Isabella II of Spain and the Captain-General of Cuba to have the island reconverted into a Spanish colony. The American Civil War rendered the United States incapable of enforcing the Monroe Doctrine. In Spain, Prime Minister Don Leopoldo O'Donnell advocated renewed colonial expansion, waging a campaign in northern Morocco that conquered the city of Tetuan. In March 1861, Santana officially restored the Dominican Republic to Spain. 

Santana initially was named Capitan-General of the new Spanish province, but it soon became obvious that Spanish authorities planned to deprive him of his power, leading him to resign in 1862. Restrictions on trade, discrimination against the mulatto majority, and an unpopular campaign by the new Spanish Archbishop, Bienvenido Monzón, against extramarital unions, which were widespread after decades of abandonment by the Catholic Church, all fed resentment of Spanish rule.

Monzón also persecuted Freemasons, whose activities were widespread before the annexation, barring them from communion until they canted their vows and gave up their Masonic documents and practices. Monzón actively persecuted Protestants as well. Protestant churches in Samaná and Santo Domingo were taken over, burned, or confiscated for military purposes, forcing many Dominican Protestants to consider moving to Haiti in search of religious toleration.

On August 16, 1863, a national war of restoration began in Santiago, where the rebels established a provisional government. “Before God, the entire world, and the throne of Castile, just and legal reasons have obliged us to take arms to restore the Dominican Republic and reconquer our liberty,” the provisional government's declaration of independence read. Dominicans were divided. Some fought for the reserve forces alongside Spanish troops. Santana returned to lead them.

The Spanish forces of the Cibao valley were obliged to concentrate in Fort San Luis, at Santiago, where they were besieged by the insurgents. The rebels had possession of three forts which face the Puerto Plata road. They undertook to make a general assault on the fort where the Spanish troops were concentrated. The besieged forces let the enemy's bands come near, and when within musket range opened a tremendous fire of artillery, which, committing great destruction, drove them back in disorder. They, however, tried their luck again, and this time set fire to the houses of the town in different parts and made their attack in the midst of the conflagration. Spanish reinforcements arrived and charged the insurgents, who received them with grapeshot and musketry from the three forts which they held. The insurgents were repulsed and the forts retaken at the point of the bayonet. The garrison of Santiago abandoned the city and marched to Puerto Plata, the main northern port, attacked by Dominicans all the way. The Spaniards reportedly lost 1,300 men. They joined the garrison in the fort at Puerto Plata, leaving the city to be pillaged by the rebels. Eventually, 600 Spanish sallied out and drove off the rebels, with help from the cannon of the fort, but by then the city had been plundered and burnt almost out of existence. The damage to Santiago and Puerto Plata was estimated at $5,000,000. By mid-November, virtually the whole garrisons of Cuba and Puerto Rico were deployed on Santo Domingo and 8,000 troops had been sent from Europe, diverted from deployment in Morocco. The Spanish navy had complete command of the sea and used a fleet of paddle wheel steamers to transport troops to, and around, the island.

As the fighting continued, racist incidents became more acute. Spanish soldiers were openly hostile to Dominicans of color, and incidents of unprovoked violence against black Dominicans and migrants in the towns proliferated. Perhaps because of the fright that Spain would seek to make Santo Domingo an enslaved twin of Cuba, Dominicans were said to fight like “supernatural fiends” with a “desperate” intensity. By early 1864, the Spanish army, unable to contain guerrilla resistance, had suffered 1,000 killed in action and 9,000 dead from disease. Spanish colonial authorities encouraged Queen Isabella II to abandon the island, seeing the occupation as a nonsensical waste of troops and money. However, the rebels were in a state of political disarray and proved unable to present a cohesive set of demands. The first president of the provisional government, Pepillo Salcedo (allied with Báez) was deposed by General in September 1864, who, in turn, was deposed by General Antonio Pimentel three months later. The rebels formalized their provisional rule by holding a national convention in February 1865, which enacted a new constitution, but the new government exerted little authority over the various regional guerrilla "caudillos", who were largely independent of one another.

Unable to extract concessions from the disorganized rebels, when the American Civil War ended, in March 1865, Queen Isabella annulled the annexation and independence was restored, with the last Spanish troops departing by July. More than 7,000 Dominicans perished in battles and epidemics. Relations between the Dominican Republic and Haiti were tense once the new Dominican government came to power since Haitian President Fabre Geffrard had refused to support the independence movement out of fear of Spanish reprisals. Within three years after fighting ended in Santo Domingo, uprisings began in both remaining Spanish colonies. In both islands, Dominican veterans joined the independence fight. Within the decade, Spanish colonialism began to crumble, and rebels won emancipation.

By the time the Spanish departed, most of the main towns lay in ruins and the island was divided among several dozen "caudillos". José María Cabral controlled most of Barahona and the southwest with the support of Báez's mahogany-exporting partners, while cattle rancher Cesáreo Guillermo assembled a coalition of former "Santanista" generals in the southeast, and Gregorio Luperón controlled the north coast. Once the Spanish were vanquished, the numerous military and guerrilla leaders began to fight among themselves. From the Spanish withdrawal to 1879, there were twenty-one changes of government and at least fifty military uprisings. Haiti served as a haven for Dominican political exiles and a base of operations for insurgents, often with the support of the Haitian government, during the frequent civil wars and revolutions of the period.

In the course of these conflicts, two parties emerged. The Partido Rojo (Literally "Red Party") represented the southern cattle ranching latifundia and mahogany-exporting interests, as well as the artisans and laborers of Santo Domingo, and was dominated by Báez, who continued to seek annexation by a foreign power. The Partido Azul (literally "Blue Party"), led by Luperón, represented the tobacco farmers and merchants of the Cibao and Puerto Plata and was nationalist and liberal in orientation. During these wars, the small and corrupt national army was far outnumbered by militias organized and maintained by local "caudillos" who set themselves up as provincial governors. These militias were filled out by poor farmers or landless plantation workers impressed into service who usually took up banditry when not fighting in revolution.

Within a month of the nationalist victory, Cabral, whose troops were the first to enter Santo Domingo, ousted Pimentel, but a few weeks later General Guillermo led a rebellion in support of Báez, forcing Cabral to resign and allowing Báez to retake the presidency in October. Báez was overthrown by the Cibao farmers under Luperón, leader of the Partido Azul, the following spring, but Luperón's allies turned on each other and Cabral reinstalled himself as president in a coup in 1867. After bringing several "Azules" ("Blues") into his cabinet the "Rojos" ("Reds") revolted, returning Báez to power. In 1869, Báez negotiated a treaty of annexation with the United States. Supported by U.S. Secretary of State William Seward, who hoped to establish a Navy base at Samaná, in 1871 the treaty was defeated in the United States Senate through the efforts of abolitionist Senator Charles Sumner.

In 1874, the "Rojo" governor of Puerto Plata, Ignacio Maria González Santín, staged a coup in support of an "Azul" rebellion but was deposed by the "Azules" two years later. In February 1876, Ulises Espaillat, backed by Luperón, was named President, but ten months later troops loyal to Báez returned him to power. One year a new rebellion allowed González to seize power, only to be deposed by Cesáreo Guillermo in September 1878, who was in turn deposed by Luperón in December 1879. Ruling the country from his hometown of Puerto Plata, enjoying an economic boom due to increased tobacco exports to Germany, Luperón enacted a new constitution setting a two-year presidential term limit and providing for direct elections, suspended the semi-formal system of bribes and initiated construction on the nation's first railroad, linking the town of La Vega with the port of Sánchez on Samaná Bay.

The Ten Years' War in Cuba brought Cuban sugar planters to the country in search of new lands and security from the insurrection that freed their slaves and destroyed their property. Most settled in the southeastern coastal plain, and, with assistance from Luperón’s government, built the nation's first mechanized sugar mills. They were later joined by Italians, Germans, Puerto Ricans and Americans in forming the nucleus of the Dominican sugar bourgeoisie, marrying into prominent families to solidify their social position. Disruptions in global production caused by the Ten Years' War, the American Civil War and the Franco-Prussian War allowed the Dominican Republic to become a major sugar exporter. Over the following two decades, sugar surpassed tobacco as the leading export, with the former fishing hamlets of San Pedro de Macorís and La Romana transformed into thriving ports. To meet their need for better transportation, over 300 miles of private rail-lines were built by and serving the sugar plantations by 1897. An 1884 slump in prices led to a wage freeze, and a subsequent labor shortage was filled by migrant workers from the Leeward Islands—the Virgin Islands, St. Kitts and Nevis, Anguilla, and Antigua (referred to by Dominicans as "cocolo"s). These English-speaking blacks were often victims of racism, but many remained in the country, finding work as stevedores and in railroad construction and sugar refineries.

Puerto Ricans were imported to work under near-slave conditions on Puerto Rican-owned sugar plantations in the Dominican Republic, in the area of La Romana, during the nineteenth century. Others worked in coffee fields. Arabs began to arrive in the Dominican Republic during the latter part of the nineteenth century. They were widely accused of being dirty and of having bad manners and habits, and the government was reproached for having allowed these immigrants into the nation. Since upper-class Dominicans refused to give membership to wealthy Arabs to their private clubs like the exclusive Club de Unión, the Arabs created their own.

Allying with the emerging sugar interests, the dictatorship of General Ulises Heureaux, who was popularly known as Lilís, brought unprecedented stability to the island through an iron-fisted rule that lasted almost two decades. The son of a Haitian father and a mother from St. Thomas, Virgin Islands, Lilís was distinguished by his blackness from most Dominican political leaders, with the exception of Luperón. He served as President 1882–1883, 1887, and 1889–1899, wielding power through a series of puppet presidents when not occupying the office. Incorporating both "Rojos" and "Azules" into his government, he developed an extensive network of spies and informants to crush potential opposition. His government undertook a number of major infrastructure projects, including the electrification of Santo Domingo, the beginning of telephone and telegraph service, the construction of a bridge over the Ozama River, and the completion of a single-track railroad linking Santiago and Puerto Plata, financed by the Amsterdam-based Westendorp Co.

Lilís's dictatorship was dependent upon heavy borrowing from European and American banks to enrich himself, stabilize the existing debt, strengthen the bribe system, pay for the army, finance infrastructural development and help set up sugar mills. However, sugar prices underwent a steep decline in the last two decades of the 19th century. When the Westendorp Co. went bankrupt in 1893, he was forced to mortgage the nation's customs fees, the main source of government revenues, to a New York financial firm called the San Domingo Improvement Co. (SDIC), which took over its railroad contracts and the claims of its European bondholders in exchange for two loans, one of $1.2 million and the other of £2 million. As the growing public debt made it impossible to maintain his political machine, Heureaux relied on secret loans from the SDIC, sugar planters and local merchants. In 1897, with his government virtually bankrupt, Lilís printed five million uninsured pesos, known as "papeletas de Lilís", ruining most Dominican merchants and inspiring a conspiracy that ended in his death. In 1899, when Lilís was assassinated by the Cibao tobacco merchants whom he had been begging for a loan, the national debt was over $35 million, fifteen times the annual budget.

The six years after Lilís's death witnessed four revolutions and five different presidents. The Cibao politicians who had conspired against Heureaux—Juan Isidro Jimenes, the nation's wealthiest tobacco planter, and General Horacio Vásquez—after being named President and Vice-President, quickly fell out over the division of spoils among their supporters, the "Jimenistas" and "Horacistas". Troops loyal to Vásquez overthrew Jimenes in 1903, but Vásquez was deposed by Jimenista General Alejandro Woss y Gil, who seized power for himself. The Jimenistas toppled his government, but their leader, Carlos Morales, refused to return power to Jimenes, allying with the Horacistas, and he soon faced a new revolt by his betrayed Jimenista allies.

In 1904, American warships bombarded insurgents in Santo Domingo for insulting the United States flag and damaging an American steamer.

With the nation on the brink of defaulting, France, Germany, Italy and the Netherlands sent warships to Santo Domingo to press the claims of their nationals. In order to preempt military intervention, United States president Theodore Roosevelt introduced the Roosevelt Corollary to the Monroe Doctrine, declaring that the United States would assume responsibility for ensuring that the nations of Latin America met their financial obligations. In January 1905, under this corollary, the United States assumed administration of the Dominican Republic's customs. Under the terms of this agreement, a Receiver-General, appointed by the U.S. President, kept 55% of total revenues to pay off foreign claimants, while remitting 45% to the Dominican government. After two years, the nation's external debt was reduced from $40 million to $17 million. In 1907, this agreement was converted into a treaty, transferring control over customs receivership to the U.S. Bureau of Insular Affairs and providing a loan of $20 million from a New York bank as payment for outstanding claims, making the United States the Dominican Republic's only foreign creditor. In 1905, the Dominican Peso was replaced by the U.S. Dollar.

In 1906, Morales resigned, and Horacista vice-president Ramon Cáceres became president. After suppressing a rebellion in the northwest by Jimenista General Desiderio Arias, his government brought political stability and renewed economic growth, aided by new American investment in the sugar industry. However, his assassination in 1911, for which Morales and Arias were at least indirectly responsible, once again plunged the republic into chaos. For two months, executive power was held by a civilian junta dominated by the chief of the army, General Alfredo Victoria. The surplus of more than 4 million pesos left by Cáceres was quickly spent to suppress a series of insurrections. He forced Congress to elect his uncle, Eladio Victoria, as President, but the latter was soon replaced by the neutral Archbishop Adolfo Nouel. After four months, Nouel resigned and was succeeded by Horacista Congressman José Bordas Valdez, who aligned with Arias and the Jimenistas to maintain power. In 1913, Vásquez returned from exile in Puerto Rico to lead a new rebellion. In June 1914 U.S. President Woodrow Wilson issued an ultimatum for the two sides to end hostilities and agree on a new president, or have the United States impose one. After the provisional presidency of Ramón Báez Machado, Jimenes was elected in October, and soon faced new demands, including the appointment of an American director of public works and financial advisor and the creation of a new military force commanded by U.S. officers. The Dominican Congress rejected these demands and began impeachment proceedings against Jimenes. The United States occupied Haiti in July 1915, with the implicit threat that the Dominican Republic might be next. Jimenes's Minister of War Desiderio Arias staged a coup d'état in April 1916, providing a pretext for the United States to occupy the Dominican Republic.

United States Marines landed in Santo Domingo on May 15, 1916. Prior to their landing, Jimenes resigned, refusing to exercise an office 'regained with foreign bullets'. On June 1, Marines occupied Monte Cristi and Puerto Plata. They occupied Monte Cristi without meeting resistance, but at Puerto Plata they had to fight their way into the city under heavy but inaccurate fire from about 500 pro-Arias irregulars. During this landing the Marines sustained several casualties, including the death of Captain Herbert J. Hirshinger, the first Marine killed in combat in the Dominican campaign. Insurgent losses, while never accurately determined, were light.

A column of Marines under Colonel Joseph H. Pendleton marched toward Santiago de los Caballeros, where rebel forces had established a government. Along the way, Dominicans tore up the railroad tracks, forcing Marines to walk. They also burned bridges, delaying the march. Twenty-four miles into the march, the Marines encountered Las Trencheras, two fortified ridges the Dominicans had long thought invulnerable: the Spanish had been defeated there in 1864. At 08:00 hours on June 27, Pendleton ordered his artillery to pound the ridgeline. Machine guns offered covering fire. A bayonet attack cleared the first ridge. Rifle fire removed the rebels who were threatening from atop the second. The significance of this battle lies in the fact that this was the first experience of Marines advancing with the support of modern artillery and machine guns.

A week later, the Marines encountered another entrenched rebel force at Guayacanas. The rebels kept up single-shot fire against the automatic weapons of the Marines before the Marines drove them off. The battle was important in the history of the 4th Marines insofar as the regiment subsequently acquired its first Medal of Honor recipient. First Sergeant Roswell Winans, while manning his machine gun, displayed such exceptional valor that he was later awarded the nation's highest military honor. Sergeant Winans obtained his award for the bravado that he demonstrated when for a time he single-handedly raked enemy lines with his weapon. Then, when the gun jammed, he set about clearing it in full view of the Dominicans without regard to his personal safety. With his supporters defeated, Arias surrendered on July 5 in exchange for being pardoned.

At San Francisco de Macorís, Governor Juan Pérez, a supporter of Arias, refused to recognize the U.S. military government. Using some 300 released prisoners, he was preparing to defend the old Spanish colonial structure, the "Fortazela". On November 29 U.S. Marine Lt. Ernest C. Williams, whose detachment was billeted in San Francisco, charged the closing gates of the fort at nightfall with a dozen Marines. Eight were shot down; the others, including Williams, forced their way in and seized the old structure. Another Marine detachment seized the police station. Reinforcements from nearby detachments soon suppressed the uprising. The Marine Corps' subsequent efforts at “state-building,” as it is commonly known today, received little assistance from Dominicans. Dominican elites, animated by nationalist resentment of the takeover of their country, refused to help the foreigners restructure their government and society.

The Dominican Congress elected Dr. Francisco Henríquez y Carvajal as President, but in November, after he refused to meet the U.S. demands, Wilson announced the imposition of a U.S. military government, with Rear Admiral Harry Shepard Knapp as Military Governor. The American military government implemented many of the institutional reforms carried out in the United States during the Progressive Era, including reorganization of the tax system, accounting and administration, expansion of primary education, the creation of a nationwide police force to unify the country, and the construction of a national system of roads, including a highway linking Santiago to Santo Domingo.

Despite the reforms, virtually all Dominicans resented the loss of their sovereignty to foreigners, few of whom spoke Spanish or displayed much real concern for the nation's welfare, and the military government, unable to win the backing of any prominent Dominican political leaders, imposed strict censorship laws and imprisoned critics of the occupation. In 1920, U.S. authorities enacted a Land Registration Act, which broke up the "terrenos comuneros" and dispossessed thousands of peasants who lacked formal titles to the lands they occupied, while legalizing false titles held by the sugar companies. In the southeast, dispossessed peasants formed armed bands, called "gavilleros", waging a guerrilla war that lasted six years, with most of the fighting in Hato Mayor and El Seibo. At any given time, the Marines faced eight to twelve such bands each composed of several hundred followers. The guerrillas benefited from a superior knowledge of the terrain and the support of the local population, and the Marines relied on increasingly brutal counterinsurgency methods. However, rivalries between various gavilleros often led them to fight against one another, and even cooperate with occupation authorities. In addition, cultural schisms between the "campesinos" (i.e. rural people, or peasants) and city dwellers prevented the guerrillas from cooperating with the urban middle-class nationalist movement.

The most notorious rebel of Seibo was a daring Dominican bandit with the nom de guerre of Vicentico Evangelista. In March 1917 he brutally executed two American civilians, engineers from an American-owned plantation, who were lashed to trees, savagely hacked with machetes, then left dangling for ravenous wild boars. He led Marine pursuers on a merry chase before surrendering on July 5 of that year. Two days later Vicentico was shot and killed by Marines “while trying to escape.” On August 13, 1918, a five-man Marine patrol was ambushed near Manchado; four Marines were killed and the survivor wounded. By 1919 the Marines had received radios that made it easier to coordinate their efforts and six Curtiss “Jenny” biplanes that allowed them to expand the reach of their patrolling and even to bomb some guerrilla outposts. The unrest in the eastern provinces lasted until 1922 when the guerrillas finally agreed to surrender in return for amnesty. During the course of the campaign between 1916 and 1922, the Marines claim to have killed or wounded 1,137 “bandits,” while 20 Marines were killed and 67 wounded. (Forty U.S. sailors died separately when a hurricane wrecked their ship on Santo Domingo's rocky shore.)

In the San Juan valley, near the border with Haïti, followers of a Vodu faith healer named Liborio resisted the occupation and aided the Haitian "cacos" in their war against the Americans, until his death in 1922. When the Haitian and Dominican forces began to fight the U.S. interventions, they suffered immensely due to the superiority of U.S. training and technology. They were poorly armed and a "minority of them carried old-model black-powder rifles; the majority went into battle with swords, machetes, and pikes." The obsolete weapons as well as the lack of training and institutional control over the regional armed forces ensured American military preeminence in the region.
In what was referred to as "la danza de los millones", with the destruction of European sugar-beet farms during World War I, sugar prices rose to their highest level in history, from $5.50 in 1914 to $22.50 per pound in 1920. Dominican sugar exports increased from 122,642 tons in 1916 to 158,803 tons in 1920, earning a record $45.3 million. However, European beet sugar production quickly recovered, which, coupled with the growth of global sugar cane production, glutted the world market, causing prices to plummet to only $2.00 by the end of 1921. This crisis drove many of the local sugar planters into bankruptcy, allowing large U.S. conglomerates to dominate the sugar industry. By 1926, only twenty-one major estates remained, occupying an estimated . Of these, twelve U.S.-owned companies owned more than 81% of this total area. While the foreign planters who had built the sugar industry integrated into Dominican society, these corporations expatriated their profits to the United States. As prices declined, sugar estates increasingly relied on Haitian laborers. This was facilitated by the military government's introduction of regulated contract labor, the growth of sugar production in the southwest, near the Haitian border, and a series of strikes by "cocolo" cane cutters organized by the Universal Negro Improvement Association.

In the 1920 United States presidential election Republican candidate Warren Harding criticized the occupation and promised eventual U.S. withdrawal. While Jimenes and Vásquez sought concessions from the United States, the collapse of sugar prices discredited the military government and gave rise to a new nationalist political organization, the Dominican National Union, led by Dr. Henríquez from exile in Santiago de Cuba, Cuba, which demanded unconditional withdrawal. They formed alliances with frustrated nationalists in Puerto Rico and Cuba, as well as critics of the occupation in the United States itself, most notably "The Nation" and the Haiti-San Domingo Independence Society. In May 1922, a Dominican lawyer, Francisco Peynado, went to Washington, D.C. and negotiated what became known as the Hughes–Peynado Plan. It stipulated the immediate establishment of a provisional government pending elections, approval of all laws enacted by the U.S. military government, and the continuation of the 1907 treaty until all the Dominican Republic's foreign debts had been settled. On October 1, Juan Bautista Vicini, the son of a wealthy Italian immigrant sugar planter, was named provisional president, and the process of U.S. withdrawal began. The principal legacy of the occupation was the creation of a National Police Force, used by the Marines to help fight against the various guerrillas, and later the main vehicle for the rise of Rafael Trujillo.

In contrast to the much romanticized fighting of the Rough Riders at San Juan Hill in Cuba almost two decades earlier, the Marines' anti-rebel campaigns in the Dominican Republic were hot, often godlessly uncomfortable, and largely devoid of heroism and glory.

The occupation ended in 1924, with a democratically elected government under president Vásquez. The Vásquez administration brought great social and economic prosperity to the country and respected political and civil rights. Rising export commodity prices and government borrowing allowed the funding of public works projects and the expansion and modernization of Santo Domingo.

Though considered to be a relatively principled man, Vásquez had risen amid many years of political infighting. In a move directed against his chief opponent Federico Velasquez, in 1927 Vásquez agreed to have his term extended from four to six years. The change was approved by the Dominican Congress, but was of debatable legality; "its enactment effectively invalidated the constitution of 1924 that Vásquez had previously sworn to uphold." Vásquez also removed the prohibition against presidential reelection and postulated himself for another term in elections to be held in May 1930. However, his actions had by then led to doubts that the contest could be fair. Furthermore, these elections took place amid economic problems, as the Great Depression had dropped sugar prices to less than one dollar per pound.

In February, a revolution was proclaimed in Santiago by a lawyer named Rafael Estrella Ureña. When the commander of the "Guardia Nacional Dominicana" (the new designation of the armed force created under the Occupation), Rafael Leonidas Trujillo Molina, ordered his troops to remain in their barracks, the sick and aging Vásquez was forced into exile and Estrella proclaimed provisional president. In May, Trujillo was elected with 95% of the vote, having used the army to harass and intimidate electoral personnel and potential opponents. After his inauguration in August, at his request, the Dominican Congress proclaimed the beginning of the 'Era of Trujillo'.

Trujillo established absolute political control while promoting economic development—from which mainly he and his supporters benefitted—and severe repression of domestic human rights. Trujillo treated his political party, "El Partido Dominicano" (The Dominican Party), as a rubber-stamp for his decisions. The true source of his power was the "Guardia Nacional"—larger, better armed, and more centrally controlled than any military force in the nation's history. By disbanding the regional militias, the Marines eliminated the main source of potential opposition, giving the Guard "a virtual monopoly on power". By 1940, Dominican military spending was 21% of the national budget. At the same time, he developed an elaborate system of espionage agencies. By the late 1950s, there were at least seven categories of intelligence agencies, spying on each other as well as the public. All citizens were required to carry identification cards and good-conduct passes from the secret police. Obsessed with adulation, Trujillo promoted an extravagant cult of personality. When a hurricane struck Santo Domingo in 1930, killing over 3,000 people, he rebuilt the city and renamed it "Ciudad Trujillo": "Trujillo City"; he also renamed the country's and the Caribbean's highest mountain, Pico Duarte (Duarte Peak), "Pico Trujillo". Over 1,800 statues of Trujillo were built, and all public works projects were required to have a plaque with the inscription 'Era of Trujillo, Benefactor of the Fatherland'.
As sugar estates turned to Haiti for seasonal migrant labor, increasing numbers settled in the Dominican Republic permanently. The census of 1920, conducted by the U.S. occupation government, gave a total of 28,258 Haitians living in the country; by 1935 there were 52,657. In October 1937, Trujillo ordered the massacre of up to 38,000 Haitians, the alleged justification being Haiti's support for Dominican exiles plotting to overthrow his regime. The killings were fuelled by the racism of Dominicans, who also disdained the manual labour which Haitians performed in conditions of near-slavery. This event later became known as the Parsley Massacre because of the story that Dominican soldiers identified Haitians by their inability to pronounce the Spanish word "perejil". Subsequently, during the first half of 1938, thousands more Haitians were forcibly deported and hundreds killed in the southern frontier region.

So that news of the slaughter would not leak out, Trujillo clamped tight censorship on all mail and news dispatches. A shocked American missionary, Father Barnes, wrote about the massacre in a letter to his sister. It never reached her. He was found on the floor of his home, murdered brutally. But the news leaked out, stirring a decision by the United States, Mexico, and Cuba to make a joint investigation. General Hugh Johnson, a former New Deal official, made a national broadcast describing how Haitian women had been stabbed and mutilated, babies bayoneted, and men tied up and thrown into the sea to drown.
The massacre was the result of a new policy which Trujillo called the 'Dominicanisation of the frontier'. Place names along the border were changed from Creole and French to Spanish, the practice of Voodoo was outlawed, quotas were imposed on the percentage of foreign workers that companies could hire, and a law was passed preventing Haitian workers from remaining after the sugar harvest. Another example of repression and prejudice came about a year after Trujillo's death, in December 28, 1962, when the mainly Dominico-Haitian peasant community of Palma Sola, which challenged the racial, political, and economic situation of the country, was bombarded with napalm by the Dominican Air Force.

Although Trujillo sought to emulate Generalissimo Francisco Franco, he welcomed Spanish Republican refugees following the Spanish Civil War. During the Holocaust in the Second World War, the Dominican Republic took in many Jews fleeing Hitler who had been refused entry by other countries. The Jews settled in Sosua. These decisions arose from a policy of "blanquismo", closely connected with anti-Haitian xenophobia, which sought to add more light-skinned individuals to the Dominican population by promoting immigration from Europe. As part of the Good Neighbor policy, in 1940, the U.S. State Department signed a treaty with Trujillo relinquishing control over the nation's customs. When the Japanese attacked Pearl Harbor Trujillo followed the United States in declaring war on the Axis powers, even though he had openly professed admiration for Hitler and Mussolini. During the Cold War, he maintained close ties to the United States, declaring himself the world's 'Number One Anticommunist' and becoming the first Latin American President to sign a Mutual Defense Assistance Agreement with the United States. One tactical asset of the United States in the Cold War was the missile tracking system established across the region, which comprised a series of individual stations in neighboring countries. One of these stations was located in the Dominican Republic, requiring bilateral negotiations to establish the facility, and cooperation to operate it. The ranks of the U.S. military mission in the Dominican Republic swelled, as aircraft trainers and mechanics joined the attachés of the four service branches and their staffs working at the U.S. embassy. The missile tracking station and the military mission were the strongest Cold War ties between the United States and the Dominican Republic, but they became liabilities as the relationship soured.

Soon after the end of World War II, Trujillo constructed an arms factory at San Cristóbal. It made hand grenades, gunpowder, dynamite, revolvers, automatic rifles, carbines, submachine guns, light machine guns, antitank guns, and munitions. In addition, some quantities of mortars and aerial bombs were produced and light artillery rebuilt. Trujillo's increasingly powerful military withstood a series of invasion attempts by leftist Dominican exiles. On June 19, 1949, an airplane carrying Dominican rebels from Guatemala was intercepted and destroyed by the Dominican coastguard at Luperón on the north coast. Ten years later, on June 14, 1959, Dominican revolutionaries launched three simultaneous attacks. At Estero Hondo and Maimón on the north coast, the rebels followed the Castro tactic of landing from ships, but the Dominican government's air power and artillery overwhelmed the attackers as they landed. At Constanza in the high mountains near the border with Haiti, a small band of armed exiles came by air. On that occasion, the heavy bombers of the Dominican Air Force came into action but were inaccurate, hitting more civilians than guerrillas. It was Dominican peasants who tracked down and captured or killed most of the fugitives, for which they received cash bounties from Trujillo's government.

Trujillo and his family established a near-monopoly over the national economy. By the time of his death, he had accumulated a fortune of around $800 million; he and his family owned 50–60 percent of the arable land, some , and Trujillo-owned businesses accounted for 80% of the commercial activity in the capital. He exploited nationalist sentiment to purchase most of the nation's sugar plantations and refineries from U.S. corporations; operated monopolies on salt, rice, milk, cement, tobacco, coffee, and insurance; owned two large banks, several hotels, port facilities, an airline and shipping line; deducted 10% of all public employees' salaries (ostensibly for his party); and received a portion of prostitution revenues. World War II brought increased demand for Dominican exports, and the 1940s and early 1950s witnessed economic growth and considerable expansion of the national infrastructure. During this period, the capital city was transformed from merely an administrative center to the national center of shipping and industry, although 'it was hardly coincidental that new roads often led to Trujillo's plantations and factories, and new harbors benefited Trujillo's shipping and export enterprises.'

Mismanagement and corruption resulted in major economic problems. By the end of the 1950s, the economy was deteriorating because of a combination of overspending on a festival to celebrate the 25th anniversary of the regime, overspending to purchase privately owned sugar mills and electricity plants, and a decision to make a major investment in state sugar production that proved economically unsuccessful. In 1956, Trujillo's agents in New York murdered Jesús María de Galíndez, a Basque exile who had worked for Trujillo but who later denounced the Trujillo regime and caused public opinion in the United States to turn against Trujillo. In June 1960, Dominican secret police agents in Caracas used a car bomb in a nearly successful attempt to kill President Rómulo Betancourt of Venezuela, who had become the leading voice in the anti-Trujillo chorus, burning him badly. Tracing the attack to Trujillo, the Organization of American States (OAS) imposed sanctions for the first time since its creation in 1946, cutting off shipments of oil, among other things, to the Dominican Republic. Refusing to back down, Trujillo lashed out at Catholic priests who read a pastoral letter from the pulpit asking for merciful treatment of political opponents. One of his last-ditch threats was to ally with the Soviet Union, as he had implied was an option in the past.

A group of Dominican dissidents killed Trujillo in a car chase on the way to his country villa near San Cristóbal on May 30, 1961. The sanctions remained in force after Trujillo's assassination. His son Ramfis took over the presidency and rounded up all the conspirators. They were summarily executed, some of them being fed to sharks. In November 1961, the military plot of the Rebellion of the Pilots forced the Trujillo family into exile, fleeing to France, and the heretofore puppet-president Joaquín Balaguer assumed effective power.

At the insistence of the United States, Balaguer was forced to share power with a seven-member Council of State, established on January 1, 1962, and including moderate members of the opposition. OAS sanctions were lifted January 4, and, after an attempted coup, Balaguer resigned and went into exile on January 16. The reorganized Council of State, under President Rafael Filiberto Bonnelly headed the Dominican government until elections could be held. These elections, in December 1962, were won by Juan Bosch, a scholar and poet who had founded the opposition "Partido Revolucionario Dominicano" (Dominican Revolutionary Party, or PRD) in exile, during the Trujillo years. His leftist policies, including land redistribution, nationalization of certain foreign holdings, and attempts to bring the military under civilian control, antagonized the military officer corps, the Catholic hierarchy, and the upper-class, who feared 'another Cuba'.

The Presidency of Juan Bosch in 1963 led to one of the tensest periods in contemporary Haitian-Dominican relations. Bosch supported the efforts of Haitian exiles who trained to overthrow François Duvalier, Haiti's repressive president. In April 1963, former Haitian army officers reportedly tried to kill Duvalier's children, and many of those accused took refuge in the embassies of Latin American countries in Port-au-Prince, the Haitian capital. When Haitian police raided the Dominican embassy and held captive 22 refugees, the Dominican Republic broke off diplomatic relations and threatened to invade Haiti. The OAS mediated the dispute and eased the tension; Dominican troops, ready to invade, pulled back from the border; and many of the refugees were granted safe conduct out of Haiti. Hostilities erupted again in September that year when both sides shelled each other across the border. The OAS again intervened to make peace.

In September 1963 Bosch was overthrown by a right-wing military coup led by Colonel Elías Wessin and was replaced by a three-man military junta. Bosch went into exile to Puerto Rico. Afterwards, a supposedly civilian triumvirate established a de facto dictatorship.

On April 16, 1965, growing dissatisfaction generated another military rebellion on April 24, 1965 that demanded Bosch's restoration. The insurgents, reformist officers and civilian combatants loyal to Bosch commanded by Colonel Francisco Caamaño, and who called themselves the Constitutionalists, staged a coup, seizing the national palace. Immediately, conservative military forces, led by Wessin and calling themselves Loyalists, struck back with tank assaults and aerial bombings against Santo Domingo. A few days of upheaval saw heavy fighting in the streets of the city and a pitched battle fought on the main bridge across the Ozama River, where civilians used guns supplied by their military allies to repulse the tank corps loyal to the military government, preventing it from entering the capital.

On April 28, these anti-Bosch army elements requested U.S. military intervention and U.S. forces landed, ostensibly to protect U.S. citizens and to evacuate U.S. and other foreign nationals. U.S. President Lyndon B. Johnson, convinced of the defeat of the Loyalist forces and fearing the creation of "a second Cuba" on America's doorstep, ordered U.S. forces to restore order. In what was initially known as Operation Power Pack, 27,677 U.S. troops were ultimately ordered to the Dominican Republic. The 4th Marine Expeditionary Force and the army's 82nd Airborne Division spearheaded the occupation. Psychological Warfare and Special Forces units also took part in the action.

Denied a military victory, the Constitutionalist rebels quickly had a Constitutionalist congress elect Caamaño president of the country. U.S. officials countered by backing General Antonio Imbert. On May 7, Imbert was sworn in as president of the Government of National Reconstruction. The next step in the stabilization process, as envisioned by Washington and the OAS, was to arrange an agreement between President Caamaño and President Imbert to form a provisional government committed to early elections. However, Caamaño refused to meet with Imbert until several of the Loyalist officers, including Wessin y Wessin, were made to leave the country. On 13 May General Imbert launched an eight-day offensive to eliminate rebel resistance north of the line of communications. During the attack, U.S. troops shot down one of the new government's five P-51 Mustangs when it accidentally strafed their position. Imbert’s forces took the northern part of the capital, destroying many buildings and killing many black civilians. The United Nations dispatched a human rights team to investigate alleged atrocities.

By May 14 the Americans had established a "safety corridor" connecting the San Isidro Air Base and the "Duarte" Bridge to the Embajador Hotel and United States Embassy in the center of Santo Domingo, essentially sealing off the Constitutionalist area of Santo Domingo. Roadblocks were established and patrols ran continuously. Some 6,500 people from many nations were evacuated to safety. In addition, the US forces airlifted in relief supplies for Dominican nationals.

By mid-May, a majority of the OAS voted for Operation “Push Ahead”, the reduction of United States forces and their replacement by an Inter-American Peace Force (IAPF). The Inter-American Peace Force was formally established on May 23. The following troops were sent by each country: Brazil – 1,130, Honduras – 250, Paraguay – 184, Nicaragua – 160, Costa Rica – 21 military police, and El Salvador – 3 staff officers. The first contingent to arrive was a rifle company from Honduras which was soon backed by detachments from Costa Rica, El Salvador, and Nicaragua. Brazil provided the largest unit, a reinforced infantry battalion. Brazilian General Hugo Panasco Alvim assumed command of the OAS ground forces, and on 26 May the U.S. forces began to withdraw.

On 15 June the rebels launched their final attempt to escape their Ciudad Nuevo stronghold. Camaaño hurled all his best remaining units and weapons against the American lines, and soon mortar rounds were hitting the 82nd Airborne Division. Although their heaviest weapons were recoilless cannons, the 82nd Airborne soundly defeated the rebels. The fighting cost the U.S. five killed and thirty-one wounded, three of whom later died. The Brazilians, who had orders to remain on the defensive, suffered five wounded.

The mauling the Constitutionalists received on the 15th made them more amenable, but not yet committed, to a negotiated settlement. The fighting continued until August 31, 1965, when a truce was declared. Most American troops left shortly afterwards as policing and peacekeeping operations were turned over to Brazilian troops, but some U.S. military presence remained until September 1966. A total of 44 American soldiers died, 27 in action. 172 were wounded in action, as were six Brazilians and five Paraguayans. An estimated 6,000 to 10,000 Dominicans died, many of them civilians killed when the Dominican Air Force bombed their crowded Santo Domingo neighborhoods prior to the U.S. invasion.

In June 1966, Joaquín Balaguer, leader of the Reformist Party (which later became the Social Christian Reformist Party (PRSC), was elected and then re-elected to office in May 1970 and May 1974, both times after the major opposition parties withdrew late in the campaign because of the high degree of violence by pro-government groups. On November 28, 1966 a constitution was created, signed, and put into effect. The constitution stated that the president was elected to a four-year term. If there was a close election there would be a second round of voting to decide the winner. The voting age was eighteen, but married people under eighteen could also vote.

Remnants of the constitutionalist movement and some scattered groups of the Dominican left started to plan for a revolution and in February 1973 Caamaño suddenly landed on a desolate beach in the southwest. Together with a small group of just ten men he made it for the mountains which they intended to make into a center for a campaign against the government of Balaguer. They were soon traced and hunted down by a party of 2,000 men, while 1,400 political, student and labor leaders were arrested all over the country. After two weeks Caamaño and his men were ambushed between Constanza and San José de Ocoa and there the wounded and captured Francisco Alberto Caamaño Deñó was shot in the head by his captors.

Balaguer led the Dominican Republic through a thorough economic restructuring, based on opening the country to foreign investment while protecting state-owned industries and certain private interests. This distorted, dependent development model produced uneven results. For most of Balaguer's first nine years in office the country experienced high growth rates (e.g., an average GDP growth rate of 9.4 percent between 1970 and 1975), to the extent that people talked about the "Dominican miracle". Foreign, mostly U.S. investment, as well as foreign aid, flowed into the country. Sugar, then the country's main export product, enjoyed good prices in the international market, and tourism grew tremendously.

However, this excellent macroeconomic performance was not accompanied by an equitable distribution of wealth. While a group of new millionaires flourished during Balaguer's administrations, the poor simply became poorer. Moreover, the poor were commonly the target of state repression, and their socioeconomic claims were labeled 'communist' and dealt with accordingly by the state security apparatus. In the May 1978 election, Balaguer was defeated in his bid for a fourth successive term by Antonio Guzmán Fernández of the PRD. Balaguer then ordered troops to storm the election centre and destroy ballot boxes, declaring himself the victor. U.S. President Jimmy Carter refused to recognize Balaguer's claim, and, faced with the loss of foreign aid, Balaguer stepped down.

Guzmán's inauguration on August 16 marked the country's first peaceful transfer of power from one freely elected president to another. By the late 1970s, economic expansion slowed considerably as sugar prices declined and oil prices rose. Rising inflation and unemployment diminished support for the government and helped trigger a wave of mass emigration from the Dominican Republic to New York, coming on the heels of the similar migration of Puerto Ricans in the preceding decades.

Elections were again held in 1982. Salvador Jorge Blanco of the Dominican Revolutionary Party defeated Bosch and a resurgent Balaguer.

Balaguer completed his return to power in 1986 when he won the Presidency again and remained in office for the next ten years. Elections in 1990 were marked by violence and suspected electoral fraud. The 1994 election too saw widespread pre-election violence, often aimed at intimidating members of the opposition. Balaguer won in 1994 but most observers felt the election had been stolen. Under pressure from the United States, Balaguer agreed to hold new elections in 1996. He himself would not run.

In 1996, U.S.-raised Leonel Fernández Reyna of Bosch's "Partido de la Liberación Dominicana" (Dominican Liberation Party) secured more than 51% of the vote, through an alliance with Balaguer. The first item on the president's agenda was the partial sale of some state-owned enterprises. Fernández was praised for ending decades of isolationism and improving ties with other Caribbean countries, but he was criticized for not fighting corruption or alleviating the poverty that affected 60% of the population.

In May 2000 the center-left Hipólito Mejía of the PRD was elected president amid popular discontent over power outages in the recently privatized electric industry. His presidency saw major inflation and instability of the peso in 2003 because of the bankruptcy of three major commercial banks in the country due to the bad policies of the principal managers. During his remaining time as president, he took action to save most savers of the closed banks, avoiding a major crisis. The relatively stable currency fell from about 16 Dominican pesos to 1 United States dollar to about 60 DOP to 1 USD and was in the 40s to the dollar when he left office in August 2004. In the May 2004 presidential elections, he was defeated by former president Leonel Fernández.

Fernández instituted austerity measures to deflate the peso and rescue the country from its economic crisis, and in the first half of 2006, the economy grew 11.7%. The peso is currently at the exchange rate of ~39 DOP to 1 USD.

Over the last three decades, remittances ("remesas") from Dominicans living abroad, mainly in the United States, have become increasingly important to the economy. From 1990 to 2000, the Dominican population of the U.S. doubled in size, from 520,121 in 1990 to 1,041,910, two-thirds of whom were born in the Dominican Republic
itself. More than half of all Dominican Americans live in New York City, with the largest concentration in the neighborhood of Washington Heights in northern Manhattan. Over the past decade, the Dominican Republic has become the largest source of immigration to New York City, and today the metropolitan area of New York has a larger Dominican population than any city except Santo Domingo. Dominican communities have also developed in New Jersey (particularly Paterson), Miami, Boston, Philadelphia, Providence, Rhode Island, and Lawrence, Massachusetts. In addition, tens of thousands of Dominicans and their descendants live in Puerto Rico. Many Dominicans arrive in Puerto Rico illegally by sea across the Mona Passage, some staying and some moving on to the mainland U.S. (See Dominican immigration to Puerto Rico.) Dominicans living abroad sent an estimated $3 billion in remittances to relatives at home, in 2006. In 1997, a new law took effect, allowing Dominicans living abroad to retain their citizenship and vote in presidential elections. President Fernández, who grew up in New York, was the principal beneficiary of this law.

The Dominican Republic was involved in the US-led coalition in Iraq, as part of the Spain-led Latin-American Plus Ultra Brigade. But in 2004, the nation pulled its 300 or so troops out of Iraq.

Danilo Medina began his tenure with a series of controversial tax reforms so as to deal with the government's troublesome fiscal situation encountered by the new administration.





</doc>
<doc id="8064" url="https://en.wikipedia.org/wiki?curid=8064" title="Geography of the Dominican Republic">
Geography of the Dominican Republic

The Dominican Republic (Spanish: "República Dominicana") is a country in the West Indies that occupies the eastern five-eighths of Hispaniola. It has an area of 48,670 km², including offshore islands. The land border shared with Haiti, which occupies the western three-eighths of the island, is 376 km long. The maximum length, east to west, is 390 km from Punta de Agua to Las Lajas, on the border with Haiti. The maximum width, north to south, is 265 km from Cape Isabela to Cape Beata. The capital, Santo Domingo, is located on the south coast.

The Dominican Republic's shores are washed by the Atlantic Ocean to the north and the Caribbean Sea to the south. The Mona Passage, a channel about 130 km wide, separates the country (and Hispaniola) from Puerto Rico.



The country is a tropical, maritime nation. Conditions are ameliorated in many areas by elevation and by the northeast trade winds, which blow steadily from the Atlantic all year long. The annual mean temperature is ; regional mean temperatures range from in the heart of the Cordillera Central (Constanza) to as high as in arid regions. Temperatures rarely rise above , and freezing temperatures only occur in winter in the highest mountains. The average temperature in Santo Domingo in January is , and in July.

The rain season for the northern coast is from November to January. For the rest of the country, the rain season is from May to November. The average annual rainfall is , with extremes of or more in the mountainous northeast (the windward side of the island) and in the southwestern valleys. The western valleys, along the Haitian border, remain relatively dry, with less than of annual precipitation, due to the rain shadow effect caused by the central and northern mountain ranges. The northwestern and southeastern extremes of the country are also arid.

The Dominican Republic is occasionally damaged by tropical storms and hurricanes, which originate in the mid-Atlantic and southeastern Caribbean from June until November (mainly from August to October) each year.

There are several smaller islands and cays that are part of the Dominican territory. The largest islands are:

The Dominican Republic is a country with many mountains, and the highest peaks of the West Indies are found here. The chains of mountains show a direction northwest-southeast, except in the Southern peninsula (in Haiti) where they have a direction west–east. The mountains are separated by valleys with the same general direction.

From north to south, the mountain ranges and valleys are:

The 8 longest rivers of the Dominican Republic are:

The Artibonite River is the longest river of the island but only 68 km are in the Dominican Republic.

The largest lake of the Hispaniola, and of the West Indies, is the "Lake Enriquillo". It is located in the "Hoya de Enriquillo" with an area of 265 km². There are three small islands within the lake. It is around 40 meters below sea level and is a saline lake with a higher concentration of salt than the sea water.

Others lakes are "Rincón" (fresh water, area of 28.2 km²), "Oviedo" (brackish water, area of 28 km²), "Redonda", "Limón".


</doc>
<doc id="8065" url="https://en.wikipedia.org/wiki?curid=8065" title="Demographics of the Dominican Republic">
Demographics of the Dominican Republic

This article is about the demographic features of the population of the Dominican Republic, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.

According to the total population was in , compared to 2,380,000 in 1950. The proportion of the population aged below 15 in 2010 was 31.2%, 62.8% were aged between 15 and 65 years of age, while 6% were aged 65 years or older.
Registration of vital events is not universal in the Dominican Republic. The Population Departement of the United Nations prepared the following estimates:

Structure of the population (01.07.2017) (Estimates) :

Structure of the population (DHS 2013) (Males 19 686, Females 19 878 = 39 564) :

Total Fertility Rate (TFR) (Wanted Fertility Rate) and Crude Birth Rate (CBR):

Demographic statistics according to the World Population Review in 2019.


Demographic statistics according to the CIA World Factbook, unless otherwise indicated.

















definition: age 15 and over can read and write (2016 est.)


Unemployment, youth ages 15-24: 




</doc>
<doc id="8067" url="https://en.wikipedia.org/wiki?curid=8067" title="Economy of the Dominican Republic">
Economy of the Dominican Republic

The Dominican Republic has the 8th largest economy
in Latin America, and is the largest in the Caribbean and Central America region. It is an
upper middle-income developing country primarily dependent on mining, agriculture, trade, and services. The country is the site of the single largest gold mine in Latin America, the Pueblo Viejo mine.
Although the service sector has recently overtaken agriculture as the leading employer of Dominicans (due principally to growth in tourism and free-trade zones), agriculture remains the most important sector in terms of domestic consumption and is in second place (behind mining) in terms of export earnings. Tourism accounts for more than $1 billion in annual earnings. free-trade zone earnings and tourism are the fastest-growing export sectors. According to a 1999 International Monetary Fund report, remittances from Dominican Americans, are estimated to be about $1.5 billion per year. Most of these funds are used to cover basic household needs such as shelter, food, clothing, health care and education. Secondarily, remittances have financed small businesses and other productive activities.

The Dominican Republic’s most important trading partner is the United States (about 40% of total commercial exchange). Other major trade partners are China, Haiti, Canada, Mexico, India, Spain, Brazil, Germany, the United Kingdom and Japan, in that quantitative order. The country exports free-trade-zone manufactured products (garments, medical devices, and so on), gold, nickel, protection equipment, bananas, liquor, cocoa beans, silver, and sauces and seasonings. It imports petroleum, industrial raw materials, capital goods, and foodstuffs. On 5 September 2005, the Congress of the Dominican Republic ratified a free trade agreement with the U.S. and five Central American countries, the Dominican Republic – Central America Free Trade Agreement (CAFTA-DR). CAFTA-DR entered into force for the Dominican Republic on 1 March 2007. The total stock of U.S. foreign direct investment (FDI) in Dominican Republic as of 2006 was U.S. $3.3 billion, much of it directed to the energy and tourism sectors, to free trade zones, and to the telecommunications sector. Remittances were close to $2.7 billion in 2006.

An important aspect of the Dominican economy is the Free Trade Zone industry (FTZ), which made up U.S. $4.55 billion in Dominican exports for 2006 (70% of total exports). Reports show, however, that the FTZs lost approximately 60,000 between 2005 and 2007 and suffered a 4% decrease in total exports in 2006. The textiles sector experienced an approximate 17% drop in exports due in part to the appreciation of the Dominican peso against the dollar, Asian competition following expiration of the quotas of the Multi-Fiber Arrangement, and a government-mandated increase in salaries, which should have occurred in 2005 but was postponed to January 2006. Lost Dominican business was captured by firms in Central America and Asia. The tobacco, jewelry, medical, and pharmaceutical sectors in the FTZs all reported increases for 2006, which somewhat offset textile and garment losses. Industry experts from the FTZs expected that entry into force of the CAFTA-DR agreement will promote substantial growth in the FTZ sector for 2007.

An ongoing concern in the Dominican Republic is the inability of participants in the electricity sector to establish financial viability for the system. Three regional electricity distribution systems were privatized in 1998 via sale of 50% of shares to foreign operators; the Mejía administration repurchased all foreign-owned shares in two of these systems in late 2003. The third, serving the eastern provinces, is operated by U.S. concerns and is 50% U.S.-owned. The World Bank records that electricity distribution losses for 2005 totaled about 38.2%, a rate of losses exceeded in only three other countries. Industry experts estimate distribution losses for 2006 will surpass 40%, primarily due to low collection rates, theft, infrastructure problems and corruption. At the close of 2006, the government had exceeded its budget for electricity subsidies, spending close to U.S. $650 million. The government plans to continue providing subsidies. Congress passed a law in 2007 that criminalizes the act of stealing electricity, but it has not yet been fully implemented. The electricity sector is a highly politicized sector and the prospect of further effective reforms of the electricity sector is poor. Debts in the sector, including government debt, amount to more than U.S. $500 million. Some generating companies are under capitalized and at times unable to purchase adequate fuel supplies.

With almost 80% of the total land area suitable for crop production and about 17% of the labor force engaged in farming, agriculture remains the primary occupation, accounting for 11% of GDP in 2001. Value of agricultural output grew at an average annual rate of 7.1% during 1968–73, but since 1975 the sector has been hampered by droughts (1975, 1977, and 1979), hurricanes (in 1979 and 1980), and slumping world prices and quota allocations for sugar (since 1985). In 1999, agricultural production was 0.4% higher than during 1989–91. The fertile Cibao Valley is the main agricultural center. In 1998, arable land totaled ; with land under permanent crops at .

After Cuba, the Dominican Republic is the second-largest Caribbean producer of sugarcane, the nation's most important crop. The State Sugar Council operates 12 sugar mills and accounts for about half of total production. Other large producers are the privately owned Vicini, with three mills, and Central Romana Corporation, whose mill is the largest in the country. Sugar is grown in the southeastern plains, around Barahona & on the North Coast Plain. In 1999, sugar production was 4.4 million tons, down from an average of 7.1 million tons during 1989–1991. Output of sugar has declined annually since 1982, and land is gradually being taken out of sugar production and switched to food crops. Production of raw sugar rose from 636,000 tons in 1990 to 813,000 tons in 1997 but fell to 374,000 tons in 1999.

Part of the crop was destroyed by hurricanes in 1979 and 1980, and 1979–80 production was only 670,000 bags (40,200 tons). Although production was usually about 57,000–59,000 tons annually in the 1980s, the acreage harvested declined from in the early 1980s to in 1999, indicating a greater yield per acre. Coffee production in 1999 was estimated at 35,000 tons; exports of coffee in 2001 generated $11 million. Cocoa and tobacco are also grown for export. Dominican Republic is one of the top 10 major producer and exporter of cocoa in the world. Cocoa is also grown in the Cibao Valley around San Francisco de Macoris. Tobacco is also grown in the Cibao Valley, but around Santiago. In 1999, production of cocoa beans was 26,000 tons and of tobacco, 35,000 tons. Rice is grown around Monte Cristi & San Francisco de Macoris. Banana production in 1999 was 432,000 tons. Production of other crops in 1999 (in thousands of tons) included rice, 563; coconuts, 184; cassava, 127; tomatoes, 281; pulses, 69; dry beans, 26; eggplants, 7; and peanuts, 2.

In 2001, Dominican livestock included 187,000 goats and 106,000 sheep. There were also about 2.1 million head of cattle, 60% for beef and 40% for dairy. The hog population was decimated by African swine fever, decreasing from 400,000 in 1978 to 20,000 in 1979; by 2001, however, it was 565,000. Poultry is the main meat source because it is cheaper than beef or pork. Poultry production relies on imports of feed grain from the United States. In 2001, 203,000 tons of poultry meat were produced, along with 71,000 tons of beef and 420,000 tons of milk.

Although the waters surrounding the Dominican Republic abound with fish, the fishing industry is comparatively undeveloped, and fish for local consumption are imported. In 1837, the total marine catch was 5 ounces, down from 1 pound in 1798 . Marlin, barracuda, kingfish, mackerel, tuna, sailfish, and tarpon are found in the Monte Cristi Bank and Samaná Bay, which also supports bonito, snapper, and American grouper. The inland catch amounted to 187 tons in 2000.

About 28.4% of the total land area consisted of forests and woodlands in 2000. Roundwood production in 2000 totaled 562,000 cu m (19.8 million cu ft). Virtually all the timber cut is for land clearing and fuel.

Mineral production has stagnated since a slump began in the mid-1980s. In 2000, mining accounted for 2% of GDP, which grew by 7.8%. Mining increased by 9.2%, stimulated by higher output and a higher average price of nickel, the country's most important mineral. Ferronickel was the country's leading export commodity and third-leading industry. Nickel is mined at Bonao. In 2000, nickel production was 39,943 tons, ranking tenth in the world, a decrease from 49,152 in 1997.

Production of gold and silver was suspended in 1999, including at what was, in 1980, the Western Hemisphere's largest gold mine, at Pueblo Viejo. Production was declining by the mid-1980s, so mining of the sulfide zone of the gold ore body was commenced, requiring more extensive processing facilities than had previously existed. Production of gold was 7,651 kg in 1987 and 3,659 in 1996, and of silver, 39,595 kg in 1988 and 17,017 kg in 1996. Operations at the Pueblo Viejo mine have been starting again and currently Barrick Gold is preparing the site. The use of a foreign company for the extraction of gold at the largest mine in the Western Hemisphere has startled and concerned many Dominicans who believe that this gold is Dominican gold and should be extracted by Dominican companies and not foreign. Some groups began to protest against the Barrick Gold in 2009 and 2010.

Production of bauxite, traditionally the principal mining product, ceased in 1992. The Aluminum Co. of America (Alcoa) mined bauxite between 1959 and 1983, when it turned its concession over to the state. Production in 1991 dropped 92% from the previous year, as a presidential decree suspended mining operations at the largest mine, in response to increasing fears of deforestation, although reforestation of mined areas was in progress. Output averaged 1 million tons each year.

The country was one of the few sources of amber in the Western Hemisphere. Salt Mountain, a 16 km block of almost solid salt west of Barahona, was the world's largest known salt deposit. There were also large deposits of gypsum near Salt Mountain, making the Dominican Republic one of three sources of gypsum in the Caribbean. The country also produced hydraulic cement, limestone, marble, and sand and gravel. Substantial lignite deposits were found in the early 1980s. Deposits of copper and platinum are known to exist.

The industrial sector contributed an estimated 32.2 percent to the country's GDP in 1999, led by mining (ferronickel, gold, and silver) and the manufacture of goods for export to the United States. To a lesser extent, there is the manufacture of food products, consumer non-durables, and building materials for the local market and for neighboring Haiti. The sector employed mated 24.3 percent of the workforce in 1998.

About 500 companies in the Dominican Republic manufacture goods primarily for the North American market. Situated in 50 industrial free zones around the country, these mostly foreign-owned corporations take advantage of generous tax and other financial inducements offered by the government to businesses that operate within the zones. Approximately 200,000 people, or about 8 percent of the workforce, are employed in this sector. They mostly produce clothing, electronic components, footwear, and leather goods, which are assembled. The raw materials or semi-manufactured goods are usually imported duty-free from other developing countries (electronic parts are imported from industrialized Puerto Rico) and put together in the free zones. Products created are cosmetics, pharmaceuticals, textiles, perfumes & foodstuffs. The value of exports amounted to US$1.9 billion in 1996, but the contribution to the trade balance was only US$520 million because many of the basic materials for the free zones had to be imported and paid for.

Other, more traditional manufacturing is based on sugar refining, cement, iron and steel production, and food processing. Rum is a significant export commodity, and beer and cigarettes are manufactured for local consumption. Most industry of this sort is located around the working-class perimeter of Santo Domingo and other large towns.

Services were estimated to contribute 64.7% (2012 est.) of the GDP. In 1999 it was estimated to employ around 58.7 percent of the workforce, making this the most important sector of the Dominican economy.

Since the mid-1980s the tourism sector has become one of the country’s most important sources of foreign exchange, and more popular tourist destinations. The country is famous for its favorable location in the Caribbean, tropical climate, beaches, and the restored Spanish colonial architecture. Many foreign investors have and continue to be encouraged to invest here to build and expand resorts and airports around the coasts. During this same period, tourism displaced sugar as the main source of the country's earnings, and by 1997 it was generating more than half of the country's total foreign exchange.

Tourism is the single biggest revenue earner, with receipts increasing more than tenfold from US$173 million in 1980 to more than US$2 billion by 2000. According to the Central Bank, the Dominican Republic received US$4.3 billion in revenues from the tourism sector in 2011. Successive governments have invested heavily in tourism development, creating upgraded airports and other infrastructure. 2.1 million tourists arrived in the country in 1999, not including visiting Dominicans. Most come from Europe, with about 25 percent originating from the United States or Canada. The country now has almost 70,000 hotel rooms, more than any other Caribbean country. About 50,000 Dominicans are directly employed in this sector, mostly working in hotels, and another 110,000 are indirectly employed as taxi drivers, tour guides, or tourist-shop staff. Most tourists visit the Dominican Republic on account of its beaches, but there is an expanding eco-tourism and outdoor activity sector, focused on the country's mountains and wildlife.

Although tourism generates large revenues, some scholars and activists argue that the development of tourism also has high impacts on many socioeconomic aspects. For instance, they argue that it involves ecological deterioration, profit leakage, social displacement, disported cultural patterns, rising land values, drugs and prostitution.

Retail activity in the Dominican Republic takes many forms, from U.S.-style supermarkets and shopping malls in Santo Domingo to rural markets and tiny family-run corner stores in villages. A small but affluent middle class can afford to shop at the former, while the large impoverished rural community resorts to buying small amounts of daily essentials from colmados (small stores that often double as bars). In an attempt to regulate the retail sector, the government has recently reformed taxation laws, so that small shops pay taxes on a regular monthly basis. Many transactions, however, go unrecorded.

The following table shows the main economic indicators in 1980–2017. Inflation below 5% is in green.
GDP:
purchasing power parity - $172.4 billion (2017 est.)

GDP - real growth rate:
4.6% (2017 est.)

GDP - per capita:
purchasing power parity - $16.900 (2017 est.)

GDP - composition by sector:
"agriculture:"
5.5%
"industry:"
33.8%
"services:"
60.8% (2017 est.)

Inflation rate (consumer prices):
3.3% (2017 est.)

Labor force:
4.732 million (2017 est.)

Labor force - by occupation:
"agriculture:"
14.4%
"industry:"
20.8%
"services:"
64.7% (2014 est.)

Unemployment rate:
5.5% (2017 est.)

Population below poverty line:
30.5% (2016)

Budget:
"revenues:"
$7.014 billion

"expenditures:"
$6.985 billion (2007 est.)

Industries:
tourism, sugar processing, ferronickel and gold mining, textiles, cement, tobacco, electrical components, medical devices

Electricity - production:
15.53 billion kWh (2015)

Electricity - consumption:
13.25 billion kWh (2015)

Electricity - exports:
0 kWh (2005)

Electricity - imports:
0 kWh (2005)

Oil - production: (2014)

Oil - consumption: (2012 est.)

Oil - exports: (2017)

Oil - imports: (2017)

Oil - proved reserves: (1 January 2006 est.)

Natural gas - production: 0 cu m (2005 est.)

Natural gas - consumption: 1.108 million cu m (2015 est).

Natural gas - exports: 0 cu m (2005 est.)

Natural gas - imports: 1.108 million cu m (2015)

Natural gas - proved reserves: 0 cu m (1 January 2006 est.)

Agriculture - products:
sugarcane, coffee, cotton, cocoa, tobacco, rice, beans, potatoes, corn, bananas; cattle, pigs, dairy products, beef, eggs

Exports:
$10.33 billion f.o.b. (2017 est.)

Exports - commodities:
ferro nickel, sugar, gold, silver, coffee, cocoa, tobacco, meats, consumer goods

Exports - partners:
United States 50.4%, United Kingdom 3.2%, Belgium 2.4% (2017)

Imports:
$19 billion f.o.b. (2017 est.)

Imports - commodities:
foodstuffs, petroleum, cotton and fabrics, chemicals and pharmaceuticals

Imports - partners:
United States 41.4%, China 13.9%, Mexico 4.5%, Brazil 4.3% (2017)

Debt - external:
$29.69 billion (31 December 2017 est.)

Economic aid - recipient:
$76.99 million (2005)

Currency:
Dominican peso

Exchange rates:
Dominican pesos per US dollar - 33.113 (2007), 33.406 (2006), 30.409 (2005), 42.12 (2004), 30.831 (2003)

Fiscal year:
calendar year



</doc>
<doc id="8068" url="https://en.wikipedia.org/wiki?curid=8068" title="Telecommunications in the Dominican Republic">
Telecommunications in the Dominican Republic

Telecommunications in the Dominican Republic include radio, television, fixed and mobile telephones, and the Internet.

Numerous television channels are available. Tricom, S.A, Wind Telecom, and Claro Codetel provide television services digitally, with channels from Latin America and elsewhere in the world. There are extensive mobile phone and land-line services. Internet access is available as Cable Internet, ADSL, WiMAX, EDGE, EV-DO and UMTS/HSDPA in most parts of the country. Projects to extend Wi-Fi (wireless internet) hots spots have been undertaken in Santo Domingo. Since 2015 the country has been actively extending its fiber optics network, to provide faster and more reliable internet to business and private users.

The Instituto Dominicano De Telecomunicaciones (INDOTEL) regulates and supervises the development of the country's telecommunications market.


Cable television in the Dominican Republic is provided by a variety of companies. These companies offer both English and Spanish language television, plus a range of channels in other languages, high definition channels, pay-per-view movies and events, sports packages, premium movies channels and adult channels such as HBO, Playboy TV, Cinecanal, MLB Extra Innings, etc. The channels are not only from the Dominican Republic, but also the United States and Europe.

In the Dominican Republic there are 46 in VHF and UHF channels free-to-air channels. The programming on the free of charge channels consists mainly of locally produced entertainment shows, news, and comedy shows; and foreign sitcoms, soap operas, movies, cartoons, and sports programs.

The main service provider in the Dominican Republic is Tricom. Aster is concentrated in Santo Domingo, but is expanding its service throughout the Dominican Republic. There are new companies using new technologies that are expanding quickly such as Claro TV (IPTV and Satellite TV), Wind Telecom (MMDS) and SKY (Satellite TV).

On election day in May 2012 government broadcast regulators took two popular national television channels (11 and 33) off the air on the grounds that they violated an electoral law prohibiting distribution of exit poll or other unofficial information regarding the final results of the electoral process. Both channels were closed on the afternoon of May 20 and reopened the next morning.



The Dominican Republic is considered one of the countries with the most advanced telecommunications infrastructures in Latin America, with over 8.9 million cell phones connected (on just about 10 million populants, with 3.5 million of them on extreme poverty conditions) and large companies like Codetel and Orange (FR) on the telecommunications market. Broadband Internet access is growing, with over 622,931 Internet accounts globally and 3,851,278 Internet users as of December, 2010 according to INDOTEL (DR Telecommunications Institute). Broadband DSL represents about 56% of the total Internet subscribers. There is access to regular ADSL, G.SHDSL, and services only on metropolitan areas, costs are high and service is decent. Cable Internet is offered by a couple of cable companies at lower costs than ADSL but the service is very deficient and unreliable. WiFi is becoming more common. It is available in some universities. Most hotels also offer wi-fi internet. The implementation of the WiMAX and HSPA technology by some of the Cellphone service providers are resulting in the rapid investment by other providers in the market to match the new and faster platform of services. Mobile broadband user have seen their percentage grow from 14% in 2007 all the way to 39% in 2010, and will continue to grow as more and more users are opting for this type of technology in a country where Home Broadband speeds are more expensive and slower. Also the ongoing installation of a Fiber-Optic network structure in the National District and the City of Santiago (second largest in the country) will force other competitors into upgrading theirs to be able to compete in the markets they now lead.

As of October 2018, not including taxes.

Key: DOP: Dominican peso, USD: United States dollar. Exchange rate ( $50 DOP : $1 USD )


The following table shows the speeds/prices* available and designed for home usage. 

<nowiki>*</nowiki>Note: The pricing and speeds are subject to change since Altice, Claro and Wind have multi plans (Two or Three services combined), those plans have a discount on all services. Up to 25% discount for combined services.


Currently the mobile internet market is governed by three aspects:


There are no government restrictions on access to the Internet or credible reports that the government monitors e-mail or Internet chat rooms without judicial oversight.

The constitution provides for freedom of speech and press, and the government generally respects these rights in practice. An independent press, an effective judiciary, and a functioning democratic political system ensure freedom of speech and press. The independent media are active and express a wide variety of views without restriction. Individuals and groups are generally able to criticize the government publicly and privately without reprisal, although there have been incidents in which authorities intimidated journalists or other news professionals. Local journalists engage in self-censorship, particularly when coverage could adversely affect the economic or political interests of media owners. The government denies using unauthorized wiretapping or other surreptitious methods to interfere with the private lives of individuals and families, however, human rights groups and opposition politicians allege that such interference does occur.




</doc>
<doc id="8069" url="https://en.wikipedia.org/wiki?curid=8069" title="Transport in the Dominican Republic">
Transport in the Dominican Republic

Transportation in the Dominican Republic is composed of a system of roads, airports, ports, harbours and an urban railway:

There are five main highways (DR-1, DR-2, DR-3, DR-4, DR-5) they are in good condition in the Dominican Republic connecting its biggest cities and tourist centers. There are nearly of highways and roads, 9,872 being paved and (2002 est.) unpaved. Like any underdeveloped nation, the Dominican Republic suffers from lack of good paved roads to connect smaller towns and less populated areas though they are working on it, however major town roads are kept in good condition.

The Santo Domingo Metro is the first mass transit system in the country, and second in the Caribbean & Central American nations after the Tren Urbano in San Juan, Puerto Rico. On February 27, 2008 the incumbent president Leonel Fernández test rode the system for the first time and free service was offered thereafter several times. Commercial service started on January 30, 2009. Several additional lines are currently being planned.

The Santiago light rail system is a planned light rail system in the Dominican Republic's second largest city, still in developing stages it was said to start on mid-2008 but right now is currently on hold due to lack of approval and of central government funds.

The Dominican Republic has a bus system that is rather reliable, and most of these public transportation vehicles are fairly comfortable. The fare is generally inexpensive, and there are bus terminals and stops in most of the island's major cities.

The Public Cars ("Carros Públicos–Conchos") are privately owned passenger cars that transit a specific route daily and passengers pay a certain fee with the convenience of stopping anywhere. This comprises one of the main ways of transportation inside the capital city of Santo Domingo, as well as other major cities.
This system though, is not very reliable and lacks discipline. The high number of public cars that travel the roads, and the fact that they do not lend themselves to regulation or central control, causes frequent transit problems among city roads. They may also be somewhat uncomfortable, since they try to fit as many people as possible inside them. As a standard, a 4-person sedan (driver included) usually carries 6 passengers, twice the amount for which they were designed.

Rail operations are provided by one state owned operator and several private operators (mainly for sugar mills):

Major ports and harbours in the Dominican Republic:


The following six local ports are a single pier with berth facility:


A local ferry service runs daily between the Samaná and Sabana del Mar ports.


Boaters and sailors who wish to dock in any of DR's ports must follow certain entry requirements: 

There are 7 major and 31 minor airports in the DR (2009):





There are direct flights to and from Dominican Republic From United States, Cuba, Canada, Mexico, Venezuela, Colombia, Argentina, Brazil, Europe and the Caribbean.




</doc>
<doc id="8070" url="https://en.wikipedia.org/wiki?curid=8070" title="Armed Forces of the Dominican Republic">
Armed Forces of the Dominican Republic

The Armed Forces of the Dominican Republic (Spanish: Fuerzas Armadas de la República Dominicana) is the combined national military of the Dominican Republic. It consists of approximately 44,000 active duty personnel, approximately 60 percent of which are utilized mainly for non-military operations, including security providers for government-owned non-military facilities, toll security, forestry workers and other state enterprises, and personal security for ministers, congressmen, etc. The president is the commander in chief for the military and the Ministry of Defense (Spanish: Ministerio de Defensa de la República Dominicana) is the chief managing body of the armed forces. The primary missions are to defend the nation and protect the territorial integrity of the country. The Dominican Republic's military is second in size to Cuba's in the Caribbean.

The Army, twice as large as the other services combined with about 56,789 active duty personnel, consists of six infantry brigades, an air cavalry squadron and a combat service support brigade. The Air Force operates two main bases, one in southern region near Santo Domingo and one in the northern region of the country, the air force operates approximately 40 aircraft including helicopters. The Navy maintains three ageing vessels which were donated from the United States, around 25 patrol crafts and interceptor boats and two helicopters.

There is a counter-terrorist group formed by members of the three branches. This group is highly trained in counter-terrorism missions. The armed forces participate fully in counter-illegal drug trade efforts, for this task, there is a taskforce known as DEPROSER 24/7 (DEfender, PROteger y SERvir). They also are active in efforts to control contraband and illegal immigration from Haiti to the Dominican Republic and from the Dominican Republic to the United States (via illegal transportation of immigrants to Puerto Rico).

Haiti under their president Jean-Pierre Boyer had invaded and occupied Dominican Republic from 1822 to 1844. The military forces of the First Republic's army comprised about 4,000 soldiers organized into seven line infantry regiments, several loose battalions, 6 escudrones cavalry and 3 artillery brigades with 2/2 brigades; This army was supplemented with national civic guard militia composed of the provinces, the National Naval Armada, original name of the Navy today; It composed of 10 ships, seven owned and 3 taken in requición and armed by the government: the Cibao frigate with 20 cannons; the brigantine schooner San Jose, five guns; the schooner La Libertad, five guns; General schooner Santana 7 guns; the schooner La Merced, five guns; Separation schooner, 3 guns; the schooner February 27, five guns. The requisition taken: the schooner Maria Luisa, 3 guns; the schooner March 30, 3 guns; and the schooner Hope, 3 guns. 674 operated by a man. In addition to the aforementioned military corps expeditionary southern army recruited by Pedro and Ramon Santana in Hato Mayor and El Seibo, with a permit issued by the Central Governing Board with the rank of commander in chief of the army existed. These men were skilled in handling machete and spear. His deputy commander was Brigadier General Antonio Duvergé. The other expeditionary army was the Northern Borders created to defend these borders: its commander was Major General Francisco A. Salcedo.

The Dominican forces would reach levels of organization and efficiency of considerable notoriety. As an example of this, it would suffice to highlight the fact of the achievement and preservation of National Independence, with the Dominican victory over repeated Haitian military invasions in the 12-year period that followed the proclamation of Independence; In addition, 55 percent of the National Budget was allocated to it.

The events that led to the United States military intervention of 1916, brought about the disappearance of any vestige of military structure in the Dominican Republic, setting the intervening forces a military government headed by Captain William Knapp, who make an interim police force called "Constabulary "equivalent to an" armed police force as a military unit "and he had the task of maintaining internal order and enforce the implementing provisions of the US government. This body, purely police function disappears in 1917, leading to the creation of a National Guard. As a result of this historic event of our recent past, the country inherited a hierarchical and organizational akin to the US Marine Corps structure, which served as a platform to the transformations that later gave rise to the armed forces we know today, made up of three components, terrestrial one, one naval and one air.

This land component, now called the National Army, inherited by both its organizational structure of the National Guard organized by the US occupation forces, which operated from April 7, 1917 until June 1921, when it becomes Dominican National Police by Executive Order No. 631 of Rear Admiral Thomas Snowden, who was at that time the military governor of Santo Domingo. After the US military occupation in 1924, Horacio Vásquez wins the presidential elections of that same year. Among his first decisions, decrees the change of the Dominican National Police in National Brigade, a situation that continues until 17 May 1928, when new turn changes the name of the Army by Law No. 928, but basically inheriting a structure Police, who obeyed schemes imposition of public order demanded by the country at that time and not those of an army in their typical roles.

Due to its characteristics and missions, organizational structure that demanded presence throughout the country, which was realized with the creation of posts and detachments in different parts of the country and the establishment in some provinces of company size units, many of which still Army retains today. Over the years and already existing National Police created by decree No. 1523 of March 2, 1936 of President Trujillo, many of these units, posts and detachments became part of it, perfectly adapted to its structure, since These were essentially created to play a policing role. So great was the influence that had the National Guard in Dominican society and very particularly in the rural population, which even today are many Dominicans who often referred to the Armed Forces and unique way to the Army as " The Guard ".

Meanwhile, the Navy has remained since its inception attached to the principles that gave rise, assuming only two name changes since its inception, but gradually evolving the transformation of what was a body created for military purposes, capable of landing and ships with weapons to face possible naval invasions, to be a component mainly responsible for enforcing the provisions on navigation, trade and fishing, as well as international treaties

The Dominican Air Force, meanwhile, emerges as an independent component in 1948, under the chairmanship of Generalissimo Rafael L. Trujillo Molina, with characteristics of innovation and modernism, which gave mobility, versatility and depth to the Armed Forces and the complement in the following years would become: a military capacity to project military power in the Caribbean environment. The situation of this air component has changed significantly after reaching its climax in the 50s, when it was one of the best air force equipped in the region, which was due to the strategic guidelines of a long-lived military dictatorship It made efforts to stay in power and he saw in this component one of its mainstays against any invasion or subversion against the dictatorship.

Its basic strength is concentrated in the infantry which in general can be said to be well equipped with combat rifles and combat equipment for soldiers. The vehicles (both transport and armored vehicles) and the artillery and anti-tank pieces that are in service. Currently, tanks and modern armor systems have been included.

The Dominican Navy was founded in 1844 also with the National Independence with 15,000 troops after Haiti had occupied the eastern part of the island for twenty five years. It keeps around 34 ships in operation, mostly coast guards, patrol boats and small speedboats. It also operates dredges, tugboats and patrol boats of height. The Navy has a small air body composed helicopter utilities Bell OH-58C Kiowa.

The Navy operates two main bases, one in the port of Santo Domingo in the Dominican capital called "Naval Base 27 de Febrero" and another in Bahía de las Calderas, in the province of Peravia, called Las Calderas Naval Base in the southern part from the country. It also has presence in the commercial ports of the country, comandancias of ports and is divided into three naval areas that in turn have posts and naval detachments.

The Dominican Air Force was founded in 1948 with 20,000 people. It has two main bases: the base area of San Isidro in the South-Central zone of the country near the capital city Santo Domingo; and the other operates jointly in the civil facilities belonging to the Gregorio Luperón International Airport, near the city of Puerto Plata in the North of the Republic. Until August 2009, the possibility of starting military operations from the María Montez airport, in the city of Barahona in the Southwest of the country and from the Punta Cana airport in the extreme east is under study.

It keeps the following fixed-wing aircraft in operation: 8 Embraer EMB 314 Super Tucano, 3 CASA C-212-400 transport; 6 T35B Pilot training; as well as around 25 helicopters such as Bell 206, Bell UH-1 Iroquois, Bell OH-58 Kiowa, Eurocopter Dauphin, OH-6 Cayuse and Sikorsky S-300.

The Specialized Security Corps are military security agencies dependent on the Ministry of the Armed Forces. and they are made up of military and civilian personnel specialized in their different areas of function. To perform Security and Protection tasks in state institutions.
Antiterrorism Command of the Dominican Armed Forces

National Department of Investigations (DNI)
Specialized Body for Airport Security and Civil Aviation (CESAC)
Specialized Body for Metro Security (CESMET)
National Service of Environmental Protection (SENPA)
Specialized Body in Tourist Security (CESTUR)
Specialized Body in Fuel Control (CECCOM)
Task Force Ciudad Tranquila (FT-CIUTRAN)
Specialized Body of Airport Security and Civil Aviation
Specialized Port Security Corps (CESEP)
Specialized Terrestrial Border Security Body (CESFRONT)



</doc>
<doc id="8071" url="https://en.wikipedia.org/wiki?curid=8071" title="Foreign relations of the Dominican Republic">
Foreign relations of the Dominican Republic

The Dominican Republic has a close relationship with the United States and with the other states of the Inter-American system. It has accredited diplomatic missions in most Western Hemisphere countries and in principal European capitals.

The Dominican Republic is a founding member of the United Nations and many of its specialized and related agencies, including the World Bank, International Labour Organization, International Atomic Energy Agency, and International Civil Aviation Organization. It also is a member of the OAS, World Trade Organization, World Health Organization, World Customs Organization the Inter-American Development Bank, Central American Integration System, and ACP Group.




</doc>
<doc id="8072" url="https://en.wikipedia.org/wiki?curid=8072" title="Disease">
Disease

A disease is a particular abnormal condition that negatively affects the structure or function of part or all of an organism, and that is not due to any external injury. Diseases are often construed as medical conditions that are associated with specific symptoms and signs. A disease may be caused by external factors such as pathogens or by internal dysfunctions. For example, internal dysfunctions of the immune system can produce a variety of different diseases, including various forms of immunodeficiency, hypersensitivity, allergies and autoimmune disorders.

In humans, "disease" is often used more broadly to refer to any condition that causes pain, dysfunction, distress, social problems, or death to the person afflicted, or similar problems for those in contact with the person. In this broader sense, it sometimes includes injuries, disabilities, disorders, syndromes, infections, isolated symptoms, deviant behaviors, and atypical variations of structure and function, while in other contexts and for other purposes these may be considered distinguishable categories. Diseases can affect people not only physically, but also mentally, as contracting and living with a disease can alter the affected person's perspective on life.

Death due to disease is called death by natural causes. There are four main types of disease: infectious diseases, deficiency diseases, hereditary diseases (including both genetic diseases and non-genetic hereditary diseases), and physiological diseases. Diseases can also be classified in other ways, such as communicable versus non-communicable diseases. The deadliest diseases in humans are coronary artery disease (blood flow obstruction), followed by cerebrovascular disease and lower respiratory infections. In developed countries, the diseases that cause the most sickness overall are neuropsychiatric conditions, such as depression and anxiety.

The study of disease is called "pathology", which includes the study of "etiology", or cause.

In many cases, terms such as "disease", "disorder", "morbidity", "sickness" and "illness" are used interchangeably. There are situations, however, when specific terms are considered preferable.


In an infectious disease, the incubation period is the time between infection and the appearance of symptoms. The latency period is the time between infection and the ability of the disease to spread to another person, which may precede, follow, or be simultaneous with the appearance of symptoms. Some viruses also exhibit a dormant phase, called viral latency, in which the virus hides in the body in an inactive state. For example, varicella zoster virus causes chickenpox in the acute phase; after recovery from chickenpox, the virus may remain dormant in nerve cells for many years, and later cause herpes zoster (shingles).


Diseases may be classified by cause, pathogenesis (mechanism by which the disease is caused), or by symptom(s). Alternatively, diseases may be classified according to the organ system involved, though this is often complicated since many diseases affect more than one organ.

A chief difficulty in nosology is that diseases often cannot be defined and classified clearly, especially when cause or pathogenesis are unknown. Thus diagnostic terms often only reflect a symptom or set of symptoms (syndrome).

Classical classification of human disease derives from observational correlation between pathological analysis and clinical syndromes. Today it is preferred to classify them by their cause if it is known.

The most known and used classification of diseases is the World Health Organization's ICD. This is periodically updated. Currently the last publication is the ICD-10.

Only some diseases such as influenza are contagious and commonly believed infectious. The micro-organisms that cause these diseases are known as pathogens and include varieties of bacteria, viruses, protozoa and fungi. Infectious diseases can be transmitted, e.g. by hand-to-mouth contact with infectious material on surfaces, by bites of insects or other carriers of the disease, and from contaminated water or food (often via fecal contamination), etc. Also, there are sexually transmitted diseases. In some cases, microorganisms that are not readily spread from person to person play a role, while other diseases can be prevented or ameliorated with appropriate nutrition or other lifestyle changes.

Some diseases, such as most (but not all) forms of cancer, heart disease, and mental disorders, are non-infectious diseases. Many non-infectious diseases have a partly or completely genetic basis (see genetic disorder) and may thus be transmitted from one generation to another.

Social determinants of health are the social conditions in which people live that determine their health. Illnesses are generally related to social, economic, political, and environmental circumstances. Social determinants of health have been recognized by several health organizations such as the Public Health Agency of Canada and the World Health Organization to greatly influence collective and personal well-being. The World Health Organization's Social Determinants Council also recognizes Social determinants of health in poverty.

When the cause of a disease is poorly understood, societies tend to mythologize the disease or use it as a metaphor or symbol of whatever that culture considers evil. For example, until the bacterial cause of tuberculosis was discovered in 1882, experts variously ascribed the disease to heredity, a sedentary lifestyle, depressed mood, and overindulgence in sex, rich food, or alcohol—all the social ills of the time.

When a disease is caused by a pathogen (e.g., when the disease malaria is caused by infection by "Plasmodium" parasites.), the term "disease" may be misleadingly used even in the scientific literature in place of its causal agent, the pathogen. This language habit can cause confusion in the communication of the cause-effect principle in epidemiology, and as such it should be strongly discouraged.


Many diseases and disorders can be prevented through a variety of means. These include sanitation, proper nutrition, adequate exercise, vaccinations and other self-care and public health measures.

Medical therapies or treatments are efforts to cure or improve a disease or other health problem. In the medical field, therapy is synonymous with the word "treatment". Among psychologists, the term may refer specifically to psychotherapy or "talk therapy". Common treatments include medications, surgery, medical devices, and self-care. Treatments may be provided by an organized health care system, or informally, by the patient or family members.

Preventive healthcare is a way to avoid an injury, sickness, or disease in the first place. A treatment or cure is applied after a medical problem has already started. A treatment attempts to improve or remove a problem, but treatments may not produce permanent cures, especially in chronic diseases. Cures are a subset of treatments that reverse diseases completely or end medical problems permanently. Many diseases that cannot be completely cured are still treatable. Pain management (also called pain medicine) is that branch of medicine employing an interdisciplinary approach to the relief of pain and improvement in the quality of life of those living with pain.

Treatment for medical emergencies must be provided promptly, often through an emergency department or, in less critical situations, through an urgent care facility.

Epidemiology is the study of the factors that cause or encourage diseases. Some diseases are more common in certain geographic areas, among people with certain genetic or socioeconomic characteristics, or at different times of the year.

Epidemiology is considered a cornerstone methodology of public health research, and is highly regarded in evidence-based medicine for identifying risk factors for disease. In the study of communicable and non-communicable diseases, the work of epidemiologists ranges from outbreak investigation to study design, data collection and analysis including the development of statistical models to test hypotheses and the documentation of results for submission to peer-reviewed journals. Epidemiologists also study the interaction of diseases in a population, a condition known as a syndemic. Epidemiologists rely on a number of other scientific disciplines such as biology (to better understand disease processes), biostatistics (the current raw information available), Geographic Information Science (to store data and map disease patterns) and social science disciplines (to better understand proximate and distal risk factors). Epidemiology can help identify causes as well as guide prevention efforts.

In studying diseases, epidemiology faces the challenge of defining them. Especially for poorly understood diseases, different groups might use significantly different definitions. Without an agreed-on definition, different researchers may report different numbers of cases and characteristics of the disease.

Some morbidity databases are compiled with data supplied by states and territories health authorities, at national levels or larger scale (such as European Hospital Morbidity Database (HMDB)) which may contain hospital discharge data by detailed diagnosis, age and sex. The European HMDB datea was submitted by European countries to the World Health Organization Regional Office for Europe.

Disease burden is the impact of a health problem in an area measured by financial cost, mortality, morbidity, or other indicators.

There are several measures used to quantify the burden imposed by diseases on people. The years of potential life lost (YPLL) is a simple estimate of the number of years that a person's life was shortened due to a disease. For example, if a person dies at the age of 65 from a disease, and would probably have lived until age 80 without that disease, then that disease has caused a loss of 15 years of potential life. YPLL measurements do not account for how disabled a person is before dying, so the measurement treats a person who dies suddenly and a person who died at the same age after decades of illness as equivalent. In 2004, the World Health Organization calculated that 932 million years of potential life were lost to premature death.

The quality-adjusted life year (QALY) and disability-adjusted life year (DALY) metrics are similar, but take into account whether the person was healthy after diagnosis. In addition to the number of years lost due to premature death, these measurements add part of the years lost to being sick. Unlike YPLL, these measurements show the burden imposed on people who are very sick, but who live a normal lifespan. A disease that has high morbidity, but low mortality, has a high DALY and a low YPLL. In 2004, the World Health Organization calculated that 1.5 billion disability-adjusted life years were lost to disease and injury. In the developed world, heart disease and stroke cause the most loss of life, but neuropsychiatric conditions like major depressive disorder cause the most years lost to being sick.

How a society responds to diseases is the subject of medical sociology.

A condition may be considered a disease in some cultures or eras but not in others. For example, obesity can represent wealth and abundance, and is a status symbol in famine-prone areas and some places hard-hit by HIV/AIDS. Epilepsy is considered a sign of spiritual gifts among the Hmong people.

Sickness confers the social legitimization of certain benefits, such as illness benefits, work avoidance, and being looked after by others. The person who is sick takes on a social role called the sick role. A person who responds to a dreaded disease, such as cancer, in a culturally acceptable fashion may be publicly and privately honored with higher social status. In return for these benefits, the sick person is obligated to seek treatment and work to become well once more. As a comparison, consider pregnancy, which is not interpreted as a disease or sickness, even if the mother and baby may both benefit from medical care.

Most religions grant exceptions from religious duties to people who are sick. For example, one whose life would be endangered by fasting on Yom Kippur or during Ramadan is exempted from the requirement, or even forbidden from participating. People who are sick are also exempted from social duties. For example, ill health is the only socially acceptable reason for an American to refuse an invitation to the White House.

The identification of a condition as a disease, rather than as simply a variation of human structure or function, can have significant social or economic implications. The controversial recognitions as diseases of repetitive stress injury (RSI) and post-traumatic stress disorder (also known as "Soldier's heart", "shell shock", and "combat fatigue") has had a number of positive and negative effects on the financial and other responsibilities of governments, corporations and institutions towards individuals, as well as on the individuals themselves. The social implication of viewing aging as a disease could be profound, though this classification is not yet widespread.

Lepers were people who were historically shunned because they had an infectious disease, and the term "leper" still evokes social stigma. Fear of disease can still be a widespread social phenomenon, though not all diseases evoke extreme social stigma.

Social standing and economic status affect health. Diseases of poverty are diseases that are associated with poverty and low social status; diseases of affluence are diseases that are associated with high social and economic status. Which diseases are associated with which states varies according to time, place, and technology. Some diseases, such as diabetes mellitus, may be associated with both poverty (poor food choices) and affluence (long lifespans and sedentary lifestyles), through different mechanisms. The term lifestyle diseases describes diseases associated with longevity and that are more common among older people. For example, cancer is far more common in societies in which most members live until they reach the age of 80 than in societies in which most members die before they reach the age of 50.

An illness narrative is a way of organizing a medical experience into a coherent story that illustrates the sick individual's personal experience.

People use metaphors to make sense of their experiences with disease. The metaphors move disease from an objective thing that exists to an affective experience. The most popular metaphors draw on military concepts: Disease is an enemy that must be feared, fought, battled, and routed. The patient or the healthcare provider is a warrior, rather than a passive victim or bystander. The agents of communicable diseases are invaders; non-communicable diseases constitute internal insurrection or civil war. Because the threat is urgent, perhaps a matter of life and death, unthinkably radical, even oppressive, measures are society's and the patient's moral duty as they courageously mobilize to struggle against destruction. The War on Cancer is an example of this metaphorical use of language. This language is empowering to some patients, but leaves others feeling like they are failures.

Another class of metaphors describes the experience of illness as a journey: The person travels to or from a place of disease, and changes himself, discovers new information, or increases his experience along the way. He may travel "on the road to recovery" or make changes to "get on the right track" or choose "pathways". Some are explicitly immigration-themed: the patient has been exiled from the home territory of health to the land of the ill, changing identity and relationships in the process. This language is more common among British healthcare professionals than the language of physical aggression.

Some metaphors are disease-specific. Slavery is a common metaphor for addictions: The alcoholic is enslaved by drink, and the smoker is captive to nicotine. Some cancer patients treat the loss of their hair from chemotherapy as a metonymy or metaphor for all the losses caused by the disease.

Some diseases are used as metaphors for social ills: "Cancer" is a common description for anything that is endemic and destructive in society, such as poverty, injustice, or racism. AIDS was seen as a divine judgment for moral decadence, and only by purging itself from the "pollution" of the "invader" could society become healthy again. More recently, when AIDS seemed less threatening, this type of emotive language was applied to avian flu and type 2 diabetes mellitus. Authors in the 19th century commonly used tuberculosis as a symbol and a metaphor for transcendence. Victims of the disease were portrayed in literature as having risen above daily life to become ephemeral objects of spiritual or artistic achievement. In the 20th century, after its cause was better understood, the same disease became the emblem of poverty, squalor, and other social problems.



</doc>
<doc id="8073" url="https://en.wikipedia.org/wiki?curid=8073" title="Dardanelles">
Dardanelles

The Dardanelles (; , ), also known from Classical Antiquity as the Hellespont
(; , "Hellespontos", literally "Sea of Helle"), is a narrow, natural strait and internationally significant waterway in northwestern Turkey that forms part of the continental boundary between Europe and Asia, and separates Asian Turkey from European Turkey. One of the world's narrowest straits used for international navigation, the Dardanelles connects the Sea of Marmara with the Aegean and Mediterranean Seas, while also allowing passage to the Black Sea by extension via the Bosphorus. The Dardanelles is long, and wide, averaging deep with a maximum depth of at its narrowest point abreast the city of Çanakkale.

Most of the northern shores of the strait along the Gallipoli Peninsula () are sparsely settled, while the southern shores along the Troad Peninsula () are inhabited by the city of Çanakkale's urban population of 110,000.

Together with the Bosphorus, the Dardanelles forms the Turkish Straits.

The contemporary Turkish name "Çanakkale Boğazı", meaning "Çanakkale Strait", is derived from the eponymous midsize city that adjoins the strait, itself meaning "Pottery Fort"—from "Çanak" (pottery) + "Kale" (Fortress)—in reference to the area's famous pottery and ceramic wares, and the landmark Ottoman fortress of Sultaniye.

The English name "Dardanelles" is an abbreviation of "Strait of the Dardanelles". During Ottoman times there was a castle on each side of the strait. These castles together were called the "Dardanelles", probably named after Dardanus, an ancient city on the Asian shore of the strait which in turn was said to take its name from Dardanus, the mythical son of Zeus and Electra.

The ancient Greek name ("Hellespontos") means "Sea of Helle", and was the ancient name of the narrow strait. It was variously named in classical literature "Hellespontium Pelagus", "Rectum Hellesponticum", and "Fretum Hellesponticum". It was so called from Helle, the daughter of Athamas, who was drowned here in the mythology of the Golden Fleece.

As a maritime waterway, the Dardanelles connects various seas along the Eastern Mediterranean, the Balkans, the Near East, and Western Eurasia, and specifically connects the Aegean Sea to the Sea of Marmara. The Marmara further connects to the Black Sea via the Bosphorus, while the Aegean further links to the Mediterranean. Thus, the Dardanelles allows maritime connections from the Black Sea all the way to the Mediterranean Sea and the Atlantic Ocean via Gibraltar, and the Indian Ocean through the Suez Canal, making it a crucial international waterway, in particular for the passage of goods coming in from Russia.

The strait is located at approximately .

The strait is long, and wide, averaging deep with a maximum depth of at its narrowest point at Nara Burnu, abreast Çanakkale. There are two major currents through the strait: a surface current flows from the Black Sea towards the Aegean Sea, and a more saline undercurrent flows in the opposite direction.

The Dardanelles is unique in many respects. The very narrow and winding shape of the strait is more akin to that of a river. It is considered one of the most hazardous, crowded, difficult and potentially dangerous waterways in the world. The currents produced by the tidal action in the Black Sea and the Sea of Marmara are such that ships under sail must await at anchorage for the right conditions before entering the Dardanelles.

As part of the only passage between the Black Sea and the Mediterranean, the Dardanelles has always been of great importance from a commercial and military point of view, and remains strategically important today. It is a major sea access route for numerous countries, including Russia and Ukraine. Control over it has been an objective of a number of hostilities in modern history, notably the attack of the Allied Powers on the Dardanelles during the 1915 Battle of Gallipoli in the course of World War I.

The ancient city of Troy was located near the western entrance of the strait, and the strait's Asiatic shore was the focus of the Trojan War. Troy was able to control the marine traffic entering this vital waterway. The Persian army of Xerxes I of Persia and later the Macedonian army of Alexander the Great crossed the Dardanelles in opposite directions to invade each other's lands, in 480 BC and 334 BC respectively.

Herodotus says that, circa 482 BC, Xerxes I (the son of Darius) had two pontoon bridges built across the width of the Hellespont at Abydos, in order that his huge army could cross from Persia into Greece. This crossing was named by Aeschylus in his tragedy "The Persians" as the cause of divine intervention against Xerxes.

According to Herodotus (vv.34), both bridges were destroyed by a storm and Xerxes had those responsible for building the bridges beheaded and the strait itself whipped. The Histories of Herodotus vii.33–37 and vii.54–58 give details of building and crossing of Xerxes' Pontoon Bridges. Xerxes is then said to have thrown fetters into the strait, given it three hundred lashes and branded it with red-hot irons as the soldiers shouted at the water.

Herodotus commented that this was a "highly presumptuous way to address the Hellespont" but in no way atypical of Xerxes. (vii.35)

Harpalus the engineer eventually helped the invading armies to cross by lashing the ships together with their bows facing the current and, so it is said, two additional anchors.

From the perspective of ancient Greek mythology, it was said that Helle, the daughter of Athamas, was drowned at the Dardanelles in the legend of the Golden Fleece. Likewise, the strait was the scene of the legend of Hero and Leander, wherein the lovesick Leander swam the strait nightly in order to tryst with his beloved, the priestess Hero, and was drowned in a storm.

The Dardanelles were vital to the defence of Constantinople during the Byzantine period.

Also, the Dardanelles was an important source of income for the ruler of the region. At the Istanbul Archaeological Museum a marble plate contains a law by the Byzantine Emperor Anastasius I (491–518 AD), that regulated fees for passage through the customs office of the Dardanelles. Translation:

... Whoever dares to violate these regulations shall no longer be regarded as a friend, and he shall be punished. Besides, the administrator of the Dardanelles must have the right to receive 50 golden Litrons, so that these rules, which we make out of piety, shall never ever be violated... ... The distinguished governor and major of the capital, who already has both hands full of things to do, has turned to our lofty piety in order to reorganize the entry and exit of all ships through the Dardanelles... ... Starting from our day and also in the future, anybody who wants to pass through the Dardanelles must pay the following: 
– All wine merchants who bring wine to the capital (Constantinopolis), except Cilicians, have to pay the Dardanelles officials 6 follis and 2 sextarius of wine. 
– In the same manner, all merchants of olive-oil, vegetables and lard must pay the Dardanelles officials 6 follis. Cilician sea-merchants have to pay 3 follis and in addition to that, 1 keration (12 follis) to enter, and 2 keration to exit.
– All wheat merchants have to pay the officials 3 follis per modius, and a further sum of 3 follis when leaving.

Since the 14th century the Dardanelles have almost continuously been controlled by the Turks.

The Dardanelles continued to constitute an important waterway under the reign of the Ottoman Empire, starting with the conquest of Gallipoli in 1354.

Ottoman control of the strait continued largely without interruption or challenges until the 19th century, when the Empire started its decline.

Gaining control or special access to the strait became a key foreign policy goal of the Russian Empire during the 19th century. During the Napoleonic Wars, Russia—supported by Great Britain in the Dardanelles Operation—blockaded the straits in 1807. Following the Ottoman Empire's defeat in the Russo-Turkish War of 1828–29, in 1833 Russia pressured the Ottomans to sign the Treaty of Hunkiar Iskelesi—which required the straits to be closed to warships of non-Black Sea powers at Russia's request. That would have effectively given Russia a free hand in the Black Sea.

That treaty alarmed the losers, who were concerned that the consequences of potential Russian expansionism in the Black Sea and Mediterranean regions could conflict with their own possessions and economic interest in the regions. At the London Straits Convention in July 1841, the United Kingdom, France, Austria, and Prussia pressured Russia to agree that only Turkish warships could traverse the Dardanelles in peacetime. The United Kingdom and France subsequently sent their fleets through the straits to attack the Crimean Peninsula during the Crimean War (1853-1856) —but this was done as allies of the Ottoman Empire. That convention was formally reaffirmed by the Congress of Paris in 1856, following the Russian defeat in the Crimean War. It remained technically in force into the 20th and 21st centuries.

In 1915 the Allies sent a massive invasion force of British, Indian, Australian, New Zealand, French and Newfoundland troops to attempt to open up the straits. In the Gallipoli campaign, Turkish troops trapped the Allies on the beaches of the Gallipoli peninsula. The campaign did damage to the career of Winston Churchill, then the First Lord of the Admiralty, who had eagerly promoted the unsuccessful use of Royal Navy sea power to force open the straits. Mustafa Kemal Atatürk, later founder of the Republic of Turkey, served as a commander for the Ottomans during the land campaign.

The Turks mined the straits to prevent Allied ships from penetrating them, but in minor actions, two submarines, one British and one Australian, did succeed in penetrating the minefields. The British one sank an obsolete Turkish pre-dreadnought battleship off the Golden Horn of Istanbul. Sir Ian Hamilton's Mediterranean Expeditionary Force failed in its attempt to capture the Gallipoli peninsula, and its withdrawal was ordered in December 1915, after eight months' fighting. Total Allied deaths included 43,000 British and Irish, 15,000 French, 8,700 Australians, 2,700 New Zealanders, 1,370 Indians and 49 Newfoundlanders. Total Turkish deaths were around 60,000.

Following the war, the 1920 Treaty of Sèvres demilitarized the strait and made it an international territory under the control of the League of Nations. The Ottoman Empire's non-ethnically Turkish territories were broken up and partitioned among the Allied Powers, and Turkish jurisdiction over the straits curbed.

After the dissolution of the Ottoman Empire following a lengthy campaign by Turks as part of the Turkish War of Independence against both the Allied Powers and the Ottoman court, the Republic of Turkey was created in 1923 by the Treaty of Lausanne, which established most of the modern sovereign territory of Turkey and restored the straits to Turkish territory, with the condition that Turkey keep them demilitarized and allow all foreign warships and commercial shipping to traverse the straits freely.

As part of its national security strategy, Turkey eventually rejected the terms of the treaty, and subsequently remilitarized the straits area over the following decade. Following extensive diplomatic negotiations, the reversion was formalized under the Montreux Convention Regarding the Regime of the Turkish Straits in July 20, 1936. That convention, which is still in force today, treats the straits as an international shipping lane while allowing Turkey to retain the right to restrict the naval traffic of non-Black Sea states.

During World War II, through February 1945, when Turkey was neutral for most of the length of the conflict, the Dardanelles were closed to the ships of the belligerent nations. Turkey declared war on Germany in February 1945, but it did not employ any offensive forces during the war.

In July 1946, the Soviet Union sent a note to Turkey proposing a new régime for the Dardanelles that would have excluded all nations except the Black Sea powers. The second proposal was that the straits should be put under joint Turkish-Soviet defence. This meant that Turkey, the Soviet Union, Bulgaria and Romania would be the only states having access to the Black Sea through the Dardanelles. The Turkish government however, under pressure from the United States, rejected these proposals.

Turkey joined NATO in 1952, thus affording its straits even more strategic importance as a commercial and military waterway.

In more recent years, the Turkish Straits have become particularly important for the oil industry. Russian oil, from ports such as Novorossyisk, is exported by tankers primarily to western Europe and the U.S. via the Bosphorus and the Dardanelles straits.

The waters of the Dardanelles are traversed by numerous passenger and vehicular ferries daily, as well as recreational and fishing boats ranging from dinghies to yachts owned by both public and private entities.

The strait also experiences significant amounts of international commercial shipping traffic by freighters and tankers.

At present, there are no vehicular crossings across the strait. However, as part of planned expansions to the Turkish National Highway Network, the Turkish Government is considering the construction of a suspension bridge between Sarıçay (a district of Çanakkale Province) on the Asian side, to Kilitbahir on the European side, at the narrowest part of the strait. In March 2017, construction of the Çanakkale 1915 Bridge between the cities of Gelibolu and Lapseki started.

2 submarine cable systems transmitting electric power at 400 kV voltage bridge the Dardanelles to feed west and east of Istanbul. They have their own landing stations in Lapseki and Sütlüce. The first, situated in the northeast quarter portion of the strait, has been energised in April 2015 and leads 2 GW via 6 phases 400 kV AC 3.9 km far thru the sea. The second, somewhat in the middle of the strait, has been still under construction in June 2016 and has quite similar data.

Both subsea power lines cross 4 optical fibre data lines laid earlier along the strait. A published map shows communication lines leading from Istanbul into the Mediterranean, named MedNautilus and landing at Athens, Sicily and elsewhere.

English Romantic poet Lord Byron (1788–1824) swam across the Dardanelles on 3 May 1810, and recorded it in his poem "Don Juan" (1821).

Çanakkale, located along the southern shores of the strait, is the finishing point every year for an organised swim across the Dardanelles, which kicks off from Eceabat. This event emulates the swim in 1810 by Lord Byron, who was himself emulating the legendary swim by Leander in the story of Hero and Leander.

The shores of the strait are also the site of ancient Troy. The "wooden horse" from the 2004 movie "Troy" is exhibited on the seafront.

The Dardanelles is also the site of two notable maritime accidents in Turkish naval history, when two generations of the submarine TCG Dumlupinar were struck by tankers on their way back from naval missions. The first incident resulted in the deaths of 96 sailors, while the second incident had no fatalities.

Due to the importance of the Gallipoli Campaign in many countries' histories, the Dardanelles also features prominently in many documentaries and films about World War I.

The Dardanelles is mentioned in the song No place like London from the movie . The song is written and composed by Stephen Sondheim and sung by Johnny Depp and Jamie Campbell Bower. Jamie's character Anthony sings, "I have sailed the world, beheld its wonders, from the Dardanelles to the mountains of Peru..."

"Bow Down to Washington", the fight song of the University of Washington, references the Dardanelles in the lyrics: "Our boys are there with bells, their fighting blood excels, it's harder to push them over the line than pass the Dardanelles."




</doc>
<doc id="8074" url="https://en.wikipedia.org/wiki?curid=8074" title="Daugava">
Daugava

The Daugava (; ) is a river rising in the Valdai Hills, flowing through Russia, Belarus, and Latvia and into the Gulf of Riga. The total length of the river is 1,020 km (630 mi), of which 325 km (202 mi) are in Russia.

The total catchment area of the river is , of which are within Belarus.

According to the Max Vasmer's "Etymological Dictionary", the toponym Dvina clearly cannot stem from a Uralic language, and it possibly comes from Indo-European word which used to mean "river" or "stream".

The river began experiencing environmental deterioration in the era of Soviet collective agriculture (producing considerable adverse water pollution runoff) and a wave of hydroelectric power projects.

Andreapol, Zapadnaya Dvina and Velizh.

Ruba, Vitebsk, Beshankovichy, Polotsk with Boris stones strewn in the vicinity, Navapolatsk, Dzisna, Verkhnedvinsk, and Druya.

Krāslava, Daugavpils, Līvāni, Jēkabpils, Pļaviņas, Aizkraukle, Jaunjelgava, Lielvārde, Kegums, Ogre, Ikšķile, Salaspils and Riga.

Humans have settled at the mouth of the Daugava and around the other shores of the Gulf of Riga for millennia, initially participating in a hunter-gatherer economy and utilizing the waters of the Daugava estuary as fishing and gathering areas for aquatic biota. Beginning around the sixth century AD, Viking explorers crossed the Baltic Sea and entered the Daugava River, navigating upriver into the Baltic interior.

In medieval times the Daugava was an important area of trading and navigation - part of the trade route from the Varangians to the Greeks - for transport of furs from the north and of Byzantine silver from the south. The Riga area, inhabited by the Finnic-speaking Livs, became a key element of settlement and defence of the mouth of the Daugava at least as early as the Middle Ages, as evidenced by the now destroyed fort at Torņakalns on the west bank of the Daugava at present day Riga. Since the Late Middle Ages the western part of the Daugava basin has come under the rule of various peoples and states; for example the Latvian town of Daugavpils, located on the western Daugava, variously came under papal rule as well as Slavonic, Polish, German and Russian sway until restoration of the Latvian independence in 1990 at the end of the Cold War.

Upstream of the Latvian town of Jekabpils the pH has a characteristic value of about 7.8; in this reach the calcium ion has a typical concentration of around 43 milligrams per liter; nitrate has a concentration of about 0.82 milligrams per liter (as nitrogen); phosphate ion is measured at 0.038 milligrams per liter; and oxygen saturation was measured at eighty percent. The high nitrate and phosphate load of the Daugava is instrumental to the buildup of extensive phytoplankton biomass in the Baltic Sea; other European rivers contributing to such high nutrient loading of the Baltic are the Oder and Vistula Rivers.

In Belarus, water pollution of the Daugava is considered moderately severe, with the chief sources being treated wastewater, fish-farming and agricultural chemical runoff (e.g. herbicides, pesticides, nitrate and phosphate).




</doc>
<doc id="8075" url="https://en.wikipedia.org/wiki?curid=8075" title="Datsun">
Datsun

Datsun (, ) is an automobile brand owned by Nissan. Datsun's original production run began in 1931. From 1958 to 1986, only vehicles exported by Nissan were identified as Datsun. By 1986 Nissan had phased out the Datsun name, but re-launched it in June 2013 as the brand for low-cost vehicles manufactured for emerging markets.

In 1931, Dat Motorcar Co. chose to name its new small car "Datson", a name which indicated the new car's smaller size when compared to the DAT's larger vehicle already in production. When Nissan took control of DAT in 1934, the name "Datson" was changed to "Datsun", because "son" also means "loss" (損 "son") in Japanese and also to honour the sun depicted in the national flag – thus the name "Datsun": . Nissan phased out the Datsun brand in March 1986. The Datsun name is internationally well known for the 510, Fairlady roadsters, the Fairlady (S30 240Z, 260Z, 280Z) S130 280ZX coupes, and recently, the Go hatchback.

Before the Datsun brand name came into being, an automobile named the DAT car was built in 1914, by the , in the Azabu-Hiroo District in Tokyo. The new car's name was an acronym of the surnames of the following company partners:

Incidentally, "datto" (how a native Japanese speaker would pronounce "dat") means to "dash off like a startled rabbit" (脱兎), which was considered a good name for the little car. The firm was renamed Kaishinsha Motorcar Co. in 1918, seven years after their establishment and again, in 1925, to DAT Motorcar Co. DAT Motors constructed trucks in addition to the DAT passenger cars. In fact, their output focused on trucks since there was almost no consumer market for passenger cars at the time. Beginning in 1918, the first DAT trucks were assembled for the military market. The low demand from the military market during the 1920s forced DAT to consider merging with other automotive industries. In 1926 the Tokyo-based DAT Motors merged with the Osaka-based also known as Jitsuyo Motors (established 1919, as a Kubota subsidiary) to become in Osaka until 1932. (Jitsuyo Jidosha began producing a three-wheeled vehicle with an enclosed cab called the Gorham in 1920, and the following year produced a four-wheeled version. From 1923 to 1925, the company produced light cars and trucks under the name of Lila.)

The DAT corporation had been selling full size cars to Japanese consumers under the DAT name since 1914. In 1930, the Japanese government created a ministerial ordinance that allowed cars with engines up to 500 cc to be driven without a license. DAT Automobile Manufacturing began development of a line of 495 cc cars to sell in this new market segment, calling the new small cars "Datson" – meaning "Son of DAT". The name was changed to "Datsun" two years later in 1933.

The first prototype Datson was completed in the summer of 1931. The production vehicle was called the Datson Type 10, and "approximately ten" of these cars were sold in 1931. They sold around 150 cars in 1932, now calling the model the Datsun Type 11. In 1933, government rules were revised to permit engines, and Datsun increased the displacement of their microcar engine to the maximum allowed. These larger displacement cars were called Type 12s.

By 1935, the company had established a true production line, following the example of Ford, and were producing a car closely resembling the Austin 7. There is evidence that six of these early Datsuns were exported to New Zealand in 1936, a market they then re-entered in May 1962. In 1937, Datsun's biggest pre-war year, 8593 were built, with some exported to Australia in knock-down form.

After Japan went to war with China in 1937, passenger car production was restricted, so by 1938, Datsun's Yokohama plant concentrated on building trucks for the Imperial Japanese Army.

When the Pacific War ended, Datsun would turn to providing trucks for the Occupation forces. This lasted until car production resumed in 1947. As before the war, Datsun closely patterned their cars on contemporary Austin products: postwar, the Devon and Somerset were selected. For Datsun's smaller cars (and trucks), such as the DB and DS series, they depended on designs based on the pre-war Austin Seven. The heavier trucks, meanwhile, were based on Chevrolet's 1937 design with an engine of Graham-Paige design. Nissan also built the 4W60 Patrol, based on the Willys Jeep, and the 4W70 Carrier, based on the Dodge M37. Not until January 1955 did Datsun offer a fully indigenous design.

That year, the Occupation returned production facilities to Japanese control, and Datsun introduced the 110 saloon and the 110-based 120 pickup.

The use of the "Datsun" name in the American market derives from the name Nissan used for its production cars. In fact, the cars produced by Nissan already used the Datsun brand name, a successful brand in Japan since 1932, long before World War II. Before the entry into the American market in 1958, Nissan did not produce cars under the Nissan brand name, but only trucks. Their in-house-designed cars were always branded as "Datsuns". Hence, for Nissan executives it would be only natural to use such a successful name when exporting models to the United States. Only in the 1960s did Datsun begin to brand some automobile models as "Nissans", like the Patrol and a small test batch of about 100 Cedric sedans, and then not again until the 1980s. The Japanese market Z-car (sold as the Fairlady Z) also had Nissan badging. In America, the Nissan branch was named ""Nissan Motor Corporation in U.S.A."", and chartered on September 28, 1960, in California, but the small cars the firm exported to America were still named Datsun.

Corporate choice favored Datsun, so as to distance the parent factory Nissan’s association by Americans with Japanese military manufacture. In fact Nissan's involvement in Japan's military industries was substantial. The company's car production at the Yokohama plant shifted towards military needs just a few years after the first passenger cars rolled off the assembly line, on April 11, 1935. By 1939 Nissan's operations had moved to Manchuria, then under Japanese occupation, where its founder and President, Yoshisuke Ayukawa, established the Manchurian Motor Company to manufacture military trucks.

Ayukawa, a well-connected and aggressive risk taker, also made himself a principal partner of the Japanese Colonial Government of Manchukuo. Ultimately, Nissan Heavy Industries emerged near the end of the war as an important player in Japan’s war machinery. After the war ended, Soviet Union seized all of Nissan’s Manchuria assets, while the Occupation Forces made use of over half of the Yokohama plant. General MacArthur had Ayukawa imprisoned for 21 months as a war criminal. After release he was forbidden from returning to any corporate or public office until 1951. He was never allowed back into Nissan, which returned to passenger car manufacture in 1947 and to its original name of Nissan Motor Company Ltd. in 1949.

American service personnel in their teens or early twenties during the Second World War would be in prime car-buying age by 1960, if only to find an economical small second car for their growing family needs. Yutaka Katayama (Mr. "K"), former president of Nissan's American operations, would have had his personal wartime experiences in mind supporting the name Datsun. Katayama's visit to Nissan’s Manchuria truck factory in 1939 made him realise the appalling conditions of the assembly lines, leading him to abandon the firm. In 1945, near the end of the war, Katayama was ordered to return to the Manchurian plant, however he rebuffed these calls and refused to return.

Katayama desired to build and sell passenger cars to people, not to the military; for him, the name ""Datsun"" had survived the war with its purity intact, not ""Nissan"". This obviously led Katayama to have problems with the corporate management. The discouragement felt by Katayama as regards his prospects at Nissan, led to his going on the verge of resigning, when Datsun’s 1958 Australian Mobilgas victories vaulted him, as leader of the winning Datsun teams, to national prominence in a Japan bent on regaining international status.

The company's first product to be exported around the world was the 113, with a proprietary four-cylinder engine.

Datsun entered the American market in 1958, with sales in California. By 1959, the company had dealers across the U.S. and began selling the 310 (known as Bluebird domestically). From 1962 to 1969 the Nissan Patrol utility vehicle was sold in the United States (as a competitor to the Toyota Land Cruiser J40 series), making it the only Nissan-badged product sold in the US prior to that name's introduction worldwide decades later.

From 1960 on, exports and production continued to grow. A new plant was built at Oppama, south of Yokohama; it opened in 1962. The next year, Bluebird sales first topped 200,000, and exports touched 100,000. By 1964, Bluebird was being built at 10,000 cars a month.

For 1966, Datsun debuted the 1000, allowing owners of kei cars to move up to something bigger. That same year, Datsun won the East African Safari Rally and merged with Prince Motors, giving the company the Skyline model range, as well as a test track at Murayama.

The company introduced the Bluebird 510 in 1967. This was followed in 1968 with the iconic 240Z, which proved affordable sports cars could be built and sold profitably: it was soon the world's #1-selling sports car. It relied on an engine based on the Bluebird and used Bluebird suspension components. It would go on to two outright wins in the East African Rally.

Katayama was made Vice President of the Nissan North American subsidiary in 1960, and as long as he was involved in decision making, both as North American Vice President from 1960 to 1965, and then President of Nissan Motor Company U.S.A. from 1965 to 1975, the cars were sold as Datsuns. “What we need to do is improve our car’s efficiency gradually and creep up slowly before others notice. Then, before Detroit realizes it, we will have become an excellent car maker, and the customers will think so too. If we work hard to sell our own cars, we won’t be bothered by whatever the other manufacturers do. If all we do is worry about the other cars in the race, we will definitely lose.”

In 1935, the very first Datsun-badged vehicle was shipped to Britain by car magnate Sir Herbert Austin. The vehicle, a Type 14, was never meant for the road or production, but was a part of a patent dispute as Austin saw a number of similarities to the car with the Austin 7 Ruby. Nissan began exporting Datsun-badged cars to the United Kingdom in 1968, at which time foreign cars were a rarity, with only a small percentage of cars being imported – some of the most popular examples at the time including the Renault 16 from France and Volkswagen Beetle from West Germany. The first European market that Nissan had entered was Finland, where sales began in 1962. Within a few years, it was importing cars to most of Western Europe.

Datsun was particularly successful on the British market. It sold just over 6,000 cars there as late as 1971, but its sales surged to more than 30,000 the following year and continued to climb over the next few years, with well-priced products including the Cherry 100A and Sunny 120Y proving particularly popular, at a time when the British motor industry was plagued by strikes and British Leyland in particular was gaining a reputation for building cars which had major issues with build quality and reliability. During the 1970s and early 1980s, Nissan frequently enjoyed the largest market share in Britain of any foreign carmaker.

By the early 1980s, the Nissan badge was gradually appearing on Datsun-badged cars, and eventually the Datsun branding was phased out, the final new car with a Datsun badge being the Micra supermini, launched in Britain from June 1983. By the end of 1984, the Datsun branding had completely disappeared in Britain, although it lingered elsewhere until 1986.

In Japan, there appears to have been what probably constituted a long-held 'official' company bias against use of the name "Datsun". At the time, Kawamata was a veteran of Nissan, in the last year of his presidency, a powerful figure whose experience in the firm exceeded two decades. His rise to its leadership position occurred in 1957 in part because of his handling of the critical Nissan workers' strike that began May 25, 1953, and ran for 100 days. During his tenure as President, Kawamata stated that he "regretted that his company did not imprint its corporate name on cars, the way Toyota does. 'Looking back, we wish we had started using Nissan on all of our cars,' he says. 'But Datsun was a pet name for the cars when we started exporting.'"

Ultimately, the decision was made to stop using the brand name "Datsun" worldwide, in order to strengthen the company name "Nissan".

"The decision to change the name Datsun to Nissan in the U.S. was announced in the autumn (September/October) of 1981. The rationale was that the name change would help the pursuit of a global strategy. A single name worldwide would increase the possibility that advertising campaigns, brochures, and promotional materials could be used across countries and simplify product design and manufacturing. Further, potential buyers would be exposed to the name and product when traveling to other countries. Industry observers, however, speculated that the most important motivation was that a name change would help Nissan market stocks and bonds in the U.S. They also presumed substantial ego involvement, since the absence of the Nissan name in the U.S. surely rankled Nissan executives who had seen Toyota and Honda become household words."

Ultimately, the name change campaign lasted for a three-year period from 1982 to 1984 – Datsun badged vehicles had been progressively fitted with small "Nissan" and "Datsun by Nissan" badges from the late 1970s onward until the Nissan name was given prominence in 1983 – although in some export markets vehicles continued to wear both the Datsun and Nissan badges until 1986. In the United Kingdom for example, the Nissan name initially was used as a prefix to the model name, with Datsun still being used as the manufacturer's name (e.g. Datsun-Nissan Micra) from 1982 until 1984. The name change had cost Nissan a figure in the region of US$500 million. Operational costs included the changing of signs at 1,100 Datsun dealerships, and amounted to US$30 million. Another US$200 million were spent during the 1982 to 1986 advertising campaigns, where the ""Datsun, We Are Driven!"" campaign (which was adopted in late 1977 in the wake of the 1973 oil crisis and subsequent 1979 energy crisis) yielded to ""The Name is Nissan"" campaign. (The latter campaign was used for some years beyond 1985.) Another US$50 million was spent on Datsun advertisements that were paid for but stopped or never used. Five years after the name change program was over, "Datsun" still remained more familiar than "Nissan".

In 2001, Nissan marketed its D22 pick-up model in Japan with the name "Datsun". This time however, the use of the brand name was wholly restricted to this one specific model name. Production of this model was between May 2001 and October 2002.

On 20 March 2012, it was announced that Nissan would revive the Datsun marque as a low-cost car brand for use in Indonesia, South Africa, India, and Russia, and on 15 July 2013, nearly three decades after it was phased out, the name was formally resurrected. Nissan said the brand's reputation for value and reliability would help it gain market share in emerging markets.

The Datsun brand was re-launched in New Delhi, India, with the Datsun Go, planned to be on sale in India in early 2014. Datsun models are sold in Indonesia, Russia, India and South Africa since 2014. The brand entered Kazakhstan in 2015, Belarus and Lebanon in 2016.

The Datsun Go will be built at the Renault-Nissan plant in Chennai, India. Production is also planned in Russia and Indonesia. The Go is based on the same Nissan V platform as the Nissan Micra. The Go+, a minivan, was added to the range in September 2013.

In February 2014, the Redi-Go concept car was presented.

The Redi-Go crossover became available in India mid-2015.

In April 2014, the first model for the Russian market, the Datsun on-Do based on Lada Granta, was launched.






</doc>
<doc id="8078" url="https://en.wikipedia.org/wiki?curid=8078" title="Dynamite">
Dynamite

Dynamite is an explosive made of nitroglycerin, sorbents (such as powdered shells or clay) and stabilizers. It was invented by the Swedish chemist and engineer Alfred Nobel in Geesthacht and patented in 1867. It rapidly gained wide-scale use as a more powerful alternative to black powder. 

Today, dynamite is mainly used in the mining, quarrying, construction, and demolition industries. Dynamite is still the product of choice for trenching applications, and as a cost-effective alternative to cast boosters. Dynamite is occasionally used as an initiator or booster for AN and ANFO explosive charges.

Dynamite was invented by Swedish chemist Alfred Nobel in the 1860s and was the first safely manageable explosive stronger than black powder, which had been invented in China in the 9th century. Black powder is now popularly known as gunpowder, because while it is effective as a propellant, it is less suitable for shattering rock or fortifications.

Alfred Nobel's father, Immanuel Nobel, was an industrialist, engineer, and inventor. He built bridges and buildings in Stockholm and founded Sweden's first rubber factory. His construction work inspired him to research new methods of blasting rock that were more effective than black powder. After some bad business deals in Sweden, in 1838 Immanuel moved his family to Saint Petersburg, where Alfred and his brothers were educated privately under Swedish and Russian tutors. At age 17, Alfred was sent abroad for two years; in the United States he met Swedish engineer John Ericsson and in France studied under famed chemist Théophile-Jules Pelouze and his pupil Ascanio Sobrero who had first synthesized nitroglycerin in 1847. It was in France that Nobel first encountered nitroglycerin, which Pelouze cautioned against using as a commercial explosive because of its high volatility (tendency to ignite). 

In 1857, Nobel filed the first of several hundred patents, mostly concerning air pressure, gas and fluid gauges, but remained fascinated with nitroglycerin's potential as an explosive. Nobel, along with his father and brother Emil, experimented with various combinations of nitroglycerin and black powder. Nobel came up with a solution of how to safely detonate nitroglycerin by inventing the detonator, or blasting cap, that allowed a controlled explosion set off from a distance using a fuse. In the summer of 1863, Nobel performed his first successful detonation of pure nitroglycerin, using a blasting cap made of a copper percussion cap and mercury fulminate. In 1864, Alfred Nobel filed patents for both the blasting cap and his method of synthesizing nitroglycerin, using sulfuric acid, nitric acid and glycerin. On 3 September 1864, while experimenting with nitroglycerin, Emil and several others were killed in an explosion at the factory at Immanuel Nobel's estate at Heleneborg. After this, Alfred founded the company Nitroglycerin Aktiebolaget AB in Vinterviken to continue work in a more isolated area and the following year moved to Germany, where he founded another company, Dynamit Nobel. 

Despite the invention of the blasting cap, the volatility of nitroglycerin rendered it useless as a commercial explosive. To solve this problem, Nobel sought to combine it with another substance that would make it safe for transport and handling but yet would not reduce its effectiveness as an explosive. He tried combinations of cement, coal, and sawdust, but was unsuccessful. Finally, he tried diatomaceous earth, fossilized algae, that he brought from the Elbe River near his factory in Hamburg, which successfully stabilized the nitroglycerin into a portable explosive. 

Nobel obtained patents for his inventions in England on 7 May 1867 and in Sweden on 19 October 1867. After its introduction, dynamite rapidly gained wide-scale use as a safe alternative to black powder and nitroglycerin. Nobel tightly controlled the patents, and unlicensed duplicating companies were quickly shut down. However, a few American businessmen got around the patent by using a slightly different formula.

Nobel originally sold dynamite as "Nobel's Blasting Powder" but decided to change the name to dynamite, from the Ancient Greek word "dýnamis" (), meaning "power".

Nitroglycerin by itself is a very strong explosive, but is extremely shock-sensitive (that is, physical shock can cause it to explode), and degrades over time to even more unstable forms, which makes it highly dangerous to transport or use. Dynamite combines nitroglycerin with absorbents and stabilizers, rendering it safe to use while retaining its powerful explosive properties.

Nobel's original composition of dynamite consisted of three parts "explosive oil" (as nitroglycerin was called), one part diatomaceous earth as the absorbent, and a small admixture of sodium carbonate antacid as the stabilizer. Ethylene glycol dinitrate was later added to the nitroglycerin to lower its freezing point and keep it from freezing into a slush at low temperatures, which made it unstable, or from sweating out when it thawed. Diatomaceous earth is not usually used today as an absorbent medium and it has been replaced by cheaper media such as sawdust, wood pulp, flour, or starch. Other stabilizers, such as calcium carbonate or zinc oxide, can be used in the place of sodium carbonate. Sodium nitrate is added to the medium as an oxidizer to improve the dynamite's brisance.

Dynamite is usually sold in the form of cardboard cylinders about long and about in diameter, with a weight of about . A stick of dynamite thus produced contains roughly 1 MJ (megajoule) of energy. Other sizes also exist, rated by either portion (Quarter-Stick or Half-Stick) or by weight.

Dynamite is usually rated by "weight strength" (the amount of nitroglycerin it contains), usually from 20% to 60%. For example, "40% dynamite" is composed of 40% nitroglycerin and 60% "dope" (the absorbent storage medium mixed with the stabilizer and any additives).

The maximum shelf life of nitroglycerin-based dynamite is recommended as one year from the date of manufacture under good storage conditions.

Over time, regardless of the sorbent used, sticks of dynamite will "weep" or "sweat" nitroglycerin, which can then pool in the bottom of the box or storage area. For that reason, explosive manuals recommend the repeated turning over of boxes of dynamite in storage. Crystals will form on the outside of the sticks, causing them to be even more sensitive to shock, friction, and temperature. Therefore, while the risk of an explosion without the use of a blasting cap is minimal for fresh dynamite, old dynamite is dangerous. Modern packaging helps eliminate this by placing the dynamite into sealed plastic bags, and using wax-coated cardboard.

Dynamite is moderately sensitive to shock. Shock resistance tests are usually carried out with a drop-hammer: about 100 mg of explosive is placed on an anvil, upon which a weight of between is dropped from different heights until detonation is achieved. With a hammer of 2 kg, mercury fulminate detonates with a drop distance of 1 to 2 cm, nitroglycerin with 4 to 5 cm, dynamite with 15 to 30 cm, and ammoniacal explosives with 40 to 50 cm.

For several decades beginning in the 1940s, the largest producer of dynamite in the world was the Union of South Africa. There the De Beers company established a factory in 1902 at Somerset West. The explosives factory was later operated by AECI (African Explosives and Chemical Industries). The demand for the product came mainly from the country's vast gold mines, centered on the Witwatersrand. The factory at Somerset West was in operation in 1903 and by 1907 it was already producing 340,000 cases, each, annually. A rival factory at Modderfontein was producing another 200,000 cases per year.

There were two large explosions at the Somerset West plant during the 1960s. Some workers died, but the loss of life was limited by the modular design of the factory and its earth works, and the planting of trees that directed the blasts upward. There were several other explosions at the Modderfontein factory. After 1985, pressure from trade unions forced AECI to phase out the production of dynamite. The factory then went on to produce ammonium nitrate emulsion-based explosives that are safer to manufacture and handle.

Dynamite was first manufactured in the U.S. by the Giant Powder Company of San Francisco, California, whose founder had obtained the exclusive rights from Nobel in 1867. Giant was eventually acquired by DuPont, which produced dynamite under the Giant name until Giant was dissolved by Du Pont in 1905.
Thereafter, DuPont produced dynamite under its own name until 1911-12 when its explosives monopoly was broken up by the U.S. Circuit Court in the "Powder Case". 
Two new companies were formed upon the breakup, the Hercules Powder Company and the Atlas Powder Company, which took up the manufacture of dynamite (in different formulations) thereafter.

Currently only Dyno Nobel manufactures dynamite in the US. The only facility producing it is located in Carthage, Missouri, but the material is purchased from Dyno Nobel by other manufacturers, who put their labels on the dynamite and boxes.

Other explosives are often referred to or confused with dynamite:

TNT is most commonly assumed to be the same as (or confused for) dynamite, largely due to the ubiquity of both explosives during the 20th century and the civilian practice of preparing dynamite charges in 8x1" "sticks" wrapped in red waxed paper and shaped to fit the cylindrical boreholes drilled in the rock face. This incorrect connection between TNT and dynamite was enhanced by Bugs Bunny cartoons where animators started labeling "any" kind of cartoon bomb (ranging from sticks of dynamite to kegs of black powder) as "TNT" because the acronym was shorter, more memorable and didn't require literacy to recognize "TNT" meant "bomb" (similar to the use of XXX markings on whiskey bottles and barrels in cartoons). This eventually led to the general perception that TNT and dynamite were one and the same.

In actuality, aside from both being high explosives, TNT and dynamite have very little in common: TNT is a 2nd generation castable explosive adopted by the military. "The German armed forces adopted it as a filling for artillery shells in 1902" 40 years after dynamite, which is a 1st generation phlegmatized explosive primarily intended for civilian earthmoving. TNT has never been popular or widespread in civilian earthmoving, as it is considerably more expensive and less powerful by weight than dynamite, as well as being slower to mix and pack into cylindrical boreholes; for its part, dynamite has never been popular in warfare because it degenerates quickly under severe conditions and can be detonated by either fire or a wayward bullet. TNT's primary asset is its remarkable insensitivity and stability: a full generation better than dynamite, it is waterproof and incapable of detonating without the extreme shock and heat provided by a blasting cap (or a sympathetic detonation); this conveniently also allows it to be melted at , poured into high explosive shells and allowed to re-solidify with no extra danger or change in the TNT's characteristics. As such, more than 90% of the TNT produced in America was always for the military market, with most filling shells, hand grenades and aerial bombs and the remainder being packaged in brown "bricks" (not red cylinders) for use as demolition charges by combat engineers.

In the United States, in 1885, the chemist Russell S. Penniman invented "ammonium dynamite", a form of explosive that used ammonium nitrate as a substitute for the more costly nitroglycerin. Ammonium nitrate has only 85% of the chemical energy of nitroglycerin.

It is rated by either "weight strength" (the amount of ammonium nitrate in the medium) or "cartridge strength" (the potential explosive strength generated by an amount of explosive of a certain density and grain size used in comparison to the explosive strength generated by an equivalent density and grain size of a standard explosive). For example, high-explosive "65% Extra Dynamite" has a weight strength of 65% ammonium nitrate and 35% "dope" (the absorbent medium mixed with the stabilizers and additives). Its "cartridge strength" would be its weight in pounds times its strength in relation to an equal amount of ANFO (the civilian baseline standard) or TNT (the military baseline standard). For example, 65% ammonium dynamite with a 20% cartridge strength would mean the stick was equal to an equivalent weight strength of 20% ANFO.

"Military dynamite" is a dynamite substitute, formulated without nitroglycerin. It contains 75% RDX, 15% TNT, 5% SAE 10 motor oil, and 5% cornstarch, but is much safer to store and handle for long periods than Nobel's dynamite. Military dynamite substitutes much more stable chemicals for nitroglycerin.

Various countries around the world have enacted explosives laws and require licenses to manufacture, distribute, store, use, and possess explosives or ingredients.





</doc>
<doc id="8079" url="https://en.wikipedia.org/wiki?curid=8079" title="David Fincher">
David Fincher

David Andrew Leo Fincher (born August 28, 1962) is an American film director, film producer, television director, television producer, and music video director. He was nominated for the Academy Award for Best Director for "The Curious Case of Benjamin Button" (2008) and "The Social Network" (2010). For the latter, he won the Golden Globe Award for Best Director and the BAFTA Award for Best Direction.

He is also known for having directed "Alien 3" in his directorial debut, and most known for films in the thriller genre, including "Seven" (1995), "The Game" (1997), "Fight Club" (1999), "Panic Room" (2002), "Zodiac" (2007), "The Girl with the Dragon Tattoo" (2011) and "Gone Girl" (2014). He was also instrumental in the creation of the Netflix series "House of Cards" (2013–2018) and "Mindhunter" (2017–present).

His films "Zodiac" and "The Social Network" are ranked in BBC's 100 Greatest Films of the 21st Century.

Fincher was born on August 28, 1962 in Denver, Colorado, the son of Claire Mae (née Boettcher), a mental health nurse from South Dakota who worked in drug addiction programs, and Howard Kelly "Jack" Fincher, an author from Oklahoma who worked as a reporter and bureau chief for "Life". Howard died of cancer in April 2003. Fincher knew from a young age he wanted to go into filmmaking. When Fincher was two years old, the family moved to San Anselmo, California, where filmmaker George Lucas was one of his neighbors.

Fincher moved to Ashland, Oregon in his teens, where he graduated from Ashland High School. During high school, he directed plays and designed sets and lighting after school, and was a non-union projectionist at a second-run movie theater, production assistant at the local television news station KOBI in Medford, Oregon, and took on other odd jobs such as fry cook, busboy, and dishwasher. Inspired by "Butch Cassidy and the Sundance Kid" (1969), Fincher began making movies at age eight with an 8mm camera.

Fincher was employed at Korty Films as a production head. He then moved up the ranks and became a visual effects producer, working on the animated "Twice Upon a Time" (1983). He was hired by Industrial Light & Magic in 1983 as an assistant cameraman and matte photographer, and worked on "Return of the Jedi" (1983) and "Indiana Jones and the Temple of Doom" (1984). In 1984, he left ILM to direct a commercial for the American Cancer Society that depicted a fetus smoking a cigarette. This quickly brought Fincher to the attention of producers in Los Angeles, and he was given the chance to direct the 1985 Rick Springfield documentary "The Beat of the Live Drum". Set on a directing career, Fincher co-founded video-production company Propaganda Films and started off directing music videos and commercials.

Like Fincher, directors such as Michael Bay, Antoine Fuqua, Michel Gondry, Spike Jonze, Alex Proyas, Paul Rachman, Mark Romanek, Zack Snyder, Gore Verbinski and others honed their talents at Propaganda Films before moving on to feature films. Though he would continue to direct spots for Levi's, Converse, Nike, Pepsi, Revlon, Sony, Coca-Cola, Chanel, and other companies, Fincher began to focus on music videos. He directed the video for 1986's "We Don't Have to Take Our Clothes Off", which was the biggest commercial success for pop/R&B singer Jermaine Stewart, Michael Jackson's "Who Is It", and worked extensively with Madonna, directing videos for "Express Yourself", "Oh Father", "Vogue" and "Bad Girl". He also directed Billy Idol's "Cradle of Love" video. Fincher referred to the production of music videos as his own kind of film school, in which he learned how to work efficiently within a small budget and time frame.

20th Century Fox hired Fincher to replace Vincent Ward as the director of the science fiction horror film "Alien 3" (1992), his feature directorial debut. The third installment in the "Alien" franchise starring Sigourney Weaver, the film was released in May 1992 to a mixed reception from critics and was considered weaker than the preceding films in the franchise. Film critic Roger Ebert, considered it to be "one of the best looking bad movies he's ever seen". Fincher became involved with several disputes with 20th Century Fox over script and budget issues during the production. In "Director's Cut: Picturing Hollywood in the 21st Century", he blames the producers for not putting the necessary trust in him. He stated in an interview with "The Guardian" in 2009: "No one hated it more than me; to this day, no one hates it more than me." It received an Academy Award nomination for Best Visual Effects.

After directing the film, he retreated back into the world of commercial and music video directing, including the video for the Grammy Award for Best Short Form Music Video-winning song "Love Is Strong" by The Rolling Stones in 1994. Following the difficult production of "Alien 3", Fincher thought that he would "rather die of colon cancer than do another movie" and eschewed reading scripts. Despite this, Fincher read Andrew Kevin Walker's screenplay for "Seven" (1995), which was actually Walker's original draft with the current ending, that was already removed by then attached director Jeremiah Chechik. Fincher expressed no interest in directing after reading the revised draft, until New Line Cinema agreed to keep the original ending. It stars Brad Pitt, Morgan Freeman, Gwyneth Paltrow, R. Lee Ermey, and Kevin Spacey, and tells the story of two detectives (played by Pitt and Freeman) tracking down a serial killer who bases his killings on the seven deadly sins. "Seven" was one of the highest-earning films of 1995, grossing more than $320 million internationally and was positively received by film critics. Writing for "Sight and Sound", John Wrathall wrote that it "stands as the most complex and disturbing entry in the serial killer genre since "Manhunter"" and Roger Ebert opined that "Seven" is "one of the darkest and most merciless films ever made in the Hollywood mainstream."

After the success of "Seven", Fincher went on to film a music video for "6th Avenue Heartache" by The Wallflowers and the thriller "The Game" (1997) from a screenplay by the screenwriting duo John Brancato and Michael Ferris. The story focuses on a San Franciscan investment banker (played by Michael Douglas) who receives an unusual gift from his younger brother (Sean Penn), in which he becomes involved in a "game" that integrates in strange ways with his everyday life, leading to frustration and uncertainty between the game and real life. Fincher hired "Seven" screenwriter Andrew Kevin Walker to make contributions and polishes to the script. The film had middling box office returns, despite being met with generally positive reviews, with specific praise for Fincher's direction and Douglas' performance.

In August 1997, Fincher agreed to direct a screen adaptation of Chuck Palahniuk's 1996 novel "Fight Club" for 20th Century Fox, his second film with the studio after the troubled production of "Alien 3". The film stars Edward Norton, Brad Pitt, and Helena Bonham Carter and follows an insomniac office worker who is known simply as The Narrator, played by Norton, who opens up a club devoted exclusively to bare knuckle fighting for men with soap salesman Tyler Durden (Pitt). "Fight Club" was an early disappointment at the box office and initially received mixed reviews. In the years following its release, "Fight Club" received a reassessment from many critics. "Entertainment Weekly", which had originally given the film a D-, later ranked the DVD #1 on its list of 50 Essential DVDs. The film's social commentary has been the source of much critical analysis from academics and film critics. Around the same period, Fincher was shortlisted by Columbia Pictures, as one of the potential directors for "Spider-Man": a live-action adaptation of the fictional comic-book character of the same name. Fincher's concept for the project had a more mature, psychologically-rooted and less action-oriented take on the classic Spider-Man mythos, skipped the titular character's origin story, instead covering those events in a 10-minute title sequence, put an emphasis on the character's struggles with his post-high school life and his super-human abilities, along with his relationship with his girlfriend/love interest: Gwen Stacy, featured the classic Spider-Man villain: the Green Goblin, as the main antagonist and would have also served as an adaptation of the iconic comic-book storyline: "The Night Gwen Stacy Died", which featured the death of Gwen Stacy at the hands of the Goblin. However, Fincher's pitch was rejected by the studio, with Sam Raimi later being hired to helm the project.

In 2002, Fincher followed up with the thriller "Panic Room". The film earned over $92 million at the U.S. box office. The story follows a single mother (Jodie Foster) and her daughter (Kristen Stewart) as they hide in a safe room of their new house, away from criminals (Forest Whitaker, Dwight Yoakam, and "Fight Club" collaborator Jared Leto) bent on finding a missing fortune. Fincher acknowledged "Panic Room" as a more mainstream thriller, describing the film, on the DVD's audio commentary, as "[basically] a date movie" and a "really good B movie" about "two people trapped in a closet".

Five years after "Panic Room", Fincher returned on March 2, 2007 with "Zodiac", an adaptation of Robert Graysmith's books about the hunt for the Zodiac Killer that starred Jake Gyllenhaal, Mark Ruffalo, Robert Downey, Jr., Anthony Edwards, and Brian Cox. The first of Fincher's films to be shot digitally, the majority of the film was recorded on a Thomson Viper FilmStream HD digital movie camera . However, high-speed film cameras were used for the Blue Rock Springs and Presidio Heights murder scenes for the slow-motion shots. It was originally to be released in the fall of 2006 but was pushed back after Fincher refused to cut 20 minutes off the film.

"Zodiac" was one of the best-reviewed films of that year, with only two other 2007 films appearing on more top-10 lists ("No Country for Old Men" and "There Will Be Blood"). However, the film struggled at the box office in the U.S., earning only $33 million, but did well overseas with a foreign gross of $51.7 million. Worldwide, "Zodiac" was a decent success. Despite an aggressive campaign by the studio, expectations surrounding Robert Downey, Jr.'s supporting performance, Fincher's direction and Vanderbilt's adapted script, the film did not earn a single Oscar nomination.

A story about life and death, "The Curious Case of Benjamin Button" is an adaptation of F. Scott Fitzgerald's short story of the same name. The film was Fincher's third with Brad Pitt. The film started shooting in November 2006 in New Orleans, before moving on to the Virgin Islands, Montreal, and L.A. Both "Zodiac" and this film are co-productions of Paramount Pictures and Warner Bros. The budget for the film was estimated at $150 million, partly due to the visual effects used to reverse the aging in Pitt's character. It received 13 nominations at the 81st Academy Awards, including Fincher's first nomination for Best Director. It won three Academy Awards for Best Art Direction, Best Makeup, and Best Visual Effects.

Fincher directed the 2010 film "The Social Network", about the legal battles of Mark Zuckerberg and the founding of Facebook. The film features an Oscar-winning screenplay by Aaron Sorkin, adapted from the book "The Accidental Billionaires". Filming started in October 2009 and was released a year later, to critical acclaim. Trent Reznor and Atticus Ross created the Oscar-winning soundtrack for the film. The film went on to win many awards, including three Academy Awards for Best Adapted Screenplay, Best Original Score, and Best Film Editing.

In 2011, Fincher directed the American version of "The Girl with the Dragon Tattoo", based on the book by Stieg Larsson, with a script written by Steven Zaillian. The film was shot in Sweden, with Rooney Mara as Lisbeth Salander and Daniel Craig as Mikael Blomkvist. Trent Reznor and Atticus Ross composed the soundtrack for the film, collaborating with Fincher a second time. The film received five Academy Award nominations, including Best Actress for Mara, and won the award for Best Film Editing.

Fincher is an executive producer of the Netflix television series "House of Cards", of which he also directed the first two episodes. The series has received positive reviews, earning nine Primetime Emmy nominations, including Outstanding Drama Series and winning Fincher the Primetime Emmy Award for Outstanding Directing for a Drama Series for the first episode.

In 2014, Fincher directed the adaptation of Gillian Flynn's novel "Gone Girl", which starred Ben Affleck and Rosamund Pike. The film earned Pike an Academy Award nomination for Best Actress, Fincher also received his third Golden Globe nomination.

In 2016, Fincher directed another Netflix series, "Mindhunter", starring Holt McCallany and Jonathan Groff. The series, that is based on the book "Mind Hunter: Inside the FBI’s Elite Serial Crime Unit", debuted worldwide on October 13, 2017.



Fincher likes to map out camera movements with computer-generated imagery, commission intricate sets, get heavily involved in post-production, and re-shoot footage after the principal photography has wrapped. He does not normally use hand-held cameras when he shoots a film, preferring cameras on a tripod. His most frequent use of a hand-held camera was for "Seven", in which five scenes were shot that way.

Fincher's music videos very rarely tell a story, focusing instead on conveying the mood of the song. In order to achieve this, the editing, the pans and close-ups of the camera closely follow the rhythms of the music and the lyrics in precise synchrony.

In a Blu-ray bonus featurette of "The Girl With the Dragon Tattoo", Fincher stated: "I think people are perverts. I've maintained that. That's the foundation of my career."

Fincher married model–photographer Donya Fiorentino (born 1967) in 1990 and divorced in 1995. They have a daughter, Phelix Imogen Fincher, born 1994. Fincher is currently married to producer Ceán Chaffin.


As a music video director, Fincher has won two Grammy Awards for Best Music Video, for his work in "Love Is Strong" by The Rolling Stones (1995) and "Suit & Tie" by Justin Timberlake and Jay-Z (2013), and three MTV Video Music Awards for Best Direction, being one of the most awarded directors in the category, alongside Spike Jonze. He also earned back-to-back MTV Video Music Awards for Best Direction in 1989 for Madonna's "Express Yourself" (1989) and for "Vogue" (1990). In 1990, he earned three of the four available nominations in the Best Direction category.

Fincher, alongside Joshua Donen and Eric Roth, won a Peabody Award for their work on "House of Cards".

His films "Zodiac" and "The Social Network" are ranked in the BBC's 100 Greatest Films of the 21st Century list.


! colspan="3" style="background: #DAA520;" | National Board of Review

! colspan="3" style="background: #DAA520;" | National Board of Review


</doc>
<doc id="8080" url="https://en.wikipedia.org/wiki?curid=8080" title="List of decades">
List of decades

This is a list of decades from the beginning of the 2nd millenium BC to the end of the 3rd millenium AD, including links to corresponding articles with more information about them.



</doc>
<doc id="8081" url="https://en.wikipedia.org/wiki?curid=8081" title="Douglas Engelbart">
Douglas Engelbart

Douglas Carl Engelbart (January 30, 1925 – July 2, 2013) was an American engineer and inventor, and an early computer and Internet pioneer. He is best known for his work on founding the field of human–computer interaction, particularly while at his Augmentation Research Center Lab in SRI International, which resulted in creation of the computer mouse, and the development of hypertext, networked computers, and precursors to graphical user interfaces. These were demonstrated at The Mother of All Demos in 1968. Engelbart's law, the observation that the intrinsic rate of human performance is exponential, is named after him.

In the early 1950s, he decided that instead of "having a steady job" – such as his position at Ames Research Center – he would focus on making the world a better place. He reasoned that because the complexity of the world's problems was increasing, and because any effort to improve the world would require the coordination of groups of people, the most effective way to solve problems was to augment human intelligence and develop ways of building collective intelligence. He believed that the computer, which was at the time thought of only as a tool for automation, would be an essential tool for future knowledge workers to solve such problems. He was a committed, vocal proponent of the development and use of computers and computer networks to help cope with the world's increasingly urgent and complex problems. Engelbart embedded a set of organizing principles in his lab, which he termed "bootstrapping". His belief was that when human systems and tool systems were aligned, such that workers spent time "improving their tools for improving their tools" it would lead to an accelerating rate of progress.

NLS, the "oN-Line System," developed by the Augmentation Research Center under Engelbart's guidance with funding primarily from DARPA, demonstrated numerous technologies, most of which are now in widespread use; it included the computer mouse, bitmapped screens, hypertext; all of which were displayed at "The Mother of All Demos" in 1968. The lab was transferred from SRI to Tymshare in the late 1970s, which was acquired by McDonnell Douglas in 1984, and NLS was renamed Augment (now the Doug Engelbart Institute). At both Tymshare and McDonnell Douglas, Engelbart was limited by a lack of interest in his ideas and funding to pursue them, and retired in 1986.

In 1988, Engelbart and his daughter Christina launched the Bootstrap Institute – later known as The Doug Engelbart Institute – to promote his vision, especially at Stanford University; this effort did result in some DARPA funding to modernize the user interface of Augment. In December 2000, United States President Bill Clinton awarded Engelbart the National Medal of Technology, the U.S.'s highest technology award. In December 2008, Engelbart was honored by SRI at the 40th anniversary of the "Mother of All Demos".

Engelbart was born in Portland, Oregon, on January 30, 1925, to Carl Louis Engelbart and Gladys Charlotte Amelia Munson Engelbart. His ancestors were of German, Swedish and Norwegian descent.

He was the middle of three children, with a sister Dorianne (three years older), and a brother David (14 months younger). The family lived in Portland, Oregon, in his early years, and moved to the surrounding countryside along Johnson Creek when he was 8. His father died one year later. He graduated from Portland's Franklin High School in 1942.

Midway through his undergraduate years at Oregon State University, near the end of World War II, he was drafted into the United States Navy, serving two years as a radar technician in the Philippines. On a small island, in a tiny hut on stilts, he read Vannevar Bush's article "As We May Think", which greatly inspired him. He returned to Oregon State and completed his bachelor's degree in electrical engineering in 1948. While at Oregon State, he was a member of Sigma Phi Epsilon social fraternity. He was hired by the National Advisory Committee for Aeronautics at the Ames Research Center, where he worked in wind tunnel maintenance. In his off hours he enjoyed hiking, camping, and folk dancing. It was there he met Ballard Fish (August 18, 1928 – June 18, 1997), who was just completing her training to become an occupational therapist. They were married in Portola State Park on May 5, 1951. Soon after, Engelbart left Ames to pursue graduate studies at the University of California, Berkeley. There, he received an M.S. in electrical engineering in 1953 and a Ph.D. in the discipline in 1955.

Engelbart's career was inspired in December 1950 when he was engaged to be married and realized he had no career goals other than "a steady job, getting married and living happily ever after". Over several months he reasoned that:

In 1945, Engelbart had read with interest Vannevar Bush's article "As We May Think", a call to action for making knowledge widely available as a national peacetime grand challenge. He had also read something about the recent phenomenon of computers, and from his experience as a radar technician, he knew that information could be analyzed and displayed on a screen. He envisioned intellectual workers sitting at display "working stations", flying through information space, harnessing their collective intellectual capacity to solve important problems together in much more powerful ways. Harnessing collective intellect, facilitated by interactive computers, became his life's mission at a time when computers were viewed as number crunching tools.

As a graduate student at Berkeley, he assisted in the construction of CALDIC. His graduate work led to eight patents. After completing his doctorate, Engelbart stayed on at Berkeley as an assistant professor for a year before departing when it became clear that he could not pursue his vision there. Engelbart then formed a startup company, Digital Techniques, to commercialize some of his doctoral research on storage devices, but after a year decided instead to pursue the research he had been dreaming of since 1951.

Engelbart took a position at SRI International (known then as Stanford Research Institute) in Menlo Park, California in 1957. He worked for Hewitt Crane on magnetic devices and miniaturization of electronics; Engelbart and Crane became close friends. At SRI, Engelbart soon obtained a dozen patents, and by 1962 produced a report about his vision and proposed research agenda titled "Augmenting Human Intellect: A Conceptual Framework". Among other highlights, this paper introduced "Building Information Modelling", which architectural and engineering practice eventually adopted (first as "parametric design") in the 1990s and after.

This led to funding from DARPA to launch his work. Engelbart recruited a research team in his new Augmentation Research Center (ARC, the lab he founded at SRI). Engelbart embedded a set of organizing principles in his lab, which he termed "bootstrapping strategy". He designed the strategy to accelerate the rate of innovation of his lab.

The ARC became the driving force behind the design and development of the oN-Line System (NLS). He and his team developed computer interface elements such as bitmapped screens, the mouse, hypertext, collaborative tools, and precursors to the graphical user interface. He conceived and developed many of his user interface ideas in the mid-1960s, long before the personal computer revolution, at a time when most computers were inaccessible to individuals who could only use computers through intermediaries (see batch processing), and when software tended to be written for vertical applications in proprietary systems.
Engelbart applied for a patent in 1967 and received it in 1970, for the wooden shell with two metal wheels (computer mouse – ), which he had developed with Bill English, his lead engineer, sometime before 1965. In the patent application it is described as an "X-Y position indicator for a display system". Engelbart later revealed that it was nicknamed the "mouse" because the tail came out the end. His group also called the on-screen cursor a "bug", but this term was not widely adopted.

He never received any royalties for the invention of the mouse. During an interview, he said "SRI patented the mouse, but they really had no idea of its value. Some years later it was learned that they had licensed it to Apple Computer for something like $40,000." Engelbart showcased the chorded keyboard and many more of his and ARC's inventions in 1968 at The Mother of All Demos.

Engelbart slipped into relative obscurity by the mid-1970s. As early as 1970, several of his researchers became alienated from him and left his organization for Xerox PARC, in part due to frustration, and in part due to differing views of the future of computing. Engelbart saw the future in collaborative, networked, timeshare (client-server) computers, which younger programmers rejected in favor of the personal computer. The conflict was both technical and ideological: the younger programmers came from an era where centralized power was highly suspect, and personal computing was just barely on the horizon.

Beginning in 1972, several key ARC personnel were involved in Erhard Seminars Training (EST), with Engelbart ultimately serving on the corporation's board of directors for many years. Although EST had been recommended by other researchers, the controversial nature of EST and other social experiments reduced the morale and social cohesion of the ARC community. The 1969 Mansfield Amendment, which ended military funding of non-military research, the end of the Vietnam War, and the end of the Apollo program gradually reduced ARC's funding from DARPA and NASA throughout the early 1970s.

SRI's management, which disapproved of Engelbart's approach to running the center, placed the remains of ARC under the control of artificial intelligence researcher Bertram Raphael, who negotiated the transfer of the laboratory to a company called Tymshare in 1976. Engelbart's house in Atherton, California burned down during this period, causing him and his family further problems. Tymshare took over NLS and the lab that Engelbart had founded, hired most of the lab's staff (including its creator as a Senior Scientist), renamed the software "Augment", and offered it as a commercial service via its new Office Automation Division. Tymshare was already somewhat familiar with NLS; when ARC was still operational, it had experimented with its own local copy of the NLS software on a minicomputer called OFFICE-1, as part of a joint project with ARC.

At Tymshare, Engelbart soon found himself further marginalized. Operational concerns at Tymshare overrode Engelbart's desire to conduct ongoing research. Various executives, first at Tymshare and later at McDonnell Douglas, which acquired Tymshare in 1984, expressed interest in his ideas, but never committed the funds or the people to further develop them. His interest inside of McDonnell Douglas was focused on the enormous knowledge management and IT requirements involved in the life cycle of an aerospace program, which served to strengthen Engelbart's resolve to motivate the information technology arena toward global interoperability and an open hyperdocument system. Engelbart retired from McDonnell Douglas in 1986, determined to pursue his work free from commercial pressure.

Teaming with his daughter, Christina Engelbart, he founded the Bootstrap Institute in 1988 to coalesce his ideas into a series of three-day and half-day management seminars offered at Stanford University from 1989 to 2000. By the early 1990s there was sufficient interest among his seminar graduates to launch a collaborative implementation of his work, and the Bootstrap Alliance was formed as a non-profit home base for this effort. Although the invasion of Iraq and subsequent recession spawned a rash of belt-tightening reorganizations which drastically redirected the efforts of their alliance partners, they continued with the management seminars, consulting, and small-scale collaborations. In the mid-1990s they were awarded some DARPA funding to develop a modern user interface to Augment, called Visual AugTerm (VAT), while participating in a larger program addressing the IT requirements of the Joint Task Force.

Engelbart was Founder Emeritus of the Doug Engelbart Institute, which he founded in 1988 with his daughter Christina Engelbart, who is Executive Director. The Institute promotes Engelbart's philosophy for boosting Collective IQ—the concept of dramatically improving how we can solve important problems together—using a strategic "bootstrapping" approach for accelerating our progress toward that goal. In 2005, Engelbart received a National Science Foundation grant to fund the open source HyperScope project. The Hyperscope team built a browser component using Ajax and Dynamic HTML designed to replicate Augment's multiple viewing and jumping capabilities (linking within and across various documents).

Engelbart attended the Program for the Future 2010 Conference where hundreds of people convened at The Tech Museum in San Jose and online to engage in dialog about how to pursue his vision to augment collective intelligence.

The most complete coverage of Engelbart's bootstrapping ideas can be found in "Boosting Our Collective IQ", by Douglas C. Engelbart, 1995. This includes three of Engelbart's key papers, edited into book form by Yuri Rubinsky and Christina Engelbart to commemorate the presentation of the 1995 SoftQuad Web Award to Doug Engelbart at the World Wide Web conference in Boston in December 1995. Only 2,000 softcover copies were printed, and 100 hardcover, numbered and signed by Engelbart and Tim Berners-Lee. Engelbart's book is now being republished by the Doug Engelbart Institute.

Two comprehensive histories of Engelbart's laboratory and work are in "What the Dormouse Said: How the Sixties Counterculture Shaped the Personal Computer Industry" by John Markoff and "A Heritage of Innovation: SRI's First Half Century" by Donald Neilson. Other books on Engelbart and his laboratory include "Bootstrapping: Douglas Engelbart, Coevolution, and the Origins of Personal Computing" by Thierry Bardini and "The Engelbart Hypothesis: Dialogs with Douglas Engelbart", by Valerie Landau and Eileen Clegg in conversation with Douglas Engelbart. All four of these books are based on interviews with Engelbart as well as other contributors in his laboratory.

Engelbart served on the Advisory Boards of the University of Santa Clara Center for Science, Technology, and Society, Foresight Institute, Computer Professionals for Social Responsibility, The Technology Center of Silicon Valley, and The Liquid Information Company.

Engelbart had four children, Gerda, Diana, Christina and Norman with his first wife Ballard, who died in 1997 after 47 years of marriage. He remarried on January 26, 2008 to writer and producer Karen O'Leary Engelbart. An 85th birthday celebration was held at the Tech Museum of Innovation. Engelbart died at his home in Atherton, California on July 2, 2013, due to kidney failure. According to the Doug Engelbart Institute, his death came after a long battle with Alzheimer's disease, which he was diagnosed with in 2007. Engelbart was 88 and was survived by his second wife, the four children from his first marriage, and nine grandchildren.

Historian of science Thierry Bardini argues that Engelbart's complex personal philosophy (which drove all his research) foreshadowed the modern application of the concept of coevolution to the philosophy and use of technology. Bardini points out that Engelbart was strongly influenced by the principle of linguistic relativity developed by Benjamin Lee Whorf. Where Whorf reasoned that the sophistication of a language controls the sophistication of the thoughts that can be expressed by a speaker of that language, Engelbart reasoned that the state of our current technology controls our ability to manipulate information, and that fact in turn will control our ability to develop new, improved technologies. He thus set himself to the revolutionary task of developing computer-based technologies for manipulating information directly, and also to improve individual and group processes for knowledge-work.

Since the late 1980s, prominent individuals and organizations have recognized the seminal importance of Engelbart's contributions. In December 1995, at the Fourth WWW Conference in Boston, he was the first recipient of what would later become the Yuri Rubinsky Memorial Award. In 1997 he was awarded the Lemelson-MIT Prize of $500,000, the world's largest single prize for invention and innovation, and the ACM Turing Award. To mark the 30th anniversary of Engelbart's 1968 demo, in 1998 the Stanford Silicon Valley Archives and the Institute for the Future hosted "Engelbart's Unfinished Revolution", a symposium at Stanford University's Memorial Auditorium, to honor Engelbart and his ideas. He was inducted into National Inventors Hall of Fame in 1998.

Also in 1998, Association for Computing Machinery (ACM) SIGCHI awarded Engelbart the CHI Lifetime Achievement Award. ACM SIGCHI later inducted Engelbart into the CHI Academy in 2002. Engelbart was awarded The Franklin Institute's Certificate of Merit in 1996 and the Benjamin Franklin Medal in 1999 in Computer and Cognitive Science. In early 2000 Engelbart produced, with volunteers and sponsors, what was called "The Unfinished Revolution – II", also known as the "Engelbart Colloquium" at Stanford University, to document and publicize his work and ideas to a larger audience (live, and online).

In December 2000, U.S. President Bill Clinton awarded Engelbart the National Medal of Technology, the country's highest technology award. In 2001 he was awarded the British Computer Society's Lovelace Medal. In 2005, he was made a Fellow of the Computer History Museum "for advancing the study of human–computer interaction, developing the mouse input device, and for the application of computers to improving organizational efficiency." He was honored with the Norbert Wiener Award, which is given annually by Computer Professionals for Social Responsibility. Robert X. Cringely did an hour-long interview with Engelbart on December 9, 2005 in his NerdTV video podcast series.

On December 9, 2008, Engelbart was honored at the 40th Anniversary celebration of the 1968 "Mother of All Demos". This event, produced by SRI International, was held at Memorial Auditorium at Stanford University. Speakers included several members of Engelbart's original Augmentation Research Center (ARC) team including Don Andrews, Bill Paxton, Bill English, and Jeff Rulifson, Engelbart's chief government sponsor Bob Taylor, and other pioneers of interactive computing, including Andy van Dam and Alan Kay. In addition, Christina Engelbart spoke about her father's early influences and the ongoing work of the Doug Engelbart Institute.

In June 2009, the New Media Consortium recognized Engelbart as an NMC Fellow for his lifetime of achievements. In 2011, Engelbart was inducted into IEEE Intelligent Systems' AI's Hall of Fame. Engelbart received the first honorary Doctor of Engineering and Technology degree from Yale University in May 2011.





</doc>
<doc id="8082" url="https://en.wikipedia.org/wiki?curid=8082" title="Diamond">
Diamond

Diamond is a solid form of the element carbon with its atoms arranged in a crystal structure called diamond cubic. At room temperature and pressure, another solid form of carbon known as graphite is the chemically stable form, but diamond almost never converts to it. Diamond has the highest hardness and thermal conductivity of any natural material, properties that are utilized in major industrial applications such as cutting and polishing tools. They are also the reason that diamond anvil cells can subject materials to pressures found deep in the Earth.

Because the arrangement of atoms in diamond is extremely rigid, few types of impurity can contaminate it (two exceptions being boron and nitrogen). Small numbers of defects or impurities (about one per million of lattice atoms) color diamond blue (boron), yellow (nitrogen), brown (defects), green (radiation exposure), purple, pink, orange or red. Diamond also has relatively high optical dispersion (ability to disperse light of different colors).

Most natural diamonds have ages between 1 billion and 3.5 billion years. Most were formed at depths between in the Earth's mantle, although a few have come from as deep as . Under high pressure and temperature, carbon-containing fluids dissolved minerals and replaced them with diamonds. Much more recently (tens to hundreds of million years ago), they were carried to the surface in volcanic eruptions and deposited in igneous rocks known as kimberlites and lamproites.

Synthetic diamonds can be grown from high-purity carbon under high pressures and temperatures or from hydrocarbon gas by chemical vapor deposition (CVD). Imitation diamonds can also be made out of materials such as cubic zirconia and silicon carbide. Natural, synthetic and imitation diamonds are most commonly distinguished using optical techniques or thermal conductivity measurements.

Diamond is a solid form of pure carbon with its atoms arranged in a crystal. Solid carbon comes in different forms known as allotropes depending on the type of chemical bond. The two most common allotropes of pure carbon are diamond and graphite. In graphite the bonds are sp orbital hybrids and the atoms form in planes with each bound to three nearest neighbors 120 degrees apart. In diamond they are sp and the atoms form tetrahedra with each bound to four nearest neighbors. Tetrahedra are rigid, the bonds are strong, and of all known substances diamond has the greatest number of atoms per unit volume, which is why it is both the hardest and the least compressible. It also has a high density, ranging from 3150 to 3530 kilograms per cubic metre (over three times the density of water) in natural diamonds and 3520 kg/m³ in pure diamond. In graphite, the bonds between nearest neighbors are even stronger but the bonds between planes are weak, so the planes can easily slip past each other. Thus, graphite is much softer than diamond. However, the stronger bonds make graphite less flammable.

Diamonds have been adapted for many uses because of the material's exceptional physical characteristics. Most notable are its extreme hardness and thermal conductivity (900–), as well as wide bandgap and high optical dispersion. Diamond's ignition point is 720– in oxygen and 850– in air.

The equilibrium pressure and temperature conditions for a transition between graphite and diamond is well established theoretically and experimentally. The pressure changes linearly between at and at (the diamond/graphite/liquid triple point).
However, the phases have a wide region about this line where they can coexist. At normal temperature and pressure, and , the stable phase of carbon is graphite, but diamond is metastable and its rate of conversion to graphite is negligible. However, at temperatures above about , diamond rapidly converts to graphite. Rapid conversion of graphite to diamond requires pressures well above the equilibrium line: at , a pressure of is needed.

Above the triple point, the melting point of diamond increases slowly with increasing pressure; but at pressures of hundreds of GPa, it decreases. At high pressures, silicon and germanium have a BC8 body-centered cubic crystal structure, and a similar structure is predicted for carbon at high pressures. At , the transition is predicted to occur at . 
The most common crystal structure of diamond is called diamond cubic. It is formed of unit cells (see the figure) stacked together. Although there are 18 atoms in the figure, each corner atom is shared by eight unit cells and each atom in the center of a face is shared by two, so there are a total of eight atoms per unit cell. Each side of the unit cell is 3.57 angstroms in length.

A diamond cubic lattice can be thought of as two interpenetrating face-centered cubic lattices with one displaced by 1/4 of the diagonal along a cubic cell, or as one lattice with two atoms associated with each lattice point. Looked at from a crystallographic direction, it is formed of layers stacked in a repeating ABCABC ... pattern. Diamonds can also form an ABAB ... structure, which is known as hexagonal diamond or lonsdaleite, but this is far less common and is formed under different conditions from cubic carbon.

Diamonds occur most often as euhedral or rounded octahedra and twinned octahedra known as "macles". As diamond's crystal structure has a cubic arrangement of the atoms, they have many facets that belong to a cube, octahedron, rhombicosidodecahedron, tetrakis hexahedron or disdyakis dodecahedron. The crystals can have rounded off and unexpressive edges and can be elongated. Diamonds (especially those with rounded crystal faces) are commonly found coated in "nyf", an opaque gum-like skin.

Some diamonds have opaque fibers. They are referred to as "opaque" if the fibers grow from a clear substrate or "fibrous" if they occupy the entire crystal. Their colors range from yellow to green or gray, sometimes with cloud-like white to gray impurities. Their most common shape is cuboidal, but they can also form octahedra, dodecahedra, macles or combined shapes. The structure is the result of numerous impurities with sizes between 1 and 5 microns. These diamonds probably formed in kimberlite magma and sampled the volatiles.

Diamonds can also form polycrystalline aggregates. There have been attempts to classify them into groups with names such as boart, ballas, stewartite and framesite, but there is no widely accepted set of criteria. Carbonado, a type in which the diamond grains were sintered (fused without melting by the application of heat and pressure), is black in color and tougher than single crystal diamond. It has never been observed in a volcanic rock. There are many theories for its origin, including formation in a star, but no consensus.

Diamond is the hardest known natural material on both the Vickers scale and the Mohs scale. Diamond's great hardness relative to other materials has been known since antiquity, and is the source of its name.

Diamond hardness depends on its purity, crystalline perfection and orientation: hardness is higher for flawless, pure crystals oriented to the <111> direction (along the longest diagonal of the cubic diamond lattice). Therefore, whereas it might be possible to scratch some diamonds with other materials, such as boron nitride, the hardest diamonds can only be scratched by other diamonds and nanocrystalline diamond aggregates.

The hardness of diamond contributes to its suitability as a gemstone. Because it can only be scratched by other diamonds, it maintains its polish extremely well. Unlike many other gems, it is well-suited to daily wear because of its resistance to scratching—perhaps contributing to its popularity as the preferred gem in engagement or wedding rings, which are often worn every day.

The hardest natural diamonds mostly originate from the Copeton and Bingara fields located in the New England area in New South Wales, Australia. These diamonds are generally small, perfect to semiperfect octahedra, and are used to polish other diamonds. Their hardness is associated with the crystal growth form, which is single-stage crystal growth. Most other diamonds show more evidence of multiple growth stages, which produce inclusions, flaws, and defect planes in the crystal lattice, all of which affect their hardness. It is possible to treat regular diamonds under a combination of high pressure and high temperature to produce diamonds that are harder than the diamonds used in hardness gauges.

Somewhat related to hardness is another mechanical property "toughness", which is a material's ability to resist breakage from forceful impact. The toughness of natural diamond has been measured as 7.5–10 MPa·m. This value is good compared to other ceramic materials, but poor compared to most engineering materials such as engineering alloys, which typically exhibit toughnesses over 100 MPa·m. As with any material, the macroscopic geometry of a diamond contributes to its resistance to breakage. Diamond has a cleavage plane and is therefore more fragile in some orientations than others. Diamond cutters use this attribute to cleave some stones, prior to faceting. "Impact toughness" is one of the main indexes to measure the quality of synthetic industrial diamonds.

Diamond has compressive yield strength of 130–140GPa. This exceptionally high value, along with the hardness and transparency of diamond, are the reasons that diamond anvil cells are the main tool for high pressure experiments. These anvils have reached pressures of . Much higher pressures may be possible with nanocrystalline diamonds.

Usually, attempting to deform bulk diamond crystal by tension or bending results in brittle fracture. However, when single crystalline diamond is in the form of nanometer-sized wires or needles (~100–300 nanometers in diameter), they can be elastically stretched by as much as 9 percent tensile strain without failure, with a maximum local tensile stress of ∼89 to 98 GPa, very close to the theoretical limit for this material.

Other specialized applications also exist or are being developed, including use as semiconductors: some blue diamonds are natural semiconductors, in contrast to most diamonds, which are excellent electrical insulators. The conductivity and blue color originate from boron impurity. Boron substitutes for carbon atoms in the diamond lattice, donating a hole into the valence band.

Substantial conductivity is commonly observed in nominally undoped diamond grown by chemical vapor deposition. This conductivity is associated with hydrogen-related species adsorbed at the surface, and it can be removed by annealing or other surface treatments.

Diamonds are naturally lipophilic and hydrophobic, which means the diamonds' surface cannot be wet by water, but can be easily wet and stuck by oil. This property can be utilized to extract diamonds using oil when making synthetic diamonds. However, when diamond surfaces are chemically modified with certain ions, they are expected to become so hydrophilic that they can stabilize multiple layers of water ice at human body temperature.

The surface of diamonds is partially oxidized. The oxidized surface can be reduced by heat treatment under hydrogen flow. That is to say, this heat treatment partially removes oxygen-containing functional groups. But diamonds (spC) are unstable against high temperature (above about ) under atmospheric pressure. The structure gradually changes into spC above this temperature. Thus, diamonds should be reduced under this temperature.

At room temperature, diamonds do not react with any chemical reagents including strong acids and bases. A diamond's surface can only be oxidized at temperatures above about in air. Diamond powder of an appropriate grain size (around 50 microns) burns with a shower of sparks after ignition from a flame. Consequently, pyrotechnic compositions based on synthetic diamond powder can be prepared. The resulting sparks are of the usual red-orange color, comparable to charcoal, but show a very linear trajectory which is explained by their high density. Diamond also reacts with fluorine gas above about .

Diamond has a wide bandgap of corresponding to the deep ultraviolet wavelength of 225 nanometers. This means that pure diamond should transmit visible light and appear as a clear colorless crystal. Colors in diamond originate from lattice defects and impurities. The diamond crystal lattice is exceptionally strong, and only atoms of nitrogen, boron and hydrogen can be introduced into diamond during the growth at significant concentrations (up to atomic percents). Transition metals nickel and cobalt, which are commonly used for growth of synthetic diamond by high-pressure high-temperature techniques, have been detected in diamond as individual atoms; the maximum concentration is 0.01% for nickel and even less for cobalt. Virtually any element can be introduced to diamond by ion implantation.

Nitrogen is by far the most common impurity found in gem diamonds and is responsible for the yellow and brown color in diamonds. Boron is responsible for the blue color. Color in diamond has two additional sources: irradiation (usually by alpha particles), that causes the color in green diamonds, and plastic deformation of the diamond crystal lattice. Plastic deformation is the cause of color in some brown and perhaps pink and red diamonds. In order of increasing rarity, yellow diamond is followed by brown, colorless, then by blue, green, black, pink, orange, purple, and red. "Black", or Carbonado, diamonds are not truly black, but rather contain numerous dark inclusions that give the gems their dark appearance. Colored diamonds contain impurities or structural defects that cause the coloration, while pure or nearly pure diamonds are transparent and colorless. Most diamond impurities replace a carbon atom in the crystal lattice, known as a carbon flaw. The most common impurity, nitrogen, causes a slight to intense yellow coloration depending upon the type and concentration of nitrogen present. The Gemological Institute of America (GIA) classifies low saturation yellow and brown diamonds as diamonds in the "normal color range", and applies a grading scale from "D" (colorless) to "Z" (light yellow). Diamonds of a different color, such as blue, are called "fancy colored" diamonds and fall under a different grading scale.

In 2008, the Wittelsbach Diamond, a blue diamond once belonging to the King of Spain, fetched over US$24 million at a Christie's auction. In May 2009, a blue diamond fetched the highest price per carat ever paid for a diamond when it was sold at auction for 10.5 million Swiss francs (6.97 million euros, or US$9.5 million at the time). That record was, however, beaten the same year: a vivid pink diamond was sold for $10.8 million in Hong Kong on December 1, 2009.

Diamonds can be identified by their high thermal conductivity. Their high refractive index is also indicative, but other materials have similar refractivity. Diamonds cut glass, but this does not positively identify a diamond because other materials, such as quartz, also lie above glass on the Mohs scale and can also cut it. Diamonds can scratch other diamonds, but this can result in damage to one or both stones. Hardness tests are infrequently used in practical gemology because of their potentially destructive nature. The extreme hardness and high value of diamond means that gems are typically polished slowly, using painstaking traditional techniques and greater attention to detail than is the case with most other gemstones; these tend to result in extremely flat, highly polished facets with exceptionally sharp facet edges. Diamonds also possess an extremely high refractive index and fairly high dispersion. Taken together, these factors affect the overall appearance of a polished diamond and most diamantaires still rely upon skilled use of a loupe (magnifying glass) to identify diamonds "by eye".

Diamonds are extremely rare, with concentrations of at most parts per billion in source rock. Before the 20th century, most diamonds were found in alluvial deposits. Loose diamonds are also found along existing and ancient shorelines, where they tend to accumulate because of their size and density. Rarely, they have been found in glacial till (notably in Wisconsin and Indiana), but these deposits are not of commercial quality. These types of deposit were derived from localized igneous intrusions through weathering and transport by wind or water.

Most diamonds come from the Earth's mantle, and most of this section discusses those diamonds. However, there are other sources. Some blocks of the crust, or terranes, have been buried deep enough as the crust thickened so they experienced ultra-high-pressure metamorphism. These have evenly distributed "microdiamonds" that show no sign of transport by magma. In addition, when meteorites strike the ground, the shock wave can produce high enough temperatures and pressures for "microdiamonds" and "nanodiamonds" to form. Impact-type microdiamonds can be used as an indicator of ancient impact craters. Popigai crater in Russia may have the world's largest diamond deposit, estimated at trillions of carats, and formed by an asteroid impact.

A common misconception is that diamonds are formed from highly compressed coal. Coal is formed from buried prehistoric plants, and most diamonds that have been dated are far older than the first land plants. It is possible that diamonds can form from coal in subduction zones, but diamonds formed in this way are rare, and the carbon source is more likely carbonate rocks and organic carbon in sediments, rather than coal.

Diamonds are far from evenly distributed over the Earth. A rule of thumb known as Clifford's rule states that they are almost always found in kimberlites on the oldest part of cratons, the stable cores of continents with typical ages of 2.5 billion years or more. However, there are exceptions. The Argyle diamond mine in Australia, the largest producer of diamonds by weight in the world, is located in a "mobile belt", also known as an "orogenic belt", a weaker zone surrounding the central craton that has undergone compressional tectonics. Instead of kimberlite, the host rock is lamproite. Lamproites with diamonds that are not economically viable are also found in the United States, India and Australia. In addition, diamonds in the Wawa belt of the Superior province in Canada and microdiamonds in the island arc of Japan are found in a type of rock called lamprophyre.

Kimberlites can be found in narrow (1 to 4 meters) dikes and sills, and in pipes with diameters that range from about 75 m to 1.5 km. Fresh rock is dark bluish green to greenish gray, but after exposure rapidly turns brown and crumbles. It is hybrid rock with a chaotic mixture of small minerals and rock fragments (clasts) up to the size of watermelons. They are a mixture of xenocrysts and xenoliths (minerals and rocks carried up from the lower crust and mantle), pieces of surface rock, altered minerals such as serpentine, and new minerals that crystallized during the eruption. The texture varies with depth. The composition forms a continuum with carbonatites, but the latter have too much oxygen for carbon to exist in a pure form. Instead, it is locked up in the mineral calcite (CaCO).

All three of the diamond-bearing rocks (kimberlite, lamproite and lamprophyre) lack certain minerals (melilite and kalsilite) that are incompatible with diamond formation. In kimberlite, olivine is large and conspicuous, while lamproite has Ti-phlogopite and lamprophyre has biotite and amphibole. They are all derived from magma types that erupt rapidly from small amounts of melt, are rich in volatiles and magnesium oxide, and are less oxidizing than more common mantle melts such as basalt. These characteristics allow the melts to carry diamonds to the surface before they dissolve.

Kimberlite pipes can be difficult to find. They weather quickly (within a few years after exposure) and tend to have lower topographic relief than surrounding rock. If they are visible in outcrops, the diamonds are never visible because they are so rare. In any case, kimberlites are often covered with vegetation, sediments, soils or lakes. In modern searches, geophysical methods such as aeromagnetic surveys, electrical resistivity and gravimetry, help identify promising regions to explore. This is aided by isotopic dating and modeling of the geological history. Then surveyors must go to the area and collect samples, looking for kimberlite fragments or "indicator minerals". The latter have compositions that reflect the conditions where diamonds form, such as extreme melt depletion or high pressures in eclogites. However, indicator minerals can be misleading; a better approach is geothermobarometry, where the compositions of minerals are analyzed as if they were in equilibrium with mantle minerals.

Finding kimberlites requires persistence, and only a small fraction contain diamonds that are commercially viable. The only major discoveries since about 1980 have been in Canada. Since existing mines have lifetimes of as little as 25 years, there could be a shortage of new diamonds in the future.

Diamonds are dated by analyzing inclusions using the decay of radioactive isotopes. Depending on the elemental abundances, one can look at the decay of rubidium to strontium, samarium to neodymium, uranium to lead, argon-40 to argon-39, or rhenium to osmium. Those found in kimberlites have ages ranging from 1 to 3.5 billion years, and there can be multiple ages in the same kimberlite, indicating multiple episodes of diamond formation. The kimberlites themselves are much younger. Most of them have ages between tens of millions and 300 million years old, although there are some older exceptions (Argyle, Premier and Wawa). Thus, the kimberlites formed independently of the diamonds and served only to transport them to the surface. Kimberlites are also much younger than the cratons they have erupted through. The reason for the lack of older kimberlites is unknown, but it suggests there was some change in mantle chemistry or tectonics. No kimberlite has erupted in human history.

Most gem-quality diamonds come from depths of 150–250 km in the lithosphere. Such depths occur below cratons in "mantle keels", the thickest part of the lithosphere. These regions have high enough pressure and temperature to allow diamonds to form and they are not convecting, so diamonds can be stored for billions of years until a kimberlite eruption samples them.

Host rocks in a mantle keel include harzburgite and lherzolite, two type of peridotite. The most dominant rock type in the upper mantle, peridotite is an igneous rock consisting mostly of the minerals olivine and pyroxene; it is low in silica and high in magnesium. However, diamonds in peridotite rarely survive the trip to the surface. Another common source that does keep diamonds intact is eclogite, a metamorphic rock that typically forms from basalt as an oceanic plate plunges into the mantle at a subduction zone.

A smaller fraction of diamonds (about 150 have been studied) come from depths of 330–660 km, a region that includes the transition zone. They formed in eclogite but are distinguished from diamonds of shallower origin by inclusions of majorite (a form of garnet with excess silicon). A similar proportion of diamonds comes from the lower mantle at depths between 660 and 800 km.

Diamond is thermodynamically stable at high pressures and temperatures, with the phase transition from graphite occurring at greater temperatures as the pressure increases. Thus, underneath continents it becomes stable at temperatures of 950 degrees Celsius and pressures of 4.5 gigapascals, corresponding to depths of 150 kilometers or greater. In subduction zones, which are colder, it becomes stable at temperatures of 800 degrees C and pressures of 3.5 gigapascals. At depths greater than 240 km, iron-nickel metal phases are present and carbon is likely to be either dissolved in them or in the form of carbides. Thus, the deeper origin of some diamonds may reflect unusual growth environments.

In 2018 the first known natural samples of a phase of ice called Ice VII were found as inclusions in diamond samples. The inclusions formed at depths between 400 and 800 km, straddling the upper and lower mantle, and provide evidence for water-rich fluid at these depths.

The amount of carbon in the mantle is not well constrained, but its concentration is estimated at 0.5 to 1 parts per thousand. It has two stable isotopes, C and C, in a ratio of approximately 99:1 by mass. This ratio has a wide range in meteorites, which implies that it was probably also broad in the early Earth. It can also be altered by surface processes like photosynthesis. The fraction is generally compared to a standard sample using a ratio δC expressed in parts per thousand. Common rocks from the mantle such as basalts, carbonatites and kimberlites have ratios between −8 and −2. On the surface, organic sediments have an average of −25 while carbonates have an average of 0.

Populations of diamonds from different sources have distributions of δC that vary markedly. Peridotitic diamonds are mostly within the typical mantle range; eclogitic diamonds have values from −40 to +3, although the peak of the distribution is in the mantle range. This variability implies that they are not formed from carbon that is "primordial" (having resided in the mantle since the Earth formed). Instead, they are the result of tectonic processes, although (given the ages of diamonds) not necessarily the same tectonic processes that act in the present.

Diamonds in the mantle form through a "metasomatic" process where a C-O-H-N-S fluid or melt dissolves minerals in a rock and replaces them with new minerals. (The vague term C-O-H-N-S is commonly used because the exact composition is not known.) Diamonds form from this fluid either by reduction of oxidized carbon (e.g., CO or CO) or oxidation of a reduced phase such as methane.

Using probes such as polarized light, photoluminescence and cathodoluminescence, a series of growth zones can be identified in diamonds. The characteristic pattern in diamonds from the lithosphere involves a nearly concentric series of zones with very thin oscillations in luminescence and alternating episodes where the carbon is resorbed by the fluid and then grown again. Diamonds from below the lithosphere have a more irregular, almost polycrystalline texture, reflecting the higher temperatures and pressures as well as the transport of the diamonds by convection.

Geological evidence supports a model in which kimberlite magma rose at 4–20 meters per second, creating an upward path by hydraulic fracturing of the rock. As the pressure decreases, a vapor phase exsolves from the magma, and this helps to keep the magma fluid. At the surface, the initial eruption explodes out through fissures at high speeds (over ). Then, at lower pressures, the rock is eroded, forming a pipe and producing fragmented rock (breccia). As the eruption wanes, there is pyroclastic phase and then metamorphism and hydration produces serpentinites.

Although diamonds on Earth are rare, they are very common in space. In meteorites, about three percent of the carbon is in the form of nanodiamonds, having diameters of a few nanometers. Sufficiently small diamonds can form in the cold of space because their lower surface energy makes them more stable than graphite. The isotopic signatures of some nanodiamonds indicate they were formed outside the Solar System in stars.

High pressure experiments predict that large quantities of diamonds condense from methane into a "diamond rain" on the ice giant planets Uranus and Neptune. Some extrasolar planets may be almost entirely composed of diamond.

Diamonds may exist in carbon-rich stars, particularly white dwarfs. One theory for the origin of carbonado, the toughest form of diamond, is that it originated in a white dwarf or supernova. Diamonds formed in stars may have been the first minerals.

The most familiar uses of diamonds today are as gemstones used for adornment, and as industrial abrasives for cutting hard materials. The markets for gem-grade and industrial-grade diamonds value diamonds differently.

The dispersion of white light into spectral colors is the primary gemological characteristic of gem diamonds. In the 20th century, experts in gemology developed methods of grading diamonds and other gemstones based on the characteristics most important to their value as a gem. Four characteristics, known informally as the "four Cs", are now commonly used as the basic descriptors of diamonds: these are its mass in "carats" (a carat being equal to 0.2 grams), "cut" (quality of the cut is graded according to proportions, symmetry and polish), "color" (how close to white or colorless; for fancy diamonds how intense is its hue), and "clarity" (how free is it from inclusions). A large, flawless diamond is known as a paragon.

A large trade in gem-grade diamonds exists. Although most gem-grade diamonds are sold newly polished, there is a well-established market for resale of polished diamonds (e.g. pawnbroking, auctions, second-hand jewelry stores, diamantaires, bourses, etc.). One hallmark of the trade in gem-quality diamonds is its remarkable concentration: wholesale trade and diamond cutting is limited to just a few locations; in 2003, 92% of the world's diamonds were cut and polished in Surat, India. Other important centers of diamond cutting and trading are the Antwerp diamond district in Belgium, where the International Gemological Institute is based, London, the Diamond District in New York City, the Diamond Exchange District in Tel Aviv, and Amsterdam. One contributory factor is the geological nature of diamond deposits: several large primary kimberlite-pipe mines each account for significant portions of market share (such as the Jwaneng mine in Botswana, which is a single large-pit mine that can produce between of diamonds per year). Secondary alluvial diamond deposits, on the other hand, tend to be fragmented amongst many different operators because they can be dispersed over many hundreds of square kilometers (e.g., alluvial deposits in Brazil).

The production and distribution of diamonds is largely consolidated in the hands of a few key players, and concentrated in traditional diamond trading centers, the most important being Antwerp, where 80% of all rough diamonds, 50% of all cut diamonds and more than 50% of all rough, cut and industrial diamonds combined are handled. This makes Antwerp a de facto "world diamond capital". The city of Antwerp also hosts the Antwerpsche Diamantkring, created in 1929 to become the first and biggest diamond bourse dedicated to rough diamonds. Another important diamond center is New York City, where almost 80% of the world's diamonds are sold, including auction sales.

The De Beers company, as the world's largest diamond mining company, holds a dominant position in the industry, and has done so since soon after its founding in 1888 by the British imperialist Cecil Rhodes. De Beers is currently the world's largest operator of diamond production facilities (mines) and distribution channels for gem-quality diamonds. The Diamond Trading Company (DTC) is a subsidiary of De Beers and markets rough diamonds from De Beers-operated mines. De Beers and its subsidiaries own mines that produce some 40% of annual world diamond production. For most of the 20th century over 80% of the world's rough diamonds passed through De Beers, but by 2001–2009 the figure had decreased to around 45%, and by 2013 the company's market share had further decreased to around 38% in value terms and even less by volume. De Beers sold off the vast majority of its diamond stockpile in the late 1990s – early 2000s and the remainder largely represents working stock (diamonds that are being sorted before sale). This was well documented in the press but remains little known to the general public.

As a part of reducing its influence, De Beers withdrew from purchasing diamonds on the open market in 1999 and ceased, at the end of 2008, purchasing Russian diamonds mined by the largest Russian diamond company Alrosa. As of January 2011, De Beers states that it only sells diamonds from the following four countries: Botswana, Namibia, South Africa and Canada. Alrosa had to suspend their sales in October 2008 due to the global energy crisis, but the company reported that it had resumed selling rough diamonds on the open market by October 2009. Apart from Alrosa, other important diamond mining companies include BHP Billiton, which is the world's largest mining company; Rio Tinto Group, the owner of the Argyle (100%), Diavik (60%), and Murowa (78%) diamond mines; and Petra Diamonds, the owner of several major diamond mines in Africa.

Further down the supply chain, members of The World Federation of Diamond Bourses (WFDB) act as a medium for wholesale diamond exchange, trading both polished and rough diamonds. The WFDB consists of independent diamond bourses in major cutting centers such as Tel Aviv, Antwerp, Johannesburg and other cities across the US, Europe and Asia. In 2000, the WFDB and The International Diamond Manufacturers Association established the World Diamond Council to prevent the trading of diamonds used to fund war and inhumane acts. WFDB's additional activities include sponsoring the World Diamond Congress every two years, as well as the establishment of the "International Diamond Council" (IDC) to oversee diamond grading.

Once purchased by Sightholders (which is a trademark term referring to the companies that have a three-year supply contract with DTC), diamonds are cut and polished in preparation for sale as gemstones ('industrial' stones are regarded as a by-product of the gemstone market; they are used for abrasives). The cutting and polishing of rough diamonds is a specialized skill that is concentrated in a limited number of locations worldwide. Traditional diamond cutting centers are Antwerp, Amsterdam, Johannesburg, New York City, and Tel Aviv. Recently, diamond cutting centers have been established in China, India, Thailand, Namibia and Botswana. Cutting centers with lower cost of labor, notably Surat in Gujarat, India, handle a larger number of smaller carat diamonds, while smaller quantities of larger or more valuable diamonds are more likely to be handled in Europe or North America. The recent expansion of this industry in India, employing low cost labor, has allowed smaller diamonds to be prepared as gems in greater quantities than was previously economically feasible.

Diamonds prepared as gemstones are sold on diamond exchanges called "bourses". There are 28 registered diamond bourses in the world. Bourses are the final tightly controlled step in the diamond supply chain; wholesalers and even retailers are able to buy relatively small lots of diamonds at the bourses, after which they are prepared for final sale to the consumer. Diamonds can be sold already set in jewelry, or sold unset ("loose"). According to the Rio Tinto Group, in 2002 the diamonds produced and released to the market were valued at US$9 billion as rough diamonds, US$14 billion after being cut and polished, US$28 billion in wholesale diamond jewelry, and US$57 billion in retail sales.

Mined rough diamonds are converted into gems through a multi-step process called "cutting".
Diamonds are extremely hard, but also brittle and can be split up by a single blow. Therefore, diamond cutting is traditionally considered as a delicate procedure requiring skills, scientific knowledge, tools and experience. Its final goal is to produce a faceted jewel where the specific angles between the facets would optimize the diamond luster, that is dispersion of white light, whereas the number and area of facets would determine the weight of the final product. The weight reduction upon cutting is significant and can be of the order of 50%. Several possible shapes are considered, but the final decision is often determined not only by scientific, but also practical considerations. For example, the diamond might be intended for display or for wear, in a ring or a necklace, singled or surrounded by other gems of certain color and shape. Some of them may be considered as classical, such as round, pear, marquise, oval, hearts and arrows diamonds, etc. Some of them are special, produced by certain companies, for example, Phoenix, Cushion, Sole Mio diamonds, etc.

The most time-consuming part of the cutting is the preliminary analysis of the rough stone. It needs to address a large number of issues, bears much responsibility, and therefore can last years in case of unique diamonds. The following issues are considered:

After initial cutting, the diamond is shaped in numerous stages of polishing. Unlike cutting, which is a responsible but quick operation, polishing removes material by gradual erosion and is extremely time consuming. The associated technique is well developed; it is considered as a routine and can be performed by technicians. After polishing, the diamond is reexamined for possible flaws, either remaining or induced by the process. Those flaws are concealed through various diamond enhancement techniques, such as repolishing, crack filling, or clever arrangement of the stone in the jewelry. Remaining non-diamond inclusions are removed through laser drilling and filling of the voids produced.

Marketing has significantly affected the image of diamond as a valuable commodity.

N. W. Ayer & Son, the advertising firm retained by De Beers in the mid-20th century, succeeded in reviving the American diamond market. And the firm created new markets in countries where no diamond tradition had existed before. N. W. Ayer's marketing included product placement, advertising focused on the diamond product itself rather than the De Beers brand, and associations with celebrities and royalty. Without advertising the De Beers brand, De Beers was advertising its competitors' diamond products as well, but this was not a concern as De Beers dominated the diamond market throughout the 20th century. De Beers' market share dipped temporarily to 2nd place in the global market below Alrosa in the aftermath of the global economic crisis of 2008, down to less than 29% in terms of carats mined, rather than sold. The campaign lasted for decades but was effectively discontinued by early 2011. De Beers still advertises diamonds, but the advertising now mostly promotes its own brands, or licensed product lines, rather than completely "generic" diamond products. The campaign was perhaps best captured by the slogan "a diamond is forever". This slogan is now being used by De Beers Diamond Jewelers, a jewelry firm which is a 50%/50% joint venture between the De Beers mining company and LVMH, the luxury goods conglomerate.

Brown-colored diamonds constituted a significant part of the diamond production, and were predominantly used for industrial purposes. They were seen as worthless for jewelry (not even being assessed on the diamond color scale). After the development of Argyle diamond mine in Australia in 1986, and marketing, brown diamonds have become acceptable gems. The change was mostly due to the numbers: the Argyle mine, with its of diamonds per year, makes about one-third of global production of natural diamonds; 80% of Argyle diamonds are brown.

Industrial diamonds are valued mostly for their hardness and thermal conductivity, making many of the gemological characteristics of diamonds, such as the 4 Cs, irrelevant for most applications. 80% of mined diamonds (equal to about annually) are unsuitable for use as gemstones and are used industrially. In addition to mined diamonds, synthetic diamonds found industrial applications almost immediately after their invention in the 1950s; another of synthetic diamond is produced annually for industrial use (in 2004; in 2014 it is , 90% of which is produced in China). Approximately 90% of diamond grinding grit is currently of synthetic origin.

The boundary between gem-quality diamonds and industrial diamonds is poorly defined and partly depends on market conditions (for example, if demand for polished diamonds is high, some lower-grade stones will be polished into low-quality or small gemstones rather than being sold for industrial use). Within the category of industrial diamonds, there is a sub-category comprising the lowest-quality, mostly opaque stones, which are known as bort.

Industrial use of diamonds has historically been associated with their hardness, which makes diamond the ideal material for cutting and grinding tools. As the hardest known naturally occurring material, diamond can be used to polish, cut, or wear away any material, including other diamonds. Common industrial applications of this property include diamond-tipped drill bits and saws, and the use of diamond powder as an abrasive. Less expensive industrial-grade diamonds, known as bort, with more flaws and poorer color than gems, are used for such purposes. Diamond is not suitable for machining ferrous alloys at high speeds, as carbon is soluble in iron at the high temperatures created by high-speed machining, leading to greatly increased wear on diamond tools compared to alternatives.

Specialized applications include use in laboratories as containment for high-pressure experiments (see diamond anvil cell), high-performance bearings, and limited use in specialized windows. With the continuing advances being made in the production of synthetic diamonds, future applications are becoming feasible. The high thermal conductivity of diamond makes it suitable as a heat sink for integrated circuits in electronics.

Approximately of diamonds are mined annually, with a total value of nearly US$9 billion, and about are synthesized annually.

Roughly 49% of diamonds originate from Central and Southern Africa, although significant sources of the mineral have been discovered in Canada, India, Russia, Brazil, and Australia. They are mined from kimberlite and lamproite volcanic pipes, which can bring diamond crystals, originating from deep within the Earth where high pressures and temperatures enable them to form, to the surface. The mining and distribution of natural diamonds are subjects of frequent controversy such as concerns over the sale of "blood diamonds" or "conflict diamonds" by African paramilitary groups. The diamond supply chain is controlled by a limited number of powerful businesses, and is also highly concentrated in a small number of locations around the world.

Only a very small fraction of the diamond ore consists of actual diamonds. The ore is crushed, during which care is required not to destroy larger diamonds, and then sorted by density. Today, diamonds are located in the diamond-rich density fraction with the help of X-ray fluorescence, after which the final sorting steps are done by hand. Before the use of X-rays became commonplace, the separation was done with grease belts; diamonds have a stronger tendency to stick to grease than the other minerals in the ore.

Historically, diamonds were found only in alluvial deposits in Guntur and Krishna district of the Krishna River delta in Southern India. India led the world in diamond production from the time of their discovery in approximately the 9th century BC to the mid-18th century AD, but the commercial potential of these sources had been exhausted by the late 18th century and at that time India was eclipsed by Brazil where the first non-Indian diamonds were found in 1725. Currently, one of the most prominent Indian mines is located at Panna.

Diamond extraction from primary deposits (kimberlites and lamproites) started in the 1870s after the discovery of the Diamond Fields in South Africa.
Production has increased over time and now an accumulated total of have been mined since that date. Twenty percent of that amount has been mined in the last five years, and during the last 10 years, nine new mines have started production; four more are waiting to be opened soon. Most of these mines are located in Canada, Zimbabwe, Angola, and one in Russia.

In the U.S., diamonds have been found in Arkansas, Colorado, New Mexico, Wyoming, and Montana. In 2004, the discovery of a microscopic diamond in the U.S. led to the January 2008 bulk-sampling of kimberlite pipes in a remote part of Montana. The Crater of Diamonds State Park in Arkansas is open to the public, and is the only mine in the world where members of the public can dig for diamonds.

Today, most commercially viable diamond deposits are in Russia (mostly in Sakha Republic, for example Mir pipe and Udachnaya pipe), Botswana, Australia (Northern and Western Australia) and the Democratic Republic of the Congo.
In 2005, Russia produced almost one-fifth of the global diamond output, according to the British Geological Survey. Australia boasts the richest diamantiferous pipe, with production from the Argyle diamond mine reaching peak levels of 42 metric tons per year in the 1990s.
There are also commercial deposits being actively mined in the Northwest Territories of Canada and Brazil.
Diamond prospectors continue to search the globe for diamond-bearing kimberlite and lamproite pipes.

In some of the more politically unstable central African and west African countries, revolutionary groups have taken control of diamond mines, using proceeds from diamond sales to finance their operations. Diamonds sold through this process are known as "conflict diamonds" or "blood diamonds".

In response to public concerns that their diamond purchases were contributing to war and human rights abuses in central and western Africa, the United Nations, the diamond industry and diamond-trading nations introduced the Kimberley Process in 2002. The Kimberley Process aims to ensure that conflict diamonds do not become intermixed with the diamonds not controlled by such rebel groups. This is done by requiring diamond-producing countries to provide proof that the money they make from selling the diamonds is not used to fund criminal or revolutionary activities. Although the Kimberley Process has been moderately successful in limiting the number of conflict diamonds entering the market, some still find their way in. According to the International Diamond Manufacturers Association, conflict diamonds constitute 2–3% of all diamonds traded. Two major flaws still hinder the effectiveness of the Kimberley Process: (1) the relative ease of smuggling diamonds across African borders, and (2) the violent nature of diamond mining in nations that are not in a technical state of war and whose diamonds are therefore considered "clean".

The Canadian Government has set up a body known as the Canadian Diamond Code of Conduct to help authenticate Canadian diamonds. This is a stringent tracking system of diamonds and helps protect the "conflict free" label of Canadian diamonds.

Synthetic diamonds are diamonds manufactured in a laboratory, as opposed to diamonds mined from the Earth. The gemological and industrial uses of diamond have created a large demand for rough stones. This demand has been satisfied in large part by synthetic diamonds, which have been manufactured by various processes for more than half a century. However, in recent years it has become possible to produce gem-quality synthetic diamonds of significant size. It is possible to make colorless synthetic gemstones that, on a molecular level, are identical to natural stones and so visually similar that only a gemologist with special equipment can tell the difference.

The majority of commercially available synthetic diamonds are yellow and are produced by so-called "high-pressure high-temperature" (HPHT) processes. The yellow color is caused by nitrogen impurities. Other colors may also be reproduced such as blue, green or pink, which are a result of the addition of boron or from irradiation after synthesis.
Another popular method of growing synthetic diamond is chemical vapor deposition (CVD). The growth occurs under low pressure (below atmospheric pressure). It involves feeding a mixture of gases (typically 1 to 99 methane to hydrogen) into a chamber and splitting them to chemically active radicals in a plasma ignited by microwaves, hot filament, arc discharge, welding torch or laser. This method is mostly used for coatings, but can also produce single crystals several millimeters in size (see picture).

As of 2010, nearly all 5,000 million carats (1,000 tonnes) of synthetic diamonds produced per year are for industrial use. Around 50% of the 133 million carats of natural diamonds mined per year end up in industrial use. Mining companies' expenses average 40 to 60 US dollars per carat for natural colorless diamonds, while synthetic manufacturers' expenses average $2,500 per carat for synthetic, gem-quality colorless diamonds. However, a purchaser is more likely to encounter a synthetic when looking for a fancy-colored diamond because nearly all synthetic diamonds are fancy-colored, while only 0.01% of natural diamonds are.

A diamond simulant is a non-diamond material that is used to simulate the appearance of a diamond, and may be referred to as diamante. Cubic zirconia is the most common. The gemstone moissanite (silicon carbide) can be treated as a diamond simulant, though more costly to produce than cubic zirconia. Both are produced synthetically.

Diamond enhancements are specific treatments performed on natural or synthetic diamonds (usually those already cut and polished into a gem), which are designed to better the gemological characteristics of the stone in one or more ways. These include laser drilling to remove inclusions, application of sealants to fill cracks, treatments to improve a white diamond's color grade, and treatments to give fancy color to a white diamond.

Coatings are increasingly used to give a diamond simulant such as cubic zirconia a more "diamond-like" appearance. One such substance is diamond-like carbon—an amorphous carbonaceous material that has some physical properties similar to those of the diamond. Advertising suggests that such a coating would transfer some of these diamond-like properties to the coated stone, hence enhancing the diamond simulant. Techniques such as Raman spectroscopy should easily identify such a treatment.

Early diamond identification tests included a scratch test relying on the superior hardness of diamond. This test is destructive, as a diamond can scratch another diamond, and is rarely used nowadays. Instead, diamond identification relies on its superior thermal conductivity. Electronic thermal probes are widely used in the gemological centers to separate diamonds from their imitations. These probes consist of a pair of battery-powered thermistors mounted in a fine copper tip. One thermistor functions as a heating device while the other measures the temperature of the copper tip: if the stone being tested is a diamond, it will conduct the tip's thermal energy rapidly enough to produce a measurable temperature drop. This test takes about two to three seconds.

Whereas the thermal probe can separate diamonds from most of their simulants, distinguishing between various types of diamond, for example synthetic or natural, irradiated or non-irradiated, etc., requires more advanced, optical techniques. Those techniques are also used for some diamonds simulants, such as silicon carbide, which pass the thermal conductivity test. Optical techniques can distinguish between natural diamonds and synthetic diamonds. They can also identify the vast majority of treated natural diamonds. "Perfect" crystals (at the atomic lattice level) have never been found, so both natural and synthetic diamonds always possess characteristic imperfections, arising from the circumstances of their crystal growth, that allow them to be distinguished from each other.

Laboratories use techniques such as spectroscopy, microscopy and luminescence under shortwave ultraviolet light to determine a diamond's origin. They also use specially made instruments to aid them in the identification process. Two screening instruments are the "DiamondSure" and the "DiamondView", both produced by the DTC and marketed by the GIA.

Several methods for identifying synthetic diamonds can be performed, depending on the method of production and the color of the diamond. CVD diamonds can usually be identified by an orange fluorescence. D-J colored diamonds can be screened through the Swiss Gemmological Institute's Diamond Spotter. Stones in the D-Z color range can be examined through the DiamondSure UV/visible spectrometer, a tool developed by De Beers. Similarly, natural diamonds usually have minor imperfections and flaws, such as inclusions of foreign material, that are not seen in synthetic diamonds.

Screening devices based on diamond type detection can be used to make a distinction between diamonds that are certainly natural and diamonds that are potentially synthetic. Those potentially synthetic diamonds require more investigation in a specialized lab. Examples of commercial screening devices are D-Screen (WTOCD / HRD Antwerp) and Alpha Diamond Analyzer (Bruker / HRD Antwerp).

Occasionally, large thefts of diamonds take place. In February 2013 armed robbers carried out a raid at Brussels Airport and escaped with gems estimated to be worth US$50M (£32M; €37M). The gang broke through a perimeter fence and raided the cargo hold of a Swiss-bound plane. The gang have since been arrested and large amounts of cash and diamonds recovered.

The identification of stolen diamonds presents a set of difficult problems. Rough diamonds will have a distinctive shape depending on whether their source is a mine or from an alluvial environment such as a beach or river—alluvial diamonds have smoother surfaces than those that have been mined. Determining the provenance of cut and polished stones is much more complex.

The Kimberley Process was developed to monitor the trade in rough diamonds and prevent their being used to fund violence. Before exporting, rough diamonds are certificated by the government of the country of origin. Some countries, such as Venezuela, are not party to the agreement. The Kimberley Process does not apply to local sales of rough diamonds within a country.

Diamonds may be etched by laser with marks invisible to the naked eye. Lazare Kaplan, a US-based company, developed this method. However, whatever is marked on a diamond can readily be removed.

The name "diamond" is derived from the ancient Greek "ἀδάμας" "(adámas"), "proper", "unalterable", "unbreakable", "untamed", from ἀ- (a-), "un-" + "δαμάω" ("damáō"), "I overpower", "I tame". Diamonds are thought to have been first recognized and mined in India, where significant alluvial deposits of the stone could be found many centuries ago along the rivers Penner, Krishna and Godavari. Diamonds have been known in India for at least 3,000 years but most likely 6,000 years.

Diamonds have been treasured as gemstones since their use as religious icons in ancient India. Their usage in engraving tools also dates to early human history. The popularity of diamonds has risen since the 19th century because of increased supply, improved cutting and polishing techniques, growth in the world economy, and innovative and successful advertising campaigns.

In 1772, the French scientist Antoine Lavoisier used a lens to concentrate the rays of the sun on a diamond in an atmosphere of oxygen, and showed that the only product of the combustion was carbon dioxide, proving that diamond is composed of carbon. Later in 1797, the English chemist Smithson Tennant repeated and expanded that experiment. By demonstrating that burning diamond and graphite releases the same amount of gas, he established the chemical equivalence of these substances.





</doc>
