<doc id="11369" url="https://en.wikipedia.org/wiki?curid=11369" title="Frank Capra">
Frank Capra

Frank Russell Capra (born Francesco Rosario Capra; May 18, 1897 – September 3, 1991) was an Italian-American film director, producer and writer who became the creative force behind some of the major award-winning films of the 1930s and 1940s. Born in Italy and raised in Los Angeles from the age of five, his rags-to-riches story has led film historians such as Ian Freer to consider him the "American Dream personified."

Capra became one of America's most influential directors during the 1930s, winning three Academy Awards for Best Director from six nominations, along with three other Oscar wins from nine nominations in other categories. Among his leading films were "It Happened One Night" (1934), "You Can't Take It with You" (1938), and "Mr. Smith Goes to Washington" (1939); Capra was nominated as Best Director and as producer for Academy Award for Best Picture on all three films, winning both awards on the first two. During World War II, Capra served in the U.S. Army Signal Corps and produced propaganda films, such as the "Why We Fight" series.

After World War II, Capra's career declined as his later films, such as "It's a Wonderful Life" (1946), performed poorly when they were first released. In ensuing decades, however, "It's a Wonderful Life" and other Capra films were revisited favorably by critics. Outside of directing, Capra was active in the film industry, engaging in various political and social issues. He served as President of the Academy of Motion Picture Arts and Sciences, worked alongside the Writers Guild of America, and was head of the Directors Guild of America.
Capra was born Francesco Rosario Capra in Bisacquino, a village near Palermo, Sicily. He was the youngest of seven children of Salvatore Capra, a fruit grower, and the former Rosaria "Serah" Nicolosi. Capra's family was Roman Catholic. The name "Capra", notes Capra's biographer Joseph McBride, represents his family's closeness to the land, and means "goat". He notes that the English word "capricious" derives from it, "evoking the animal's skittish temperament", adding that "the name neatly expresses two aspects of Frank Capra's personality: emotionalism and obstinacy."

In 1903, when he was five, Capra emigrated to the United States with his family, who traveled in one of the steerage compartments of the steamship, "Germania", which was the cheapest way to book passage. For Capra, the journey, which took 13 days, remained in his mind for the rest of his life as one of his worst experiences:

Capra remembers the ship's arrival in New York Harbor, where he saw "a statue of a great lady, taller than a church steeple, holding a torch above the land we were about to enter". He recalls his father's exclamation at the sight:

The family settled in Los Angeles's East Side (today Chinatown), which Capra described in his autobiography as an Italian "ghetto". Capra's father worked as a fruit picker and young Capra sold newspapers after school for 10 years, until he graduated from high school. Instead of working after graduating, as his parents wanted, he enrolled in college. He worked through college at the California Institute of Technology, playing banjo at nightclubs and taking odd jobs, which included working at the campus laundry facility, waiting tables, and cleaning engines at a local power plant. He studied chemical engineering and graduated in the spring of 1918. Capra later wrote that his college education had "changed his whole viewpoint on life from the viewpoint of an alley rat to the viewpoint of a cultured person".

Soon after graduating college, Capra was commissioned in the United States Army as a second lieutenant, having completed campus ROTC. In the Army, he taught mathematics to artillerymen at Fort Point, San Francisco. His father died during the war in an accident (1916). In the Army, Capra contracted Spanish flu and was medically discharged to return home to live with his mother. He became a naturalized U.S. citizen in 1920, taking the name Frank Russell Capra. Living at home with his siblings and mother, Capra was the only family member with a college education, yet he was the only one who remained chronically unemployed. After a year without work, seeing how his siblings had steady jobs, he felt he was a failure, which led to bouts of depression and abdominal pains, later discovered to have been an undiagnosed burst appendix.

After recovering at home, Capra moved out and spent the next few years living in flophouses in San Francisco and hopping freight trains, wandering the Western United States. To support himself, he took odd jobs on farms, as a movie extra, playing poker, and selling local oil well stocks. In his early twenties, Capra had to undergo a circumcision due to recurring bouts of STIs (the first of which happened after an anonymous encounter with a woman at a party in San Francisco), which caused severe damage to his sex life, an affliction that lasted until his twilight years.

It was during this time that the 24-year-old Capra directed a 32-minute documentary film titled "La Visita Dell'Incrociatore Italiano Libya a San Francisco". Not only did it document the visit of the Italian naval vessel "Libya" to San Francisco, but also the reception given to the crew of the ship by San Francisco's L'Italia Virtus Club, now known as the San Francisco Italian Athletic Club.

At 25, Capra took a job selling books written and published by American philosopher, Elbert Hubbard. Capra recalled that he "hated being a peasant, being a scrounging new kid trapped in the Sicilian ghetto of Los Angeles. ... All I had was cockiness—and let me tell you that gets you a long way."

During his book sales efforts—and nearly broke—Capra read a newspaper article about a new movie studio opening in San Francisco. Capra phoned them saying he had moved from Hollywood, and falsely implied that he had experience in the budding film industry. Capra's only prior exposure to films was in 1915 while attending Manual Arts High School. The studio's founder, Walter Montague, was nonetheless impressed by Capra and offered him $75 to direct a one-reel silent film. Capra, with the help of a cameraman, made the film in two days and cast it with amateurs.

After that first serious job in films, Capra began efforts to finding similar openings in the film industry. He took a position with another minor San Francisco studio, and subsequently received an offer to work with producer Harry Cohn at his new studio in Los Angeles. During this time, he worked as a property man, film cutter, title writer, and assistant director.

Capra later became a gag writer for Hal Roach's "Our Gang" series. He was twice hired as a writer for slapstick comedy director, Mack Sennett, in 1918 and 1924. Under him, Capra wrote scripts for comedian Harry Langdon. According to Capra, it was he who invented Langdon's character, the innocent fool living in a "naughty world."

When Langdon eventually left Sennett to make longer, feature-length movies with First National Studios, he took Capra along as his personal writer and director. They made three feature films together during 1926 and 1927, all of them successful with critics and the public. The films made Langdon a recognized comedian in the caliber of Charlie Chaplin and Buster Keaton. Capra and Langdon later had a falling out, and Capra was fired. During the following years, Langdon's films went into decline without Capra's assistance. After splitting with Langdon, Capra directed a picture for First National, "For the Love of Mike", (1927). This was a silent comedy about three bickering godfathers, a German, a Jew, and an Irishman, starring a budding actress, Claudette Colbert. The movie was considered a failure.

Capra returned to Harry Cohn's studio, now named Columbia Pictures, which was then producing short films and two-reel comedies for "fillers" to play between main features. Columbia was one of many start-up studios on "Poverty Row" in Los Angeles. Like the others, Columbia was unable to compete with larger studios, which often had their own production facilities, distribution, and theaters. Cohn rehired Capra in 1928 to help his studio produce new, full-length feature films, to compete with the major studios. Capra would eventually direct 20 films for Cohn's studio, including all of his classics.

Because of Capra's engineering education, he adapted more easily to the new sound technology than most directors. He welcomed the transition to sound, recalling, "I wasn't at home in silent films." Most studios were unwilling to invest in the new sound technology, assuming it was a passing fad. Many in Hollywood considered sound a threat to the industry and hoped it would pass quickly; McBride notes that "Capra was not one of them." When he saw Al Jolson singing in "The Jazz Singer" in 1927, considered the first talkie, Capra recalled his reaction:

Few of the studio heads or crew were aware of Capra's engineering background until he began directing "The Younger Generation" in 1929. The chief cinematographer who worked with Capra on a number of films, was likewise unaware. He describes this early period in sound for film:

During his first year with Columbia, Capra directed nine films, some of which were successful. After the first few, Harry Cohn said "it was the beginning of Columbia making a better quality of pictures." According to Barson, "Capra became ensconced as Harry Cohn's most trusted director." His films soon established Capra as a "bankable" director known throughout the industry, and Cohn raised Capra's initial salary of $1,000 per film to $25,000 per year. Capra directed a film for MGM during this period, but soon realized he "had much more freedom under Harry Cohn's benevolent dictatorship", where Cohn also put Capra's "name above the title" of his films, a first for the movie industry. Capra wrote of this period and recalled the confidence that Cohn placed in Capra's vision and directing:

Capra directed his first "real" sound picture, "The Younger Generation", in 1929. It was a rags-to-riches romantic comedy about a Jewish family's upward mobility in New York City, with their son later trying to deny his Jewish roots to keep his rich, gentile girlfriend. According to Capra biographer Joseph McBride, Capra "obviously felt a strong identification with the story of a Jewish immigrant who grows up in the ghetto of New York ... and feels he has to deny his ethnic origins to rise to success in America." Capra, however, denied any connection of the story with his own life.

Nonetheless, McBride insists that "The Younger Generation" abounds with parallels to Capra's own life." McBride notes the "devastatingly painful climactic scene", where the young social-climbing son, embarrassed when his wealthy new friends first meet his parents, passes his mother and father off as house servants. That scene, notes McBride, "echoes the shame Capra admitted feeling toward his own family as he rose in social status."

During his years at Columbia, Capra worked often with screenwriter Robert Riskin (husband of Fay Wray), and cameraman Joseph Walker. In many of Capra's films, the wise-cracking and sharp dialogue was often written by Riskin, and he and Capra went on to become Hollywood's "most admired writer-director team."

Capra's films in the 1930s enjoyed immense success at the Academy Awards. "It Happened One Night" (1934) became the first film to win all five top Oscars (Best Picture, Best Director, Best Actor, Best Actress, and Best Adapted Screenplay). Written by Robert Riskin, it is one of the first of the "screwball comedies", and with its release in the Great Depression, critics considered it an escapist story and a variation of the "American Dream". The film established the names of Capra, Columbia Pictures, and stars Clark Gable and Claudette Colbert in the movie industry. The film has been called "picaresque." It was one of the earliest "road movies" and inspired variations on that theme by other filmmakers.

He followed the film with "Broadway Bill" (1934), a screwball comedy about horse racing. The film was a turning point for Capra, however, as he began to conceive an additional dimension to his movies. He started using his films to convey messages to the public. Capra explains his new thinking:
This added goal was inspired after meeting with a Christian Scientist friend who told him to view his talents in a different way:

Capra began to embody messages in subsequent films, many of which conveyed "fantasies of goodwill." The first of those was "Mr. Deeds Goes to Town" (1936), for which Capra won his second Best Director Oscar. Critic Alistair Cooke observed that Capra was "starting to make movies about themes instead of people."

In 1938, Capra won his third Director Oscar in five years for "You Can't Take It with You", which also won Best Picture. In addition to his three directing wins, Capra received directing nominations for three other films ("Lady for a Day", "Mr. Smith Goes to Washington", and "It's a Wonderful Life"). On May 5, 1936, Capra hosted the 8th Academy Awards ceremony.

Although "It's a Wonderful Life" is his best-known film, Friedman notes that it was "Mr. Smith Goes to Washington" (1939), which most represented the "Capra myth." That film expressed Capra's patriotism more than any others, and "presented the individual working within the democratic system to overcome rampant political corruption."

The film, however, became Capra's most controversial. In his research before filming, he was able to stand close to President Franklin D. Roosevelt during a press conference after the recent acts of war by Germany in Europe. Capra recalls his fears:

When the filming was completed, the studio sent preview copies to Washington. Joseph P. Kennedy Sr., U.S. ambassador to the UK, wrote to Columbia head Harry Cohn, "Please do not play this picture in Europe." Politicians were concerned about the potential negative effect the film might have on the morale of the United States' allies, as World War II had begun. Kennedy wrote to President Roosevelt that, "In foreign countries this film must inevitably strengthen the mistaken impression that the United States is full of graft, corruption and lawlessness." Many studio heads agreed, nor did they want negative feelings about Hollywood instilled in political leaders.

Nonetheless, Capra's vision of the film's significance was clear:

Capra pleaded with Cohn to allow the film to go into distribution and remembers the intensity of their decision making:

Cohn and Capra chose to ignore the negative publicity and demands, and released the film as planned. It was later nominated for 11 Academy Awards, only winning one (for Best Original Story) partly because of the number of major pictures that were nominated that year was 10, including "The Wizard of Oz" and "Gone with the Wind". Hollywood columnist Louella Parsons called it a "smash patriotic hit" and most critics agreed, seeing that audiences left the theaters with "an enthusiasm for democracy" and "in a glow of patriotism."

The significance of the film's message was established further in France, shortly after World War II began. When the French public were asked to select which film they wanted to see most, having been told by the Vichy government that soon no more American films would be allowed in France, the overwhelming majority chose it over all others. To a France soon to be invaded and occupied by Nazi forces, the film most expressed the "perseverance of democracy and the American way."

In 1941 Capra directed "Meet John Doe" (1941), which some consider Capra's most controversial movie. The film's hero, played by Gary Cooper, is a former baseball player now bumming around, lacking goals. He is selected by a news reporter to represent the "common man," to capture the imagination of ordinary Americans. The film was released shortly before America became involved in World War II, and citizens were still in an isolationist mood. According to some historians, the film was made to convey a "deliberate reaffirmation of American values," though ones that seemed uncertain with respect to the future.

Film author Richard Glazer speculates that the film may have been autobiographical, "reflecting Capra's own uncertainties." Glazer describes how, "John's accidental transformation from drifter to national figure parallels Capra's own early drifting experience and subsequent involvement in movie making ... "Meet John Doe", then, was an attempt to work out his own fears and questions."

Within four days after the Japanese Attack on Pearl Harbor on December 7, 1941, Capra quit his successful directing career in Hollywood and received a commission as a major in the United States Army. He also gave up his presidency of the Screen Directors Guild. Being 44 years of age, he was not asked to enlist, but, notes Friedman, "Capra had an intense desire to prove his patriotism to his adopted land."

Capra recalls some personal reasons for enlisting:

During the next four years of World War II, Capra's job was to head a special section on morale to explain to soldiers "why the hell they're in uniform", writes Capra, and were not "propaganda" films like those created by the Nazis and Japan. Capra directed or co-directed seven documentary war information films.

Capra was assigned to work directly under Chief of Staff George C. Marshall, the most senior officer in command of the Army, who later created the Marshall Plan and was awarded a Nobel Peace Prize. Marshall chose to bypass the usual documentary film-making department, Signal Corps, because he felt they were not capable of producing "sensitive and objective troop information films." One colonel explained the importance of these future films to Capra:

During his first meeting with General Marshall, Capra was told his mission:

The films included the seven-episode "Why We Fight" series – consisting of "Prelude to War" (1942), "The Nazis Strike" (1942), "Divide and Conquer" (1943), "The Battle of Britain" (1943), "The Battle of Russia" (1943), "The Battle of China" (1944), "War Comes to America" (1945) – plus "" (1945), "Here Is Germany" (1945), "Tunisian Victory" (1945), and "Two Down and One to Go" (1945) that do not bear the "Why We Fight" banner; as well as the African-American related film, "The Negro Soldier" (1944).

After he completed the first few documentaries, government officials and U.S. Army staff felt they were powerful messages and excellent presentations of why it was necessary for the United States to fight in the war. All footage came from military and government sources, whereas during earlier years, many newsreels secretly used footage from enemy sources. Animated charts were created by Walt Disney and his animators. A number of Hollywood composers wrote the background music, including Alfred Newman and Russian-born composer Dimitri Tiomkin. After the first complete film was viewed by General Marshall along with U.S. Army staff, Marshall approached Capra: "Colonel Capra, how did you do it? That is a most wonderful thing."

Officials made efforts to see that the films were seen in theaters throughout the U.S. They were translated into French, Spanish, Portuguese, and Chinese for use by other countries. Winston Churchill ordered that "all" of them be shown to the British public in theaters. They are today often broadcast on television and used as a teaching aid.

The "Why We Fight" series is widely considered a masterpiece of war information documentaries, and won an Academy Award. "Prelude to War" won the 1942 Academy Award for Best Documentary Feature. When his career ended, Capra regarded these films as his most important works. As a colonel, he received the Legion of Merit in 1943 and the Distinguished Service Medal in 1945.

After the war ended, along with directors William Wyler and George Stevens, Capra founded Liberty Films. Their studio became the first independent company of directors since United Artists in 1919 whose goal was to make films without interference by studio bosses. However, the only pictures completed by the studio were "It's a Wonderful Life" (1946) and "State of the Union" (1948). The first of these was a box office disappointment, but was nominated for five Academy Awards.

While the film did not resonate with audiences in 1946, its popularity has grown through the years. In 1998, the American Film Institute (AFI) named it one of the best films ever made, putting it at 11th on AFI's 100 Years...100 Movies list of the top American films of all time. In 2006, the AFI put the film at the top of its AFI's 100 Years...100 Cheers list, ranking what AFI considers the most inspirational American movies of all time. It would become Capra's last film to win major acclaim—his successful years were now behind him, although he directed five more films over the next 14 years.

For "State of the Union" (1948), Capra changed studios. It would be the only time he ever worked for Metro-Goldwyn-Mayer. Although the project had an excellent pedigree with stars Spencer Tracy and Katharine Hepburn, the film was not a success, and Capra's statement, "I think "State of the Union" was my most perfect film in handling people and ideas" has few adherents today.

In January 1952, the U.S. Ambassador to India asked Capra to represent the U.S. film industry at an International Film Festival to be held in India. A State Department friend of Capra asked him and explained why his trip would be important:

After two weeks in India, Capra discovered that Bowles' fears were warranted, as many film sessions were used by Russian and Chinese representatives to give long political speeches. At a lunch with 15 Indian directors and producers, he stressed that "they must preserve freedom as artists, and that any government control would hinder that freedom. A totalitarian system—and they would become nothing but publicity men for the party in power." Capra had a difficult time communicating this, however, as he noted in his diary:

When he returned to Washington to give his report, Secretary of State Dean Acheson gave Capra his commendation for "virtually single-handedly forestalling a possible Communist take-over of Indian films." Ambassador Bowles also conveyed gratitude to Capra for "one helluva job."

Following "It's a Wonderful Life" and "State of the Union," which were done soon after the war ended, Capra's themes were becoming out of step with changes in the film industry and the public mood. Friedman finds that while Capra's ideas were popular with depression-era and prewar audiences, they became less relevant to a prospering post-war America. Capra had become "disconnected from an American culture that had changed" during the previous decade. Biographer Joseph McBride argues that Capra's disillusionment was more related to the negative effect that the House Un-American Activities Committee (HUAC) had on the film industry in general. The HUAC interrogations in the early 1950s ended many Hollywood careers. Capra himself was not called to testify, although he was a prime target of the committee due to his past associations with many Hollywood blacklisted screenwriters.

Capra blamed his early retirement from films on the rising power of stars, which forced him to continually compromise his artistic vision. He also claimed that increasing budgetary and scheduling demands had constrained his creative abilities. Film historian Michael Medved agreed with Capra, noting that he walked away from the movie business because "he refused to adjust to the cynicism of the new order." In his autobiography, written in 1971, Capra expressed his feelings about the shifting film industry:

Capra added that in his opinion, "practically all the Hollywood film-making of today is stooping to cheap salacious pornography in a crazy bastardization of a great art to compete for the 'patronage' of deviates and masturbators."

Capra remained employable in Hollywood during and after the HUAC hearings, but chose nonetheless to demonstrate his loyalty by attempting to re-enlist in the Army at the outbreak of the Korean War, in 1950. He was rejected due to his age. He was later invited to join the Defense Department's newly formed Think Tank project, VISTA, but was denied the necessary clearance. According to Friedman, "these two rejections were devastating to the man who had made a career of demonstrating American ideals in film", along with his directing award-winning documentary films for the Army.

Capra directed two films at Paramount Pictures starring Bing Crosby, "Riding High" (1950) and "Here Comes the Groom" (1951). By 1952, at the age of 55, Capra effectively retired from Hollywood filmmaking; he shifted to working with the California Institute of Technology, his alma mater, to produce educational films on science topics.

From 1952 to 1956, Capra produced four science-related television specials in color for The Bell System Science Series: "Our Mr. Sun" (1956), "Hemo the Magnificent" (1957), "The Strange Case of the Cosmic Rays" (1957), and "Meteora: The Unchained Goddess" (1958). These educational science documentaries were popular favorites for school science classrooms. It was eight years before he directed another theatrical film, "A Hole in the Head" (1959) with Frank Sinatra and Edward G. Robinson, his first feature film in color. His final theatrical film was with Glenn Ford and Bette Davis, named "Pocketful of Miracles" (1961), a remake of his 1933 film "Lady for a Day". In the mid-1960s he worked on pre-production for an adaptation of Martin Caidin's novel "Marooned," but budgetary constraints caused him to eventually shelve it.

Capra's final film, "Rendezvous in Space" (1964), was an industrial film made for the Martin Marietta Company and shown at the 1964 New York World's Fair. It was exhibited at the New York Hall of Science after the Fair ended.

Capra's directing style relied on improvisation to a great extent. He was noted for going on the set with no more than the master scenes written. He explained his reasoning:

According to some experts, Capra used great, unobtrusive craftsmanship when directing, and felt it was bad directing to distract the audience with fancy technical gimmicks. Film historian and author William S. Pechter described Capra's style as one "of almost classical purity." He adds that his style relied on editing to help his films sustain a "sequence of rhythmic motion." Pechter describes its effect:

Film critic John Raeburn discusses an early Capra film, "American Madness" (1932), as an example of how he had mastered the movie medium and expressed a unique style:

As for Capra's subject matter, film author Richard Griffith tries to summarize Capra's common theme:

Capra's personality when directing gave him a reputation for "fierce independence" when dealing with studio bosses. On the set he was said to be gentle and considerate, "a director who displays absolutely no exhibitionism." As Capra's films often carry a message about basic goodness in human nature, and show the value of unselfishness and hard work, his wholesome, feel-good themes have led some cynics to term his style "Capra-corn." However, those who hold his vision in higher regard prefer the term "Capraesque".

Capra's basic themes of championing the common man, as well as his use of spontaneous, fast-paced dialogue and goofy, memorable lead and supporting characters, made him one of the most popular and respected filmmakers of the 20th century. His influence can be traced in the works of many directors, including Robert Altman, Ron Howard, Masaki Kobayashi, Akira Kurosawa, John Lasseter, David Lynch, John Milius, Martin Scorsese, Steven Spielberg, Oliver Stone and François Truffaut

Capra married actress Helen Howell in 1923. They divorced in 1928. He married Lucille Warner in 1932, with whom he had a daughter and three sons, one of whom died in infancy.

Capra was four times president of the Academy of Motion Picture Arts and Sciences and three times president of the Directors Guild of America, which he helped found. Under his presidency, he worked to give directors more artistic control of their films. During his career as a director, he retained an early ambition to teach science, and after his career declined in the 1950s, he made educational television films related to science subjects.

Physically, Capra was short, stocky, and vigorous, and enjoyed outdoor activities such as hunting, fishing, and mountain climbing. In his later years, he spent time writing short stories and songs, along with playing guitar. He collected fine and rare books during the 1930s and 1940s. Six hundred and forty items from his "distinguished library" were sold by Parke-Bernet Galleries at auction in New York in April 1949, realizing $68,000 ($ today).

His son Frank Capra Jr. was the president of EUE Screen Gems Studios in Wilmington, North Carolina, until his death on December 19, 2007. His grandsons, brothers Frank Capra III and Jonathan Capra, have both worked as assistant directors; Frank III worked on the 1995 film "The American President", which referred to Frank Capra in the film's dialogue.

Capra's political views coalesced in his movies, which promoted and celebrated the spirit of American individualism. A conservative Republican, Capra railed against Franklin D. Roosevelt during his tenure as governor of New York, and opposed his presidency during the years of the Depression. Capra stood against government intervention during the national economic crisis.

In his later years, Capra became a self-described pacifist and was very critical of the Vietnam War.

In 1985, aged 88, Capra suffered one of a series of strokes. He died in La Quinta, California, of a heart attack in his sleep in 1991 at the age of 94. He was interred at Coachella Valley Public Cemetery in Coachella, California.

He left part of his ranch in Fallbrook, California, to the California Institute of Technology, to be used as a retreat center. Capra's personal papers and some film related materials are contained in the Wesleyan University Cinema Archives, which allows scholars and media experts full access.

During the golden age of Hollywood, Capra's "fantasies of goodwill" made him one of the two or three most famous and successful directors in the world. Film historian Ian Freer notes that at the time of his death in 1991, his legacy remained intact:

Director/actor John Cassavetes contemplating Capra's contribution to film quipped: "Maybe there really wasn't an America, it was only Frank Capra." Capra's films were his love letters to an idealized America—a cinematic landscape of his own invention. The performances his actors gave were invariable portrayals of personalities developed into recognizable images of popular culture, "their acting has the bold simplicity of an icon ..."

Like his contemporary, director John Ford, Capra defined and aggrandized the tropes of mythic America where individual courage invariably triumphs over collective evil. Film historian Richard Griffith speaks of Capra's "... reliance on sentimental conversation and the ultimate benevolence of ordinary America to resolve all deep conflicts." "Average America" is visualized as "... a tree lined street, undistinguished frame houses surrounded by modest areas of grass, a few automobiles. For certain purposes it assumed that all "real "Americans live in towns like this, and so great is the power of myth, even the born city-dweller is likely to believe vaguely that he too lives on this shady street, or comes from it, or is going to."

NYU professor Leonard Quart writes:

Although Capra's stature as a director had declined in the 1950s, his films underwent a revival in the 1960s:

French film historian John Raeburn, editor of "Cahiers du cinéma", noted that Capra's films were unknown in France, but there too his films underwent a fresh discovery by the public. He believes the reason for his renewed popularity had to do with his themes, which he made credible "an ideal conception of an American national character":

In 1982, the American Film Institute honored Capra by giving him their AFI Life Achievement Award. The event was used to create the television film, "The American Film Institute Salute to Frank Capra", hosted by James Stewart. In 1986, Capra received the National Medal of Arts. During his acceptance speech for the AFI award, Capra stressed his most important values:

Capra expanded on his visions in his 1971 autobiography, "The Name Above the Title":

The "Why We Fight" series earned Capra the Legion of Merit in 1943 and the Distinguished Service Medal in 1945.

In 1957, Capra was awarded the George Eastman Award, given by George Eastman House for distinguished contribution to the art of film.

Los Angeles Mayor Sam Yorty, by vote of the city council, declared May 12, 1962 as "Frank Capra Day." George Sidney, President of the Directors Guild stated that "This is the first time in the history of Hollywood, that the city of Los Angeles has officially recognized a creative talent." At the event ceremony, director John Ford announced that Capra had also received an honorary Order of the British Empire (OBE) on the recommendation of Winston Churchill. Ford suggested publicly to Capra:

In 1966, Capra was awarded the Distinguished Alumni Award from his alma mater Caltech. (see section "Early Life", supra)

In 1975, Capra was awarded the Golden Anchor Award by the U.S Naval Reserve's Combat Camera Group for his contribution to World War II Naval photography and production of the "Why We Fight" series. The award ceremony included a video salute by President Ford. Attending were many of Capra's favorite actors including: Jimmy Stewart, Donna Reed, Pat O'Brien, Jean Arthur, and others.

An annual "It's a Wonderful Life" celebration that Capra attended in 1981, during which he said, "This is one of the proudest moments of my life," was recounted in "The New Yorker".

He was nominated six times for Best Director and seven times for Outstanding Production/Best Picture. Out of six nominations for Best Director, Capra received the award three times. He briefly held the record for winning the most Best Director Oscars when he won for the third time in 1938, until this record was matched by John Ford in 1941, and then later surpassed by Ford in 1952. William Wyler also matched this record upon winning his third Oscar in 1959.

The Academy Film Archive has preserved two of Capra's films, "The Matinee Idol" (1928) and "Two Down and One to Go!" (1945).










</doc>
<doc id="11370" url="https://en.wikipedia.org/wiki?curid=11370" title="FIFA World Cup">
FIFA World Cup

The FIFA World Cup, often simply called the World Cup, is an international association football competition contested by the senior men's national teams of the members of the "" (FIFA), the sport's global governing body. The championship has been awarded every four years since the inaugural tournament in 1930, except in 1942 and 1946 when it was not held because of the Second World War. The current champion is France, which won its second title at the 2018 tournament in Russia.

The current format of the competition involves a qualification phase, which currently takes place over the preceding three years, to determine which teams qualify for the tournament phase, which is often called the "World Cup Finals". After this, 32 teams, including the automatically qualifying host nation(s), compete in the tournament phase for the title at venues within the host nation(s) over a period of about a month.

The 21 World Cup tournaments have been won by eight national teams. Brazil have won five times, and they are the only team to have played in every tournament. The other World Cup winners are Germany and Italy, with four titles each; Argentina, France and inaugural winner Uruguay, with two titles each; and England and Spain with one title each.

The World Cup is the most prestigious association football tournament in the world, as well as the most widely viewed and followed sporting event in the world, exceeding even the Olympic Games; the cumulative viewership of all matches of the 2006 World Cup was estimated to be 26.29 billion with an estimated 715.1 million people watching the final match, a ninth of the entire population of the planet.

17 countries have hosted the World Cup. Brazil, France, Italy, Germany and Mexico have each hosted twice, while Uruguay, Switzerland, Sweden, Chile, England, Argentina, Spain, the United States, Japan and South Korea (jointly), South Africa and Russia have each hosted once. Qatar are planned as hosts of the 2022 finals, and 2026 will be jointly hosted by Canada, the United States and Mexico, which will give Mexico the distinction of being the first country to have hosted games in three finals.

The world's first international football match was a challenge match played in Glasgow in 1872 between Scotland and England, which ended in a 0–0 draw. The first international tournament, the inaugural British Home Championship, took place in 1884. As football grew in popularity in other parts of the world at the start of the 20th century, it was held as a demonstration sport with no medals awarded at the 1900 and 1904 Summer Olympics (however, the International Olympic Committee has retroactively upgraded their status to official events), and at the 1906 Intercalated Games.

After FIFA was founded in 1904, it tried to arrange an international football tournament between nations outside the Olympic framework in Switzerland in 1906. These were very early days for international football, and the official history of FIFA describes the competition as having been a failure.

At the 1908 Summer Olympics in London, football became an official competition. Planned by The Football Association (FA), England's football governing body, the event was for amateur players only and was regarded suspiciously as a show rather than a competition. Great Britain (represented by the England national amateur football team) won the gold medals. They repeated the feat at the 1912 Summer Olympics in Stockholm.

With the Olympic event continuing to be contested only between amateur teams, Sir Thomas Lipton organised the Sir Thomas Lipton Trophy tournament in Turin in 1909. The Lipton tournament was a championship between individual clubs (not national teams) from different nations, each one of which represented an entire nation. The competition is sometimes described as "The First World Cup", and featured the most prestigious professional club sides from Italy, Germany and Switzerland, but the FA of England refused to be associated with the competition and declined the offer to send a professional team. Lipton invited West Auckland, an amateur side from County Durham, to represent England instead. West Auckland won the tournament and returned in 1911 to successfully defend their title.

In 1914, FIFA agreed to recognise the Olympic tournament as a "world football championship for amateurs", and took responsibility for managing the event. This paved the way for the world's first intercontinental football competition, at the 1920 Summer Olympics, contested by Egypt and 13 European teams, and won by Belgium. Uruguay won the next two Olympic football tournaments in 1924 and 1928. Those were also the first two open world championships, as 1924 was the start of FIFA's professional era.

Due to the success of the Olympic football tournaments, FIFA, with President Jules Rimet as the driving force, again started looking at staging its own international tournament outside of the Olympics. On 28 May 1928, the FIFA Congress in Amsterdam decided to stage a world championship itself. With Uruguay now two-time official football world champions and to celebrate their centenary of independence in 1930, FIFA named Uruguay as the host country of the inaugural World Cup tournament.

The national associations of selected nations were invited to send a team, but the choice of Uruguay as a venue for the competition meant a long and costly trip across the Atlantic Ocean for European sides. Indeed, no European country pledged to send a team until two months before the start of the competition. Rimet eventually persuaded teams from Belgium, France, Romania, and Yugoslavia to make the trip. In total, 13 nations took part: seven from South America, four from Europe and two from North America.
The first two World Cup matches took place simultaneously on 13 July 1930, and were won by France and the USA, who defeated Mexico 4–1 and Belgium 3–0 respectively. The first goal in World Cup history was scored by Lucien Laurent of France. In the final, Uruguay defeated Argentina 4–2 in front of 93,000 people in Montevideo, and became the first nation to win the World Cup. After the creation of the World Cup, FIFA and the IOC disagreed over the status of amateur players, and so football was dropped from the 1932 Summer Olympics. Olympic football returned at the 1936 Summer Olympics, but was now overshadowed by the more prestigious World Cup.

The issues facing the early World Cup tournaments were the difficulties of intercontinental travel, and war. Few South American teams were willing to travel to Europe for the 1934 World Cup and all North and South American nations except Brazil and Cuba boycotted the 1938 tournament. Brazil was the only South American team to compete in both. The 1942 and 1946 competitions, which Germany and Brazil sought to host, were cancelled due to World War II and its aftermath.

The 1950 World Cup, held in Brazil, was the first to include British participants. British teams withdrew from FIFA in 1920, partly out of unwillingness to play against the countries they had been at war with, and partly as a protest against foreign influence on football, but rejoined in 1946 following FIFA's invitation. The tournament also saw the return of 1930 champions Uruguay, who had boycotted the previous two World Cups. Uruguay won the tournament again after defeating the host nation Brazil, in the match called "Maracanazo" (Portuguese: "Maracanaço").

In the tournaments between 1934 and 1978, 16 teams competed in each tournament, except in 1938, when Austria was absorbed into Germany after qualifying, leaving the tournament with 15 teams, and in 1950, when India, Scotland, and Turkey withdrew, leaving the tournament with 13 teams. Most of the participating nations were from Europe and South America, with a small minority from North America, Africa, Asia, and Oceania. These teams were usually defeated easily by the European and South American teams. Until 1982, the only teams from outside Europe and South America to advance out of the first round were: USA, semi-finalists in 1930; Cuba, quarter-finalists in 1938; North Korea, quarter-finalists in 1966; and Mexico, quarter-finalists in 1970.

The tournament was expanded to 24 teams in 1982, and then to 32 in 1998, also allowing more teams from Africa, Asia and North America to take part. Since then, teams from these regions have enjoyed more success, with several having reached the quarter-finals: Mexico, quarter-finalists in 1986; Cameroon, quarter-finalists in 1990; South Korea, finishing in fourth place in 2002; Senegal, along with USA, both quarter-finalists in 2002; Ghana, quarter-finalists in 2010; and Costa Rica, quarter-finalists in 2014. Nevertheless, European and South American teams continue to dominate, e.g., the quarter-finalists in 1994, 1998, 2006 and 2018 were all from Europe or South America and so were the finalists of all tournaments so far.

Two hundred teams entered the 2002 FIFA World Cup qualification rounds; 198 nations attempted to qualify for the 2006 FIFA World Cup, while a record 204 countries entered qualification for the 2010 FIFA World Cup.

In October 2013, Sepp Blatter spoke of guaranteeing the Caribbean Football Union's region a position in the World Cup. In the edition of 25 October 2013 of the "FIFA Weekly" Blatter wrote that: "From a purely sporting perspective, I would like to see globalisation finally taken seriously, and the African and Asian national associations accorded the status they deserve at the FIFA World Cup. It cannot be that the European and South American confederations lay claim to the majority of the berths at the World Cup." Those two remarks suggested to commentators that Blatter could be putting himself forward for re-election to the FIFA Presidency.

Following the magazine's publication, Blatter's would-be opponent for the FIFA Presidency, UEFA President Michel Platini, responded that he intended to extend the World Cup to 40 national associations, increasing the number of participants by eight. Platini said that he would allocate an additional berth to UEFA, two to the Asian Football Confederation and the Confederation of African Football, two shared between CONCACAF and CONMEBOL, and a guaranteed place for the Oceania Football Confederation. Platini was clear about why he wanted to expand the World Cup. He said: "[The World Cup is] not based on the quality of the teams because you don't have the best 32 at the World Cup ... but it's a good compromise. ... It's a political matter so why not have more Africans? The competition is to bring all the people of all the world. If you don't give the possibility to participate, they don't improve."

In October 2016, FIFA president Gianni Infantino stated his support for a 48-team World Cup in 2026. On 10 January 2017, FIFA confirmed the 2026 World Cup will have 48 finalist teams.

By May 2015, the games were under a particularly dark cloud because of the 2015 FIFA corruption case, allegations and criminal charges of bribery, fraud and money laundering to corrupt the issuing of media and marketing rights (rigged bids) for FIFA games, with FIFA officials accused of taking bribes totaling more than $150 million over 24 years. In late May, the U.S. Justice Department announced a 47-count indictment with charges of racketeering, wire fraud and money laundering conspiracy against 14 people. Arrests of over a dozen FIFA officials were made since that time, particularly on 29 May and 3 December. By the end of May 2015, a total of nine FIFA officials and five executives of sports and broadcasting markets had already been charged on corruption. At the time, FIFA president Sepp Blatter announced he would relinquish his position in February 2016.

On 4 June 2015 Chuck Blazer while co-operating with the FBI and the Swiss authorities admitted that he and the other members of FIFA's then-executive committee were bribed in order to promote the 1998 and 2010 World Cups. On 10 June 2015 Swiss authorities seized computer data from the offices of Sepp Blatter. The same day, FIFA postponed the bidding process for the 2026 FIFA World Cup in light of the allegations surrounding bribery in the awarding of the 2018 and 2022 tournaments. Then-secretary general Jérôme Valcke stated, "Due to the situation, I think it's nonsense to start any bidding process for the time being." On 28 October 2015, Blatter and FIFA VP Michel Platini, a potential candidate for presidency, were suspended for 90 days; both maintained their innocence in statements made to the news media.

On 3 December 2015 two FIFA vice-presidents were arrested on suspicion of bribery in the same Zurich hotel where seven FIFA officials had been arrested in May. An additional 16 indictments by the U.S. Department of Justice were announced on the same day.

An equivalent tournament for women's football, the FIFA Women's World Cup, was first held in 1991 in China. The women's tournament is smaller in scale and profile than the men's, but is growing; the number of entrants for the 2007 tournament was 120, more than double that of 1991.

Men's football has been included in every Summer Olympic Games except 1896 and 1932. Unlike many other sports, the men's football tournament at the Olympics is not a top-level tournament, and since 1992, an under-23 tournament with each team allowed three over-age players. Women's football made its Olympic debut in 1996.

The FIFA Confederations Cup was a tournament held one year before the World Cup at the World Cup host nation(s) as a dress rehearsal for the upcoming World Cup. It is contested by the winners of each of the six FIFA confederation championships, along with the FIFA World Cup champion and the host country. The first edition took place in 1992 and the last edition was played in 2017. In March 2019, FIFA confirmed that the tournament would no longer be active owing to an expansion of the FIFA Club World Cup in 2021.

FIFA also organises international tournaments for youth football (FIFA U-20 World Cup, FIFA U-17 World Cup, FIFA U-20 Women's World Cup, FIFA U-17 Women's World Cup), club football (FIFA Club World Cup), and football variants such as futsal (FIFA Futsal World Cup) and beach soccer (FIFA Beach Soccer World Cup). The latter three do not have a women's version, although a FIFA Women's Club World Cup has been proposed.

The FIFA U-20 Women's World Cup is held the year before each Women's World Cup and both tournaments are awarded in a single bidding process. The U-20 tournament serves as a dress rehearsal for the larger competition.

From 1930 to 1970, the "Jules Rimet Trophy" was awarded to the World Cup winning team. It was originally simply known as the "World Cup" or "Coupe du Monde", but in 1946 it was renamed after the FIFA president Jules Rimet who set up the first tournament. In 1970, Brazil's third victory in the tournament entitled them to keep the trophy permanently. However, the trophy was stolen in 1983 and has never been recovered, apparently melted down by the thieves.
After 1970, a new trophy, known as the FIFA World Cup Trophy, was designed. The experts of FIFA, coming from seven countries, evaluated the 53 presented models, finally opting for the work of the Italian designer Silvio Gazzaniga. The new trophy is high, made of solid 18 carat (75%) gold and weighs . The base contains two layers of semi-precious malachite while the bottom side of the trophy bears the engraved year and name of each FIFA World Cup winner since 1974. The description of the trophy by Gazzaniga was: "The lines spring out from the base, rising in spirals, stretching out to receive the world. From the remarkable dynamic tensions of the compact body of the sculpture rise the figures of two athletes at the stirring moment of victory."

This new trophy is not awarded to the winning nation permanently. World Cup winners retain the trophy only until the post-match celebration is finished. They are awarded a gold-plated replica rather than the solid gold original immediately afterwards.

Currently, all members (players, coaches, and managers) of the top three teams receive medals with an insignia of the World Cup Trophy; winners' (gold), runners-up' (silver), and third-place (bronze). In the 2002 edition, fourth-place medals were awarded to hosts South Korea. Before the 1978 tournament, medals were only awarded to the eleven players on the pitch at the end of the final and the third-place match. In November 2007, FIFA announced that all members of World Cup-winning squads between 1930 and 1974 were to be retroactively awarded winners' medals.

Since the second World Cup in 1934, qualifying tournaments have been held to thin the field for the final tournament. They are held within the six FIFA continental zones (Africa, Asia, North and Central America and Caribbean, South America, Oceania, and Europe), overseen by their respective confederations. For each tournament, FIFA decides the number of places awarded to each of the continental zones beforehand, generally based on the relative strength of the confederations' teams.

The qualification process can start as early as almost three years before the final tournament and last over a two-year period. The formats of the qualification tournaments differ between confederations. Usually, one or two places are awarded to winners of intercontinental play-offs. For example, the winner of the Oceanian zone and the fifth-placed team from the Asian zone entered a play-off for a spot in the 2010 World Cup. From the 1938 World Cup onwards, host nations receive automatic qualification to the final tournament. This right was also granted to the defending champions between 1938 and 2002, but was withdrawn from the 2006 FIFA World Cup onward, requiring the champions to qualify. Brazil, winners in 2002, were the first defending champions to play qualifying matches.

The current final tournament has been used since 1998 and features 32 national teams competing over the course of a month in the host nation(s). There are two stages: the group stage followed by the knockout stage.

In the group stage, teams compete within eight groups of four teams each. Eight teams are seeded, including the hosts, with the other seeded teams selected using a formula based on the FIFA World Rankings and/or performances in recent World Cups, and drawn to separate groups. The other teams are assigned to different "pots", usually based on geographical criteria, and teams in each pot are drawn at random to the eight groups. Since 1998, constraints have been applied to the draw to ensure that no group contains more than two European teams or more than one team from any other confederation.

Each group plays a round-robin tournament, in which each team is scheduled for three matches against other teams in the same group. This means that a total of six matches are played within a group. The last round of matches of each group is scheduled at the same time to preserve fairness among all four teams. The top two teams from each group advance to the knockout stage. Points are used to rank the teams within a group. Since 1994, three points have been awarded for a win, one for a draw and none for a loss (before, winners received two points).

If one considers all possible outcomes (win, draw, loss) for all six matches in a group, there are 729 (= 3) outcome combinations possible. However, 207 of these combinations lead to ties between the second and third places. In such case, the ranking among these teams is determined as follows:

The knockout stage is a single-elimination tournament in which teams play each other in one-off matches, with extra time and penalty shootouts used to decide the winner if necessary. It begins with the round of 16 (or the second round) in which the winner of each group plays against the runner-up of another group. This is followed by the quarter-finals, the semi-finals, the third-place match (contested by the losing semi-finalists), and the final.

On 10 January 2017, FIFA approved a new format, the 48-team World Cup (to accommodate more teams), which consists of 16 groups of three teams each, with two teams qualifying from each group, to form a round of 32 knockout stage, to be implemented by 2026.

Early World Cups were given to countries at meetings of FIFA's congress. The locations were controversial because South America and Europe were by far the two centres of strength in football and travel between them required three weeks by boat. The decision to hold the first World Cup in Uruguay, for example, led to only four European nations competing. The next two World Cups were both held in Europe. The decision to hold the second of these in France was disputed, as the South American countries understood that the location would alternate between the two continents. Both Argentina and Uruguay thus boycotted the 1938 FIFA World Cup.

Since the 1958 FIFA World Cup, to avoid future boycotts or controversy, FIFA began a pattern of alternating the hosts between the Americas and Europe, which continued until the 1998 FIFA World Cup. The 2002 FIFA World Cup, hosted jointly by South Korea and Japan, was the first one held in Asia, and the first tournament with multiple hosts. South Africa became the first African nation to host the World Cup in 2010. The 2014 FIFA World Cup was hosted by Brazil, the first held in South America since Argentina 1978, and was the first occasion where consecutive World Cups were held outside Europe.

The host country is now chosen in a vote by FIFA's Council. This is done under an exhaustive ballot system. The national football association of a country desiring to host the event receives a "Hosting Agreement" from FIFA, which explains the steps and requirements that are expected from a strong bid. The bidding association also receives a form, the submission of which represents the official confirmation of the candidacy. After this, a FIFA designated group of inspectors visit the country to identify that the country meets the requirements needed to host the event and a report on the country is produced. The decision on who will host the World Cup is usually made six or seven years in advance of the tournament. However, there have been occasions where the hosts of multiple future tournaments were announced at the same time, as was the case for the 2018 and 2022 World Cups, which were awarded to Russia and Qatar, with Qatar becoming the first Middle Eastern country to host the tournament.

For the 2010 and 2014 World Cups, the final tournament is rotated between confederations, allowing only countries from the chosen confederation (Africa in 2010, South America in 2014) to bid to host the tournament. The rotation policy was introduced after the controversy surrounding Germany's victory over South Africa in the vote to host the 2006 tournament. However, the policy of continental rotation will not continue beyond 2014, so any country, except those belonging to confederations that hosted the two preceding tournaments, can apply as hosts for World Cups starting from 2018. This is partly to avoid a similar scenario to the bidding process for the 2014 tournament, where Brazil was the only official bidder.

The 2026 FIFA World Cup was chosen to be held in the United States, Canada and Mexico, marking the first time a World Cup has been shared by three host nations. The 2026 tournament will be the biggest World Cup ever held, with 48 teams playing 80 matches. Sixty matches will take place in the US, including all matches from the quarter-finals onward, while Canada and Mexico will host 10 games each.

Six of the eight champions have won one of their titles while playing in their own homeland, the exceptions being Brazil, who finished as runners-up after losing the deciding match on home soil in 1950 and lost their semi-final against Germany in 2014, and Spain, which reached the second round on home soil in 1982. England (1966) won its only title while playing as a host nation. Uruguay (1930), Italy (1934), Argentina (1978) and 
France (1998) won their first titles as host nations but have gone on to win again, while Germany (1974) won their second title on home soil.

Other nations have also been successful when hosting the tournament. Switzerland (quarter-finals 1954), Sweden (runners-up in 1958), Chile (third place in 1962), South Korea (fourth place in 2002), and Mexico (quarter-finals in 1970 and 1986) all have their best results when serving as hosts. So far, South Africa (2010) has been the only host nation to fail to advance beyond the first round.

 The best-attended single match, shown in the last three columns, has been the final in 11 of the 21 World Cups . Another match or matches drew more attendance than the final in 1930, 1938, 1958, 1962, 1970–1982, 1990 and 2006.


 
The World Cup was first televised in 1954 and is now the most widely viewed and followed sporting event in the world. The cumulative viewership of all matches of the 2006 World Cup is estimated to be 26.29 billion. 715.1 million individuals watched the final match of this tournament (a ninth of the entire population of the planet). The 2006 World Cup draw, which decided the distribution of teams into groups, was watched by 300 million viewers. The World Cup attracts many sponsors such as Coca-Cola, McDonald's and Adidas. For these companies and many more, being a sponsor strongly impacts their global brands. Host countries typically experience a multimillion-dollar revenue increase from the month-long event.
The governing body of the sport, FIFA, generated $4.8 billion in revenue from the 2014 tournament.
Each FIFA World Cup since 1966 has its own mascot or logo. "World Cup Willie", the mascot for the 1966 competition, was the first World Cup mascot. World Cups feature official match balls specially designed for each tournament. Each World Cup also has an official song, which have been performed by artists ranging from Shakira to Will Smith. Other songs, such as “Nessun dorma”, performed by The Three Tenors at four World Cup concerts, have also become identified with the tournament.

Forming a partnership with FIFA in 1970, Panini published its first sticker album for the 1970 World Cup. Since then, collecting and trading stickers and cards has become part of the World Cup experience, especially for the younger generation. FIFA has also licensed World Cup video games since 1986, with Electronic Arts the current license holder.

The World Cup even has a statistically significant effect on birth rates, the male/female sex ratio of newborns, and heart attacks in nations whose national teams are competing.

In all, 79 nations have played in at least one World Cup. Of these, eight national teams have won the World Cup, and they have added stars to their badges, with each star representing a World Cup victory. (Uruguay, however, choose to display four stars on their badge, representing their two gold medals at the 1924 and 1928 Summer Olympics and their two World Cup titles in 1930 and 1950).

With five titles, Brazil are the most successful World Cup team and also the only nation to have played in every World Cup (21) to date. Brazil were also the first team to win the World Cup for the third (1970), fourth (1994) and fifth (2002) time. Italy (1934 and 1938) and Brazil (1958 and 1962) are the only nations to have won consecutive titles. West Germany (1982–1990) and Brazil (1994–2002) are the only nations to appear in three consecutive World Cup finals. Germany has made the most top-four finishes (13), medals (12), as well as the most finals (8).

To date, the final of the World Cup has only been contested by teams from the UEFA (Europe) and CONMEBOL (South America) confederations. European nations have won twelve titles, while South American have won nine. Only two teams from outside these two continents have ever reached the semi-finals of the competition: United States (North, Central America and Caribbean) in 1930 and South Korea (Asia) in 2002. The best result of an African team is reaching the quarter-finals: Cameroon in 1990, Senegal in 2002 and Ghana in 2010. Only one Oceanian qualifier, Australia in 2006, has advanced to the second round.

Brazil, Argentina, Spain and Germany are the only teams to win a World Cup outside their continental confederation; Brazil came out victorious in Europe (1958), North America (1970 and 1994) and Asia (2002). Argentina won a World Cup in North America in 1986, while Spain won in Africa in 2010. In 2014, Germany became the first European team to win in the Americas. Only on five occasions have consecutive World Cups been won by teams from the same continent, and currently it is the first time with four champions in a row from the same continental confederation. Italy and Brazil successfully defended their titles in 1938 and 1962 respectively, while Italy's triumph in 2006 has been followed by wins for Spain in 2010, Germany in 2014 and France in 2018. Currently, it is also the first time that one of the currently winning continents (Europe) is ahead of the other (South America) by more than one championship.

At the end of each World Cup, awards are presented to the players and teams for accomplishments other than their final team positions in the tournament. There are currently six awards:
An "All-Star Team" consisting of the best players of the tournament has also been announced for each tournament since 1998.

Three players share the record for playing in the most World Cups; Mexico's Antonio Carbajal (1950–1966) and Rafael Márquez (2002–2018); and Germany's Lothar Matthäus (1982–1998) all played in five tournaments. Matthäus has played the most World Cup matches overall, with 25 appearances. Brazil's Djalma Santos (1954–1962), West Germany's Franz Beckenbauer (1966–1974) and Germany's Philipp Lahm (2006–2014) are the only players to be named to three Finals All-Star Teams.

Miroslav Klose of Germany (2002–2014) is the all-time top scorer at the finals, with 16 goals. He broke Ronaldo of Brazil's record of 15 goals (1998–2006) during the 2014 semi-final match against Brazil. West Germany's Gerd Müller (1970–1974) is third, with 14 goals. The fourth placed goalscorer, France's Just Fontaine, holds the record for the most goals scored in a single World Cup; all his 13 goals were scored in the 1958 tournament.

In November 2007, FIFA announced that all members of World Cup-winning squads between 1930 and 1974 were to be retroactively awarded winners' medals. This made Brazil's Pelé the only player to have won three World Cup winners' medals (1958, 1962, and 1970, although he did not play in the 1962 final due to injury), with 20 other players who have won two winners' medals. Seven players have collected all three types of World Cup medals (winners', runner- ups', and third-place); five players were from West Germany's squad of 1966–1974 including Franz Beckenbauer, Jürgen Grabowski, Horst-Dieter Höttges, Sepp Maier and Wolfgang Overath (1966–1974), Italy's Franco Baresi (1982, 1990, 1994) and the most recent has been Miroslav Klose of Germany (2002–2014) with four consecutive medals.

Brazil's Mário Zagallo, West Germany's Franz Beckenbauer and France's Didier Deschamps are the only people to date to win the World Cup as both player and head coach. Zagallo won in 1958 and 1962 as a player and in 1970 as head coach. Beckenbauer won in 1974 as captain and in 1990 as head coach, and Deschamps repeated the feat in 2018, after having won in 1998 as captain. Italy's Vittorio Pozzo is the only head coach to ever win two World Cups (1934 and 1938). All World Cup-winning head coaches were natives of the country they coached to victory.

Among the national teams, Germany and Brazil have played the most World Cup matches (109), Germany appeared in the most finals (8), semi-finals (13), quarter-finals (16), while Brazil has appeared in the most World Cups (21), has the most wins (73) and has scored the most goals (229). The two teams have played each other twice in the World Cup, in the 2002 final and in the 2014 semi-final.




</doc>
<doc id="11371" url="https://en.wikipedia.org/wiki?curid=11371" title="Quintus Fabius Maximus Verrucosus">
Quintus Fabius Maximus Verrucosus

Quintus Fabius Maximus Verrucosus, surnamed Cunctator ( 280–203 BC), was a Roman statesman and general of the third century BC. He was consul five times (233, 228, 215, 214, and 209 BC) and was appointed dictator in 221 and 217 BC. He was censor in 230 BC. His agnomen, "Cunctator", usually translated as "the delayer", refers to the strategy that he employed against Hannibal's forces during the Second Punic War. Facing an outstanding commander with superior numbers, he pursued a then-novel strategy of targeting the enemy's supply lines, and accepting only smaller engagements on favourable ground, rather than risking his entire army on direct confrontation with Hannibal himself. As a result, he is regarded as the originator of many tactics used in guerrilla warfare.

Born at Rome c. 280 BC, Fabius was a descendant of the ancient patrician Fabia gens. He was the son or grandson of Quintus Fabius Maximus Gurges, three times consul and "princeps senatus", and grandson or great-grandson of Quintus Fabius Maximus Rullianus, a hero of the Samnite Wars, who like Verrucosus held five consulships, as well as the offices of dictator and censor. Many earlier ancestors had also been consuls. His cognomen, "Verrucosus", or "warty", used to distinguish him from other members of his family, derived from a wart on his upper lip.

According to Plutarch, Fabius possessed a mild temper and slowness in speaking. As a child, he had difficulties in learning, engaged in sports with other children cautiously and appeared submissive in his interactions with others. All the above were perceived by those who knew him superficially to be signs of inferiority. However, according to Plutarch, these traits proceeded from stability, greatness of mind, and lion-likeness of temper. By the time he reached adulthood and was roused by active life, his virtues exerted themselves; consequently, his lack of energy displayed during his earlier years was revealed as a result of a lack of passion and his slowness was recognised as a sign of prudence and firmness.

While still a youth in 265 BC, Fabius was consecrated an augur. It is unknown whether he participated in the First Punic War, fought between the Roman Republic and Carthage from 264 to 241 BC, or what his role might have been. Fabius' political career began in the years following that war. He was probably quaestor in 237 or 236 BC, and curule aedile about 235. During his first consulship, in 233 BC, Fabius was awarded a triumph for his victory over the Ligurians, whom he defeated and drove into the Alps. He was censor in 230, then consul a second time in 228. It is possible that he held the office of dictator for a first time around this time: according to Livy, Fabius's tenure of the dictatorship in 217 was his second term in that office, with Gaius Flaminius as his deputy and magister equitum during the first term: however Plutarch suggests that Flaminius was deputy instead to Marcus Minucius Rufus - presumably Fabius's great political rival of that name, who later served as deputy to Fabius himself (see below). It is of course possible that Flaminius was successively deputy to both, after Minucius's apparently premature deposition following bad augural omens: and also possible that little of note (other than, possibly, holding elections during the absence of consuls) was accomplished during either dictatorship.

According to Livy, in 218 BC Fabius took part in an embassy to Carthage, sent to demand redress for the capture of the supposedly neutral town of Saguntum in Spain. After the delegation had received the Carthaginians' reply, it was Fabius himself who, addressing the Carthaginian senate, issued a formal declaration of war between Carthage and the Roman Republic. However, Cassius Dio, followed by Zonaras, calls the ambassador "Marcus Fabius", suggesting that it was his cousin, Marcus Fabius Buteo, who issued the declaration of war against the Carthaginians.

When the Consul Gaius Flaminius was killed during the disastrous Roman defeat at the Battle of Lake Trasimene in 217 BC, panic swept Rome. With Consular armies destroyed in two major battles, and Hannibal approaching Rome's gates, the Romans feared the imminent destruction of their city. The Roman Senate decided to appoint a dictator, and chose Fabius for the role - possibly for the second time, though evidence of a previous term seems to be conflicting - in part due to his advanced age and experience. However, he was not allowed to appoint his own Master of the Horse; instead, the Romans chose a political enemy, Marcus Minucius. Then Fabius quickly sought to calm the Roman people by asserting himself as a strong Dictator at the moment of what was perceived to be the worst crisis in Roman history. He asked the Senate to allow him to ride on horseback, which Dictators were never allowed to do. He then caused himself to be accompanied by the full complement of twenty-four lictors, and ordered the surviving Consul, Gnaeus Servilius Geminus, to dismiss his lictors (in essence, surrendering his office), and to present himself before Fabius as a private citizen.

Plutarch tells us that Fabius believed that the disaster at Lake Trasimene was due, in part, to the fact that the gods had become neglected. Before that battle, a series of omens had been witnessed, including a series of lightning bolts, which Fabius had believed were warnings from the gods. He had warned Flaminius of this, but Flaminius had ignored the warnings. And so Fabius, as Dictator, next sought to please the gods. He ordered a massive sacrifice of the whole product of the next harvest season throughout Italy, in particular that of cows, goats, swine, and sheep. In addition, he ordered that musical festivities be celebrated, and then told his fellow citizens to each spend a precise sum of 333 sestertii and 333 denarii. Plutarch isn't sure exactly how Fabius came up with this number, although he believes it was to honor the perfection of the number three, as it is the first of the odd numbers, and one of the first of the prime numbers. It is not known if Fabius truly believed that these actions had won the gods over to the Roman side, although the actions probably did (as intended) convince the average Roman that the gods had finally been won over.

Fabius respected Hannibal's military skill and so refused to meet him in a pitched battle. Instead, he kept his troops close to Hannibal, hoping to exhaust him in a long war of attrition. Fabius was able to harass the Carthaginian foraging parties, limiting Hannibal's ability to wreak destruction, while conserving his own military force. The delaying tactics involved not directly engaging Hannibal, while also exercising a "scorched earth" practice to prevent Hannibal's forces from obtaining grain and other resources. 

The Romans were unimpressed with this defensive strategy and at first gave Fabius his epithet Cunctator (delayer) as an insult. The strategy was in part ruined because of a lack of unity in the command of the Roman army, since Fabius' Master of the Horse, Minucius, was a political enemy of Fabius. At one point, Fabius was called by the priests to assist with certain sacrifices, and as such, Fabius left the command of the army in the hands of Minucius during his absence. Fabius had told Minucius not to attack Hannibal in his absence, but Minucius disobeyed and attacked anyway. The attack, though of no strategic value, resulted in the retreat of several enemy units, and so the Roman people, desperate for good news, believed Minucius to be a hero. On hearing of this, Fabius became enraged, and, as Dictator, could have ordered Minucius' execution for his disobedience. One of the Plebeian Tribunes (chief representatives of the people) for the year, Metilius, was a partisan of Minucius, and as such he sought to use his power to help Minucius. The Plebeian Tribunes were the only magistrates independent of the Dictator, and so with his protection, Minucius was relatively safe. Plutarch states that Metilius "boldly applied himself to the people in the behalf of Minucius", and had Minucius granted powers equivalent to those of Fabius. By this, Plutarch probably means that as a Plebeian Tribune, Metilius had the Plebeian Council, a popular assembly which only Tribunes could preside over, grant Minucius quasi-dictatorial powers.

Fabius did not attempt to fight the promotion of Minucius, but rather decided to wait until Minucius' rashness caused him to run headlong into some disaster. He realized what would happen when Minucius was defeated in battle by Hannibal. Fabius, we are told, reminded Minucius that it was Hannibal, and not he, who was the enemy. Minucius proposed that they share the joint control of the army, with command rotating between the two every other day. Fabius rejected this, and instead let Minucius command half of the army, while he commanded the other half. Minucius openly claimed that Fabius was cowardly because he failed to confront the Carthaginian forces. Near the present-day town of Larino in the Molise (then called Larinum), Hannibal had taken up position in a town called Gerione. In the valley between Larino and Gerione, Minucius decided to make a broad frontal attack on Hannibal's troops. Several thousand men were involved on either side. It appeared that the Roman troops were winning, but Hannibal had set a trap. Soon the Roman troops were being slaughtered. Upon seeing the ambush of Minucius' army, Fabius cried "O Hercules! how much sooner than I expected, though later than he seemed to desire, hath Minucius destroyed himself!" On ordering his army to join the battle and rescue their fellow Romans, Fabius exclaimed "We must make haste to rescue Minucius, who is a valiant man, and a lover of his country."

Fabius rushed to his co-commander's assistance and Hannibal's forces immediately retreated. After the battle, there was some feeling that there would be conflict between Minucius and Fabius; however, the younger soldier marched his men to Fabius' encampment and is reported to have said, "My father gave me life. Today you saved my life. You are my second father. I recognize your superior abilities as a commander." When Fabius' term as Dictator ended, consular government was restored, and Gnaeus Servilius Geminus and Marcus Atilius Regulus assumed the consulship for the remainder of the year.

The once looked down upon tactics employed by Fabius came then to be respected. It is said, asserts Plutarch, that even Hannibal acknowledged and feared the Fabian strategy and the Roman inexhaustible manpower. After Fabius lured him away from Apulia into the Bruttian territory and then proceeded to besiege Tarentum by treachery in 209 BC, Hannibal commented, "It seems that the Romans have found another Hannibal, for we have lost Tarentum in the same way that we took it."

Shortly after Fabius had laid down his dictatorship, Gaius Terentius Varro and Ameilus Paullus were elected as consuls. They rallied the people through the assemblies, and won their support for his plan to abandon Fabius' strategy, and engage Hannibal directly. Varro's rashness did not surprise Fabius, but when Fabius learned of the size of the army (eighty-eight thousand soldiers) that Varro had raised, he became quite concerned. Unlike the losses that had been suffered by Minucius, a major loss by Varro had the potential to kill so many soldiers that Rome might have had no further resources with which to continue the war. Fabius had warned the other consul for the year, Aemilius Paullus, to make sure that Varro remained unable to directly engage Hannibal. According to Plutarch, Paullus replied to Fabius that he feared the votes in Rome more than Hannibal's army.

When word reached Rome of the disastrous Roman defeat under Varro and Paullus at the Battle of Cannae in 216 BC, the Senate and the People of Rome turned to Fabius for guidance. They had believed his strategy to be flawed before, but now they thought him to be as wise as the gods. He walked the streets of Rome, assured as to eventual Roman victory, in an attempt to comfort his fellow Romans. Without his support, the senate might have remained too frightened to even meet. He placed guards at the gates of the city to stop the frightened Romans from fleeing, and regulated mourning activities. He set times and places for this mourning, and ordered that each family perform such observances within their own private walls, and that the mourning should be complete within a month; following the completion of these mourning rituals, the entire city was purified of its blood-guilt in the deaths. This decree effectively outlawed competitive outdoor mourning, which could have had a devastating psychological impact on the survivors. Although he did not again hold the office of dictator - and indeed, it was granted to others over him - he might as well have been one unofficially at this time, because whatever measures he proposed were immediately adopted with little or no further debate.

"Cunctator" became an honorific title, and his delaying tactic was followed in Italy for the rest of the war. Fabius' own military success was small, aside from the reconquest of Tarentum in 209 BC. For this victory, Plutarch tells us, he was awarded a second triumph that was even more splendid than the first. When Marcus Livius Macatus, the governor of Tarentum, claimed the merit of recovering the town, Fabius rejoined, "Certainly, had you not lost it, I would have never retaken it." After serving as Dictator, he served as a Consul twice more (in 215 BC and 214 BC), and for a fifth time in 209 BC. He was also Chief Augur (at a very young age) and Pontifex, but never Pontifex Maximus according to Gaius Stern (citing Livy on Fabius). The holding of seats in the two highest colleges was not repeated until either Julius Caesar or possibly Sulla.

In the senate, he opposed the young and ambitious Scipio Africanus, who wanted to carry the war to Africa. Fabius continued to argue that confronting Hannibal directly was too dangerous. Scipio planned to take Roman forces to Carthage itself and force Hannibal to return to Africa to defend the city. Scipio was eventually given limited approval, despite continuous opposition from Fabius, who blocked levies and restricted Scipio's access to troops. Fabius wished to ensure that sufficient forces remained to defend Roman territory if Scipio was defeated. Fabius became gravely ill and died in 203 BC, shortly after Hannibal's army left Italy, and before the eventual Roman victory over Hannibal at the Battle of Zama won by Scipio.

Part of his eulogy is preserved on a fragment, which praised his delaying strategy in his altercations with Hannibal during the Second Punic War. The inscription reads as follows: "...[as censor] he conducted the first revision of the senate membership and held committal elections in the consulship of Marcus Junius Pera and Marcus Barbula; he besieged and recaptured Tarentum and the strong-hold of Hannibal, and [obtained enormous booty?]; he won surpassing glory by his military [exploits?]." 

Later, he became a legendary figure and the model of a tough, courageous Roman, and was bestowed the honorific title, "The Shield of Rome" (similar to Marcus Claudius Marcellus being named the "Sword of Rome"). According to Ennius, "unus homo nobis cunctando restituit rem" – "one man, by delaying, restored the state to us." Virgil, in the Aeneid, has Aeneas' father Anchises mention Fabius Maximus while in Hades as the greatest of the many great Fabii, quoting the same line. While Hannibal is mentioned in the company of history's greatest generals, military professionals have bestowed Fabius' name on an entire strategic doctrine known as "Fabian strategy", and George Washington has been called "the American Fabius."

According to its own ancient legend, the Roman princely family of Massimo descends from Fabius Maximus.






</doc>
<doc id="11376" url="https://en.wikipedia.org/wiki?curid=11376" title="Floating-point arithmetic">
Floating-point arithmetic

In computing, floating-point arithmetic (FP) is arithmetic using formulaic representation of real numbers as an approximation so as to support a trade-off between range and precision. For this reason, floating-point computation is often found in systems which include very small and very large real numbers, which require fast processing times. A number is, in general, represented approximately to a fixed number of significant digits (the significand) and scaled using an exponent in some fixed base; the base for the scaling is normally two, ten, or sixteen. A number that can be represented exactly is of the following form:
where significand is an integer, base is an integer greater than or equal to two, and exponent is also an integer.
For example:

The term "floating point" refers to the fact that a number's radix point ("decimal point", or, more commonly in computers, "binary point") can "float"; that is, it can be placed anywhere relative to the significant digits of the number. This position is indicated as the exponent component, and thus the floating-point representation can be thought of as a kind of scientific notation.

A floating-point system can be used to represent, with a fixed number of digits, numbers of different orders of magnitude: e.g. the distance between galaxies or the diameter of an atomic nucleus can be expressed with the same unit of length. The result of this dynamic range is that the numbers that can be represented are not uniformly spaced; the difference between two consecutive representable numbers grows with the chosen scale.
Over the years, a variety of floating-point representations have been used in computers. In 1985, the IEEE 754 Standard for Floating-Point Arithmetic was established, and since the 1990s, the most commonly encountered representations are those defined by the IEEE.

The speed of floating-point operations, commonly measured in terms of FLOPS, is an important characteristic of a computer system, especially for applications that involve intensive mathematical calculations.

A floating-point unit (FPU, colloquially a math coprocessor) is a part of a computer system specially designed to carry out operations on floating-point numbers.

A number representation specifies some way of encoding a number, usually as a string of digits.

There are several mechanisms by which strings of digits can represent numbers. In common mathematical notation, the digit string can be of any length, and the location of the radix point is indicated by placing an explicit "point" character (dot or comma) there. If the radix point is not specified, then the string implicitly represents an integer and the unstated radix point would be off the right-hand end of the string, next to the least significant digit. In fixed-point systems, a position in the string is specified for the radix point. So a fixed-point scheme might be to use a string of 8 decimal digits with the decimal point in the middle, whereby "00012345" would represent 0001.2345.

In scientific notation, the given number is scaled by a power of 10, so that it lies within a certain range—typically between 1 and 10, with the radix point appearing immediately after the first digit. The scaling factor, as a power of ten, is then indicated separately at the end of the number. For example, the orbital period of Jupiter's moon Io is seconds, a value that would be represented in standard-form scientific notation as seconds.

Floating-point representation is similar in concept to scientific notation. Logically, a floating-point number consists of:

To derive the value of the floating-point number, the "significand" is multiplied by the "base" raised to the power of the "exponent", equivalent to shifting the radix point from its implied position by a number of places equal to the value of the exponent—to the right if the exponent is positive or to the left if the exponent is negative.

Using base-10 (the familiar decimal notation) as an example, the number , which has ten decimal digits of precision, is represented as the significand together with 5 as the exponent. To determine the actual value, a decimal point is placed after the first digit of the significand and the result is multiplied by to give , or . In storing such a number, the base (10) need not be stored, since it will be the same for the entire range of supported numbers, and can thus be inferred.

Symbolically, this final value is:

where is the significand (ignoring any implied decimal point), is the precision (the number of digits in the significand), is the base (in our example, this is the number "ten"), and is the exponent.

Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), eight (octal floating point), base three (balanced ternary floating point) and even base .

A floating-point number is a rational number, because it can be represented as one integer divided by another; for example is (145/100)×1000 or /100. The base determines the fractions that can be represented; for instance, 1/5 cannot be represented exactly as a floating-point number using a binary base, but 1/5 can be represented exactly using a decimal base (, or ). However, 1/3 cannot be represented exactly by either binary (0.010101...) or decimal (0.333...), but in base 3, it is trivial (0.1 or 1×3) . The occasions on which infinite expansions occur depend on the base and its prime factors.
The way in which the significand (including its sign) and exponent are stored in a computer is implementation-dependent. The common IEEE formats are described in detail later and elsewhere, but as an example, in the binary single-precision (32-bit) floating-point representation, formula_4, and so the significand is a string of 24 bits. For instance, the number π's first 33 bits are:

In this binary expansion, let us denote the positions from 0 (leftmost bit, or most significant bit) to 32 (rightmost bit). The 24-bit significand will stop at position 23, shown as the underlined bit above. The next bit, at position 24, is called the "round bit" or "rounding bit". It is used to round the 33-bit approximation to the nearest 24-bit number (there are specific rules for halfway values, which is not the case here). This bit, which is in this example, is added to the integer formed by the leftmost 24 bits, yielding:

When this is stored in memory using the IEEE 754 encoding, this becomes the significand . The significand is assumed to have a binary point to the right of the leftmost bit. So, the binary representation of π is calculated from left-to-right as follows:

where is the precision ( in this example), is the position of the bit of the significand from the left (starting at and finishing at here) and is the exponent ( in this example).

It can be required that the most significant digit of the significand of a non-zero number be non-zero (except when the corresponding exponent would be smaller than the minimum one). This process is called "normalization". For binary formats (which uses only the digits and ), this non-zero digit is necessarily . Therefore, it does not need to be represented in memory; allowing the format to have one more bit of precision. This rule is variously called the "leading bit convention", the "implicit bit convention", the "hidden bit convention", or the "assumed bit convention".

The floating-point representation is by far the most common way of representing in computers an approximation to real numbers. However, there are alternatives:

In 1914, Leonardo Torres y Quevedo designed an electro-mechanical version of Charles Babbage's Analytical Engine, and included floating-point arithmetic.
In 1938, Konrad Zuse of Berlin completed the Z1, the first binary, programmable mechanical computer; it uses a 24-bit binary floating-point number representation with a 7-bit signed exponent, a 17-bit significand (including one implicit bit), and a sign bit. The more reliable relay-based Z3, completed in 1941, has representations for both positive and negative infinities; in particular, it implements defined operations with infinity, such as formula_11, and it stops on undefined operations, such as formula_12.
Zuse also proposed, but did not complete, carefully rounded floating-point arithmetic that includes formula_13 and NaN representations, anticipating features of the IEEE Standard by four decades. In contrast, von Neumann recommended against floating-point numbers for the 1951 IAS machine, arguing that fixed-point arithmetic is preferable.

The first "commercial" computer with floating-point hardware was Zuse's Z4 computer, designed in 1942–1945. In 1946, Bell Laboratories introduced the Mark V, which implemented decimal floating-point numbers.

The Pilot ACE has binary floating-point arithmetic, and it became operational in 1950 at National Physical Laboratory, UK. Thirty-three were later sold commercially as the English Electric DEUCE. The arithmetic is actually implemented in software, but with a one megahertz clock rate, the speed of floating-point and fixed-point operations in this machine were initially faster than those of many competing computers.

The mass-produced IBM 704 followed in 1954; it introduced the use of a biased exponent. For many decades after that, floating-point hardware was typically an optional feature, and computers that had it were said to be "scientific computers", or to have "scientific computation" (SC) capability (see also Extensions for Scientific Computation (XSC)). It was not until the launch of the Intel i486 in 1989 that "general-purpose" personal computers had floating-point capability in hardware as a standard feature.

The UNIVAC 1100/2200 series, introduced in 1962, supported two floating-point representations:

The IBM 7094, also introduced in 1962, supports single-precision and double-precision representations, but with no relation to the UNIVAC's representations. Indeed, in 1964, IBM introduced hexadecimal floating-point representations in its System/360 mainframes; these same representations are still available for use in modern z/Architecture systems. However, in 1998, IBM included IEEE-compatible binary floating-point arithmetic to its mainframes; in 2005, IBM also added IEEE-compatible decimal floating-point arithmetic.

Initially, computers used many different representations for floating-point numbers. The lack of standardization at the mainframe level was an ongoing problem by the early 1970s for those writing and maintaining higher-level source code; these manufacturer floating-point standards differed in the word sizes, the representations, and the rounding behavior and general accuracy of operations. Floating-point compatibility across multiple computing systems was in desperate need of standardization by the early 1980s, leading to the creation of the IEEE 754 standard once the 32-bit (or 64-bit) word had become commonplace. This standard was significantly based on a proposal from Intel, which was designing the i8087 numerical coprocessor; Motorola, which was designing the 68000 around the same time, gave significant input as well.

In 1989, mathematician and computer scientist William Kahan was honored with the Turing Award for being the primary architect behind this proposal; he was aided by his student (Jerome Coonen) and a visiting professor (Harold Stone).

Among the x86 innovations are these:

A floating-point number consists of two fixed-point components, whose range depends exclusively on the number of bits or digits in their representation. Whereas components linearly depend on their range, the floating-point range linearly depends on the significand range and exponentially on the range of exponent component, which attaches outstandingly wider range to the number.

On a typical computer system, a "double-precision" (64-bit) binary floating-point number has a coefficient of 53 bits (including 1 implied bit), an exponent of 11 bits, and 1 sign bit. Since 2 = 1024, the complete range of the positive normal floating-point numbers in this format is from 2 ≈ 2 × 10 to approximately 2 ≈ 2 × 10.

The number of normalized floating-point numbers in a system ("B", "P", "L", "U") where


is formula_14.

There is a smallest positive normalized floating-point number,

which has a 1 as the leading digit and 0 for the remaining digits of the significand, and the smallest possible value for the exponent.

There is a largest floating-point number,

which has "B" − 1 as the value for each digit of the significand and the largest possible value for the exponent.

In addition, there are representable values strictly between −UFL and UFL. Namely, positive and negative zeros, as well as denormalized numbers.

The IEEE standardized the computer representation for binary floating-point numbers in IEEE 754 (a.k.a. IEC 60559) in 1985. This first standard is followed by almost all modern machines. It was revised in 2008. IBM mainframes support IBM's own hexadecimal floating point format and IEEE 754-2008 decimal floating point in addition to the IEEE 754 binary format. The Cray T90 series had an IEEE version, but the SV1 still uses Cray floating-point format.

The standard provides for many closely related formats, differing in only a few details. Five of these formats are called "basic formats" and others are termed "extended formats"; three of these are especially widely used in computer hardware and languages:

Increasing the precision of the floating point representation generally reduces the amount of accumulated round-off error caused by intermediate calculations.
Less common IEEE formats include:
Any integer with absolute value less than 2 can be exactly represented in the single precision format, and any integer with absolute value less than 2 can be exactly represented in the double precision format. Furthermore, a wide range of powers of 2 times such a number can be represented. These properties are sometimes used for purely integer data, to get 53-bit integers on platforms that have double precision floats but only 32-bit integers.

The standard specifies some special values, and their representation: positive infinity (+∞), negative infinity (−∞), a negative zero (−0) distinct from ordinary ("positive") zero, and "not a number" values (NaNs).

Comparison of floating-point numbers, as defined by the IEEE standard, is a bit different from usual integer comparison. Negative and positive zero compare equal, and every NaN compares unequal to every value, including itself. All values except NaN are strictly smaller than +∞ and strictly greater than −∞. Finite floating-point numbers are ordered in the same way as their values (in the set of real numbers).

Floating-point numbers are typically packed into a computer datum as the sign bit, the exponent field, and the significand or mantissa, from left to right. For the IEEE 754 binary formats (basic and extended) which have extant hardware implementations, they are apportioned as follows:

While the exponent can be positive or negative, in binary formats it is stored as an unsigned number that has a fixed "bias" added to it. Values of all 0s in this field are reserved for the zeros and subnormal numbers; values of all 1s are reserved for the infinities and NaNs. The exponent range for normalized numbers is [−126, 127] for single precision, [−1022, 1023] for double, or [−16382, 16383] for quad. Normalized numbers exclude subnormal values, zeros, infinities, and NaNs.

In the IEEE binary interchange formats the leading 1 bit of a normalized significand is not actually stored in the computer datum. It is called the "hidden" or "implicit" bit. Because of this, single precision format actually has a significand with 24 bits of precision, double precision format has 53, and quad has 113.

For example, it was shown above that π, rounded to 24 bits of precision, has:
The sum of the exponent bias (127) and the exponent (1) is 128, so this is represented in single precision format as

In the IEEE 754 standard, zero is signed, meaning that there exist both a "positive zero" (+0) and a "negative zero" (−0). In most run-time environments, positive zero is usually printed as "0" and the negative zero as "-0". The two values behave as equal in numerical comparisons, but some operations return different results for +0 and −0. For instance, 1/(−0) returns negative infinity, while 1/+0 returns positive infinity (so that the identity 1/(1/±∞) = ±∞ is maintained). Other common functions with a discontinuity at "x"=0 which might treat +0 and −0 differently include log("x"), signum("x"), and the principal square root of for any negative number "y". As with any approximation scheme, operations involving "negative zero" can occasionally cause confusion. For example, in IEEE 754, "x" = "y" does not always imply 1/"x" = 1/"y", as 0 = −0 but 1/0 ≠ 1/−0.

Subnormal values fill the underflow gap with values
where the absolute distance between them is the same as for
adjacent values just outside the underflow gap.
This is an improvement over the older practice to just have zero in the underflow gap,
and where underflowing results were replaced by zero (flush to zero).

Modern floating-point hardware usually handles subnormal values (as well as normal values),
and does not require software emulation for subnormals.

The infinities of the extended real number line can be represented in IEEE floating-point datatypes,
just like ordinary floating-point values like 1, 1.5, etc.
They are not error values in any way, though they are often (but not always, as it depends on the rounding) used as
replacement values when there is an overflow. Upon a divide-by-zero exception,
a positive or negative infinity is returned as an exact result. An infinity can also be introduced as
a numeral (like C's "INFINITY" macro, or "∞" if the programming language allows that syntax).

IEEE 754 requires infinities to be handled in a reasonable way, such as

IEEE 754 specifies a special value called "Not a Number" (NaN) to be returned as the result of certain "invalid" operations, such as 0/0, ∞×0, or sqrt(−1). In general, NaNs will be propagated i.e. most operations involving a NaN will result in a NaN, although functions that would give some defined result for any given floating-point value will do so for NaNs as well, e.g. NaN ^ 0 = 1. There are two kinds of NaNs: the default "quiet" NaNs and, optionally, "signaling" NaNs. A signaling NaN in any arithmetic operation (including numerical comparisons) will cause an "invalid operation" to be signaled.

The representation of NaNs specified by the standard has some unspecified bits that could be used to encode the type or source of error; but there is no standard for that encoding. In theory, signaling NaNs could be used by a runtime system to flag uninitialized variables, or extend the floating-point numbers with other special values without slowing down the computations with ordinary values, although such extensions are not common.

It is a common misconception that the more esoteric features of the IEEE 754 standard discussed here, such as extended formats, NaN, infinities, subnormals etc., are only of interest to numerical analysts, or for advanced numerical applications; in fact the opposite is true: these features are designed to give safe robust defaults for numerically unsophisticated programmers, in addition to supporting sophisticated numerical libraries by experts. The key designer of IEEE 754, William Kahan notes that it is incorrect to "... [deem] features of IEEE Standard 754 for Binary Floating-Point Arithmetic that ...[are] not appreciated to be features usable by none but numerical experts. The facts are quite the opposite. In 1977 those features were designed into the Intel 8087 to serve the widest possible market... Error-analysis tells us how to design floating-point arithmetic, like IEEE Standard 754, moderately tolerant of well-meaning ignorance among programmers".

By their nature, all numbers expressed in floating-point format are rational numbers with a terminating expansion in the relevant base (for example, a terminating decimal expansion in base-10, or a terminating binary expansion in base-2). Irrational numbers, such as π or √2, or non-terminating rational numbers, must be approximated. The number of digits (or bits) of precision also limits the set of rational numbers that can be represented exactly. For example, the number 123456789 cannot be exactly represented if only eight decimal digits of precision are available.

When a number is represented in some format (such as a character string) which is not a native floating-point representation supported in a computer implementation, then it will require a conversion before it can be used in that implementation. If the number can be represented exactly in the floating-point format then the conversion is exact. If there is not an exact representation then the conversion requires a choice of which floating-point number to use to represent the original value. The representation chosen will have a different value from the original, and the value thus adjusted is called the "rounded value".

Whether or not a rational number has a terminating expansion depends on the base. For example, in base-10 the number 1/2 has a terminating expansion (0.5) while the number 1/3 does not (0.333...). In base-2 only rationals with denominators that are powers of 2 (such as 1/2 or 3/16) are terminating. Any rational with a denominator that has a prime factor other than 2 will have an infinite binary expansion. This means that numbers which appear to be short and exact when written in decimal format may need to be approximated when converted to binary floating-point. For example, the decimal number 0.1 is not representable in binary floating-point of any finite precision; the exact binary representation would have a "1100" sequence continuing endlessly:
where, as previously, "s" is the significand and "e" is the exponent.

When rounded to 24 bits this becomes
which is actually 0.100000001490116119384765625 in decimal.
As a further example, the real number π, represented in binary as an infinite sequence of bits is
but is
when approximated by rounding to a precision of 24 bits.

In binary single-precision floating-point, this is represented as "s" = 1.10010010000111111011011 with "e" = 1.
This has a decimal value of
whereas a more accurate approximation of the true value of π is

The result of rounding differs from the true value by about 0.03 parts per million, and matches the decimal representation of π in the first 7 digits. The difference is the discretization error and is limited by the machine epsilon.

The arithmetical difference between two consecutive representable floating-point numbers which have the same exponent is called a unit in the last place (ULP). For example, if there is no representable number lying between the representable numbers 1.45a70c22 and 1.45a70c24, the ULP is 2×16, or 2. For numbers with a base-2 exponent part of 0, i.e. numbers with an absolute value higher than or equal to 1 but lower than 2, an ULP is exactly 2 or about 10 in single precision, and exactly 2 or about 10 in double precision. The mandated behavior of IEEE-compliant hardware is that the result be within one-half of a ULP.

Rounding is used when the exact result of a floating-point operation (or a conversion to floating-point format) would need more digits than there are digits in the significand. IEEE 754 requires "correct rounding": that is, the rounded result is as if infinitely precise arithmetic was used to compute the value and then rounded (although in implementation only three extra bits are needed to ensure this). There are several different rounding schemes (or "rounding modes"). Historically, truncation was the typical approach. Since the introduction of IEEE 754, the default method ("round to nearest, ties to even", sometimes called Banker's Rounding) is more commonly used. This method rounds the ideal (infinitely precise) result of an arithmetic operation to the nearest representable value, and gives that representation as the result. In the case of a tie, the value that would make the significand end in an even digit is chosen. The IEEE 754 standard requires the same rounding to be applied to all fundamental algebraic operations, including square root and conversions, when there is a numeric (non-NaN) result. It means that the results of IEEE 754 operations are completely determined in all bits of the result, except for the representation of NaNs. ("Library" functions such as cosine and log are not mandated.)

Alternative rounding options are also available. IEEE 754 specifies the following rounding modes:

Alternative modes are useful when the amount of error being introduced must be bounded. Applications that require a bounded error are multi-precision floating-point, and interval arithmetic.
The alternative rounding modes are also useful in diagnosing numerical instability: if the results of a subroutine vary substantially between rounding to + and − infinity then it is likely numerically unstable and affected by round-off error.

For ease of presentation and understanding, decimal radix with 7 digit precision will be used in the examples, as in the IEEE 754 "decimal32" format. The fundamental principles are the same in any radix or precision, except that normalization is optional (it does not affect the numerical value of the result). Here, "s" denotes the significand and "e" denotes the exponent.

A simple method to add floating-point numbers is to first represent them with the same exponent. In the example below, the second number is shifted right by three digits, and one then proceeds with the usual addition method:

In detail:

This is the true result, the exact sum of the operands. It will be rounded to seven digits and then normalized if necessary. The final result is

Note that the lowest three digits of the second operand (654) are essentially lost. This is round-off error. In extreme cases, the sum of two non-zero numbers may be equal to one of them:

In the above conceptual examples it would appear that a large number of extra digits would need to be provided by the adder to ensure correct rounding; however, for binary addition or subtraction using careful implementation techniques only two extra "guard" bits and one extra "sticky" bit need to be carried beyond the precision of the operands.

Another problem of loss of significance occurs when two nearly equal numbers are subtracted. In the following example "e" = 5; "s" = 1.234571 and "e" = 5; "s" = 1.234567 are representations of the rationals 123457.1467 and 123456.659.

The best representation of this difference is "e" = −1; "s" = 4.877000, which differs more than 20% from "e" = −1; "s" = 4.000000. In extreme cases, all significant digits of precision can be lost (although gradual underflow ensures that the result will not be zero unless the two operands were equal). This "cancellation" illustrates the danger in assuming that all of the digits of a computed result are meaningful. Dealing with the consequences of these errors is a topic in numerical analysis; see also Accuracy problems.

To multiply, the significands are multiplied while the exponents are added, and the result is rounded and normalized.

Similarly, division is accomplished by subtracting the divisor's exponent from the dividend's exponent, and dividing the dividend's significand by the divisor's significand.

There are no cancellation or absorption problems with multiplication or division, though small errors may accumulate as operations are performed in succession. In practice, the way these operations are carried out in digital logic can be quite complex (see Booth's multiplication algorithm and Division algorithm).
For a fast, simple method, see the Horner method.

Floating-point computation in a computer can run into three kinds of problems:

Prior to the IEEE standard, such conditions usually caused the program to terminate, or triggered some kind
of trap that the programmer might be able to catch. How this worked was system-dependent,
meaning that floating-point programs were not portable. (Note that the term "exception" as used in IEEE 754 is a general term meaning an exceptional condition, which is not necessarily an error, and is a different usage to that typically defined in programming languages such as a C++ or Java, in which an "exception" is an alternative flow of control, closer to what is termed a "trap" in IEEE 754 terminology).

Here, the required default method of handling exceptions according to IEEE 754 is discussed (the IEEE 754 optional trapping and other "alternate exception handling" modes are not discussed). Arithmetic exceptions are (by default) required to be recorded in "sticky" status flag bits. That they are "sticky" means that they are not reset by the next (arithmetic) operation, but stay set until explicitly reset. The use of "sticky" flags thus allows for testing of exceptional conditions to be delayed until after a full floating-point expression or subroutine: without them exceptional conditions that could not be otherwise ignored would require explicit testing immediately after every floating-point operation. By default, an operation always returns a result according to specification without interrupting computation. For instance, 1/0 returns +∞, while also setting the divide-by-zero flag bit (this default of ∞ is designed so as to often return a finite result when used in subsequent operations and so be safely ignored).

The original IEEE 754 standard, however, failed to recommend operations to handle such sets of arithmetic exception flag bits. So while these were implemented in hardware, initially programming language implementations typically did not provide a means to access them (apart from assembler). Over time some programming language standards (e.g., C99/C11 and Fortran) have been updated to specify methods to access and change status flag bits. The 2008 version of the IEEE 754 standard now specifies a few operations for accessing and handling the arithmetic flag bits. The programming model is based on a single thread of execution and use of them by multiple threads has to be handled by a means outside of the standard (e.g. C11 specifies that the flags have thread-local storage).

IEEE 754 specifies five arithmetic exceptions that are to be recorded in the status flags ("sticky bits"):
The default return value for each of the exceptions is designed to give the correct result in the majority of cases such that the exceptions can be ignored in the majority of codes. "inexact" returns a correctly rounded result, and "underflow" returns a denormalized small value and so can almost always be ignored. "divide-by-zero" returns infinity exactly, which will typically then divide a finite number and so give zero, or else will give an "invalid" exception subsequently if not, and so can also typically be ignored. For example, the effective resistance of n resistors in parallel (see fig. 1) is given by formula_17. If a short-circuit develops with formula_18 set to 0, formula_19 will return +infinity which will give a final formula_20 of 0, as expected (see the continued fraction example of for another example).
"Overflow" and "invalid" exceptions can typically not be ignored, but do not necessarily represent errors: for example, a root-finding routine, as part of its normal operation, may evaluate a passed-in function at values outside of its domain, returning NaN and an "invalid" exception flag to be ignored until finding a useful start point.

The fact that floating-point numbers cannot precisely represent all real numbers, and that floating-point operations cannot precisely represent true arithmetic operations, leads to many surprising situations. This is related to the finite precision with which computers generally represent numbers.

For example, the non-representability of 0.1 and 0.01 (in binary) means that the result of attempting to square 0.1 is neither 0.01 nor the representable number closest to it. In 24-bit (single precision) representation, 0.1 (decimal) was given previously as "e" = −4; "s" = 110011001100110011001101, which is
Squaring this number gives
Squaring it with single-precision floating-point hardware (with rounding) gives
But the representable number closest to 0.01 is

Also, the non-representability of π (and π/2) means that an attempted computation of tan(π/2) will not yield a result of infinity, nor will it even overflow. It is simply not possible for standard floating-point hardware to attempt to compute tan(π/2), because π/2 cannot be represented exactly. This computation in C:

/* Enough digits to be sure we get the correct approximation. */
double pi = 3.1415926535897932384626433832795;
double z = tan(pi/2.0);

will give a result of 16331239353195370.0. In single precision (using the tanf function), the result will be −22877332.0.

By the same token, an attempted computation of sin(π) will not yield zero. The result will be (approximately) 0.1225 in double precision, or −0.8742 in single precision.

While floating-point addition and multiplication are both commutative ("a" + "b" = "b" + "a" and "a" × "b" = "b" × "a"), they are not necessarily associative. That is, ("a" + "b") + "c" is not necessarily equal to "a" + ("b" + "c"). Using 7-digit significand decimal arithmetic:

They are also not necessarily distributive. That is, ("a" + "b") × "c" may not be the same as "a" × "c" + "b" × "c":

In addition to loss of significance, inability to represent numbers such as π and 0.1 exactly, and other slight inaccuracies, the following phenomena may occur:


"Machine precision" is a quantity that characterizes the accuracy of a floating-point system, and is used in backward error analysis of floating-point algorithms. It is also known as unit roundoff or "machine epsilon". Usually denoted Ε, its value depends on the particular rounding being used.

With rounding to zero,
whereas rounding to nearest,

This is important since it bounds the "relative error" in representing any non-zero real number x within the normalized range of a floating-point system:

Backward error analysis, the theory of which was developed and popularized by James H. Wilkinson, can be used to establish that an algorithm implementing a numerical function is numerically stable. The basic approach is to show that although the calculated result, due to roundoff errors, will not be exactly correct, it is the exact solution to a nearby problem with slightly perturbed input data. If the perturbation required is small, on the order of the uncertainty in the input data, then the results are in some sense as accurate as the data "deserves". The algorithm is then defined as "backward stable". Stability is a measure of the sensitivity to rounding errors of a given numerical procedure; by contrast, the condition number of a function for a given problem indicates the inherent sensitivity of the function to small perturbations in its input and is independent of the implementation used to solve the problem.

As a trivial example, consider a simple expression giving the inner product of (length two) vectors formula_25 and formula_26, then
and so
which is the sum of two slightly perturbed (on the order of Ε) input data, and so is backward stable. For more realistic examples in numerical linear algebra, see Higham 2002 and other references below.

Although, as noted previously, individual arithmetic operations of IEEE 754 are guaranteed accurate to within half a ULP, more complicated formulae can suffer from larger errors due to round-off. The loss of accuracy can be substantial if a problem or its data are ill-conditioned, meaning that the correct result is hypersensitive to tiny perturbations in its data. However, even functions that are well-conditioned can suffer from large loss of accuracy if an algorithm numerically unstable for that data is used: apparently equivalent formulations of expressions in a programming language can differ markedly in their numerical stability. One approach to remove the risk of such loss of accuracy is the design and analysis of numerically stable algorithms, which is an aim of the branch of mathematics known as numerical analysis. Another approach that can protect against the risk of numerical instabilities is the computation of intermediate (scratch) values in an algorithm at a higher precision than the final result requires, which can remove, or reduce by orders of magnitude, such risk: IEEE 754 quadruple precision and extended precision are designed for this purpose when computing at double precision.

For example, the following algorithm is a direct implementation to compute the function A(x) = (x−1) / (exp(x−1) − 1) which is well-conditioned at 1.0, however it can be shown to be numerically unstable and lose up to half the significant digits carried by the arithmetic when computed near 1.0.

double A(double X)

If, however, intermediate computations are all performed in extended precision (e.g. by setting line [1] to C99 long double), then up to full precision in the final double result can be maintained. Alternatively, a numerical analysis of the algorithm reveals that if the following non-obvious change to line [2] is made:

then the algorithm becomes numerically stable and can compute to full double precision.

To maintain the properties of such carefully constructed numerically stable programs, careful handling by the compiler is required. Certain "optimizations" that compilers might make (for example, reordering operations) can work against the goals of well-behaved software. There is some controversy about the failings of compilers and language designs in this area: C99 is an example of a language where such optimizations are carefully specified so as to maintain numerical precision. See the external references at the bottom of this article.

A detailed treatment of the techniques for writing high-quality floating-point software is beyond the scope of this article, and the reader is referred to, and the other references at the bottom of this article. Kahan suggests several rules of thumb that can substantially decrease by orders of magnitude the risk of numerical anomalies, in addition to, or in lieu of, a more careful numerical analysis. These include: as noted above, computing all expressions and intermediate results in the highest precision supported in hardware (a common rule of thumb is to carry twice the precision of the desired result i.e. compute in double precision for a final single precision result, or in double extended or quad precision for up to double precision results); and rounding input data and results to only the precision required and supported by the input data (carrying excess precision in the final result beyond that required and supported by the input data can be misleading, increases storage cost and decreases speed, and the excess bits can affect convergence of numerical procedures: notably, the first form of the iterative example given below converges correctly when using this rule of thumb). Brief descriptions of several additional issues and techniques follow.

As decimal fractions can often not be exactly represented in binary floating-point, such arithmetic is at its best when it is simply being used to measure real-world quantities over a wide range of scales (such as the orbital period of a moon around Saturn or the mass of a proton), and at its worst when it is expected to model the interactions of quantities expressed as decimal strings that are expected to be exact. An example of the latter case is financial calculations. For this reason, financial software tends not to use a binary floating-point number representation. The "decimal" data type of the C# and Python programming languages, and the decimal formats of the IEEE 754-2008 standard, are designed to avoid the problems of binary floating-point representations when applied to human-entered exact decimal values, and make the arithmetic always behave as expected when numbers are printed in decimal.

Expectations from mathematics may not be realized in the field of floating-point computation. For example, it is known that formula_39, and that formula_40, however these facts cannot be relied on when the quantities involved are the result of floating-point computation.

The use of the equality test (codice_2) requires care when dealing with floating-point numbers. Even simple expressions like codice_3 will, on most computers, fail to be true (in IEEE 754 double precision, for example, codice_4 is approximately equal to -4.44089209850063e-16). Consequently, such tests are sometimes replaced with "fuzzy" comparisons (codice_5, where epsilon is sufficiently small and tailored to the application, such as 1.0E−13). The wisdom of doing this varies greatly, and can require numerical analysis to bound epsilon. Values derived from the primary data representation and their comparisons should be performed in a wider, extended, precision to minimize the risk of such inconsistencies due to round-off errors. It is often better to organize the code in such a way that such tests are unnecessary. For example, in computational geometry, exact tests of whether a point lies off or on a line or plane defined by other points can be performed using adaptive precision or exact arithmetic methods.

Small errors in floating-point arithmetic can grow when mathematical algorithms perform operations an enormous number of times. A few examples are matrix inversion, eigenvector computation, and differential equation solving. These algorithms must be very carefully designed, using numerical approaches such as Iterative refinement, if they are to work well.

Summation of a vector of floating-point values is a basic algorithm in scientific computing, and so an awareness of when loss of significance can occur is essential. For example, if one is adding a very large number of numbers, the individual addends are very small compared with the sum. This can lead to loss of significance. A typical addition would then be something like
The low 3 digits of the addends are effectively lost. Suppose, for example, that one needs to add many numbers, all approximately equal to 3. After 1000 of them have been added, the running sum is about 3000; the lost digits are not regained. The Kahan summation algorithm may be used to reduce the errors.

Round-off error can affect the convergence and accuracy of iterative numerical procedures. As an example, Archimedes approximated π by calculating the perimeters of polygons inscribing and circumscribing a circle, starting with hexagons, and successively doubling the number of sides. As noted above, computations may be rearranged in a way that is mathematically equivalent but less prone to error (numerical analysis).
Two forms of the recurrence formula for the circumscribed polygon are:

Here is a computation using IEEE "double" (a significand with 53 bits of precision) arithmetic:

While the two forms of the recurrence formula are clearly mathematically equivalent, the first subtracts 1 from a number extremely close to 1, leading to an increasingly problematic loss of significant digits. As the recurrence is applied repeatedly, the accuracy improves at first, but then it deteriorates. It never gets better than about 8 digits, even though 53-bit arithmetic should be capable of about 16 digits of precision. When the second form of the recurrence is used, the value converges to 15 digits of precision.




</doc>
<doc id="11378" url="https://en.wikipedia.org/wiki?curid=11378" title="First Epistle to the Corinthians">
First Epistle to the Corinthians

The First Epistle to the Corinthians (), usually referred to as First Corinthians or 1 Corinthians is a Pauline epistle of the New Testament of the Christian Bible. The epistle is attributed to Paul the Apostle and a co-author named Sosthenes, and is addressed to the Christian church in Corinth. Scholars believe that Sosthenes was the amanuensis who wrote down the text of the letter at Paul's direction. Called "a masterpiece of pastoral theology", it addresses various issues that had arisen in the Christian community at Corinth.

There is a consensus among historians and Christian theologians that Paul is the author of the First Epistle to the Corinthians (c. AD 53–54). The letter is quoted or mentioned by the earliest of sources, and is included in every ancient canon, including that of Marcion of Sinope. Some scholars point to the epistle's potentially embarrassing references to the existence of sexual immorality in the church as strengthening the case for the authenticity of the letter.

However, the epistle does contain a passage that is widely believed to have been interpolated into the text by a later scribe:
Part of the reason for suspecting that this passage is an interpolation is that in some manuscripts, it is placed at the end of Chapter 14, instead of at its canonical location. This kind of variability is generally considered by textual critics to be a sign that a note, initially placed in the margins of the document, has been copied into the body of the text by a scribe. The passage also seems to contradict 11:5, where women are described as praying and prophesying in church.

Furthermore, some scholars believe that the passage constitutes a separate letter fragment or scribal interpolation because it equates the consumption of meat sacrificed to idols with idolatry, while Paul seems to be more lenient on this issue in and . Such views are rejected by other scholars who give arguments for the unity of .

About the year AD 50, towards the end of his second missionary journey, Paul founded the church in Corinth, before moving on to Ephesus, a city on the west coast of today's Turkey, about 180 miles by sea from Corinth. From there he traveled to Caesarea, and Antioch. Paul returned to Ephesus on his third missionary journey and spent approximately three years there (, , ). It was while staying in Ephesus that he received disconcerting news of the community in Corinth regarding jealousies, rivalry, and immoral behavior. It also appears that based on a letter the Corinthians sent Paul (e.g. ), the congregation was requesting clarification on a number of matters, such as marriage and the consumption of meat previously offered to idols.

By comparing Acts of the Apostles and mentions of Ephesus in the Corinthian correspondence, scholars suggest that the letter was written during Paul's stay in Ephesus, which is usually dated as being in the range of AD 53–57.

Anthony C. Thiselton suggests that it is possible that I Corinthians was written during Paul's first (brief) stay in Ephesus, at the end of his Second Journey, usually dated to early AD 54. However, it is more likely that it was written during his extended stay in Ephesus, where he refers to sending Timothy to them (, ).

The epistle may be divided into seven parts:


 Some time before 2 Corinthians was written, Paul paid them a second visit (; ) to check some rising disorder (; ), and wrote them a letter, now lost (). They had also been visited by Apollos (), perhaps by Peter (), and by some Jewish Christians who brought with them letters of commendation from Jerusalem (; ; ; ).

Paul wrote this letter to correct what he saw as erroneous views in the Corinthian church. Several sources informed Paul of conflicts within the church at Corinth: Apollos (Acts 19:1), a letter from the Corinthians, the "household of Chloe", and finally Stephanas and his two friends who had visited Paul (1:11; 16:17). Paul then wrote this letter to the Corinthians, urging uniformity of belief ("that ye all speak the same thing and that there be no divisions among you", 1:10) and expounding Christian doctrine. Titus and a brother whose name is not given were probably the bearers of the letter to the church at Corinth (2 Corinthians 2:13; 8:6, 16–18).

In general, divisions within the church at Corinth seem to be a problem, and Paul makes it a point to mention these conflicts in the beginning. Specifically, pagan roots still hold sway within their community. Paul wants to bring them back to what he sees as correct doctrine, stating that God has given him the opportunity to be a "skilled master builder" to lay the foundation and let others build upon it (1 Cor 3:10).

Later, Paul wrote about immorality in Corinth by discussing an immoral brother, how to resolve personal disputes, and sexual purity. Regarding marriage, Paul states that it is better for Christians to remain unmarried, but that if they lacked self-control, it is better to marry than "burn" (πυροῦσθαι) which Christians have traditionally thought meant to burn with sinful desires. The Epistle may include marriage as an apostolic practice in 1 Corinthians 9:5, "Do we not have the right to be accompanied by a believing wife, as do the other apostles and the brothers of the Lord and Cephas (Peter)?" (In the last case, the letter concurs with Matthew 8:14, which mentions Peter having a mother-in-law and thus, by interpolation, a wife.) However, the Greek word for "wife" is the same word for "woman". The Early Church Fathers including Tertullian, Jerome, and Augustine state the Greek word is ambiguous and the women in 1 Corinthians 9:5 were women ministering to the Apostles as women ministered to Christ (cf Matthew 27:55, Luke 8:1–3), and were not wives, and assert they left their "offices of marriage" to follow Christ.

Paul also argues that married people must please their spouses, just as every Christian must please God. The letter is also notable for mentioning the role of women in churches, that for instance they must remain silent (1 Cor. 14:34–35), and yet they have a role of prophecy and apparently speaking tongues in churches (11:2–16). If 14:34–35 is not an interpolation, certain scholars resolve the tension between these texts by positing that wives were either contesting their husband's inspired speeches at church, or the wives/women were chatting and asking questions in a disorderly manner when others were giving inspired utterances. Their silence was unique to the particular situation in the Corinthian gatherings at that time, and on this reading, Paul did not intend his words to be universalized for all women of all churches of all eras. After discussing his views on worshipping idols, Paul finally ends with his views on resurrection. He states that Christ died for our sins, and was buried, and rose on the third day according to the scriptures (1 Cor. 15:3). Paul then asks: "Now if Christ is preached as raised from the dead, how can some of you say that there is no resurrection of the dead?" (1 Cor. 15:12) and addresses the question of resurrection.

Throughout the letter, Paul presents issues that are troubling the community in Corinth and offers ways to fix them. Paul states that this letter is to "admonish" them as beloved children. They are expected to become imitators of Jesus and follow the ways in Christ as he, Paul, teaches in all his churches (1 Cor. 4:14–16).

This epistle contains some well-known phrases, including: "all things to all men" (), "through a glass, darkly" (), and "When I was a child, I spoke as a child, I understood as a child, I thought as a child" ().

St. John Chrysostom, Doctor of the Church, wrote a commentary on 1 Corinthians, formed by 44 homilies.





</doc>
<doc id="11379" url="https://en.wikipedia.org/wiki?curid=11379" title="List of Scots">
List of Scots

List of Scots is an incomplete list of notable people from Scotland.



















</doc>
<doc id="11380" url="https://en.wikipedia.org/wiki?curid=11380" title="List of South Africans">
List of South Africans

This is a list of notable South Africans who are the subjects of Wikipedia articles.




Also see: Prelates, clerics and evangelists




See also: South African poets and Afrikaans language poets


















See also: Dutch Cape governors, British Cape governors, Natal governors and Governors-General





See also: Gcaleka rulers, <br>,<br> Xhosa Chiefs,<br> Zulus









</doc>
<doc id="11382" url="https://en.wikipedia.org/wiki?curid=11382" title="File manager">
File manager

A file manager or file browser is a computer program that provides a user interface to manage files and folders. The most common operations performed on files or groups of files include creating, opening (e.g. viewing, playing, editing or printing), renaming, moving or copying, deleting and searching for files, as well as modifying file attributes, properties and file permissions. Folders and files may be displayed in a hierarchical tree based on their directory structure. Some file managers contain features inspired by web browsers, including forward and back navigational buttons.

Some file managers provide network connectivity via protocols, such as FTP, HTTP, NFS, SMB or WebDAV. This is achieved by allowing the user to browse for a file server (connecting and accessing the server's file system like a local file system) or by providing its own full client implementations for file server protocols.

A term that predates the usage of "file manager" is "directory editor". An early directory editor, DIRED, was developed circa 1974 at the Stanford Artificial Intelligence Laboratory by Stan Kugell.

A directory editor was written for EXEC 8 at the University of Maryland, and was available to other users at that time. The term was used by other developers, including Jay Lepreau, who wrote the dired program in 1980, which ran on BSD. This was in turn inspired by an older program with the same name running on TOPS-20. Dired inspired other programs, including dired, the editor script (for emacs and similar editors), and ded.
"File-list" file managers are lesser known and older than orthodox file managers.

One such file manager is flist, which was introduced sometime before 1980 on the Conversational Monitor System.
This is a variant of fulist, which originated before late 1978, according to comments by its author, Theo Alkema.

The flist program provided a list of files in the user's minidisk, and allowed sorting by any file attribute. The file attributes could be passed to scripts or function-key definitions, making it simple to use flist as part of CMS EXEC, EXEC 2 or XEDIT scripts.

This program ran only on IBM VM/SP CMS, but was the inspiration for other programs, including filelist (a script run via the Xedit editor), and programs running on other operating systems, including a program also called flist, which ran on OpenVMS, and fulist (from the name of the corresponding internal IBM program), which runs on Unix.

Orthodox file managers (sometimes abbreviated to "OFM") or command-based file managers are text-menu based file managers, that commonly have three windows (two panels and one command line window). Orthodox file managers are one of the longest running families of file managers, preceding graphical user interface-based types. Developers create applications that duplicate and extend the manager that was introduced by PathMinder and John Socha's famous Norton Commander for DOS. The concept dates to the mid-1980s—PathMinder was released in 1984, and Norton Commander version 1.0 was released in 1986. Despite the age of this concept, file managers based on Norton Commander are actively developed, and dozens of implementations exist for DOS, Unix, and Microsoft Windows. Nikolai Bezroukov publishes his own set of criteria for an OFM standard (version 1.2 dated June 1997).

An orthodox file manager typically has three windows. Two of the windows are called panels and are positioned symmetrically at the top of the screen. The third is the command line, which is essentially a minimized command (shell) window that can be expanded to full screen. Only one of the panels is active at a given time. The active panel contains the "file cursor". Panels are resizable and can be hidden. Files in the active panel serve as the source of file operations performed by the manager. For example, files can be copied or moved from the active panel to the location represented in the passive panel. This scheme is most effective for systems in which the keyboard is the primary or sole input device. The active panel shows information about the current working directory and the files that it contains. The passive (inactive) panel shows the content of the same or another directory (the default target for file operations). Users may customize the display of columns that show relevant file information. The active panel and passive panel can be switched (often by pressing the tab key).

The following features describe the class of orthodox file managers.

Other common features include:

The introduction of tabbed panels in some file managers (for example Total Commander) made it possible to manipulate more than one active and passive directory at a time.

Orthodox file managers are among the most portable file managers. Examples are available on almost any platform, with both command-line and graphical interfaces. This is unusual among command line managers in that something purporting to be a standard for the interface is published. They are also actively supported by developers. This makes it possible to do the same work on different platforms without much relearning of the interface.

Sometimes they are called dual-pane managers, a term that is typically used for programs such as the Windows File Explorer (see below). But they have three panes including a command line pane below (or hidden behind) two symmetric panes. Furthermore, most of these programs allow using just one of the two larger panes with the second hidden. Some also add an item to the Context Menu in Windows to "Open two Explorers, side by side".

Notable ones include:

A navigational file manager is a newer type of file manager. Since the advent of GUIs, it has become the dominant type of file manager for desktop computers.

Typically, it has two panes, with the filesystem tree in the left pane and the contents of the current directory in the right pane. For macOS, the Miller columns view in Finder (originating in NeXTStep) is a variation on the navigational file manager theme.

The interface in a navigational file manager often resembles a web browser, complete with "back" and "forward" buttons, and often "reload" buttons. Most also contain an address bar into which the file or directory path (or URI) can be typed.

Most navigational file managers have two panes, the left pane being a tree view of the filesystem. This means that unlike orthodox file managers, the two panes are asymmetrical in their content and use.

Selecting a directory in the Navigation pane on the left designates it as the current directory, displaying its contents in the Contents pane on the right. However, expanding (+) or collapsing (-) a portion of the tree without selecting a directory will not alter the contents of the right pane. The exception to this behavior applies when collapsing a parent of the current directory, in which case the selection is refocused on the collapsed parent directory, thus altering the list in the Contents pane.

The process of moving from one location to another need not open a new window. Several instances of the file manager can be opened simultaneously and communicate with each other via drag-and-drop and clipboard operations, so it is possible to view several directories simultaneously and perform cut-and paste operations between instances.

File operations are based on drag-and-drop and editor metaphors: users can select and copy files or directories onto the clipboard and then paste them in a different place in the filesystem or even in a different instance of the file manager.

Notable examples of navigational file managers include:

Spatial file managers use a spatial metaphor to represent files and directories as if they were actual physical objects. A spatial file manager imitates the way people interact with physical objects.

Some ideas behind the concept of a spatial file manager are:


As in navigational file managers, when a directory is opened, the icon representing the directory changes—perhaps from an image showing a closed drawer to an opened one, perhaps the directory's icon turns into a silhouette filled with a pattern—and a new window is opened to represent that directory.

Examples of file managers that use a spatial metaphor to some extent include:

Dysfunctional spatial file managers:

Some projects have attempted to implement a three-dimensional method of displaying files and directory structures. Three-dimensional file browsing has not become popular; the exact implementation tends to differ between projects, and there are no common standards to follow.

Examples of three-dimensional file managers include:

Web-based file managers are typically scripts written in either PHP, Ajax, Perl, ASP or another server-side language. When installed on a local server or on a remote server, they allow files and directories located there to be managed and edited, using a web browser, without the need for FTP Access.

More advanced, and usually commercially distributed, web-based file management scripts allow the administrator of the file manager to configure secure, individual user accounts, each with individual account permissions. Authorized users have access to documents stored on the server or in their individual user directories anytime, from anywhere, via a web browser.

A web-based file manager can serve as an organization's digital repository. For example, documents, digital media, publishing layouts, and presentations can be stored, managed, and shared between customers, suppliers, and remote workers, or just internally.

Web-based file managers are becoming increasingly popular due to the rise in popularity of dynamic web content management systems (CMS) and the need for non-technical website moderators to manage media on their websites powered by these platforms.

An example is net2ftp, a PHP- and JavaScript-based FTP client.




</doc>
<doc id="11385" url="https://en.wikipedia.org/wiki?curid=11385" title="File viewer">
File viewer

A file viewer is an application software that presents the data stored in a computer file in a human-friendly form. The file contents are generally displayed on the screen, or they may be printed. Also, they may be read aloud using speech synthesis.

File viewers do not edit files, yet it is common for them to be able to export data in a different file format, or to copy information from the viewed to the system-wide clipboard. A file viewer is limited-functionality software in the sense that it does not have a capability to create a file, or modify the content of an existing one. Instead, it is used only to display or print the content.

File viewers have to have sufficient knowledge about the file format to be viewed in order to handle different byte orders, code pages or newline styles.

Some file viewer may be classified as filters that translate binary files into plain text (one example antiword). However, depending on the competence of the translating routines, some information may be lost.

Image viewers display graphics files onscreen. Most viewers are capable of reading multiple graphics file formats but some such as JPEGview are dedicated to a single format. Common image viewer features include thumbnail preview and creation, and image zooming.

For more complex or proprietary file formats, file viewers are usually provided by the same companies that make the editing software using those formats. Viewers are usually distributed free of charge, while editors have to be bought. For example, the full version of Adobe Acrobat can be used to create content for most computer platforms. To ensure that people can access the documents created with Adobe Acrobat, the software publisher created a viewer program, the Acrobat Reader, and made it available for free. Microsoft also makes viewers for Word and PowerPoint documents freely available. These viewer applications allow the file format to be readable on all supported operating-systems, free of charge, making the commercial product a more attractive solution.

A web browser is a type of file viewer, which renders HTML markup into a human-friendly presentation. Although HTML is stored in plain text files, viewing an HTML file in a browser and in a text editor produces significantly different results. Web browsers may also be used to view image and multimedia files.

There are also types of data that are not intended for static display — these incorporate the time dimension. Viewers for such formats are named players. But the essence is the same — presenting file contents in human-friendly form (i.e. displaying video on the screen as intended, or playing sound through loudspeakers). And the same consideration of different file formats is present.








</doc>
<doc id="11387" url="https://en.wikipedia.org/wiki?curid=11387" title="First Epistle of Peter">
First Epistle of Peter

The First Epistle of Peter, usually referred to simply as First Peter and often written 1 Peter, is a book of the New Testament. The author presents himself as Peter the Apostle, and, following Roman Catholic tradition, the epistle has been held to have been written during his time as Bishop of Rome or Bishop of Antioch, though neither title is used in the epistle. The text of the letter states that it was written from Babylon. The letter is addressed to various churches in Asia Minor suffering religious persecution.

The authorship of 1 Peter has traditionally been attributed to the Apostle Peter because it bears his name and identifies him as its author (1:1). Although the text identifies Peter as its author, the language, dating, style, and structure of this letter have led many scholars to conclude that it is pseudonymous. Many scholars argue that Peter was not the author of the letter because its writer appears to have had a formal education in rhetoric and philosophy, and an advanced knowledge of the Greek language, none of which would be usual for a Galilean fisherman.

Graham Stanton rejects Petrine authorship because 1 Peter was most likely written during the reign of Domitian in AD 81, which is when he believes widespread Christian persecution began, which is long after the death of Peter. However, current scholarship has abandoned the persecution argument because the described persecution within the work does not necessitate a time period outside of the period of Peter. Other scholars doubt Petrine authorship because they are convinced that 1 Peter is dependent on the Pauline epistles and thus was written after Paul the Apostle’s ministry because it shares many of the same motifs espoused in Ephesians, Colossians, and the Pastoral Epistles. Others argue that it makes little sense to ascribe the work to Peter when it could have been ascribed to Paul. Alternatively, one theory supporting legitimate Petrine authorship of 1 Peter is the "secretarial hypothesis", which suggests that 1 Peter was dictated by Peter and was written in Greek by his secretary, Silvanus (5:12). John Elliot disagrees, suggesting that the notion of Silvanus as secretary or author or drafter of 1 Peter introduces more problems than it solves because the Greek rendition of 5:12 suggests that Silvanus was not the secretary, but the courier/bearer of 1 Peter, and some see Mark as a contributive amanuensis in the composition and writing of the work. On the one hand, some scholars such as Bart D. Ehrman are convinced that the language, dating, literary style, and structure of this text makes it implausible to conclude that 1 Peter was written by Peter; according to these scholars, it is more likely that 1 Peter is a pseudonymous letter, written later by one of the disciples of Peter in his honor. On the other hand, some scholars argue that there is enough evidence to conclude that Peter did, in fact, write 1 Peter. For instance, there are similarities between 1 Peter and Peter's speeches in the Biblical book of Acts, and early attestation of Peter's authorship is found in 2 Peter (AD 60–160) and the letters of Clement (AD 70-140), all supporting genuine Petrine origin. Ultimately, the authorship of 1 Peter remains contested.

1 Peter is addressed to the “elect resident aliens” scattered throughout Pontus, Galatia, Cappadocia, Asia, and Bithynia. The five areas listed in 1:1 as the geographical location of the first readers were Roman provinces in Asia Minor. The order in which the provinces are listed may reflect the route to be taken by the messenger who delivered the circular letter. The recipients of this letter are referred to in 1:1 as “exiles of the Dispersion.” In 1:17, they are urged to “live in reverent fear during the time of your exile". The social makeup of the addressees of 1 Peter is debatable because some scholars interpret “strangers” (1:1) as Christians longing for their home in heaven, some interpret it as literal “strangers”, or as an Old Testament adaptation applied to Christian believers.

While the new Christians have encountered oppression and hostility from locals, Peter advises them to maintain loyalty to both their religion and the Roman Empire (1 Peter 2:17).

The author counsels (1) to steadfastness and perseverance under persecution (1–2:10); (2) to the practical duties of a holy life (2:11–3:13); (3) he adduces the example of Christ and other motives to patience and holiness (3:14–4:19); and (4) concludes with counsels to pastors and people (chap. 5).

David Bartlett lists the following outline to structure the literary divisions of 1 Peter.

The Petrine author writes of his addressees undergoing “various trials” (1 Peter 1:6), being “tested by fire” (which isn't a physical reference but a metaphor for a spiritual warfare) (1:7), maligned “as evildoers” (2:12) and suffering “for doing good” (3:17). Based on such internal evidence, biblical scholar John Elliott summarizes the addressees’ situation as one marked by undeserved suffering. Verse (), "Spirits in prison", is a continuing theme in Christianity, and one considered by most theologians to be enigmatic and difficult to interpret.

A number of verses in the epistle contain possible clues about the reasons Christians experienced opposition. Exhortations to live blameless lives (2:15; 3:9, 13, 16) may suggest that the Christian addressees were accused of immoral behavior, and exhortations to civil obedience (2:13–17) perhaps imply that they were accused of disloyalty to governing powers.

However, scholars differ on the nature of persecution inflicted on the addressees of 1 Peter. Some read the epistle to be describing persecution in the form of social discrimination, while some read them to be official persecution.

Some scholars believe that the sufferings the epistle's addressees were experiencing were social in nature, specifically in the form of verbal derision. Internal evidence for this includes the use of words like “malign” (2:12; 3:16), and “reviled” (4:14). Biblical scholar John Elliott notes that the author explicitly urges the addressees to respect authority (2:13) and even honor the emperor (2:17), strongly suggesting that they were unlikely to be suffering from official Roman persecution. It is significant to him that the author notes that “your brothers and sisters in all the world are undergoing the same kinds of suffering” (5:9), indicating suffering that is worldwide in scope. Elliott sees this as grounds to reject the idea that the epistle refers to official persecution, because the first worldwide persecution of Christians officially meted by Rome did not occur until the persecution initiated by Decius in AD 250.

On the other hand, scholars who support the official persecution theory take the exhortation to defend one's faith (3:15) as a reference to official court proceedings. They believe that these persecutions involved court trials before Roman authorities, and even executions.

One common supposition is that 1 Peter was written during the reign of Domitian (AD 81–96). Domitian's aggressive claim to divinity would have been rejected and resisted by Christians. Biblical scholar Paul Achtemeier believes that persecution of Christians by Domitian would have been in character, but points out that there is no evidence of official policy targeted specifically at Christians. If Christians were persecuted, it is likely to have been part of Domitian’s larger policy suppressing all opposition to his self-proclaimed divinity. There are other scholars who explicitly dispute the idea of contextualizing 1 Peter within Domitian’s reign. Duane Warden believes that Domitian’s unpopularity even among Romans renders it highly unlikely that his actions would have great influence in the provinces, especially those under the direct supervision of the senate such as Asia (one of the provinces 1 Peter is addressed to).

Also often advanced as a possible context for 1 Peter is the trials and executions of Christians in the Roman province of Bithynia-Pontus under Pliny the Younger. Scholars who support this theory believe that a famous letter from Pliny to Emperor Trajan concerning the delation of Christians reflects the situation faced by the addressees of this epistle. In Pliny's letter, written in AD 112, he asks Trajan if the accused Christians brought before him should be punished based on the name ‘Christian’ alone, or for crimes associated with the name. For biblical scholar John Knox, the use of the word “name” in 4:14–16 is the “crucial point of contact” with that in Pliny’s letter. In addition, many scholars in support of this theory believe that there is content within 1 Peter that directly mirrors the situation as portrayed in Pliny’s letter. For instance, they interpret the exhortation to defend one’s faith “with gentleness and reverence” in 3:15–16 as a response to Pliny executing Christians for the obstinate manner in which they professed to be Christians. Generally, this theory is rejected mainly by scholars who read the suffering in 1 Peter to be caused by social, rather than official, discrimination.

The author refers to Jesus, after his death, proclaiming to spirits in prison (3:18–20). This passage, and a few others (such as Matthew 27:52 and Luke 23:43), are the basis of the traditional Christian belief in the descent of Christ into hell, or the harrowing of hell. Though interpretations vary, some theologians see this passage as referring to Jesus, after his death, going to a place (neither heaven nor hell in the ultimate sense) where the souls of pre-Christian people waited for the Gospel. The first creeds to mention the harrowing of hell were Arian formularies of Sirmium (359), Nike (360), and Constantinople (360). It spread through the west and later appeared in the Apostles' Creed.


Online translations of the First Epistle of Peter:


</doc>
<doc id="11388" url="https://en.wikipedia.org/wiki?curid=11388" title="First Epistle of John">
First Epistle of John

The First Epistle of John, often referred to as First John and written 1 John or I John, is the first of the Johannine epistles of the New Testament, and the fourth of the catholic epistles. It is attributed to John the Evangelist, traditionally thought to be the author of the Gospel of John and the other two Johannine epistles. This epistle was probably written in Ephesus in AD 95–110. The work was written to counter docetism, which is the belief that Jesus did not come "in the flesh", but only as a spirit. It also defined how Christians are to discern true teachers: by their ethics, their proclamation of Jesus in the flesh, and by their love.

The main themes of the epistle are love and fellowship with God. The author describes various tests by which readers may ascertain whether or not their communion with God is genuine, and teaches that the proof of spiritual regeneration is a life of active righteousness. It also distinguishes between the world (which is full of evil and under the dominion of Satan) and the children of God (who are set apart from the world).

The epistle is not written in the same form as the other biblical epistles, lacking an epistolary opening or conclusion. The epistle is written in a simple style, without syntactical flourishes, and makes frequent use of asyndeton, where related thoughts are placed next to one another without conjunctions. In contrast to the linear style used in the Pauline epistles, John's thought moves in loops or circles forming a slowly advancing sequence of thought. This is similar to the parallel structure of Hebrew poetry, in which the second verse of a couplet often carries the same meaning as the first, though in the epistle the frequent recapitulations of already expressed ideas serve also to add to what has previously been said. In summary, the epistle may be said to exhibit a paraenetic style which is "marked by personal appeal, contrasts of right and wrong, true and false, and an occasional rhetorical question".

Some scholars have proposed the idea that the epistle is really John's commentary on a selection of traditional parallel couplets. While this theory, first propounded by Ernst von Dobschütz and Rudolf Bultmann, is not universally accepted, Amos Wilder writes that, "It is at least clear that there are considerable and sometimes continuous elements in the epistle whose style distinguishes them from that of the author both with respect to poetic structure and syntactic usage."

The epistle is traditionally held to have been composed by John the Evangelist, at Ephesus, when the writer was in advanced age. The epistle's content, language and conceptual style are very similar to the Gospel of John, 2 John, and 3 John, indicating that they were written by the same author. Indeed, at the end of the 19th century scholar Ernest DeWitt Burton wrote that there could be "no reasonable doubt" that 1 John and the gospel were written by the same author, and Amos Wilder has said that, "Early Christian tradition and the great majority of modern scholars have agreed on the common authorship of these writings, even where the author has not been identified with the apostle John." This majority view is typified by the Swiss Reformer Johannes Oecolampadius, who, in summarizing the career of the beloved apostle, refers to his first epistle as "the purest gospel."

However, other modern scholars have challenged this position. Though the common authorship of the three epistles is still almost universally accepted, scholars such as Heinrich Julius Holtzmann and C. H. Dodd have maintained that the epistle and the gospel were written by different authors. There are at least two principal arguments for this view. The first is that the epistle often uses a demonstrative pronoun at the beginning of a sentence, then a particle or conjunction, followed by an explanation or definition of the demonstrative at the end of the sentence, a stylistic technique which is not used in the gospel. The second is that the author of the epistle "uses the conditional sentence in a variety of rhetorical figures which are unknown to the gospel".

"The Fourth Gospel addresses itself to the challenges posed by Judaism and others outside Johannine circles who have rejected the community's vision of Jesus as preexistent Son, sent by the Father. The epistles (First, Second, and Third John) "describe the fracturing of the Johannine community itself".

The author wrote the epistle so that the joy of his audience would "be full" (1:4); that they would "not practice sin" (2:1); that "we should love one another" (3:11); and that "you who believe in the name of the Son of God... may know that you have eternal life" (5:13). We can therefore distinguish in the epistle both a general purpose (to increase mutual joy) and a specific purpose (to provide readers with tests by which they might assure themselves of their salvation). It appears as though the author was concerned about heretical teachers that had been influencing churches under his care. Such teachers were considered Antichrists (2:18–19) who had once been church leaders but whose teaching became heterodox. It appears that these teachers taught a form of docetism in which Jesus came to earth as a spirit without a real body of flesh (4:2) that his death on the cross was not as a true atonement for sins (1:7). It appears that John might have also been rebuking a proto-Gnostic named Cerinthus, who also denied the true humanity of Christ.

The purpose of the author (1:1–4) is to declare the Word of Life to those to whom he writes, in order that they might be united in fellowship with the Father and his Son Jesus Christ. He shows that the means of union with God are, (i) on the part of Christ, his atoning work providing salvation through faith (1:7,9; 2:2,25; 3:5; 4:9,10,14; 5:11-13,20) and his advocacy (2:1; 5:6,7); and (ii) on the part of man, holiness (1:6; 2:15,16,29; 3:10,12), obedience (2:3; 3:6,24; 5:2,3,18), purity (3:3,18), faith (3:23; 4:3; 5:5), and love (2:4,7,8; 3:11,14,16; 4:7,8,12,19-21; 5:1).

Whereas the Gospel of John was written to unbelievers, this epistle was written to those who were already believers (5:13). It seems likely that its audience was largely gentile rather than Jewish, since it contains few Old Testament quotations or distinctly Jewish forms of expression. The epistle was probably carried by itinerant missionaries to different churches throughout the region and read aloud to the congregations, due to, in no small part, John's status as an apostle and elder within the first century church.

A Trinitarian gloss added to Latin translations of the epistle in the 4th century was interpolated in the text over the course of the Middle Ages, known as the Johannine Comma. Although no Greek manuscripts before the 15th century include the passage, Erasmus added it to later editions of his edition of the New Testament, beginning in 1522. Bibles translated from his edition integrate the passage, including the King James Version (1611), which renders it as follows ("in italics"):

Translations made since the 18th century and based on a critical edition do not include this text, or include it as a footnote.





</doc>
<doc id="11390" url="https://en.wikipedia.org/wiki?curid=11390" title="First Vatican Council">
First Vatican Council

The First Vatican Council () was convoked by Pope Pius IX on 29 June 1868, after a period of planning and preparation that began on 6 December 1864. This, the twentieth ecumenical council of the Catholic Church, held three centuries after the Council of Trent, opened on 8 December 1869 and adjourned on 20 October 1870. Unlike the five earlier general councils held in Rome, which met in the Lateran Basilica and are known as Lateran councils, it met in the Vatican Basilica, hence its name. Its best-known decision is its definition of papal infallibility.

The council was convoked to deal with the contemporary problems of the rising influence of rationalism, liberalism, and materialism. Its purpose was, besides this, to define the Catholic doctrine concerning the Church of Christ. There was discussion and approval of only two constitutions: the Dogmatic Constitution on the Catholic Faith ("Dei Filius") and the First Dogmatic Constitution on the Church of Christ ("Pastor aeternus"), the latter dealing with the primacy and infallibility of the Bishop of Rome. The first matter brought up for debate was the dogmatic draft of Catholic doctrine against the manifold errors due to rationalism. The Council condemned rationalism, liberalism, naturalism, materialism and pantheism. The Catholic Church was on the defensive against the main ideology of the 19th century.

This council was summoned by Pope Pius IX by a bull on 29 June 1868. The first session was held in St. Peter's Basilica on 8 December 1869. Preliminary sessions dealt with general administrative matters and committee assignments. Bishop Bernard John McQuaid complained of rainy weather, inadequate heating facilities and boredom. Bishop James Roosevelt Bayley of Newark, New Jersey, noted the high prices in Rome. When Lord Houghton asked Cardinal Manning what had been going on, he answered:“Well, we meet, and we look at one another, and then we talk a little, but when we want to know what we have been doing, we read the Times”.

The doctrine of papal infallibility was not new and had been used by Pope Pius in defining as dogma, in 1854, the Immaculate Conception of Mary, the mother of Jesus. However, the proposal to define papal infallibility itself as dogma met with resistance, not because of doubts about the substance of the proposed definition, but because some considered it inopportune to take that step at that time. Richard McBrien divides the bishops attending Vatican I into three groups. The first group, which McBrien calls the "active infallibilists", was led by Henry Edward Manning and Ignatius von Senestréy. According to McBrien, the majority of the bishops were not so much interested in a formal definition of papal infallibility as they were in strengthening papal authority and, because of this, were willing to accept the agenda of the infallibilists. A minority, some 10 per cent of the bishops, McBrien says, opposed the proposed definition of papal infallibility on both ecclesiastical and pragmatic grounds, because, in their opinion, it departed from the ecclesiastical structure of the early Christian church. From a pragmatic perspective, they feared that defining papal infallibility would alienate some Catholics, create new difficulties for union with non-Catholics, and provoke interference by governments in ecclesiastical affairs. Those who held this view included most of the German and Austro-Hungarian bishops, nearly half of the Americans, one third of the French, most of the Chaldaeans and Melkites, and a few Armenians. Only a few bishops appear to have had doubts about the dogma itself.

On 24 April 1870, the dogmatic constitution on the Catholic faith "Dei Filius" was adopted unanimously. The draft presented to the council on 8 March drew no serious criticism, but a group of 35 English-speaking bishops, who feared that the opening phrase of the first chapter, ""Sancta romana catholica Ecclesia"" (the holy roman catholic Church), might be construed as favouring the Anglican branch theory, later succeeded in having an additional adjective inserted, so that the final text read: ""Sancta catholica apostolica romana Ecclesia"" (the holy catholic apostolic roman Church). The constitution thus set forth the teaching of the "Holy Catholic Apostolic Roman Church" on God, revelation and faith.

There was stronger opposition to the draft constitution on the nature of the church, which at first did not include the question of papal infallibility, but the majority party in the council, whose position on this matter was much stronger, brought it forward. It was decided to postpone discussion of everything in the draft except infallibility. The decree did not go forward without controversy; Cardinal , Archbishop of Bologna, proposed adding that the Pope is assisted by "the counsel of the bishops manifesting the tradition of the churches." The Pope rejected Guidi's view of the bishops as witnesses to the tradition, maintaining that "I am the tradition."

On 13 July 1870, a preliminary vote on the section on infallibility was held in a general congregation: 451 voted simply in favour ("placet"), 88 against ("non placet"), and 62 in favour but on condition of some amendment ("placet iuxta modum"). This made evident what the final outcome would be, and some 60 members of the opposition left Rome so as not to be associated with approval of the document. The final vote, with a choice only between "placet" and "non placet", was taken on 18 July 1870, with 433 votes in favour and only 2 against defining as a dogma the infallibility of the pope when speaking "ex cathedra". The two votes in opposition were cast by Bishop Aloisio Riccio and Bishop Edward Fitzgerald.

The dogmatic constitution states that the Pope has "full and supreme power of jurisdiction over the whole Church" (chapter 3:9); and that, when he
None of the bishops who had argued that proclaiming the definition was inopportune refused to accept it. Some Catholics, mainly of German language and largely inspired by the historian Ignaz von Döllinger, formed the separate Old Catholic Church in protest; von Döllinger did not formally join the new group.

Discussion of the rest of the document on the nature of the church was to continue when the bishops returned after a summer break. However, in the meanwhile the Franco-Prussian War broke out. With the swift German advance and the capture of Emperor Napoleon III, French troops protecting papal rule in Rome withdrew from the city.

Consequently, on 20 September 1870, one month after the Kingdom of Italy had occupied Rome, Pope Pius IX, who then considered himself a prisoner in the Vatican, issued the bull "Postquam Dei munere", adjourning the council indefinitely. While some proposed to continue the council in the Belgian city of Mechlin, it was never reconvened. The council was formally closed in 1960, prior to the formation of the Second Vatican Council.



</doc>
<doc id="11391" url="https://en.wikipedia.org/wiki?curid=11391" title="First Council of the Lateran">
First Council of the Lateran

The Council of 1123 is reckoned in the series of Ecumenical councils by the Catholic Church. It was convoked by Pope Callixtus II in December, 1122, immediately after the Concordat of Worms. The Council sought to: (a) bring an end to the practice of the conferring of ecclesiastical benefices by people who were laymen; (b) free the election of bishops and abbots from secular influence; (c) clarify the separation of spiritual and temporal affairs; (d) re-establish the principle that spiritual authority resides solely in the Church; (e) abolish the claim of the emperors to influence papal elections.

The council convoked by Callistus II was significant in size: three hundred bishops and more than six hundred abbots assembled at Rome in March, 1123; Callistus presided in person. During the Council the decisions of the Concordat of Worms were read and ratified. Various other decisions were promulgated.

The First Lateran Council was called by Pope Callistus II whose reign began February 1, 1119. It demarcated the end of the Investiture controversy which had begun before the time of Pope Gregory VII. The issues had been contentious and had continued with unabated bitterness for almost a century. Guido, as he was called before his elevation to the papacy, was the son of William I, Count of Burgundy. He was closely connected with nearly all the royal houses of Europe on both sides of his family. He had been named the papal legate to France by Pope Paschal II. During Guido's tenure in this office, Paschal II yielded to the military threats of Henry V, Holy Roman Emperor, and was induced to issue the Privilegium in the year 1111. By this document the Church gave up much of what had been claimed and subsequently attained by Pope Gregory VII and his Gregorian Reforms.

These concessions did not bring the expected peace but were received with violent reactionary opposition everywhere. Europe had come to expect an end to the Investiture controversy, and was not willing to return to the old days when the Holy Roman Emperor named the pope. The greatest resistance was seen in France and was led by Guido, who still held the office of the papal legate. He had been present in the Lateran Synod of 1112 which had proclaimed the Privilegium of 1111. On his return to France, Guido convoked an assembly of the French and Burgundian bishops at Vienne (1112). There the lay investiture of the clergy (the practice of the king, especially the Holy Roman Emperor naming bishops and the pope) was denounced as heretical. A sentence of excommunication was pronounced against Henry V, who had extorted through violence from the pope the concessions documented in the Privilegium. The agreement was deemed to be opposed to the interests of the Church. The decrees from the assembly of Vienne which denounced the Privilegium were sent to Paschal II with a request for confirmation. Pope Paschal II confirmed these which were received in general terms, on October 20, 1112.

Guido was later created cardinal by Pope Paschal II. The latter did not seem to have been pleased with Guido’s bold and forward attacks upon Henry V, Holy Roman Emperor. On the death of Paschal II, January 21, 1118, Gelasius II was elected pope. He was immediately seized by the Italian allies of Henry V, and on his liberation by the populace fled to Gaeta, where he was crowned. Henry V demanded the confirmation of the "Privilegium" and received no satisfactory reply. He then set about naming Burdinus, the archbishop of Braga, as his own pope. This pope assumed the name Gregory VIII, but came to be known as antipope Gregory VIII. Burdinus had already been deposed and excommunicated because he had crowned Henry V and the Holy Roman Emperor in Rome in 1117.

The excommunication of Bardinus was reiterated in Canon 6 of the document produced by Lateran I. Gelasius II promptly excommunicated the antipope Gregory VIII and Henry V. Gelasius was forced to flee under duress from the army of Henry V, and took refuge in the monastery of Cluny, where he died in January 1119. On the fourth day after the death of Gelasius II, February I, 1119, owing mainly to the exertions of Cardinal Cuno, Guido was elected pope and assumed the title of Callistus II. He was crowned Pope at Vienne on February 9, 1119.

Because of his close connection with the great royal families of Germany, France, England and Denmark, Callistus' papacy was received with much anticipation and celebration throughout Europe. There was a real hope throughout the Continent that the Investiture controversy might be settled once and for all. In the interest of conciliation, even the papal embassy was received by Henry V, Holy Roman Emperor at Strasburg. However, it soon became clear that Henry was not willing to concede his presumed and ancient right to name the pope and bishops within his kingdom. Perhaps to demonstrate conciliation or because of political necessity, Henry withdrew his support for antipope Gregory VIII.

It was agreed that Henry and Pope Callistus would meet at Mousson. On June 8, 1119, Callistus held a synod at Toulouse to proclaim the disciplinary reforms he had worked to attain in the French Church. In October, 1119, he opened the council at Reims. Louis VI of France and most of the barons of France attended this council along with more than four hundred bishops and abbots. The Pope was also to meet with Henry V, Holy Roman Emperor at Mousson. However, Henry showed up with an army of thirty thousand men. Callistus left Reims for Mousson, but upon learning of the warlike stance of Henry, quickly retreated back to Reims. Here, the Church dealt with issues of simony, concubinage of the clergy.

It was clear by now that Henry was in no mood to reconcile and a compromise with him was not to be had. The Conclave at Reims considered the situation and determined, as an entire Church, to formally excommunicate both Henry V and the antipope Gregory VIII. This occurred on October 30, 1119. While at Reims, Callistus tried to effect a settlement with Henry I of England and his brother Robert. This too, met with failure.

Callistus was determined to enter Rome which was occupied by the German forces and the antipope Gregory VIII. There was an uprising by the population which forced Gregory VIII to flee the city. After much political and military intrigue in Rome and the southern Italian states, Gregory VIII was formally deposed and Callistus II was generally recognized as the legitimate Pope in 1121. Having become the established power in Italy, Callistus now returned the conflict with Henry V over the issue of lay investiture. Henry had been the recipient of great pressure from many of his barons in Germany over his conflict with the pope. Some had entered into open rebellion. Henry was forced by circumstances to seek a peace with Callistus. Initial negotiations were conducted in October, 1121, at Wurzburg. Lambert, the Cardinal of Ostia was dispatched to convoke a synod at Worms, which began on September 8, 1122. By September 23, the Concordat of Worms, also called the Pactum Calixtinum was concluded. On his side, the emperor gave up his claim to investiture with ring and crosier and granted freedom of election to the episcopal sees.

The elections of bishops could be witnessed by the emperor or his representatives. Callistus obtained the right to name bishops throughout Germany, but still did not have this power in much of Burgundy and Italy.

The First Lateran Council was convoked to confirm the Concordat of Worms. The council was most representative with nearly three hundred bishops and six hundred abbots from every part of Catholic Europe being present. It convened on March 18, 1123. Decrees were also passed directed against simony, concubinage among the clergy, church robbers, and forgers of Church documents; the council also reaffirmed indulgences for Crusaders.

In the remaining few years of his life, Callistus II attempted to secure the status of the Church as it had existed at the end of the reign of Pope Gregory VII. He reorganized and reformed the churches around Rome, canonized Conrad of Constance, condemned the teaching of Peter de Bruis, confirmed the Bishop Thurston of York against the wishes of Henry I of England, and affirmed the freedom of York from the see of Canterbury. Callistus died December 13, 1124. He was succeeded by Pope Honorius II. Callistus II was a strong figure who brought a relative, if tentative peace between Germany and the Church. The Concordat of Worms and the First Lateran Council changed forever the belief in the divine right of kings to name the pope and bishops, and reshaped the nature of church and state forever.

Texts of the First Lateran Council may vary in both wording and numbering of the canons depending on source. In this translation, the precepts of the Concordat of Worms are codified in Canons 2, 4 and 10.

CANON I
Summary. Ordinations and promotions made for pecuniary considerations are devoid of every dignity.

Text. Following the example of the holy fathers and recognizing the obligation of our office, we absolutely forbid in virtue of the authority of the Apostolic See that anyone be ordained or promoted for money in the Church of God. Has anyone thus secured ordination or promotion in the Church, the rank acquired shall be devoid of every dignity.

CANON 2

Summary. Only a priest may be made provost, archpriest, and dean; only a deacon may be archdeacon.

Text. No one except a priest shall be promoted to the dignity of provost, archpriest, or dean;
and no one shall be made archdeacon unless he is a deacon.

CANON 3

Summary. Priests, deacons, and subdeacons are forbidden to live with women other than such as were permitted by the Nicene Council.

Text. We absolutely forbid priests, deacons, and subdeacons to associate with concubines and women, or to live with women other than such as the Nicene Council (canon 3) for reasons of necessity permitted, namely, the mother, sister, or aunt, or any such person concerning whom no suspicion could arise.

CANON 4

Summary. Lay persons, no matter how pious they may be, have no authority to dispose of anything that belongs to the Church.

Text. In accordance with the decision of Pope Stephen, we declare that lay persons, no matter how devout they may be, have no 
authority to dispose of anything belonging to the Church, but according to the Apostolic canon the supervision of all ecclesiastical affairs belongs to the bishop, who shall administer them conformably to the will of God. If therefore any prince or other layman shall arrogate to himself the right of disposition, control, or ownership of ecclesiastical goods or properties, let him be judged guilty of sacrilege.

CANON 5

Summary. Marriages between blood-relatives are forbidden.

Text. We forbid marriages between blood-relatives because they are forbidden by the divine and secular laws. Those who contract such alliances, as also their offspring, the divine laws not only ostracize but declare accursed, while the civil laws brand them as infamous and deprive them of hereditary rights. We, therefore, following the example of our fathers, declare and stigmatize them as infamous.

CANON 6

Summary. Ordinations by Burdinus and the bishops consecrated by him are invalid.

Text. The ordinations made by the heresiarch Burdinus after his condemnation by the Roman Church, as also those made by the bishops consecrated by him after that point of time, we declare to be invalid.

CANON 7

Summary. No one is permitted to arrogate to himself the episcopal authority in matters pertaining to the cura animarum and the bestowal of benefices.

Text. No archdeacon, archpriest, provost, or dean shall bestow on another the care of souls or the prebends of a church without the decision or consent of the bishop; indeed, as the sacred canons point out, the care of souls and the disposition of ecclesiastical property are vested in the authority of the bishop. If anyone shall dare act contrary to this and arrogate to himself the power belonging to the bishop, let him be expelled from the Church.

CANON 8

Summary. Military persons are forbidden under penalty of anathema to invade or forcibly hold the city of Benevento.

Text. Desiring with the grace of God to protect the recognized possessions of the Holy Roman Church, we forbid under pain of anathema any military person to invade or forcibly hold Benevento, the city of St. Peter. If anyone act contrary to this, let him be anathematized.

CANON 9

Summary. Those excommunicated by one bishop, may not be restored by others.

Text. We absolutely forbid that those who have been excommunicated by their own bishops be received into the communion of the Church by other bishops, abbots, and clerics.
CANON 10

Summary. A bishop consecrated after an uncanonical election shall be deposed.

Text. No one shall be consecrated bishop who has not been canonically elected. If anyone dare do this, both the consecrator and the one consecrated shall be deposed without hope of reinstatement.

CANON 11

Summary. To those who give aid to the Christians in the Orient is granted the remission of sins, and their families and possessions are taken under the protection of the Roman Church.

Text. For effectively crushing the tyranny of the infidels, we grant to those who go to Jerusalem and also to those who give aid toward the defense of the Christians, the remission of their sins and we take under the protection of St. Peter and the Roman Church their homes, their families, and all their belongings, as was already ordained by Pope Urban II. Whoever, therefore, shall dare molest or seize these during the absence of their owners, shall incur excommunication. Those, however, who with a view of going to Jerusalem or to Spain (that is, against the Moors) are known to have attached the cross to their garments and afterward removed it, we command in virtue of our Apostolic authority to replace it and begin the journey within a year from the coming Easter. Otherwise we shall excommunicate them and interdict within their territory all divine service except the baptism of infants and the administration of the last rites to the dying.

CANON 12

Summary. The property of the porticani dying without heirs is not to be disposed of in a manner contrary to the wish of the one deceased.

Text. With the advice of our brethren and of the entire Curia, as well as with the will and consent of the prefect, we decree the abolition of that evil custom which has hitherto prevailed among the porticani, namely, of disposing, contrary to the wish of the one deceased, of the property of porticani dying without heirs; with this understanding, however, that in future the porticani remain faithful to the Roman Church, to us and to our successors.

CANON 13

Summary. If anyone violates the truce of God and after the third admonition does not make satisfaction, he shall be anathematized.

Text. If anyone shall violate the truce of God he shall be admonished three times by the bishop to make satisfaction. If he disregards the third admonition the bishop, either with the advice of the metropolitan or with that of two or one of the neighboring bishops, shall pronounce the sentence of anathema against the violator and in writing denounce him to all the bishops. 
CANON 14

Summary. Laymen are absolutely forbidden to remove offerings from the altars of Roman churches.

Text. Following the canons of the holy fathers, we absolutely and under penalty of anathema forbid laymen to remove the offerings from the altars of the churches of St. Peter, of The Savior (Lateran Basilica), of St. Mary Rotund, in a word, from the altars of any of the churches or from the crosses. By our Apostolic authority we forbid also the fortifying of churches and their conversion to profane uses.

CANON 15

Summary. Counterfeiters of money shall be excommunicated.

Text. Whoever manufactures or knowingly expends counterfeit money, shall be cut off from the communion of the faithful (excommunicated) as one accursed, as an oppressor of the poor and a disturber of the city.

CANON 16

Summary. Robbers of pilgrims and of merchants shall be excommunicated.

Text. If anyone shall dare attack pilgrims going to Rome to visit the shrines of the Apostles and the oratories of other saints and rob them of the things they have with them, or exact from merchants new imposts and tolls, let him be excommunicated till he has made satisfaction.

CANON 17

Summary. Abbots and monks may not have the cura animarum.

Text. We forbid abbots and monks to impose public penances, to visit the sick, to administer extreme unction, and to sing public masses. The chrism, holy oil, consecration of altars, and ordination of clerics they shall obtain from the bishops in whose dioceses they reside.

CANON 18

Summary. The appointment of priests to churches belongs to the bishops, and without their consent they may not receive tithes and churches from laymen.

Text. Priests shall be appointed to parochial churches by the bishops, to whom they shall be responsible for the care of souls and other matters pertaining to them. They are not permitted to receive tithes and churches from laics without the will and consent of the bishops. If they act otherwise, let them be subject to the canonical penalties.

CANON 19

Summary. Taxes paid to bishops by monks since Gregory VII must be continued. Monks may not by prescription acquire the possessions of churches and of bishops.

Text. The tax (servitium) which monasteries and their churches have rendered to the bishops since the time of Gregory VII, shall be continued. We absolutely forbid abbots and monks to acquire by prescription after thirty years the possessions of churches and of shops.

CANON 20

Summary. Churches and their possessions, as well as the person and things connected with them, shall remain safe and unmolested.

Text. Having in mind the example of our fathers and discharging the duty of our pastoral office, we decree that churches and their possessions, as well as the persons connected with them, namely, clerics and monks and their servants (conversi), also the laborers and the things they use, shall remain safe and unmolested. If anyone shall dare act contrary to this and, recognizing his crime, does not within the space of thirty days make proper amends, let him be cut off from the Church and anathematized.

CANON 21

Summary. Clerics in major orders may not marry, and marriages already contracted must be dissolved.

Text. We absolutely forbid priests, deacons, subdeacons, and monks to have concubines or to contract marriage. We decree in accordance with the definitions of the sacred canons, that marriages already contracted by such persons must be dissolved, and that the persons be condemned to do penance.

CANON 22

Summary. The alienation of possessions of the exarchate of Ravenna is condemned, and the Ordinaries made by the intruders are invalid.

Text. The alienation that has been made especially by Otto, Guido, Jerome, and perhaps by Philip of possessions of the exarchate of Ravenna, we condemn. In a general way we declare invalid the alienations in whatever manner made by bishops and abbots whether intruded or canonically elected, and also the ordinations conferred by them whether with the consent of the clergy of the Church or simoniacally. We also absolutely forbid any cleric in any way to alienate his prebend or any ecclesiastical benefice. If he has presumed to do this in the past or shall presume to do so in the future, his action shall be null and he shall be subject to the canonical penalties .

Lateran I was the first of four Lateran Councils between the years 1123–1215. The first was not very original in its concept, nor one called to meet a pressing theological question. For the most part, Pope Callistus II summoned the council to ratify the various meetings and concords which had been occurring in and around Rome for several years. The most pressing issue was that of the Investiture controversy which had consumed nearly a century of contention and open warfare. At the heart of the question was the ancient right of the Holy Roman Emperor to name the pope as well as bishops and priests. These would be invested with some secular symbol such as a sword or scepter and the spiritual authority represented by a ring, miter and crosier. To an illiterate population, it appeared the bishop or abbot was now the king’s inferior and owed his position to the king. This issue came to the fore in the first part of the eleventh century when Rome and the pope sought autonomy from the Holy Roman Emperor. It had been a central issue in the reign of Pope Gregory VII and his battles with Henry IV, Holy Roman Emperor. The issue was never settled. Years of teaching by Roman trained priests and bishops in Germany had led to an educated generation which rejected the idea of divine right of kings. 
The Third Lateran Council and the Fourth Lateran Council are generally considered to be of much greater significance than Lateran I. However, Lateran I marked the first time a general and large Council had been held in the West. All previous Councils had been in the East and dominated by Greek theologians and philosophers.
In the struggle between Stephen of England and Matilda, the daughter of Henry I of England, the English Church slipped away from the close control the Normans had exercised. Stephen was forced to make many concessions to the Church to gain some element of political control. Historians have largely considered his rule to be a disaster, calling it The Anarchy.

Because of political necessity, the Holy Roman Emperors were restrained from directly naming bishops in the kingdom. In practicality, the process continued to a certain extent. The issue of separation of Church and State was simply recast in a different direction. Of all the Gregorian Reforms which were embodied by Lateran I, celibacy of the clergy was the most successful. Simony was curtailed. As time progressed, secular interference into the politics of the Church was seen to continue, albeit in different ways from that of the Investiture controversy.

It has been argued by some historians that the Concordat of Worms and its reiteration by Lateran I were little more than face saving measures by the Church. Henry V, Holy Roman Emperor continued to name bishops within his kingdom. His control over the papacy was definitely abated. At the time, the Concordat of Worms was proclaimed as a great victory for Henry V inside the Holy Roman Empire. It did serve to constrain much of the most recent warfare in and outside the empire. In the end, Henry V died the monarch of a much diminished kingdom.




</doc>
<doc id="11393" url="https://en.wikipedia.org/wiki?curid=11393" title="Four Noble Truths">
Four Noble Truths

In Buddhism, the Four Noble Truths (Sanskrit: "catvāri āryasatyāni"; Pali: "cattāri ariyasaccāni") are "the truths of the Noble Ones", the truths or realities for the "spiritually worthy ones". The truths are:

They are traditionally identified as the first teaching given by the Buddha, and considered one of the most important teachings in Buddhism.

The four truths appear in many grammatical forms in the ancient Buddhist texts, and they have both a symbolic and a propositional function. Symbolically, they represent the awakening and liberation of the Buddha, and of the potential for his followers to reach the same religious experience as him. As propositions, the Four Truths are a conceptual framework that appear in the Pali canon and early Hybrid Sanskrit Buddhist scriptures. They are a part of the broader "network of teachings", (the ""dhamma" matrix") which have to be taken together. They provide a conceptual framework for introducing and explaining Buddhist thought, which has to be personally understood or "experienced".

As a proposition, the four truths defy an exact definition, but refer to and express the basic orientation of Buddhism: unguarded sensory contact gives rise to craving and clinging to impermanent states and things, which are "dukkha", "incapable of satisfying" and painful. This craving keeps us caught in "samsara", the endless cycle of repeated rebirth, and the continued "dukkha" that comes with it. There is a way to end this cycle, namely by attaining "nirvana", cessation of craving, whereafter rebirth and the accompanying "dukkha" will no longer arise again. This can be accomplished by following the eightfold path, confining our automatic responses to sensory contact by restraining oneself, cultivating discipline and wholesome states, and practicing mindfulness and "dhyana" (meditation).

The function of the four truths, and their importance, developed over time and the Buddhist tradition slowly recognized them as the Buddha's first teaching. This tradition was established when "prajna", or "liberating insight", came to be regarded as liberating in itself, instead of or in addition to the practice of "dhyana". This "liberating insight" gained a prominent place in the sutras, and the four truths came to represent this liberating insight, as a part of the enlightenment story of the Buddha. The four truths grew to be of central importance in the Theravada tradition of Buddhism by about the 5th-century CE, which holds that the insight into the four truths is liberating in itself. They are less prominent in the Mahayana tradition, which sees the higher aims of insight into "sunyata", emptiness, and following the Bodhisattva path as central elements in their teachings and practice. The Mahayana tradition reinterpreted the four truths to explain how a liberated being can still be "pervasively operative in this world". Beginning with the exploration of Buddhism by western colonialists in the 19th century and the development of Buddhist modernism, they came to be often presented in the west as the central teaching of Buddhism, sometimes with novel modernistic reinterpretations very different from the historic Buddhist traditions in Asia.

The four truths are best known from their presentation in the "Dhammacakkappavattana Sutta" text, which contains two sets of the four truths, while various other sets can be found in the Pāli Canon, a collection of scriptures in the Theravadan Buddhist tradition. The full set, which is most commonly used in modern expositions, contains grammatical errors, pointing to multiple sources for this set and translation problems within the ancient Buddhist community. Nevertheless, they were considered correct by the Pali tradition, which didn't correct them.

According to the Buddhist tradition, the "Dhammacakkappavattana Sutta", "Setting the Wheel of Dhamma in Motion", contains the first teachings that the Buddha gave after attaining full awakening, and liberation from rebirth. According to L. S. Cousins, many scholars are of the view that "this discourse was identified as the first sermon of the Buddha only at a later date," and according to professor of religion Carol S. Anderson the four truths may originally not have been part of this sutta, but were later added in some versions. Within this discourse, the four noble truths are given as follows ("bhikkus" is normally translated as "Buddhist monks"):
According to this sutra, with the complete comprehension of these four truths release from "samsara", the cycle of rebirth, was attained:
The comprehension of these four truths by his audience leads to the opening of the "Dhamma Eye", that is, the attainment of right vision:
According to K.R. Norman, the basic set is as follows:

According to K. R. Norman, the Pali canon contains various shortened forms of the four truths, the "mnemonic set", which were "intended to remind the hearer of the full form of the NTs." The earliest form of the mnemonic set was "dukkham samudayo nirodho magga", without the reference to the Pali terms "sacca" or "arya", which were later added to the formula. The four mnemonic terms can be translated as follows:

According to L.S. Cousins, the four truths are not restricted to the well-known form where "dukkha" is the subject. Other forms take "the world, the arising of the world" or "the āsavas, the arising of the āsavas" as their subject. According to Cousins, "the well-known form is simply shorthand for all of the forms." "The world" refers to the saṅkhāras, that is, all compounded things, or to the six sense spheres.

The various terms all point to the same basic idea of Buddhism, as described in five skandhas and twelve nidānas. In the five skandhas, sense-contact with objects leads to sensation and perception; the saṅkhāra ('inclinations', c.q. craving etc.) determine the interpretation of, and the response to, these sensations and perceptions, and affect consciousness in specific ways. The "twelve nidānas" describe the further process: craving and clinging ("upādāna") lead to "bhava" (becoming) and "jāti" (birth). 

In the orthodox interpretation, "bhava" is interpreted as "kammabhava", that is , "karma", while "jāti" is interpreted as rebirth: from sensation comes craving, from craving comes karma, from karma comes rebirth. The aim of the Buddhist path is to reverse this causal chain: when there is no (response to) sensation, there is no craving, no karma, no rebirth. In Thai Buddhism, "bhava" is interpreted as behavior which serves craving and clinging, while "jāti" is interpreted as the repeated birth of the ego or self-sense, which perpetuates the process of self-serving responses and actions.

The Pali terms "ariya sacca" (Sanskrit: "arya satya") are commonly translated as "noble truths". This translation is a convention started by the earliest translators of Buddhist texts into English. According to K.R. Norman, this is just one of several possible translations. According to Paul Williams,
The term "arya" was later added to the four truths. The term "ariya" (Sanskrit: "arya") can be translated as "noble", "not ordinary", "valuable", "precious". "pure", Paul Williams:
The term "sacca" (Sanskrit: "satya") is a central term in Indian thought and religion. It is typically translated as "truth"; but it also means "that which is in accord with reality", or "reality". According to Rupert Gethin, the four truths are "four 'true things' or 'realities' whose nature, we are told, the Buddha finally understood on the night of his awakening." They function as "a convenient conceptual framework for making sense of Buddhist thought." According to K. R. Norman, probably the best translation is "the truth[s] of the noble one (the Buddha)". It is a statement of how things are seen by a Buddha, how things really are when seen correctly. It is the truthful way of seeing, Through not seeing things this way, and behaving accordingly, we suffer.

According to Anderson, the four truths have both a symbolic and a propositional function:
As a symbol, they refer to the possibility of awakening, as represented by the Buddha, and are of utmost importance:
As a proposition, they are part of the matrix or "network of teachings", in which they are "not particularly central", but have an equal place next to other teachings, describing how release from craving is to be reached. A long recognized feature of the Theravada canon is that it lacks an "overarching and comprehensive structure of the path to "nibbana"." The sutras form a network or matrix, and the four truths appear within this "network of teachings", which have to be taken together. Within this network, "the four noble truths are one doctrine among others and are not particularly central", but are a part of "the entire "dhamma" matrix". The four noble truths are be set and learnt in that network, learning "how the various teachings intersect with each other", and refer to the various Buddhist techniques, which are all explicitly and implicitly part of the passages which refer to the four truths. According to Anderson,

As a proposition, the four truths defy an exact definition, but refer to and express the basic orientation of Buddhism: sensory contact gives rise to clinging and craving to temporary states and things, which is ultimately unsatisfactory and painful, "dukkha", and sustains "samsara", the repeated cycle of "bhava" (becoming, habitual tendencies) and "jāti" ("birth", interpreted as either rebirth, the coming to be of a new existence; or as the arising of the sense of self as a mental phenomenon).
By following the Buddhist path, craving and clinging can be confined, peace of mind and real happiness
can be attained, and the repeated cycle of repeated becoming and birth will be stopped.
The truth of "dukkha", "incapable of satisfying", "painful", is the basic insight that "samsara", life in this "mundane world", with its clinging and craving to impermanent states and things" is "dukkha", unsatisfactory and painful. We expect happiness from states and things which are impermanent, and therefore cannot attain real happiness.

The truth of "samudaya", "arising", "coming together", or "dukkha-samudaya", the origination or arising of "dukkha", is the truth that repeated life in this world, and its associated "dukkha" arises, or continues, with taṇhā, "thirst", craving for and clinging to these impermanent states and things.

The truth of "nirodha", cessation, or "dukkha-nirodha", the cessation of "dukkha", is the truth that "dukkha" ceases, or can be confined, when craving and clinging cease or are confined, and nirvana is attained. "Nirvana" refers to the moment of attainment itself, and the resulting peace of mind and happiness ("khlesa-nirvana"), but also to the final dissolution of the five skandhas at the time of death ("skandha-nirvana" or "parinirvana"); in the Theravada-tradition, it also refers to a transcendental reality which is "known at the moment of awakening". According to Gethin, "modern Buddhist usage tends to restrict 'nirvāṇa' to the awakening experience and reserve 'parinirvāṇa' for the death experience. When "nirvana" is attained, no more karma is being produced, and rebirth and dissatisfaction will no longer arise again. Cessation is "nirvana", "blowing out", and peace of mind. Joseph Goldstein explains:
The truth of "magga", refers to the path to the cessation of, or liberation from "dukkha". By following the Noble Eightfold Path, to "moksha", liberation, restraining oneself, cultivating discipline, and practicing mindfulness and meditation, one starts to disengage from craving and clinging to impermanent states and things, and rebirth and dissatisfaction will be ended. The term "path" is usually taken to mean the Noble Eightfold Path, but other versions of "the path" can also be found in the Nikayas. The Theravada tradition regards insight into the four truths as liberating in itself.

The well-known eightfold path consists of the understanding that this world is fleeting and unsatisfying, and how craving keeps us tied to this fleeting world; a friendly and compassionate attitude to others; a correct way of behaving; mind-control, which means not feeding on negative thoughts, and nurturing positive thoughts; constant awareness of the feelings and responses which arise; and the practice of "dhyana", meditation. The tenfold path adds the right (liberating) insight, and liberation from rebirth.

The four truths are to be internalised, and understood or "experienced" personally, to turn them into a lived reality.

The four truths describe "dukkha" and its ending as a means to reach peace of mind in this life, but also as a means to end rebirth.

According to Geoffrey Samuel, "the Four Noble Truths [...] describe the knowledge needed to set out on the path to liberation from rebirth." By understanding the four truths, one can stop this clinging and craving, attain a pacified mind, and be freed from this cycle of rebirth and redeath. Patrick Olivelle explains that moksha is a central concept in Indian religions, and "literally means freedom from samsara." Melvin E. Spiro further explains that "desire is the cause of suffering because desire is the cause of rebirth." When desire ceases, rebirth and its accompanying suffering ceases. Peter Harvey explains:

The last sermon, the "Maha-parinibbana Sutta" (Last Days of the Buddha, Digha Nikaya 16)", states it as follows:
According to Bhikkhu Buddhadasa, "birth" does refer not to physical birth and death, but to the birth and death of our self-concept, the "emergence of the ego". According to Buddhadhasa,
Some contemporary teachers tend to explain the four truths psychologically, by taking "dukkha" to mean mental anguish in addition to the physical pain of life, and interpreting the four truths as a means to attain happiness in this life. In the contemporary Vipassana movement that emerged out of the Theravada Buddhism, freedom and the "pursuit of happiness" have become the main goals, not the end of rebirth, which is hardly mentioned in their teachings.

Yet, though freedom and happiness is a part of the Buddhist teachings, these words refer to something different in traditional Asian Buddhism. According to Fronsdal, "when Asian teachers do talk about freedom, it is primarily in reference to what one is free from—that is, from greed, hate, delusion, grasping, attachment, wrong view, self, and most significantly, rebirth". "Nibbana" is the final freedom, and it has no purpose beyond itself. In contrast, freedom in the creative modern interpretation of Four Noble Truths and the Eightfold Path means living happily and wisely, "without drastic changes in lifestyle". Such freedom and happiness is not the goal of Four Noble Truths and related doctrines within traditional Buddhism, but the vipassana teachings in the West make no reference to traditional Theravada doctrines, instead they present only the pragmatic and experiential goals in the form of therapy for the audience's current lives. The creative interpretations are driven in part because the foundational premises of Buddhism do not make sense to audiences outside of Asia. According to Spiro, "the Buddhist message is not simply a psychological message", but an eschatological message.

According to Anderson, "the four truths are recognized as perhaps the most important teaching of the Buddha." Yet, as early as 1935 Caroline Rhys Davids wrote that for a teaching so central to Theravada Buddhism, it was missing from critical passages in the Pali canon. According to Gethin, the four truths and the eightfold path are only two lists of "literally hundreds of similar lists covering the whole range of the theory and practice of ancient Buddhism." The position of the four truths within the canon raises questions, and has been investigated throughout the 19th and 20th centuries.

According to academic scholars, inconsistencies in the oldest texts may reveal developments in the oldest teachings. While the Theravada-tradition holds that the Sutta Pitaka is "the definitive recension of the Buddha-word", and Theravadins argue that it is likely that the sutras date back to the Buddha himself, in an unbroken chain of oral transmission, academic scholars have identified many of such inconsistencies, and tried to explain them. Information of the oldest teachings of Buddhism, such as on the Four Noble Truths, has been obtained by analysis of the oldest texts and these inconsistencies, and are a matter of ongoing discussion and research. According to Schmithausen, three positions held by scholars of Buddhism can be distinguished regarding the possibility to retain knowledge of the oldest Buddhism:

According to Bronkhorst, the four truths may already have been formulated in earliest Buddhism, but did not have the central place they acquired in later buddhism. According to Anderson, only by the time of the commentaries, in the fifth century CE, did the four truths come to be identified in the Theravada tradition as the central teaching of the Buddha. According to Anderson,

According to Feer and Anderson, the four truths probably entered the Sutta Pitaka from the Vinaya, the rules for monastic order. They were first added to enlightenment-stories which contain the Four Jhanas, replacing terms for "liberating insight". From there they were added to the biographical stories of the Buddha.

Scholars have noted inconsistencies in the presentations of the Buddha's enlightenment, and the Buddhist path to liberation, in the oldest sutras. They offer that these inconsistencies show that the Buddhist teachings evolved, either during the lifetime of the Buddha, or thereafter. According to the Japanese scholar Ui, the four truths are not the earliest representation of the Buddha's enlightenment. Instead, they are a rather late theory on the content of the Buddha's enlightenment. According to Vetter and Bronkhorst, the earliest Buddhist path consisted of a set of practices which culminate in the practice of "dhyana", leading to a calm of mind and awareness (mindfulness) which according to Vetter "is" the liberation which is being sought. Later on, "liberating insight" came to be regarded as equally liberating. This "liberating insight" came to be exemplified by "prajna", or the insight in the "four truths", but also by other elements of the Buddhist teachings. According to Vetter and Bronkhorst, this growing importance of "liberating insight" was a response to other religious groups in India, which held that a liberating insight was indispensable for "moksha", liberation from rebirth. This change is reflected in the canon, where, according to Bronkhorst,

According to Vetter and Bonkhorst, the ideas on what exactly constituted this "liberating insight" was not fixed but developed over time. According to Bronkhorst, in earliest Buddhism the four truths did not serve as a description of "liberating insight". Initially the term "prajna" served to denote this "liberating insight". Later on, "prajna" was replaced in the suttas by the "four truths". This happened in those texts where practicing the four jhanas preceded the attainment of "liberating insight", and where this practice of the four jhanas then culminates in "liberating insight". This "liberating insight" came to be defined as "insight into the four truths", which is presented as the "liberating insight" which constituted the awakening, or "enlightenment" of the Buddha. When he understood these truths he was "enlightened" and liberated, as reflected in Majjhima Nikaya 26:42: "his taints are destroyed by his seeing with wisdom."

Bronkhorst points to an inconsistency, noting that the four truths refer here to the eightfold path as the means to gain liberation, while the attainment of insight into the four truths is portrayed as liberating in itself. According to Bronkhorst, this is an inconsistency which reveals a change which took place over time in the composition of the sutras. An example of this substitution, and its consequences, is Majjhima Nikaya 36:42-43, which gives an account of the awakening of the Buddha.

According to Schmithausen, the four truths were superseded by "pratityasamutpada", and still later, in the Hinayana schools, by the doctrine of the non-existence of a substantial self or person.. Schmithausen further states that still other descriptions of this "liberating insight" exist in the Buddhist canon:
In contrast, Thanissaro Bikkhu presents the view that the four truths, pratityasamutpada and anatta are inextricably intertwined .

In their symbolic function, the sutras present the insight into the four truths as the culmination of the Buddh's path to awakening. In the "Vinayapitaka" and the "Sutta-pitaka" they have the same symbolic function, in a reenactment by his listeners of the Buddha's awakening by attaining the "dhamma-eye". In contrast, here this insight serves as the starting point to path-entry for his audience. These sutras present a repeated sequence of events:

Yet, in other sutras, where the four truths have a propositional function, the comprehension of the four truths destroys the corruptions. They do so in combination with the practice of the "jhanas" and the attainment of the divine eye, with which past lives and the working of rebirth are being seen.

According to Anderson, following Schmithausen and Bronkhorst, these two presentations give two different models of the path to liberation, reflecting their function as a symbol and as a proposition. Most likely, the four truths were first associated with the culmination of the path in the destruction of the "āsavās", where they substituted the unspecified "liberating insight"; as the canon developed, they became more logically associated with the beginning of the Buddhist path.

According to Anderson there is a strong tendency within scholarship to present the four truths as the most essential teaching of Buddhism. According to Anderson, the four truths have been simplified and popularized in western writings, due to "the colonial project of gaining control over Buddhism." According to Crosby, the Buddhist teachings are reduced to a "simple, single rationalized account", which has parallels in the reinterpretation of the Buddha in western literature.

The presentation of the four truths as one of the most important teachings of the Buddha "has been [done] to reduce the four noble truths to a teaching that is accessible, pliable, and therefore readily appropriated by non-Buddhists." There is a great variety of teachings in the Buddhist literature, which may be bewildering for those who are unaware of this variety. The four truths are easily accessible in this regard, and are "readily [understood] by those outside the Buddhist traditions." For example Walpola Rahula's "What the Buddha Taught", a widely used introductory text for non-Buddhists, uses the four truths as a framework to present an overview of the Buddhist teachings.

According to Harris, the British in the 19th century crafted new representations of Buddhism and the Buddha. 19th century missionaries studied Buddhism, to be more effective in their missionary efforts. The Buddha was de-mystified, and reduced from a "superhuman" to a "compassionate, heroic human", serving "western historical method and the missionary agenda of situating the Buddha firmly below the divine." The four truths were discovered by the British by reading the Buddhist texts, and were not immediately granted the central position they later received.

The writings of British missionaries show a growing emphasis on the four truths as being central to Buddhism, with somewhat different presentations of them. This colonial project had a strong influence on some strands of Buddhism, culminating in so-called Protestant Buddhism, which incorporated several essentially Protestant attitudes regarding religion, such as the emphasis on written texts. According to Gimello, Rahula's book is an example of this Protestant Budhism, and "was created in an accommodating response to western expectations, and in nearly diametrical opposition to Buddhism as it had actually been practised in traditional Theravada."

Hendrik Kern proposed in 1882 that the model of the four truths may be an analogy with classical Indian medicine, in which the four truths function as a medical diagnosis, and the Buddha is presented as a physician. Kern's analogy became rather popular, but "there is not sufficient historical evidence to conclude that the Buddha deliberately drew upon a clearly defined medical model for his fourfold analysis of human pain."

According to Anderson, those scholars who did not place the four truths at the center of Buddhism, either "located the four truths in a fuller reading of the Theravada canon and the larger context of South Asian literature", or "located the teaching within an experience of Buddhism as practiced in a contemporary setting." According to Anderson, "these autors suggest a more complex reading of the four noble truths than those who locate the teaching as the key to or as a crucial element within the grand scheme of Buddhism."

The developing Buddhist tradition inserted the four truths, using various formulations, at various sutras. They are being used both as a symbol of all dhammas and the Buddha's awakening, and as a set of propositions which function within a matrix of teachings. According to Anderson, there is no single way to understand the teachings; one teaching may be used to explain another teaching, and vice versa. The teachings form a network, which should be apprehended as such to understand how the various teachings intersect with each other.

The "Mahasaccaka Sutta" ("The Greater Discourse to Saccaka", Majjhima Nikaya 36) gives one of several versions of the Buddha's way to liberation. He attains the three knowledges, namely knowledge of his former lifes, knowledge of death and rebirth, and knowledge of the destruction of the taints, the Four Noble Truths. After going through the four dhyanas, and gaining the first two knowledges, the story proceeds:
Bronkhorst dismisses the first two knowledges as later additions, and proceeds to notice that the recognition of the intoxicants is modelled on the four truths. According to Bronkhorst, those are added the bridge the original sequence of "I directed my mind to the knowledge of the destruction of the intoxicants. My mind was liberated", which was interrupted by the addition of the four truths. Bronkhorst points out that those do not fit here, since the four truths culminate in the knowledge of the path to be followed, while the Buddha himself is already liberated at that point.

According to the Buddhist tradition, the first talk of Gautama Buddha after he attained enlightenment is recorded in the "Dhammacakkappavattana Sutta" ("Setting in Motion the Wheel of Dhamma", Samyutta Nikaya 56.11). The "Dhammacakkappavattana Sutta" provides details on three stages in the understanding of each truth, for a total of twelve insights. The three stages for understanding each truth are:

These three stages of understanding are emphasized particularly in the Theravada tradition, but they are also recognized by some contemporary Mahayana teachers.

According to Cousins, many scholars are of the view that "this discourse was identified as the first sermon of the Buddha only at a later date." According to Stephen Batchelor, the "Dhammacakkappavattana Sutta" contains incongruities, and states that
According to Bronkhorst this "first sermon" is recorded in several sutras, with important variations. In the Vinaya texts, and in the "Dhammacakkappavattana Sutta" which was influenced by the Vinaya texts, the four truths are included, and Kondañña is enlightened when the "vision of Dhamma" arises in him: "whatever is subject to origination is all subject to cessation." Yet, in the "Ariyapariyesanā Sutta" ("The Noble Search", Majjhima Nikaya 26) the four truths are not included, and the Buddha gives the five ascetics personal instructions in turn, two or three of them, while the others go out begging for food. The versions of the "first sermon" which include the four truths, such as the "Dhammacakkappavattana Sutta", omit this instruction, showing that
According to Bronkhorst, this indicates that the four truths were later added to earlier descriptions of liberation by practicing the four dhyanas, which originally was thought to be sufficient for the destruction of the arsavas. Anderson, following Norman, also thinks that the four truths originally were not part of this sutta, and were later added in some versions.

According to Bronkhorst, the "twelve insights" are probably also a later addition, born out of unease with the substitution of the general term "prajna" for the more specific "four truths".

According to the Buddhist tradition, the "Maha-parinibbana Sutta" (Last Days of the Buddha, Digha Nikaya 16) was given near the end of the Buddha's life. This sutta "gives a good general idea of the Buddha's Teaching:"


</doc>
<doc id="11396" url="https://en.wikipedia.org/wiki?curid=11396" title="French Republican calendar">
French Republican calendar

The French Republican calendar (), also commonly called the French Revolutionary calendar ("calendrier révolutionnaire français"), was a calendar created and implemented during the French Revolution, and used by the French government for about 12 years from late 1793 to 1805, and for 18 days by the Paris Commune in 1871. The revolutionary system was designed in part to remove all religious and royalist influences from the calendar, and was part of a larger attempt at decimalisation in France (which also included decimal time of day, decimalisation of currency, and metrication). It was used in government records in France and other areas under French rule, including Belgium, Luxembourg, and parts of the Netherlands, Germany, Switzerland, Malta, and Italy.

Sylvain Maréchal, prominent anticlerical atheist, published the first edition of his "Almanach des Honnêtes-gens" (Almanac of Honest People) in 1788. On pages 14–15 appears a calendar, consisting of twelve months. The first month is "Mars, ou Princeps" (March, or First), the last month is "Février, ou Duodécembre" (February, or Twelfth). (The months of September [meaning "the seventh"] through December [meaning "the tenth"] are already numeric names, although their meanings do not match their positions in either the Julian or the Gregorian calendar since the Romans added the months January and February to the original ten-month March to December year of King Romulus.) The lengths of the months are the same as the lengths given them by Julius Caesar; however, the 10th, 20th, and 30th are singled out of each month as the end of a "décade" (group of ten). Individual days were assigned, instead of to the traditional saints, to people noteworthy for mostly secular achievements; 25 December is assigned to both Jesus and Newton.

Later editions of the almanac would switch to the Republican Calendar.

The days of the French Revolution and Republic saw many efforts to sweep away various trappings of the "ancien régime" (the old feudal monarchy); some of these were more successful than others. The new Republican government sought to institute, among other reforms, a new social and legal system, a new system of weights and measures (which became the metric system), and a new calendar. Amid nostalgia for the ancient Roman Republic, the theories of the Enlightenment were at their peak, and the devisers of the new systems looked to nature for their inspiration. Natural constants, multiples of ten, and Latin as well as Ancient Greek derivations formed the fundamental blocks from which the new systems were built.

The new calendar was created by a commission under the direction of the politician Charles-Gilbert Romme seconded by Claude Joseph Ferry and Charles-François Dupuis. They associated with their work the chemist Louis-Bernard Guyton de Morveau, the mathematician and astronomer Joseph-Louis Lagrange, the astronomer Joseph Jérôme Lefrançois de Lalande, the mathematician Gaspard Monge, the astronomer and naval geographer Alexandre Guy Pingré, and the poet, actor and playwright Fabre d'Églantine, who invented the names of the months, with the help of André Thouin, gardener at the Jardin des Plantes of the Muséum National d'Histoire Naturelle in Paris. As the rapporteur of the commission, Charles-Gilbert Romme presented the new calendar to the Jacobin-controlled National Convention on 23 September 1793, which adopted it on 24 October 1793 and also extended it proleptically to its epoch of 22 September 1792. It is because of his position as rapporteur of the commission that the creation of the republican calendar is attributed to Romme.

The calendar is frequently named the "French Revolutionary Calendar" because it was created during the Revolution, but this is a slight misnomer. Indeed, there was initially a debate as to whether the calendar should celebrate the Great Revolution, which began in July 1789, or the Republic, which was established in 1792. Immediately following 14 July 1789, papers and pamphlets started calling 1789 year of Liberty and the following years and . It was in 1792, with the practical problem of dating financial transactions, that the legislative assembly was confronted with the problem of the calendar. Originally, the choice of epoch was either 1 January 1789 or 14 July 1789. After some hesitation the assembly decided on 2 January 1792 that all official documents would use the "era of Liberty" and that the year of Liberty started on 1 January 1792. This usage was modified on 22 September 1792 when the Republic was proclaimed and the Convention decided that all public documents would be dated Year I of the French Republic. The decree of 2 January 1793 stipulated that the year II of the Republic began on 1 January 1793; this was revoked with the introduction of the new calendar, which set 22 September 1793 as the beginning of year . The establishment of the Republic was used as the epochal date for the calendar; therefore, the calendar commemorates the Republic, not the Revolution. In France, it is known as the "calendrier républicain" as well as the "calendrier révolutionnaire".

French coins of the period naturally used this calendar. Many show the year () in Arabic numbers, although Roman numerals were used on some issues. Year 11 coins typically have a date to avoid confusion with the Roman .

The French Revolution is usually considered to have ended with the coup of 18 Brumaire, Year (9 November 1799), the coup d'état of Napoleon Bonaparte against the established constitutional regime of the "Directoire".

The Concordat of 1801 re-established the Roman Catholic Church as an official institution in France, although not as the state religion of France. The concordat took effect from Easter Sunday, 28 Germinal, Year (8 April 1802); it restored the names of the days of the week to the ones from the Gregorian Calendar, and fixed Sunday as the official day of rest and religious celebration. However, the other attributes of the republican calendar, the months, and years, remained as they were.

The French Republic ended with the coronation of Napoleon I as "Empereur des Français" (Emperor of the French) on 11 Frimaire, Year (2 December 1804), but the republican calendar would remain in place for another year. Napoleon finally abolished the republican calendar with effect from 1 January 1806 (the day after 10 Nivôse Year ), a little over twelve years after its introduction. It was, however, used again briefly in the "Journal officiel" for some dates during a short period of the Paris Commune, 6–23 May 1871 (16 Floréal–3 Prairial Year ).

Years appear in writing as Roman numerals (usually), with epoch 22 September 1792, the beginning of the "Republican Era" (the day the French First Republic was proclaimed, one day after the Convention abolished the monarchy). As a result, Roman Numeral I indicates the first year of the republic, that is, the year before the calendar actually came into use. By law, the beginning of each year was set at midnight, beginning on the day the apparent autumnal equinox falls at the Paris Observatory.

There were twelve months, each divided into three ten-day weeks called "décades". The tenth day, "décadi", replaced Sunday as the day of rest and festivity. The five or six extra days needed to approximate the solar or tropical year were placed after the months at the end of each year and called complementary days. This arrangement was an almost exact copy of the calendar used by the Ancient Egyptians, though in their case the beginning of the year was marked by summer solstice rather than autumn equinox.

A period of four years ending on a leap day was to be called a "Franciade". The name "Olympique" was originally proposed but changed to Franciade to commemorate the fact that it had taken the revolution four years to establish a republican government in France.

The leap year was called "Sextile", an allusion to the "bissextile" leap years of the Julian and Gregorian calendars, because it contained a sixth complementary day.

Each day in the Republican Calendar was divided into ten hours, each hour into 100 decimal minutes, and each decimal minute into 100 decimal seconds. Thus an hour was 144 conventional minutes (more than twice as long as a conventional hour), a minute was 86.4 conventional seconds (44% longer than a conventional minute), and a second was 0.864 conventional seconds (13.6% shorter than a conventional second).

Clocks were manufactured to display this decimal time, but it did not catch on. Mandatory use of decimal time was officially suspended 7 April 1795, although some cities continued to use decimal time as late as 1801.

The numbering of years in the Republican Calendar by Roman numerals ran counter to this general decimalization tendency.

The Republican calendar year began the day the autumnal equinox occurred in Paris, and had twelve months of 30 days each, which were given new names based on nature, principally having to do with the prevailing weather in and around Paris.

Note: On many printed calendars of Year II (1793–94), the month of "Thermidor" was named "Fervidor" (from Latin "fervidus", "burning hot").

Most of the month names were new words coined from French, Latin, or Greek. The endings of the names are grouped by season. "Dor" means "giving" in Greek.

In Britain, a contemporary wit mocked the Republican Calendar by calling the months: Wheezy, Sneezy and Freezy; Slippy, Drippy and Nippy; Showery, Flowery and Bowery; Hoppy, Croppy and Poppy. The Scottish historian Thomas Carlyle suggested somewhat more serious English names in his 1837 work "", namely Vintagearious, Fogarious, Frostarious, Snowous, Rainous, Windous, Buddal, Floweral, Meadowal, Reapidor, Heatidor, and Fruitidor. Like the French originals, they are neologisms suggesting a meaning related to the season.

The month is divided into three "décades" or "weeks" of ten days each, named simply:

Décades were abandoned in Floréal an X (April 1802).

The Catholic Church used a calendar of saints, which named each day of the year after an associated saint. To reduce the influence of the Church, Fabre d'Églantine introduced a Rural Calendar in which each day of the year had a unique name associated with the rural economy, stated to correspond to the time of year. Every "décadi" (ending in 0) was named after an agricultural tool. Each "quintidi" (ending in 5) was named for a common animal. The rest of the days were named for "grain, pasture, trees, roots, flowers, fruits" and other plants, except for the first month of winter, Nivôse, during which the rest of the days were named after minerals.

Five extra days – six in leap years – were national holidays at the end of every year. These were originally known as "les sans-culottides" (after "sans-culottes"), but after year III (1795) as "les jours complémentaires":

Below are the Gregorian dates each Republican year ("an" in French) began while the calendar was in effect.


The calendar was abolished in the year XIV (1805). After this date, opinions seem to differ on the method by which the leap years would have been determined if the calendar were still in force. There are at least four hypotheses used to convert dates from the Gregorian calendar:

The following table shows when several years of the Republican Era begin on the Gregorian calendar, according to each of the four above methods:

For this calendar, the Romme method of calculating leap years is used. Other methods may differ by one day. Time may be cached and therefore not accurate. Decimal time is according to Paris mean time, which is 9 minutes 21 seconds (6.49 decimal minutes) ahead of Greenwich Mean Time.

Leap years in the calendar are a point of great dispute, due to the contradicting statements in the establishing decree stating:

and:
These two specifications are incompatible, as leap years defined by the autumnal equinox in Paris do not recur on a regular four-year schedule. Thus, the years , , and were observed as leap years, and the years and were also planned as such, even though they were five years apart.
A fixed arithmetic rule for determining leap years was proposed in the name of the Committee of Public Education by Gilbert Romme on 19 Floréal An  (8 May 1795). The proposed rule was to determine leap years by applying the rules of the Gregorian calendar to the years of the French Republic (years , , , etc. were to be leap years) except that year 4000 (the last year of ten 400-year periods) should be a common year instead of a leap year. Shortly thereafter, he was sentenced to the guillotine, and his proposal was never adopted and the original astronomical rule continued, which excluded any other fixed arithmetic rule. The proposal was intended to avoid uncertain future leap years caused by the inaccurate astronomical knowledge of the 1790s (even today, this statement is still valid due to the uncertainty in ΔT). In particular, the committee noted that the autumnal equinox of year 144 was predicted to occur at 11:59:40 pm local apparent time in Paris, which was closer to midnight than its inherent 3 to 4 minute uncertainty.

The calendar was abolished by an act dated 22 Fructidor an (9 September 1805) and signed by Napoleon, which referred to a report by Michel-Louis-Étienne Regnaud de Saint-Jean d'Angély and Jean Joseph Mounier, listing two fundamental flaws.
The report also noted that the 10-day décade was unpopular and had already been suppressed three years earlier in favor of the 7-day week, removing what was considered by some as one of the calendar's main benefits. The 10-day décade was unpopular with laborers because they received only one full day of rest out of ten, instead of one in seven, although they also got a half-day off on the fifth day. It also, by design, conflicted with Sunday religious observances.

Another criticism of the calendar was that despite the poetic names of its months, they are tied to the climate and agriculture of metropolitan France and therefore not applicable to France's overseas territories.

The "18 Brumaire" or "Brumaire" was the coup d'état of Napoléon Bonaparte on 18 Brumaire An (9 November 1799), which many historians consider as the end of the French Revolution. Karl Marx's 1852 essay "The Eighteenth Brumaire of Louis Napoleon" compares the coup d'état of 1851 of Louis Napoléon unfavorably to his uncle's earlier coup, with the statement "History repeats ... first as tragedy, then as farce".

Another famous revolutionary date is 9 Thermidor An (27 July 1794), the date the Convention turned against Robespierre, who, along with others associated with the Mountain, was guillotined the following day. Based on this event, the term "Thermidorian" entered the Marxist vocabulary as referring to revolutionaries who destroy the revolution from the inside and turn against its true aims. For example, Leon Trotsky and his followers used this term about Joseph Stalin.

Émile Zola's novel "Germinal" takes its name from the calendar's month of Germinal.

The seafood dish Lobster Thermidor was named after the 1891 play "Thermidor", set during the Revolution.

The French frigates of the "Floréal" class all bear names of Republican months.

The Convention of 9 Brumaire An , 30 October 1794, established the École normale supérieure. The date appears prominently on the entrance to the school.

The French composer Fromental Halévy was named after the feast day of 'Fromental' in the Revolutionary Calendar, which occurred on his birthday in year (27 May 1799).

Neil Gaiman's "The Sandman" series included a story called "Thermidor" that takes place in that month during the French Revolution.

The "Liavek" shared world series uses a calendar that is a direct translation of the French Republican calendar.

Sarah Monette's "Doctrine of Labyrinths" series borrows the Republican calendar for one of the two competing calendars (their usage splits between social classes) in the fictional city of Mélusine.

Jacques Rivette's 1974 film "Celine and Julie Go Boating" refers to the calendar and its hours of the day.

Alain Tanner's 1979 film "Messidor" presents a haphazard summer road trip of two young women in Switzerland.



</doc>
<doc id="11397" url="https://en.wikipedia.org/wiki?curid=11397" title="Freeman Dyson">
Freeman Dyson

Freeman John Dyson (born 15 December 1923) is a British theoretical physicist and mathematician known for his work in quantum electrodynamics, solid-state physics, astronomy and nuclear engineering. He is professor emeritus in the Institute for Advanced Study in Princeton, a Visitor of Ralston College and a member of the Board of Sponsors of the Bulletin of the Atomic Scientists.

Dyson originated several concepts that bear his name, such as Dyson's transform, a fundamental technique in additive number theory, which he developed as part of his proof of Mann's theorem; the Dyson tree, a hypothetical genetically-engineered plant capable of growing in a comet; the Dyson series, a perturbative series where each term is represented by Feynman diagrams; the Dyson sphere, a thought experiment that attempts to explain how a space-faring civilization would meet its energy requirements with a hypothetical megastructure that completely encompasses a star and captures a large percentage of its power output; and Dyson's eternal intelligence, a means by which an immortal society of intelligent beings in an open universe could escape the prospect of the heat death of the universe by extending subjective time to infinity while expending only a finite amount of energy. Dyson believes global warming is caused by increased carbon dioxide through burning fossil fuels, but is sceptical about the simulation models used to predict climate change, arguing that political efforts to reduce causes of climate change distract from other global problems that should take priority.

Born on 15 December 1923, at Crowthorne in Berkshire, Dyson is the son of the English composer George Dyson, who was later knighted. His mother had a law degree, and after Dyson was born she worked as a social worker. Dyson had one sibling, his older sister, Alice, who remembered him as a boy surrounded by encyclopedias and always calculating on sheets of paper. At the age of four he tried to calculate the number of atoms in the sun. As a child, he showed an interest in large numbers and in the solar system, and was strongly influenced by the book "Men of Mathematics" by Eric Temple Bell. Politically, Dyson says he was "brought up as a socialist".

From 1936 to 1941 Dyson was a scholar at Winchester College, where his father was Director of Music. At age 17 he studied mathematics with G.H. Hardy at Trinity College, Cambridge (where he won a scholarship at age 15) and at age 19 was assigned to war work in the Operational Research Section (ORS) of the Royal Air Force's Bomber Command, where he developed analytical methods for calculating the ideal density for bomber formations to help the Royal Air Force bomb German targets during the Second World War. After the war, Dyson was readmitted to Trinity College, Cambridge, where he obtained a BA degree in mathematics. From 1946 to 1949 he was a Fellow of his college, occupying rooms just below those of the philosopher Ludwig Wittgenstein, who resigned his professorship in 1947. In 1947 Dyson published two papers in number theory. Friends and colleagues describe him as shy and self-effacing, with a contrarian streak that his friends find refreshing but his intellectual opponents find exasperating. "I have the sense that when consensus is forming like ice hardening on a lake, Dyson will do his best to chip at the ice", Steven Weinberg said of him. His friend the neurologist and author Oliver Sacks said: "A favourite word of Freeman's about doing science and being creative is the word 'subversive'. He feels it's rather important not only to be not orthodox, but to be subversive, and he's done that all his life." 

On G. I. Taylor's advice and recommendation, Dyson moved to the United States in 1947 as a Commonwealth Fellow to earn a physics doctorate with Hans Bethe at Cornell University (1947–48). There he made the acquaintance of Richard Feynman. The budding English physicist recognized the brilliance of the flamboyant American, and attached himself as quickly as possible. He then moved to the Institute for Advanced Study (1948–49), before returning to England (1949–51), where he was a research fellow at the University of Birmingham.

In 1949 Dyson demonstrated the equivalence of two formulations of quantum electrodynamics (QED): Richard Feynman's diagrams and the operator method developed by Julian Schwinger and Shin'ichirō Tomonaga. He was the first person after their creator to appreciate the power of Feynman diagrams and his paper written in 1948 and published in 1949 was the first to make use of them. He said in that paper that Feynman diagrams were not just a computational tool but a physical theory and developed rules for the diagrams that completely solved the renormalization problem. Dyson's paper and also his lectures presented Feynman's theories of QED in a form that other physicists could understand, facilitating the physics community's acceptance of Feynman's work. J. Robert Oppenheimer, in particular, was persuaded by Dyson that Feynman's new theory was as valid as Schwinger's and Tomonaga's. Oppenheimer rewarded Dyson with a lifetime appointment at the Institute for Advanced Study, "for proving me wrong", in Oppenheimer's words.

Also in 1949, in related work, Dyson invented the Dyson series. It was this paper that inspired John Ward to derive his celebrated Ward–Takahashi identity.

In 1951 Dyson joined the faculty at Cornell as a physics professor, though he still had no doctorate, and in 1953 he received a permanent post at the Institute for Advanced Study in Princeton, New Jersey, where he has remained. In 1957 he became a naturalized citizen of the United States and renounced his British nationality. One reason he gave decades later is that his children born in the United States had not been recognized as British subjects.

From 1957 to 1961 Dyson worked on Project Orion, which proposed the possibility of space-flight using nuclear pulse propulsion. A prototype was demonstrated using conventional explosives, but the 1963 Partial Test Ban Treaty, which Dyson was involved in and supported, permitted only underground nuclear weapons testing, so the project was abandoned.

In 1958 Dyson was a member of the design team under Edward Teller for TRIGA, a small, inherently safe nuclear reactor used throughout the world in hospitals and universities for the production of medical isotopes.

A seminal paper by Dyson came in 1966, when, together with Andrew Lenard and independently of Elliott H. Lieb and Walter Thirring, he proved rigorously that the Pauli exclusion principle plays the main role in the stability of bulk matter. Hence it is not the electromagnetic repulsion between outer-shell orbital electrons that prevents two stacked wood blocks from coalescing into a single piece, but the exclusion principle applied to electrons and protons that generates the classical macroscopic normal force. In condensed matter physics, Dyson also analysed the phase transition of the Ising model in 1 dimension and spin waves.

Dyson also did work in a variety of topics in mathematics, such as topology, analysis, number theory and random matrices. In 1973 the number theorist Hugh Lowell Montgomery was visiting the Institute for Advanced Study and had just made his pair correlation conjecture concerning the distribution of the zeros of the Riemann zeta function. He showed his formula to the mathematician Atle Selberg, who said that it looked like something in mathematical physics and that Montgomery should show it to Dyson, which he did. Dyson recognized the formula as the pair correlation function of the Gaussian unitary ensemble, which physicists have studied extensively. This suggested that there might be an unexpected connection between the distribution of primes (2, 3, 5, 7, 11,  ...) and the energy levels in the nuclei of heavy elements such as uranium.

Around 1979 Dyson worked with the Institute for Energy Analysis on climate studies. This group, under Alvin Weinberg's direction, pioneered multidisciplinary climate studies, including a strong biology group. Also during the 1970s, Dyson worked on climate studies conducted by the JASON defense advisory group.

Dyson retired from the Institute for Advanced Study in 1994. In 1998 he joined the board of the Solar Electric Light Fund. he was president of the Space Studies Institute, the space research organization founded by Gerard K. O'Neill; as of 2013 he is on its board of trustees. Dyson is a longtime member of the JASON group.

Dyson has won numerous scientific awards, but never a Nobel Prize. Nobel physics laureate Steven Weinberg has said that the Nobel committee has "fleeced" Dyson, but Dyson himself remarked in 2009, "I think it's almost true without exception if you want to win a Nobel Prize, you should have a long attention span, get hold of some deep and important problem and stay with it for ten years. That wasn't my style." Dyson is a regular contributor to "The New York Review of Books".

In 2012 Dyson published (with William H. Press) a fundamental new result about the prisoner's dilemma in the Proceedings of the National Academy of Sciences of the United States of America.

With his first wife, the Swiss mathematician Verena Huber-Dyson, Dyson had two children, Esther and George. In 1958 he married Imme Jung, a masters runner, and they had four more children, Dorothy, Mia, Rebecca, and Emily Dyson.

Dyson's eldest daughter, Esther, is a digital technology consultant and investor; she has been called "the most influential woman in all the computer world". His son, George, is a historian of science, one of whose books is "Project Orion: The Atomic Spaceship 1957–1965".

Dyson admits his record as a prophet is mixed, but thinks it is better to be wrong than vague, and that in meeting the world's material needs, technology must be beautiful and cheap.

Dyson has coined the term "green technologies", based on biology instead of physics or chemistry, to describe new species of microorganisms and plants designed to meet human needs. He argues that such technologies would be based on solar power rather than the fossil fuels whose use he sees as part of what he calls "gray technologies" of industry. He believes that genetically engineered crops, which he describes as green, can help end rural poverty, with a movement based in ethics to end the inequitable distribution of wealth on the planet.

Dyson favors the dual origin theory: that life first formed as cells, then enzymes, and finally, much later, genes. This was first propounded by the Russian Alexander Oparin. J. B. S. Haldane developed the same theory independently. In Dyson's version of the theory life evolved in two stages, widely separated in time. Because of the biochemistry he regards it as too unlikely that genes could have developed fully blown in one process. Current cells contain adenosine triphosphate or ATP and adenosine 5'-monophosphate or AMP, which greatly resemble each other but have completely different functions. ATP transports energy around the cell, and AMP is part of RNA and the genetic apparatus. Dyson proposes that in a primitive early cell containing ATP and AMP, RNA and replication were invented accidentally because of the similarity between AMP and RNA. He suggests that AMP was produced when ATP molecules lost two of their phosphate radicals, and then one cell somewhere performed Eigen's experiment and produced RNA.

There is no direct evidence for the dual origin theory, because once genes developed, they took over, obliterating all traces of the earlier forms of life. In the first origin, the cells were probably just drops of water held together by surface tension, teeming with enzymes and chemical reactions, and having a primitive kind of growth or replication. When the liquid drop became too big, it split into two drops. Many complex molecules formed in these "little city economies" and the probability that genes would eventually develop in them was much greater than in the prebiotic environment.

In 1960 Dyson wrote a short paper for the journal "Science" titled "Search for Artificial Stellar Sources of Infrared Radiation". In it he speculated that a technologically advanced extraterrestrial civilization might surround its native star with artificial structures to maximize the capture of the star's energy. Eventually the civilization would enclose the star, intercepting electromagnetic radiation with wavelengths from visible light downward and radiating waste heat outward as infrared radiation. One method of searching for extraterrestrial civilizations would be to look for large objects radiating in the infrared range of the electromagnetic spectrum.

Dyson conceived that such structures would be clouds of asteroid-sized space habitats, though science fiction writers have preferred a solid structure: either way, such an artefact is often called a Dyson sphere, although Dyson used the term "shell". Dyson says that he used the term "artificial biosphere" in the article to mean a habitat, not a shape. The general concept of such an energy-transferring shell had been advanced decades earlier by author Olaf Stapledon in his 1937 novel "Star Maker", a source Dyson has credited publicly.

Dyson has also proposed the creation of a "Dyson tree", a genetically engineered plant capable of growing on a comet. He suggested that comets could be engineered to contain hollow spaces filled with a breathable atmosphere, thus providing self-sustaining habitats for humanity in the outer Solar System.

Dyson has been interested in space travel since he was a child, reading such science fiction classics as Olaf Stapledon's "Star Maker". As a young man, he worked for General Atomics on the nuclear-powered Orion spacecraft. He hoped Project Orion would put men on Mars by 1965, Saturn by 1970. For a quarter-century Dyson has been unhappy about how the government conducts space travel:
He still hopes for cheap space travel, but is resigned to waiting for private entrepreneurs to develop something new and inexpensive.

Dyson also proposed the use of bioengineered space colonies to colonize the Kuiper Belt on the outer edge of our Solar System. He proposed that habitats could be grown from space hardened spores. The colonies could then be warmed by large reflector plant leaves that could focus the dim, distant sunlight back on the growing colony. This was illustrated by Pat Rawlings on the cover of the National Space Society's "Ad Astra" magazine.

Dyson proposed that an immortal group of intelligent beings could escape the prospect of heat death by extending time to infinity while expending only a finite amount of energy. This is also known as the Dyson scenario.

His concept "Dyson's transform" led to one of the most important lemmas of Olivier Ramaré's theorem: that every even integer can be written as a sum of no more than six primes.

The Dyson series, the formal solution of an explicitly time-dependent Schrödinger equation by iteration, and the corresponding Dyson time-ordering operator formula_1 an entity of basic importance in the mathematical formulation of quantum mechanics, are also named after Dyson.

Dyson and Hugh Montgomery discovered together an intriguing connection between quantum physics and Montgomery's pair correlation conjecture about the zeros of the Zeta function. The primes 2, 3, 5, 7, 11, 13, 17, 19, ... are described by the Riemann Zeta function, and Dyson had previously developed a description of quantum physics based on m by m arrays of totally random numbers. Montgomery and Dyson discovered that the "eigenvalues" of these matrices are spaced apart in exactly the same manner as Montgomery conjectured for the nontrivial zeros of the Zeta function. Andrew Odlyzko has verified the conjecture on a computer, using his Odlyzko–Schönhage algorithm to calculate many zeros. Dyson recognized this connection because of a number-theory question Montgomery asked him. Dyson had published results in number theory in 1947, while a Fellow at Trinity College, Cambridge, and so was able to understand Montgomery's question. If Montgomery had not been visiting the Institute for Advanced Study that week, this connection might not have been discovered.

There are in nature one, two, and three dimensional quasicrystals. Mathematicians define a quasicrystal as a set of discrete points whose Fourier transform is also a set of discrete points. Odlyzko has done extensive computations of the Fourier transform of the nontrivial zeros of the Zeta function, and they seem to form a one-dimensional quasicrystal. This would in fact follow from the Riemann hypothesis.

In number theory and combinatorics rank of a partition of a positive integer is a certain integer associated with the partition. Dyson introduced the concept in a paper published in the journal "Eureka". It was presented in the context of a study of certain congruence properties of the partition function discovered by the mathematician Srinivasa Ramanujan. A different concept, sharing the same name, is used in combinatorics, where the rank is taken to be the size of the Durfee square of the partition.

In number theory, the crank of a partition is a certain integer associated with the partition in number theory. Dyson first introduced the term without a definition in a 1944 paper in a journal published by the Mathematics Society of Cambridge University. He then gave a list of properties this yet-to-be-defined quantity should have. In 1988, George E. Andrews and Frank Garvan discovered a definition for the crank satisfying the properties Dyson had hypothesized.

Astrochicken is the name given to a thought experiment Dyson expounded in his book "Disturbing the Universe" (1979). He contemplated how humanity could build a small, self-replicating automaton that could explore space more efficiently than a manned craft could. He attributed the general idea to John von Neumann, based on a lecture von Neumann gave in 1948 titled "The General and Logical Theory of Automata". Dyson expanded on von Neumann's automata theories and added a biological component.

Dyson has suggested that philosophers can be broadly, if simplistically, divided into splitters and lumpers. These roughly correspond to materialists, who imagine the world divided into atoms, and Platonists, who regard it as made up of ideas.

Helios is a design for a spacecraft propulsion system in which small (0.1 kiloton) nuclear bombs would be detonated in a chamber roughly 30 feet (9.1 m) in diameter. Water would be injected into the chamber, superheated by the explosion and expelled for thrust. The Helios propulsion system was conceived originally by Dyson.

Dyson agrees that anthropogenic global warming exists and that one of its main causes is the increase of carbon dioxide in the atmosphere resulting from the burning of fossil fuels. He has said that in many ways increased atmospheric carbon dioxide is beneficial, and that it is increasing biological growth, agricultural yields and forests. He believes that existing simulation models of climate change fail to account for some important factors, and that the results thus contain too great a margin of error to reliably predict future trends.

Dyson's views on global warming have been criticized. Climate scientist James Hansen said that Dyson "doesn't know what he's talking about... If he's going to wander into something with major consequences for humanity and other life on the planet, then he should first do his homework—which he obviously has not done on global warming." Dyson replied that "[m]y objections to the global warming propaganda are not so much over the technical facts, about which I do not know much, but it's rather against the way those people behave and the kind of intolerance to criticism that a lot of them have."

In 2008 Dyson endorsed the now common usage of "global warming" as synonymous with global anthropogenic climate change, but argued that political efforts to reduce the causes of climate change distract from other global problems that should take priority.

Since originally taking interest in climate studies in the 1970s, Dyson has suggested that carbon dioxide levels in the atmosphere could be controlled by planting fast-growing trees. He calculates that it would take a trillion trees to remove all carbon from the atmosphere. In a 2014 interview he said, "What I'm convinced of is that we don't understand climate ... It will take a lot of very hard work before that question is settled."

Dyson is a member of the academic advisory council of the Global Warming Policy Foundation, a climate sceptic think tank chaired by Nigel Lawson.

At the British Bomber Command, Dyson and colleagues proposed removing two gun turrets from the RAF Lancaster bombers, to cut the catastrophic losses due to German fighters in the Battle of Berlin. A Lancaster without turrets could fly faster and be much more maneuverable.

On hearing the news of the bombing of Hiroshima:

In 1967, in his capacity as a military adviser, Dyson wrote an influential paper on the issue of possible US use of tactical nuclear weapons in the Vietnam War. When a general said in a meeting, "I think it might be a good idea to throw in a nuke now and then, just to keep the other side guessing ..." Dyson became alarmed and obtained permission to write a report on the pros and cons of using such weapons from a purely military point of view. (This report, "Tactical Nuclear Weapons in Southeast Asia", published by the Institute for Defense Analyses, was obtained, with some redactions, by the Nautilus Institute for Security and Sustainability under the Freedom of Information act in 2002.) It was sufficiently objective that both sides in the debate based their arguments on it. Dyson says that the report showed that, even from a narrow military point of view, the US was better off not using nuclear weapons. Dyson stated on the Dick Cavett show that the use of nuclear weaponry was a bad idea for the US at the time because "our targets were large and theirs were small." (His unstated assumption was that the Soviets would respond by supplying tactical nukes to the other side.)

Dyson opposed the Vietnam War, the Gulf War and the invasion of Iraq. He supported Barack Obama in the 2008 US presidential election and "The New York Times" has described him as a political liberal. He was one of 29 leading US scientists who wrote Obama a strongly supportive letter about his administration's 2015 nuclear deal with Iran.

Dyson was raised in what he has described as a “watered-down Church of England Christianity”. He is a nondenominational Christian and has attended various churches, from Presbyterian to Roman Catholic. Regarding doctrinal or Christological issues, he has said, "I am neither a saint nor a theologian. To me, good works are more important than theology."

Dyson partially disagrees with the famous remark by his fellow physicist Steven Weinberg that "With or without religion, good people can behave well and bad people can do evil; but for good people to do evil—that takes religion."

While Dyson has called himself a Christian, he identifies himself as agnostic about some of the specifics of his faith. For example, in reviewing "The God of Hope and the End of the World" by John Polkinghorne, Dyson wrote:

In "The God Delusion" (2006), biologist Richard Dawkins criticized Dyson for accepting the religious Templeton Prize in 2000: "It would be taken as an endorsement of religion by one of the world's most distinguished physicists." In 2000 Dyson declared that he is a (non-denominational) Christian, and he has disagreed with Dawkins on several occasions, as when he criticized Dawkins' understanding of evolution.











</doc>
<doc id="11399" url="https://en.wikipedia.org/wiki?curid=11399" title="Fourth Council of the Lateran">
Fourth Council of the Lateran

The Fourth Council of the Lateran was convoked by Pope Innocent III with the papal bull "Vineam domini Sabaoth" of 19 April 1213, and the Council gathered at Rome's Lateran Palace beginning 11 November 1215. Due to the great length of time between the Council's convocation and meeting, many bishops had the opportunity to attend. It is considered by the Catholic Church to have been the twelfth ecumenical council and is sometimes called the "Great Council" or "General Council of Lateran" due to the presence of 71 patriarchs and metropolitan bishops, 412 bishops, 900 abbots and priors together with representatives of several monarchs. 

During this council, the teaching on transubstantiation— a doctrine of the Catholic Church which describes the method by which the bread and wine offered in the sacrament of the Eucharist becomes the actual blood and body of Christ— was defined. It also infamously was the first to require from Jews (and Muslims) to wear distinctive clothing.

Lateran IV stands as the high-water mark of the medieval papacy. Its political and ecclesiastical decisions endured down to the Council of Trent while modern historiography has deemed it the most significant papal assembly of the Later Middle Ages. The Fourth Lateran Council was the largest and most representative of the medieval councils to that date.

In summoning the bishops to a general council, Innocent III emphasized that reforms must be made in the Church and that a new crusade to the Holy Land must be launched. He also reminded them that it was not appropriate that their retinue include birds and hunting dogs.

The agenda laid out in "Vineam domini Sabaoth" included reform of the Church, the stamping out of heresy, establishing peace and liberty, and calling for a new crusade. During this council, the doctrine of transubstantiation— a Church doctrine which describes the method by which the bread and wine offered in the sacrament of the Eucharist becomes the actual blood and body of Christ— was infallibly defined. The scholarly consensus is that the constitutions were drafted by Innocent III himself.

In secular matters, the Council confirmed the elevation of Frederick II as Holy Roman Emperor. 

There were violent scenes between the partisans of Simon de Montfort among the French bishops and those of the Count of Toulouse. Raymond VI of Toulouse, his son (afterwards Raymond VII), and Raymond-Roger of Foix attended the Council to dispute the threatened confiscation of their territories; Bishop Foulques and Guy de Montfort (brother of Simon de Montfort) argued in favour of the confiscation. All of Raymond VI's lands were confiscated, save Provence, which was kept in trust to be restored to his son, Raymond VII. Pierre-Bermond of Sauve's claim to Toulouse was rejected, and Toulouse was awarded to de Montfort; the lordship of Melgueil was separated from Toulouse and entrusted to the bishops of Maguelonne.

Canons presented to the Council included:





In addition, it threatened excommunication to those who supplied ships, arms, and other war materials to the Saracens.

Effective application of the decrees varied according to local conditions and customs.



</doc>
<doc id="11401" url="https://en.wikipedia.org/wiki?curid=11401" title="Franconia">
Franconia

Franconia (; ) is a region in Germany, characterised by its culture and language, and may be roughly associated with the areas in which the East Franconian dialect group, colloquially referred to as "Franconian" (German: ""Fränkisch""), is spoken. There are several other Franconian dialects, but only the East Franconian ones are colloquially referred to as "Franconian".

"Core Franconia" is constituted by the three administrative regions of Lower, Middle, and Upper Franconia (largest cities: Würzburg, Nuremberg, and Bamberg, respectively) of the state of Bavaria. Also part of the cultural region of Franconia are the adjacent Franconian-speaking regions of the otherwise Thuringian and Upper Saxon-speaking state of Thuringia (South Thuringia, south of the Rennsteig ridge; largest city: Suhl), the Franconian-speaking parts of Heilbronn-Franconia (largest city: Schwäbisch Hall) in the state of Baden-Württemberg, and small parts of the state of Hesse.

Those parts of the region of Vogtland lying in the state of Saxony (largest city: Plauen) are sometimes regarded as Franconian as well, because the Vogtlandian dialects are mostly East Franconian. The inhabitants of Saxon Vogtland, however, mostly do not consider themselves as "Franconian". On the other hand, the inhabitants of the Hessian-speaking parts of Lower Franconia west of the Spessart mountains (largest city: Aschaffenburg) do consider themselves as "Franconian". Heilbronn-Franconia's largest city of Heilbronn and its surrounding areas being South Franconian-speaking, those are only sometimes regarded as Franconian. 

Franconia's largest city and unofficial capital is Nuremberg, which is contiguous with Erlangen and Fürth, with which it forms a large conurbation, with around 1.3 million inhabitants.

The German word "Franken"—Franconians—also refers to the ethnic group, which is mainly to be found in this region. They are to be distinguished from the Germanic tribe of the Franks, and historically formed their easternmost settlement area. The origins of Franconia lie in the settlement of the Franks from the 6th century in the area probably populated until then mainly by the Elbe Germanic people in the Main river area, known from the 9th century as East Francia ("Francia Orientalis"). In the Middle Ages the region formed much of the eastern part of the Duchy of Franconia and, from 1500, the Franconian Circle. In the course of the restructuring of the south German states by Napoleon after the demise of the Holy Roman Empire, most of Franconia was awarded to Bavaria.

The German name for Franconia, "Franken", comes from the dative plural form of "Franke," a member of the Germanic tribe known as the Franks. 
The name of the Franks in turn derives from a word meaning "daring, bold", cognate with old Norwegian "frakkr", "quick, bold".
In the 9th century the realm of the Franks was divided. The German region of Franconia corresponds to the region along the river Main which was the original territory of the Ripuarian Franks.
English distinguishes between "Franks" (the early medieval Germanic people) and "Franconians" in reference to the high medieval stem duchy, following Middle Latin use of "Francia" for France vs. "Franconia" for the German duchy, while in German the name "Franken" is equally used for both, while the French are called "Franzosen", after Old French "françois", from Latin "franciscus", from Late Latin "Francus", from "Frank", the Germanic tribe.

The Franconian lands lie principally in Bavaria, north and south of the sinuous River Main which, together with the left (southern) Regnitz tributary, including its Rednitz and Pegnitz headstreams, drains most of Franconia. Other large rivers include the upper Werra in Thuringia and the Tauber, as well as the upper Jagst and Kocher streams in the west, both right tributaries of the Neckar. In southern Middle Franconia, the Altmühl flows towards the Danube; the Rhine–Main–Danube Canal crosses the European Watershed. The man-made Franconian Lake District has become a popular destination for day-trippers and tourists.

The landscape is characterized by numerous "Mittelgebirge" ranges of the German Central Uplands. The Western natural border of Franconia is formed by the Spessart and Rhön Mountains, separating it from the former Rhenish Franconian lands around Aschaffenburg (officially part of Lower Franconia), whose inhabitants speak Hessian dialects. To the north rise the Rennsteig ridge of the Thuringian Forest, the Thuringian Highland and the Franconian Forest, the border with the Upper Saxon lands of Thuringia. The Franconian lands include the present-day South Thuringian districts of Schmalkalden-Meiningen, Hildburghausen and Sonneberg, the historical "Gau" of Grabfeld, held by the House of Henneberg from the 11th century and later part of the Wettin duchy of Saxe-Meiningen.

In the east, the Fichtel Mountains lead to Vogtland, Bohemian Egerland ("Chebsko") in the Czech Republic, and the Bavarian Upper Palatinate. The hills of the Franconian Jura in the south mark the border with the Upper Bavarian region ("Altbayern"), historical Swabia, and the Danube basin. The northern parts of the Upper Bavarian Eichstätt District, territory of the historical Bishopric of Eichstätt, are also counted as part of Franconia.

In the west, Franconia proper comprises the Tauber Franconia region along the Tauber river, which is largely part of the Main-Tauber-Kreis in Baden-Württemberg. The state's larger Heilbronn-Franken region also includes the adjacent Hohenlohe and Schwäbisch Hall districts. In the city of Heilbronn, beyond the Haller Ebene plateau, South Franconian dialects are spoken. Furthermore, in those easternmost parts of the Neckar-Odenwald-Kreis which had formerly belonged to the Bishopric of Würzburg, the inhabitants have preserved their Franconian identity. Franconian areas in East Hesse along Spessart and Rhön comprise Gersfeld and Ehrenberg.

The two largest cities of Franconia are Nuremberg and Würzburg. Though located on the southeastern periphery of the area, the Nuremberg metropolitan area is often identified as the economic and cultural centre of Franconia. Further cities in Bavarian Franconia include Fürth, Erlangen, Bayreuth, Bamberg, Aschaffenburg, Schweinfurt, Hof, Coburg, Ansbach and Schwabach. The major (East) Franconian towns in Baden-Württemberg are Schwäbisch Hall on the Kocher — the imperial city declared itself "Swabian" in 1442 — and Crailsheim on the Jagst river. The main towns in Thuringia are Suhl and Meiningen.

Franconia may be distinguished from the regions that surround it by its peculiar historical factors and its cultural and especially linguistic characteristics, but it is not a political entity with a fixed or tightly defined area. As a result, it is debated whether some areas belong to Franconia or not. Pointers to a more precise definition of Franconia's boundaries include: the territories covered by the former Duchy of Franconia and former Franconian Circle, the range of the East Franconian dialect group, the common culture and history of the region and the use of the Franconian Rake on coats of arms, flags and seals. However, a sense of popular consciousness of being Franconian is only detectable from the 19th century onwards, which is why the circumstances of the emergence of a Frankish identity are disputed. Franconia has many cultural peculiarities which have been adopted from other regions and further developed.

The following regions are counted as part of Franconia today: the Bavarian provinces of Lower Franconia, Upper Franconia and Middle Franconia, the municipality of Pyrbaum in the county of Neumarkt in der Oberpfalz, the northwestern part of the Upper Bavarian county of Eichstätt (covering the same area as the old county of Alt-Eichstätt), the East Franconian counties of South Thuringia, parts of Fulda and the Odenwaldkreis in Hesse, the Baden-Württemberg regions of Tauber Franconia and Hohenlohe as well as the region around the Badenian Buchen.

In individual cases the membership of some areas is disputed. These include the Bavarian language area of Alt-Eichstätt and the Hessian-speaking region around Aschaffenburg, which was never part of the Franconian Imperial Circle. The affiliation of the city of Heilbronn, whose inhabitants do not call themselves Franks, is also controversial. Moreover, the sense of belonging to Franconia in the Frankish-speaking areas of Upper Palatinate, South Thuringia and Hesse is sometimes less marked.

The region of Franconia is divided among the states of Hesse, Thuringia, Bavaria and Baden-Württemberg. The largest part of Franconia, both by population and area, belongs to the Free State of Bavaria and is divided into the three provinces ("Regierungsbezirke") of Middle Franconia (capital: Ansbach), Upper Franconia (capital: Bayreuth) and Lower Franconia (capital: Würzburg). The name of these provinces, as in the case of Upper and Lower Bavaria, refers to their situation with respect to the River Main. Thus Upper Franconia lies on the upper reaches of the river, Lower Franconia on its lower reaches and Middle Franconia lies in between, although the Main itself does not flow through Middle Franconia. Where the boundaries of these three provinces meet (the 'tripoint') is the "Dreifrankenstein" ("Three Franconias Rock").
Small parts of Franconia also belong to the Bavarian provinces of Upper Palatinate and Upper Bavaria.

The Franconian territories of Baden-Württemberg are the regions of Tauber Franconia and Hohenlohe (which belong to the Heilbronn-Franconia Region with its office in Heilbronn and form part of the Stuttgart Region) and the area around the Badenian Buchen in the Rhein-Neckar Region.

The Franconian parts of Thuringia (Henneberg Franconia) lie within the Southwest Thuringia Planning Region.

The Franconian regions in Hesse form the smaller parts of the counties of Fulda (Kassel province) and the Odenwaldkreis (Darmstadt province), or lie on the borders with Bavaria or Thuringia.

The two most important rivers of the region are the Main and its primary tributary, the Regnitz. The tributaries of these two rivers in Franconia are the Tauber, Pegnitz, Rednitz and Franconian Saale. Other major rivers in the region are the Jagst and Kocher in Hohenlohe-Franconia, which empty into the Neckar north of Heilbronn in Baden-Württemberg, the Altmühl and the Wörnitz in Middle Franconia, both tributaries of the Danube, and the upper and middle reaches of the Werra, the right-hand headstream of the Weser. In the northeast of Upper Franconia rise two left-hand tributaries of the Elbe: the Saxon Saale and the Eger.

The Main-Danube Canal connects the Main and Danube across Franconia, running from Bamberg via Nuremberg to Kelheim. It thus complements the Rhine, Main and Danube, helping to ensure a continuous navigable waterway between the North Sea and the Black Sea. In Franconia, there are only a few, often very small, natural lakes. This is due to fact that most natural lakes in Germany are glacial or volcanic in origin, and Franconia escaped both influences in recent earth history. Among the largest waterbodies are reservoirs, which are mostly used as water reserves for the relatively dry landscapes of Franconia. These includes the waters of the Franconian Lake District, which was established in the 1970s and is also a tourist attraction. The heart of these lakes is the Großer Brombachsee, which has an area of 8.7 km² and is thus the largest waterbody in Franconia by surface area.

Several Central Upland ranges dominate the Franconian countryside. In the southeast,Franconia is shielded from the rest of Bavaria by the Franconian Jura. In the east, the Fichtel Mountains form the border; in the north are Franconian Forest, the Thuringian Forest, the Rhön Mountains and the Spessart form a kind of natural barrier. To the west are the Franconian Heights and the Swabian-Franconian Forest. In the Franconian part of South Hesse is the Odenwald. Parts of the southern Thuringian Forest border on Franconia. The most important hill ranges in the interior of the region are the Steigerwald and the Franconian Jura with their sub-ranges of Hahnenkamm and Franconian Switzerland. The highest mountain in Franconia is the Schneeberg in the Fichtel Mountains which is . Other well-known mountains include the Ochsenkopf (1,024m), the Kreuzberg (927.8m) and the Hesselberg (689.4m). The outliers of the region include the Hesselberg and the Gleichberge. The lowest point in Franconia is the water level of the River Main in Kahl which lies at a height of 100 metres above sea level.

In addition to the hill and mountain ranges, there are also several very level areas, including the Middle Franconian Basin and the Hohenlohe Plain. In the south of Franconia are smaller parts of the flat Nördlinger Ries, one of the best preserved impact craters on earth.

Franconia's flora is dominated by deciduous and coniferous forests. Natural forests in Franconia occur mainly in the ranges of the Spessart, Franconian Forest, Odenwald and Steigerwald. The Nuremberg "Reichswald" is another great forest, located within the metropolitan region of Nuremberg. Other large areas of forest in the region are the Mönchswald, the Reichsforst in the Fichtel Mountains and the Selb Forest. In the river valleys along the Main and Tauber, the countryside was developed for viticulture. In Spessart there are great oak forests. Also widespread are calcareous grasslands, extensively used pastures on very oligotrophic, poor sites. In particular, the southern Franconian Jura, with the Altmühl Valley, is characterized by poor grassland of this type. Many of these places have been designated as a protected areas.

Franconia has several regions with sandy habitats that are unique for south Germany and are protected as the so-called Sand Belt of Franconia or "Sandachse Franken". When the Altmühlsee reservoir was built, a bird island was created and designated as a nature reserve where a variety of birds nest. Another important reserve is the Black Moor in the Rhön, which is one of the most important bog areas in Central Europe. A well known reserve is the Luisenburg Rock Labyrinth at Wunsiedel, a felsenmeer of granite blocks up to several metres across. The establishment of the first Franconian national park in the Steigerwald caused controversy and its designation was rejected in July 2011 by the Bavarian government. The reason was the negative attitude of local population. Conservationists are now demanding protection for parts of the Steigerwald by nominating it for a World Heritage Site. There are several nature parks in Franconia, including the Altmühl Valley Nature Park, which, since 1969, has been one of the largest in Germany.

Other nature parks are the Swabian-Franconian Forest Nature Park in Baden-Württemberg, and the nature parks of Bavarian Rhön, Fichtel Mountains, Franconian Heights, Franconian Forest, Franconian Switzerland-Veldenstein Forest, Haßberge, Spessart and Steigerwald in Bavaria, as well as the Bergstraße-Odenwald Nature Park which straddles Bavaria, Baden-Württemberg and Hesse. Nature parks cover almost half the area of Franconia.

In 1991 UNESCO recognised the Rhön as a biosphere reserve. Among the most picturesque geotopes in Bavaria, are the Franconian sites of "Fossa Carolina", the Twelve Apostle Rocks ("Zwölf-Apostel-Felsen"), the Ehrenbürg, the cave ruins of Riesenburg and the lake of Frickenhäuser See. The European Bird Reserves in Franconia are found mainly in uplands like the Steigerwald, in large forests like Nuremberg's Imperial Forest or along rivers like the Altmühl. There are also numerous Special Areas of Conservation and protected landscapes. In Franconia there are very many tufas, raised stream beds near river sources within the karst landscape that are known as 'stone runnels' ("Steinerne Rinnen"). There are protected examples at Heidenheim and Wolfsbronn.

Like large parts of Germany, Franconia only has a few large species of wild animal. Forest dwellers include various species of marten, fallow deer, red deer, roe deer, wild boar and fox. In natural areas such as the Fichtel mountains there are populations of lynx and capercaillie, and beaver and otter have grown in numbers. There are occasional sightings of animals that had long been extinct in Central Europe, for example, the wolf.

Only in the extreme northeast of Franconia and in the Spessart are there Variscan outcrops of the crystalline basement, which were uplifted from below the surface when the Alps exerted a northwards-oriented pressure. These are rocks of pre-Permian vintage, which were folded during various stages of Variscan orogeny in the Late Palaeozoic - before about 380 to 300 million years ago - and, in places, were metamorphosed under high pressure and temperature or were crystallized by ascending magma in the Earth's crust. Rocks which were unchanged or only lightly metamorphosed, because they had been deformed at shallow crustal depths, include the Lower Carboniferous shale and greywacke of Franconian Forest. The Fichtel mountains, the Münchberg Plateau and the Spessart, by contrast, have more metamorphic rocks (phyllite, schist, amphibolite, gneiss). The Fichtel mountains are also characterized by large granite bodies, called post-kinematic plutons which, in the late phase of Variscan orogeny, intruded into the metamorphic rocks. In most cases these are S-type granites whose melting was caused by heated-up sedimentary rocks sunk deep into the Earth's crust. While the Fichtel and Franconian Forest can be assigned to the Saxo-Thuringian Zone of Central European Variscan orogeny, the Spessart belongs to the Central German Crystalline Zone. The Münchberg mass is variously attributed to the Saxo-Thuringian or Moldanubian Zones.

A substantially larger part of the shallow subsurface in Franconia comprises Mesozoic, unmetamorphosed, unfolded rocks of the South German Scarplands. The regional geological element of the South German Scarplands is the Franconian Platform ("Süddeutsche Großscholle"). At the so-called Franconian Line, a significant fault line, the Saxo-Thuringian-Moldanubian basement was uplifted in places up to 2000 m above the Franconian Platform. The western two-thirds of Franconia is dominated by the Triassic with its sandstones, siltstones and claystones (so-called siliciclastics) of the bunter sandstone; the limestones and marls of the Muschelkalk and the mixed, but predominantly siliciclastic, sedimentary rocks of the Keuper. In the Rhön, the Triassic rocks are overlain and intruded by volcanic rock (basalts, basanites, phonolites and trachytes) of the Tertiary. The eastern third of Franconia is dominated by the Jurassic rocks of the Franconian Jura, with the dark shales of the Black Jura, the shales and ferruginous sandstones of the Brown Jura and, the weathering-resistant limestones and dolomitic rocks of the White Jura, which stand out from the landscape and form the actual ridge of the Franconian Jura itself. In the Jura, mostly siliciclastic sedimentary rocks formed in the Cretaceous have survived.

The Mesozoic sediments have been deposited in largescale basin areas. During the Triassic, the Franconian part of these depressions was often part of the mainland, in the Jurassic it was covered for most of the time by a marginal sea of the western Tethys Ocean. At the time when the limestones and dolomites of the White Jura were being deposited, this sea was divided into sponge reefs and intervening lagoons. The reef bodies and the fine-grained lagoon limestones and marls are the material from which the majority of the Franconian Jura is composed today. Following a drop in the sea level towards the end of the Upper Jurassic, larger areas also became part of the mainland at the beginning of the subsequent Cretaceous period. During the Upper Cretaceous, the sea advanced again up to the area of the Franconian Jura. At the end of the Cretaceous, the sea then retreated again from the region. In addition, large parts of South and Central Germany experienced a general uplift -or in areas where the basement had broken through a substantial uplift - the course of formation of the Alps during the Tertiary. Since then, Franconia has been mainly influenced by erosion and weathering (especially in the Jura in the form of karst), which has ultimately led to formation of today's landscapes.

The oldest macrofossils in Franconia, which are also the oldest in Bavaria, are archaeocyatha, sponge-like, goblet-shaped marine organisms, which were discovered in 2013 in a limestone block of Late Lower Cambrian age, about 520 million years old. The block comes from the vicinity Schwarzenbach am Wald from the so-called Heinersreuth Block Conglomerate ("Heinersreuther Blockkonglomerat"), a Lower Carboniferous wildflysch. However, the aforementioned archaeocyathids are not three-dimensional fossils, but two-dimensional thin sections. These thin sections had already been prepared and investigated in the 1970s but the archaeocyathids among them were apparently overlooked at that time.

Better known and more highly respected fossil finds in Franconia come from the unfolded sedimentary rocks of the Triassic and Jurassic. The bunter sandstone, however, only has a relatively small number of preserved whole fossils. Much more commonly, it contains trace fossils, especially the tetrapod footprints of "Chirotherium". The type locality for these animal tracks is Hildburghausen in the Thuringian part of Franconia, where it occurs in the so-called Thuringian Chirotherium Sandstone ("Thüringer Chirotheriensandstein", main Middle Bunter Sandstone). "Chirotherium" is also found in the Bavarian and Württemberg parts of Franconia. Sites include Aura near Bad Kissingen, Karbach, Gambach and Külsheim. There the deposits are somewhat younger (Upper Bunter Sandstone), and the corresponding stratigraphic interval is called the Franconian Chirotherium Beds ("Fränkische Chirotherienschichten"). Among the less significant body fossil records of vertebrates are the procolophonid "Anomoiodon liliensterni" from Reurieth in the Thuringian part of Franconia and "Koiloskiosaurus coburgiensis" from Mittelberg near Coburg, both from the Thuringian Chirotherium Sandstone, and the Temnospondyle "Mastodonsaurus ingens" (possibly identical with the mastodonsaurus, "Heptasaurus cappelensis") from the Upper Bunter at Gambach.

As early as the first decade of the 19th century George, Count of Münster began systematic fossil gathering and digs and in the Upper Muschelkalk at Bayreuth. For example, the Oschenberg hill near Laineck became the type locality of two relatively well-known marine reptiles of the Triassic period, later found in other parts of Central Europe: the "flat tooth lizard", "Placodus" and the "false lizard", "Nothosaurus".

In Franconia's middle Keuper (the Feuerletten) is one of the best known and most common species of dinosaurs of Central Europe: "Plateosaurus engelhardti", an early representative of the sauropodomorpha. Its type locality is located at Heroldsberg south of Nuremberg. When the remains of "Plateosaurus" were first discovered there in 1834, it was the first discovery of a dinosaur on German soil, and this occurred even before the name "dinosauria" was coined. Another important "Plateosaurus" find in Franconia was made at Ellingen.

Far more famous than "Plateosaurus", "Placodus" and "Nothosaurus" is the "Archaeopteryx", probably the first bird geologically. It was discovered in the southern Franconian Jura, "inter alia" at the famous fossil site of Solnhofen in the Solnhofen Platform Limestone ("Solnhofener Plattenkalk", (Solnhofen-Formation, early Tithonian, Upper Jurassic). In addition to "Archaeopteryx", in the very fine-grained, laminated lagoon limestones are the pterosaur "Pterodactylus" and various bony fishes as well as numerous extremely detailed examples of invertebrates e.g. feather stars and dragonflies. Eichstätt is the other "big" and similarly famous fossil locality in the Solnhofen Formation, situated on the southern edge of the Jura in Upper Bavaria. Here, as well as "Archaeopteryx", the theropod dinosaurs, "Compsognathus" and "Juravenator," were found.

An inglorious episode in the history of paleontology took place in Franconia: fake fossils, known as Beringer's Lying Stones, were acquired in the 1720s by Würzburg doctor and naturalist, Johann Beringer, for a lot of money and then described in a monograph, along with genuine fossils from the Würzburg area. However, it is not entirely clear whether the Beringer forgeries were actually planted or whether he himself was responsible for the fraud.

Franconia has a humid cool temperate transitional climate, which is neither very continental nor very maritime. The average monthly temperatures vary depending on the area between about -1 to -2 °C in January and 17 to 19 °C in August, but may reach a peak of about 35 °C for a few days in the summer, especially in the large cities. The climate of Franconia is sunny and relatively warm. For part of the summer, for example, Lower Franconia is one the sunniest areas in Germany. Daily temperatures in the Bavarian part of Franconia are an average of 0.1 °C higher than the average for Bavaria as a whole. Relatively less rain falls in Franconia, and likewise in the rest of North Bavaria rain than is usual for its geographic location; even summer storms are often less powerful than in other areas of South Germany. In southern Bavaria about 2,000 mm of precipitation falls annually and almost three times as much as in parts of Franconia (about 500–900 mm) in the rain shadow of the Spessart, Rhön and Odenwald.

Franconia, as part of Germany, has a high quality of life. In the "Worldwide Quality of Living Survey" by Mercer in 2010, the city of Nuremberg was one of the top 25 cities in the world in terms of quality of life and came sixth in Germany. In environmental ranking Nuremberg came thirteenth in the world and was the best German city In a survey by the German magazine, "Focus," on quality of life in 2014, the districts of Eichstätt and Fürth were among the top positions in the table. In the "Glücksatlas" by Deutsche Post Franconia achieved some of the highest scores, but the region slipped in 2013 to 13th place out of 19.

Franconia is named after the Franks, a Germanic tribe who conquered most of Western Europe by the middle of the 8th century. Despite its name, Franconia is not the homeland of the Franks, but rather owes its name to being partially settled by Franks from the Rhineland during the 7th century AD following the defeat of the Alamanni and Thuringians who had dominated the region earlier.

At the beginning of the 10th century a "Duchy of Franconia" () was established within East Francia, which comprised modern Hesse, Palatinate, parts of Baden-Württemberg and most of today's Franconia. After the dissolution of the so-called Stem duchy of Franconia, the Holy Roman Emperors created the Franconian Circle (German "Fränkischer Reichskreis") in 1500 to embrace the principalities that grew out of the eastern half of the former duchy. The territory of the Franconian Circle roughly corresponds with modern Franconia. The title of a "Duke of Franconia" was claimed by the Würzburg bishops until 1803 and by the kings of Bavaria until 1918. Examples of Franconian cities founded by Frankish noblemen are Würzburg, first mentioned in the 7th century, Ansbach, first mentioned in 748, and Weissenburg, founded in the 7th century.

Fossil finds show that the region was already settled by primitive man, "Homo erectus", in the middle Ice Age about 600,000 years ago. Probably the oldest human remains in the Bavarian part of Franconia were found in the cave ruins of Hunas at Pommelsbrunn in the county of Nuremberg Land. In the late Bronze Age, the region was probably only sparsely inhabited, as few noble metals occur here and the soils are only moderately fertile. In the subsequent Iron Age (from about 800 B.C.) the Celts become the first nation to be discernible in the region. In northern Franconia they built a chain of hill forts as a line of defence against the Germanii advancing from the north. On the Staffelberg they built a powerful settlement, to which Ptolemy the name "oppidum Menosgada", and on the Gleichberge is the largest surviving "oppidum" in Central Germany, the Steinsburg. With the increased expansion of Rome in the first century B.C. and the simultaneous advance of the Elbe Germanic tribes from the north, the Celtic culture began to fall into decline. The southern parts of present-day Franconia soon fell under Roman control; however, most of the region remained in Free Germania. Initially Rome tried extend its direct influence far to the northeast; in the longer term, however, the Germanic-Roman frontier formed further southwest.
Under the emperors, Domitian (81-96), Trajan (98-117) and Hadrian (117-138), the Rhaetian Limes was built as a border facing the Germanic tribes to the north. This defensive line ran through the south of Franconia and described an arc across the region whose northernmost point lay at present-day Gunzenhausen. To protect it, the Romans built several forts like Biriciana at Weißenburg, but by the mid-third century, the border could no longer be maintained and by 250 A.D. the Alemanni occupied the areas up to the Danube. Fortified settlements such as the Gelbe Bürg at Dittenheim controlled the new areas. More such Gau forts have been detected north of the former Limes as well. To which tribe their occupants belonged is unknown in most cases. However, it is likely that it was mainly Alemanni and Juthungi in especially in the south. By contrast, it was the Burgundians who settled on the Lower and Middle Main. Many of these hill forts appear to have been destroyed, however, no later than 500 A.D. The reasons are not entirely clear, but it could have been as a result of invasions by the Huns which thus triggered the Great Migration. In many cases, however, it was probably conquest by the Franks that spelt the end of these hilltop settlements.

With their victories over the heartlands of the Alamanni and Thuringians in the 6th century, the present region of Franconia also fell to the Franks. After the division of the Frankish Empire, East Francia ("Francia orientialis") was formed from the territories of the dioceses of Mainz, Worms, Würzburg and Speyer. Later, the diocese of Bamberg was added. In the 7th century, the Slavs started to populate the northeastern parts of the region from the east, because the area of today's Upper Franconia was very sparsely populated (Bavaria Slavica). However, in the 10th and 11th centuries, they largely gave up their own language and cultural tradition. The majority of the population of Franconia was pagan well into the Early Middle Ages, The first people to spread the Christian faith strongly were wandering Irish Anglo-Saxon monks in the early 7th century. Saint Kilian, who together with his companions, Saint Colman and Saint Totnan are considered to be the apostles to the Franks, suffering martyrdom in Würzburg in the late 7th century, probably did not encounter any pagans in the ducal court. It was probably Saint Boniface who carried the Christian mission deep into the heart of the ordinary population of Franconia.
In the mid-9th century the tribal Duchy of Franconia emerged, one of the five tribal or stem duchies of East Francia. The territory of the stem duchy was far bigger than modern Franconia and covered the whole of present-day Hesse, northern Baden-Württemberg, southern Thuringia, large parts of Rhineland-Palatinate and parts of the Franconian provinces in Bavaria. It extended as far west as Speyer, Mainz, and Worms (west of the Rhine) and even included Frankfurt ("ford of the Franks"). In the early 10th century, the Babenbergs and Conradines fought for power in Franconia. Ultimately this discord led to the Babenberg Feud which was fuelled and controlled by the crown. The outcome of this feud meant the loss of power for the Babenbergs, but indirectly resulted in the Conradines winning the crown of East Francia. Sometime around 906, Conrad succeeded in establishing his ducal hegemony over Franconia, but when the direct Carolingian male line failed in 911, Conrad was acclaimed King of the Germans, largely because of his weak position in his own duchy. Franconia, like Alamannia was fairly fragmented and the duke's position was often disputed between the chief families. Conrad had granted Franconia to his brother Eberhard on his succession, but when Eberhard rebelled against Otto I in 938, he was deposed from his duchy, which disintegrated in 939 on Eberhard's death into West or Rhenish Franconia ('), and East Franconia (') and was directly subordinated to the Reich. Only after that was the former "Francia orientalis" considered to be under the sphere of the bishops of Würzburg as the true Franconia, its territory gradually shrinking to its present area.

Meanwhile, the inhabitants of parts of present-day Upper and Middle Franconia, who were not under the control of Würzburg, probably also considered themselves to be Franks at that time, and certainly their dialect distinguished them from the inhabitants of Bavaria and Swabia.

Unlike the other stem duchies, Franconia became the homeland and power base of East Frankish and German kings after the Ottonians died out in 1024. As a result, in the High Middle Ages, the region did not become a strong regional force such as those which formed in Saxony, Bavaria and Swabia. In 1007, the later canonized Henry II founded the Bishopric of Bamberg and endowed it with rich estates. Bamberg became a favoured "Pfalz" and an important centre of the Empire. Because parts of the Bishopric of Würzburg also fell to Bamberg, Würzburg was enfeoffed several royal estates by King Henry II by way of compensation.
From the 12th century Nuremberg Castle was the seat of the Burgraviate of Nuremberg. The burgraviate was ruled from about 1190 by the Zollerns, the Franconian line of the later House of Hohenzollern, which provided the German emperors of the 19th and 20th century. Under the Hohenstaufen kings, Conrad III and Frederick Barbarossa, Franconia became the centre of power in the Empire. During the time when there was no emperor, the Interregnum (1254–1273), some territorial princes became ever more powerful. After the Interregnum, however, the rulers succeeded in re-establishing a stronger royal lordship in Franconia. Franconia soon played an important role again for the monarchy at the time of Rudolf of Habsburg; the itineraries of his successors showing their preference for the Rhine-Main region. In 1376 the Swabian League of Cities was founded and was joined later by several Franconian imperial cities. During the 13th century the Teutonic Order was formed, taking over its first possession in Franconia in 1209, the Bailiwick of Franconia. The foundation of many schools and hospitals and the construction of numerous churches and castles in this area goes back to the work of this Roman Catholic military order. The residence place of the bailiwick was at Ellingen until 1789 when it was transferred to today's Bad Mergentheim. Other orders such as the Knights Templar could not gain a foothold in Franconia; the Order of St. John worked in the Bishopric of Würzburg and had short term commands.

As of the 13th century, the following states, among others, had formed in the territory of the former Duchy:

On 2 July 1500 during the reign of Emperor Maximilian I, as part of the Imperial Reform Movement, the Empire was divided into Imperial Circles. This led in 1512 to the formation of the Franconian Circle. Seen from a modern perspective, the Franconian Circle may be viewed as an important basis for the sense of a common Franconian identity that exists today. The Franconian Circle also shaped the geographical limits of the present-day Franconia. In the late Middle Ages and Early Modern Period, the Imperial Circle was severely affected by "Kleinstaaterei", the patchwork of tiny states in this region of Germany. As during the late Middle Ages, the bishops of Würzburg used the nominal title of Duke of Franconia during the time of the Imperial Circle. In 1559, the Franconian Circle was given jurisdiction over coinage ("Münzaufsicht") and, in 1572, was the only Circle to issue its own police ordinance.

Members of the Franconian Circle included the imperial cities, the prince-bishoprics, the Bailiwick of Franconia of the Teutonic Order and several counties. The Imperial Knights with their tiny territories, of which there was a particularly large number in Franconia, were outside the Circle assembly and, until 1806, formed the Franconian Knights Circle ("Fränkischer Ritterkreis") consisting of six Knights' Cantons. Because the extent of Franconia, already referred to above, is disputed, there were many areas that might be counted as part of Franconia today, that lay outside the Franconian Circle. For example, the area of Aschaffenburg belonged to Electoral Mainz and was a part of the Electoral Rhenish Circle, the area of Coburg belonged to the Upper Saxon Circle and the Heilbronn area to the Swabian Circle. In the 16th century, the College of Franconian Counts was founded to represent the interests of the counts in Franconia.

Franconia played an important role in the spread of the Reformation initiated by Martin Luther, Nuremberg being one of the places where the Luther Bible was printed. The majority of other Franconian imperial cities and imperial knights embraced the new confession. In the course of the counter-reformation several regions of Franconia returned to Catholicism, however, and there was also an increase in witch trials. In addition to Lutheranism, the radical reformatory baptist movement spread early on across the Franconian area. Important Baptist centres were Königsberg and Nuremberg.
In 1525, the burden of heavy taxation and socage combined with new, liberal ideas that chimed with the Reformation movement, unleashed the German Peasants' War. The Würzburg area was particularly hard hit with numerous castles and monasteries being burned down. In the end, however, the uprisings were suppressed and for centuries the lowest strata of society were excluded from all political activity.

From 1552, Margrave Albert Alcibiades attempted to break the supremacy of the mighty imperial city of Nuremberg and to secularise the ecclesial estates in the Second Margrave War, to create a duchy over which he would rule. Large areas of Franconia were eventually devastated in the fighting until King Ferdinand I together with several dukes and princes decided to overthrow Albert.

In 1608, the reformed princes merged into a so-called Union within the Empire. In Franconia, the margraves of Ansbach and Bayreuth as well as the imperial cities were part of this alliance. The Catholic side responded in 1609 with a counter-alliance, the League. The conflicts between the two camps ultimately resulted in the Thirty Years' War, which was the greatest strain on the cohesion of the Franconian Circle Initially, Franconia was not a theatre of war, although marauding armies repeatedly crossed its territory. However, in 1631, Swedish troops under Gustavus Adolphus advanced into Franconia and established a large encampment in summer 1632 around Nuremberg. However, the Swedes lost the Battle of the Alte Veste against Wallenstein's troops and eventually withdrew. Franconia was one of the poorest regions in the Empire and lost its imperial political significance. During the course of the war, about half the local population lost their lives. To compensate for these losses about 150,000 displaced Protestants settled in Protestant areas, including Austrian exiles.
Franconia never developed into a unified territorial state, because the patchwork quilt of small states ("Kleinstaaterei") survived the Middle Ages and lasted until the 18th century. As a result, the Franconian Circle had the important task of preserving peace, preventing abuses and to repairing war damage and had a regulatory role in the region until the end of the Holy Roman Empire. Until the War of the Spanish Succession, the Circle had become an almost independent organization and joined the Grand Alliance against Louis XIV as an almost sovereign state. The Circle also developed early forms of a welfare state. It also played a major role in the control of disease during the 16th and 17th centuries. After Charles Alexander abdicated in 1792, the former margraviates of Ansbach and Bayreuth were annexed by Prussia. Karl August Freiherr von Hardenberg was appointed as governor of these areas by Prussia.

Most of modern-day Franconia became part of Bavaria in 1803 thanks to Bavaria's alliance with Napoleon. Culturally it is in many ways different from Bavaria proper ("Altbayern", Old Bavaria), however. The ancient name was resurrected in 1837 by Ludwig I of Bavaria. During the Nazi period, Bavaria was broken up into several different Gaue, including Franconia and Main-Franconia.

In 1803, what was to become the Kingdom of Bavaria was given large parts of Franconia through the enactment of the "Reichsdeputationshauptschluss" under pressure from Napoleon for secularization and mediatisation. In 1806, the Act of Confederation led to stronger ties between Bavaria, Württemberg, Baden and other areas with France, whereupon the Holy Roman Empire including the Franconian Circle fell apart. As a reward Bavaria was promised other estates, including the city of Nuremberg. In the so-called "Rittersturm" of 1803, Bavaria, Württemberg and Baden seized the territories of the Imperial Knights and Franconian nobility, whose estates were often no bigger than a few parishes, even though the "Reichsdeputationshauptschluss" had not authorised this. In 1806 and 1810, Prussia had to release the territories of Ansbach and Bayreuth, which it had annexed in 1792, to Bavaria, whereby Prussia lost its supremacy in the region.

In 1814, as a result of the Congress of Vienna, the territories of the Principality of Aschaffenburg and Grand Duchy of Würzburg went to the Kingdom of Bavaria. In order to merge the patchwork quilt of small states in Franconia and Swabia into a greater Bavaria, Maximilian Joseph Montgelas reformed the political structure. Out of this in January 1838 emerged the Franconian provinces with their present names of Middle, Upper and Lower Franconia. . Considerable resentment arose in parts of the Franconian territories over their new membership of Bavaria. There were liberal demands for republican structures which erupted in the revolts of 1848 and 1849 and the Gaibach Festival in 1832. On the one hand the reconciliation policy of the Wittelsbachs and Montgelas' aforementioned policy of unification, and, on the other hand, the inclusion of Bavaria in the German Empire in 1871, which weakened her power Bavaria slightly, the conflict between Franconia and Bavaria eased considerably.

From 1836 to 1846, the Kingdom of Bavaria built the Ludwig Canal from Bamberg to Kelheim, which was only abandoned in 1950. However, the canal lost much of its importance shortly after the arrival of the railways. Between 1843 and 1854, the Ludwig South-North Railway was established within Franconia, which ran from Lindau on Lake Constance via Nuremberg, Bamberg and Kulmbach to Hof. The first locomotive to run on German soil steamed 1835 from Nuremberg to Fürth on 7 December 1835.

After the First World War the monarchy in Bavaria was abolished, but the state could not agree on a compromise between a Soviet system and parliamentarianism. This caused fighting between the opposing camps and the then prime minister was shot. As a result, the government fled to Bamberg in 1919, where the Bamberg Constitution was adopted while, in Munich, the Bavarian Soviet Republic reigned briefly. In 1919 the Free State of Coburg voted in a referendum against joining Thuringia and was instead united with Bavaria on 1 July 1920.

During the Nazi era Nuremberg played a prominent role in the self-expression of the National Socialists as the permanent seat of the Nazi Party. Gunzenhausen made its mark as one of the first towns in the Reich itself to exercise discrimination against the Jewish population. The first Hitler Monument in Germany was established there in April 1933. On 25 March 1934 the first anti-Jewish pogrom in Bavaria took place in Gunzenhausen. The attack brought the town negative press coverage worldwide. On 15 September, a Reichstag was specially convened in Nuremberg for the purpose of passing the Nuremberg Laws, under which the antisemitic ideology of the Nazis became a legal basis for such actions.

Like all parts of the German Reich, Franconia was badly affected by Allied air raids. Nuremberg, as a major industrial centre and transportation hub, was hit particularly hard. Between 1940 and 1945 the city was the target of dozens of air raids. Many other places were also affected by air raids. For example, the air raid on 4 December 1944 on Heilbronn and the bombing of Würzburg on 16 March 1945, in which both old towns were almost completely destroyed, was a disaster for both cities. By contrast, the old town of Bamberg was almost completely spared. In order to protect cultural artefacts, the historic art bunker was built below Nuremberg Castle. In the closing stages of the Second World War, at the end of March and April 1945, Franconian towns and cities were captured by formations of the US Army who advanced from the west after the failure of the Battle of the Bulge and Operation Nordwind. The Battle of Nuremberg lasted five days and resulted in at least 901 deaths. The Battle of Crailsheim lasted 16 days, the Battle of Würzburg seven and the Battle of Merkendorf three days.

Following the unconditional surrender on 8 May 1945, Bavarian Franconia became part of the American zone of occupation; whilst South Thuringia, with the exception of smaller enclaves like Ostheim, became part of the Soviet zone and the Franconian parts of today's Baden-Württemberg also went to the American zone The most important part of the Allied prosecution programme against leaders of the Nazi regime were the Nuremberg Trials against leaders of the German Empire during the Nazi era, held from 20 November 1945 to 14 April 1949. The Nuremberg Trials are considered a breakthrough for the principle that, for a core set of crimes, there is no immunity from prosecution. For the first time, the representatives of a sovereign state were held accountable for their actions. In autumn 1946, the Free State of Bavaria was reconstituted with the enactment of the Bavarian Constitution.

The state of Württemberg-Baden was founded on 19 September 1945. On 25 April 1952 this state merged with Baden and Württemberg-Hohenzollern (both from the former French occupation zone) to create the present state of Baden-Württemberg. On 1 December 1945 the state of Hesse was founded. Beginning in 1945, refugees and displaced persons from Eastern Europe were settled particularly in rural areas. After 1945, Bavaria and Baden-Württemberg managed the transition from economies that were predominantly agriculture to become leading industrial states in the so-called "Wirtschaftswunder". In Lower and Upper Franconia, there was still the problem, however, of the zone along the Inner German Border which was a long way from the markets for its agricultural produce, and was affected by migration and relatively high unemployment, which is why these areas received special support from federal and state governments.

By contrast, the state of Thuringia was restored by the Soviets in 1945. On 7 October 1949 the German Democratic Republic, commonly known as East Germany, was founded. In 1952 in the course of the 1952 administrative reform in East Germany, the state of Thuringia was relieved of its function. The Soviet occupying forces exacted a high level of reparations (especially the dismantling of industrial facilities) which made the initial economic conditions in East Germany very difficult. Along with the failed economic policies of the GDR, this led to a general frustration that fuelled the uprising of 17 June. There were protests in the Franconian territories too, for example in Schmalkalden. The village of Mödlareuth became famous because, for 41 years, it was divided by the Inner German Border and was nicknamed 'Little Berlin. After "Die Wende", the fall of the Berlin Wall on 9 November 1989 and reunification on 3 October 1990, made possible mainly by mass demonstrations in East Germany and local exodus of East Germans, the state of Thuringia was reformed with effect from 14 October 1990.

In the years from 1971 to 1980 an administrative reform was carried out in Bavaria with the aim of creating more efficient municipalities ("Gemeinden") and counties ("Landkreise"). Against sometimes great protests by the population, the number of municipalities was reduced by a third and the number of counties by about a half. Among the changes was the transfer of the Middle Franconian county of Eichstätt to Upper Bavaria. On 18 May 2006, the Bavarian Landtag approved the introduction of Franconia Day ("Tag der Franken") in the Franconian territories of the free state.

Since "Die Wende", new markets have opened up for the Franconian region of Bavaria in the new (formerly East German) federal states and the Czech Republic, enabling the economy to recover. Today, Franconia is in the centre of the EU (at Oberwestern near Westerngrund; )

While Old Bavaria is overwhelmingly Roman Catholic, Franconia is a mixed area. Lower Franconia and the western half of Upper Franconia (Bamberg, Lichtenfels, Kronach) is predominantly Catholic, while most of Middle and the eastern half of Upper Franconia (Bayreuth, Hof, Kulmbach) are predominantly Protestant (Evangelical Church in Germany). The city of Fürth in Middle Franconia historically (before the Nazi era) had a large Jewish population; Henry Kissinger was born there.

A large part of the population of Franconia, which has a population of five million, consider themselves Franconians ("Franken", in German homonymous with the name of the historical Franks), a sub-ethnic group of the German people alongside Alemanni, Swabians, Bavarians, Thuringians and Saxons. 
Such an ethnic identity is generally not shared by other parts of the Franconian-speaking area (members of which may identify as Rhine Franconians ("Rheinfranken") or Moselle Franconians ("Moselfranken").

The Free State of Bavaria counts Franconians as one of the "four tribes of Bavaria" ("vier Stämme Bayerns"), alongside Bavarians, Swabians and Sudeten Germans.

With the exception of Heilbronn, all cities in Franconia and all towns with a population of over 50,000 are within the Free State of Bavaria. The five cities of Franconia are Nuremberg, Würzburg, Fürth, Heilbronn and Erlangen. In Middle Franconia, in the metropolitan region of Nuremberg there is a densely populated urban area consisting of Nuremberg, Fürth, Erlangen and Schwabach. Nuremberg is the fourteenth largest city in Germany and the second largest in Bavaria.

The largest settlements in Baden-Württemberg's Franconian region are Heilbronn (pop: 117,531), Schwäbisch Hall (37,096) and Crailsheim (32,417). The largest places in the Thuringian part are Suhl (35,665), Sonneberg (23,796) and Meiningen (20,966). The largest place in the Hessian part of Franconia is Gersfeld with just 5,512 inhabitants. The largest cities within Bavaria are Nuremberg (495,121), Würzburg (124,577), Fürth (118,358) and Erlangen (105,412).

In the Middle Ages Franconia, with its numerous towns, was separate and not part of other territories such as the Duchy of Bavaria. In the late medieval period it was dominated by mainly smaller towns with a few hundred to a thousand inhabitants, whose size barely distinguished them from the villages. Many towns grew up along large rivers or were founded by the prince-bishops and nobility. Even the Hohenstaufens operated in many towns, most of which later became Imperial Cities with a strong orientation towards Nuremberg. The smallest town in Franconia is Thuringia's Ummerstadt with 487 inhabitants.

German is the official language and also the "lingua franca". Numerous other languages are spoken that come from other language regions or the native countries of immigrants.

East Franconian German, the dialect spoken in Franconia, is very different from the Austro-Bavarian dialect. Most Franconians do not call themselves Bavarians. Even though there is no Franconian state, red and white are regarded as the state colours ("Landesfarben") of Franconia.

The proportion of Roman Catholics and Protestants among the population of Franconia is roughly the same, but varies from region to region. Large areas of Middle and Upper Franconia are mainly Protestant. The denominational orientation today still reflects the territorial structure of Franconia at the time of the Franconian Circle. For example, regions, that used to be under the care of the bishoprics of Bamberg, Würzburg and Eichstätt, are mainly Catholic today. On the other hand, all former territories of the imperial cities and the margraviates of Ansbach and Bayreuth have remained mainly Lutheran. The region around the city of Erlangen, which belonged to the Margraviate of Bayreuth, was a refuge for the Huguenots who fled there after the St. Bartholomew's Day massacre in France. Following the success of the Reformation in Nuremberg under Andreas Osiander, it had been an exclusively Protestant imperial city and belonged to the Protestant league of imperial states, the Corpus Evangelicorum, within the "Reichstag". Subsequent historical events such as the stream of refugees after the Second World War and the increasing mobility of the population has since blurred denominational geographical boundaries, however.

The influx of immigrants from Eastern Europe has also seen the establishment of an Orthodox community in Franconia. The Romanian Orthodox Metropolis of Germany, Central and Northern Europe has its headquarters in Nuremberg.

Before the Nazi era Franconia was as a region with significant Jewish communities, most of whom were Ashkenazi Jews. The first Jewish communities appeared in Franconia in the 12th and 13th centuries and thus later than, for example, in Regensburg. In the Middle Ages, Franconia was a stronghold of Torah studies. But Franconia also began to exclude the Jewish populations particularly early on. For example, there were two Jewish massacres - the Rintfleisch massacres of 1298 and the Armleder Uprising of 1336-1338 - and in the 15th and 16th centuries many cities exiled their Jewish populations, which is why many Jews settled in rural communities. Franconia also rose to early prominence in the discrimination of Jews during the Nazi era. One of the first casualties of the organized Nazi persecution of Jews took place on 21 March in Künzelsau and on 25/26 March 1933 in Creglingen, where police and SA troops under the leadership of "Standartenführer" Fritz Klein led a so-called "weapons search operations".
Whilst, in 1818, about 65 per cent of Bavarian Jews lived in the Bavarian part of Franconia, today there are only Jewish communities in Bamberg, Bayreuth, Erlangen, Fürth, Hof, Nuremberg and Würzburg and in Heilbronn in Baden-Württemberg.

Adherents of Islam continue to grow, especially in the larger cities, due to the influx of "gastarbeiters" and other immigrants from Muslim countries. As a result, many 'backyard mosques' ("Hinterhofmoschees") have sprung up, which are gradually being replaced by purpose-built mosques.

Franconia has almost 300 small breweries. The northwestern parts, the areas around river Main called Franconian wine region also produce a lot of wine. Food typical for the region includes Bratwurst (especially the famous small Nuremberger Bratwurst), "Schäuferla" (roast pork shoulder), Sauerbraten, dumplings, potato salad (typically made with broth), fried carp, Grupfder (seasoned cheese spread), "Presssack" (a type of Head cheese: pressed or jellied pork trimmings, like tongue, cheeks, etc.). Lebkuchen are a traditional type of biscuit, and Küchla is a sort of sweet fried dough.

The tourism industry stresses the romantic character of Franconia. Arguments for this include the picturesque countryside and the many historic buildings that present the long history and culture of the region., In addition, the relatively few industrial towns outside of the main industrial cities is underlined. Franconian wine, the rich tradition of beer brewing and local culinary specialities, such as "Lebküchnerei" or gingerbread baking, are also seen as a draw that is worth marketing, and which make Franconia a popular tourist destination in Germany. The Romantic Road, the best known German theme route, links several of the tourist high points in western Franconia. The Castle Road runs through the whole Franconian region with its numerous castles and other medieval structures.

The Franconian countryside is suitable for many sporting activities. For example, the Franconian Way, Celtic Way and the hiking trail network of the Altmühl Valley and the Central Uplands offer a lot of hiking options.

Cycling along the large rivers is very popular, for example along the Main Cycleway, which was the first German long distance cycleway to be awarded five starts by the Allgemeiner Deutscher Fahrrad-Club (ADFC). The Tauber Valley Cycleway, a 101 kilometre-long cycle trail in Tauber Franconia, was the second German long distance cycleway to receive five stars.

In the Fichtel Mountains and the Franconian Forest, many tourists come for making hiking tours. In winter people can do skiing f. e. on the Ochsenkopf. Very popular are raftings on the Wild Rodach in Wallenfels in the Franconian Forest.





</doc>
<doc id="11402" url="https://en.wikipedia.org/wiki?curid=11402" title="FileMan">
FileMan

FileMan is a set of utilities written by George Timson in the late 1970s and early 1980s, using MUMPS, which provide a meta-data function for MUMPS applications. The FileMan utilities allow the definition of data structures, menus and security, reports, and forms, allowing someone to set up applications without tremendous experience in the MUMPS programming language.

FileMan was designed to support the complex information storage and processing needs of hospitals. It was based on an active data dictionary that was able to invoke the full interpretive power of the MUMPS language from within a data reference. For example, a field called "Length of Stay" could invoke a MUMPS expression that would process the various dates, transfers, and discharges that would then be returned as if it were stored as a fixed data element.

MUMPS differs from many languages in its handling of the null string. A large percentage of the FileMan internal data structures are null strings, in which the information is located in the name of the "nothing" being referenced. This approach does not fit the traditional Relational Data Model.

Its first use was in the development of medical applications for the Veterans Administration, now called the Department of Veterans Affairs, a branch of the United States Government.
Since it was a work created by the US federal government, a copyright cannot be placed on the source code, making the source code in the public domain. Because of this, it has been used for rapid development of applications across a number of organizations, including commercial products.

FileMan may be used standalone, or may be used with the VA Kernel, which provides an operating system neutral environment for applications.



</doc>
<doc id="11404" url="https://en.wikipedia.org/wiki?curid=11404" title="United States Foreign Intelligence Surveillance Court">
United States Foreign Intelligence Surveillance Court

The United States Foreign Intelligence Surveillance Court (FISC, also called the FISA Court) is a U.S. federal court established and authorized under the Foreign Intelligence Surveillance Act of 1978 (FISA) to oversee requests for surveillance warrants against foreign spies inside the United States by federal law enforcement and intelligence agencies. Such requests are made most often by the National Security Agency (NSA) and the Federal Bureau of Investigation (FBI). Congress created FISA and its court as a result of the recommendations by the U.S. Senate's Church Committee. 

From its opening in 1978 until 2009, the court was housed on the sixth floor of the Robert F. Kennedy Department of Justice Building. Since 2009, the court has been relocated to the E. Barrett Prettyman United States Courthouse in Washington, D.C.

In 2013, a top-secret order issued by the court, which was later leaked to the media from documents culled by Edward Snowden, required a subsidiary of Verizon to provide a daily, on-going feed of all call detail recordsincluding those for domestic callsto the NSA.

Each application for one of these surveillance warrants (called a FISA warrant) is made before an individual judge of the court. The court may allow third parties to submit briefs as "amici curiae". When the U.S. Attorney General determines that an emergency exists, the Attorney General may authorize the emergency employment of electronic surveillance before obtaining the necessary authorization from the FISC, if the Attorney General or their designee notifies a judge of the court at the time of authorization and applies for a warrant as soon as practicable but not more than seven days after authorization of such surveillance, as required by .

If an application is denied by one judge of the court, the federal government is not allowed to make the same application to a different judge of the court, but may appeal to the United States Foreign Intelligence Surveillance Court of Review. Such appeals are rare: the first appeal from the FISC to the Court of Review was made in 2002 ("In re Sealed Case No. 02-001"), 24 years after the founding of the court.

Also rare is for FISA warrant requests to be turned down. During the 25 years from 1979 to 2004, 18,742 warrants were granted, while only four were rejected. Fewer than 200 requests had to be modified before being accepted, almost all of them in 2003 and 2004. The four rejected requests were all from 2003, and all four were partially granted after being submitted for reconsideration by the government. Of the requests that had to be modified, few were before the year 2000. During the next eight years, from 2004 to 2012, there were over 15,100 additional warrants granted, and another seven being rejected. Over the entire 33-year period, the FISA court granted 33,942 warrants, with only 12 denials – a rejection rate of 0.03 percent of the total requests. This does not include the number of warrants that were modified by the FISA court.
Notes:
On May 17, 2002, the court rebuffed Attorney General John Ashcroft, releasing an opinion that alleged that the FBI and Justice Department officials had "supplied erroneous information to the court" in more than 75 applications for search warrants and wiretaps, including one signed by FBI Director Louis J. Freeh. Whether this rejection was related to the court starting to require modification of significantly more requests in 2003 is unknown.

On December 16, 2005, "The New York Times" reported that the Bush administration had been conducting surveillance against U.S. citizens without specific approval from the FISA court for each case since 2002. On December 20, 2005, Judge James Robertson resigned his position with the court, apparently in protest of the secret surveillance, and later, in the wake of the Snowden leaks of 2013, criticized the court-sanctioned expansion of the scope of government surveillance and its being allowed to craft a secret body of law. The government's apparent circumvention of the court started prior to the increase in court-ordered modifications to warrant requests.

In 2011, the Obama administration secretly won permission from the Foreign Intelligence Surveillance Court to reverse restrictions on the National Security Agency's use of intercepted phone calls and e-mails, permitting the agency to search deliberately for Americans' communications in its massive databases. The searches take place under a surveillance program Congress authorized in 2008 under Section 702 of the Foreign Intelligence Surveillance Act. Under that law, the target must be a foreigner "reasonably believed" to be outside the United States, and the court must approve the targeting procedures in an order good for one year. But a warrant for each target would thus no longer be required. That means that communications with Americans could be picked up without a court first determining that there is probable cause that the people they were talking to were terrorists, spies or "foreign powers". The FISC also extended the length of time that the NSA is allowed to retain intercepted U.S. communications from five years to six years with an extension possible for foreign intelligence or counterintelligence purposes. Both measures were done without public debate or any specific authority from Congress.

Because of the sensitive nature of its business, the court is a "secret court" – its hearings are closed to the public. While records of the proceedings are kept, they also are unavailable to the public, although copies of some records with classified information redacted have been made public. Due to the classified nature of its proceedings, usually only attorneys licensed to practice in front of the US government are permitted to appear before the court. Because of the nature of the matters heard before it, court hearings may need to take place at any time of day or night, weekdays or weekends; thus, at least one judge must be "on call" at all times to hear evidence and decide whether or not to issue a warrant.

A heavily redacted version of a 2008 appeal by Yahoo! of an order issued with respect to NSA's PRISM program had been published for the edification of other potential appellants. The identity of the appellant was declassified in June 2013.

There has been growing criticism of the court since the September 11, 2001 attacks. This is partly because the court sits "ex parte" – in other words, in the absence of anyone but the judge and the government present at the hearings. This, combined with the minimal number of requests that are rejected by the court has led experts to characterize it as a rubber stamp (former National Security Agency analyst Russ Tice called it a "kangaroo court with a rubber stamp"). The accusation of being a "rubber stamp" was rejected by FISA Court president Reggie B. Walton who wrote in a letter to Senator Patrick J. Leahy: "The annual statistics provided to Congress by the Attorney General ... – frequently cited to in press reports as a suggestion that the Court's approval rate of application is over 99% – reflect only the number of "final" applications submitted to and acted on by the Court. These statistics do not reflect the fact that many applications are altered to prior or final submission or even withheld from final submission entirely, often after an indication that a judge would not approve them." He added: "There is a rigorous review process of applications submitted by the executive branch, spearheaded initially by five judicial branch lawyers who are national security experts and then by the judges, to ensure that the court's authorizations comport with what the applicable statutes authorize." In a following letter Walton stated that the government had revamped 24.4% of its requests in the face of court questions and demands in time from July 1, 2013 to September 30, 2013. This figure became available after Walton decided in the summer of 2013 that the FISC would begin keeping its own tally of how Justice Department warrant applications for electronic surveillance fared – and would track for the first time when the government withdrew or resubmitted those applications with changes. Some requests are modified by the court but ultimately granted, while the percentage of denied requests is statistically negligible (11 denied requests out of around 34,000 granted in 35 years – equivalent to 0.03%). The accusation that the FISC is a "rubber stamp" court was also rejected by Robert S. Litt (General Counsel of Office of the Director of National Intelligence): "When [the Government] prepares an application for [a section 215 order, it] first submit[s] to the [FISC] what's called a "read copy", which the court staff will review and comment on. [A]nd they will almost invariably come back with questions, concerns, problems that they see. And there is an iterative process back and forth between the Government and the [FISC] to take care of those concerns so that at the end of the day, we're confident that we're presenting something that the [FISC] will approve. That is hardly a rubber stamp. It's rather extensive and serious judicial oversight of this process."

A 2003 Senate Judiciary Committee "Interim Report on FBI Oversight in the 107th Congress by the Senate Judiciary Committee: FISA Implementation Failures" cited the "unnecessary secrecy" of the court among its "most important conclusions":

In a July 2013 interview, Senator and privacy advocate Ron Wyden described the FISC warrant process as "the most one-sided legal process in the United States". "I don't know of any other legal system or court that really doesn't highlight anything except one point of view", he said. Later in the interview he said Congress should seek to "diversify some of the thinking on the court".

Elizabeth Gotein, a co-director of the Liberty and National Security Program of the Brennan Center for Justice at the New York University School of Law, has criticized the court as being too compromised to be an impartial tribunal that oversees the work of the NSA and other U.S. intelligence activities. Since the court meets in secret, hears only the arguments of the government prior to deciding a case, and its rulings cannot be appealed or even reviewed by the public, she has argued that: "Like any other group that meets in secret behind closed doors with only one constituency appearing before them, they're subject to capture and bias."

A related bias of the court results from what critics such as Julian Sanchez, a scholar at the Cato Institute, have described as the near certainty of the polarization or groupthink of the judges of the court. Since all of the judges are appointed by the same person (the Chief Justice of the United States), as of 2013 nearly all currently serving judges are of the same political party (the Republican Party), hear no opposing testimony and feel no pressure from colleagues or the public to moderate their rulings, group polarization is almost a certainty. "There's the real possibility that these judges become more extreme over time, even when they had only a mild bias to begin with", Sanchez said.

The court's judges are appointed solely by the Chief Justice of the United States without confirmation or oversight by the U.S. Congress. This gives the chief justice the ability to appoint like-minded judges and create a court without diversity. "The judges are hand-picked by someone who, through his votes on the Supreme Court, we have come to learn has a particular view on civil liberties and law enforcement", Theodore Ruger, a professor at the University of Pennsylvania Law School, said with respect to Chief Justice John Roberts. "The way the FISA is set up, it gives him unchecked authority to put judges on the court who feel the same way he does." And Stephen Vladeck, a law professor at the University of Texas School of Law, added, "Since FISA was enacted in 1978, we've had three chief justices, and they have all been conservative Republicans, so I think one can worry that there is insufficient diversity." Since May 2014, however, four of the five judges appointed by Chief Justice Roberts to the FISA Court were appointed to their prior federal court positions by Presidents Bill Clinton and Barack Obama.

There are some reform proposals. Senator Richard Blumenthal from Connecticut proposed that each of the chief judges of the 12 major appeals courts select a district judge for the surveillance court; the chief justice would still pick the review panel that hears rare appeals of the court's decisions, but six other Supreme Court justices would have to sign off. Another proposal authored by Representative Adam Schiff of California would give the president the power to nominate judges for the court, subject to Senate approval, while Representative Steve Cohen proposed that Congressional leaders pick eight of the court's members.

Stephen Vladeck, a professor at the University of Texas School of Law, has argued that, without having to seek the approval of the court (which he has said merely reviews certifications to ensure that they and not the surveillance itself comply with the various statutory requirements), the U.S. Attorney General and the Director of National Intelligence can engage in sweeping programmatic surveillance for one year at a time. There are procedures used by the NSA to target non-U.S. persons and procedures used by the NSA to minimize data collection from U.S. persons. These court-approved policies allow the NSA to do the following:

Jameel Jaffer, the ACLU's deputy legal director, said in light of revelations that the government secured telephone records from Verizon and Internet data from some of the largest providers that safeguards that are supposed to be protecting individual privacy are not working. Elizabeth Goitein, co-director of the Liberty and National Security Program at the Brennan Center for Justice in New York, wrote in the Wall Street Journal that when courts make mistakes, the losing party has the right to appeal and the erroneous decision is reversed. "That process cannot happen when a secret court considers a case with only one party before it."

According to "The Guardian", "The broad scope of the court orders, and the nature of the procedures set out in the documents, appear to clash with assurances from President Obama and senior intelligence officials that the NSA could not access Americans' call or email information without warrants". Glenn Greenwald, who published details of the PRISM surveillance program, explained:

Deputy Attorney General James M. Cole and NSA Deputy Director John C. Inglis cited the court's oversight in defending the constitutionality of the NSA's surveillance activities before during a hearing before the House Judiciary Committee in July 2013. Representative Jerrold Nadler, challenged Cole's defense of the program's constitutionality, and he said the secrecy in which the court functioned negated the validity of its review. "The fact that a secret court unaccountable to public knowledge of what it's doing ... may join you in misusing or abusing the statutes is of no comfort whatsoever", Nadler said. Orin Kerr, a law professor at George Washington University, said the secrecy that comes along with national security makes it difficult to evaluate how the administration carries out the wide authority Congress has given it. "FISA court judges hear all of this and they think it's legal," Kerr said. "What we really don't know, though, are what the FISA court's opinions say."

In July 2013, "The New York Times" published disclosures from anonymous government whistleblowers of secret law written by the court holding that vast collections of data on all Americans (even those not connected in any way to foreign enemies) amassed by the NSA do not violate the warrant requirements of Fourth Amendment to the U.S. Constitution. It reported that anyone suspected of being involved in nuclear proliferation, espionage or cyber-attacks, according to the court, may be considered a legitimate target for warrantless surveillance. Acting like a parallel U.S. Supreme Court, the court greatly broadened the "special-needs" exception to do so.

The newspaper reported that in "more than a dozen classified rulings, the nation's surveillance court has created a secret body of law giving the National Security Agency the power to amass vast collections of data on Americans". It also wrote, with respect to the court:

The "special-needs" doctrine is an exemption to the Fourth Amendment's Warrants Clause which commands that "no Warrants shall issue, but upon probable cause, supported by Oath or affirmation, and particularly describing the place to be searched, and the persons or things to be and seized". The U.S. Supreme Court has recognized an exemption to the Warrants Clause "outside the foreign intelligence context, in so-called 'special-needs' cases. In those cases, the Court excused compliance with the Warrant Clause when the purpose behind the governmental action went beyond routine law enforcement and insisting upon a warrant would materially interfere with the accomplishment of that purpose. See, "Vernonia School District 47J v. Acton", 515 U.S. 646, 653 (1995) (upholding drug testing of highschool athletes and explaining that the exception to the warrant requirement applied "when special needs, beyond the normal need for law enforcement, make the warrant and probable-cause requirement[s] impracticable (quoting "Griffin v. Wisconsin", 483 U.S. 868, 873 (1987))); "Skinner v. Ry. Labor Execs. Ass'n", 489 U.S. 602, 620 (1989) (upholding regulations instituting drug and alcohol testing of railroad workers for safety reasons); cf. "Terry v. Ohio", 392 U.S. 1, 23-24 (1968) (upholding pat-frisk for weapons to protect officer safety during investigatory stop)". The U.S. Foreign Intelligence Surveillance Court of Review concluded on August 22, 2008, in the case "In re Directives [redacted text] Pursuant to Section 105B of the Foreign Intelligence Surveillance Act", that the "special-needs" doctrine applied by analogy to justify a foreign intelligence exception to the warrant requirement for surveillance undertaken for national security purposes and directed at a foreign power or an agent of a foreign power reasonably believed to be located outside the U.S.

James Robertson a former judge for the U.S. District Court for the District of Columbia, who, in 2004, ruled against the Bush administration in the "Hamdan v. Rumsfeld" case, and also served on the FISC for three years between 2002 and 2005 said he was "frankly stunned" by the newspaper's report that court rulings had created a new body of law broadening the ability of the NSA to use its surveillance programs to target not only terrorists but suspects in cases involving espionage, cyberattacks and weapons of mass destruction. Geoffrey R. Stone, a professor of constitutional law at the University of Chicago, said he was troubled by the idea that the court is creating a significant body of law without hearing from anyone outside the government, forgoing the adversarial system that is a staple of the American justice system. He said, "That whole notion is missing in this process".

The court concluded that mass collection of telephone metadata (including the time of phone calls and numbers dialed) does not violate the Fourth Amendment as long as the government establishes a valid reason under national security regulations before taking the next step of actually examining the contents of an American's communications. This concept is rooted partly in the special needs doctrine. "The basic idea is that it's O.K. to create this huge pond of data", an unnamed U.S. official said, "but you have to establish a reason to stick your pole in the water and start fishing". Under the new procedures passed by the U.S. Congress in the FISA Amendments Act of 2008, even the collection of metadata must be considered "relevant" to a terrorism investigation or other intelligence activities. The court has indicated that while individual pieces of data may not appear "relevant" to a terrorism investigation, the total picture that the bits of data create may in fact be relevant, according to U.S. officials with knowledge of the decisions.

A secret ruling made by the court that redefined the single word "relevant" enabled the NSA to gather phone data on millions of Americans. In classified orders starting in the mid-2000s, the court accepted that "relevant" could be broadened to permit an entire database of records on millions of people, in contrast to a more conservative interpretation widely applied in criminal cases, in which only some of those records would likely be allowed. Under the Patriot Act, the Federal Bureau of Investigation can require businesses to hand over "tangible things", including "records", as long as the FBI shows it is reasonable to believe the things are "relevant to an authorized investigation" into international terrorism or foreign intelligence activities. The history of the word "relevant" is key to understanding that passage. The Supreme Court in 1991 said things are "relevant" if there is a "reasonable possibility" that they will produce information related to the subject of the investigation. In criminal cases, courts previously have found that very large sets of information did not meet the relevance standard because significant portions innocent people's information would not be pertinent. But the court has developed separate precedents, centered on the idea that investigations to prevent national-security threats are different from ordinary criminal cases. The court's rulings on such matters are classified and almost impossible to challenge because of the secret nature of the proceedings. According to the court, the special nature of national-security and terrorism-prevention cases means "relevant" can have a broader meaning for those investigations, say people familiar with the rulings.

People familiar with the system that uses phone records in investigations have said that the court's novel legal theories allow the system to include bulk phone records, as long as there are privacy safeguards to limit searches. NSA analysts may query the database only "when there is a reasonable suspicion, based on specific facts, that the particular basis for the query is associated with a foreign terrorist organization", according to Director of National Intelligence James Clapper. The NSA database includes data about people's phone calls numbers dialed, how long a call lasted but not the actual conversations. According to Supreme Court rulings, a phone call's content is covered by the Constitution's Fourth Amendment, which restricts unreasonable searches, but the other types of data are not.

"Relevant" has long been a broad standard, but the way the court is interpreting it, to mean, in effect, "everything", is new, said Mark Eckenwiler, a lawyer who until December 2012 was the Justice Department's primary authority on federal criminal surveillance law. "I think it's a stretch" of previous federal legal interpretations, said Eckenwiler. If a federal attorney "served a grand-jury subpoena for such a broad class of records in a criminal investigation, he or she would be laughed out of court". Given the traditional legal definition of relevant, Timothy Edgar, a former top privacy lawyer at the Office of the Director of National Intelligence and the National Security Council in the Bush and Obama administrations, noted it is "a fair point" to say that someone reading the law might believe it refers to "individualized requests" or "requests in small batches, rather than in bulk database form". From that standpoint, Edgar said, the reinterpretation of relevant amounts to "secret law".

In June 2013, a copy of a top-secret warrant, issued by the court on April 25, 2013, was leaked to London's "The Guardian" newspaper by NSA contractor Edward Snowden. That warrant orders Verizon Business Network Services to provide a daily feed to the NSA containing "telephony metadata" – comprehensive call detail records, including location data – about all calls in its system, including those that occur "wholly within the United States, including local telephone calls". The Obama administration published on July 31, 2013 a FISA Court ruling supporting an earlier order requiring a Verizon subsidiary to turn over all of its customers' phone logs for a three-month period, with rules that must be followed when accessing the data.

The document leaked to "The Guardian" acted as a "smoking gun" and sparked a public outcry of criticism and complaints that the court exceeded its authority and violated the Fourth Amendment by issuing general warrants. "The Washington Post" then reported that it knew of other orders, and that the court had been issuing such orders, to all telecommunication companies, every three months since May 24, 2006.

Since the telephone metadata program was revealed, the intelligence community, some members of Congress, and the Obama administration have defended its legality and use. Most of these defenses involve the 1979 Supreme Court decision "Smith v. Maryland" which established that people do not have a "reasonable expectation" of privacy for electronic metadata held by third parties like a cellphone provider. That data is not considered "content", theoretically giving law enforcement more flexibility in collecting it.

On July 19, 2013, the court renewed the permission for the NSA to collect Verizon customer records en masse. The U.S. government was relying on a part of American case law known as the "third-party doctrine". This notion said that when a person has voluntarily disclosed information to a third party — in this case, the telephony metadata — the customer no longer has a reasonable expectation of privacy over the numbers dialed nor their duration. Therefore, this doctrine argued, such metadata can be accessed by law enforcement with essentially no problem. The content of communications are, however, subject to the Fourth Amendment. The Foreign Intelligence Surveillance Court held in October 2011, citing multiple Supreme Court precedents, that the Fourth Amendment prohibition against unreasonable searches and seizures applies to the contents of all communications, whatever the means, because "a person's private communications are akin to personal papers".

Former FISC judge Colleen Kollar-Kotelly, who provided the legal foundation for the NSA amassing a database of all Americans' phone records, told associates in the summer of 2013 that she wanted her legal argument out. Rulings for the plaintiff in cases brought by the ACLU on September 10 and 12, 2013, prompted James Clapper to concede that the government had overreached in its covert surveillance under part 215 of FISA and that the Act would likely be amended to reflect Congressional concern.

The American Civil Liberties Union, a customer of Verizon, asked on November 22, 2013 a federal district court in Lower Manhattan, New York to end the NSA phone call data collection program. The ACLU argued that the program violated the U.S. Constitution's guarantees of privacy and information as well as exceeding the scope of its authorizing legislation, Section 215 of the Patriot Act. The U.S. government countered that the program is constitutional and that Congress was fully informed when it authorized and reauthorized Section 215. Moreover, a government lawyer said, the ACLU has no standing to bring the case because it cannot prove that its members have been harmed by the NSA's use of the data.

In November 2016, Louise Mensch reported on the news website "Heat Street" that, after an initial June 2016 FBI request was denied, the FISA court had granted a more narrowly-focused October request from the FBI "to examine the activities of 'U.S. persons' in Donald Trump's campaign with ties to Russia". On 12 January 2017, BBC journalist Paul Wood reported that, in response to an April 2016 tip from a foreign intelligence agency to the CIA about "money from the Kremlin going into the US presidential campaign", a joint taskforce had been established including representatives of the FBI, the Department of the Treasury, the Department of Justice, the CIA, the Office of the Director of National Intelligence and the National Security Agency. In June 2016, lawyers from the Department of Justice applied to the FISA court for "permission to intercept the electronic records from two Russian banks". According to Wood, this application was rejected, as was a more narrowly focused request in July, and the order was finally granted by a different FISA judge on 15 October, three weeks before the presidential election. On January 19, "The New York Times" reported that one of its sources had claimed "intelligence reports based on some of the wiretapped communications had been provided to the White House".

On 13 March, the Senate Intelligence Committee demanded that the Trump administration provide evidence to support the President Trump's claim that former President Obama had wiretapped Trump Tower. On 16 March, the Committee reported that they had seen no evidence to support Trump's accusation that the Obama administration tapped his phones during the 2016 presidential campaign.

On Fox News on 14 March, commentator Andrew Napolitano said, "Three intelligence sources have informed Fox News that President Obama went outside the chain of command. ... He used GCHQ. What is that? It's the initials for the British intelligence spying agency. Simply by saying to them, 'The president needs transcripts of conversations involving candidate Trump's conversations' he's able to get it and there's no American fingerprints on this." Two days later, on 16 March, White House press spokesperson, Sean Spicer, read this claim to the press. A GCHQ spokesman responded: "Recent allegations made by media commentator Judge Andrew Napolitano about GCHQ being asked to conduct 'wiretapping' against the then president elect are nonsense. They are utterly ridiculous and should be ignored." On 17 March, the U.S. issued a formal apology to the United Kingdom for the accusation.

On April 11, "The Washington Post" reported that the FBI had been granted a FISA warrant in the summer of 2016 to monitor then-Trump foreign policy adviser Carter Page. According to the report, "The FBI and the Justice Department obtained the warrant targeting Carter Page's communications after convincing a Foreign Intelligence Surveillance Court judge that there was probable cause to believe Page was acting as an agent of a foreign power, in this case Russia, according to the officials." The report also states that the warrant has been renewed multiple times since its first issue. These warrants were criticized in the controversial Nunes memo for allegedly being issued on the basis of evidence gathered by politically motivated sources. However, this memo has come under attack from both Republican and Democrat lawmakers, as well as law enforcement authorities and intelligence officials for purportedly being written in a misleading and partisan manner and omitting key details.

When the court was founded, it was composed of seven federal district judges appointed by the Chief Justice of the United States, each serving a seven-year term, with one judge being appointed each year. In 2001, the USA PATRIOT Act expanded the court from seven to eleven judges, and required that at least three of the Court's judges live within of the District of Columbia. No judge may be appointed to this court more than once, and no judge may be appointed to both the Court of Review and the FISA court.

Chief Justice John Roberts has appointed all of the current judges.


Notes
References


</doc>
<doc id="11407" url="https://en.wikipedia.org/wiki?curid=11407" title="FC Den Bosch">
FC Den Bosch

FC Den Bosch () is a football club from 's-Hertogenbosch, Netherlands.

They were founded 18 August 1965, as FC Den Bosch/BVV. They are the successor of BVV (1906) and Wilhelmina (1890). Their stadium is called 'De Vliert', an 8,500 all-seater. Ruud van Nistelrooy started his professional career at this club. In 2005 they finished bottom of the Eredivisie and were relegated.


Below is a table with FC Den Bosch's domestic results since the introduction of professional football in 1956.


During the 2012–13 KNVB Cup quarter-final match against AZ, American forward Jozy Altidore was the target of racist chants. The club's director, Peter Bijvelds, blamed "malicious supporters making a scandalous mess of the evening". He said Den Bosch, AZ and the referee considered abandoning the match, but decided against it.

"We can't deny that, certainly when we play top matches, we have a structural problem with a group of people who ruin things", Bijvelds told Dutch radio.

This racial incident, however, was a minor one, and gravely offended the vast majority of Den Bosch supporters. Following this incident, the club and fans went on a series of actions to rectify the image of the club and re-instate their strong stance against any forms of racism. Evident to this was a campaign launched by the club to equip a village in Africa with football kits and football equipment.






</doc>
<doc id="11408" url="https://en.wikipedia.org/wiki?curid=11408" title="Female genital mutilation">
Female genital mutilation

Female genital mutilation (FGM), also known as female genital cutting and female circumcision, is the ritual cutting or removal of some or all of the external female genitalia. The practice is found in Africa, Asia and the Middle East, and within communities from countries in which FGM is common. UNICEF estimated in 2016 that 200 million women living today in 30 countries—27 African countries, Indonesia, Iraqi Kurdistan and Yemen—have undergone the procedures.

Typically carried out by a traditional circumciser using a blade, FGM is conducted from days after birth to puberty and beyond. In half the countries for which national figures are available, most girls are cut before the age of five. Procedures differ according to the country or ethnic group. They include removal of the clitoral hood and clitoral glans; removal of the inner labia; and removal of the inner and outer labia and closure of the vulva. In this last procedure, known as infibulation, a small hole is left for the passage of urine and menstrual fluid; the vagina is opened for intercourse and opened further for childbirth.

The practice is rooted in gender inequality, attempts to control women's sexuality, and ideas about purity, modesty and beauty. It is usually initiated and carried out by women, who see it as a source of honour and fear that failing to have their daughters and granddaughters cut will expose the girls to social exclusion. Adverse health effects depend on the type of procedure; they can include recurrent infections, difficulty urinating and passing menstrual flow, chronic pain, the development of cysts, an inability to get pregnant, complications during childbirth, and fatal bleeding. There are no known health benefits.

There have been international efforts since the 1970s to persuade practitioners to abandon FGM, and it has been outlawed or restricted in most of the countries in which it occurs, although the laws are poorly enforced. Since 2010 the United Nations has called upon healthcare providers to stop performing all forms of the procedure, including reinfibulation after childbirth and symbolic "nicking" of the clitoral hood. The opposition to the practice is not without its critics, particularly among anthropologists, who have raised difficult questions about cultural relativism and the universality of human rights.

Until the 1980s FGM was widely known in English as female circumcision, implying an equivalence in severity with male circumcision. From 1929 the Kenya Missionary Council referred to it as the sexual mutilation of women, following the lead of Marion Scott Stevenson, a Church of Scotland missionary. References to the practice as mutilation increased throughout the 1970s. In 1975 Rose Oldfield Hayes, an American anthropologist, used the term "female genital mutilation" in the title of a paper in "American Ethnologist", and four years later Fran Hosken, an Austrian-American feminist writer, called it mutilation in her influential "The Hosken Report: Genital and Sexual Mutilation of Females". The Inter-African Committee on Traditional Practices Affecting the Health of Women and Children began referring to it as female genital mutilation in 1990, and the World Health Organization (WHO) followed suit in 1991. Other English terms include "female genital cutting" (FGC) and "female genital mutilation/cutting" (FGM/C), preferred by those who work with practitioners.

In countries where FGM is common, the practice's many variants are reflected in dozens of terms, often alluding to purification. In the Bambara language, spoken mostly in Mali, it is known as "bolokoli" ("washing your hands") and in the Igbo language in eastern Nigeria as "isa aru" or "iwu aru" ("having your bath"). Other terms include "khifad", "tahoor", "quodiin, irua, bondo, kuruna, negekorsigin", and "kene-kene". A common Arabic term for purification has the root "t-h-r", used for male and female circumcision ("tahur" and "tahara"). It is also known in Arabic as "khafḍ" or "khifaḍ". Communities may refer to FGM as "pharaonic" for infibulation and "sunna" circumcision for everything else. "Sunna" means "path or way" in Arabic and refers to the tradition of Muhammad, although none of the procedures are required within Islam. The term "infibulation" derives from "fibula", Latin for clasp; the Ancient Romans reportedly fastened clasps through the foreskins or labia of slaves to prevent sexual intercourse. The surgical infibulation of women came to be known as pharaonic circumcision in Sudan, and as Sudanese circumcision in Egypt. In Somalia it is known simply as "qodob" ("to sew up").

The procedures are generally performed by a traditional circumciser (cutter or "exciseuse") in the girls' homes, with or without anaesthesia. The cutter is usually an older woman, but in communities where the male barber has assumed the role of health worker he will also perform FGM. When traditional cutters are involved, non-sterile devices are likely to be used, including knives, razors, scissors, glass, sharpened rocks and fingernails. According to a nurse in Uganda, quoted in 2007 in "The Lancet", a cutter would use one knife on up to 30 girls at a time. Health professionals are often involved in Egypt, Kenya, Indonesia and Sudan; in Egypt 77 percent of FGM procedures, and in Indonesia over 50 percent, were performed by medical professionals as of 2008 and 2016. Women in Egypt reported in 1995 that a local anaesthetic had been used on their daughters in 60 percent of cases, a general anaesthetic in 13 percent, and neither in 25 percent (two percent were missing/don't know).

The WHO, UNICEF and UNFPA issued a joint statement in 1997 defining FGM as "all procedures involving partial or total removal of the external female genitalia or other injury to the female genital organs whether for cultural or other non-therapeutic reasons". The procedures vary considerably according to ethnicity and individual practitioners. During a 1998 survey in Niger, women responded with over 50 different terms when asked what was done to them. Translation problems are compounded by the women's confusion over which type of FGM they experienced, or even whether they experienced it. Several studies have suggested that survey responses are unreliable. A 2003 study in Ghana found that in 1995 four percent said they had not undergone FGM, but in 2000 said they had, while 11 percent switched in the other direction. In Tanzania in 2005, 66 percent reported FGM, but a medical exam found that 73 percent had undergone it. In Sudan in 2006, a significant percentage of infibulated women and girls reported a less severe type.

Standard questionnaires from United Nations bodies ask women whether they or their daughters have undergone the following: (1) cut, no flesh removed (symbolic nicking); (2) cut, some flesh removed; (3) sewn closed; or (4) type not determined/unsure/doesn't know. The most common procedures fall within the "cut, some flesh removed" category and involve complete or partial removal of the clitoral glans. The World Health Organization (a UN agency) created a more detailed typology: Types I–III vary in how much tissue is removed; Type III is equivalent to the UNICEF category "sewn closed"; and Type IV describes miscellaneous procedures, including symbolic nicking.
Type I is "partial or total removal of the clitoris and/or the prepuce". Type Ia involves removal of the clitoral hood only. This is rarely performed alone. The more common procedure is Type Ib (clitoridectomy), the complete or partial removal of the clitoral glans (the visible tip of the clitoris) and clitoral hood. The circumciser pulls the clitoral glans with her thumb and index finger and cuts it off.

Type II (excision) is the complete or partial removal of the inner labia, with or without removal of the clitoral glans and outer labia. Type IIa is removal of the inner labia; Type IIb, removal of the clitoral glans and inner labia; and Type IIc, removal of the clitoral glans, inner and outer labia. "Excision" in French can refer to any form of FGM.

Type III (infibulation or pharaonic circumcision), the "sewn closed" category, involves the removal of the external genitalia and fusion of the wound. The inner and/or outer labia are cut away, with or without removal of the clitoral glans. Type III is found largely in northeast Africa, particularly Djibouti, Eritrea, Ethiopia, Somalia, and Sudan (although not in South Sudan). According to one 2008 estimate, over eight million women in Africa are living with Type III FGM. According to UNFPA in 2010, 20 percent of women with FGM have been infibulated. In Somalia "[t]he child is made to squat on a stool or mat facing the circumciser at a height that offers her a good view of the parts to be handled. ... adult helpers grab and pull apart the legs of the girl. ... If available, this is the stage at which a local anaesthetic would be used":

The element of speed and surprise is vital and the circumciser immediately grabs the clitoris by pinching it between her nails aiming to amputate it with a slash. The organ is then shown to the senior female relatives of the child who will decide whether the amount that has been removed is satisfactory or whether more is to be cut off.

After the clitoris has been satisfactorily amputated ... the circumciser can proceed with the total removal of the labia minora and the paring of the inner walls of the labia majora. Since the entire skin on the inner walls of the labia majora has to be removed all the way down to the perineum, this becomes a messy business. By now, the child is screaming, struggling, and bleeding profusely, which makes it difficult for the circumciser to hold with bare fingers and nails the slippery skin and parts that are to be cut or sutured together. ...

Having ensured that sufficient tissue has been removed to allow the desired fusion of the skin, the circumciser pulls together the opposite sides of the labia majora, ensuring that the raw edges where the skin has been removed are well approximated. The wound is now ready to be stitched or for thorns to be applied. If a needle and thread are being used, close tight sutures will be placed to ensure that a flap of skin covers the vulva and extends from the mons veneris to the perineum, and which, after the wound heals, will form a bridge of scar tissue that will totally occlude the vaginal introitus.
The amputated parts might be placed in a pouch for the girl to wear. A single hole of 2–3 mm is left for the passage of urine and menstrual fluid. The vulva is closed with surgical thread, or agave or acacia thorns, and might be covered with a poultice of raw egg, herbs and sugar. To help the tissue bond, the girl's legs are tied together, often from hip to ankle; the bindings are usually loosened after a week and removed after two to six weeks. If the remaining hole is too large in the view of the girl's family, the procedure is repeated.

The vagina is opened for sexual intercourse, for the first time either by a midwife with a knife or by the woman's husband with his penis. In some areas, including Somaliland, female relatives of the bride and groom might watch the opening of the vagina to check that the girl is a virgin. The woman is opened further for childbirth ("defibulation" or "deinfibulation"), and closed again afterwards ("reinfibulation"). Reinfibulation can involve cutting the vagina again to restore the pinhole size of the first infibulation. This might be performed before marriage, and after childbirth, divorce and widowhood. Hanny Lightfoot-Klein interviewed hundreds of women and men in Sudan in the 1980s about sexual intercourse with Type III:

The penetration of the bride's infibulation takes anywhere from 3 or 4 days to several months. Some men are unable to penetrate their wives at all (in my study over 15%), and the task is often accomplished by a midwife under conditions of great secrecy, since this reflects negatively on the man's potency. Some who are unable to penetrate their wives manage to get them pregnant in spite of the infibulation, and the woman's vaginal passage is then cut open to allow birth to take place. ... Those men who do manage to penetrate their wives do so often, or perhaps always, with the help of the "little knife". This creates a tear which they gradually rip more and more until the opening is sufficient to admit the penis.

Type IV is "[a]ll other harmful procedures to the female genitalia for non-medical purposes", including pricking, piercing, incising, scraping and cauterization. It includes nicking of the clitoris (symbolic circumcision), burning or scarring the genitals, and introducing substances into the vagina to tighten it. Labia stretching is also categorized as Type IV. Common in southern and eastern Africa, the practice is supposed to enhance sexual pleasure for the man and add to the sense of a woman as a closed space. From the age of eight, girls are encouraged to stretch their inner labia using sticks and massage. Girls in Uganda are told they may have difficulty giving birth without stretched labia.

A definition of FGM from the WHO in 1995 included gishiri cutting and angurya cutting, found in Nigeria and Niger. These were removed from the WHO's 2008 definition because of insufficient information about prevalence and consequences. Angurya cutting is excision of the hymen, usually performed seven days after birth. Gishiri cutting involves cutting the vagina's front or back wall with a blade or penknife, performed in response to infertility, obstructed labour and other conditions. In a study by Nigerian physician Mairo Usman Mandara, over 30 percent of women with gishiri cuts were found to have vesicovaginal fistulae (holes that allow urine to seep into the vagina).

FGM harms women's physical and emotional health throughout their lives. It has no known health benefits. The short-term and late complications depend on the type of FGM, whether the practitioner has had medical training, and whether they used antibiotics and sterilized or single-use surgical instruments. In the case of Type III, other factors include how small a hole was left for the passage of urine and menstrual blood, whether surgical thread was used instead of agave or acacia thorns, and whether the procedure was performed more than once (for example, to close an opening regarded as too wide or re-open one too small).
Common short-term complications include swelling, excessive bleeding, pain, urine retention, and healing problems/wound infection. A 2014 systematic review of 56 studies suggested that over one in ten girls and women undergoing any form of FGM, including symbolic nicking of the clitoris (Type IV), experience immediate complications, although the risks increased with Type III. The review also suggested that there was under-reporting. Other short-term complications include fatal bleeding, anaemia, urinary infection, septicaemia, tetanus, gangrene, necrotizing fasciitis (flesh-eating disease), and endometritis. It is not known how many girls and women die as a result of the practice, because complications may not be recognized or reported. The practitioners' use of shared instruments is thought to aid the transmission of hepatitis B, hepatitis C and HIV, although no epidemiological studies have shown this.

Late complications vary depending on the type of FGM. They include the formation of scars and keloids that lead to strictures and obstruction, epidermoid cysts that may become infected, and neuroma formation (growth of nerve tissue) involving nerves that supplied the clitoris. An infibulated girl may be left with an opening as small as 2–3 mm, which can cause prolonged, drop-by-drop urination, pain while urinating, and a feeling of needing to urinate all the time. Urine may collect underneath the scar, leaving the area under the skin constantly wet, which can lead to infection and the formation of small stones. The opening is larger in women who are sexually active or have given birth by vaginal delivery, but the urethra opening may still be obstructed by scar tissue. Vesicovaginal or rectovaginal fistulae can develop (holes that allow urine or faeces to seep into the vagina). This and other damage to the urethra and bladder can lead to infections and incontinence, pain during sexual intercourse and infertility. Painful periods are common because of the obstruction to the menstrual flow, and blood can stagnate in the vagina and uterus. Complete obstruction of the vagina can result in hematocolpos and hematometra (where the vagina and uterus fill with menstrual blood). The swelling of the abdomen that results from the collection of fluid, together with the lack of menstruation, can lead to suspicion of pregnancy; Asma El Dareer, a Sudanese physician, reported in 1979 that a girl in Sudan with this condition was killed by her family.

FGM may place women at higher risk of problems during pregnancy and childbirth, which are more common with the more extensive FGM procedures. Infibulated women may try to make childbirth easier by eating less during pregnancy to reduce the baby's size. In women with vesicovaginal or rectovaginal fistulae, it is difficult to obtain clear urine samples as part of prenatal care, making the diagnosis of conditions such as pre-eclampsia harder. Cervical evaluation during labour may be impeded and labour prolonged or obstructed. Third-degree laceration (tears), anal-sphincter damage and emergency caesarean section are more common in infibulated women.

Neonatal mortality is increased. The WHO estimated in 2006 that an additional 10–20 babies die per 1,000 deliveries as a result of FGM. The estimate was based on a study conducted on 28,393 women attending delivery wards at 28 obstetric centres in Burkina Faso, Ghana, Kenya, Nigeria, Senegal and Sudan. In those settings all types of FGM were found to pose an increased risk of death to the baby: 15 percent higher for Type I, 32 percent for Type II, and 55 percent for Type III. The reasons for this were unclear, but may be connected to genital and urinary tract infections and the presence of scar tissue. According to the study, FGM was associated with an increased risk to the mother of damage to the perineum and excessive blood loss, as well as a need to resuscitate the baby, and stillbirth, perhaps because of a long .

According to a 2015 systematic review there is little high-quality information available on the psychological effects of FGM. Several small studies have concluded that women with FGM suffer from anxiety, depression and post-traumatic stress disorder. Feelings of shame and betrayal can develop when women leave the culture that practises FGM and learn that their condition is not the norm, but within the practising culture they may view their FGM with pride, because for them it signifies beauty, respect for tradition, chastity and hygiene. Studies on sexual function have also been small. A 2013 meta-analysis of 15 studies involving 12,671 women from seven countries concluded that women with FGM were twice as likely to report no sexual desire and 52 percent more likely to report dyspareunia (painful sexual intercourse). One third reported reduced sexual feelings.

Aid agencies define the prevalence of FGM as the percentage of the 15–49 age group that has experienced it. These figures are based on nationally representative household surveys known as Demographic and Health Surveys (DHS), developed by Macro International and funded mainly by the United States Agency for International Development (USAID); and Multiple Indicator Cluster Surveys (MICS) conducted with financial and technical help from UNICEF. These surveys have been carried out in Africa, Asia, Latin America and elsewhere roughly every five years, since 1984 and 1995 respectively. The first to ask about FGM was the 1989–1990 DHS in northern Sudan. The first publication to estimate FGM prevalence based on DHS data (in seven countries) was written by Dara Carr of Macro International in 1997.

Questions the women are asked during the surveys include: "Was the genital area just nicked/cut without removing any flesh? Was any flesh (or something) removed from the genital area? Was your genital area sewn?" Most women report "cut, some flesh removed" (Types I and II).

Type I is the most common form in Egypt, and in the southern parts of Nigeria. Type III (infibulation) is concentrated in northeastern Africa, particularly Djibouti, Eritrea, Somalia and Sudan. In surveys in 2002–2006, 30 percent of cut girls in Djibouti, 38 percent in Eritrea, and 63 percent in Somalia had experienced Type III. There is also a high prevalence of infibulation among girls in Niger and Senegal, and in 2013 it was estimated that in Nigeria three percent of the 0–14 age group had been infibulated. The type of procedure is often linked to ethnicity. In Eritrea, for example, a survey in 2002 found that all Hedareb girls had been infibulated, compared with two percent of the Tigrinya, most of whom fell into the "cut, no flesh removed" category.

FGM is mostly found in what Gerry Mackie called an "intriguingly contiguous" zone in Africa—east to west from Somalia to Senegal, and north to south from Egypt to Tanzania. Nationally representative figures are available for 27 countries in Africa, as well as Indonesia, Iraqi Kurdistan and Yemen. Over 200 million women and girls are thought to be living with FGM in those 30 countries.

The highest concentrations among the 15–49 age group are in Somalia (98 percent), Guinea (97 percent), Djibouti (93 percent), Egypt (91 percent) and Sierra Leone (90 percent). As of 2013, 27.2 million women had undergone FGM in Egypt, 23.8 million in Ethiopia, and 19.9 million in Nigeria. There is a high concentration in Indonesia, where according to UNICEF Type I (clitoridectomy) and Type IV (symbolic nicking) are practised; the Indonesian Ministry of Health and Indonesian Ulema Council both say the clitoris should not be cut. The prevalence rate for the 0–11 group in Indonesia is 49 percent (13.4 million). Smaller studies or anecdotal reports suggest that FGM is also practised in Colombia, Jordan, Oman, Saudi Arabia and parts of Malaysia; in the United Arab Emirates; and in India by the Dawoodi Bohra. It is found within immigrant communities around the world.

Prevalence figures for the 15–19 age group and younger show a downward trend. For example, Burkina Faso fell from 89 percent (1980) to 58 percent (2010); Egypt from 97 percent (1985) to 70 percent (2015); and Kenya from 41 percent (1984) to 11 percent (2014). Beginning in 2010, household surveys asked women about the FGM status of all their living daughters. The highest concentrations among girls aged 0–14 were in Gambia (56 percent), Mauritania (54 percent), Indonesia (49 percent for 0–11) and Guinea (46 percent). The figures suggest that a girl was one third less likely in 2014 to undergo FGM than she was 30 years ago. According to a 2018 study published in "BMJ Global Health", the prevalence within the 0–14 year old group fell in East Africa from 71.4 percent in 1995 to 8 percent in 2016; in North Africa from 57.7 percent in 1990 to 14.1 percent in 2015; and in West Africa from 73.6 percent in 1996 to 25.4 percent in 2017. If the current rate of decline continues, the number of girls cut will nevertheless continue to rise because of population growth, according to UNICEF in 2014; they estimate that the figure will increase from 3.6 million a year in 2013 to 4.1 million in 2050.

Surveys have found FGM to be more common in rural areas, less common in most countries among girls from the wealthiest homes, and (except in Sudan and Somalia) less common in girls whose mothers had access to primary or secondary/higher education. In Somalia and Sudan the situation was reversed: in Somalia the mothers' access to secondary/higher education was accompanied by a rise in prevalence of FGM in their daughters, and in Sudan access to any education was accompanied by a rise.

FGM is not invariably a rite of passage between childhood and adulthood, but is often performed on much younger children. Girls are most commonly cut shortly after birth to age 15. In half the countries for which national figures were available in 2000–2010, most girls had been cut by age five. Over 80 percent (of those cut) are cut before the age of five in Nigeria, Mali, Eritrea, Ghana and Mauritania. The 1997 Demographic and Health Survey in Yemen found that 76 percent of girls had been cut within two weeks of birth. The percentage is reversed in Somalia, Egypt, Chad and the Central African Republic, where over 80 percent (of those cut) are cut between five and 14. Just as the type of FGM is often linked to ethnicity, so is the mean age. In Kenya, for example, the Kisi cut around age 10 and the Kamba at 16.

A country's national prevalence often reflects a high sub-national prevalence among certain ethnicities, rather than a widespread practice. In Iraq, for example, FGM is found mostly among the Kurds in Erbil (58 percent prevalence within age group 15–49, as of 2011), Sulaymaniyah (54 percent) and Kirkuk (20 percent), giving the country a national prevalence of eight percent. The practice is sometimes an ethnic marker, but it may differ along national lines. For example, in the northeastern regions of Ethiopia and Kenya, which share a border with Somalia, the Somali people practise FGM at around the same rate as they do in Somalia. But in Guinea all Fulani women responding to a survey in 2012 said they had experienced FGM, against 12 percent of the Fulani in Chad, while in Nigeria the Fulani are the only large ethnic group in the country not to practise it.

Dahabo Musa, a Somali woman, described infibulation in a 1988 poem as the "three feminine sorrows": the procedure itself, the wedding night when the woman is cut open, then childbirth when she is cut again. Despite the evident suffering, it is women who organize all forms of FGM. Anthropologist Rose Oldfield Hayes wrote in 1975 that educated Sudanese men who did not want their daughters to be infibulated (preferring clitoridectomy) would find the girls had been sewn up after the grandmothers arranged a visit to relatives. Gerry Mackie has compared the practice to footbinding. Like FGM, footbinding was carried out on young girls, nearly universal where practised, tied to ideas about honour, chastity and appropriate marriage, and "supported and transmitted" by women.
FGM practitioners see the procedures as marking not only ethnic boundaries but also gender difference. According to this view, male circumcision defeminizes men while FGM demasculinizes women. Fuambai Ahmadu, an anthropologist and member of the Kono people of Sierra Leone, who in 1992 underwent clitoridectomy as an adult during a Sande society initiation, argued in 2000 that it is a male-centred assumption that the clitoris is important to female sexuality. African female symbolism revolves instead around the concept of the womb. Infibulation draws on that idea of enclosure and fertility. "[G]enital cutting completes the social definition of a child's sex by eliminating external traces of androgyny," Janice Boddy wrote in 2007. "The female body is then covered, closed, and its productive blood bound within; the male body is unveiled, opened and exposed."

In communities where infibulation is common, there is a preference for women's genitals to be smooth, dry and without odour, and both women and men may find the natural vulva repulsive. Some men seem to enjoy the effort of penetrating an infibulation. The local preference for dry sex causes women to introduce substances into the vagina to reduce lubrication, including leaves, tree bark, toothpaste and Vicks menthol rub. The WHO includes this practice within Type IV FGM, because the added friction during intercourse can cause lacerations and increase the risk of infection. Because of the smooth appearance of an infibulated vulva, there is also a belief that infibulation increases hygiene.

Common reasons for FGM cited by women in surveys are social acceptance, religion, hygiene, preservation of virginity, marriageability and enhancement of male sexual pleasure. In a study in northern Sudan, published in 1983, only 17.4 percent of women opposed FGM (558 out of 3,210), and most preferred excision and infibulation over clitoridectomy. Attitudes are changing slowly. In Sudan in 2010, 42 percent of women who had heard of FGM said the practice should continue. In several surveys since 2006, over 50 percent of women in Mali, Guinea, Sierra Leone, Somalia, Gambia and Egypt supported FGM's continuance, while elsewhere in Africa, Iraq and Yemen most said it should end, although in several countries only by a narrow margin.

Against the argument that women willingly choose FGM for their daughters, UNICEF calls the practice a "self-enforcing social convention" to which families feel they must conform to avoid uncut daughters facing social exclusion. Ellen Gruenbaum reported that, in Sudan in the 1970s, cut girls from an Arab ethnic group would mock uncut Zabarma girls with "Ya, Ghalfa!" ("Hey, unclean!"). The Zabarma girls would respond "Ya, mutmura!" (A "mutmara" was a storage pit for grain that was continually opened and closed, like an infibulated woman.) But despite throwing the insult back, the Zabarma girls would ask their mothers, "What's the matter? Don't we have razor blades like the Arabs?"

Because of poor access to information, and because circumcisers downplay the causal connection, women may not associate the health consequences with the procedure. Lala Baldé, president of a women's association in Medina Cherif, a village in Senegal, told Mackie in 1998 that when girls fell ill or died, it was attributed to evil spirits. When informed of the causal relationship between FGM and ill health, Mackie wrote, the women broke down and wept. He argued that surveys taken before and after this sharing of information would show very different levels of support for FGM. The American non-profit group Tostan, founded by Molly Melching in 1991, introduced community-empowerment programs in several countries that focus on local democracy, literacy, and education about healthcare, giving women the tools to make their own decisions. In 1997, using the Tostan program, Malicounda Bambara in Senegal became the first village to abandon FGM. By 2018 over 8,000 communities in eight countries had pledged to abandon FGM and child marriage.

Surveys have shown a widespread belief, particularly in Mali, Mauritania, Guinea and Egypt, that FGM is a religious requirement. Gruenbaum has argued that practitioners may not distinguish between religion, tradition and chastity, making it difficult to interpret the data. FGM's origins in northeastern Africa are pre-Islamic, but the practice became associated with Islam because of that religion's focus on female chastity and seclusion. There is no mention of it in the Quran. It is praised in a few "daʻīf" (weak) "hadith" (sayings attributed to Muhammad) as noble but not required, although it is regarded as obligatory by the Shafi'i version of Sunni Islam. In 2007 the Al-Azhar Supreme Council of Islamic Research in Cairo ruled that FGM had "no basis in core Islamic law or any of its partial provisions".

There is no mention of FGM in the Bible. Christian missionaries in Africa were among the first to object to FGM, but Christian communities in Africa do practise it. A 2013 UNICEF report identified 17 African countries in which at least 10 percent of Christian women and girls aged 15 to 49 had undergone FGM; in Niger 55 percent of Christian women and girls had experienced it, compared with two percent of their Muslim counterparts. The only Jewish group known to have practised it are the Beta Israel of Ethiopia. Judaism requires male circumcision, but does not allow FGM. FGM is also practised by animist groups, particularly in Guinea and Mali.
The practice's origins are unknown. Gerry Mackie has suggested that, because FGM's east-west, north-south distribution in Africa meets in Sudan, infibulation may have begun there with the Meroite civilization (c. 800 BCE – c. 350 CE), before the rise of Islam, to increase confidence in paternity. According to historian Mary Knight, Spell 1117 (c. 1991–1786 BCE) of the Ancient Egyptian Coffin Texts may refer in hieroglyphs to an uncircumcised girl ("'m't"):

a-m-a:X1-D53-B1

The spell was found on the sarcophagus of Sit-hedjhotep, now in the Egyptian Museum, and dates to Egypt's Middle Kingdom. (Paul F. O'Rourke argues that "'m't" probably refers instead to a menstruating woman.) The proposed circumcision of an Egyptian girl, Tathemis, is also mentioned on a Greek papyrus, from 163 BCE, in the British Museum: "Sometime after this, Nephoris [Tathemis's mother] defrauded me, being anxious that it was time for Tathemis to be circumcised, as is the custom among the Egyptians."

The examination of mummies has shown no evidence of FGM. Citing the Australian pathologist Grafton Elliot Smith, who examined hundreds of mummies in the early 20th century, Knight writes that the genital area may resemble Type III because during mummification the skin of the outer labia was pulled toward the anus to cover the pudendal cleft, possibly to prevent sexual violation. It was similarly not possible to determine whether Types I or II had been performed, because soft tissues had deteriorated or been removed by the embalmers.

The Greek geographer Strabo (c. 64 BCE – c. 23 CE) wrote about FGM after visiting Egypt around 25 BCE: "This is one of the customs most zealously pursued by them [the Egyptians]: to raise every child that is born and to circumcise ["peritemnein"] the males and excise ["ektemnein"] the females ..." Philo of Alexandria (c. 20 BCE – 50 CE) also made reference to it: "the Egyptians by the custom of their country circumcise the marriageable youth and maid in the fourteenth (year) of their age, when the male begins to get seed, and the female to have a menstrual flow." It is mentioned briefly in a work attributed to the Greek physician Galen (129 – c. 200 CE): "When [the clitoris] sticks out to a great extent in their young women, Egyptians consider it appropriate to cut it out." Another Greek physician, Aëtius of Amida (mid-5th to mid-6th century CE), offered more detail in book 16 of his "Sixteen Books on Medicine", citing the physician Philomenes. The procedure was performed in case the clitoris, or "nymphê", grew too large or triggered sexual desire when rubbing against clothing. "On this account, it seemed proper to the Egyptians to remove it before it became greatly enlarged," Aëtius wrote, "especially at that time when the girls were about to be married":

The surgery is performed in this way: Have the girl sit on a chair while a muscled young man standing behind her places his arms below the girl's thighs. Have him separate and steady her legs and whole body. Standing in front and taking hold of the clitoris with a broad-mouthed forceps in his left hand, the surgeon stretches it outward, while with the right hand, he cuts it off at the point next to the pincers of the forceps.

It is proper to let a length remain from that cut off, about the size of the membrane that's between the nostrils, so as to take away the excess material only; as I have said, the part to be removed is at that point just above the pincers of the forceps. Because the clitoris is a skinlike structure and stretches out excessively, do not cut off too much, as a urinary fistula may result from cutting such large growths too deeply.

The genital area was then cleaned with a sponge, frankincense powder and wine or cold water, and wrapped in linen bandages dipped in vinegar, until the seventh day when calamine, rose petals, date pits or a "genital powder made from baked clay" might be applied.

Whatever the practice's origins, infibulation became linked to slavery. Mackie cites the Portuguese missionary João dos Santos, who in 1609 wrote of a group near Mogadishu who had a "custome to sew up their Females, especially their slaves being young to make them unable for conception, which makes these slaves sell dearer, both for their chastitie, and for better confidence which their Masters put in them". Thus, Mackie argues, a "practice associated with shameful female slavery came to stand for honor".

Gynaecologists in 19th-century Europe and the United States removed the clitoris to treat insanity and masturbation. A British doctor, Robert Thomas, suggested clitoridectomy as a cure for nymphomania in 1813.
The first reported clitoridectomy in the West, described in "The Lancet" in 1825, was performed in 1822 in Berlin by Karl Ferdinand von Graefe on a 15-year-old girl who was masturbating excessively.

Isaac Baker Brown, an English gynaecologist, president of the Medical Society of London and co-founder in 1845 of St. Mary's Hospital, believed that masturbation, or "unnatural irritation" of the clitoris, caused hysteria, spinal irritation, fits, idiocy, mania and death. He therefore "set to work to remove the clitoris whenever he had the opportunity of doing so", according to his obituary. Brown performed several clitoridectomies between 1859 and 1866. In the United States, J. Marion Sims followed Brown's work and in 1862 slit the neck of a woman's uterus and amputated her clitoris, "for the relief of the nervous or hysterical condition as recommended by Baker Brown". When Brown published his views in "On the Curability of Certain Forms of Insanity, Epilepsy, Catalepsy, and Hysteria in Females" (1866), doctors in London accused him of quackery and expelled him from the Obstetrical Society.

Later in the 19th century, A. J. Bloch, a surgeon in New Orleans, removed the clitoris of a two-year-old girl who was reportedly masturbating. According to a 1985 paper in the "Obstetrical & Gynecological Survey", clitoridectomy was performed in the United States into the 1960s to treat hysteria, erotomania and lesbianism. From the mid-1950s, James Burt, a gynaecologist in Dayton, Ohio, performed non-standard repairs of episiotomies after childbirth, adding more stitches to make the vaginal opening smaller. From 1966 until 1989, he performed "love surgery" by cutting women's pubococcygeus muscle, repositioning the vagina and urethra, and removing the clitoral hood, thereby making their genital area more appropriate, in his view, for intercourse in the missionary position. "Women are structurally inadequate for intercourse," he wrote; he said he would turn them into "horny little mice". In the 1960s and 1970s he performed these procedures without consent while repairing episiotomies and performing hysterectomies and other surgery; he said he had performed a variation of them on 4,000 women by 1975. Following complaints, he was required in 1989 to stop practicing medicine in the United States.

Protestant missionaries in British East Africa (present-day Kenya) began campaigning against FGM in the early 20th century, when Dr. John Arthur joined the Church of Scotland Mission (CSM) in Kikuyu. An important ethnic marker, the practice was known by the Kikuyu, the country's main ethnic group, as "irua" for both girls and boys. It involved excision (Type II) for girls and removal of the foreskin for boys. Unexcised Kikuyu women ("irugu") were outcasts.

Jomo Kenyatta, general secretary of the Kikuyu Central Association and later Kenya's first prime minister, wrote in 1938 that, for the Kikuyu, the institution of FGM was the ""conditio sine qua non" of the whole teaching of tribal law, religion and morality". No proper Kikuyu man or woman would marry or have sexual relations with someone who was not circumcised. A woman's responsibilities toward the tribe began with her initiation. Her age and place within tribal history was traced to that day, and the group of girls with whom she was cut was named according to current events, an oral tradition that allowed the Kikuyu to track people and events going back hundreds of years.

Beginning with the CSM mission in 1925, several missionary churches declared that FGM was prohibited for African Christians. The CSM announced that Africans practising it would be excommunicated, which resulted in hundreds leaving or being expelled. The stand-off turned FGM into a focal point of the Kenyan independence movement; the 1929–1931 period is known in the country's historiography as the female circumcision controversy.

In 1929 the Kenya Missionary Council began referring to FGM as the "sexual mutilation of women", rather than circumcision, and a person's stance toward the practice became a test of loyalty, either to the Christian churches or to the Kikuyu Central Association. Hulda Stumpf, an American missionary with the Africa Inland Mission who opposed FGM in the girls' school she helped to run, was murdered in 1930. Edward Grigg, the governor of Kenya, told the British Colonial Office that the killer, who was never identified, had tried to circumcise her.

In 1956 the council of male elders (the "Njuri Nchecke") in Meru announced a ban on FGM. Over the next three years, thousands of girls cut each other's genitals with razor blades as a symbol of defiance. The movement came to be known as "Ngaitana" ("I will circumcise myself"), because to avoid naming their friends the girls said they had cut themselves. Historian Lynn Thomas described the episode as significant in the history of FGM because it made clear that its victims were also its perpetrators. FGM was eventually outlawed in Kenya in 2001, although the practice continued, reportedly driven by older women.

The first known non-colonial campaign against FGM began in Egypt in the 1920s, when the Egyptian Doctors' Society called for a ban. There was a parallel campaign in Sudan, run by religious leaders and British women. Infibulation was banned there in 1946, but the law was unpopular and barely enforced. The Egyptian government banned infibulation in state-run hospitals in 1959, but allowed partial clitoridectomy if parents requested it. (Egypt banned FGM entirely in 2007.)

In 1959, the UN asked the WHO to investigate FGM, but the latter responded that it was not a medical matter. Feminists took up the issue throughout the 1970s. The Egyptian physician and feminist Nawal El Saadawi criticized FGM in her book "Women and Sex" (1972); the book was banned in Egypt and El Saadawi lost her job as director general of public health. She followed up with a chapter, "The Circumcision of Girls", in her book "The Hidden Face of Eve: Women in the Arab World" (1980), which described her own clitoridectomy when she was six years old:

I did not know what they had cut off from my body, and I did not try to find out. I just wept, and called out to my mother for help. But the worst shock of all was when I looked around and found her standing by my side. Yes, it was her, I could not be mistaken, in flesh and blood, right in the midst of these strangers, talking to them and smiling at them, as though they had not participated in slaughtering her daughter just a few moments ago.
In 1975, Rose Oldfield Hayes, an American social scientist, became the first female academic to publish a detailed account of FGM, aided by her ability to discuss it directly with women in Sudan. Her article in "American Ethnologist" called it "female genital mutilation", rather than female circumcision, and brought it to wider academic attention. Edna Adan Ismail, who worked at the time for the Somalia Ministry of Health, discussed the health consequences of FGM in 1977 with the Somali Women's Democratic Organization. Two years later Fran Hosken, an Austria-American feminist, published "The Hosken Report: Genital and Sexual Mutilation of Females" (1979), the first to offer global figures. She estimated that 110,529,000 women in 20 African countries had experienced FGM. The figures were speculative but consistent with later surveys. Describing FGM as a "training ground for male violence", Hosken accused female practitioners of "participating in the destruction of their own kind". The language caused a rift between Western and African feminists; African women boycotted a session featuring Hosken during the UN's Mid-Decade Conference on Women in Copenhagen in July 1980.

In 1979, the WHO held a seminar, "Traditional Practices Affecting the Health of Women and Children", in Khartoum, Sudan, and in 1981, also in Khartoum, 150 academics and activists signed a pledge to fight FGM after a workshop held by the Babiker Badri Scientific Association for Women's Studies (BBSAWS), "Female Circumcision Mutilates and Endangers Women – Combat it!" Another BBSAWS workshop in 1984 invited the international community to write a joint statement for the United Nations. It recommended that the "goal of all African women" should be the eradication of FGM and that, to sever the link between FGM and religion, clitoridectomy should no longer be referred to as "sunna".

The Inter-African Committee on Traditional Practices Affecting the Health of Women and Children, founded in 1984 in Dakar, Senegal, called for an end to the practice, as did the UN's World Conference on Human Rights in Vienna in 1993. The conference listed FGM as a form of violence against women, marking it as a human-rights violation, rather than a medical issue. Throughout the 1990s and 2000s governments in Africa and the Middle East passed legislation banning or restricting FGM. In 2003 the African Union ratified the Maputo Protocol on the rights of women, which supported the elimination of FGM. By 2015 laws restricting FGM had been passed in at least 23 of the 27 African countries in which it is concentrated, although several fell short of a ban.

In December 1993, the United Nations General Assembly included FGM in resolution 48/104, the Declaration on the Elimination of Violence Against Women, and from 2003 sponsored International Day of Zero Tolerance for Female Genital Mutilation, held every 6 February. UNICEF began in 2003 to promote an evidence-based social norms approach, using ideas from game theory about how communities reach decisions about FGM, and building on the work of Gerry Mackie on the demise of footbinding in China. In 2005 the UNICEF Innocenti Research Centre in Florence published its first report on FGM. UNFPA and UNICEF launched a joint program in Africa in 2007 to reduce FGM by 40 percent within the 0–15 age group and eliminate it from at least one country by 2012, goals that were not met and which they later described as unrealistic. In 2008 several UN bodies recognized FGM as a human-rights violation, and in 2010 the UN called upon healthcare providers to stop carrying out the procedures, including reinfibulation after childbirth and symbolic nicking. In 2012 the General Assembly passed resolution 67/146, "Intensifying global efforts for the elimination of female genital mutilations".

Immigration spread the practice to Australia, New Zealand, Europe and North America, all of which outlawed it entirely or restricted it to consenting adults. Sweden outlawed FGM in 1982 with the "Act Prohibiting the Genital Mutilation of Women", the first Western country to do so. Several former colonial powers, including Belgium, Britain, France and the Netherlands, introduced new laws or made clear that it was covered by existing legislation. legislation banning FGM had been passed in 33 countries outside Africa and the Middle East.

In the United States an estimated 513,000 women and girls had experienced FGM or were at risk as of 2012. A Nigerian woman successfully contested deportation in March 1994 on the grounds that her daughters might be cut, and in 1996 Fauziya Kasinga from Togo became the first to be granted asylum to escape FGM. In 1996 the Federal Prohibition of Female Genital Mutilation Act made it illegal to perform FGM on minors for non-medical reasons, and in 2013 the Transport for Female Genital Mutilation Act prohibited transporting a minor out of the country for the purpose of FGM. The first FGM conviction in the US was in 2006, when Khalid Adem, who had emigrated from Ethiopia, was sentenced to ten years for aggravated battery and cruelty to children after severing his two-year-old daughter's clitoris with a pair of scissors. A federal judge ruled in 2018 that the 1996 Act was unconstitutional, arguing that FGM is a "local criminal activity" that should be regulated by states, not by Congress; he made his ruling during a case against members of the Dawoodi Bohra community in Michigan accused of carrying out FGM. Twenty-four states had legislation banning FGM as of 2016. The American Academy of Pediatrics opposes all forms of the practice, including pricking the clitoral skin.

Canada recognized FGM as a form of persecution in July 1994, when it granted refugee status to Khadra Hassan Farah, who had fled Somalia to avoid her daughter being cut. In 1997 section 268 of its Criminal Code was amended to ban FGM, except where "the person is at least eighteen years of age and there is no resulting bodily harm". there had been no prosecutions. Canadian officials have expressed concern that a few thousand Canadian girls are at risk of "vacation cutting", whereby girls are taken overseas to undergo the procedure, but as of 2017 there were no firm figures.

According to the European Parliament, 500,000 women in Europe had undergone FGM . France is known for its tough stance against FGM. Up to 30,000 women there were thought to have experienced it as of 1995. According to Colette Gallard, a family-planning counsellor, when FGM was first encountered in France, the reaction was that Westerners ought not to intervene. It took the deaths of two girls in 1982, one of them three months old, for that attitude to change. In 1991 a French court ruled that the Convention Relating to the Status of Refugees offered protection to FGM victims; the decision followed an asylum application from Aminata Diop, who fled an FGM procedure in Mali. The practice is outlawed by several provisions of France's penal code that address bodily harm causing permanent mutilation or torture. All children under six who were born in France undergo medical examinations that include inspection of the genitals, and doctors are obliged to report FGM. The first civil suit was in 1982, and the first criminal prosecution in 1993. In 1999 a woman was given an eight-year sentence for having performed FGM on 48 girls. By 2014 over 100 parents and two practitioners had been prosecuted in over 40 criminal cases.

Around 137,000 women and girls living in England and Wales were born in countries where FGM is practised, as of 2011. Performing FGM on children or adults was outlawed under the Prohibition of Female Circumcision Act 1985. This was replaced by the Female Genital Mutilation Act 2003 and Prohibition of Female Genital Mutilation (Scotland) Act 2005, which added a prohibition on arranging FGM outside the country for British citizens or permanent residents. The United Nations Committee on the Elimination of Discrimination against Women (CEDAW) asked the government in July 2013 to "ensure the full implementation of its legislation on FGM". The first charges were brought in 2014 against a physician and another man; the physician had stitched an infibulated woman after opening her for childbirth. Both men were acquitted in 2015.

Anthropologists have accused FGM eradicationists of cultural colonialism, and have been criticized in turn for their moral relativism and failure to defend the idea of universal human rights. According to critics of the eradicationist position, the biological reductionism of the opposition to FGM, and the failure to appreciate FGM's cultural context, serves to "other" practitioners and undermine their agency—in particular when parents are referred to as "mutilators".

Africans who object to the tone of FGM opposition risk appearing to defend the practice. The feminist theorist Obioma Nnaemeka, herself strongly opposed to FGM, argued in 2005 that renaming the practice "female genital mutilation" had introduced "a subtext of barbaric African and Muslim cultures and the West's relevance (even indispensability) in purging [it]". According to Ugandan law professor Sylvia Tamale, the early Western opposition to FGM stemmed from a Judeo-Christian judgment that African sexual and family practices, including not only FGM but also dry sex, polygyny, bride price and levirate marriage, required correction. African feminists "take strong exception to the imperialist, racist and dehumanising infantilization of African women", she wrote in 2011. Commentators highlight the voyeurism in the treatment of women's bodies as exhibits. Examples include images of women's vaginas after FGM or girls undergoing the procedure. The 1996 Pulitzer-prize-winning photographs of a 16-year-old Kenyan girl experiencing FGM were published by 12 American newspapers, without her consent either to be photographed or to have the images published.

The debate has highlighted a tension between anthropology and feminism, with the former's focus on tolerance and the latter's on equal rights for women. According to the anthropologist Christine Walley, a common position in anti-FGM literature has been to present African women as victims of false consciousness participating in their own oppression, a position promoted by feminists in the 1970s and 1980s, including Fran Hosken, Mary Daly and Hanny Lightfoot-Klein. It prompted the French Association of Anthropologists to issue a statement in 1981, at the height of the early debates, that "a certain feminism resuscitates (today) the moralistic arrogance of yesterday's colonialism".

Nnaemeka argues that the crucial question, broader than FGM, is why the female body is subjected to so much "abuse and indignity", including in the West. Several authors have drawn a parallel between FGM and cosmetic procedures. Ronán Conroy of the Royal College of Surgeons in Ireland wrote in 2006 that cosmetic genital procedures were "driving the advance" of FGM by encouraging women to see natural variations as defects. Anthropologist Fadwa El Guindi compared FGM to breast enhancement, in which the maternal function of the breast becomes secondary to men's sexual pleasure. Benoîte Groult, the French feminist, made a similar point in 1975, citing FGM and cosmetic surgery as sexist and patriarchal. Against this, the medical anthropologist Carla Obermeyer argued in 1999 that FGM may be conducive to a subject's social well-being in the same way that rhinoplasty and male circumcision are. Despite the 2007 ban in Egypt, Egyptian women wanting FGM for their daughters seek "amalyet tajmeel" (cosmetic surgery) to remove what they see as excess genital tissue.
Cosmetic procedures such as labiaplasty and clitoral hood reduction do fall within the WHO's definition of FGM, which aims to avoid loopholes, but the WHO notes that these elective practices are generally not regarded as FGM. Some legislation banning FGM, such as in Canada and the US, covers minors only, but several countries, including Sweden and the UK, have banned it regardless of consent. Sweden, for example, has banned operations "on the outer female sexual organs with a view to mutilating them or bringing about some other permanent change in them, regardless of whether or not consent has been given for the operation". Gynaecologist Birgitta Essén and anthropologist Sara Johnsdotter argue that the law seems to distinguish between Western and African genitals, and deems only African women (such as those seeking reinfibulation after childbirth) unfit to make their own decisions.

The philosopher Martha Nussbaum argues that a key concern with FGM is that it is mostly conducted on children using physical force. The distinction between social pressure and physical force is morally and legally salient, comparable to the distinction between seduction and rape. She argues further that the literacy of women in practising countries is generally poorer than in developed nations, which reduces their ability to make informed choices.

Several commentators maintain that children's rights are violated not only by FGM but also by the genital alteration of intersex children, who are born with anomalies that physicians choose to correct. Arguments have been made that non-therapeutic male circumcision, practised by Muslims, Jews and some Christian groups, also violates children's rights. Globally about 30 percent of males over 15 are circumcised; of these, about two-thirds are Muslim. An American Academy of Pediatrics circumcision task force issued a policy statement in 2012 that the health benefits of male circumcision outweigh the risks; they recommended that it be carried out, if it is performed, by "trained and competent practitioners ... using sterile techniques and effective pain management". The statement met with protests from a group of 38 doctors in Europe, who accused the task force of "cultural bias". At least half the male population of the United States is circumcised, while most men in Europe are not.


Books and book chapters
Journal articles

United Nations reports

Personal stories


</doc>
<doc id="11411" url="https://en.wikipedia.org/wiki?curid=11411" title="Fermentation (disambiguation)">
Fermentation (disambiguation)

Fermentation is a metabolic process whereby electrons released from nutrients are ultimately transferred to molecules obtained from the breakdown of those same nutrients.

Fermentation may also refer to:




</doc>
<doc id="11415" url="https://en.wikipedia.org/wiki?curid=11415" title="Forcemeat">
Forcemeat

Forcemeat (derived from the French "farcir", "to stuff") is a mixture of ground, lean meat mixed with fat by grinding, sieving, or puréeing the ingredients. The result may either be smooth or coarse, depending on the desired consistency of the final product. Forcemeats are used in the production of numerous items found in charcuterie, including quenelles, sausages, pâtés, terrines, roulades, and galantines. Forcemeats are usually produced from raw meat, except in the case of a "gratin". Meats commonly used include pork, fish (pike, trout, or salmon), seafood, game meats (venison, boar, or rabbit), poultry, game birds, veal, and pork livers. Pork fatback is preferred as a fat, as it has a somewhat neutral flavor.

Forcemeats are an ancient food, and are included in "Apicius", a collection of Roman cookery recipes, usually thought to have been compiled in the late 4th or early 5th century AD.


Often, the only binder in a forcemeat is the physical structure of the protein used. Sometimes a secondary binder is necessary to hold the mixture. These binders are generally needed when preparing the country-style and "gratin" forcemeats. The three types of binders are eggs, dry milk powder, and panades. A panade can be made from starchy ingredients which aid in the binding process; these include well-cooked potatoes which have been puréed, cream-soaked bread, or pâte à choux.




</doc>
<doc id="11417" url="https://en.wikipedia.org/wiki?curid=11417" title="Forseti">
Forseti

Forseti (Old Norse "the presiding one," actually "president" in modern Icelandic and Faroese) is the god of justice and reconciliation in Norse mythology. He is generally identified with Fosite, a god of the Frisians. Jacob Grimm noted that if, as Adam of Bremen states, Fosite's sacred island was Heligoland, that would make him an ideal candidate for a deity known to both Frisians and Scandinavians, but that it is surprising he is never mentioned by Saxo Grammaticus.

Grimm took "Forseti", ""praeses"", to be the older form of the name, first postulating an unattested Old High German equivalent *"forasizo" (cf. modern German "Vorsitzender" "one who presides"). but later preferring a derivation from "fors", a "whirling stream" or "cataract", connected to the spring and the god's veneration by seagoing peoples. It is plausible that "Fosite" is the older name and "Forseti" a folk etymology. According to the German philologist, Hans Kuhn, the Germanic form Fosite is linguistically identical to Greek "Poseidon", hence the original name must have been introduced before the Proto-Germanic sound change, probably via Greek sailors purchasing amber. The Greek traveller Pytheas of Massalia, who describes the amber trade, is known to have visited the region around 325 BC.

According to Snorri Sturluson in the Prose Edda, Forseti is the son of Baldr and Nanna. His home is Glitnir, its name, meaning "shining," refers to its silver ceiling and golden pillars, which radiated light that could be seen from a great distance. His is the best of courts; all those who come before him leave reconciled. This suggests skill in mediation and is in contrast to his fellow god Týr, who "is not called a reconciler of men." However, as de Vries points out, the only basis for associating Forseti with justice seems to have been his name; there is no corroborating evidence in Norse mythology. 'Puts to sleep all suits' or 'stills all strifes' may have been a late addition to the strophe Snorri cites, from which he derives the information.

The first element in the name "Forsetlund" (Old Norse "Forsetalundr"), a farm in the parish of Onsøy ('Odin's island'), in eastern Norway, seems to be the genitive case of Forseti, offering evidence he was worshipped there.

According to Alcuin's Life of St. Willebrord, the saint visited an island between Frisia and Denmark that was sacred to Fosite and was called Fositesland after the god worshipped there. There was a sacred spring from which water had to be drawn in silence, it was so holy. Willebrord defiled the spring by baptizing people in it and killing a cow there. Altfrid tells the same story of St. Liudger. Adam of Bremen retells the story and adds that the island was "Heiligland", i.e., Heligoland.

There is also a late-medieval legend of the origins of written Frisian laws. Wishing to assemble written lawcodes for all his subject peoples, Charlemagne summoned twelve representatives of the Frisian people, the "Āsegas" ('law-speakers'), and demanded they recite their people's laws. When they could not do so after several days, he let them choose between death, slavery, or being set adrift in a rudderless boat. They chose the last and prayed for help, whereupon a thirteenth man appeared, with a golden axe on his shoulder. He steered the boat to land with the axe, then threw it ashore; a spring appeared where it landed. He taught them laws and then disappeared. The stranger and the spring have traditionally been identified with Fosite and the sacred spring of Fositesland.

Modern scholarship, however, is critical about this hypotheses, as the attribute of the axe is normally associated with Thor, not with Forseti.

The German neofolk band Forseti named itself after the god.




</doc>
<doc id="11418" url="https://en.wikipedia.org/wiki?curid=11418" title="Fiorello H. La Guardia">
Fiorello H. La Guardia

Fiorello Henry La Guardia (; born Fiorello Enrico La Guardia, ; December 11, 1882September 20, 1947) was an American politician. He is best known for being the 99th Mayor of New York City for three terms from 1934 to 1945 as a Republican. Previously he had been elected to Congress in 1916 and 1918, and again from 1922 through 1930. Irascible, energetic, and charismatic, he craved publicity and is acclaimed as one of the greatest mayors in American history. Only five feet, two inches (1.57 m) tall, he was called "the Little Flower" ("" is Italian for "little flower").

La Guardia, a Republican who appealed across party lines, was very popular in New York during the 1930s. As a New Dealer, he supported President Franklin D. Roosevelt, a Democrat, and in turn Roosevelt heavily funded the city and cut off patronage for La Guardia's enemies. La Guardia revitalized New York City and restored public faith in City Hall. He unified the transit system, directed the building of low-cost public housing, public playgrounds, and parks, constructed airports, reorganized the police force, defeated the powerful Tammany Hall political machine, and reestablished employment on merit in place of patronage jobs. La Guardia is also remembered for his WNYC radio program "Talk to the People," which aired from December 1941 until December 1945.

La Guardia was seen as a domineering leader who verged on authoritarian but whose reform politics were carefully tailored to address the sentiments of his diverse constituency. He won elections against the historically corrupt Tammany Hall political system, presided during the Great Depression and World War II, implemented New Deal welfare and public works programs in the city, and gave political support to immigrants and ethnic minorities. He was also supported by President Roosevelt. La Guardia was known as a reform mayor who helped clean out corruption, brought in experts, and made the city responsible for its own citizens. His administration engaged new groups that had been kept out of the political system, gave New York its modern infrastructure, and raised expectations of new levels of urban possibility.

La Guardia was born in Greenwich Village in New York City. His father, Achille La Guardia, was a lapsed Catholic from Cerignola, Italy, and his mother, Irene Coen, was a Jewish woman from Trieste, then part of the Austro-Hungarian Empire; his maternal grandmother Fiorina Luzzatto Coen was a Luzzatto, a member of the prestigious Italian-Jewish family of scholars, kabbalists, and poets and had among her ancestors the famous rabbi Samuel David Luzzatto. It was in Trieste that Achille La Guardia met and married Irene. Fiorello La Guardia was raised an Episcopalian and practiced that religion all his life. His middle name "Enrico" was anglicized to "Henry" when he was a child.

He moved to Arizona with his family, where his father had a bandmaster position at Fort Whipple in the U.S. Army. La Guardia attended public schools and high school in Prescott, Arizona. After his father was discharged from his bandmaster position in 1898, Fiorello lived in Trieste. He graduated from the Dwight School, a private school on the Upper West Side of New York City.

La Guardia joined the State Department and served in U.S. consulates in Budapest, Trieste (Austria-Hungary, now Italy), and Fiume (Austria-Hungary, now Rijeka, Croatia), (1901–1906). He returned to the United States to continue his education at New York University. From 1907 to 1910, he worked as an interpreter for the U.S. Bureau of Immigration at the Ellis Island immigration station.

He graduated from New York University School of Law in 1910, was admitted to the bar the same year, and began a law practice in New York City.

La Guardia married twice. His first wife was Thea Almerigotti, an Istrian immigrant, whom he married on March 8, 1919. In June 1920 they had a daughter, Fioretta Thea, who died May 9, 1921, of spinal meningitis. His first wife died of tuberculosis on November 29, 1921, at the age of 26. In 1929 he married Marie Fisher (1895–1984) who had been his secretary while in Congress; they adopted two children, Eric Henry (born 1930) and Jean Marie (1928–1962), the biological daughter of Thea's sister.

La Guardia became Deputy Attorney General of New York in January 1915. In 1916, he was elected to the U.S. House of Representatives, where he had a reputation as a fiery and devoted reformer. As a Representative, La Guardia represented an ethnically diverse slum district in East Harlem and, although barred from important committee posts because of his political independence, he was a tireless and vocal champion of progressive causes. La Guardia took office on March 4, 1917, but soon was commissioned into the United States Army Air Service; he rose to the rank of major in command of a unit of Ca.44 bombers on the Italian-Austrian front in World War I. He resigned his seat in Congress on December 31, 1919. He served as senior advisor to President Herbert Hoover from 1930–33.

In 1919, La Guardia was chosen to run as the Republican candidate for the office of President of the New York City Board of Aldermen. His Democratic opponent was Robert L. Moran, an alderman from the Bronx who had succeeded to the Board presidency in 1918 when Alfred E. Smith, who had been elected board president in 1917, became governor. Michael "Dynamite Mike" Kelly, commander of New York's Third "Shamrock" Battalion, also joined the race. Tammany Hall looked with alarm upon Kelly's entrance into the campaign and tried to persuade him to withdraw his candidacy and throw his support behind Moran. When he refused, Tammany went to the New York Supreme Court and successfully sued to keep Kelly's name off the ballot. When Election Day arrived, over 3,500 of Kelly's supporters wrote Kelly's name on the ballot. This number was sufficient to defeat Moran, who lost to La Guardia by 1,363 votes.

As the son of Italian immigrants and an interpreter on Ellis Island between 1907 and 1910, La Guardia had experienced how immigration policies affected the families that came to the United States. He wanted a change for the immigrants, especially with the immigrant medical examinations that took place on Ellis Island. His passion for justice among immigrants, and his ability to speak Italian, Yiddish, and Croatian helped him in his endeavor for justice amongst immigrant factory workers and set him on his path in public service.

La Guardia, running as a Republican, won a seat in Congress from the Italian stronghold of East Harlem in 1922 and served in the House until March 3, 1933. A leading liberal reformer, La Guardia sponsored labor legislation and railed against immigration quotas. His major legislation was the Norris–La Guardia Act, cosponsored with Nebraska senator George Norris in 1932. It circumvented Supreme Court limitations on the activities of labor unions, especially as those limitations were imposed between the enactment of the Clayton Antitrust Act in 1914 and the end of the 1920s. Based on the theory that the lower courts are creations not of the Constitution but of Congress, and that Congress therefore has wide power in defining and restricting their jurisdiction, the act forbids issuance of injunctions to sustain anti-union contracts of employment, to prevent ceasing or refusing to perform any work or remain in any relation of employment, or to restrain acts generally constituting component parts of strikes, boycotts, and picketing. It also said courts could no longer enforce yellow-dog contracts, which are labor contracts prohibiting a worker from joining a union.

Never an isolationist, he supported using American influence abroad on behalf of democracy or for national independence or against autocracy. Thus he supported the Irish independence movement and the anti-czarist Russian Revolution of 1917, but did not approve of Vladimir Lenin. Unlike most progressive colleagues, such as Norris, La Guardia consistently backed internationalism, speaking in favor of the League of Nations and the Inter-Parliamentary Union as well as peace and disarmament conferences. In domestic policies he tended toward socialism and wanted to nationalize and regulate; however he was never close to the Socialist Party and never bothered to read Karl Marx.

As a congressman, La Guardia was a tireless and vocal champion of progressive causes, from allowing more immigration and removing U.S. troops from Nicaragua to speaking up for the rights and livelihoods of striking miners, impoverished farmers, oppressed minorities, and struggling families. He fought for progressive income taxes, greater government oversight of Wall Street, and national employment insurance for workers idled by the Great Depression.

La Guardia was one of the first Republicans to voice his opinion about prohibition, urging that the Dry cause "would prove disastrous in the long run". This was breaking a taboo, given the fact that both parties "avoided taking a stand on prohibition issues" at the time.

As a Republican, La Guardia had to support Harding in 1920; he had to be silent in the 1928 campaign although he favored Al Smith, a Democrat.

Walker and his Irish-run Tammany Hall were forced out of office by scandal and La Guardia was determined to replace him. First he had to win the nomination of both the Republican party and also the "Fusion" group of independents. He was not the first choice of either, for they distrusted Italians. On the other hand, La Guardia had enormous determination, high visibility, the support of reformer Samuel Seabury and the ability to ruin the prospects of any rival by a divisive primary contest. He secured the nominations and expected an easy win against hapless incumbent Mayor John P. O'Brien. However, at the last minute Joseph V. McKee entered the race as the nominee of the new "Recovery party". McKee was a formidable opponent because he was sponsored by Bronx Democratic boss Edward J. Flynn and apparently was opposed by President Franklin Roosevelt. La Guardia made corruption his main issue. The campaign saw mud slung three ways, with La Guardia denounced as a far-left "Red", O'Brien as a pawn of the bosses, and McKee as an anti-Semite. La Guardia's win was based on a complex coalition of regular Republicans (mostly middle class German Americans in the boroughs outside Manhattan), a minority of reform-minded Democrats, some Socialists, a large proportion of middle-class Jews, and the great majority of Italians. The Italians had been loyal to Tammany; their switch proved decisive.

La Guardia came to office in January 1934 with five main goals:

He achieved most of the first four goals in his first hundred days, as FDR gave him 20% of the entire national CWA budget for work relief. La Guardia then collaborated closely with Robert Moses, with support from the governor, Democrat Herbert Lehman, to upgrade the decaying infrastructure. The city was favored by the New Deal in terms of funding for public works projects.

La Guardia governed in an uneasy alliance with New York's Jews and liberal WASPs, together with ethnic Italians and Germans.

La Guardia was not an orthodox Republican. He also ran as the nominee of the American Labor Party, a union-dominated anti-Tammany left wing group that supported Franklin D. Roosevelt for president beginning in 1936. La Guardia supported Roosevelt, chairing the Committee of Independent Voters for Roosevelt and Wallace with Senator George Norris during the 1940 presidential election.

La Guardia was the city's first Italian-American mayor, but was not a typical Italian New Yorker. He was a Republican Episcopalian who had grown up in Arizona and had a Triestine Jewish mother and a lapsed Catholic father. He spoke several languages; when working at Ellis Island, he was certified as an interpreter for Italian, German, Yiddish, and Croatian. It served him well during a contentious congressional campaign in 1922. When Henry Frank, a Jewish opponent, accused him of anti-Semitism, La Guardia rejected the suggestion that he publicly disclose that his mother was Jewish as "self-serving". Instead, La Guardia dictated an open letter in Yiddish that was also printed in Yiddish. In it, he challenged Frank to publicly and openly debate the issues of the campaign "ENTIRELY IN THE YIDDISH LANGUAGE." Frank, although he was Jewish, could not speak the language and was forced to decline—and lost the election.

La Guardia loathed the gangsters who brought a negative stereotype and shame to the Italian community. His first action as mayor was to order the chief of police to arrest mob boss Lucky Luciano on whatever charges could be found. La Guardia then went after the gangsters with a vengeance, stating in a radio address to the people of New York in his high-pitched, squeaky voice, "Let's drive the bums out of town". In 1934 he went on a search-and-destroy mission looking for mob boss Frank Costello's slot machines, which La Guardia executed with gusto, rounding up thousands of the "one armed bandits", swinging a sledgehammer and dumping them off a barge into the water for the newspapers and media. In 1935 La Guardia appeared at The Bronx Terminal Market to institute a citywide ban on the sale, display, and possession of artichokes, whose prices were inflated by mobs. When prices went down, the ban was lifted. In 1936, La Guardia had special prosecutor Thomas E. Dewey, a future Republican presidential candidate, single out Lucky Luciano for prosecution. Dewey led a successful investigation into Luciano's lucrative prostitution operation, eventually sending Luciano to jail with a 30–50 year sentence. The case was made into the 1937 movie "Marked Woman", starring Bette Davis.

La Guardia proved successful in shutting down the burlesque theaters, whose shows offended his puritanical sensibilities.

La Guardia's admirers credit him, among other things, with restoring the economy of New York City during and after the Great Depression. He is given credit for many massive public works programs administered by his powerful Parks Commissioner Robert Moses, which employed thousands of voters. The mayor's relentless lobbying for federal funds allowed New York to develop its economic infrastructure.

To obtain large-scale federal money the mayor became a close partner of Roosevelt and New Deal agencies such as the CWA, PWA, and WPA, which poured $1.1 billion into the city from 1934–39. In turn he gave FDR a showcase for New Deal achievement, helped defeat FDR's political enemies in Tammany Hall (the Democratic party machine in Manhattan). He and Moses built highways, bridges and tunnels, transforming the physical landscape of New York City. The West Side Highway, East River Drive, Brooklyn Battery Tunnel, Triborough Bridge, and two airports (LaGuardia Airport, and, later, Idlewild, now JFK Airport) were built during his mayoralty.

1939 was a busy year, as he opened the 1939 New York World's Fair at Flushing Meadows-Corona Park, Queens, opened New York Municipal Airport No. 2 in Queens (later renamed Fiorello H. LaGuardia Field), and had the city buy out the Interborough Rapid Transit Company and Brooklyn–Manhattan Transit Corporation, thus completing the public takeover of the subway system. When the city's newspapers were closed by a strike he famously read the comics on the radio.

Responding to popular disdain for the sometimes corrupt City Council, La Guardia successfully proposed a reformed 1938 City Charter that created a powerful new New York City Board of Estimate, similar to a corporate board of directors.

He was an outspoken and early critic of Adolf Hitler and the Nazi regime. In a public address in 1934, La Guardia warned that "part of Hitler's program is the complete annihilation of the Jews in Germany". In 1937, speaking before the Women's Division of the American Jewish Congress, he called for the creation of a special pavilion at the upcoming New York World's Fair, "a chamber of horrors" for "that brown-shirted fanatic". He also encouraged the boycotting of German goods, led anti-Nazi rallies, and promoted legislation to facilitate the U.S. rescue of the Jewish refugees.

La Guardia's sister, Gemma La Guardia Gluck (1881–1962), and brother-in-law, Herman Gluck (a Hungarian Jew whom she met while teaching English in Europe), were living in Hungary and were arrested by the Gestapo on June 7, 1944, when the Nazis took control of Budapest. Adolf Eichmann and Heinrich Himmler knew that Gemma was La Guardia's sister and ordered her to be held as a political prisoner. She and Herman Gluck were deported to Mauthausen concentration camp in Austria, where he died, as Gemma learned from reading a newspaper account a year after her own release. She was transferred from Mauthausen to the notorious women's concentration camp at Ravensbrück, located some fifty miles from Berlin, where unbeknownst to Gemma at the time, her daughter Yolanda (whose husband also died in the camps) and baby grandson were also held for a year in a separate barracks. Gemma Gluck, who was held in Block II of the camp and assigned prisoner #44139, was one of the few survivors of this camp and wrote about her time at Ravensbrück.

In 1941 during the run-up to American involvement in World War II, President Roosevelt appointed La Guardia first director of the new Office of Civilian Defense (OCD). Roosevelt was an admirer of La Guardia; after meeting Winston Churchill for the first time he described him as "an English Mayor La Guardia". The OCD was the national agency responsible for preparing for blackouts, air raid wardens, sirens, and shelters in case of German air raids. The government knew that such air raids were impossible, but the goal was to psychologically mobilize many thousands of middle class volunteers to make them feel part of the war effort. At the urging of aviation advocate Gill Robb Wilson, LaGuardia, in his capacity as Director of the OCD, created the Civil Air Patrol with , signed by him on December 1, 1941 and published December 8, 1941. La Guardia remained Mayor of New York, shuttling back and forth with three days in Washington and four in the city in an effort to do justice to two herculean jobs. On top of this, he still performed other gestures, such as arranging police protection with his personal assurances for local artists Joe Simon and Jack Kirby, when they were threatened by Nazi supporters for their new patriotic comic book superhero, Captain America. After the attack on Pearl Harbor in December 1941, his role was turned over to full-time director of OCD, James M. Landis. La Guardia's popularity slipped away and he ran so poorly in straw polls in 1945 that he did not run for a fourth term.

Unemployment ended, and the city was a gateway for military supplies and soldiers sent to Europe, with the Brooklyn Navy Yard providing many of the warships and the garment trade providing uniforms. The city's great financiers, however, were less important in decision making than the policy makers in Washington, and very high wartime taxes were not offset by heavy war spending. New York was not a center of heavy industry and did not see a wartime boom, as defense plants were built elsewhere. FDR refused to make La Guardia a general and was unable to provide fresh money for the city. By 1944 the city was short of funds to pay for La Guardia's new programs.

La Guardia was the director general for the United Nations Relief and Rehabilitation Administration (UNRRA) in 1946.

A man of short stature, La Guardia's height is sometimes given as . According to an article in "The New York Times", however, his actual height was .

La Guardia was a Scottish Rite Freemason, and was a member of Garibaldi Lodge #542, in New York City.

He died of pancreatic cancer in his home at 5020 Goodridge Avenue, in the Riverdale section of The Bronx on September 20, 1947, aged 64 and is interred at Woodlawn Cemetery in The Bronx, New York City.

La Guardia was ranked first among the nation's mayors in a 1993 poll of historians and social scientists.
According to biographer Mason B. Williams, his close collaboration with Roosevelt's New Deal proved a striking success in linking national money and local needs. La Guardia enabled the political recognition of new groups that had been largely excluded from the political system, such as Jews and Italians. His administration (in cooperation with Robert Moses) gave New York its modern infrastructure. His far-sighted goals raised ambitions for new levels of urban possibility. According to Thomas Kessner, trends since his tenure mean that "people would be afraid of allowing anybody to take that kind of power".

In 1972 the United States Postal Service honored La Guardia with a 14-cent postage stamp.

New York's LaGuardia Airport, LaGuardia Community College, and other parks and buildings around New York City are named for him.

A strong supporter of Zionism, LaGuardia Street and LaGuardia interchange both in Tel Aviv, Israel, were named in his honor.

Known for his love of music, La Guardia was noted for spontaneously conducting professional and student orchestras and was instrumental in the creation of the High School of Music & Art in 1936, now renamed the Fiorello H. LaGuardia High School of Music & Art and Performing Arts.

La Guardia was a fictionalized character in many films – in "Ghostbusters II" La Guardia's ghost talks to New York Mayor Lenny (played by David Margulies). He was also the subject of the hit 1959 Broadway musical "Fiorello!", portrayed by actor Tom Bosley and in "The Little Flower", portrayed by Tony Lo Bianco. The original production of "Fiorello!" won 3 Tony Awards including Best Musical, as well as a Pulitzer Prize for Drama in 1960, and ran for two years from 1959 to 1961.





</doc>
<doc id="11424" url="https://en.wikipedia.org/wiki?curid=11424" title="Flag">
Flag

A flag is a piece of fabric (most often rectangular or quadrilateral) with a distinctive design and colours. It is used as a symbol, a signalling device, or for decoration. The term "flag" is also used to refer to the graphic design employed, and flags have evolved into a general tool for rudimentary signalling and identification, especially in environments where communication is challenging (such as the maritime environment, where semaphore is used). The study of flags is known as "vexillology" from the Latin "vexillum", meaning "flag" or "banner".

National flags are patriotic symbols with widely varied interpretations that often include strong military associations because of their original and ongoing use for that purpose. Flags are also used in messaging, advertising, or for decorative purposes.

Some military units are called "flags" after their use of flags. A "flag" (Arabic: لواء) is equivalent to a brigade in Arab countries. In Spain, a "flag" (Spanish: "bandera") is a battalion-equivalent in the Spanish Legion.

In antiquity, field signs or standards were used in warfare that can be categorised as vexilloid or 'flag-like'. This is considered originated in the ancient Egypt or Assyria. Examples include the Sassanid battle standard Derafsh Kaviani, and the standards of the Roman legions such as the eagle of Augustus Caesar's Xth legion, or the dragon standard of the Sarmatians; the latter was let fly freely in the wind, carried by a horseman, but judging from depictions it was more similar to an elongated dragon kite than to a simple flag.

Flag as recognized today, made of a piece of cloth representing a particular entity, is considered invented in the Indian subcontinent or Chinese Zhou dynasty (1046-256 BCE). Chinese flags depicted animals decorated in certain colors. A royal flag is considered being used as well, which was required to be treated with a similar level of respect attributed to the ruler. Indian flags were often triangular shaped and decorated with attachments such as yak's tail and the state umbrella. These usages spread to Southeast Asia as well, and considered transmitted to Europe through the Muslim world where plainly colored flags were being used due to Islamic prescriptions.

In Europe, during the High Middle Ages, flags came to be used primarily as a heraldic device in battle, allowing more easily to identify a knight than only from the heraldic device painted on the shield. Already during the high medieval period, and increasingly during the Late Middle Ages, city states and communes such as those of the Old Swiss Confederacy also began to use flags as field signs. Regimental flags for individual units became commonplace during the Early Modern period.

During the peak of the age of sail, beginning in the early 17th century, it was customary (and later a legal requirement) for ships to carry flags designating their nationality; these flags eventually evolved into the national flags and maritime flags of today. Flags also became the preferred means of communications at sea, resulting in various systems of flag signals; "see, International maritime signal flags".

Use of flags outside of military or naval context begins only with the rise of nationalist sentiment by the end of the 18th century; the earliest national flags date to that period, and during the 19th century it became common for every sovereign state to introduce a national flag. 

One of the most popular uses of a flag is to symbolise a nation or country. Some national flags have been particularly inspirational to other nations, countries, or subnational entities in the design of their own flags. Some prominent examples include:



National flag designs are often used to signify nationality in other forms, such as flag patches.

A "civil" flag is a version of the national flag that is flown by civilians on non-government installations or craft. The use of civil flags was more common in the past, in order to denote buildings or ships that were not manned by the military. In some countries the civil flag is the same as the war flag or state flag, but without the coat of arms, such as in the case of Spain, and in others it's an alteration of the war flag.

Several countries, including the British Army and the Royal Navy (White Ensign) of the United Kingdom (Great Britain) and the Soviet Union have had unique flags flown by their armed forces separately, rather than the national flag.

Other countries' armed forces (such as those of the United States or Switzerland) use their standard national flag, in addition, the U.S. has alongside flags and seals designed from long tradition for each of its six uniformed military services/military sub-departments in the U.S. Department of Defense and the U.S. Department of Homeland Security. The Philippines' armed forces may use their standard national flag, but during times of war the flag is turned upside down. Bulgaria's flag is also turned upside down during times of war. These are also considered war flags, though the terminology only applies to the flag's military usage.

Large versions of the war flag flown on the warships of countries' navies are known as battle ensigns. In addition besides flying the national standard or a military services' emblem flag at a military fort, base, station or post and at sea at the stern (rear) or main top mast of a warship, a Naval Jack flag and other Maritime flags, pennants and emblems are flown at the bow (front). In times of war waving a white flag is a banner of truce, talks/negotiations or surrender.

Four distinctive African flags currently in the collection of the National Maritime Museum in Britain were flown in action by Itsekiri ships under the control of Nana Olomu during conflict in the late 19th century. One is the flag generally known as the Benin Empire flag and one is referred to as Nana Olomu's flag.
Among international flags are the Flag of the United Nations, the Olympic flag, and the Paralympic flag.

Flags are particularly important at sea, where they can mean the difference between life and death, and consequently where the rules and regulations for the flying of flags are strictly enforced. A national flag flown at sea is known as an ensign. A courteous, peaceable merchant ship or yacht customarily flies its ensign (in the usual ensign position), together with the flag of whatever nation it is currently visiting at the mast (known as a courtesy flag). To fly one's ensign alone in foreign waters, a foreign port or in the face of a foreign warship traditionally indicates a willingness to fight, with cannon, for the right to do so. As of 2009, this custom is still taken seriously by many naval and port authorities and is readily enforced in many parts of the world by boarding, confiscation and other civil penalties.

In some countries yacht ensigns are different from merchant ensigns in order to signal that the yacht is not carrying cargo that requires a customs declaration. Carrying commercial cargo on a boat with a yacht ensign is deemed to be smuggling in many jurisdictions. There is a system of international maritime signal flags for numerals and letters of the alphabet. Each flag or pennant has a specific meaning when flown individually. As well, semaphore flags can be used to communicate on an "ad hoc" basis from ship to ship over short distances.
Traditionally, a vessel flying under the courtesy flag of a specific nation, regardless of the vessel's country of registry, is considered to be operating under the law of her 'host' nation.

Another category of maritime flag flown by some United States Government ships is the distinguishing mark. Although the United States Coast Guard has its own service ensign, all other U.S. Government ships fly the national ensign their service ensign, following United States Navy practice. To distinguish themselves from ships of the Navy, such ships historically have flown their parent organisation's flag from a forward mast as a distinguishing mark. Today, for example, commissioned ships of the National Oceanic and Atmospheric Administration (NOAA) fly the NOAA flag as a distinguishing mark.

Flags are usually rectangular in shape (often in the ratio 2:3, 1:2, or 3:5), but may be of any shape or size that is practical for flying, including square, triangular, or swallow tailed. A more unusual flag shape is that of the flag of Nepal, which is in the shape of two stacked triangles. Other unusual flag shapes include the flag of Ohio and the flag of Tampa.

Many flags are dyed through and through to be inexpensive to manufacture, such that the reverse side is the mirror image of the obverse (front) side, generally the side displayed when, from the observer's point of view, the flag flies from pole-side left to right. This presents two possibilities:


Some complex flag designs are not intended to be shown on both sides, requiring separate obverse and reverse sides if made correctly. In these cases there is a design element (usually text) which is not symmetric and should be read in the same direction, regardless of whether the hoist is to the viewer's left or right. These cases can be divided into two types:

Common designs on flags include crosses, stripes, and divisions of the surface, or "field", into bands or quarters—patterns and principles mainly derived from heraldry. A heraldic coat of arms may also be flown as a banner of arms, as is done on both the state flag of Maryland and the flag of Kiribati.

The "de jure" flag of Libya under Muammar Gaddafi, which consisted of a rectangular field of green, was for a long period the only national flag using a single colour and no design or insignia. However, other historical states have also used flags without designs or insignia, such as the Soviet Republic of Hungary, whose flag was a plain field of red.

Colours are normally described with common names, such as "red", but may be further specified using colourimetry.

The largest flag flown from a flagpole worldwide, according to Guinness World Records, is the flag of Mexico flown in Piedras Negras, Mexico. This flag was about . The largest flag ever made was the flag of Qatar; the flag, which measures at , was completed in December 2013 in Doha.

The general parts of a flag are: canton (the upper inner section of the flag), field or ground (the entire flag except the canton), the hoist (the edge used to attach the flag to the hoist), and the fly (the furthest edge from the hoist end).

Vertical flags are sometimes used in lieu of the standard horizontal flag in central and eastern Europe, particularly in the German-speaking countries. This practice came about because the relatively brisk wind needed to display horizontal flags is not common in these countries.

The standard horizontal flag (no. 1 in the preceding illustration) is nonetheless the form most often used even in these countries.

The vertical flag (German: "Hochformatflagge" or "Knatterflagge"; no. 2) is a vertical form of the standard flag. The flag's design may remain unchanged (No. 2a) or it may change, e.g. by changing horizontal stripes to vertical ones (no. 2b). If the flag carries an emblem, it may remain centred or may be shifted slightly upwards.

The vertical flag for hoisting from a beam (German: "Auslegerflagge" or "Galgenflagge"; no. 3) is additionally attached to a horizontal beam, ensuring that it is fully displayed even if there is no wind.

The vertical flag for hoisting from a horizontal pole (German: "Hängeflagge"; no. 4) is hoisted from a horizontal pole, normally attached to a building. The topmost stripe on the horizontal version of the flag faces away from the building.

The vertical flag for hoisting from a crossbar or banner (German: "Bannerflagge"; no. 5) is firmly attached to a horizontal crossbar from which it is hoisted, either by a vertical pole (no. 5a) or a horizontal one (no. 5b). The topmost stripe on the horizontal version of the flag normally faces to the left.

Flags can play many different roles in religion. In Buddhism, prayer flags are used, usually in sets of five differently coloured flags. Several flags and banners including the Black Standard are associated with Islam. Many national flags and other flags include religious symbols such as the cross, the crescent, or a reference to a patron saint. Flags are also adopted by religious groups and flags such as the Jain flag, Nishan Sahib (Sikhism), the Saffron Flag (Hindu) and the Christian flag are used to represent a whole religion.

As languages rarely have a flag designed to represent them, it is a common but unofficial practice to use national flags to identify them. The practice is discouraged and because flags tend to evoke feelings other than the intended meaning. Examples of such use include:

Though this can be done in an uncontroversial manner in some cases, this can easily lead to some problems for certain languages:
In this second case, common solutions include symbolising these languages by:

Thus, on the Internet, it is common to see the English language associated with the flag of the United Kingdom, or sometimes the flag of England, the flag of the United States or a U.S.-UK mixed flag, usually divided diagonally.

Since many flags have a simple design, there is bound to be cases of flags with similar designs. From 1948 to 1989, the flag of Romania had an insignia in the middle of the tricolour flag. In 1989 the insignia was removed, reverting Romania's flag back to an earlier version. This version matched the design which had been adopted by Chad in 1959. This has concerned the Chadian government, and in 2004 they requested that the United Nations should consider it an issue. In response, the Romanian President Ion Iliescu stated to the media, "The tricolour belongs to us. We will not give up the tricolour".

In certain cases, flag similarities are not coincidental, but the result of a conscious choice.

The Pan-Arab colours black, white, green, and red are first known from the flag of the Arab Revolt in 1916. The colours were intended to represent certain Arab dynasties. Countries currently using flags with all four Pan-Arab colours include Jordan, Kuwait, Palestine, Sudan and the UAE; several other Arab states use a subset.

The tricolour flag of Russia, inspired by the flag of the Netherlands, was introduced in the late 17th century. Based on this flag, the first Pan-Slav congress defined the Pan-Slavic colours red, blue and white. Among former and current countries beside Russia using flags with these colours, are Yugoslavia and the successor states Croatia, Serbia and Slovenia as well as the Czech Republic and Slovakia.

The oldest flag of the Nordic countries is the flag of Denmark with a description dating from 1748. The design has a cross symbol in a rectangular field, with the center of the cross shifted towards the hoist. This basic design is called the Nordic cross and has been adopted by the other Nordic countries Finland, Iceland, Norway and Sweden as well as the dependent territories of Faroe Islands and Åland. Similar flags are also used as regional flags, most prominently the semi-official flag of Scania. The design has also been used outside the Nordic countries in order to underline a cultural connection; examples are Shetland and Orkney.

Various flags have been modelled on the flag of the United States. Liberia was founded by freed African-American and ex-Caribbean slaves as settlers from the United States and the Caribbean. When Liberia gained independence in 1847 the flag of the new state was modelled on that of the United States, although the symbolism of the elements were differently interpreted. The US flag has also served as the model for the flags of Uruguay, El Salvador (between 1865 and 1912), Brazil (for the first few days of the Republic) and Brittany.

The Red Cross on white background as a protection symbol was declared at the First Geneva Convention in 1864. The emblem was formed by reversing the colours of the Swiss flag out of respect to Switzerland.

Because of their ease of signalling and identification, flags are often used in sports.



Some countries use diplomatic flags, such as the United Kingdom (see ) and the Kingdom of Thailand (see ).

The socialist movement uses red flags to represent their cause. The anarchist movement has a variety of different flags, but the primary flag associated with them is the black flag. In the Spanish civil war, the anarchists used the red-and-black bisected flag. In the 20th century, the rainbow flag was adopted as a symbol of the LGBT social movements. Its derivatives include the Bisexual pride and Transgender pride flags.

Some of these political flags have become national flags, such as the red flag of the Soviet Union and national socialist banners for Nazi Germany. The present Flag of Portugal is based on what had been the political flag of the Portuguese Republican Party previous to the 5 October 1910 revolution which brought this party to power.

Some disability advocacy groups have adopted flags to raise awareness of their causes.

The Epilepsy Awareness Flag includes a prominent lowercase letter 'e' on a white background.

When the World Federation of the Deaf adopted its own flag, this action caused some controversy within the deaf community due to the popularity of another flag which was already being flown by many deaf people and related organisations.

Flags are often representative of an individual's affinity or allegiance to a country, team or business and can be presented in various ways. A popular trend that has surfaced revolves around the idea of the 'mobile' flag in which an individual displays their particular flag of choice on their vehicle. These items are commonly referred to as car flags and are usually manufactured from high strength polyester material and are attached to a vehicle via a polypropylene pole and clip window attachment.

In Australia, Canada, New Zealand, the Philippines, Republic of Ireland and the United Kingdom, a pair of red-yellow flags is used to mark the limits of the bathing area on a beach, usually guarded by surf lifesavers. If the beach is closed, the poles of the flags are crossed. The flags are coloured with a red triangle and a yellow triangle making a rectangular flag, or a red rectangle over a yellow rectangle. On many Australian beaches there is a slight variation with beach condition signalling. A red flag signifies a closed beach (in the UK also other dangers), yellow signifies strong current or difficult swimming conditions, and green represents a beach safe for general swimming. In Ireland, a red and yellow flag indicates that it is safe to swim; a red flag that it is unsafe; and no flag indicates that there are no lifeguards on duty. Blue flags may also be used away from the yellow-red lifesaver area to designate a zone for surfboarding and other small, non-motorised watercraft.

Reasons for closing the beach include:


A surf flag exists, divided into four quadrants. The top left and bottom right quadrants are black, and the remaining area is white.

Signal flag "India" (a black circle on a yellow square) is frequently used to denote a "blackball" zone where surfboards cannot be used but other water activities are permitted.

Railways use a number of coloured flags. When used as wayside signals they usually use the following meanings (exact meanings are set by the individual railroad company):


At night, the flags are replaced with lanterns showing the same colours.

Flags displayed on the front of a moving locomotive are an acceptable replacement for classification lights and usually have the following meanings (exact meanings are set by the individual railroad company):


Additionally, a railroad brakeman will typically carry a red flag to make his or her hand signals more visible to the engineer. Railway signals are a development of railway flags.

A flagpole, flagmast, flagstaff, or staff can be a simple support made of wood or metal. If it is taller than can be easily reached to raise the flag, a cord is used, looping around a pulley at the top of the pole with the ends tied at the bottom. The flag is fixed to one lower end of the cord, and is then raised by pulling on the other end. The cord is then tightened and tied to the pole at the bottom. The pole is usually topped by a flat plate or ball called a "truck" (originally meant to keep a wooden pole from splitting) or a finial in a more complex shape. Very high flagpoles may require more complex support structures than a simple pole, such as a guyed mast.

Dwajasthambam are flagpoles commonly found at the entrances of South Indian Hindu temples.

Since 23 September 2014, the tallest free-standing flagpole in the world is the Jeddah Flagpole in Saudi Arabia at a height of , exceeding the former record holder the Dushanbe Flagpole in Tajikistan (height: ), National Flagpole in Azerbaijan (height: ) and the North Korean flagpole at Kijŏng-dong (height: ). The flagpole in North Korea actually is a radio tower with a flag on top. Besides two flagpoles mentioned above, the previous six world-record flagpoles were all built by American company Trident Support, and the rest are in: Ashgabat, Turkmenistan: ; Aqaba, Jordan: ; Amman, Jordan: ; and Abu Dhabi, United Arab Emirates: .

The tallest flagpole in the United Kingdom from 1959 until 2013 stood in Kew Gardens. It was made from a Canadian Douglas-fir tree and was in height.

The current tallest flagpole in the United States (and the tallest flying an American flag) is the pole completed before Memorial Day 2014 and custom-made with an base in concrete by wind turbine manufacturer Broadwind Energy. It is situated on the north side of the Acuity Insurance headquarters campus along Interstate 43 in Sheboygan, Wisconsin, and is visible from Cedar Grove. The pole can fly a 220-pound flag for in light wind conditions and a heavier 350-pound flag in higher wind conditions.

Flagpoles can be designed in one piece with a taper (typically a steel taper or a Greek entasis taper), or be made from multiple pieces to make them able to expand. In the United States, ANSI/NAAMM guide specification FP-1001-97 covers the engineering design of metal flagpoles to ensure safety.

Hoisting the flag is the act of raising the flag on the flagpole. Raising or lowering flags, especially national flags, usually involves ceremonies and certain sets of rules, depending on the country, and usually involve the performance of a national anthem.

A flag-raising squad is a group of people, usually troops, cadets, or students, that marches in and brings the flags for the flag-hoisting ceremony. Flag-hoisting ceremonies involving flag-raising squads can be simple or elaborate, involving large numbers of squads. Elaborate flag-hoisting ceremonies are usually performed on national holidays.

Semaphore is a form of communication that utilises flags. The signalling is performed by an individual using two flags (or lighted wands), the positions of the flags indicating a symbol. The person who holds the flags is known as the signalman. This form of communication is primarily used by naval signallers. This technique of signalling was adopted in the early 19th century and is still used in various forms today.

The colours of the flags can also be used to communicate. For example; a white flag means, among other things, surrender or peace, a red flag can be used as a warning signal, and a black flag can mean war, or determination to defeat enemies.

Orientation of a flag is also used for communication, though the practice is rarely used given modern communication systems. Raising a flag upside-down was indicative that the raising force controlled that particular area, but that it was in severe distress.

When blown by the wind, flags are subject to wave-like motions that grow in amplitude along the length of the flag. This is sometimes ascribed to the flag pole giving vortex shedding; however, flags that are held by lanyards also can be seen to flap.





</doc>
<doc id="11425" url="https://en.wikipedia.org/wiki?curid=11425" title="Father Dougal McGuire">
Father Dougal McGuire

Father Dougal McGuire is a character in the Channel 4 sitcom "Father Ted". Created by Arthur Mathews and Graham Linehan, Dougal was portrayed by comedian Ardal O'Hanlon for the programme's three series. The character is a childlike, simple-minded Roman Catholic curate exiled to Craggy Island, a small island off the coast of Galway.

Dougal originated as an unseen character in a short-lived stand-up routine performed by Mathews in the late 1980s. Portraying an early version of Father Ted Crilly on-stage, Mathews occasionally discussed Dougal as one of Ted's great friends. In 1994, the writers took "Father Ted" to television, casting O'Hanlon as the on-screen Dougal. In a 2001 poll conducted by Channel 4 Dougal was ranked fifth on their list of the 100 Greatest TV Characters.

Arthur Mathews created the character of Father Ted while working at "Hot Press" in 1987–89. During production weekends, he and Paul Woodfull had the idea for The Joshua Trio, a comedic U2 tribute band. The band performed various warm-up sketches written by Mathews, Woodfull, and Graham Linehan, who joined in a non-musical capacity. These sketches included stand-up performed by Mathews in-character as Father Ted Crilly. As Ted, Mathews sometimes read from a book, "Notes from Africa", purportedly written by Father Dougal McGuire, a missionary friend who described his experiences of being attacked and chased by natives. In one sketch, Ted discussed his concern for Dougal, who had been voted Most Unpopular Priest in Africa for two years running and was spending Christmas up a tree in the grounds of The Bob Geldof Centre.

In 1990, Linehan and Mathews began writing "Irish Lives", a six-part comedy television series. The show would have taken the form of a mockumentary, with each episode focusing on interviewing a different character, one of whom was Father Ted Crilly. The story involved Ted returning to his seminary to catch up with old friends. When producer Geoffrey Perkins asked Linehan and Mathews to discard the mockumentary format and expand the Father Ted episode to a traditional sitcom, Father Dougal became one of the main characters. When writing Dougal, Linehan and Mathews drew on Stan Laurel, incorporating some of Linehan's own behaviour during moments of confusion.

Linehan and Mathews saw O'Hanlon in a modernised Shakespeare play broadcast by RTÉ, and were impressed by the "weird, gormless" face he could pull. Linehan later said, "That was Dougal right there. He was just spot-on and he became our secret weapon. The show took off so quickly because Ardal was so instantly funny." The writers have said that the only other actor they feel might have worked in the role is Don Wycherley, who plays Dougal's Rugged Island counterpart, Father Cyril McDuff, in the show.

There have been several attempts to remake the show for American audiences. In 2004, it was reported that Graham Norton (who played Father Noel Furlong in "Father Ted") had signed on to play Dougal alongside Steve Martin as Ted. No remake has yet entered production.

References to Dougal's family are rare. In "Grant Unto Him Eternal Rest", he mentions that his parents are dead, and also refers to an uncle who died after his heart stopped beating for a week. It is unclear how Dougal entered the priesthood, with Ted wondering, "Dougal, how did you get into the Church? Was it, like, collect twelve crisp packets and become a priest?"

By the time the show begins, Dougal has been exiled to Craggy Island as punishment for unknown misdeeds. In an early interview, the writers stated that it involved "a baptism gone wrong". In "The Passion of Saint Tibulus", Bishop Brennan says that Dougal cannot be allowed back into "the real world" after "the Blackrock incident", in which hundreds of nuns' lives were "irreparably damaged".

Dougal is also famously known for wearing an Irish football jersey when he is in bed.

On the Channel 4 website for Father Ted, the profile for Father Dougal states that 'Dougal was relegated to the island after an unfortunate incident on a SeaLink ferry that put the lives of hundreds of nuns in danger.'

In "Old Grey Whistle Theft", Dougal mentions that he is 25 years old.

In the 2011 documentary "Unintelligent Design", Linehan said that Dougal had been conceived as a cross between wide-eyed bartender Woody in "Cheers" and roadsweeper Trigger in "Only Fools and Horses". In another interview, they mentioned Latka Gravas from "Taxi" as an influence and compared the relationship between Ted and Dougal to that between Don Quixote and Sancho Panza: "Alongside the wily priest who would lie at the drop of a hat we wanted a gormless idiot who was the very model of innocence."

For his portrayal of Dougal, O'Hanlon turned to Laurel and Hardy and "Fawlty Towers"s bumbling waiter Manuel. O'Hanlon also drew inspiration from his child sister, as well as dogs, explaining: "Dougal had to be more than just stupid. He had to be otherworldly and very, very strange. I saw Dougal as very doglike, very puppyish and lovable, and really loyal to Ted."

After the first episode aired, Ben Thompson of "The Independent" singled out O'Hanlon as "the real star of the show", and said that Dougal's "holy-fool innocence" as "worthy of James Stewart". Writing for the "Irish Examiner", Ed Power said that while the "meme-worthy" Dougal and Jack received the most attention at the time of broadcast, Morgan's straight-man performance was the highlight in retrospect. Morgan attributed the show's success to the appealing double-act formed by Dougal, "an idiot who knows nothing", and Ted, "an idiot who thinks he knows something but actually knows nothing."

As testament to the character's enduring popularity, Irish bookmakers humorously began collecting bets on whether Dougal would succeed Pope John Paul II upon his death. The odds were 1,000-1 (better odds than some genuine candidates), and some small stakes were actually received.

In 2001, O'Hanlon reprised the role of Dougal for a series of PBS advertisements to coincide with "Father Ted"s American broadcast; these segments were included on later DVD releases as "Fundraising with Father Dougal".


</doc>
<doc id="11426" url="https://en.wikipedia.org/wiki?curid=11426" title="Flores">
Flores

Flores (Indonesian: Pulau Flores) is one of the Lesser Sunda Islands, a group of islands in the eastern half of Indonesia. The population was 1,931,000 in the 2010 census and the largest town is Maumere. The name "Flores" is derived from the Portuguese for "flowers".

Flores is located east of Sumbawa and Komodo islands and west of Lembata island and the Alor Archipelago. To the southeast is Timor. To the south, across the Sumba Strait, is Sumba island and to the north, beyond the Flores Sea, is Sulawesi.

Among all islands containing Indonesian territory, Flores is the 10th most populous after Java, Sumatra, Borneo (Kalimantan), Sulawesi, New Guinea, Bali, Madura, Lombok, and Timor and also the 10th biggest island of Indonesia.

Unlike most islands in the Indonesian archipelago, the name "Flores" was given by the Portuguese, from "Cabo de Flores" (Cape of Flowers), the Portuguese term for the eastern part of the island. This part of the island, originally called Kopondai, was so named by the Portuguese because of the flowering "Delonix regia" trees found there. The original name of Flores was "Nipa", referring to the serpent.

Portuguese traders and missionaries came to Flores in the 16th century, mainly to Larantuka and Sikka. Their influence is still discernible in Sikka's language, culture and religion. The first Portuguese visit took place in 1511, through the expedition of António de Abreu and his vice-captain Francisco Serrão, en route through the Sunda islands.

The Dominican order was extremely important in this island, as well as in the neighbouring islands of Timor and Solor. When in 1613 the Dutch attacked the Fortress of Solor, the population of this fort, led by the Dominicans, moved to the harbor town of Larantuka, on the eastern coast of Flores. This population was mixed, of Portuguese and local islanders descent and Larantuqueiros, Topasses or, as Dutch knew them, the 'Black Portuguese' (Zwarte Portuguezen).

The Larantuqueiros or Topasses became the dominant sandalwood trading people of the region for the next 200 years. This group used Portuguese as the language for worship, Malay as the language of trade and a mixed dialect as mother tongue. This was observed by William Dampier, an English privateer visiting the Island in 1699:

In 1846, Dutch and Portuguese initiated negotiations towards delimiting the territories but these negotiations led nowhere. In 1851 Lima Lopes, the new governor of Timor, Solor and Flores, agreed to sell eastern Flores and the nearby islands to the Dutch in return for a payment of 200,000 Florins in order to support his impoverished administration. Lima Lopes did so without the consent of Lisbon and was dismissed in disgrace, but his agreement was not rescinded and in 1854 Portugal ceded all its historical claims on Flores. After this, Flores became part of the territory of the Dutch East Indies.

During World War II a Japanese invasion force landed at Reo on 14 May 1942 and occupied Flores. After the war Flores became part of independent Indonesia.

On 12 December 1992, an earthquake measuring 7.8 on the Richter scale occurred, killing 2,500 people in and around Maumere, including islands off the north coast.

In 2017 two men were killed in Flores due to land disputes between warrior clans; the Mbehel, a West Maggarai mountain tribe, and the Rangko from Sulawesi island who helped build Manggarai and were given land near Labuan Bajo by the Manggarai king.

Flores is part of the East Nusa Tenggara province. The island along with smaller minor islands are split into eight regencies (local government districts); from west to east these are: Manggarai Barat (West Manggarai), Manggarai Tengah (Central Manggarai), Manggarai Timur (East Manggarai), Ngada, Nagekeo, Ende, Sikka and Flores Timur (East Flores). Flores has 39.1% of the East Nusa Tenggara provincial population , and the most Indonesians of all islands in the province.

Main Cities in Flores are Labuan Bajo, Ruteng, Bajawa, Ende, Maumere and Larantuka

The west coast of Flores is one of the few places, aside from the island of Komodo itself, where the Komodo dragon can be found in the wild, and is part of Komodo National Park, a UNESCO World Heritage Site. Kelimutu National Park is the second national park designated on Flores to protect endangered species. The Flores giant rat is also endemic to the island, and Verhoeven's giant tree rat was formerly present. These giant rodents are considered examples of island gigantism.

Flores was also the habitat of several extinct dwarf forms of the proboscidean "Stegodon", the most recent ("Stegodon florensis insularis") disappearing approximately 12,000 years ago and the diminutive "Homo floresiensis". It is speculated by scientists that limited resources and an absence of advanced predators made the few megafaunal species that reached the island subject to insular dwarfism.

The presence of "Trigonoceps" vultures indicates that the island bore mammalian carnivores at some point.

In September 2003, at Liang Bua Cave in western Flores, paleoanthropologists discovered small skeletons that they described as a previously unknown hominin species, "Homo floresiensis". These are informally named "hobbits" and appear to have stood about tall.

This hominin had originally been considered to be remarkable for its survival until relatively recent times, only 12,000 years ago. However, by 2016, more extensive stratigraphic and chronological work has pushed the dating of the most recent evidence of their existence back to 50,000 years ago.

There are many languages spoken on the island of Flores, all of them belonging to the Austronesian family. In the centre of the island in the districts of Ngada, Nagekeo, and Ende there is what is variously called the Central Flores Dialect Chain or the Central Flores Linkage. Within this area there are slight linguistic differences in almost every village. At least six separate languages are identifiable. These are from west to east: Ngadha, Nage, Keo, Ende, Lio and Palu'e, which is spoken on the island with the same name of the north coast of Flores. Locals would probably also add So'a and Bajawa to this list, which anthropologists have labeled dialects of Ngadha.
The peoples of Flores are almost entirely Roman Catholic Christians, whereas most other Indonesians are Muslim. As a consequence, Flores may be regarded as surrounded by a religious border. The prominence of Catholicism on the island results from its colonisation by Portugal. In other parts of Indonesia with significant Christian populations, such as the Maluku Islands and Sulawesi, the geographical divide is less rigid and Muslims and Christians sometimes live side by side. Flores thereby also has less religious violence that has sporadically occurred in other parts of Indonesia. There are several churches on the island. On May 26, 2019, Flores' St. Paul Catholic University of Indonesia was formally inaugurated by Indonesian Education Minister Mohamad Nasir, becoming the first Catholic University in Indonesia.

The most famous tourist attraction in Flores is the Kelimutu volcano which containing three colored lakes, located in the district of Ende close to the town of Moni, although there is also the Inierie volcano near Bajawa. These crater lakes are in the caldera of a volcano, and fed by a volcanic gas source, resulting in highly acidic water. The colored lakes change colors on an irregular basis, depending on the oxidation state of the lake from bright red through green and blue.

There are snorkelling and diving locations along the north coast of Flores, most notably Maumere and Riung. However, due to the destructive practice of local fishermen using bombs to fish, and locals selling shells to tourists, combined with the after effects of a devastating tsunami in 1992, the reefs have slowly been destroyed.

Labuan Bajo, located on the western tip is often used by tourists as a base to visit Komodo and Rinca islands. Labuan Bajo also attracts scuba divers, as whale sharks inhabit the waters around Labuan bajo.

The Luba and Bena villages include traditional houses in Flores. Bena is also noted for its Stone Age megaliths.

Larantuka, on the isle's eastern end, is known for its Holy Week festivals.

In recent years, local tourist firms around Kelimutu have begun promoting cycling tours around Flores, some of which take up to five or six days depending on the particular program.

In addition to tourism, the main economic activities on Flores are agriculture, fishing and seaweed production. The primary food crops being grown on Flores are rice, maize, sweet potato and cassava, while the main cash crops are coffee, coconut, candle nut and cashew. Flores is one of the newest origins for Indonesian coffee. Previously, most Arabica coffee ("Coffea arabica") from Flores was blended with other origins. Now, demand is growing for this coffee because of its heavy body and sweet chocolate, floral and woody notes.

There are at least six airports in Flores distributed along the island, ordered from west to east:




</doc>
<doc id="11427" url="https://en.wikipedia.org/wiki?curid=11427" title="First Punic War">
First Punic War

The First Punic War (264 to 241 BC) was the first of three wars fought between Ancient Carthage and the Roman Republic, the two great powers of the Western Mediterranean. For 23 years, in the longest continuous conflict and greatest naval war of antiquity, the two powers struggled for supremacy, primarily on the Mediterranean island of Sicily and its surrounding waters, and also in North Africa.

The war began in 264 BC with the Roman conquest of the Carthaginian-controlled city of Messina in Sicily, granting Rome a military foothold on the island. The Romans built up a navy to challenge Carthage, the greatest naval power in the Mediterranean, for control over the waters around Sicily. In naval battles and storms, 700 Roman and 500 Carthaginian quinqueremes were lost, along with hundreds of thousands of lives. Command of the sea was won and lost by both sides repeatedly. A Roman invasion of Carthaginian Africa was destroyed in battle at the Bagradas and the Roman consul Marcus Atilius Regulus was captured by the Carthaginians in 255. In 23 years, the Romans slowly conquered Sicily and drove the Carthaginians to the west end of the island.

After both sides had been brought to a state of near exhaustion, the Romans mobilized their citizenry's private wealth and created a new fleet under consul Gaius Lutatius Catulus. The Carthaginian fleet was destroyed at the Aegates Islands in 241, forcing the cut-off Carthaginian troops on Sicily to give up. A peace treaty was signed in which Carthage was made to pay a heavy indemnity and Rome ejected Carthage from Sicily, annexing the island as a Roman province.

The war was followed by a failed revolt against the Carthaginian Empire. The Romans exploited Carthage's weakness to seize the Carthaginian possessions of Sardinia and Corsica in violation of the peace treaty. The unresolved strategic competition between Rome and Carthage would lead to the eruption of the Second Punic War in 218 BC.

The series of wars between Rome and Carthage took the name "Punic" from the Latin adjective for Carthaginian, "Punicus". This is derived from "Poeni" (Carthaginians) and refers to the Carthaginian heritage as Phoenician colonists. A Carthaginian name(s) for the conflicts does not survive in any records.

Rome had recently emerged as the leading city-state in the Italian Peninsula, a wealthy, powerful, expansionist republic with a successful citizen army. Over the past one hundred years, Rome had come into conflict, and defeated rivals on the Italian peninsula, then incorporated them into the Roman political world. First, the Latin League was forcibly dissolved during the Latin War, then the power of the Samnites was broken during the three prolonged Samnite wars, and then the Greek cities of Magna Graecia (southern Italy) submitted to Roman power at the conclusion of the Pyrrhic War. By the beginning of the First Punic War, the Romans had secured the whole of the Italian peninsula, except Gallia Cisalpina in the Po Valley.

Carthage was a republic that dominated the political, military and economic affairs of the western Mediterranean Sea, especially on the North African coasts and islands, and above all, due to its navy. It originated as a Phoenician colony in Africa, near modern Tunis. Carthage had become a wealthy centre for trade networks extending from Gadir (Cádiz) along the coasts of southern Iberia and North Africa, across the Balearic Islands, Corsica, Sardinia, and the western half of Sicily, to the ports of the eastern Mediterranean, including Tyre, its mother city, on the shores of the Levant. At the height of power, just before the First Punic War, Carthage was hostile to foreign ships (such as Roman and Greek vessels) in the western Mediterranean.

North African peoples, such as the Berbers, in the area around Carthage were loosely associated with Carthage. In the midst of the First Punic War, some tribes rebelled against Carthage, opening a second front while the Carthaginians battled the Romans in Sicily.

Greek colonists were also a major presence in the western Mediterranean, following centuries of colonial settlement, trade and conflicts with Rome over Magna Graecia and with Carthage over places such as Sicily. The rich, strategically influential, and well-fortified Greek colony of Syracuse was politically independent of Rome and Carthage. Hostilities of the First Punic War began with developments involving the Romans, Carthaginians, and Greek colonists in Sicily and southern Italy.

In 288 BC, the Mamertines, a group of Italian (Campanian) mercenaries originally hired by Agathocles of Syracuse, occupied the city of Messana (modern Messina) in the north-eastern tip of Sicily, killing all the men and taking the women as their wives. At the same time, a group of Roman troops made up of Campanian "citizens without the vote" revolted and seized control of Rhegium, lying across the Straits of Messina on the mainland of Italy. In 270 BC, the Romans regained control of Rhegium and severely punished the survivors of the revolt. In Sicily, the Mamertines ravaged the countryside and collided with the expanding regional empire of the independent city of Syracuse. Hiero II, tyrant of Syracuse, defeated the Mamertines near Mylae on the Longanus River. Following their defeat, the Mamertines appealed to both Rome and Carthage for assistance. The Carthaginians acted first, approached Hiero to take no further action and convinced the Mamertines to accept a Carthaginian garrison in Messana. Either unhappy with the prospect of a Carthaginian garrison or convinced that the recent alliance between Rome and Carthage against Pyrrhus reflected cordial relations between the two, the Mamertines, hoping for more reliable protection, petitioned Rome for an alliance. However, the rivalry between Rome and Carthage had grown since the war with Pyrrhus and that alliance was simply no longer feasible.

According to the historian Polybius, considerable debate took place in Rome on the question as to whether to accept the Mamertines' appeal for help and thus likely enter into a war with Carthage. The Romans did not wish to come to the aid of soldiers who had unjustly stolen a city from its rightful possessors, and they were still recovering from the insurrection of Campanian troops at the Battle of Rhegium in 271 BC. However, many were also unwilling to see Carthaginian power in Sicily expand even further. Leaving them at Messana would give the Carthaginians a free hand to deal with Syracuse. After the Syracusans had been defeated, the Carthaginian takeover of Sicily would essentially be complete. A deadlocked senate put the matter before the popular assembly, where it was decided to accept the Mamertines' request and Appius Claudius Caudex was appointed commander of a military expedition with orders to cross to Messana.

Sicily is a hilly volcanic island, with geographical obstacles and rough terrain making lines of communication difficult to maintain. For this reason, land warfare played a secondary role in the First Punic War. Land operations were confined to small scale raids and skirmishes, with few pitched battles. Sieges and land blockades were the most common large-scale operations for the regular army. The main blockade targets were the important ports since neither Carthage nor Rome were based in Sicily, and both needed continuous reinforcements and communication with their mainlands.

The land war in Sicily began with the Roman landing at Messana in 264 BC. According to Polybius, despite the Carthaginian pre-war naval advantage, the Roman landing was virtually unopposed. Two legions commanded by Appius Claudius Caudex disembarked at Messana, where the Mamertines had expelled the Carthaginian garrison commanded by Hanno (no relation to Hanno the Great). After defeating the Syracusan and Carthaginian forces besieging Messana, the Romans marched south and in turn besieged Syracuse. After a brief siege, with no Carthaginian help in sight, Syracuse made peace with the Romans.

According to the terms of the treaty, Syracuse would become a Roman ally, pay a somewhat light indemnity of 100 talents of silver to Rome and, perhaps most importantly, agree to help supply the Roman army in Sicily. That solved the Roman problem of having to keep an overseas army provisioned while facing an enemy with a superior navy. Following the defection of Syracuse from Carthage, several other smaller Carthaginian dependencies in Sicily also switched to the Roman side.

Meanwhile, Carthage had begun to build a mercenary army in Africa, which was to be shipped to Sicily to meet the Romans. According to the historian Philinus, this army was composed of 50,000 infantry, 6,000 cavalry, and 60 elephants and partly composed of Ligurians, Celts and Iberians.

In past wars on the island of Sicily, Carthage had won by relying on certain fortified strong-points throughout the island, and their plan was to conduct the land war in the same fashion. The mercenary army would operate in the open against the Romans, while the strongly fortified cities would provide a defensive base from which to operate.

In 262 BC, Rome besieged Agrigentum, an operation that involved both consular armies—a total of four Roman legions—and took several months to resolve. The garrison of Agrigentum (known to the Greeks as Acragas) managed to call for reinforcements and the Carthaginian relief force, commanded by Hanno, destroyed the Roman supply base at Erbessus. With supplies from Syracuse cut, the Romans were now besieged and constructed a line of contravallation. After a few skirmishes, disease struck the Roman army while supplies in Agrigentum were running low, and both sides saw an open battle as preferable to the current situation. Although the Romans won a clear victory over the Carthaginian relief force at the Battle of Agrigentum, the Carthaginian army defending the city managed to escape. Agrigentum, now lacking any real defences, fell easily to the Romans, who then sacked the city and enslaved the populace.

At the beginning of the First Punic War, Rome had virtually no experience in naval warfare, whereas the strong and powerful Carthage had a great deal of experience on the seas thanks to its centuries of sea-based trade. Nevertheless, the growing Roman Republic soon understood the importance of Mediterranean control in the outcome of the conflict.

The first major Roman fleet was constructed after the victory of Agrigentum in 261 BC. Some historians have speculated that, since Rome lacked advanced naval technology, the design of the warships was probably copied from captured Carthaginian triremes and quinqueremes or from ships that had beached on Roman shores due to storms. According to Polybius, the Romans seized a shipwrecked Carthaginian quinquereme, and used it as a blueprint for their own ships. Other historians have pointed out that Rome did have experience with naval technology, as she patrolled her coasts against piracy. Another possibility is that Rome received technical assistance from its seafaring Sicilian ally, Syracuse. Regardless of the state of their naval technology at the start of the war, Rome quickly adapted.

In order to compensate for the lack of experience, and to make use of standard land military tactics at sea, the Romans equipped their new ships with a special boarding device, the "corvus". The Roman military was a land-based army, while Carthage was primarily a naval power. This boarding-bridge allowed the Roman navy to circumvent some of Carthage's naval skills by using their marines to board Carthaginian ships and fight in hand-to-hand combat. Instead of manoeuvring to ram, which was the standard naval tactic at the time, "corvus" equipped ships would manoeuver alongside the enemy vessel, deploy the bridge which would attach to the enemy ship through spikes on the end of the bridge, and send legionaries across as boarding parties.

The new weapon would prove its worth in the Battle of Mylae, the first Roman naval victory, and would continue to do so in the following years, especially in the huge Battle of Cape Ecnomus. The addition of the "corvus" forced Carthage to review its military tactics, and since the city had difficulty in doing so, Rome had the naval advantage.

The Roman fleet, under the command of Gaius Duilius, engaged the Carthaginians, under general Hannibal Gisco, off northern Mylae in 260 BC. Polybius states that the Carthaginians had 130 ships, but does not give an exact figure for the Romans. The loss of 17 ships at the Lipari Islands from a starting total of 120 ships suggests that Rome had 103 remaining. However, it is possible that this number was greater, thanks to captured ships and the assistance of Roman allies. The Carthaginians anticipated victory, due to their superior experience at sea.

The "corvi" were very successful, and helped the Romans seize the first 30 Carthaginian ships that were close enough. In order to avoid the "corvi", the Carthaginians were forced to navigate around them and approach the Romans from behind, or from the side. The "corvus" was usually still able to pivot and grapple most oncoming ships. After a further 20 Carthaginian ships had been hooked and lost to the Romans, Hannibal Gisco retreated with his surviving ships, leaving Duilius with a clear victory.

Instead of pursuing the remaining Carthaginians, Duilius sailed to Sicily to relieve the city of Segesta, which had been under siege from the Carthaginian infantry commander Hamilcar. Modern historians have wondered at Duilius’ decision not to immediately follow up with another naval attack, but Hannibal Gisco’s remaining 80 ships were probably still too strong for Rome to conquer.

The Roman advance now continued westward from Agrigentum to relieve the besieged city of Macella in 260 BC, which had sided with Rome and was attacked by the Carthaginians for doing so. In the north, the Romans, with their northern sea flank secured by their naval victory at the Battle of Mylae, advanced toward Thermae. They were defeated there by the Carthaginians under Hamilcar (a popular Carthaginian name, not to be confused with Hannibal Barca's father, with the same name) in 260 BC. The Carthaginians took advantage of this victory by counter-attacking, in 259 BC, and seizing Enna. Hamilcar continued south to Camarina, in Syracusan territory, presumably with the intent to convince the Syracusans to rejoin the Carthaginian side.

In 259 BC, consul Lucius Cornelius Scipio occupied Aleria in Corsica and probably Olbia in Sardinia. Hanno died while fighting at Olbia. The Romans withdrew because of the arrival of a Carthaginian fleet. Cornelius Scipio celebrated his victories over the Carthaginians and Sardinians with a triumph the following year. During the same year, a naval battle occurred near Sulci. The Carthaginian fleet was defeated and the commander Hannibal Gisco, who abandoned his men and fled to Sulci, was later captured by his soldiers and crucified.

The next year, 258 BC, the Romans were able to regain the initiative by retaking Enna and Camarina. In central Sicily, they took the town of Mytistraton, which they had attacked twice previously. The Romans also moved in the north by marching across the northern coast toward Panormus, but were not able to take the city.

After their conquests in the Agrigentum campaign, and following several naval battles, Rome attempted (256/255 BC) the second large scale land operation of the war. Seeking a swifter end to the war than the long sieges in Sicily would have provided, Rome decided to invade the Carthaginian colonies of Africa and usurp Carthage's supremacy in the Mediterranean Sea, consequently forcing Carthage to accept its terms.

In order to initiate its invasion of Africa, the Roman Republic constructed a major fleet, comprising transports for the army and its equipment, and warships for protection. Carthage attempted to intervene with a fleet of 350 ships (according to Polybius), but was defeated in the Battle of Cape Ecnomus.

As a result of the battle, the Roman army, commanded by Marcus Atilius Regulus, landed in Africa and began ravaging the Carthaginian countryside. The Siege of Aspis (or Clupea) was the first fighting on African land during the war. Regulus was next victorious at the Battle of Adys, forcing Carthage to sue for peace. According to Polybius, the terms suggested were so heavy that Carthage decided they would be better off not under Roman rule. The negotiations failed but fortunately, for the Carthaginians, Xanthippus, a Spartan mercenary, returned to Carthage to reorganise its army. Xanthippus defeated the Roman army and captured Regulus at the Battle of Tunis, and then managed to cut off what remained of the Roman army from its base by re-establishing Carthaginian naval supremacy.

The Romans, meanwhile, had sent a new fleet to pick up the survivors of its African expedition. Although the Romans defeated the Carthaginian fleet and were successful in rescuing their army in Africa, a storm destroyed nearly the entire Roman fleet on the return trip; the number of casualties in the disaster may have exceeded 90,000 men. The Carthaginians took advantage of this to attack Agrigentum. They did not believe that they could hold the city, so they burned it and left.

The Romans were able to rally, however, and quickly resumed the offensive. With a new fleet of 140 ships, Rome returned to the strategy of taking the Carthaginian cities in Sicily one by one.

Attacks began with naval assaults on Lilybaeum, the centre of Carthaginian power on Sicily, and a raid on Africa. Both efforts ended in failure. The Romans retreated from Lilybaeum, and the Roman African force was caught in another storm and destroyed.

The Romans, however, made great progress in the north. The city of Thermae was captured in 252 BC, enabling another advance on the port city of Panormus. The Romans attacked this city after taking Kephalodon in 251 BC. After fierce fighting, the Carthaginians were defeated and the city fell. With Panormus captured, much of western inland Sicily fell with it. The cities of Ietas, Solous, Petra, and Tyndaris agreed to peace with the Romans that same year.

The next year, the Romans shifted their attention to the north-west. They sent a naval expedition toward Lilybaeum. En route, the Romans seized and burned the Carthaginian hold-out cities of Selinous and Heraclea Minoa. This expedition to Lilybaeum was not successful, but attacking the Carthaginian headquarters demonstrated Roman resolve to take all of Sicily. The Roman fleet was defeated by the Carthaginians at Drepana, forcing the Romans to continue their attacks from land. Roman forces at Lilybaeum were relieved, and Eryx, near Drepana, was seized thus menacing that important city as well.

Following the conclusive naval victory off Drepana in 249 BC, Carthage ruled the seas as Rome was unwilling to finance the construction of yet another expensive fleet. Nevertheless, the Carthaginian faction that opposed the conflict, led by the land-owning aristocrat Hanno the Great, gained power and in 244 BC, considering the war to be over, started the demobilisation of the fleet, giving the Romans a chance to again attain naval superiority.

At this point (247 BC), Carthage sent general Hamilcar Barca (Hannibal's father) to Sicily. His landing at Heirkte (near Panormus) drew the Romans away to defend that port city and resupply point and gave Drepana some breathing room. Subsequent guerrilla warfare kept the Roman legions pinned down and preserved Carthage's toehold in Sicily, although Roman forces which bypassed Hamilcar forced him to relocate to Eryx, to better defend Drepana.

Perhaps in response to Hamilcar's raids, Rome built another fleet (paid for by donations from wealthy citizens). It was this fleet that rendered the Carthaginian success in Sicily futile, as the stalemate Hamilcar produced in Sicily became irrelevant following the Roman naval victory at the Battle of the Aegates Islands in 241 BC, where the new Roman fleet under consul Gaius Lutatius Catulus was victorious over an undermanned and hastily built Carthaginian fleet. Carthage lost most of its fleet and was economically incapable of funding another, or of finding manpower for the crews.

Without naval support, Hamilcar Barca was cut off from Carthage and forced to negotiate peace and agree to evacuate Sicily. Hamilcar Barca had a subordinate named Gesco conduct the negotiations with Lutatius, in order to create the impression that he had not really been defeated.

Due to the difficulty of operating in Sicily, most of the First Punic War was fought at sea, including the most decisive battles. But one reason the war bogged down into stalemate on the landward side was because ancient navies were ineffective at maintaining seaward blockades of enemy ports. Consequently, Carthage was able to reinforce and re-supply its besieged strongholds, especially Lilybaeum, on the western end of Sicily. Both sides of the conflict had publicly funded fleets. This fact compromised Carthage and Rome's finances and eventually decided the course of the war.

Despite the Roman victories at sea, the Roman Republic lost countless ships and crews during the war, due to both storms and battles. On at least two occasions (255 and 253 BC), whole fleets were destroyed in bad weather; the disaster off Camarina in 255 BC counted 270 ships and 119,280 men lost, the greatest single loss in history. One theory is that the weight of the "corvus" on the prows of the ships made the ships unstable and caused them to sink in bad weather. Later, as Roman experience in naval warfare grew, the "corvus" device was made attachable and detachable due to its impact on the navigability of the war vessels.

Rome won the First Punic War after 23 years of conflict and in the end became the dominant naval power of the Mediterranean. In the aftermath of the war, both states were financially and demographically exhausted. Corsica, Sardinia and Africa remained Carthaginian, but they had to pay a high war indemnity. Rome's victory was greatly influenced by its persistence. Moreover, the Roman Republic's ability to attract private investments in the war effort to fund ships and crews was one of the deciding factors of the war, particularly when contrasted with the Carthaginian nobility's apparent unwillingness to risk their fortunes for the common war effort.

The exact number of casualties on each side is difficult to determine, due to bias in the historical sources.

According to sources (excluding land warfare casualties):

Although uncertain, the casualties were heavy for both sides. Polybius commented that the war was, at the time, the most destructive in terms of casualties in the history of warfare, including the battles of Alexander the Great. Analysing the data from the Roman census of the 3rd century BC, Adrian Goldsworthy noted that, during the conflict, Rome lost about 50,000 male citizens. This excludes auxiliary troops and every other man in the army without citizen status, who would be outside the head count.

The terms of the Treaty of Lutatius designed by the Romans were particularly heavy for Carthage, which had lost bargaining power following its defeat at the Aegates islands. Accordingly, Carthage agreed to:

Further clauses determined that the allies of each side would not be attacked by the other, no attacks were to be made by either side upon the other's allies and both sides were prohibited from recruiting soldiers within the territory of the other. This denied the Carthaginians access to any mercenary manpower from Italy and most of Sicily, although this later clause was temporarily abolished during the Mercenary War.

In the aftermath of the war, Carthage had insufficient state funds. Hanno the Great tried to induce the disbanded armies to accept diminished payment, but kindled a movement that led to an internal conflict, the Mercenary War. After a hard struggle from the combined efforts of Hamilcar Barca, Hanno the Great and others, the Punic forces were finally able to annihilate the mercenaries and the insurgents. However, during this conflict, Rome took advantage of the opportunity to strip Carthage of Corsica and Sardinia as well.

Perhaps the most immediate political result of the First Punic War was the downfall of Carthage's naval power. Conditions signed in the peace treaty were intended to compromise Carthage's economic situation and prevent the city's recovery. The indemnity demanded by the Romans strained the city's finances and forced Carthage to look to other areas of influence for the money to pay Rome.

Carthage, seeking to make up for the recent territorial losses and a plentiful source of silver to pay the large indemnity owed to Rome, turned its attention to Iberia; and in 237 BC, the Carthaginians, led by Hamilcar Barca, began a series of campaigns to expand their control over the peninsula. Though Hamilcar was killed in 229 BC, the offensive continued with the Carthaginians extending their power towards the Ebro valley and founding "New Carthage" in 228 BC. When Carthage besieged the Roman protected town of Saguntum in 218 BC, it ignited the Second Punic War with Rome.

As for Rome, the end of the First Punic War marked the start of Rome's expansion beyond the Italian Peninsula. Sicily became the first Roman province (Sicilia) governed by a former praetor, instead of an ally. Sicily would become very important to Rome as a source of grain. Importantly, Syracuse was granted nominal independent ally status for the lifetime of Hiero II, and was not incorporated into the Roman province of Sicily until after it was sacked by Marcus Claudius Marcellus during the Second Punic War.







</doc>
<doc id="11429" url="https://en.wikipedia.org/wiki?curid=11429" title="False document">
False document

A false document is a technique, employed to create verisimilitude in a work of fiction, where an author tries to create a sense of authenticity beyond the normal and expected suspension of disbelief for a work of art by inventing and inserting documents that appear to be factual. The goal of a false document is to convince an audience that what is being presented is factual. 

A forged document, the Zinoviev Letter, helped bring the downfall of the first Labour Government in Britain. Conspiracies within secret intelligence services have occurred more recently, leading Harold Wilson to put in place rules to prevent in the 1960s phone tapping of members of Parliament, for example.

"The Protocols of the Elders of Zion", purporting to describe a Jewish plan for global domination, was first published in Russia in 1903, translated into multiple languages, and disseminated internationally in the early part of the 20th century.

Artist JSG Boggs's life and work have been extensively explored by author and journalist Lawrence Weschler. Boggs draws currency with exceptional care and accuracy, but he only ever draws one side. He then attempts to buy things with the piece of paper upon which he has drawn the currency. His goal is to pass each bill for its face value in common transactions. He buys lunch, clothes, and lodging in this manner, and after the transactions are complete, his bills fetch many times their face value on the art market. Boggs does not make any money from the much larger art market value of his work, only from reselling the goods bought, the change and receipts and other such materials. He has been arrested in many countries, and there is much controversy surrounding his work.

Orson Welles' "F for Fake" is a prime example of a film which is both about falsification (art forgery and the journalism surrounding art forgery) as well as having falsified moments within the film. The movie follows the exploits of a famous art forger, his biographer Clifford Irving, and the subsequent fake autobiography of Howard Hughes that Irving tries to publish. The issues of veracity and forgery are explored in the film, while at the same time, Welles tricks the audience by incorporating fake bits of narrative alongside the documentary footage.

There is a long history of producers creating tie-in material to promote and merchandise movies and television shows. Tie-in materials as far-ranging as toys, games, lunch boxes, clothing and so on have all been created and in some cases generate as much or more revenue as the original programming. One big merchandising arena is publishing. In most cases such material is not considered canon within the show's mythology; however, in some instances the books, magazines, etc. are specifically designed by the creators to be canonical. With the rise of the Internet, in-canon online material has become more prominent.

The following is a list of "false document" in-canon supplemental material:
Additionally, a set of trading cards was produced which are also canon.

A number of hoaxes have involved false documents:

Pseudepigrapha are falsely attributed works, texts whose claimed author is not the true author, or a work whose real author attributed it to a figure of the past. Pseudepigraphy covers the false ascription of names of authors to works, even to authentic works that make no such claim within their text. Thus a widely accepted but incorrect attribution of authorship may make a completely authentic text pseudepigraphical. Assessing the actual writer of a text locates questions of pseudepigraphical attribution within the discipline of literary criticism.

In biblical studies, the term "pseudepigrapha" typically refers to an assorted collection of Jewish religious works thought to be written "c." 300 BC to 300 AD. They are distinguished by Protestants from the Deuterocanonical books (Catholic and Orthodox) or Apocrypha (Protestant), the books that appear in extant copies of the Septuagint from the fourth century on, and the Vulgate but not in the Hebrew Bible or in Protestant Bibles. The Catholic Church distinguishes only between the deuterocanonical and all the other books, that are called biblical apocrypha, a name that is also used for the pseudepigrapha in the Catholic usage. In addition, two books considered canonical in the Orthodox Tewahedo churches, "viz." Book of Enoch and Book of Jubilees, are categorized as pseudepigrapha from the point of view of Chalcedonian Christianity.




</doc>
<doc id="11431" url="https://en.wikipedia.org/wiki?curid=11431" title="Fernando Pessoa">
Fernando Pessoa

Fernando António Nogueira Pessoa (; 13 June 1888 – 30 November 1935), commonly known as Fernando Pessoa, was a Portuguese poet, writer, literary critic, translator, publisher and philosopher, described as one of the most significant literary figures of the 20th century and one of the greatest poets in the Portuguese language. He also wrote in and translated from English and French.

Pessoa was a prolific writer, and not only under his own name, for he dreamed up approximately seventy-five others. He did not call them "pseudonyms" because he felt that did not capture their true independent intellectual life and instead called them "heteronyms". These imaginary figures sometimes held unpopular or extreme views.

Pessoa was born in Lisbon on 13 June 1888. When Pessoa was five, his father, Joaquim de Seabra Pessôa, died of tuberculosis and the following year, on 2 January, his younger brother Jorge, aged one, also died.

After the second marriage of his mother, Maria Magdalena Pinheiro Nogueira, proxy wedding to João Miguel dos Santos Rosa, Fernando sailed with his mother for South Africa in the beginning of 1896, to join his stepfather, a military officer appointed Portuguese consul in Durban, capital of the former British Colony of Natal. Later on, in 1918, Pessoa wrote a letter in which refers:

The young Pessoa received his early education at St. Joseph Convent School, a Catholic grammar school run by Irish and French nuns. He moved to the Durban High School in April 1899, becoming fluent in English and developing an appreciation for English literature. During the Matriculation Examination, held at the time by the University of the Cape of Good Hope (forerunner of the University of Cape Town), in November 1903 he was awarded the recently created Queen Victoria Memorial Prize for best paper in English. While preparing to enter university, he also attended the Durban Commercial High School during one year, in the evening shift.

Meanwhile, Pessoa started writing short stories in English, some under the name of David Merrick, many of which he left unfinished. At the age of sixteen, "The Natal Mercury" (edition of 6 July 1904) published his poem "Hillier did first usurp the realms of rhyme...", under the name of C. R. Anon (anonymous), along with a brief introductory text: "I read with great amusement...". In December, "The Durban High School Magazine" published his essay "Macaulay". From February to June 1905, in the section "The Man in the Moon", "The Natal Mercury" also published at least four sonnets by Fernando Pessoa: "Joseph Chamberlain", "To England I", "To England II" and "Liberty". His poems often carried humorous versions of Anon as the author's name. Pessoa started using pen names quite young. The first one, still in his childhood, was Chevalier de Pas, supposedly a French noble. In addition to Charles Robert Anon and David Merrick, the young writer also signed up, among other pen names, as Horace James Faber, Alexander Search, and other meaningful names.

In the preface to "The Book of Disquiet", Pessoa wrote about himself:

The young Pessoa was described by a schoolfellow as follows:
Ten years after his arrival, he sailed for Lisbon via the Suez Canal on board the "Herzog", leaving Durban for good at the age of seventeen. This journey inspired the poems "Opiário" (dedicated to his friend, the poet and writer Mário de Sá-Carneiro) published in March 1915, in "Orpheu" nr.1 and "Ode Marítima" (dedicated to the futurist painter Santa-Rita Pintor) published in June 1915, in "Orpheu" nr.2 by his heteronym Álvaro de Campos.

While his family remained in South Africa, Pessoa returned to Lisbon in 1905 to study diplomacy. After a period of illness, and two years of poor results, a student strike against the dictatorship of Prime Minister João Franco put an end to his formal studies. Pessoa became an autodidact, a devoted reader who spent a lot of time at the library. In August 1907, he started working as a practitioner at R.G. Dun & Company, an American mercantile information agency (currently D&B, Dun & Bradstreet). His grandmother died in September and left him a small inheritance, which he spent on setting up his own publishing house, the "Empreza Ibis". The venture was not successful and closed down in 1910, but the name ibis, the sacred bird of Ancient Egypt and inventor of the alphabet in Greek mythology, would remain an important symbolic reference for him.

Pessoa returned to his uncompleted formal studies, complementing his British education with self-directed study of Portuguese culture. The pre-revolutionary atmosphere surrounding the assassination of King Charles I and Crown Prince Luís Filipe in 1908, and the patriotic outburst resulting from the successful republican revolution in 1910, influenced the development of the budding writer; as did his step-uncle, Henrique dos Santos Rosa, a poet and retired soldier, who introduced the young Pessoa to Portuguese poetry, notably the romantics and symbolists of the 19th century. In 1912, Fernando Pessoa entered the literary world with a critical essay, published in the cultural journal "A Águia", which triggered one of the most important literary debates in the Portuguese intellectual world of the 20th century: the polemic regarding a super-Camões. In 1915 a group of artists and poets, including Fernando Pessoa, Mário de Sá-Carneiro and Almada Negreiros, created the literary magazine "Orpheu", which introduced modernist literature to Portugal. Only two issues were published (Jan–Feb–Mar and Apr–May–Jun 1915), the third failed to appear due to funding difficulties. Lost for many years, this issue was finally recovered and published in 1984. Among other writers and poets, "Orpheu" published Pessoa, orthonym, and the modernist heteronym, Álvaro de Campos.

Along with the artist Ruy Vaz, Pessoa also founded the art journal "Athena" (1924–25), in which he published verses under the heteronyms Alberto Caeiro and Ricardo Reis. Along with his profession, as free-lance commercial translator, Fernando Pessoa undertook intense activity as a writer, literary critic and political analyst, contributing to the journals and newspapers "A Águia" (1912–13), "A República" (1913), "Theatro" (1913), "A Renascença" (1914), "O Raio" (1914), "A Galera" (1915), "Orpheu" (1915), "O Jornal" (1915), "Eh Real!" (1915), "Exílio" (1916), "Centauro" (1916), "A Ideia Nacional" (1916), "Terra Nossa" (1916), "O Heraldo" (1917), "Portugal Futurista" (1917), "Acção" (1919–20), "Ressurreição" (1920), "Contemporânea" (1922–26), "Athena" (1924–25), "Diário de Lisboa" (1924–35), "Revista de Comércio e Contabilidade" (1926), "Sol" (1926), "O Imparcial" (1927), "Presença" (1927–34), "Revista Solução Editora" (1929–1931), "Notícias Ilustrado" (1928–30), "Girassol" (1930), "Revolução" (1932), "Descobrimento" (1932), "Fama" (1932–33), "Fradique" (1934) and "Sudoeste" (1935).

After his return to Portugal, when he was seventeen, Pessoa barely left his beloved city of Lisbon, which inspired the poems "Lisbon Revisited" (1923 and 1926), under the heteronym Álvaro de Campos. From 1905 to 1920, when his family returned from Pretoria after the death of his stepfather, he lived in fifteen different locations in the city, moving from one rented room to another depending on his fluctuating finances and personal troubles.

Pessoa adopted the detached perspective of the flâneur "Bernardo Soares", another of his heteronyms. This character was supposedly an accountant, working for "Vasques", the boss of an office located in Douradores Street. "Soares" also supposedly lived in the same downtown street, a world that Pessoa knew quite well due to his long career as freelance correspondence translator. Indeed, from 1907 until his death in 1935, Pessoa worked in twenty-one firms located in Lisbon's downtown, sometimes in two or three of them simultaneously. In "The Book of Disquiet", "Bernardo Soares" describes some of those typical places and its "atmosphere". In his daydream soliloquy he also wrote about Lisbon in the first half of the 20th century. "Soares" describes crowds in the streets, buildings, shops, traffic, river Tagus, the weather, and even its author, Fernando Pessoa:

A statue of Pessoa sitting at a table (below) can be seen outside A Brasileira, one of the preferred places of young writers and artists of "Orpheu"'s group during the 1910s. This coffeehouse, in the aristocratic district of Chiado, is quite close to Pessoa's birthplace: 4, São Carlos Square (in front of the Opera House, where stands another statue of the writer), one of the most elegant neighborhoods of Lisbon. Later on, Pessoa was a frequent customer at Martinho da Arcada, a centennial coffeehouse in Comercio Square, surrounded by ministries, almost an "office" for his private business and literary concerns, where he used to meet friends in the 1920s and 1930s.

In 1925, Pessoa wrote in English a guidebook to Lisbon but it remained unpublished until 1992.

Pessoa translated a number of Portuguese books into English, and into Portuguese "The Scarlet Letter" by Nathaniel Hawthorne, and the short stories "The Theory and the Hound", "The Roads We Take" and "Georgia's Ruling" by O. Henry. Pessoa also translated into Portuguese the poetry "Godiva" by Alfred Tennyson, "Lucy" by William Wordsworth, "Barbara Frietchie" by John Greenleaf Whittier, "Catarina to Camoens" by Elizabeth Barrett Browning, and "The Raven", "Annabel Lee" and "Ulalume" by Edgar Allan Poe who, along with Walt Whitman, strongly influenced him.

As a translator, Pessoa had his own method:

In addition, Pessoa translated into Portuguese some books by the leading theosophists Helena Blavatsky, Charles Webster Leadbeater, Annie Besant, and Mabel Collins.

In 1912–14, while living with his aunt "Anica" and cousins, Pessoa took part in "semi-spiritualist sessions" that were carried out at home, but he was considered a "delaying element" by the other members of the sessions. Pessoa's interest in spiritualism was truly awakened in the second half of 1915, while translating theosophist books. This was further deepened in the end of March 1916, when he suddenly started having experiences where he became a medium, which were revealed through automatic writing. On 24 June, Pessoa wrote an impressive letter to his aunt and godmother, then living in Switzerland with her daughter and son in law, in which he describes this "mystery case" that surprised him.

Besides automatic writing, Pessoa stated also that he had "astral" or "etherial visions" and was able to see "magnetic auras" similar to radiographic images. He felt "more curiosity than fear", but was respectful towards this phenomenon and asked secrecy, because "there is no advantage, but many disadvantages" in speaking about this. Mediumship exerted a strong influence in Pessoa's writings, who felt "sometimes suddenly being owned by something else" or having a "very curious sensation" in the right arm, which was "lifted into the air" without his will. Looking in the mirror, Pessoa saw several times what appeared to be the heteronyms: his "face fading out" and being replaced by the one of "a bearded man", or another one, four men in total.

Pessoa also developed a strong interest in astrology, becoming a competent astrologist. He elaborated more than 1,500 astrological charts, including well-known people like William Shakespeare, Lord Byron, Oscar Wilde, Chopin, Robespierre, Napoleon I, Benito Mussolini, Wilhelm II, Leopold II of Belgium, Victor Emmanuel III, Alfonso XIII, or the Kings Sebastian and Charles of Portugal, and Salazar. In 1915, he created the heteronym "Raphael Baldaya", an astrologist who planned to write "System of Astrology" and "Introduction to the Study of Occultism". Pessoa established the pricing of his astrological services from 500 to 5,000 réis and made horoscopes of customers, friends and also himself and, astonishingly, of the heteronyms and also of journals as "Orpheu".

Born on 13 June, Pessoa was native of Gemini and had Scorpio as rising sign. The characters of the main heteronyms were inspired by the four astral elements: air, fire, water and earth. It means that Pessoa and his heteronyms altogether comprised the full principles of ancient knowledge. Those heteronyms were designed according to their horoscopes, all including Mercury, the planet of literature. Astrology was part of his everyday life and Pessoa kept that interest until his death, which he was able to predict with some accuracy.

As a mysticist, Pessoa was an enthusiast of esotericism, occultism, hermetism, numerology and alchemy. Along with spiritualism and astrology, he also paid attention to neopaganism, theosophy, rosicrucianism and freemasonry, which strongly influenced his literary work. He has declared himself a Pagan, in the sense of an "intellectual mystic of the sad race of the Neoplatonists from Alexandria" and a believer in "the Gods, their agency and their real and materially superior existence". His interest in occultism led Pessoa to correspond with Aleister Crowley and later helped him to elaborate a fake suicide, when Crowley visited Portugal in 1930. Pessoa translated Crowley's poem "Hymn To Pan" into Portuguese, and the catalogue of Pessoa's library shows that he possessed Crowley's books "Magick in Theory and Practice" and "Confessions". Pessoa also wrote on Crowley's doctrine of Thelema in several fragments, including "Moral".

Pessoa's declared about secret societies:

Literary critic Martin Lüdke described Pessoa's philosophy as a kind of pandeism, especially those writings under the heteronym Alberto Caeiro.

In his early years, Pessoa was influenced by major English classic poets such as Shakespeare, Milton and Pope, or romantics like Shelley, Byron, Keats, Wordsworth, Coleridge and Tennyson. After his return to Lisbon in 1905, Pessoa was influenced by French symbolists and decadentists Charles Baudelaire, Maurice Rollinat, Stéphane Mallarmé; mainly by Portuguese poets as Antero de Quental, Gomes Leal, Cesário Verde, António Nobre, Camilo Pessanha or Teixeira de Pascoaes. Later on, he was also influenced by modernists as W. B. Yeats, James Joyce, Ezra Pound and T. S. Eliot, among many other writers.

During World War I, Pessoa wrote to a number of British publishers, namely Constable & Co. Ltd. (currently Constable & Robinson), in order to print his collection of English verse "The Mad Fiddler" (unpublished during his lifetime), but it was refused. However, in 1920, the prestigious literary journal "Athenaeum" included one of those poems. Since the British publication failed, in 1918 Pessoa published in Lisbon two slim volumes of English verse: "Antinous" and "35 Sonnets", received by the British literary press without enthusiasm. Along with some friends, he founded another publishing house – Olisipo – which published in 1921 a further two English poetry volumes: "English Poems I–II" and "English Poems III" by Fernando Pessoa. In his publishing house, Pessoa issued also some books by his friends: "A Invenção do Dia Claro" (The invention of the clear day) by José de Almada Negreiros, "Canções" (Songs) by António Botto, and "Sodoma Divinizada" (Divinized Sodome) by Raul Leal (Henoch). Olisipo closed down in 1923, following the scandal known as "Literatura de Sodoma" (Literature of Sodome), which Pessoa started with his paper "António Botto e o Ideal Estético em Portugal" (António Botto and the aesthetical ideal in Portugal), published in the journal "Contemporanea".

Politically, Pessoa described himself as "a British-style conservative, that is to say, liberal within conservatism and absolutely anti-reactionary," and adhered closely to the Spencerian individualism of his upbringing. He described his brand of nationalism as "mystic, cosmopolitan, liberal, and anti-Catholic." He was an outspoken elitist and aligned himself against communism, socialism, fascism and Catholicism. He initially rallied to the First Portuguese Republic but the ensuing instability caused him to reluctantly support the military coups of 1917 and 1926 as a means of restoring order and preparing the transition to a new constitutional normality. He wrote a pamphlet in 1928 supportive of the military dictatorship but after the establishment of the New State, in 1933, Pessoa became disenchanted with the regime and wrote critically of Salazar and fascism in general, maintaining a hostile stance towards its corporatist program, illiberalism, and censorship. In the beginning of 1935, Pessoa was banned by the Salazar regime, after he wrote in defense of Freemasonry. The regime also suppressed two articles Pessoa wrote in which he condemned Mussolini's invasion of Abyssinia and fascism as a threat to human liberty everywhere.

On 29 November 1935, Pessoa was taken to the Hospital de São Luís, suffering from abdominal pain and a high fever; there he wrote, in English, his last words: "I know not what tomorrow will bring." He died the next day, 30 November 1935, around 8 pm, aged 47. His cause of death is commonly given as cirrhosis of the liver, due to alcoholism, though this is disputed: others attribute his death to pancreatitis (again from alcoholism), or other ailments.

In his lifetime, he published four books in English and one alone in Portuguese: "Mensagem" (Message). However, he left a lifetime of unpublished, unfinished or just sketchy work in a domed, wooden trunk (25,574 manuscript and typed pages which have been housed in the Portuguese National Library since 1988). The heavy burden of editing this huge work is still in progress. In 1985 (fifty years after his death), Pessoa's remains were moved to the Hieronymites Monastery, in Lisbon, where Vasco da Gama, Luís de Camões, and Alexandre Herculano are also buried. Pessoa's portrait was on the 100-escudo banknote.

As the fake heteronym Coelho Pacheco, over a long period Pessoa's “triumphant day” was taken as real, however, it has been proved that this event was one more fiction created by Pessoa.

Pessoa's earliest heteronym, at the age of six, was Chevalier de Pas. Other childhood heteronyms included Dr. Pancrácio and David Merrick, followed by Charles Robert Anon, an English young man that became Pessoa's "alter ego". In 1905/7, when Pessoa was a student at the University of Lisbon, Alexander Search took the place of Anon. The main reason for this was that, although Search is English, he was born in Lisbon as his author. But Search represents a transition heteronym that Pessoa used while searching to adapt to the Portuguese cultural reality. After the republican revolution, in 1910, and consequent patriotic atmosphere, Pessoa created another "alter ego", Álvaro de Campos, supposedly a Portuguese naval engineer, born in Tavira and graduated in Glasgow. Translator Richard Zenith notes that Pessoa eventually established at least seventy-two heteronyms. According to Pessoa himself, there were three main heteronyms: Alberto Caeiro, Álvaro de Campos and Ricardo Reis. The heteronyms possess distinct biographies, temperaments, philosophies, appearances, writing styles and even signatures.

Pessoa wrote on the heteronyms:

Alberto Caeiro was Pessoa's first great heteronym; it is summarized by Pessoa as follows: "He sees things with the eyes only, not with the mind. He does not let any thoughts arise when he looks at a flower... the only thing a stone tells him is that it has nothing at all to tell him... this way of looking at a stone may be described as the totally unpoetic way of looking at it. The stupendous fact about Caeiro is that out of this sentiment, or rather, absence of sentiment, he makes poetry."

What this means, and what makes Caeiro such an original poet is the way he apprehends existence. He does not question anything whatsoever; he calmly accepts the world as it is. The recurrent themes to be found in nearly all of Caeiro's poems are wide-eyed childlike wonder at the infinite variety of nature, as noted by a critic. He is free of metaphysical entanglements. Central to his world-view is the idea that in the world around us, all is surface: things are precisely what they seem, there is no hidden meaning anywhere.

He manages thus to free himself from the anxieties that batter his peers; for Caeiro, things simply exist and we have no right to credit them with more than that. Caeiro attains happiness by not questioning, and by thus avoiding doubts and uncertainties. He apprehends reality solely through his eyes, through his senses. Octavio Paz called him the innocent poet. Paz made a shrewd remark on the heteronyms: In each are particles of negation or unreality. Reis believes in form, Campos in sensation, Pessoa in symbols. Caeiro doesn't believe in anything. He exists.

Poetry before Caeiro was essentially interpretative; what poets did was to offer an interpretation of their perceived surroundings; Caeiro does not do this. Instead, he attempts to communicate his senses, and his feelings, without any interpretation whatsoever.

Caeiro attempts to approach Nature from a qualitatively different mode of apprehension; that of simply perceiving (an approach akin to phenomenological approaches to philosophy). Poets before him would make use of intricate metaphors to describe what was before them; not so Caeiro: his self-appointed task is to bring these objects to the reader's attention, as directly and simply as possible. Caeiro sought a direct experience of the objects before him.

As such it is not surprising to find that Caeiro has been called an anti-intellectual, anti-Romantic, anti-subjectivist, anti-metaphysical...an anti-poet, by critics; Caeiro simply—is. He is in this sense very unlike his creator Fernando Pessoa: Pessoa was besieged by metaphysical uncertainties; these were, to a large extent, the cause of his unhappiness; not so Caeiro: his attitude is anti-metaphysical; he avoided uncertainties by adamantly clinging to a certainty: his belief that there is no meaning behind things. Things, for him, simply—are.

Caeiro represents a primal vision of reality, of things. He is the pagan incarnate. Indeed, Caeiro was not simply a pagan but paganism itself.

The critic Jane M. Sheets sees the insurgence of Caeiro—who was Pessoa's first major heteronym—as essential in founding the later poetic "personas": By means of this artless yet affirmative anti-poet, Caeiro, a short-lived but vital member of his coterie, Pessoa acquired the base of an experienced and universal poetic vision. After Caeiro's tenets had been established, the avowedly poetic voices of Campos, Reis and Pessoa himself spoke with greater assurance.

In a letter to William Bentley, Pessoa wrote that "a "knowledge" of the language would be indispensable, for instance, to appraise the 'Odes' of Ricardo Reis, whose Portuguese would draw upon him the blessing of António Vieira, as his stile and diction that of Horace (he has been called, admirably I believe, 'a Greek Horace who writes in Portuguese')".

Reis, both a character and a heteronym of Fernando Pessoa himself, sums up his philosophy of life in his own words, admonishing, "See life from a distance. Never question it. There's nothing it can tell you." Like Caeiro, whom he admires, Reis defers from questioning life. He is a modern pagan who urges one to seize the day and accept fate with tranquility. "Wise is the one who does not seek. The seeker will find in all things the abyss, and doubt in himself." In this sense, Reis shares essential affinities with Caeiro.

Believing in the Greek gods, yet living in a Christian Europe, Reis feels that his spiritual life is limited and true happiness cannot be attained. This, added to his belief in Fate as a driving force for all that exists, as such disregarding freedom, leads to his epicureanist philosophy, which entails the avoidance of pain, defending that man should seek tranquility and calm above all else, avoiding emotional extremes.

Where Caeiro wrote freely and spontaneously, with joviality, of his basic, meaningless connection to the world, Reis writes in an austere, cerebral manner, with premeditated rhythm and structure and a particular attention to the correct use of the language when approaching his subjects of, as characterized by Richard Zenith, "the brevity of life, the vanity of wealth and struggle, the joy of simple pleasures, patience in time of trouble, and avoidance of extremes".

In his detached, intellectual approach, he is closer to Fernando Pessoa's constant rationalization, as such representing the orthonym's wish for measure and sobriety and a world free of troubles and respite, in stark contrast to Caeiro's spirit and style. As such, where Caeiro's predominant attitude is that of joviality, his sadness being accepted as natural ("My sadness is a comfort for it is natural and right."), Reis is marked by melancholy, saddened by the impermanence of all things.

Ricardo Reis is the main character of José Saramago's 1986 novel "The Year of the Death of Ricardo Reis".

Álvaro de Campos manifests, in a way, as a hyperbolic version of Pessoa himself. Of the three heteronyms he is the one who feels most strongly, his motto being 'to feel everything in every way.' 'The best way to travel,' he wrote, 'is to feel.' As such, his poetry is the most emotionally intense and varied, constantly juggling two fundamental impulses: on the one hand a feverish desire to be and feel everything and everyone, declaring that 'in every corner of my soul stands an altar to a different god' (alluding to Walt Whitman's desire to 'contain multitudes'), on the other, a wish for a state of isolation and a sense of nothingness.

As a result, his mood and principles varied between violent, dynamic exultation, as he fervently wishes to experience the entirety of the universe in himself, in all manners possible (a particularly distinctive trait in this state being his futuristic leanings, including the expression of great enthusiasm as to the meaning of city life and its components) and a state of nostalgic melancholy, where life is viewed as, essentially, empty.

One of the poet's constant preoccupations, as part of his dichotomous character, is that of identity: he does not know who he is, or rather, fails at achieving an ideal identity. Wanting to be everything, and inevitably failing, he despairs. Unlike Caeiro, who asks nothing of life, he asks too much. In his poetic meditation 'Tobacco Shop' he asks:

"Mensagem", written in Portuguese, is a symbolist epic made up of 44 short poems organized in three parts or Cycles:

The first, called "Brasão" (Coat-of-Arms), relates Portuguese historical protagonists to each of the fields and charges in the Portuguese coat of arms. The first two poems ("The castles" and "The escutcheons") draw inspiration from the material and spiritual natures of Portugal. Each of the remaining poems associates to each charge a historical personality. Ultimately they all lead to the Golden Age of Discovery.

The second Part, called "Mar Português" (Portuguese Sea), references the country's Age of Portuguese Exploration and to its seaborne Empire that ended with the death of King Sebastian at El-Ksar el Kebir ("Alcácer-Quibir" in Portuguese) in 1578. Pessoa brings the reader to the present as if he had woken up from a dream of the past, to fall in a dream of the future: he sees King Sebastian returning and still bent on accomplishing a Universal Empire.

The third Cycle, called "O Encoberto" ("The Hidden One"), refers to Pessoa's vision of a future world of peace and the Fifth Empire (which, according to Pessoa, is spiritual and not material, because if it were material England would already have achieved it). After the Age of Force, (Vis), and Taedium (Otium) will come Science (understanding) through a reawakening of "The Hidden One", or "King Sebastian". The Hidden One represents the fulfillment of the destiny of mankind, designed by God since before Time, and the accomplishment of Portugal.

King Sebastian is very important, indeed he appears in all three parts of Mensagem. He represents the capacity of dreaming, and believing that it's possible to achieve dreams.

One of the most famous quotes from "Mensagem" is the first line from "O Infante" (belonging to the second Part), which is "Deus quer, o homem sonha, a obra nasce" (which translates roughly to "God wishes, man dreams, the work is born"). Another well-known quote from "Mensagem" is the first line from "Ulysses", "O mito é o nada que é tudo" (a possible translation is "The myth is the nothing that is all"). This poem refers to Ulysses, king of Ithaca, as Lisbon's founder (recalling an ancient Greek myth).

In 1912, Fernando Pessoa wrote a set of essays (later collected as "The New Portuguese Poetry") for the cultural journal "A Águia" (The Eagle), founded in Oporto, in December 1910, and run by the republican association Renascença Portuguesa. In the first years of the Portuguese Republic, this cultural association was started by republican intellectuals led by the writer and poet Teixeira de Pascoaes, philosopher Leonardo Coimbra and historian Jaime Cortesão, aiming for the renewal of Portuguese culture through the aesthetic movement called Saudosismo. Pessoa contributed to the journal "A Águia" with a series of papers: 'The new Portuguese Poetry Sociologically Considered' (nr. 4), 'Relapsing...' (nr. 5) and 'The Psychological Aspect of the new Portuguese Poetry' (nrs. 9,11 and 12). These writings were strongly encomiastic to saudosist literature, namely the poetry of Teixeira de Pascoaes and Mário Beirão. The articles disclose Pessoa as a connoisseur of modern European literature and an expert of recent literary trends. On the other hand, he does not care much for a methodology of analysis or problems in the history of ideas. He states his confidence that Portugal would soon produce a great poet – a super-Camões – pledged to make an important contribution for European culture, and indeed, for humanity.

The philosophical notes of young Fernando Pessoa, mostly written between 1905 and 1912, illustrate his debt to the history of Philosophy more through commentators than through a first-hand protracted reading of the Classics, ancient or modern. The issues he engages with pertain to every philosophical discipline and concern a large profusion of concepts, creating a vast semantic spectrum in texts whose length oscillates between half a dozen lines and half a dozen pages and whose density of analysis is extremely variable; simple paraphrasis, expression of assumptions and original speculation.

Pessoa sorted the philosophical systems thus:

Such pantheist transcendentalism is used by Pessoa to define the project that "encompasses and exceeds all systems"; to characterize the new poetry of Saudosismo where the "typical contradiction of this system" occurs; to inquire of the particular social and political results of its adoption as the leading cultural paradigm; and, at last, he hints that metaphysics and religiosity strive "to find in everything a beyond".







</doc>
<doc id="11432" url="https://en.wikipedia.org/wiki?curid=11432" title="Full moon">
Full moon

The full moon is the lunar phase when the Moon appears fully illuminated from Earth's perspective. This occurs when Earth is located between the Sun and the Moon (more exactly, when the ecliptic longitudes of the Sun and Moon differ by 180°). This means that the lunar hemisphere facing Earth – the near side – is completely sunlit and appears as a circular disk. The full moon occurs roughly once a month.

The time interval between a full (or new) moon and the next repetition of the same phase, a synodic month, averages about 29.53 days. Therefore, in those lunar calendars in which each month begins on the day of the new moon, the full moon falls on either the 14th or 15th day of the lunar month. Because a calendar month consists of a whole number of days, a month in a lunar calendar may be either 29 or 30 days long.

A full moon is often thought of as an event of a full night's duration. This is somewhat misleading because its phase seen from Earth continuously waxes or wanes (though much too slowly to notice in real time with the naked eye). By definition, its maximum illumination occurs at the moment waxing stops. For any given location, about half of these maximum full moons may be visible, while the other half occurs during the day, when the full moon is below the horizon.

Many almanacs list full moons not only by date, but also by their exact time, usually in Coordinated Universal Time (UTC). Typical monthly calendars that include lunar phases may be offset by one day when prepared for a different time zone.

Full moon is generally a suboptimal time for astronomical observation of the Moon because shadows vanish. It is a poor time for other observations because the bright sunlight reflected by the Moon, amplified by the opposition surge, then outshines many stars.

On 12 December 2008, the full moon was closer to the Earth than it had been at any time in the previous 15 years. This was referred to in popular media as a supermoon.

On 19 March 2011, there was another full "supermoon", closer to the Earth than at any time in the previous 18 years.

On 14 November 2016, there was another full "supermoon"; this time it was closer to the Earth than at any time in the previous 68 years.

The date and approximate time of a specific full moon (assuming a circular orbit) can be calculated from the following equation:
where "d" is the number of days since 1 January 2000 00:00:00 in the Terrestrial Time scale used in astronomical ephemerides; for Universal Time (UT) add the following approximate correction to "d":
where "N" is the number of full moons since the first full moon of 2000. The true time of a full moon may differ from this approximation by up to about 14.5 hours as a result of the non-circularity of the Moon's orbit. See New moon for an explanation of the formula and its parameters.

The age and apparent size of the full moon vary in a cycle of just under 14 synodic months, which has been referred to as a full moon cycle.

When the Moon moves into Earth's shadow, a lunar eclipse occurs, during which all or part of the Moon's face may appear reddish due to the Rayleigh scattering of blue wavelengths and the refraction of sunlight through Earth's atmosphere. Lunar eclipses happen only during full moon and around points on its orbit where the satellite may pass through the planet's shadow. A lunar eclipse does not occur every month because the Moon's orbit is inclined 5.14° with respect to the ecliptic plane of Earth; thus, the Moon usually passes north or south of Earth's shadow, which is mostly restricted to this plane of reference. Lunar eclipses happen only when the full moon occurs around either node of its orbit (ascending or descending). Therefore, a lunar eclipse occurs about every six months, and often two weeks before or after a solar eclipse, which occurs during new moon around the opposite node.

Full moons are traditionally associated with insomnia (inability to sleep), insanity (hence the terms "lunacy" and "lunatic") and various "magical phenomena" such as lycanthropy. Psychologists, however, have found that there is no strong evidence for effects on human behavior around the time of a full moon. They find that studies are generally not consistent, with some showing a positive effect and others showing a negative effect. In one instance, the 23 December 2000 issue of the "British Medical Journal" published two studies on dog bite admission to hospitals in England and Australia. The study of the Bradford Royal Infirmary found that dog bites were twice as common during a full moon, whereas the study conducted by the public hospitals in Australia found that they were less likely.
Historically, month names are names of moons (lunations, not necessarily full moons) in lunisolar calendars. Since the introduction of the solar Julian calendar in the Roman Empire, and later the Gregorian calendar worldwide, people no longer perceive month names as "moon" names. The traditional Old English month names were equated with the names of the Julian calendar from an early time (soon after Christianization, according to the testimony of Bede around AD 700).

Some full moons have developed new names in modern times, such as "blue moon", as well as "harvest moon" and "hunter's moon" for the full moons of autumn.

Lunar eclipses occur only at full moon and often cause a reddish hue on the near side of the Moon. This full moon has been called a blood moon in popular culture. 

The "harvest moon" and the "hunter's moon" are traditional names for the full moons in late summer and in the autumn in the Northern Hemisphere, usually in September and October, respectively.

The "harvest moon" is the full moon nearest the autumnal equinox (22 or 23 September), occurring anytime within two weeks before or after that date. The "hunter's moon" is the full moon following it. The names are recorded from the early 18th century. The "Oxford English Dictionary" entry for "harvest moon" cites a 1706 reference, and for "hunter's moon" a 1710 edition of "The British Apollo", where the term is attributed to "the country people" ("The Country People call this the Hunters-Moon.") The names became traditional in American folklore, where they are now often popularly attributed to Native Americans. The Feast of the Hunters' Moon is a yearly festival in West Lafayette, Indiana, held in late September or early October each year since 1968. In 2010, the harvest moon occurred on the night of the equinox itself (some 5 hours after the moment of equinox) for the first time since 1991.

All full moons rise around the time of sunset. Since the Moon moves eastward among the stars faster than the Sun, lunar culmination is delayed by about 50.47 minutes (on average) each day, thus causing moonrise to occur later each day.

Due to the high lunar standstill, the harvest and hunter's moons of 2007 were special because the time difference between moonrises on successive evenings was much shorter than average. The Moon rose about 30 minutes later from one night to the next, as seen from about 40° N or S latitude. (This is because the full Moon of September 2007 rose in the northeast rather than in the east.) Hence, no long period of darkness occurred between sunset and moonrise for several days after the full Moon, thus lengthening the time in the evening when enough twilight and moonlight to work to get the harvest in.

The "Maine Farmers' Almanac" from around the 1930s began to publish Native American "Indian" full moon names. The "Farmers' Almanac" (since 1955 published in Maine, but not the same publication as the "Maine Farmers' Almanac") continues to do so.

An early list of "Indian month names" was published in 1918 by Daniel Carter Beard in his "The American Boy's Book of Signs, Signals and Symbols" for use by the boy scouts. Beard's "Indian" month names were:

Such names have gained currency in American folklore. They appear in print more widely outside of the almanac tradition from the 1990s in popular publications about the Moon.
"Mysteries of the Moon" by Patricia Haddock ("Great Mysteries Series", Greenhaven Press, 1992) gave an extensive list of such names along with the individual tribal groups they were supposedly associated with. Haddock supposes that certain "Colonial American" moon names were adopted from Algonquian languages (which were formerly spoken in the territory of New England), while others are based in European tradition (e.g. the Colonial American names for the May moon, "Milk Moon", "Mother's Moon", "Hare Moon" have no parallels in the supposed native names, while the name of November, "Beaver Moon" is supposedly based in a Algonquian) language.

The individual names (some inconsistent) given in "Farmers' Almanac", which is not authoritative, include the following:
The Long Night's Moon is the last full Moon of the year and the one nearest the winter solstice.

"Ice Moon" is also used to refer to the first full Moon of January or February.

In Hinduism, most festivals are celebrated on auspicious days. Many of the Hindu festivals are celebrated on days with a full moon at night.
Different parts of India celebrate the same day with different names, as listed below:

Most pre-modern calendars the world over were lunisolar, combining the solar year with the lunation by means of intercalary months.
The Julian calendar abandoned this method in favour of a purely solar reckoning while conversely the 7th-century Islamic calendar opted for a purely lunar one.

A continuing lunisolar calendar is in the Hebrew calendar. Evidence of this is noted in the dates of Passover and Easter in Judaism and Christianity, respectively. Passover falls on the full moon on 15 Nisan of the Hebrew calendar. The date of the Jewish Rosh Hashana and Sukkot festivals along with all other Jewish holidays are dependent on the dates of the new moons.

In lunisolar calendars, an intercalary month occurs seven times in the 19 years of the Metonic cycle, or on average every 2.7 years (19/7). In the Hebrew Calendar this is noted with a periodic extra month of Adar in the early spring.

In the modern system of "traditional" full moon names tied to the solstice and equinox points, a supernumerary full moon in such a period is called a blue moon. The term "blue moon" used in this sense may date to as early as the 16th century, but it became well known in the United States due to the "Farmers' Almanac" (published since 1818).

According to the "Farmers' Almanac", a "blue moon" is the third full moon in any period between either solstice and equinox, or between equinox and solstice, (calculated using the mean tropical year), which contains four full moons. These seasons are equal in length, unlike the astronomical ones, which vary in length depending on the Earth's speed in its elliptical orbit round the Sun. To compare, in 1983 the equal length seasons began at 1.48 am on 23 March, 9.15 am on 22 June, 4.42 pm on 21 September and 12.10 am on 22 December, while the astronomical seasons began at 4.39 am on 21 March, 11.09 pm on 21 June, 2.42 pm on 23 September and 10.30 am on 22 December (all times GMT). Due to a misinterpretation of this definition in the March 1946 "Sky & Telescope" magazine, "blue moon" has also been used in the sense of "the second full moon in any month which contains two full moons (this usage has been noted as "erroneous" by "Sky & Telescope" in 1999). According to either definition, "blue moons" occur with the average frequency of intercalary months, seven times in 19 years, the "Farmers' Almanac" system of "full moon names" effectively defining a lunisolar calendar.




</doc>
<doc id="11433" url="https://en.wikipedia.org/wiki?curid=11433" title="Film format">
Film format

A film format is a technical definition of a set of standard characteristics regarding image capture on photographic film, for either stills or filmmaking. It can also apply to projected film, either slides or movies. The primary characteristic of a film format is its size and shape.

In the case of motion picture film, the format may also include audio parameters (though often not). Other characteristics usually include the film gauge, pulldown method, lens anamorphosis (or lack thereof), and film gate or projector aperture dimensions, all of which need to be defined for photography as well as projection, as they may differ.

"For roll holder" means film for cartridge roll holders, allowing roll film to be used with cameras designed to use glass plates. These were spooled with the emulsion facing outward, rather than inward as in film designed for native roll-film cameras. Types 106 to 114 were for Eastman-Walker rollholders, while types 50 to 54 were for Graflex rollholders.

The primary reason there were so many different negative formats in the early days was that prints were made by contact, without use of an enlarger. The film format would thus be exactly the same as the size of the print—so if you wanted large prints, you would have to use a large camera and corresponding film format.

Before World War II, each film manufacturer used its own system of numbering for the various sizes of rollfilms they made. The following sortable table shows the corresponding numbers. A blank space means that manufacturer did not make film in that size. Two numbers in one box refers to films available with different numbers of exposures, usually 6 and either 10 or 12. Spool length is measured between inner faces of the flanges; several films of the same image size were available on different spools to fit different cameras.




</doc>
<doc id="11439" url="https://en.wikipedia.org/wiki?curid=11439" title="Faster-than-light">
Faster-than-light

Faster-than-light (also superluminal or FTL) communication and travel are the conjectural propagation of information or matter faster than the speed of light.

The special theory of relativity implies that only particles with zero rest mass may travel at the speed of light. Tachyons, particles whose speed exceeds that of light, have been hypothesized, but their existence would violate causality, and the consensus of physicists is that they cannot exist. On the other hand, what some physicists refer to as "apparent" or "effective" FTL depends on the hypothesis that unusually distorted regions of spacetime might permit matter to reach distant locations in less time than light could in normal or undistorted spacetime.

According to the current scientific theories, matter is required to travel at slower-than-light (also subluminal or STL) speed with respect to the locally distorted spacetime region. "Apparent" FTL is not excluded by general relativity; however, any apparent FTL physical plausibility is speculative. Examples of apparent FTL proposals are the Alcubierre drive and the traversable wormhole.

In the context of this article, FTL is the transmission of information or matter faster than "c", a constant equal to the speed of light in a vacuum, which is 299,792,458 m/s (by definition of the meter) or about 186,282.397 miles per second. This is not quite the same as traveling faster than light, since:
Neither of these phenomena violates special relativity or creates problems with causality, and thus neither qualifies as "FTL" as described here.

In the following examples, certain influences may appear to travel faster than light, but they do not convey energy or information faster than light, so they do not violate special relativity.

For an earth-bound observer, objects in the sky complete one revolution around the Earth in one day. Proxima Centauri, the nearest star outside the Solar System, is about four light-years away. In this frame of reference, in which Proxima Centauri is perceived to be moving in a circular trajectory with a radius of four light years, it could be described as having a speed many times greater than "c" as the rim speed of an object moving in a circle is a product of the radius and angular speed. It is also possible on a geostatic view, for objects such as comets to vary their speed from subluminal to superluminal and vice versa simply because the distance from the Earth varies. Comets may have orbits which take them out to more than 1000 AU. The circumference of a circle with a radius of 1000 AU is greater than one light day. In other words, a comet at such a distance is superluminal in a geostatic, and therefore non-inertial, frame.

If a laser beam is swept across a distant object, the spot of laser light can easily be made to move across the object at a speed greater than "c". Similarly, a shadow projected onto a distant object can be made to move across the object faster than "c". In neither case does the light travel from the source to the object faster than "c", nor does any information travel faster than light. An analogy can be made to pointing a water hose in one direction and then quickly moving the hose to point the stream of water in another direction. At no point does the water leaving the hose ever increase in velocity, but the endpoint of the stream can be moved faster than the water in the stream itself.

Since there is no "retardation" (or aberration) of the apparent position of the source of a gravitational or electric static field when the source moves with constant velocity, the static field "effect" may seem at first glance to be "transmitted" faster than the speed of light. However, uniform motion of the static source may be removed with a change in reference frame, causing the direction of the static field to change immediately, at all distances. This is not a change of position which "propagates", and thus this change cannot be used to transmit information from the source. No information or matter can be FTL-transmitted or propagated from source to receiver/observer by an electromagnetic field.

The rate at which two objects in motion in a single frame of reference get closer together is called the mutual or closing speed. This may approach twice the speed of light, as in the case of two particles travelling at close to the speed of light in opposite directions with respect to the reference frame.

Imagine two fast-moving particles approaching each other from opposite sides of a particle accelerator of the collider type. The closing speed would be the rate at which the distance between the two particles is decreasing. From the point of view of an observer standing at rest relative to the accelerator, this rate will be slightly less than twice the speed of light.

Special relativity does not prohibit this. It tells us that it is wrong to use Galilean relativity to compute the velocity of one of the particles, as would be measured by an observer traveling alongside the other particle. That is, special relativity gives the correct velocity-addition formula for computing such relative velocity.

It is instructive to compute the relative velocity of particles moving at "v" and −"v" in accelerator frame, which corresponds to the closing speed of 2"v" > "c". Expressing the speeds in units of "c", β = "v"/"c":

If a spaceship travels to a planet one light-year (as measured in the Earth's rest frame) away from Earth at high speed, the time taken to reach that planet could be less than one year as measured by the traveller's clock (although it will always be more than one year as measured by a clock on Earth). The value obtained by dividing the distance traveled, as determined in the Earth's frame, by the time taken, measured by the traveller's clock, is known as a proper speed or a proper velocity. There is no limit on the value of a proper speed as a proper speed does not represent a speed measured in a single inertial frame. A light signal that left the Earth at the same time as the traveller would always get to the destination before the traveller.

Since one might not travel faster than light, one might conclude that a human can never travel further from the Earth than 40 light-years if the traveler is active between the age of 20 and 60. A traveler would then never be able to reach more than the very few star systems which exist within the limit of 20–40 light-years from the Earth. This is a mistaken conclusion: because of time dilation, the traveler can travel thousands of light-years during their 40 active years. If the spaceship accelerates at a constant 1 g (in its own changing frame of reference), it will, after 354 days, reach speeds a little under the speed of light (for an observer on Earth), and time dilation will increase their lifespan to thousands of Earth years, seen from the reference system of the Solar System, but the traveler's subjective lifespan will not thereby change. If the traveler returns to the Earth, they will land thousands of years into the Earth's future. Their speed will not be seen as higher than the speed of light by observers on Earth, and the traveler will not measure their speed as being higher than the speed of light, but will see a length contraction of the universe in their direction of travel. And as the traveler turns around to return, the Earth will seem to experience much more time than the traveler does. So, while their (ordinary) coordinate speed cannot exceed "c", their proper speed (distance as seen by Earth divided by their proper time) can be much greater than "c". This is seen in statistical studies of muons traveling much further than "c" times their half-life (at rest), if traveling close to "c".

The phase velocity of an electromagnetic wave, when traveling through a medium, can routinely exceed "c", the vacuum velocity of light. For example, this occurs in most glasses at X-ray frequencies. However, the phase velocity of a wave corresponds to the propagation speed of a theoretical single-frequency (purely monochromatic) component of the wave at that frequency. Such a wave component must be infinite in extent and of constant amplitude (otherwise it is not truly monochromatic), and so cannot convey any information.
Thus a phase velocity above "c" does not imply the propagation of signals with a velocity above "c".

The group velocity of a wave may also exceed "c" in some circumstances. In such cases, which typically at the same time involve rapid attenuation of the intensity, the maximum of the envelope of a pulse may travel with a velocity above "c". However, even this situation does not imply the propagation of signals with a velocity above "c", even though one may be tempted to associate pulse maxima with signals. The latter association has been shown to be misleading, because the information on the arrival of a pulse can be obtained before the pulse maximum arrives. For example, if some mechanism allows the full transmission of the leading part of a pulse while strongly attenuating the pulse maximum and everything behind (distortion), the pulse maximum is effectively shifted forward in time, while the information on the pulse does not come faster than "c" without this effect. However, group velocity can exceed "c" in some parts of a Gaussian beam in a vacuum (without attenuation). The diffraction causes the peak of the pulse to propagate faster, while overall power does not.

The expansion of the universe causes distant galaxies to recede from us faster than the speed of light, if proper distance and cosmological time are used to calculate the speeds of these galaxies. However, in general relativity, velocity is a local notion, so velocity calculated using comoving coordinates does not have any simple relation to velocity calculated locally. (See Comoving and proper distances for a discussion of different notions of 'velocity' in cosmology.) Rules that apply to relative velocities in special relativity, such as the rule that relative velocities cannot increase past the speed of light, do not apply to relative velocities in comoving coordinates, which are often described in terms of the "expansion of space" between galaxies. This expansion rate is thought to have been at its peak during the inflationary epoch thought to have occurred in a tiny fraction of the second after the Big Bang (models suggest the period would have been from around 10 seconds after the Big Bang to around 10 seconds), when the universe may have rapidly expanded by a factor of around 10 to 10.

There are many galaxies visible in telescopes with red shift numbers of 1.4 or higher. All of these are currently traveling away from us at speeds greater than the speed of light. Because the Hubble parameter is decreasing with time, there can actually be cases where a galaxy that is receding from us faster than light does manage to emit a signal which reaches us eventually.

However, because the expansion of the universe is accelerating, it is projected that most galaxies will eventually cross a type of cosmological event horizon where any light they emit past that point will never be able to reach us at any time in the infinite future, because the light never reaches a point where its "peculiar velocity" towards us exceeds the expansion velocity away from us (these two notions of velocity are also discussed in Comoving and proper distances#Uses of the proper distance). The current distance to this cosmological event horizon is about 16 billion light-years, meaning that a signal from an event happening at present would eventually be able to reach us in the future if the event was less than 16 billion light-years away, but the signal would never reach us if the event was more than 16 billion light-years away.

Apparent superluminal motion is observed in many radio galaxies, blazars, quasars, and recently also in microquasars. The effect was predicted before it was observed by Martin Rees and can be explained as an optical illusion caused by the object partly moving in the direction of the observer, when the speed calculations assume it does not. The phenomenon does not contradict the theory of special relativity. Corrected calculations show these objects have velocities close to the speed of light (relative to our reference frame). They are the first examples of large amounts of mass moving at close to the speed of light. Earth-bound laboratories have only been able to accelerate small numbers of elementary particles to such speeds.

Certain phenomena in quantum mechanics, such as quantum entanglement, might give the superficial impression of allowing communication of information faster than light. According to the no-communication theorem these phenomena do not allow true communication; they only let two observers in different locations see the same system simultaneously, without any way of controlling what either sees. Wavefunction collapse can be viewed as an epiphenomenon of quantum decoherence, which in turn is nothing more than an effect of the underlying local time evolution of the wavefunction of a system and "all" of its environment. Since the underlying behavior does not violate local causality or allow FTL communication, it follows that neither does the additional effect of wavefunction collapse, whether real "or" apparent.

The uncertainty principle implies that individual photons may travel for short distances at speeds somewhat faster (or slower) than "c", even in a vacuum; this possibility must be taken into account when enumerating Feynman diagrams for a particle interaction. However, it was shown in 2011 that a single photon may not travel faster than "c". In quantum mechanics, virtual particles may travel faster than light, and this phenomenon is related to the fact that static field effects (which are mediated by virtual particles in quantum terms) may travel faster than light (see section on static fields above). However, macroscopically these fluctuations average out, so that photons do travel in straight lines over long (i.e., non-quantum) distances, and they do travel at the speed of light on average. Therefore, this does not imply the possibility of superluminal information transmission.

There have been various reports in the popular press of experiments on faster-than-light transmission in optics — most often in the context of a kind of quantum tunnelling phenomenon. Usually, such reports deal with a phase velocity or group velocity faster than the vacuum velocity of light. However, as stated above, a superluminal phase velocity cannot be used for faster-than-light transmission of information.

The Hartman effect is the tunneling effect through a barrier where the tunneling time tends to a constant for large barriers. This could, for instance, be the gap between two prisms. When the prisms are in contact, the light passes straight through, but when there is a gap, the light is refracted. There is a non-zero probability that the photon will tunnel across the gap rather than follow the refracted path. For large gaps between the prisms the tunnelling time approaches a constant and thus the photons appear to have crossed with a superluminal speed.

However, the Hartman effect cannot actually be used to violate relativity by transmitting signals faster than "c", because the tunnelling time "should not be linked to a velocity since evanescent waves do not propagate". The evanescent waves in the Hartman effect are due to virtual particles and a non-propagating static field, as mentioned in the sections above for gravity and electromagnetism.

In physics, the Casimir–Polder force is a physical force exerted between separate objects due to resonance of vacuum energy in the intervening space between the objects. This is sometimes described in terms of virtual particles interacting with the objects, owing to the mathematical form of one possible way of calculating the strength of the effect. Because the strength of the force falls off rapidly with distance, it is only measurable when the distance between the objects is extremely small. Because the effect is due to virtual particles mediating a static field effect, it is subject to the comments about static fields discussed above.

The EPR paradox refers to a famous thought experiment of Albert Einstein, Boris Podolsky and Nathan Rosen that was realized experimentally for the first time by Alain Aspect in 1981 and 1982 in the Aspect experiment. In this experiment, the measurement of the state of one of the quantum systems of an entangled pair apparently instantaneously forces the other system (which may be distant) to be measured in the complementary state. However, no information can be transmitted this way; the answer to whether or not the measurement actually affects the other quantum system comes down to which interpretation of quantum mechanics one subscribes to.

An experiment performed in 1997 by Nicolas Gisin has demonstrated non-local quantum correlations between particles separated by over 10 kilometers. But as noted earlier, the non-local correlations seen in entanglement cannot actually be used to transmit classical information faster than light, so that relativistic causality is preserved. The situation is akin to sharing a synchronized coin flip, where the second person to flip their coin will always see the opposite of what the first person sees, but neither has any way of knowing whether they were the first or second flipper, without communicating classically. See No-communication theorem for further information. A 2008 quantum physics experiment also performed by Nicolas Gisin and his colleagues has determined that in any hypothetical non-local hidden-variable theory, the speed of the quantum non-local connection (what Einstein called "spooky action at a distance") is at least 10,000 times the speed of light.

The delayed-choice quantum eraser is a version of the EPR paradox in which the observation (or not) of interference after the passage of a photon through a double slit experiment depends on the conditions of observation of a second photon entangled with the first. The characteristic of this experiment is that the observation of the second photon can take place at a later time than the observation of the first photon, which may give the impression that the measurement of the later photons "retroactively" determines whether the earlier photons show interference or not, although the interference pattern can only be seen by correlating the measurements of both members of every pair and so it can't be observed until both photons have been measured, ensuring that an experimenter watching only the photons going through the slit does not obtain information about the other photons in an FTL or backwards-in-time manner.

Faster-than-light communication is, according to relativity, equivalent to time travel. What we measure as the speed of light in a vacuum (or near vacuum) is actually the fundamental physical constant "c". This means that all inertial observers, regardless of their relative velocity, will always measure zero-mass particles such as photons traveling at "c" in a vacuum. This result means that measurements of time and velocity in different frames are no longer related simply by constant shifts, but are instead related by Poincaré transformations. These transformations have important implications:

The speed of light
is related to the vacuum permittivity "ε" and the vacuum permeability "μ". Therefore, not only the phase velocity, group velocity, and energy flow velocity of electromagnetic waves but also the velocity of a photon can be faster than "c" in a special material has the constant permittivity or permeability whose value is less than that in vacuum.

Special relativity postulates that the speed of light in vacuum is invariant in inertial frames. That is, it will be the same from any frame of reference moving at a constant speed. The equations do not specify any particular value for the speed of the light, which is an experimentally determined quantity for a fixed unit of length. Since 1983, the SI unit of length (the meter) has been defined using the speed of light.

The experimental determination has been made in vacuum. However, the vacuum we know is not the only possible vacuum which can exist. The vacuum has energy associated with it, called simply the vacuum energy, which could perhaps be altered in certain cases. When vacuum energy is lowered, light itself has been predicted to go faster than the standard value "c". This is known as the Scharnhorst effect. Such a vacuum can be produced by bringing two perfectly smooth metal plates together at near atomic diameter spacing. It is called a Casimir vacuum. Calculations imply that light will go faster in such a vacuum by a minuscule amount: a photon traveling between two plates that are 1 micrometer apart would increase the photon's speed by only about one part in 10. Accordingly, there has as yet been no experimental verification of the prediction. A recent analysis argued that the Scharnhorst effect cannot be used to send information backwards in time with a single set of plates since the plates' rest frame would define a "preferred frame" for FTL signalling. However, with multiple pairs of plates in motion relative to one another the authors noted that they had no arguments that could "guarantee the total absence of causality violations", and invoked Hawking's speculative chronology protection conjecture which suggests that feedback loops of virtual particles would create "uncontrollable singularities in the renormalized quantum stress-energy" on the boundary of any potential time machine, and thus would require a theory of quantum gravity to fully analyze. Other authors argue that Scharnhorst's original analysis, which seemed to show the possibility of faster-than-"c" signals, involved approximations which may be incorrect, so that it is not clear whether this effect could actually increase signal speed at all.

The physicists Günter Nimtz and Alfons Stahlhofen, of the University of Cologne, claim to have violated relativity experimentally by transmitting photons faster than the speed of light. They say they have conducted an experiment in which microwave photons — relatively low-energy packets of light — travelled "instantaneously" between a pair of prisms that had been moved up to apart. Their experiment involved an optical phenomenon known as "evanescent modes", and they claim that since evanescent modes have an imaginary wave number, they represent a "mathematical analogy" to quantum tunnelling. Nimtz has also claimed that "evanescent modes are not fully describable by the Maxwell equations and quantum mechanics have to be taken into consideration." Other scientists such as Herbert G. Winful and Robert Helling have argued that in fact there is nothing quantum-mechanical about Nimtz's experiments, and that the results can be fully predicted by the equations of classical electromagnetism (Maxwell's equations).

Nimtz told "New Scientist" magazine: "For the time being, this is the only violation of special relativity that I know of." However, other physicists say that this phenomenon does not allow information to be transmitted faster than light. Aephraim Steinberg, a quantum optics expert at the University of Toronto, Canada, uses the analogy of a train traveling from Chicago to New York, but dropping off train cars from the tail at each station along the way, so that the center of the ever-shrinking main train moves forward at each stop; in this way, the speed of the center of the train exceeds the speed of any of the individual cars.

Winful argues that the train analogy is a variant of the "reshaping argument" for superluminal tunneling velocities, but he goes on to say that this argument is not actually supported by experiment or simulations, which actually show that the transmitted pulse has the same length and shape as the incident pulse. Instead, Winful argues that the group delay in tunneling is not actually the transit time for the pulse (whose spatial length must be greater than the barrier length in order for its spectrum to be narrow enough to allow tunneling), but is instead the lifetime of the energy stored in a standing wave which forms inside the barrier. Since the stored energy in the barrier is less than the energy stored in a barrier-free region of the same length due to destructive interference, the group delay for the energy to escape the barrier region is shorter than it would be in free space, which according to Winful is the explanation for apparently superluminal tunneling.

A number of authors have published papers disputing Nimtz's claim that Einstein causality is violated by his experiments, and there are many other papers in the literature discussing why quantum tunneling is not thought to violate causality.

It was later claimed by Eckle "et al." that particle tunneling does indeed occur in zero real time. Their tests involved tunneling electrons, where the group argued a relativistic prediction for tunneling time should be 500–600 attoseconds (an attosecond is one quintillionth (10) of a second). All that could be measured was 24 attoseconds, which is the limit of the test accuracy. Again, though, other physicists believe that tunneling experiments in which particles appear to spend anomalously short times inside the barrier are in fact fully compatible with relativity, although there is disagreement about whether the explanation involves reshaping of the wave packet or other effects.

Because of the strong empirical support for special relativity, any modifications to it must necessarily be quite subtle and difficult to measure. The best-known attempt is doubly special relativity, which posits that the Planck length is also the same in all reference frames, and is associated with the work of Giovanni Amelino-Camelia and João Magueijo.

There are speculative theories that claim inertia is produced by the combined mass of the universe (e.g., Mach's principle), which implies that the rest frame of the universe might be "preferred" by conventional measurements of natural law. If confirmed, this would imply special relativity is an approximation to a more general theory, but since the relevant comparison would (by definition) be outside the observable universe, it is difficult to imagine (much less construct) experiments to test this hypothesis.

Although the theory of special relativity forbids objects to have a relative velocity greater than light speed, and general relativity reduces to special relativity in a local sense (in small regions of spacetime where curvature is negligible), general relativity does allow the space between distant objects to expand in such a way that they have a "recession velocity" which exceeds the speed of light, and it is thought that galaxies which are at a distance of more than about 14 billion light-years from us today have a recession velocity which is faster than light. Miguel Alcubierre theorized that it would be possible to create a warp drive, in which a ship would be enclosed in a "warp bubble" where the space at the front of the bubble is rapidly contracting and the space at the back is rapidly expanding, with the result that the bubble can reach a distant destination much faster than a light beam moving outside the bubble, but without objects inside the bubble locally traveling faster than light. However, several objections raised against the Alcubierre drive appear to rule out the possibility of actually using it in any practical fashion. Another possibility predicted by general relativity is the traversable wormhole, which could create a shortcut between arbitrarily distant points in space. As with the Alcubierre drive, travelers moving through the wormhole would not "locally" move faster than light travelling through the wormhole alongside them, but they would be able to reach their destination (and return to their starting location) faster than light traveling outside the wormhole.

Gerald Cleaver and Richard Obousy, a professor and student of Baylor University, theorized that manipulating the extra spatial dimensions of string theory around a spaceship with an extremely large amount of energy would create a "bubble" that could cause the ship to travel faster than the speed of light. To create this bubble, the physicists believe manipulating the 10th spatial dimension would alter the dark energy in three large spatial dimensions: height, width and length. Cleaver said positive dark energy is currently responsible for speeding up the expansion rate of our universe as time moves on.

In 1977, a paper on Heim theory theorized that it may be possible to travel faster than light by using magnetic fields to enter a higher-dimensional space.

The possibility that Lorentz symmetry may be violated has been seriously considered in the last two decades, particularly after the development of a realistic effective field theory that describes this possible violation, the so-called Standard-Model Extension. This general framework has allowed experimental searches by ultra-high energy cosmic-ray experiments and a wide variety of experiments in gravity, electrons, protons, neutrons, neutrinos, mesons, and photons.
The breaking of rotation and boost invariance causes direction dependence in the theory as well as unconventional energy dependence that introduces novel effects, including Lorentz-violating neutrino oscillations and modifications to the dispersion relations of different particle species, which naturally could make particles move faster than light.

In some models of broken Lorentz symmetry, it is postulated that the symmetry is still built into the most fundamental laws of physics, but that spontaneous symmetry breaking of Lorentz invariance shortly after the Big Bang could have left a "relic field" throughout the universe which causes particles to behave differently depending on their velocity relative to the field; however, there are also some models where Lorentz symmetry is broken in a more fundamental way. If Lorentz symmetry can cease to be a fundamental symmetry at Planck scale or at some other fundamental scale, it is conceivable that particles with a critical speed different from the speed of light be the ultimate constituents of matter.

In current models of Lorentz symmetry violation, the phenomenological parameters are expected to be energy-dependent. Therefore, as widely recognized, existing low-energy bounds cannot be applied to high-energy phenomena; however, many searches for Lorentz violation at high energies have been carried out using the Standard-Model Extension.
Lorentz symmetry violation is expected to become stronger as one gets closer to the fundamental scale.

In this approach the physical vacuum is viewed as the quantum superfluid which is essentially non-relativistic whereas the Lorentz symmetry is not an exact symmetry of nature but rather the approximate description valid only for the small fluctuations of the superfluid background. Within the framework of the approach a theory was proposed in which the physical vacuum is conjectured to be the quantum Bose liquid whose ground-state wavefunction is described by the logarithmic Schrödinger equation. It was shown that the relativistic gravitational interaction arises as the small-amplitude collective excitation mode whereas relativistic elementary particles can be described by the particle-like modes in the limit of low momenta. The important fact is that at very high velocities the behavior of the particle-like modes becomes distinct from the relativistic one - they can reach the speed of light limit at finite energy; also, faster-than-light propagation is possible without requiring moving objects to have imaginary mass.

In 2007 the MINOS collaboration reported results measuring the flight-time of 3 GeV neutrinos yielding a speed exceeding that of light by 1.8-sigma significance. However, those measurements were considered to be statistically consistent with neutrinos traveling at the speed of light. After the detectors for the project were upgraded in 2012, MINOS corrected their initial result and found agreement with the speed of light. Further measurements are going to be conducted.

On September 22, 2011, a preprint from the OPERA Collaboration indicated detection of 17 and 28 GeV muon neutrinos, sent 730 kilometers (454 miles) from CERN near Geneva, Switzerland to the Gran Sasso National Laboratory in Italy, traveling faster than light by a relative amount of (approximately 1 in 40,000), a statistic with 6.0-sigma significance. On 17 November 2011, a second follow-up experiment by OPERA scientists confirmed their initial results. However, scientists were skeptical about the results of these experiments, the significance of which was disputed. In March 2012, the ICARUS collaboration failed to reproduce the OPERA results with their equipment, detecting neutrino travel time from CERN to the Gran Sasso National Laboratory indistinguishable from the speed of light. Later the OPERA team reported two flaws in their equipment set-up that had caused errors far outside their original confidence interval: a fiber optic cable attached improperly, which caused the apparently faster-than-light measurements, and a clock oscillator ticking too fast.

In special relativity, it is impossible to accelerate an object the speed of light, or for a massive object to move the speed of light. However, it might be possible for an object to exist which moves faster than light. The hypothetical elementary particles with this property are called tachyonic particles. Attempts to quantize them failed to produce faster-than-light particles, and instead illustrated that their presence leads to an instability.

Various theorists have suggested that the neutrino might have a tachyonic nature, while others have disputed the possibility.

Mechanical equations to describe hypothetical exotic matter which possesses a negative mass, negative momentum, negative pressure, and negative kinetic energy are

Considering formula_7 and formula_8, the energy-momentum relation of the particle is corresponding to the following dispersion relation

of a wave that can propagate in the negative-index metamaterial. The pressure of radiation pressure in the metamaterial is negative and negative refraction, inverse Doppler effect and reverse Cherenkov effect imply that the momentum is also negative. So the wave in a negative-index metamaterial can be applied to test the theory of exotic matter and negative mass. For example, the velocity equals

That is to say, such a wave can break the light barrier under certain conditions.

General relativity was developed after special relativity to include concepts like gravity. It maintains the principle that no object can accelerate to the speed of light in the reference frame of any coincident observer. However, it permits distortions in spacetime that allow an object to move faster than light from the point of view of a distant observer. One such distortion is the Alcubierre drive, which can be thought of as producing a ripple in spacetime that carries an object along with it. Another possible system is the wormhole, which connects two distant locations as though by a shortcut. Both distortions would need to create a very strong curvature in a highly localized region of space-time and their gravity fields would be immense. To counteract the unstable nature, and prevent the distortions from collapsing under their own 'weight', one would need to introduce hypothetical exotic matter or negative energy.

General relativity also recognizes that any means of faster-than-light travel could also be used for time travel. This raises problems with causality. Many physicists believe that the above phenomena are impossible and that future theories of gravity will prohibit them. One theory states that stable wormholes are possible, but that any attempt to use a network of wormholes to violate causality would result in their decay. In string theory, Eric G. Gimon and Petr Hořava have argued that in a supersymmetric five-dimensional Gödel universe, quantum corrections to general relativity effectively cut off regions of spacetime with causality-violating closed timelike curves. In particular, in the quantum theory a smeared supertube is present that cuts the spacetime in such a way that, although in the full spacetime a closed timelike curve passed through every point, no complete curves exist on the interior region bounded by the tube.

In physics, the speed of light in a vacuum is assumed to be a constant. However, hypotheses exist that the speed of light is variable.

The speed of light is a dimensional quantity and so cannot be measured. Measurable quantities in physics are, without exception, dimensionless, although they are often constructed as ratios of dimensional quantities. For example, when the height of a mountain is measured, what is really measured is the ratio of its height to the length of a meter stick. The conventional SI system of units is based on seven basic dimensional quantities, namely distance, mass, time, electric current, thermodynamic temperature, amount of substance, and luminous intensity. These units are defined to be independent and so cannot be described in terms of each other. As an alternative to using a particular system of units, one can reduce all measurements to dimensionless quantities expressed in terms of ratios between the quantities being measured and various fundamental constants such as Newton's constant, the speed of light and Planck's constant; physicists can define at least 26 dimensionless constants which can be expressed in terms of these sorts of ratios and which are currently thought to be independent of one another. By manipulating the basic dimensional constants one can also construct the Planck time, Planck length, and Planck energy which make a good system of units for expressing dimensional measurements, known as Planck units.

João Magueijo proposed a different set of units, a choice which he justifies with the claim that some equations will be simpler in these new units. In the new units he fixes the fine structure constant, a quantity which some people, using units in which the speed of light is fixed, have claimed is time-dependent. Thus in the system of units in which the fine structure constant is fixed, the observational claim is that the speed of light is time-dependent.




</doc>
<doc id="11440" url="https://en.wikipedia.org/wiki?curid=11440" title="FTL">
FTL

FTL may stand for:





</doc>
<doc id="11442" url="https://en.wikipedia.org/wiki?curid=11442" title="FidoNet">
FidoNet

FidoNet is a worldwide computer network that is used for communication between bulletin board systems (BBSes). It uses a store-and-forward system to exchange private (email) and public (forum) messages between the BBSes in the network, as well as other files and protocols in some cases.

The FidoNet system was based on a number of small interacting programs. Only one of these interacted with the BBS system directly and was the only portion that had to be ported to support other BBS software. This greatly eased porting, and FidoNet was one of the few networks that was widely supported by almost all BBS software, as well as a number of non-BBS online services. This modular construction also allowed FidoNet to easily upgrade to new data compression systems, which was important in an era using modem-based communications over telephone links with high long-distance calling charges.

The rapid improvement in modem speeds during the early 1990s, combined with the rapid decrease in price of computer systems and storage, made BBSes increasingly popular. By the mid-1990s there were almost 40,000 FidoNet systems in operation, and it was possible to communicate with millions of users around the world. Only UUCPNET came close in terms of breadth or numbers; FidoNet's user base far surpassed other networks like BITNET.

The broad availability of low-cost Internet connections starting in the mid-1990s lessened the need for FidoNet's store-and-forward system, as any system in the world could be reached for equal cost. Direct dialing into local BBS systems rapidly declined. Although FidoNet has shrunk considerably since the late 1990s, it has remained in use even today despite internet connectivity becoming universally available.

There are two major accounts of the development of the FidoNet, differing only in small details.

Around Christmas 1983, Tom Jennings started work on a new MS-DOS–hosted bulletin board system that would emerge as Fido BBS. Jennings set up the system in San Francisco some time in early 1984. Another early user was John Madil, who was trying to set up a similar system in Baltimore on his Rainbow 100. Fido started spreading to new systems, and Jennings eventually started keeping an informal list of their phone numbers, with Jennings becoming #1 and Madil #2.

Jennings released the first version of the FidoNet software in June 1984. In early 1985 he wrote a document explaining the operations of the FidoNet, along with a short portion on the history of the system. In this version, FidoNet was developed as a way to exchange mail between the first two Fido BBS systems, Jennings' and Madil's, to "see if it could be done, merely for the fun of it". This was first supported in Fido V7, "sometime in June 84 or so".

In early 1984, Ben Baker was planning on starting a BBS for the newly forming computer club at the McDonnell Douglas automotive division in St. Louis. Baker was part of the CP/M special interest group within the club. He intended to use the seminal, CP/M-hosted, CBBS system, and went looking for a machine to run it on. The club's president told Baker that DEC would be giving them a Rainbow 100 computer on indefinite loan, so he made plans to move the CBBS onto this machine. The Rainbow contained two processors, an Intel 8088 and a Zilog Z80, allowing it to run both MS-DOS and CP/M, with the BBS running on the latter. When the machine arrived, they learned that the Z80 side had no access to the I/O ports, so CBBS could not communicate with a modem. While searching for software that would run on the MS-DOS side of the system, Baker learned of Fido through Madil.

The Fido software required changes to the serial drivers to work properly on the Rainbow. A porting effort started, involving Jennings, Madil and Baker. This caused all involved to rack up considerable long distance charges as they all called each other during development, or called into each other's BBSes to leave email. During one such call "in May or early June", Baker and Jennings discussed how great it would be if the BBS systems could call each other automatically, exchanging mail and files between them. This would allow them to compose mail on their local machines, and then deliver it quickly, as opposed to calling in and typing the message in while on a long-distance telephone connection. Jennings responded by calling into Baker's system that night and uploading a new version of the software consisting of three files: FIDO_DECV6 (the new version of the BBS program itself), FIDONET, and NODELIST.BBS. The new version of FIDO BBS had a timer that caused it to exit at a specified time, normally at night, and as it exited it would run the separate FIDONET program. NODELIST was the list of Fido BBS systems, which Jennings had already been compiling.

The FIDONET program was what later became known as a "mailer". FIDO was modified to use a previously unused numeric field in the message headers to store a "node number" for the machine the message should be delivered to. When FIDONET ran, it would search through the email database for any messages with a number in this field. FIDONET collected all of the messages for a particular node number into a file known as a "message packet". After all the packets were generated, one for each node, the FIDONET program would look up the destination node's phone number in NODELIST.BBS, and call the remote system. Provided that FIDONET was running on that system, the two systems would handshake and, if this succeeded, the calling system would upload its packet, download a return packet if there was one, and disconnect. FIDONET would then unpack the return packet, place the received messages into the local system's storage, and move onto the next packet. When there were no remaining packet, it would exit, and run the FIDO BBS program.

In order to lower long distance charges, the mail exchanges were timed to run late at night, normally 4 AM. This would later be known as "national mail hour", and, later still, as "Zone Mail Hour".

By June 1984 Version 7 of the system was being run in production, and nodes were rapidly being added to the network. By August there were almost 30 systems in the nodelist, 50 by September, and over 160 by January 1985. As the network grew, the maintenance of the nodelist became prohibitive, and errors were common. In these cases people would start receiving phone calls at 4 AM, from a caller that would say nothing and then hang up. In other cases the system would be listed before it was up and running, resulting in long distance calls that accomplished nothing.

In August 1984 Jennings handed off control of the nodelist to the group in St. Louis, mostly Ken Kaplan and Ben Baker. Kaplan had come across Fido as part of finding a BBS solution for his company, which worked with DEC computers and had been given a Rainbow computer and a USRobotics 1200bit/s modem. From then on, joining FidoNet required one to set up their system and use it to deliver a netmail message to a special system, Node 51. The message contained various required contact information. If this message was transmitted successfully, it ensured that at least some of the system was working properly. The nodelist team would then reply with another netmail message back to the system in question, containing the assigned node number. If delivery succeeded, the system was considered to be working properly, and it was added to the nodelist. The first new nodelist was published on 21 September 1984.

Growth continued to accelerate, and by the spring of 1985 the system was already reaching its limit of 250 nodes. In addition to the limits on growth of what was clearly a popular system, nodelist maintenance continued to grow more and more time consuming.

It was also realized that Fido systems were generally clustered – of the 15 systems running by the start of June 1984, 5 of them were in St. Louis. A user on Jennings's system in San Francisco that addressed emails to different systems in St. Louis would cause calls to be made to each of those BBSes in turn. Local calls were normally free or charged at a low rate. Additionally, the initial call setup, generally the first minute of the call, was normally billed at a higher rate than continuing an existing connection. Therefore, it would make sense to deliver all the messages from all the users in San Francisco to all of the users in St. Louis in a single call. Packets were generally small enough to be delivered within a minute or two, so delivering all the messages in a single call could greatly reduce costs by avoiding multiple first-minute charges. Once delivered, the packet would be broken out into separate packets for local systems, and delivered using multiple local free calls.

The team settled on the concept of adding a new "network number" patterned on the idea of area codes. A complete network address would now consist of the network and node number pair, which would be written with a slash between them. All mail travelling between networks would first be sent to their local "network host", someone who volunteered to pay for any long distance charges. That single site would collect up all the netmail from all of the systems in their network, then re-package it into single packets destined to each network. They would then call any required network admin sites and deliver the packet to them. That site would then process the mail as normal, although all of the messages in the packet would be guaranteed to be local calls.

The network address was placed in an unused field in the Fido message database, which formerly always held a zero. Systems running existing versions of the software already ignored the fields containing the new addressing, so they would continue to work as before; when noticing a message addressed to another node they would look it up and call that system. Newer systems would recognize the network number and instead deliver that message to the network host. To ensure backward compatibility, existing systems retained their original node numbers through this period.

A huge advantage of the new scheme was that node numbers were now unique only within their network, not globally. This meant the previous 250 node limit was gone, but for a variety of reasons this was initially limited to about 1,200. This change also devolved the maintenance of the nodelists down to the network hosts, who then sent updated lists back to Node 51 to be collected into the master list. The St. Louis group now had to only maintain their own local network, and do basic work to compile the global list.

At a meeting held in Kaplan's living room in St. Louis on 11 April 1985 the various parties hammered out all of the details of the new concept. As part of this meeting, they also added the concept of a "region", a purely administrative level that was not part of the addressing scheme. Regional hosts would handle any stragglers in the network maps, remote systems that had no local network hosts. They then divided up the US into ten regions that they felt would have roughly equal populations.

By May, Jennings had early versions of the new software running. These early versions specified the routing manually through a new ROUTE.BBS file that listed network hosts for each node. For instance, an operator might want to forward all mail to St. Louis through a single node, node 10. ROUTE.BBS would then include a list of all the known systems in that area, with instructions to forward mail to each of those nodes through node 10. This process was later semi-automated by John Warren's NODELIST program. Over time, this information was folded into updated versions of the nodelist format, and the ROUTES file is no longer used.

A new version of FIDO and FIDONET, 10C, was released containing all of these features. On 12 June 1985 the core group brought up 10C, and most Fido systems had upgraded within a few months. The process went much smoother than anyone imagined, and very few nodes had any problems.

Some time during the evolution of Fido, file attachments were added to the system, allowing a file to be referenced from an email message. During the normal exchange between two instances of FIDONET, any files attached to the messages in the packets were delivered after the packet itself had been up or downloaded. It is not clear when this was added, but it was already a feature of the basic system when the 8 February 1985 version of the FidoNet standards document was released, so this was added very early in Fido's history.

At a sysop meeting in Dallas, the idea was raised that it would be nice if there was some way for the sysops to post messages that would be shared among the systems. In February 1986 Jeff Rush, one of the group members, introduced a new mailer that extracted messages from public forums that the sysop selected, in a manner similar to the way the original mailer handled private messages. The new program was known as a "tosser/scanner". The tosser produced a file that was similar (or identical) to the output from the normal netmail scan, however, these files were then compressed and attached to a normal netmail message as an attachment. This message was then sent to a special address on the remote system. After receiving netmail as normal, the scanner on the remote system looked for these messages, unpacked them, and put them into the same public forum on the original system.

In this fashion, Rush's system implemented a store and forward public message system similar to Usenet, but based on, and hosted by, the FidoNet system. The first such "echomail" forum was one created by the Dallas area sysops to discuss business, known as SYSOP. Another called TECH soon followed. Several public "echos" soon followed, including GAYNET and CLANG. These spawned hundreds of new echos, and led to the creation of the Echomail Conference List (Echolist) by Thomas Kenny in January 1987. Echomail produced world-spanning shared forums, and its traffic volume quickly surpassed the original netmail system. By the early 1990s, echo mail was carrying over 8 MB of compressed message traffic a day, many times that when uncompressed.

Echomail did not necessarily use the same distribution pathways as normal netmail, and the distribution routing was stored in a separate setup file not unlike the original ROUTES.BBS. At the originating site a header line was added to the message indicating the origin system's name and address. After that, each system that the message traveled through added itself to a growing PATH header, as well as a SEENBY header. SEENBY prevented the message from looping around the network in the case of mis-configured routing information.

Echomail was not the only system to use the file attachment feature of netmail to implement store-and-forward capabilities. Similar concepts were used by online games and other systems as well.

The evolution towards the net/node addressing scheme was also useful for reducing communications costs between continents, where timezone differences on either end of the connection might also come into play. For instance, the best time to forward mail in the US was at night, but that might not be the best time for European hosts to exchange. Efforts towards introducing a continental level to the addressing system started in 1986.

At the same time, it was noted that some power users were interested in using FidoNet protocols as a way of delivering the large quantities of echomail to their local machines where it could be read offline. These users did not want their systems to appear in the nodelist - they did not (necessarily) run a bulletin board system and were not publicly accessible. A mechanism allowing netmail delivery to these systems without the overhead of nodelist maintenance was desirable.

In October 1986 the last major change to the FidoNet network was released, adding "zones" and "points". Zones represented major geographical areas roughly corresponding to continents. There were six zones in total, North America, South America, Europe, Oceania, Asia, and Africa. Points represented non-public nodes, which were created privately on a BBS system. Point mail was delivered to a selected host BBS as normal, but then re-packaged into a packet for the point to pick up on-demand. The complete addressing format was now codice_1, so a real example might be codice_2. Points were widely used only for a short time, the introduction of offline reader systems filled this role with systems that were much easier to use. Points remain in use to this day, but are less popular than when they were introduced.

Although FidoNet supported file attachments from even the earliest standards, this feature tended to be rarely used and was often turned off. File attachments followed the normal mail routing through multiple systems, and could back up transfers all along the line as the files were copied. A solution was offered in the form of "file requests", which made file transfers driven by the "calling" system and used one-time point-to-point connections instead of the traditional routing. Two such standards became common, "WaZOO" and "Bark", which saw varying support among different mailers. Both worked in a similar fashion, with the mailer calling the remote system and sending a new handshake packet to request the files.

Although FidoNet was, by far, the best known BBS-based network, it was by no means the only one. From 1988 on, PCBoard systems were able to host similar functionality known as RelayNet, while other popular networks included RBBSNet from the Commodore 64 world, and AlterNet. Late in the evolution of the FidoNet system, there was a proposal to allow mail (but not forum messages) from these systems to switch into the FidoNet structure. This was not adopted, and the rapid rise of the internet made this superfluous as these networks rapidly added internet exchange, which acted as a lingua franca.

FidoNet started in 1984 and listed 100 nodes by the end of that year. Steady growth continued through the 1980s, but a combination of factors led to rapid growth after 1988. These included faster and less expensive modems, and rapidly declining costs of hard drives and computer systems in general. By April 1993 the FidoNet nodelist contained over 20,000 systems. At that time it was estimated that each node had, on average, about 200 active users. Of these 4 million users in total, 2 million users commonly used echomail, the shared public forums, while about 200,000 used the private netmail system. At its peak, FidoNet listed approximately 39,000 systems.

Throughout its lifetime, FidoNet was beset with management problems and infighting. Much of this can be traced to the fact that the inter-net delivery cost real money, and the traffic grew more rapidly than decreases caused by improving modem speeds and downward trending long distance rates. As they increased, various methods of recouping the costs were attempted, all of which caused friction in the groups. The problems were so bad that Jennings came to refer to the system as the "fight-o-net".

As modems reached speeds of 28.8 kbit/s, the overhead of the TCP/IP protocols were no longer so egregious and dial-up Internet became increasingly common. By 1995 the bulletin board market was reeling as users abandoned local BBS systems in favour of larger sites and web pages, which could be accessed worldwide for the same cost as accessing a local BBS system. This also made FidoNet less expensive to implement, because inter-net transfers could be delivered over the Internet as well, at little or no marginal cost. But this seriously diluted the entire purpose of the store-and-forward model, which had been built up specifically to address a long-distance problem that no longer existed.

The FidoNet nodelist started shrinking, especially in areas with widespread availability of internet connections. This downward trend continues, but has levelled out at approximately 2,500 nodes. FidoNet remains popular in areas where Internet access is difficult to come by, or expensive.

There is now (~2014) a retro movement which is resulting in a slow increase in internet connected BBS and nodes. Telnet, Rlogin, and SSH are being used between systems. This means you can telnet to many BBS worldwide as cheaply as ones next door. Also Usenet and internet mail has been added, along with long file names to many newer versions of BBS software, some being free-ware, resulting in increasing use. Nodelists are no longer declining in all cases.

FidoNet is governed in a hierarchical structure according to FidoNet policy, with designated coordinators at each level to manage the administration of FidoNet nodes and resolve disputes between members. Network coordinators are responsible for managing the individual nodes within their area, usually a city or similar sized area. Regional coordinators are responsible for managing the administration of the network coordinators within their region, typically the size of a state, or small country. Zone coordinators are responsible for managing the administration of all of the regions within their zone. The world is divided into six zones, the coordinators of which elect one of themselves to be the "International Coordinator" of FidoNet.

FidoNet was historically designed to use modem-based dial-up (POTS) access between bulletin board systems, and much of its policy and structure reflected this.

The FidoNet system officially referred only to transfer of "Netmail"—the individual private messages between people using bulletin boards—including the protocols and standards with which to support it. A netmail message would contain the name of the person sending, the name of the intended recipient, and the respective FidoNet addresses of each. The FidoNet system was responsible for routing the message from one system to the other (details below), with the bulletin board software on each end being responsible for ensuring that only the intended recipient could read it. Due to the hobbyist nature of the network, any privacy between sender and recipient was only the result of politeness from the owners of the FidoNet systems involved in the mail's transfer. It was common, however, for system operators to reserve the right to review the content of mail that passed through their system.

Netmail allowed for the "attachment" of a single file to every message. This led to a series of "piggyback" protocols that built additional features onto FidoNet by passing information back and forth as file attachments. These included the automated distribution of files, and transmission of data for inter-BBS games.

By far the most commonly used of these piggyback protocols was "Echomail", public discussions similar to Usenet newsgroups in nature. Echomail was supported by a variety of software that collected up new messages from the local BBSes' public forums (the "scanner"), compressed it using ARC or ZIP, attached the resulting archive to a Netmail message, and sent that message to a selected system. On receiving such a message, identified because it was addressed to a particular "user", the reverse process was used to extract the messages, and a "tosser" put them back into the new system's forums.

Echomail was so popular that for many users, Echomail "was" the FidoNet. Private person-to-person Netmail was relatively rare.

FidoNet is politically organized into a tree structure, with different parts of the tree electing their respective coordinators. The FidoNet hierarchy consists of "zones", "regions", "networks", "nodes" and "points" broken down more-or-less geographically.

The highest level is the zone, which is largely continent-based:

Each zone is broken down into regions, which are broken down into nets, which consist of individual nodes. Zones 7-4095 are used for "othernets"; groupings of nodes which use Fido-compatible software to carry their own independent message areas without being in any way controlled by FidoNet's political structure. Using un-used zone numbers would ensure that each network would have a unique set of addresses, avoiding potential routing conflicts and ambiguities for systems that belonged to more than one network.

FidoNet addresses explicitly consist of a "zone" number, a "network" number (or region number), and a "node" number. They are written in the form Zone:Network/Node. The FidoNet structure also allows for semantic designation of region, host, and hub status for particular nodes, but this status is not directly indicated by the main address.

For example, consider a node located in Tulsa, Oklahoma, United States with an assigned node number is 918, located in Zone 1 (North America), Region 19, and Network 170. The full FidoNet address for this system would be 1:170/918. The "region" was used for administrative purposes, and was only part of the address if the node was listed directly underneath the Regional Coordinator, rather than one of the networks that were used to divide the region further.

FidoNet policy requires that each FidoNet system maintain a "nodelist" of every other member system. Information on each node includes the name of the system or BBS, the name of the node operator, the geographic location, the telephone number, and software capabilities. The nodelist is updated weekly, to avoid unwanted calls to nodes that had shut down, with their phone numbers possibly having been reassigned for voice use by the respective telephone company.

To accomplish regular updates, coordinators of each network maintain the list of systems in their local areas. The lists are forwarded back to the International Coordinator via automated systems on a regular basis. The International Coordinator would then compile a new nodelist, and generate the list of changes (nodediff) to be distributed for node operators to apply to their existing nodelist.

In a theoretical situation, a node would normally forward messages to a "hub". The hub, acting as a distribution point for mail, might then send the message to the Net Coordinator. From there it may be sent through a Regional Coordinator, or to some other system specifically set up for the function. Mail to other zones might be sent through a Zone Gate.

For example, a FidoNet message might follow the path:

Originally there was no specific relationship between network numbers and the regions they reside in. In some areas of FidoNet, most notably in Zone 2, the relationship between region number and network number are entwined. For example, 2:201/329 is in Net 201 which is in Region 20 while 2:2410/330 is in Net 2410 which is in Region 24. Zone 2 also relates the node number to the hub number if the network is large enough to contain any hubs. This effect may be seen in the nodelist by looking at the structure of Net 2410 where node 2:2410/330 is listed under Hub 300. This is not the case in other zones.

In Zone 1, things are much different. Zone 1 was the starting point and when Zones and Regions were formed, the existing nets were divided up regionally with no set formula. The only consideration taken was where they were located geographically in respect to the region's mapped outline. As net numbers got added, the following formula was used.
Region number × 20

Then when some regions started running out of network numbers, the following was also used.

Region number × 200

Region 19, for instance, contains nets 380-399 and 3800-3999 in addition to those that were in Region 19 when it was formed.

Part of the objective behind the formation of local nets was to implement cost reduction plans by which all messages would be sent to one or more hubs or hosts in compressed form (ARC was nominally standard, but PKZIP is universally supported); one toll call could then be made during off-peak hours to exchange entire message-filled archives with an out-of-town uplink for further redistribution.

In practice, the FidoNet structure allows for any node to connect directly to any other, and node operators would sometimes form their own toll-calling arrangements on an ad-hoc basis, allowing for a balance between collective cost saving and timely delivery. For instance, if one node operator in a network offered to make regular toll calls to a particular system elsewhere, other operators might arrange to forward all of their mail destined for the remote system, and those near it, to the local volunteer. Operators within individual networks would sometimes have cost-sharing arrangements, but it was also common for people to volunteer to pay for regular toll calls either out of generosity, or to build their status in the community.

This ad-hoc system was particularly popular with networks that were built on top of FidoNet. Echomail, for instance, often involved relatively large file transfers due to its popularity. If official FidoNet distributors refused to transfer Echomail due to additional toll charges, other node operators would sometimes volunteer. In such cases, Echomail messages would be routed to the volunteers' systems instead.

The FidoNet system was best adapted to an environment in which local telephone service was inexpensive and long-distance calls (or intercity data transfer via packet-switched networks) costly. Therefore, it fared somewhat poorly in Japan, where even local lines are expensive, or in France, where tolls on local calls and competition with Minitel or other data networks limited its growth.

As the number of messages in Echomail grew over time, it became very difficult for users to keep up with the volume while logged into their local BBS. "Points" were introduced to address this, allowing technically savvy users to receive the already compressed and batched Echomail (and Netmail) and read it locally on their own machines.

To do this, the FidoNet addressing scheme was extended with the addition of a final address segment, the point number. For instance, a user on the example system above might be given point number 10, and thus could be sent mail at the address 1:170/918.10.

In real-world use, points are fairly difficult to set up. The FidoNet software typically consisted of a number of small utility programs run by manually edited scripts that required some level of technical ability. Reading and editing the mail required either a "sysop editor" program, or a BBS program to be run locally.

In North America (Zone 1), where local calls are generally free, the benefits of the system were offset by its complexity. Points were used only briefly, and even then only to a limited degree. Dedicated offline mail reader programs such as Blue Wave, Squiggy and Silver Xpress (OPX) were introduced in the mid-1990s, and quickly rendered the point system obsolete. Many of these packages supported the QWK offline mail standard.

In other parts of the world, especially Europe, this was different. In Europe, even local calls are generally metered, so there was a strong incentive to keep the duration of the calls as short as possible. Point software employs standard compression (ZIP, ARJ, etc.) and so keeps the calls down to a few minutes a day at most. In contrast to North America, pointing saw rapid and fairly widespread uptake in Europe.

Many regions distribute a pointlist in parallel with the nodelist. The pointlist segments are maintained by Net- and Region Pointlist Keepers and the Zone Point List Keeper assembles them into the Zone pointlist. At the peak of FidoNet there were over 120,000 points listed in the Zone 2 pointlist. Listing points is on a voluntary basis and not every point is listed, so how many points there really were is anybody's guess. As of June 2006, there are still some 50,000 listed points. Most of them are in Russia and Ukraine.

FidoNet contained several technical specifications for compatibility between systems. The most basic of all is "FTS-0001", with which all FidoNet systems are required to comply as a minimal requirement. FTS-0001 defined:

Other specifications that were commonly used provided for "echomail", different transfer protocols and handshake methods ("e.g.: Yoohoo/Yoohoo2u2, EMSI"), file compression, nodelist format, transfer over reliable connections such as the Internet (Binkp), and other aspects.

Since computer bulletin boards historically used the same telephone lines for transferring mail as were used for dial-in human users of the BBS, FidoNet policy dictates that at least one designated line of each FidoNet node must be available for accepting mail from other FidoNet nodes during a particular hour of each day.

"Zone Mail Hour", as it was named, varies depending on the geographic location of the node, and was designated to occur during the early morning. The exact hour varies depending on the time zone, and any node with only one telephone line is required to reject human callers. In practice, particularly in later times, most FidoNet systems tend to accept mail at any time of day when the phone line is not busy, usually during night.

Most FidoNet deployments were designed in a modular fashion. A typical deployment would involve several applications that would communicate through shared files and directories, and switch between each other through carefully designed scripts or batch files. However, monolithic software that encompassed all required functions in one package is available, such as D'Bridge. Such software eliminated the need for custom batch files and is tightly integrated in operation. The preference of deployment was that of the operator and there were both pros and cons of running in either fashion.

Arguably the most important piece of software on a DOS-based Fido system was the "FOSSIL driver", which was a small device driver which provided a standard way for the Fido software to talk to the modem. This driver needed to be loaded before any Fido software would work. An efficient FOSSIL driver meant faster, more reliable connections.

"Mailer software" was responsible for transferring files and messages between systems, as well as passing control to other applications, such as the BBS software, at appropriate times. The mailer would initially answer the phone and, if necessary, deal with incoming mail via FidoNet transfer protocols. If the mailer answered the phone and a human caller was detected rather than other mailer software, the mailer would exit, and pass control to the BBS software, which would then initialise for interaction with the user. When outgoing mail was waiting on the local system, the mailer software would attempt to send it from time to time by dialing and connecting to other systems who would accept and route the mail further. Due to the costs of toll calls which often varied between peak and off-peak times, mailer software would usually allow its operator to configure the optimal times in which to attempt to send mail to other systems.

"BBS software" was used to interact with human callers to the system. BBS software would allow dial-in users to use the system's message bases and write mail to others, locally or on other BBSes. Mail directed to other BBSes would later be routed and sent by the mailer, usually after the user had finished using the system. Many BBSes also allowed users to exchange files, play games, and interact with other users in a variety of ways (i.e.: node to node chat).

A "scanner/tosser" application, such as FastEcho, FMail, TosScan and Squish, would normally be invoked when a BBS user had entered a new FidoNet message that needed to be sent, or when a mailer had received new mail to be imported into the local messages bases. This application would be responsible for handling the packaging of incoming and outgoing mail, moving it between the local system's message bases and the mailer's inbound and outbound directories. The scanner/tosser application would generally be responsible for basic routing information, determining which systems to forward mail to.

In later times, "message readers" or "editors" that were independent of BBS software were also developed. Often the System Operator of a particular BBS would use a devoted message reader, rather than the BBS software itself, to read and write FidoNet and related messages. One of the most popular editors in 2008 was GoldED+. In some cases FidoNet nodes, or more often FidoNet points, had no public bulletin board attached, and existed only for the transfer of mail for the benefit of the node's operator. Most nodes in 2009 had no BBS access, but only points, if anything.

The original "Fido BBS" software, and some other FidoNet-supporting software from the 1980s, is no longer functional on modern systems. This is for several reasons, including problems related to the Y2K bug. In some cases, the original authors have left the BBS or shareware community, and the software, much of which was closed source, has been rendered abandonware.

Several DOS based legacy FidoNet Mailers such as FrontDoor, Intermail, MainDoor and D'Bridge from the early 1990s can still be run today under Windows without a modem, by using the freeware NetFoss Telnet FOSSIL driver, and by using a Virtual Modem such as NetSerial. This allows the mailer to "dial" an IP address or hostname via Telnet, rather than dialing a real POTS phone number. There are similar solutions for Linux such as MODEMU (modem emulator) which has limited success when combined with DOSEMU (DOS emulator).
Mail Tossers such as FastEcho and FMail are still used today under both Windows and Linux/DOSEMU.
There are several modern Windows based FidoNet Mailers available today with source code, including Argus, Radius, and Taurus. MainDoor is another Windows based Fidonet mailer, which also can be run using either a modem or directly over TCP/IP. Two popular free and open source software FidoNet mailers for Unix-like systems are the binkd (cross-platform, IP-only, uses the binkp protocol) and qico (supports modem communication as well as the IP protocol of ifcico and binkp).

On the "hardware" side, Fido systems were usually well-equipped machines, for their day, with quick CPUs, high-speed modems and 16550 UARTs, which were at the time an upgrade. As a Fidonet system was usually a BBS, it needed to quickly process any new mail events before returning to its 'waiting for call' state. In addition, the BBS itself usually necessitated lots of storage space. Finally, a FidoNet system usually had at least one dedicated phoneline. Consequently, operating a Fidonet system often required significant financial investment, a cost usually met by the owner of the system.

While the use of FidoNet has dropped dramatically compared with its use up to the mid-1990s, it is still used in many countries and especially Russia and former republics of the USSR. Some BBSes, including those that are now available for users with Internet connections via telnet, also retain their FidoNet netmail and echomail feeds.

Some of FidoNet's echomail conferences are available via gateways with the Usenet news hierarchy using software like UFGate. There are also mail gates for exchanging messages between Internet and FidoNet. Widespread net abuse and e-mail spam on the Internet side has caused some gateways (such as the former 1:1/31 IEEE fidonet.org gateway) to become unusable or cease operation entirely.

"FidoNews" is the newsletter of the FidoNet community. Affectionately nicknamed "The Snooze", it is published weekly. It was first published in 1984. Throughout its history, it has been published by various people and entities, including the short-lived International FidoNet Association.




</doc>
<doc id="11444" url="https://en.wikipedia.org/wiki?curid=11444" title="Falsification">
Falsification

Falsification may refer to:


</doc>
<doc id="11445" url="https://en.wikipedia.org/wiki?curid=11445" title="Fatherland">
Fatherland

Fatherland is the nation of one's "fathers", "forefathers" or "ancestors". It can be viewed as a nationalist concept, in so far as it is evocative of emotions related to family ties and links them to national identity and patriotism, but in the English language it can also simply mean the country of one's birth or origin. It can be compared to motherland and homeland, and some languages will use more than one of these terms. The national anthem of the Netherlands between 1815 and 1932, "Wien Neêrlands Bloed", makes extensive use of the parallel Dutch word, as does the current Dutch national anthem, Het Wilhelmus.

The Ancient Greek "patris", fatherland, led to "patrios", "of our fathers" and thence to the Latin "patriota" and Old French "patriote", meaning compatriot; from these the English word patriotism is derived. The related Ancient Roman word "Patria" led to similar forms in modern Romance languages.

"Fatherland" was first encountered by the vast majority of citizens in countries that did not themselves use it during World War II, when it was featured in news reports associated with Nazi Germany. German government propaganda used its appeal to nationalism when making references to Germany and the state. It was used in "Mein Kampf", and on a sign in a German concentration camp, also signed, Adolf Hitler. As such, the word "Vaterland" could be connected with National Socialism outside Germany; in Germany, this is not the case.

Groups with languages that refer to their native country as a "fatherland" include:






</doc>
<doc id="11447" url="https://en.wikipedia.org/wiki?curid=11447" title="Flag of the United States">
Flag of the United States

The flag of the United States of America, often referred to as the American flag or U.S. flag, is the national flag of the United States. It consists of thirteen equal horizontal stripes of red (top and bottom) alternating with white, with a blue rectangle in the canton (referred to specifically as the "union") bearing fifty small, white, five-pointed stars arranged in nine offset horizontal rows, where rows of six stars (top and bottom) alternate with rows of five stars. The 50 stars on the flag represent the 50 states of the United States of America, and the 13 stripes represent the thirteen British colonies that declared independence from the Kingdom of Great Britain, and became the first states in the U.S. Nicknames for the flag include the Stars and Stripes, Old Glory, and the Star-Spangled Banner.

The current design of the U.S. flag is its 27th; the design of the flag has been modified officially 26 times since 1777. The 48-star flag was in effect for 47 years until the 49-star version became official on July 4, 1959. The 50-star flag was ordered by the then president Eisenhower on August 21, 1959, and was adopted in July 1960. It is the longest-used version of the U.S. flag and has been in use for over years.

At the time of the Declaration of Independence in July 1776, the Continental Congress would not legally adopt flags with "stars, white in a blue field" for another year. The flag contemporaneously known as "the Continental Colors" has historically been referred to as the first national flag.

The Continental Navy raised the Colors as the ensign of the fledgling nation in the American War for Independence—likely with the expedient of transforming their previous British red ensigns by adding white stripes—and would use this flag until 1777, when it would form the basis for the subsequent "de jure" designs.

The name "Grand Union" was first applied to the Continental Colors by George Preble in his 1872 history of the U.S. flag.

The flag closely resembles the British East India Company flag of the era, and Sir Charles Fawcett argued in 1937 that the company flag inspired the design. Both flags could have been easily constructed by adding white stripes to a British Red Ensign, one of the three maritime flags used throughout the British Empire at the time. However, an East India Company flag could have from nine to 13 stripes, and was not allowed to be flown outside the Indian Ocean. Benjamin Franklin once gave a speech endorsing the adoption of the Company's flag by the United States as their national flag. He said to George Washington, "While the field of your flag must be new in the details of its design, it need not be entirely new in its elements. There is already in use a flag, I refer to the flag of the East India Company." This was a way of symbolising American loyalty to the Crown as well as the United States' aspirations to be self-governing, as was the East India Company. Some colonists also felt that the Company could be a powerful ally in the American War of Independence, as they shared similar aims and grievances against the British government tax policies. Colonists therefore flew the Company's flag, to endorse the Company.

However, the theory that the Grand Union Flag was a direct descendant of the flag of the East India Company has been criticised as lacking written evidence. On the other hand, the resemblance is obvious, and a number of the Founding Fathers of the United States were aware of the East India Company's activities and of their free administration of India under Company rule. In any case, both the stripes (barry) and the stars (mullets) have precedents in classical heraldry. Mullets were comparatively rare in early modern heraldry, but an example of mullets representing territorial divisions predating the U.S. flag are those in the coat of arms of Valais of 1618, where seven mullets stood for seven districts.

On June 14, 1777, the Second Continental Congress passed the Flag Resolution which stated: ""Resolved", That the flag of the thirteen United States be thirteen stripes, alternate red and white; that the union be thirteen stars, white in a blue field, representing a new constellation." Flag Day is now observed on June 14 of each year. While scholars still argue about this, tradition holds that the new flag was first hoisted in June 1777 by the Continental Army at the Middlebrook encampment.

The first official U.S. flag flown during battle was on August 3, 1777, at Fort Schuyler (Fort Stanwix) during the Siege of Fort Stanwix. Massachusetts reinforcements brought news of the adoption by Congress of the official flag to Fort Schuyler. Soldiers cut up their shirts to make the white stripes; scarlet material to form the red was secured from red flannel petticoats of officers' wives, while material for the blue union was secured from Capt. Abraham Swartwout's blue cloth coat. A voucher is extant that Capt. Swartwout of Dutchess County was paid by Congress for his coat for the flag.

The 1777 resolution was most probably meant to define a naval ensign. In the late 18th century, the notion of a national flag did not yet exist, or was only nascent. The flag resolution appears between other resolutions from the Marine Committee. On May 10, 1779, Secretary of the Board of War Richard Peters expressed concern "it is not yet settled what is the Standard of the United States." However, the term, "Standard," referred to a national standard for the Army of the United States. Each regiment was to carry the national standard in addition to its regimental standard. The national standard was not a reference to the national or naval flag.

The Flag Resolution did not specify any particular arrangement, number of points, nor orientation for the stars and the arrangement or whether the flag had to have seven red stripes and six white ones or vice versa. The appearance was up to the maker of the flag. Some flag makers arranged the stars into one big star, in a circle or in rows and some replaced a state's star with its initial. One arrangement features 13 five-pointed stars arranged in a circle, with the stars arranged pointing outwards from the circle (as opposed to up), the so-called Betsy Ross flag. This flag, however, is more likely a flag used for celebrations of anniversaries of the nation's birthday. Experts have dated the earliest known example of this flag to be 1792 in a painting by John Trumbull.

Despite the 1777 resolution, the early years of American independence featured many different flags. Most were individually crafted rather than mass-produced. While there are many examples of 13-star arrangements, some of those flags included blue stripes as well as red and white. Benjamin Franklin and John Adams, in a letter dated October 3, 1778, to Ferdinand I of the Two Sicilies, described the American flag as consisting of "13 stripes, alternately red, white, and blue, a small square in the upper angle, next the flag staff, is a blue field, with 13 white stars, denoting a new Constellation." John Paul Jones used a variety of 13-star flags on his U.S. Navy ships including the well-documented 1779 flags of the Serapis and the Alliance. The Serapis flag had three rows of eight-pointed stars with stripes that were red, white, and blue. The flag for the "Alliance", however, had five rows of eight-pointed stars with 13 red and white stripes, and the white stripes were on the outer edges. Both flags were documented by the Dutch government in October 1779, making them two of the earliest known flags of 13 stars.

Francis Hopkinson of New Jersey, a naval flag designer, and a signer of the Declaration of Independence, designed the 1777 flag while he was the Chairman of the Continental Navy Board's Middle Department, sometime between his appointment to that position in November 1776 and the time that the flag resolution was adopted in June 1777. The Navy Board was under the Continental Marine Committee. Not only did Hopkinson claim that he designed the U.S. flag, but he also claimed that he designed a flag for the U.S. Navy. Hopkinson was the only person to have made such a claim during his own lifetime, when he sent a letter and several bills to Congress for his work. These claims are documented in the Journals of the Continental Congress and George Hasting's biography of Hopkinson. Hopkinson initially wrote a letter to Congress, via the Continental Board of Admiralty, on May 25, 1780. In this letter, he asked for a "Quarter Cask of the Public Wine" as payment for designing the U.S. flag, the seal for the Admiralty Board, the seal for the Treasury Board, Continental currency, the Great Seal of the United States, and other devices. However, in three subsequent bills to Congress, Hopkinson asked to be paid in cash, but he did not list his U.S. flag design. Instead, he asked to be paid for designing the "great Naval Flag of the United States" in the first bill; the "Naval Flag of the United States" in the second bill; and "the Naval Flag of the States" in the third, along with the other items. The flag references were generic terms for the naval ensign that Hopkinson had designed, that is, a flag of seven red stripes and six white ones. The predominance of red stripes made the naval flag more visible against the sky on a ship at sea. By contrast, Hopkinson's flag for the United States had seven white stripes, and six red ones – in reality, six red stripes laid on a white background. Hopkinson's sketches have not been found, but we can make these conclusions because Hopkinson incorporated different stripe arrangements in the Admiralty (naval) Seal that he designed in the Spring of 1780 and the Great Seal of the United States that he proposed at the same time. His Admiralty Seal had seven red stripes; whereas, his second U.S. Seal proposal had seven white ones. Hopkinson's flag for the Navy is the one that the Nation preferred as the national flag. Remnants of Hopkinson's U.S. flag of seven white stripes can be found in the Great Seal of the United States and the President's seal. When Hopkinson was chairman of the Navy Board, his position was like that of today's Secretary of the Navy. The payment was not made, however, because it was determined he had already received a salary as a member of Congress. This contradicts the legend of the Betsy Ross flag, which suggests that she sewed the first Stars and Stripes flag by request of the government in the Spring of 1776. Furthermore, a letter from the War Board to George Washington on May 10, 1779, documents that there was still no design established for a national flag for the Army's use in battle.

The origin of the stars and stripes design has been muddled by a story disseminated by the descendants of Betsy Ross. The apocryphal story credits Betsy Ross for sewing the first flag from a pencil sketch handed to her by George Washington. No evidence for this exists either in the diaries of George Washington nor in the records of the Continental Congress. Indeed, nearly a century passed before Ross' grandson, William Canby, first publicly suggested the story in 1870. By her family's own admission, Ross ran an upholstery business, and she had never made a flag as of the supposed visit in June 1776. Furthermore, her grandson admitted that his own search through the Journals of Congress and other official records failed to find corroboration of his grandmother's story.

The family of Rebecca Young claimed that she sewed the first flag. Young's daughter was Mary Pickersgill, who made the Star Spangled Banner Flag. She was assisted by Grace Wisher, an African American girl at just 13 years old. According to rumor, the Washington family coat of arms, shown in a 15th-century window of Selby Abbey, was the origin of the stars and stripes.

In 1795, the number of stars and stripes was increased from 13 to 15 (to reflect the entry of Vermont and Kentucky as states of the Union). For a time the flag was not changed when subsequent states were admitted, probably because it was thought that this would cause too much clutter. It was the 15-star, 15-stripe flag that inspired Francis Scott Key to write "Defence of Fort M'Henry", later known as "The Star Spangled Banner", which is now the American national anthem. The flag is currently on display in the exhibition, "The Star-Spangled Banner: The Flag That Inspired the National Anthem" at the Smithsonian Institution National Museum of American History in a two-story display chamber that protects the flag while it is on view.

On April 4, 1818, a plan was passed by Congress at the suggestion of U.S. Naval Captain Samuel C. Reid in which the flag was changed to have 20 stars, with a new star to be added when each new state was admitted, but the number of stripes would be reduced to 13 so as to honor the original colonies. The act specified that new flag designs should become official on the first July 4 (Independence Day) following admission of one or more new states. The most recent change, from 49 stars to 50, occurred in 1960 when the present design was chosen, after Hawaii gained statehood in August 1959. Before that, the admission of Alaska in January 1959 prompted the debut of a short-lived 49-star flag.

Prior to the adoption of the 48-star flag in 1912, there was no official arrangement of the stars in the canton, although the U.S. Army and U.S. Navy used standardized designs. Throughout the 19th century there was an abundance of different star patterns, rectangular and circular.

On July 4, 2007, the 50-star flag became the version of the flag in longest use, surpassing the 48-star flag that was used from 1912 to 1959.

The U.S. flag was brought to the city of Canton (Guǎngzhōu) in China in 1784 by the merchant ship "Empress of China", which carried a cargo of ginseng. There it gained the designation "Flower Flag" (). According to a pseudonymous account first published in the "Boston Courier" and later retold by author and U.S. naval officer George H. Preble:

In the above quote, the Chinese words are written phonetically based on spoken Cantonese. The names given were common usage in the nineteenth and early twentieth centuries. Vietnam has borrowed the term for the United States, as or ("Flower Flag") in Vietnamese language.

Chinese now refer to the United States as . "Měi" is short for "Měilìjiān" (, phono-semantic matching of "American") and "guó" means "country", so this name is unrelated to the flag. However, the "flower flag" terminology persists in some places today: for example, American Ginseng is called "flower flag ginseng" () in Chinese, and Citibank, which opened a branch in China in 1902, is known as "Flower Flag Bank" ().

Additionally, the seal of the Municipal Council of Shanghai International Settlement included the U.S. flag as part of top left hand shield near the flags of the United Kingdom to symbolize the foreign concessions in the Chinese city of Shanghai.

The U.S. flag took its first trip around the world in 1787–90 on board the "Columbia". William Driver, who coined the phrase "Old Glory", took the U.S. flag around the world in 1831–32. The flag attracted the notice of Japanese when an oversized version was carried to Yokohama by the steamer "Great Republic" as part of a round-the-world journey in 1871.

In the following table depicting the 28 various designs of the United States flag, the star patterns for the flags are merely the "usual" patterns, often associated with the United States Navy. Canton designs, prior to the proclamation of the 48-star flag, had no official arrangement of the stars. Furthermore, the exact "colors" of the flag were not standardized until 1934.

If a new U.S. state were to be admitted, it would require a new design on the flag to accommodate the additional star.

In the November 2012 U.S. election, Puerto Rico voted to become a U.S. state. However, the legitimacy of the result of this election was disputed. On June 11, 2017, another referendum was held, this time with the result that 97% of voters in Puerto Rico voted for statehood, but it had a turnout of only 23%. Similarly in November 2016, a statehood referendum was held in the District of Columbia where 86% of voters approved the proposal. There have also been repeated calls for some states, most notably California, to split into two or more separate states.

The flag of the United States is one of the nation's most widely recognized symbols. Within the United States, flags are frequently displayed not only on public buildings but on private residences. The flag is a common motif on decals for car windows, and on clothing ornamentation such as badges and lapel pins. Throughout the world the flag has been used in public discourse to refer to the United States.

The flag has become a powerful symbol of Americanism, and is flown on many occasions, with giant outdoor flags used by retail outlets to draw customers. Reverence for the flag has at times reached religion-like fervor: in 1919 William Norman Guthrie's book "The Religion of Old Glory" discussed "the cult of the flag"
and formally proposed .

Despite a number of attempts to ban the practice, desecration of the flag remains protected as free speech. Scholars have noted the irony that "<nowiki>[t]</nowiki>he flag is so revered because it represents the land of the free, and that freedom includes the ability to use or abuse that flag in protest". Comparing practice worldwide, Testi noted in 2010 that the United States was not unique in adoring its banner, for the flags of Scandinavian countries are also "beloved, domesticated, commercialized and sacralized objects".

This nationalist attitude around the flag is a shift from earlier sentiments; the US flag was largely a "military ensign or a convenient marking of American territory" that rarely appeared outside of forts, embassies, and the like until the opening of the American Civil War in April 1861, when Major Robert Anderson was forced to surrender Fort Sumter in Charleston Harbor to Confederates. Anderson was celebrated in the North as a hero and U.S. citizens throughout Northern states co-opted the national flag to symbolize U.S. nationalism and rejection of secessionism:

The basic design of the current flag is specified by ; outlines the addition of new stars to represent new states. The gives the following values:

These specifications are contained in an executive order which, strictly speaking, governs only flags made for or by the U.S. federal government. In practice, most U.S. national flags available for sale to the public have a different width-to-height ratio; common sizes are or (flag ratio 1.5), or (1.6), or or (1.667). Even flags flown over the U.S. Capitol for sale to the public through Representatives or Senators are provided in these sizes. Flags that are made to the prescribed 1.9 ratio are often referred to as "G-spec" (for "government specification") flags.

The exact red, white, and blue colors to be used in the flag are specified with reference to the CAUS Standard Color Reference of America, 10th edition. Specifically, the colors are "White", "Old Glory Red", and "Old Glory Blue". The CIE coordinates for the colors of the 9th edition of the Standard Color Card were formally specified in "JOSA" in 1946. These colors form the standard for cloth, and there is no perfect way to convert them to RGB for display on screen or CMYK for printing. The "relative" coordinates in the following table were found by scaling the luminous reflectance relative to the flag's "white".

As with the design, the official colors are only officially required for flags produced for the U.S. federal government, and other colors are often used for mass-market flags, printed reproductions, and other products intended to evoke flag colors. The practice of using more saturated colors than the official cloth is not new. As Taylor, Knoche, and Granville wrote in 1950: "The color of the official wool bunting [of the blue field] is a very dark blue, but printed reproductions of the flag, as well as merchandise supposed to match the flag, present the color as a deep blue much brighter than the official wool."

Sometimes, Pantone Matching System (PMS) approximations to the flag colors are used. One set was given on the website of the U.S. embassy in London as early as 1998; the website of the U.S. embassy in Stockholm claimed in 2001 that those had been suggested by Pantone, and that the U.S. Government Printing Office preferred a different set. A third red was suggested by a California Military Department document in 2002. In 2001, the Texas legislature specified that the colors of the Texas flag should be "(1) the same colors used in the United States flag; and (2) defined as numbers 193 (red) and 281 (dark blue) of the Pantone Matching System."

When Alaska and Hawaii were being considered for statehood in the 1950s, more than 1,500 designs were submitted to President Dwight D. Eisenhower. Although some of them were 49-star versions, the vast majority were 50-star proposals. At least three of these designs were identical to the present design of the 50-star flag. At the time, credit was given by the executive department to the United States Army Institute of Heraldry for the design.

Of these proposals, one created by 17-year-old Robert G. Heft in 1958 as a school project received the most publicity. His mother was a seamstress, but refused to do any of the work for him. He originally received a B– for the project. After discussing the grade with his teacher, it was agreed (somewhat jokingly) that if the flag was accepted by Congress, the grade would be reconsidered. Heft's flag design was chosen and adopted by presidential proclamation after Alaska and before Hawaii was admitted into the Union in 1959. According to Heft, his teacher did keep to their agreement and changed his grade to an A for the project. The 49- and 50-star flags were each flown for the first time at Fort McHenry on Independence Day, in 1959 and 1960 respectively.

Traditionally, the flag may be decorated with golden fringe surrounding the perimeter of the flag as long as it does not deface the flag proper. Ceremonial displays of the flag, such as those in parades or on indoor posts, often use fringe to enhance the appearance of the flag.

The first recorded use of fringe on a flag dates from 1835, and the Army used it officially in 1895. No specific law governs the legality of fringe, but a 1925 opinion of the attorney general addresses the use of fringe (and the number of stars) "... is at the discretion of the Commander in Chief of the Army and Navy ..." as quoted from footnote in previous volumes of Title 4 of the United States Code law books and is a source for claims that such a flag is a military ensign not civilian. However, according to the Army Institute of Heraldry, which has official custody of the flag designs and makes any change ordered, there are no implications of symbolism in the use of fringe. Several federal courts have upheld this conclusion, most recently and forcefully in "Colorado v. Drew", a Colorado Court of Appeals judgment that was released in May 2010. Traditionally, the Army and Air Force use a fringed National Color for parade, color guard and indoor display, while the Sea Services (Navy, Marine Corps and Coast Guard) use a fringeless National Color for all occasions.

The flag is customarily flown year-round at most public buildings, and it is not unusual to find private houses flying full-size () flags. Some private use is year-round, but becomes widespread on civic holidays like Memorial Day, Veterans Day, Presidents' Day, Flag Day, and on Independence Day. On Memorial Day it is common to place small flags by war memorials and next to the graves of U.S. war veterans. Also on Memorial Day it is common to fly the flag at half staff, until noon, in remembrance of those who lost their lives fighting in U.S. wars.

The United States Flag Code outlines certain guidelines for the use, display, and disposal of the flag. For example, the flag should never be dipped to any person or thing, unless it is the ensign responding to a salute from a ship of a foreign nation. This tradition may come from the 1908 Summer Olympics in London, where countries were asked to dip their flag to King Edward VII: the American flag bearer did not. Team captain Martin Sheridan is famously quoted as saying "this flag dips to no earthly king", though the true provenance of this quotation is unclear.
The flag should never be allowed to touch the ground and, if flown at night, must be illuminated. If the edges become tattered through wear, the flag should be repaired or replaced. When a flag is so tattered that it can no longer serve as a symbol of the United States, it should be destroyed in a dignified manner, preferably by burning. The American Legion and other organizations regularly conduct flag retirement ceremonies, often on Flag Day, June 14. (The Boy Scouts of America recommends that modern nylon or polyester flags be recycled instead of burned, due to hazardous gases being produced when such materials are burned.) 

The Flag Code prohibits using the flag "for any advertising purpose" and also states that the flag "should not be embroidered, printed, or otherwise impressed on such articles as cushions, handkerchiefs, napkins, boxes, or anything intended to be discarded after temporary use". Both of these codes are generally ignored, almost always without comment.

Section 8, entitled Respect For Flag states in part: "The flag should never be used as wearing apparel, bedding, or drapery", and "No part of the flag should ever be used as a costume or athletic uniform". Section 3 of the Flag Code defines "the flag" as anything "by which the average person seeing the same without deliberation may believe the same to represent the flag of the United States of America".

An additional part of Section 8 Respect For Flag, that is frequently violated at sporting events is part (c) "The flag should never be carried flat or horizontally, but always aloft and free."

Although the Flag Code is U.S. federal law, there is no penalty for a private citizen or group failing to comply with the Flag Code and it is not widely enforced—indeed, punitive enforcement would conflict with the First Amendment right to freedom of speech. Passage of the proposed Flag Desecration Amendment would overrule legal precedent that has been established.

When the flag is affixed to the right side of a vehicle of any kind (e.g.: cars, boats, planes, any physical object that moves), it should be oriented so that the canton is towards the front of the vehicle, as if the flag were streaming backwards from its hoist as the vehicle moves forward. Therefore, U.S. flag decals on the right sides of vehicles may appear to be reversed, with the union to the observer's right instead of left as more commonly seen.

The flag has been displayed on every U.S. spacecraft designed for manned flight, including Mercury, Gemini, Apollo Command/Service Module, Apollo Lunar Module, and the Space Shuttle. The flag also appeared on the S-IC first stage of the Saturn V launch vehicle used for Apollo. But since Mercury, Gemini, and Apollo were launched and landed vertically and were not capable of horizontal atmospheric flight as the Space Shuttle did on its landing approach, the "streaming" convention was not followed and these flags were oriented with the stripes running horizontally, perpendicular to the direction of flight.

On some U.S. military uniforms, flag patches are worn on the right shoulder, following the vehicle convention with the union toward the front. This rule dates back to the Army's early history, when both mounted cavalry and infantry units would designate a standard bearer, who carried the Colors into battle. As he charged, his forward motion caused the flag to stream back. Since the Stars and Stripes are mounted with the canton closest to the pole, that section stayed to the right, while the stripes flew to the left. Several US military uniforms, such as flight suits worn by members of the United States Air Force and Navy, have the flag patch on the left shoulder.

Other organizations that wear flag patches on their uniforms can have the flag facing in either direction. The congressional charter of the Boy Scouts of America stipulates that Boy Scout uniforms should not imitate U.S. military uniforms; consequently, the flags are displayed on the right shoulder with the stripes facing front, the reverse of the military style. Law enforcement officers often wear a small flag patch, either on a shoulder, or above a shirt pocket.

Every U.S. astronaut since the crew of Gemini 4 has worn the flag on the left shoulder of his or her space suit, with the exception of the crew of Apollo 1, whose flags were worn on the right shoulder. In this case, the canton was on the left.

The flag did not appear on U.S. postal stamp issues until the Battle of White Plains Issue was released in 1926, depicting the flag with a circle of 13 stars. The 48-star flag first appeared on the General Casimir Pulaski issue of 1931, though in a . The first U.S. postage stamp to feature the flag as the sole subject was issued July 4, 1957, Scott catalog number 1094. Since that time the flag has frequently appeared on U.S. stamps.

In 1907 Eben Appleton, New York stockbroker and grandson of Lieutenant Colonel George Armistead (the commander of Fort McHenry during the 1814 bombardment) loaned the Star Spangled Banner Flag to the Smithsonian Institution, and in 1912 he converted the loan to a gift. Appleton donated the flag with the wish that it would always be on view to the public. In 1994, the National Museum of American History determined that the Star Spangled Banner Flag required further conservation treatment to remain on public display. In 1998 teams of museum conservators, curators, and other specialists helped move the flag from its home in the Museum's Flag Hall into a new conservation laboratory. Following the reopening of the National Museum of American History on November 21, 2008, the flag is now on display in a special exhibition, "The Star-Spangled Banner: The Flag That Inspired the National Anthem," where it rests at a 10 degree angle in dim light for conservation purposes.

By presidential proclamation, acts of Congress, and custom, U.S. flags are displayed continuously at certain locations.


The flag should especially be displayed at full staff on the following days:

The flag is displayed at half-staff (half-mast in naval usage) as a sign of respect or mourning. Nationwide, this action is proclaimed by the president; statewide or territory-wide, the proclamation is made by the governor. In addition, there is no prohibition against municipal governments, private businesses or citizens flying the flag at half-staff as a local sign of respect and mourning. However, many flag enthusiasts feel this type of practice has somewhat diminished the meaning of the original intent of lowering the flag to honor those who held high positions in federal or state offices. President Dwight D. Eisenhower issued the first proclamation on March 1, 1954, standardizing the dates and time periods for flying the flag at half-staff from all federal buildings, grounds, and naval vessels; other congressional resolutions and presidential proclamations ensued. However, they are only guidelines to all other entities: typically followed at state and local government facilities, and encouraged of private businesses and citizens.

To properly fly the flag at half-staff, one should first briefly hoist it top of the staff, then lower it to the half-staff position, halfway between the top and bottom of the staff. Similarly, when the flag is to be lowered from half-staff, it should be first briefly hoisted to the top of the staff.

Federal statutes provide that the flag should be flown at half-staff on the following dates:

National Korean War Veterans Armistice Day, on July 27, was formerly a day of half-staff observance until the law expired in 2003. In 2009, it became a day of full-staff observance.

Though not part of the official Flag Code, according to military custom, flags should be folded into a triangular shape when not in use. To properly fold the flag:


There is also no specific meaning for each fold of the flag. However, there are scripts read by non-government organizations and also by the Air Force that are used during the flag folding ceremony. These scripts range from historical timelines of the flag to religious themes.

Traditionally, the flag of the United States plays a role in military funerals, and occasionally in funerals of other civil servants (such as law enforcement officers, fire fighters, and U.S. presidents). A burial flag is draped over the deceased's casket as a pall during services. Just prior to the casket being lowered into the ground, the flag is ceremonially folded and presented to the deceased's next of kin as a token of respect.







</doc>
<doc id="11448" url="https://en.wikipedia.org/wiki?curid=11448" title="Federated States of Micronesia">
Federated States of Micronesia

The Federated States of Micronesia (; abbreviated FSM and also known simply as Micronesia) is an independent republic associated with the United States. It consists of four states from west to east, Yap, Chuuk, Pohnpei and Kosraethat are spread across the Western Pacific Ocean. Together, the states comprise around 607 islands (a combined land area of approximately ) that cover a longitudinal distance of almost just north of the equator. They lie northeast of New Guinea, south of Guam and the Marianas, west of Nauru and the Marshall Islands, east of Palau and the Philippines, about north of eastern Australia and some southwest of the main islands of Hawaii.

While the FSM's total land area is quite small, it occupies more than of the Pacific Ocean, giving the country the 14th largest Exclusive Economic Zone in the world. The sovereign island nation's capital is Palikir, located on Pohnpei Island, while the largest city is Weno, located in the Chuuk Atoll.

Each of its four states is centered on one or more main high islands, and all but Kosrae include numerous outlying atolls. The Federated States of Micronesia is spread across part of the Caroline Islands in the wider region of Micronesia, which consists of thousands of small islands divided among several countries. The term "Micronesia" may refer to the Federated States or to the region as a whole.

The FSM was formerly a part of the Trust Territory of the Pacific Islands (TTPI), a United Nations Trust Territory under U.S. administration, but it formed its own constitutional government on May 10, 1979, becoming a sovereign state after independence was attained on November 3, 1986 under a Compact of Free Association with the United States. Other neighboring island entities, and also former members of the TTPI, formulated their own constitutional governments and became the Republic of the Marshall Islands (RMI) and the Republic of Palau (ROP). The FSM has a seat in the United Nations and has been a member of the Pacific Community since 1983.

The ancestors of the Micronesians settled over four thousand years ago. A decentralized chieftain-based system eventually evolved into a more centralized economic and religious culture centered on Yap Island.

Nan Madol, consisting of a series of small artificial islands linked by a network of canals, is often called the Venice of the Pacific. It is located on the eastern periphery of the island of Pohnpei and used to be the ceremonial and political seat of the Saudeleur dynasty that united Pohnpei's estimated 25,000 people from about AD 500 until 1500, when the centralized system collapsed.

European explorers—first the Portuguese in search of the Spice Islands (Indonesia) and then the Spanish—reached the Carolines in the sixteenth century. The Spanish incorporated the archipelago to the Spanish East Indies through the capital, Manila, and in the 19th century established a number of outposts and missions. In 1887, they founded the town of "Santiago de la Ascension" in what today is Kolonia on the island of Pohnpei.

Following defeat in the Spanish–American War, the Spanish sold the archipelago to Germany in 1899 under the German–Spanish Treaty of 1899. Germany incorporated it into German New Guinea.

During World War I, it was captured by Japan. Following the war, the League of Nations awarded a mandate for Japan to administer the islands as part of the South Pacific Mandate.

During World War II, a significant portion of the Japanese fleet was based in Truk Lagoon. In February 1944, Operation Hailstone, one of the most important naval battles of the war, took place at Truk, in which many Japanese support vessels and aircraft were destroyed.

Following World War II, it was administered by the United States under United Nations auspices in 1947 as part of the Trust Territory of the Pacific Islands pursuant to Security Council Resolution 21.

On May 10, 1979, four of the Trust Territory districts ratified a new constitution to become the Federated States of Micronesia. Palau, the Marshall Islands, and the Northern Mariana Islands chose not to participate. The FSM signed a Compact of Free Association with the United States, which entered into force on November 3, 1986, marking Micronesia's emergence from trusteeship to independence. Independence was formally concluded under international law in 1990, when the United Nations officially ended the Trusteeship status pursuant to Security Council Resolution 683. The Compact was renewed in 2004.

The Federated States of Micronesia is governed by the 1979 constitution, which guarantees fundamental human rights and establishes a separation of governmental powers. The unicameral Congress has fourteen members elected by popular vote. Four senators—one from each state—serve four-year terms; the remaining ten senators represent single-member districts based on population, and serve two-year terms. The President and Vice President are elected by Congress from among the four state-based senators to serve four-year terms in the executive branch. Their congressional seats are then filled by special elections.

The president and vice president are supported by an appointed cabinet. There are no formal political parties.

In international politics, the Federated States of Micronesia has often voted with the United States with respect to United Nations General Assembly resolutions.

The FSM is a sovereign, self-governing state in free association with the United States of America, which is wholly responsible for its defense. The Division of Maritime Surveillance operates a paramilitary Maritime Wing and a small Maritime Police Unit. The Compact of Free Association allows FSM citizens to join the U.S. military without having to obtain U.S. permanent residency or citizenship, allows for immigration and employment for Micronesians in the U.S., and establishes economic and technical aid programs.

FSM has foreign relations with 56 countries, including the Holy See. FSM was admitted to the United Nations based on the Security Council's recommendation on August 9, 1991 in Resolution 703 and the General Assembly's approval on September 17, 1991 in Resolution 46/2. The FSM is an active member of the Pacific Islands Forum.

The four states in the federation are, from west to east:
These states are further divided into municipalities.

Spain has a claim to sovereignty over a few islands including Kapingamarangi in Pohnpei State. A commission of cardinals under Pope Leo XIII arbitrated a dispute for the Caroline Islands and others extending from the Equator to 11°N Latitude and from 133°E to 164°E Longitude. Germany and Spain on 17 December 1885 agreed in a treaty that they were a part of the Spanish East Indies. In 1899, Spain sold "las Carolinas" to Germany. Kapingamarangi is far south of the Carolines and the people are racially and culturally Polynesian, not Micronesian or Carolinian. In 1948, Emilio Pastor Santos of the Spanish National Research Council found that the charts and maps up to 1899 had shown that Kapingamarangi and a few other islands had never been considered part of the Carolines, were not included in the description of the territory transferred to Germany and were never ceded by Spain; therefore, Spain retained sovereignty. In 1949, the Cabinet of Diplomatic Information of the Spanish Ministry of Foreign Affairs issued the following declaration:
"... The Ministry recognises that it is a certain fact and historic truth due to Article 3 of the Treaty of July 1, 1899, that Spain reserved a series of rights in Micronesia and for another thing, the specifications of the territories which Spain ceded in 1899 leaves apart certain groups of islands in the same zone."
Successive Spanish governments have not abandoned Spain's sovereignty, or insisted on enforcing it, or recognized the sovereignty of the Federated States of Micronesia over Kapingamarangi. The Federated States of Micronesia claims sovereignty and has de facto control of the island.

The Federated States of Micronesia consists of 607 islands extending across the archipelago of the Caroline Islands east of the Philippines. The islands have a combined area of .

The islands are grouped into four states, which are Yap, Chuuk (called Truk until January 1990), Pohnpei (known as "Ponape" until November 1984), and Kosrae (formerly Kusaie). These four states are each represented by a white star on the national flag. The capital is Palikir, on Pohnpei.

The Federated States of Micronesia is served by four international airports.

Economic activity in the Federated States of Micronesia consists primarily of subsistence farming and fishing. The islands have few mineral deposits worth exploiting, except for high-grade phosphate. Long line fishing of tuna is also viable with foreign vessels from China that operated in the 1990s. The potential for a tourist industry exists, but the remoteness of the location and a lack of adequate facilities hinder development. Financial assistance from the U.S. is the primary source of revenue, with the U.S. pledged to spend $1.3 billion in the islands in 1986–2001; when the Compact was amended in 2004, the United States committed to providing $110 million in development aid through 2023. The CIA World Factbook lists high dependence on U.S. aid as one of the main concerns of the FSM. Geographical isolation and a poorly developed infrastructure are major impediments to long-term growth.

The indigenous population of the nation, which is predominantly Micronesian, consists of various ethnolinguistic groups. It has a nearly 100% Pacific Islander and Asian population: Chuukese 48.8%, Pohnpeian 24.2%, Kosraean 6.2%, Yapese 5.2%, Yap outer islands 4.5%, Asian 1.8%, Polynesian 1.5%, other 6.4%, unknown 1.4%. A sizeable minority also have some Japanese ancestry, which is a result of intermarriages between Japanese settlers and Micronesians during the Japanese colonial period.

There is also a growing expatriate population of Americans, Australians, Europeans, and residents from China and the Philippines since the 1990s. English has become the common language of the government, and for secondary and tertiary education. Outside of the main capital towns of the four FSM states, the local languages are primarily spoken. Population growth remains high at more than 3% annually, offset somewhat by net emigration.

English is the official and common language. Also spoken are Chuukese, Kosraean, Pohnpeian, Yapese, Ulithian, Woleaian, Nukuoro, and Kapingamarangi.

Other languages spoken in the country include Pingelapese, Ngatikese, Satawalese, Puluwatese, Mortlockese, and Mokilese. There are about 3,000 speakers of Kapingamarangi and Ulithian, and under 1,000 speakers of Nukuoro.

Most Micronesians are Christian. Several Protestant denominations, as well as the Roman Catholic Church, are present in every Micronesian state. Most Protestant groups trace their roots to American Congregationalist missionaries. On the island of Kosrae, the population is approximately 7,800; 95 percent are Protestants. On Pohnpei, the population of 35,000 is evenly divided between Protestants and Catholics. Most immigrants are Filipino Catholics who have joined local Catholic churches, e.g. Our Lady of Mercy Catholic Church in Pohnpei.

On Chuuk and Yap, an estimated 60 percent are Catholic and 40 percent are Protestant. Religious groups with small followings include Baptists, Assemblies of God, Salvation Army, Seventh-day Adventists, Jehovah's Witnesses, The Church of Jesus Christ of Latter-day Saints (Mormons), and the Bahá'í Faith. There is a small group of Buddhists on Pohnpei, and a small group of Ahmadiyya Muslims in Kosrae. Attendance at religious services is generally high; churches are well supported by their congregations and play a significant role in civil society.

In the 1890s, on the island of Pohnpei, intermissionary conflicts and the conversion of clan leaders resulted in religious divisions along clan lines which persist today. More Protestants live on the western side of the island, while more Catholics live on the eastern side. Missionaries of many religious traditions are present and operate freely. The Constitution provides for freedom of religion, and the Government generally respected this right in practice. The US government received no reports of societal abuses or discrimination based on religious belief or practice in 2007.

See Health in the Federated States of Micronesia

The sport of football in the Federated States of Micronesia is run by the Federated States of Micronesia Football Association. They control the Micronesian Games, the nation's football championship and the Micronesia national football team.

The Federated States of Micronesia Athletic Association is the governing body for the country's sports and athletics.

Each of the four states has its own culture and traditions, but there are also common cultural and economic bonds that are centuries old. Cultural similarities include the importance of the traditional extended family and clan systems and are found on all the islands.

The island of Yap is notable for its "stone money" (Rai stones), large disks usually of calcite, up to in diameter, with a hole in the middle. The islanders, aware of the owner of a piece, do not necessarily move them when ownership changes. There are five major types: "Mmbul", "Gaw", "Ray", "Yar", and "Reng", the last being only in diameter. Their value is based on both size and history, many of them having been brought from other islands, as far as New Guinea, but most coming in ancient times from Palau. Approximately 6,500 of them are scattered around the island.

Pohnpei is home to "Nan Madol: Ceremonial Centre of Eastern Micronesia", a UNESCO World Heritage Site, but the site is currently listed as "In Danger" due to natural causes. The government is working on the conservation of the site.

There have been very few published literary writers from the Federated States of Micronesia. In 2008, Emelihter Kihleng became the first ever Micronesian to publish a collection of poetry in the English language.









</doc>
<doc id="11449" url="https://en.wikipedia.org/wiki?curid=11449" title="Frederick William, Elector of Brandenburg">
Frederick William, Elector of Brandenburg

Frederick William (; 16 February 1620 – 29 April 1688) was Elector of Brandenburg and Duke of Prussia, thus ruler of Brandenburg-Prussia, from 1640 until his death in 1688. A member of the House of Hohenzollern, he is popularly known as "the Great Elector" ("") because of his military and political achievements. Frederick William was a staunch pillar of the Calvinist faith, associated with the rising commercial class. He saw the importance of trade and promoted it vigorously. His shrewd domestic reforms gave Prussia a strong position in the post-Westphalian political order of north-central Europe, setting Prussia up for elevation from duchy to kingdom, achieved under his son and successor.

Elector Frederick William was born in Berlin to George William, Elector of Brandenburg, and Elisabeth Charlotte of the Palatinate. His inheritance consisted of the Margraviate of Brandenburg, the Duchy of Cleves, the County of Mark, and the Duchy of Prussia.

During the Thirty Years' War, George William strove to maintain, with a minimal army, a delicate balance between the Protestant and Catholic forces fighting throughout the Holy Roman Empire. Out of these unpromising beginnings Frederick William managed to rebuild his war-ravaged territories. In contrast to the religious disputes that disrupted the internal affairs of other European states, Brandenburg-Prussia benefited from the policy of religious tolerance adopted by Frederick William. With the help of French subsidies, he built up an army to defend the country. In the Second Northern War, he was forced to accept Swedish vassalage for the Duchy of Prussia according to the terms of the Treaty of Königsberg, but as the war progressed he succeeded in gaining full sovereignty for the Prussian duchy in the treaties of Labiau, Wehlau, Bromberg and Oliva, leaving the Holy Roman Emperor as his only liege for his imperial holdings.

In the conflict for Pomerania inheritance, Frederick William had to accept two setbacks, one in the Northern War and one in the Scanian War. Though militarily successful in Swedish Pomerania, he had to bow to France's demands and return his gains to Sweden in the Treaty of Saint-Germain-en-Laye.

Frederick William was a military commander of wide renown, and his standing army would later become the model for the Prussian Army. He is notable for his joint victory with Swedish forces at the Battle of Warsaw, which, according to Hajo Holborn, marked "the beginning of Prussian military history", but the Swedes turned on him at the behest of King Louis XIV and invaded Brandenburg. After marching 250 kilometres in 15 days back to Brandenburg, he caught the Swedes by surprise and managed to defeat them on the field at the Battle of Fehrbellin, destroying the myth of Swedish military invincibility. He later destroyed another Swedish army that invaded the Duchy of Prussia during the Great Sleigh Drive in 1678. He is noted for his use of broad directives and delegation of decision-making to his commanders, which would later become the basis for the German doctrine of Auftragstaktik, and he is noted for using rapid mobility to defeat his foes.

Frederick William is notable for raising an army of 40,000 soldiers by 1678, through the General War Commissariat presided over by Joachim Friedrich von Blumenthal. He was an advocate of mercantilism, monopolies, subsidies, tariffs, and internal improvements. Following Louis XIV's revocation of the Edict of Nantes, Frederick William encouraged skilled French and Walloon Huguenots to emigrate to Brandenburg-Prussia with the Edict of Potsdam, bolstering the country's technical and industrial base. On Blumenthal's advice he agreed to exempt the nobility from taxes and in return they agreed to dissolve the Estates-General. He also simplified travel in Brandenburg and the Duchy of Prussia by connecting riverways with canals, a system that was expanded by later Prussian architects, such as Georg Steenke; the system is still in use today.

On 7 December 1646 in The Hague, Frederick William entered into a marriage, proposed by Blumenthal as a partial solution to the Jülich-Berg question, with Luise Henriette of Nassau (1627–1667), daughter of Frederick Henry of Orange-Nassau and Amalia of Solms-Braunfels and his 1st cousin once removed through William the Silent. Their children were as follows:

On 13 June 1668 in Gröningen, Frederick William married Sophie Dorothea of Holstein-Sonderburg-Glücksburg, daughter of Philip, Duke of Schleswig-Holstein-Sonderburg-Glücksburg and Sophie Hedwig of Saxe-Lauenburg.
Their children were the following:



</doc>
<doc id="11454" url="https://en.wikipedia.org/wiki?curid=11454" title="Frederick V">
Frederick V

Frederick V or Friedrich V may refer to: 



</doc>
<doc id="11456" url="https://en.wikipedia.org/wiki?curid=11456" title="French horn">
French horn

The French horn (since the 1930s known simply as the "horn" in some professional music circles) is a brass instrument made of tubing wrapped into a coil with a flared bell. The double horn in F/B (technically a variety of German horn) is the horn most often used by players in professional orchestras and bands. A musician who plays a French horn is known as a horn player or hornist.

Pitch is controlled through the combination of the following factors: speed of air through the instrument (controlled by the player's lungs and thoracic diaphragm); diameter and tension of lip aperture (by the player's lip muscles—the embouchure) in the mouthpiece; plus, in a modern French horn, the operation of valves by the left hand, which route the air into extra sections of tubing. Most horns have lever-operated rotary valves, but some, especially older horns, use piston valves (similar to a trumpet's) and the Vienna horn uses double-piston valves, or pumpenvalves. The backward-facing orientation of the bell relates to the perceived desirability to create a subdued sound in concert situations, in contrast to the more piercing quality of the trumpet. A horn without valves is known as a natural horn, changing pitch along the natural harmonics of the instrument (similar to a bugle). Pitch may also be controlled by the position of the hand in the bell, in effect reducing the bell's diameter. The pitch of any note can easily be raised or lowered by adjusting the hand position in the bell. The key of a natural horn can be changed by adding different crooks of different lengths.

Three valves control the flow of air in the "single horn", which is tuned to F or less commonly B. The more common "double horn" has a fourth, trigger valve, usually operated by the thumb, which routes the air to one set of tubing tuned to F or another tuned to B which expands the horn range to over four octaves and blends with flutes or clarinets in a woodwind ensemble. Triple horns with five valves are also made, usually tuned in F, B, and a descant E or F. There are also double horns with five valves tuned in B, descant E or F, and a stopping valve, which greatly simplifies the complicated and difficult hand-stopping technique, though these are rarer. Also common are "descant" doubles, which typically provide B and alto F branches.

A crucial element in playing the horn deals with the mouthpiece. Most of the time, the mouthpiece is placed in the exact center of the lips, but, because of differences in the formation of the lips and teeth of different players, some tend to play with the mouthpiece slightly off center. Although the exact side-to-side placement of the mouthpiece varies for most horn players, the up-and-down placement of the mouthpiece is generally two-thirds on the upper lip and one-third on the lower lip. When playing higher notes, the majority of players exert a small degree of additional pressure on the lips using the mouthpiece. However, this is undesirable from the perspective of both endurance and tone: excessive mouthpiece pressure makes the horn sound forced and harsh, and decreases player's stamina due to the resulting constricted flow of blood to the lips and lip muscles.

The name "French horn" is found only in English, first coming into use in the late 17th century. At that time, French makers were preeminent in the manufacture of hunting horns, and were credited with creating the now-familiar, circular "hoop" shape of the instrument. As a result, these instruments were often called, even in English, by their French names: "trompe de chasse" or "cor de chasse" (the clear modern distinction between "trompes", trumpets, and "cors", horns, did not exist at that time). 

German makers first devised "crooks" to make such horns playable in different keys—so musicians came to use "French" and "German" to distinguish the simple hunting horn from the newer horn with crooks, which in England was also called by the Italian name "corno cromatico" (chromatic horn). 

More recently, "French horn" is often used colloquially, though the adjective has normally been avoided when referring to the European orchestral horn, ever since the German horn began replacing the French-style instrument in British orchestras around 1930. The International Horn Society has recommended since 1971 that the instrument be simply called the "horn".

There is also a more specific use of "French horn" to describe a particular horn type, differentiated from the German horn and Vienna horn. In this sense, "French horn" refers to a narrow-bore instrument () with three Périnet (piston) valves. It retains the narrow bell-throat and mouthpipe crooks of the orchestral hand horn of the late 18th century, and most often has an "ascending" third valve. This is a whole-tone valve arranged so that with the valve in the "up" position the valve loop is engaged, but when the valve is pressed the loop is cut out, raising the pitch by a whole tone.

As the name indicates, humans originally used to blow on the actual horns of animals before starting to emulate them in metal. This original usage survives in the shofar, a ram's horn, which plays an important role in Jewish religious rituals.

Early metal horns were less complex than modern horns, consisting of brass tubes with a slightly flared opening (the bell) wound around a few times. These early "hunting" horns were originally played on a hunt, often while mounted, and the sound they produced was called a recheat. Change of pitch was controlled entirely by the lips (the horn not being equipped with valves until the 19th century). Without valves, only the notes within the harmonic series are available. By combining a long length with a narrow bore, the French horn's design allows the player to easily reach the higher overtones which differ by whole tones, thus making it capable of playing melodies before valves were invented.

Early horns were commonly pitched in B alto, A, A, G, F, E, E, D, C, and B basso. Since the only notes available were those on the harmonic series of one of those pitches, they had no ability to play in different keys. The remedy for this limitation was the use of crooks, i.e., sections of tubing of differing length that, when inserted, altered the length of the instrument, and thus its pitch.

In the mid-18th century, horn players began to insert the right hand into the bell to change the length of the instrument, adjusting the tuning up to the distance between two adjacent harmonics depending on how much of the opening was covered.

In 1818 the German makers Heinrich Stölzel and Friedrich Blümel patented the first valved horn, using rotary valves. Piston valves were introduced in France about 1839 by François Périnet. Valves were initially intended to overcome problems associated with changing crooks during a performance. Valves' unreliability, musical taste, and players' distrust, among other reasons, slowed their adoption into mainstream. Many traditional conservatories and players refused to use them at first, claiming that the valveless horn, or "natural horn", was a better instrument. Some musicians who specialize in period instruments use a natural horn to play in original performance styles, to try to recapture the sound of an older piece's original performances.

The use of valves, however, opened up a great deal more flexibility in playing in different keys; in effect, the horn became an entirely different instrument, fully chromatic for the first time. Valves were originally used primarily as a means to play in different keys without crooks, not for harmonic playing. That is reflected in compositions for horns, which only began to include chromatic passages in the late 19th century. When valves were invented, generally, the French made smaller horns with piston valves and the Germans made larger horns with rotary valves.

In English, the term "French horn" is often used. Nevertheless, the International Horn Society has recommended since 1971 that the instrument be simply called the "horn", despite the ambiguity of the term.

Horns may be classified in single horn, double horn, compensating double horn, and triple horn as well as the versatility of detachable bells.
Single horns use a single set of tubes connected to the valves. This allows for simplicity of use and a much lighter weight. They are usually in the keys of F or B, although many F horns have longer slides to tune them to E, and almost all B horns have a valve to put them in the key of A. The problem with single horns is the inevitable choice between accuracy or tone – while the F horn has the "typical" horn sound, above third-space C accuracy is a concern for the majority of players because, by its nature, one plays high in the horn's harmonic series where the overtones are closer together. This led to the development of the B horn, which, although easier to play accurately, has a less desirable sound in the mid and especially the low register where it is not able to play all of the notes. The solution has been the development of the double horn, which combines the two into one horn with a single lead pipe and bell. Both main types of single horns are still used today as student models because they are cheaper and lighter than double horns. In addition, the single B horns are sometimes used in solo and chamber performances and the single F survives orchestrally as the Vienna horn. Additionally, single F alto and B alto descants are used in the performance of some baroque horn concertos and F, B and F alto singles are occasionally used by jazz performers.

Dennis Brain's benchmark recordings of the Mozart Horn Concerti were made on a single B instrument by Gebr. Alexander, now on display at the Royal Academy of Music in London.

Despite the introduction of valves, the single F horn proved difficult for use in the highest range, where the partials grew closer and closer, making accuracy a great challenge. An early solution was simply to use a horn of higher pitch—usually B. The use of the F versus the B horn was extensively debated among horn players of the late 19th century, until the German horn maker Ed. Kruspe (namesake of his family's brass instrument firm) produced a prototype of the "double horn" in 1897.

The double horn also combines two instruments into a single frame: the original horn in F, and a second, higher horn keyed in B. By using a fourth valve (usually operated by the thumb), the horn player can quickly switch from the deep, warm tones of the F horn to the higher, brighter tones of the B horn, or vice versa, as the horn player may choose to have the horn set into B by default by making a simple adjustment to the valves. The two sets of tones are commonly called "sides" of the horn. Using the fourth valve not only changes the basic length (and thus the harmonic series and pitch) of the instrument, it also causes the three main valves to use proportionate slide lengths.

In the US, the two most common styles ("wraps") of double horns are named Kruspe and Geyer/Knopf, after the first instrument makers who developed and standardized them. The Kruspe wrap locates the B change valve above the first valve, near the thumb. The Geyer wrap has the change valve behind the third valve, near the little finger (although the valve's trigger is still played with the thumb). In effect, the air flows in a completely different direction on the other model. Kruspe wrap horns tend to be larger in the bell throat than the Geyer wrap horns. Typically, Kruspe models are constructed from nickel silver (also called German silver, an alloy of copper, nickel and zinc, containing no actual silver) while Geyer horns tend to be of yellow brass. Both models have their own strengths and weaknesses, and while the choice of instrument is very personal, an orchestral horn section is usually found to have either one or the other, owing to the differences in tone color, response, and projection of the two different styles.

In Europe the most popular horns are arguably those made by Gebr. Alexander, of Mainz (particularly the Alexander 103), and those made by Paxman in London. In Germany and the Benelux countries, the Alex 103 is extremely popular. These horns do not fit strictly into the Kruspe or Knopf camps, but have features of both. Alexander prefers the traditional medium bell size, which they have produced for many years, whereas Paxman do offer their models in a range of bell throat sizes. In the United States, the Conn 8D, a mass-produced instrument based on the Kruspe design, has been extremely popular in many areas (New York, Los Angeles, Cleveland, Philadelphia). Since roughly the early 1990s, however, for reasons ranging from changing tastes to a general dislike of Conn's newer 8Ds, orchestras have been moving away from the popular Conn 8D. Geyer model horns (by Carl Geyer, Karl Hill, Keith Berg, Steve Lewis, Jerry Lechniuk, Dan Rauch, and Ricco-Kuhn) are used in other areas (San Francisco, Chicago, Pittsburgh, Boston, Houston). The CF Schmidt double, with its unique piston change valve, is occasionally found in sections playing Geyer/Knopf model equipment.

The horn, although not large, is awkward in its shape and does not lend itself well to transport where space is shared or limited, especially on planes. To compensate, horn makers can make the bell detachable; this allows for smaller and more manageable horn cases.

The variety in horn history necessitates consideration of the natural horn, Vienna horn, mellophone, marching horn, and Wagner tuba.

The natural horn is the ancestor of the modern horn. It is essentially descended from hunting horns, with its pitch controlled by air speed, aperture (opening of the lips through which air passes) and the use of the right hand moving around, as well as in and out of the bell. Although a few recent composers have written specifically for the natural horn (e.g., György Ligeti's "Hamburg Concerto"), today it is played primarily as a period instrument. The natural horn can only play from a single harmonic series at a time because there is only one length of tubing available to the horn player. A proficient player can indeed alter the pitch by partially muting the bell with the right hand, thus enabling the player to reach some notes that are not part of the instrument's natural harmonic series – of course this technique also affects the quality of the tone. The player has a choice of key by using crooks to change the length of tubing. 

The Vienna horn is a special horn used primarily in Vienna, Austria. Instead of using rotary valves or piston valves, it uses the pumpenvalve (or Vienna valve), which is a double-piston operating inside the valve slides, and usually situated on the opposite side of the corpus from the player's left hand, and operated by a long pushrod. Unlike the modern horn, which has grown considerably larger internally (for a bigger, broader, and louder tone), and considerably heavier (with the addition of valves and tubing in the case of the double horn) the Vienna horn very closely mimics the size and weight of the natural horn, (although the valves do add some weight, they are lighter than rotary valves) even using crooks in the front of the horn, between the mouthpiece and the instrument. Although instead of the full range of keys, Vienna horn players usually use an F crook and it is looked down upon to use others, though switching to an A or B crook for higher pitched music does happen on occasion. Vienna horns are often used with funnel shaped mouthpieces similar to those used on the natural horn, with very little (if any) backbore and a very thin rim. The Viennese horn requires very specialized technique and can be quite challenging to play, even for accomplished players of modern horns. The Vienna horn has a warmer, softer sound than the modern horn. Its pumpenvalves facilitate a continuous transition between notes (glissando); conversely, a more precise operating of the valves is required to avoid notes that sound out of tune.

Two instruments are called a "mellophone". The first is an instrument shaped somewhat like a horn, in that it is formed in a circle. It has piston valves and is played with the right hand on the valves. Manufacturing of this instrument sharply decreased in the middle of the 20th century, and this mellophone (or mellophonium) rarely appears today.

The second instrument is used in modern brass bands and marching bands, and is more accurately called a "marching mellophone" or mellophone. A derivative of the F alto horn, it is keyed in F. It is shaped like a flugelhorn, with piston valves played with the right hand and a forward-pointing bell. These horns are generally considered better marching instruments than regular horns because their position is more stable on the mouth, they project better, and they weigh less. It is primarily used as the middle voice of drum and bugle corps. Though they are usually played with a V-cup cornet-like mouthpiece, their range overlaps the common playing range of the horn. This mouthpiece switch makes the mellophone louder, less mellow, and more brassy and brilliant, making it more appropriate for marching bands. Often now with the use of converters, traditional conical horn mouthpieces are used to achieve the more mellow sound of a horn to make the marching band sound more like a concert band.

As they are pitched in F or G and their range overlaps that of the horn, mellophones can be used in place of the horn in brass and marching band settings. Mellophones are, however, sometimes unpopular with horn players because the mouthpiece change can be difficult and requires a different embouchure. Mouthpiece adapters are available so that a horn mouthpiece can fit into the mellophone lead pipe, but this does not compensate for the many differences that a horn player must adapt to. The "feel" of the mellophone can be foreign to a horn player. Another unfamiliar aspect of the mellophone is that it is designed to be played with the right hand instead of the left (though it can be played with the left). Intonation can also be an issue with the mellophone.

While horn players may be asked to play the mellophone, it is unlikely that the instrument was ever intended as a substitute for the horn, mainly because of the fundamental differences described. As an instrument it compromises between the ability to sound like a horn, while being used like a trumpet or flugelhorn, a tradeoff that sacrifices acoustic properties for ergonomics.

The marching horn is quite similar to the mellophone in shape and appearance, but is pitched in the key of B, the same as the B side of a double horn. It is also available in F alto, one octave above the F side of a double horn. The marching horn is also played with a horn mouthpiece (unlike the mellophone, which needs an adapter to fit the horn mouthpiece). These instruments are primarily used in marching bands so the sound comes from a forward-facing bell, as dissipation of the sound from the backward-facing bell becomes a concern in open-air environments. Many college marching bands and drum corps, however, use mellophones instead, which, with many marching bands, better balance the tone of the other brass instruments; additionally, mellophones require less special training of trumpeters, who considerably outnumber horn players.

The Wagner tuba is a rare brass instrument that is essentially a horn modified to have a larger bell throat and a vertical bell. Despite its name, it is generally not considered part of the tuba family. Invented for Richard Wagner specifically for his work "Der Ring des Nibelungen", it has since been written for by various other composers, including Bruckner, Stravinsky and Richard Strauss. It uses a horn mouthpiece and is available as a single tuba in B or F, or, more recently, as a double tuba similar to the double horn. Its common range is similar to that of the euphonium, but its possible range is the same as that of the horn, extending from low F, below the bass clef staff to high C above the treble staff when read in F. These low pedals are substantially easier to play on the Wagner tuba than on the horn. Wagner viewed the regular horn as a woodwind rather than a brass instrument, evidenced by his placing of the horn parts in his orchestral scores in the woodwind group and not in their usual place above the trumpets in the brass section.

Discussion of the repertoire of horns must recognize the different needs of orchestras and concert bands in contrast to marching bands, as above, but also the use of horns in a wide variety of music, including chamber music and jazz.

The horn is most often used as an orchestral and concert band instrument, with its singular tone being employed by composers to achieve specific effects. Leopold Mozart, for example, used horns to signify the hunt, as in his "Jagdsinfonie" (hunting symphony). Telemann wrote much for the horn, and it features prominently in the work of Handel and in Bach's "Brandenburg Concerto no. 1". Once the technique of hand-stopping had been developed, allowing fully chromatic playing, composers began to write seriously for the horn. Gustav Mahler made great use of the horn's uniquely haunting and distant sound in his symphonies, notably the famous "Nachtmusik" (serenade) section of his Symphony No. 7.

Many composers have written works that have become favorites in the horn repertoire. These include Poulenc ("Elegie") and Saint-Saëns ("Morceau de Concert for horn and orchestra", op. 94 and "Romance", op. 36). Others, particularly Wolfgang Amadeus Mozart, whose friend Joseph Leutgeb was a noted horn player, wrote extensively for the instrument, including concerti and other solo works. Mozart's "A Musical Joke" satirizes the limitations of contemporary horn playing, including the risk of selecting the wrong crook by mistake.

The development of the valve horn was exploited by romantic composers such as Bruckner, Mahler, and Richard Strauss, whose father was a well-known professional horn player. Strauss's "Till Eulenspiegel's Merry Pranks" contains one of the best known horn solos from this period, relying on the chromatic facility of the valved horn. Schumann's "Konzertstück" for four horns and orchestra is a notable three-movement work. Brahms had a lifelong love-affair with the instrument, with many prominently featured parts throughout his four symphonies. However players today typically play Brahms on modern valved instruments.

There is an abundance of chamber music repertoire for horn. It is a standard member of the wind quintet and brass quintet, and often appears in other configurations, such as Brahms' Horn Trio for violin, horn and piano (for which, however, Brahms specified the natural horn). Also, the horn can be used by itself in a horn ensemble or "horn choir". The horn choir is especially practical because the extended range of the horn provides the composer or arranger with more possibilities, registerally, sonically, and contrapuntally.

A classical orchestra usually has at least two French horn players. Typically, the first horn played a high part and the second horn played a low part. Composers from Beethoven (early 1800s) onwards commonly used four horns. Here, the first and second horns played as a pair (first horn being high, second horn being low), and the third and fourth horns played as another pair (third horn being high, fourth horn being low). 

Music written for the modern horn follows a similar pattern with the first and third horns being high and the second and fourth horns being low. This configuration serves multiple purposes. It is easier to play high when the adjacent player is playing low and vice versa. Pairing makes it easier to write for horns, as the third and fourth horns can take over from the first and second horns or play contrasting material. For example, if the piece is in C minor, the first and second horns might be in C, the tonic major key, which could get most of the notes, and the third and fourth horns might be in E, the relative major key, to fill in the gaps. 

Many orchestral horn sections in the 2010s also have an assistant who doubles the first horn part for selected passages, joining in loud parts, playing instead of the principal if there is a first horn solo approaching, or alternating with the principal if the part is tiring to play. Often the assistant is asked to play a passage after resting a long time. Also, he or she may be asked to enter in the middle of a passage, exactly matching the sound, articulation, and overall interpretation of the principal, thus enabling the principal horn to rest a bit.

The French horn was at first rarely used in jazz music (Note that colloquially in jazz, the word "horn" refers to any wind instrument). Notable exponents, however, began including French horn in jazz pieces and ensembles. These include composer/arranger Gil Evans who included the French horn as an ensemble instrument from the 1940s, first in Claude Thornhill's groups, and later with the pioneering cool jazz nonet (nine-piece group) led by trumpeter Miles Davis, and in many other projects that sometimes also featured Davis, as well as Don Ellis, a trumpet player from Stan Kenton's jazz band. Notable works of Ellis' jazz French horn include "Strawberry Soup" and other songs on the album "Tears of Joy". Notable improvising horn players in jazz include Julius Watkins, Willie Ruff, John Graas, David Amram, John Clark, Vincent Chancey, Mark Taylor, Giovanni Hoffer, Arkady Shilkloper, Adam Unsworth, and Tom Varner.


People who are more notable for their other achievements, but also play the horn, include actors Ewan McGregor and David Ogden Stiers, comedian and television host Jon Stewart, journalist Chuck Todd, The Who bassist and singer John Entwistle, and rapper and record producer B.o.B.




</doc>
<doc id="11457" url="https://en.wikipedia.org/wiki?curid=11457" title="Fra Angelico">
Fra Angelico

Fra Angelico (born Guido di Pietro; February 18, 1455) was an Italian painter of the Early Renaissance, described by Vasari in his "Lives of the Artists" as having "a rare and perfect talent".

He was known to contemporaries as Fra Giovanni da Fiesole (Brother John of Fiesole) and Fra Giovanni Angelico (Angelic Brother John). In modern Italian he is called Beato Angelico (Blessed Angelic One); the common English name Fra Angelico means the "Angelic friar".

In 1982, Pope John Paul II proclaimed his beatification in recognition of the holiness of his life, thereby making the title of "Blessed" official. Fiesole is sometimes misinterpreted as being part of his formal name, but it was merely the name of the town where he took his vows as a Dominican friar, and was used by contemporaries to separate him from others who were also known as Fra Giovanni. He is listed in the Roman Martyrology as "Beatus Ioannes Faesulanus, cognomento Angelicus"—"Blessed Giovanni of Fiesole, surnamed 'the Angelic' ".

Vasari wrote of Fra Angelico that "it is impossible to bestow too much praise on this holy father, who was so humble and modest in all that he did and said and whose pictures were painted with such facility and piety."

Fra Angelico was born Guido di Pietro at Rupecanina in the Tuscan area of Mugello near Fiesole towards the end of the 14th century. Nothing is known of his parents. He was baptized Guido or Guidolino. The earliest recorded document concerning Fra Angelico dates from October 17, 1417 when he joined a religious confraternity or guild at the Carmine Church, still under the name of Guido di Pietro. This record reveals that he was already a painter, a fact that is subsequently confirmed by two records of payment to Guido di Pietro in January and February 1418 for work done in the church of Santo Stefano del Ponte. The first record of Angelico as a friar dates from 1423, when he is first referred to as Fra Giovanni (Friar John), following the custom of those entering one of the older religious orders of taking a new name. He was a member of the local community at Fiesole, not far from Florence, of the Dominican Order; one of the medieval Orders belonging to a category known as mendicant Orders because they generally lived not from the income of estates but from begging or donations. Fra, a contraction of "frater" (Latin for 'brother'), is a conventional title for a mendicant friar.

According to Vasari, Fra Angelico initially received training as an illuminator, possibly working with his older brother Benedetto who was also a Dominican and an illuminator. The former Dominican convent of San Marco in Florence, now a state museum, holds several manuscripts that are thought to be entirely or partly by his hand. The painter Lorenzo Monaco may have contributed to his art training, and the influence of the Sienese school is discernible in his work. He also trained with master Varricho in Milan He had several important charges in the convents he lived in, but this did not limit his art, which very soon became famous. According to Vasari, the first paintings of this artist were an altarpiece and a painted screen for the Charterhouse (Carthusian monastery) of Florence; none such exist there now.

From 1408 to 1418, Fra Angelico was at the Dominican friary of Cortona, where he painted frescoes, now mostly destroyed, in the Dominican Church and may have been assistant to Gherardo Starnina or a follower of his. Between 1418 and 1436 he was at the convent of Fiesole, where he also executed a number of frescoes for the church and the Altarpiece, which was deteriorated but has since been restored. A predella of the Altarpiece remains intact and is conserved in the National Gallery, London, and is a great example of Fra Angelico's ability. It shows Christ in Glory surrounded by more than 250 figures, including beatified Dominicans.

In 1436, Fra Angelico was one of a number of the friars from Fiesole who moved to the newly built convent or friary of San Marco in Florence. This was an important move which put him in the centre of artistic activity of the region and brought about the patronage of one of the wealthiest and most powerful members of the city's governing authority, or "Signoria" (namely Cosimo de' Medici), who had a cell reserved for himself at the friary in order that he might retreat from the world. 
It was, according to Vasari, at Cosimo's urging that Fra Angelico set about the task of decorating the convent, including the magnificent fresco of the Chapter House, the often-reproduced Annunciation at the top of the stairs leading to the cells, the Maesta (or Coronation of the Madonna) with Saints (cell 9) and the many other devotional frescoes, of smaller format but remarkable luminous quality, depicting aspects of the Life of Christ that adorn the walls of each cell.

In 1439 Fra Angelico completed one of his most famous works, the "San Marco Altarpiece" at Florence. The result was unusual for its time. Images of the enthroned Madonna and Child surrounded by saints were common, but they usually depicted a setting that was clearly heaven-like, in which saints and angels hovered about as divine presences rather than people. But in this instance, the saints stand squarely within the space, grouped in a natural way as if they were able to converse about the shared experience of witnessing the Virgin in glory. Paintings such as this, known as Sacred Conversations, were to become the major commissions of Giovanni Bellini, Perugino and Raphael.

In 1445 Pope Eugene IV summoned him to Rome to paint the frescoes of the Chapel of the Holy Sacrament at St Peter's, later demolished by Pope Paul III. Vasari claims that at this time Fra Angelico was offered the Archbishopric of Florence by Pope Nicholas V, and that he refused it, recommending another friar for the position. The story seems possible and even likely. However, if Vasari's date is correct, then the pope must have been Eugene IV and not Nicholas, who was elected Pope only on 6 March 1447. Moreover, the archbishop in 1446–1459 was the Dominican Antoninus of Florence (Antonio Pierozzi), canonized by Pope Adrian VI in 1523. In 1447 Fra Angelico was in Orvieto with his pupil, Benozzo Gozzoli, executing works for the Cathedral. Among his other pupils were Zanobi Strozzi.

From 1447 to 1449 Fra Angelico was back at the Vatican, designing the frescoes for the Niccoline Chapel for Nicholas V. The scenes from the lives of the two martyred deacons of the Early Christian Church, St. Stephen and St. Lawrence may have been executed wholly or in part by assistants. The small chapel, with its brightly frescoed walls and gold leaf decorations gives the impression of a jewel box. From 1449 until 1452, Fra Angelico returned to his old convent of Fiesole, where he was the Prior.

In 1455, Fra Angelico died while staying at a Dominican convent in Rome, perhaps on an order to work on Pope Nicholas' chapel. He was buried in the church of Santa Maria sopra Minerva. 
The English writer and critic William Michael Rossetti wrote of the friar:
Pope John Paul II beatified Fra Angelico on October 3, 1982, and in 1984 declared him patron of Catholic artists.

Fra Angelico was working at a time when the style of painting was in a state of change. This process of change had begun a hundred years previous with the works of Giotto and several of his contemporaries, notably Giusto de' Menabuoi, both of whom had created their major works in Padua, although Giotto was trained in Florence by the great Gothic artist, Cimabue, and painted a fresco cycle of St Francis in the Bardi Chapel in the Basilica di Santa Croce. Giotto had many enthusiastic followers, who imitated his style in fresco, some of them, notably the Lorenzetti, achieving great success.

The patrons of these artists were most often monastic establishments or wealthy families endowing a church. Because the paintings often had devotional purpose, the clients tended to be conservative. Frequently, it would seem, the wealthier the client, the more conservative the painting. There was a very good reason for this. The paintings that were commissioned made a statement about the patron. Thus the more gold leaf it displayed, the more it spoke to the patron's glory. The other valuable commodities in the paint-box were lapis lazuli and vermilion. Paint made from these colours did not lend itself to a tonal treatment. The azure blue made of powdered lapis lazuli went on flat, the depth and brilliance of colour being, like the gold leaf, a sign of the patron's ability to provide well. For these reasons, altarpieces are often much more conservatively painted than frescoes, which were often of almost life-sized figures and relied upon a stage-set quality rather than lavish display in order to achieve effect.

Fra Angelico was the contemporary of Gentile da Fabriano. Gentile's altarpiece of the "Adoration of the Magi", 1423, in the Uffizi is regarded as one of the greatest works of the style known as International Gothic. At the time it was painted, another young artist, known as Masaccio, was working on the frescoes for the Brancacci Chapel at the church of the Carmine. Masaccio had fully grasped the implications of the art of Giotto. Few painters in Florence saw his sturdy, lifelike and emotional figures and were not affected by them. His work partner was an older painter, Masolino, of the same generation as Fra Angelico. Masaccio died at 27, leaving the work unfinished.

The works of Fra Angelico reveal elements that are both conservatively Gothic and progressively Renaissance. In the altarpiece of the Coronation of the Virgin, painted for the Florentine church of Santa Maria Novella, are all the elements that a very expensive altarpiece of the 14th century was expected to provide; a precisely tooled gold background, lots of azure, lots of vermilion and an obvious display of arsenic green. The workmanship of the gilded haloes and gold-edged robes is exquisite and all very Gothic. What makes this a Renaissance painting, as against Gentile da Fabriano's masterpiece, is the solidity, the three-dimensionality and naturalism of the figures and the realistic way in which their garments hang or drape around them. Even though it is clouds these figures stand upon, and not the earth, they do so with weight.

The series of frescoes that Fra Angelico painted for the Dominican friars at San Marcos realise the advancements made by Masaccio and carry them further. Away from the constraints of wealthy clients and the limitations of panel painting, Fra Angelico was able to express his deep reverence for his God and his knowledge and love of humanity. The meditational frescoes in the cells of the convent have a quieting quality about them. They are humble works in simple colours. There is more mauvish-pink than there is red, and the brilliant and expensive blue is almost totally lacking. In its place is dull green and the black and white of Dominican robes. There is nothing lavish, nothing to distract from the spiritual experiences of the humble people who are depicted within the frescoes. Each one has the effect of bringing an incident of the life of Christ into the presence of the viewer. They are like windows into a parallel world. These frescoes remain a powerful witness to the piety of the man who created them.
Vasari relates that Cosimo de' Medici seeing these works, inspired Fra Angelico to create a large Crucifixion scene with many saints for the Chapter House. As with the other frescoes, the wealthy patronage did not influence the Friar's artistic expression with displays of wealth.

Masaccio ventured into perspective with his creation of a realistically painted niche at Santa Maria Novella. Subsequently, Fra Angelico demonstrated an understanding of linear perspective particularly in his Annunciation paintings set inside the sort of arcades that Michelozzo and Brunelleschi created at San’ Marco's and the square in front of it.

When Fra Angelico and his assistants went to the Vatican to decorate the chapel of Pope Nicholas, the artist was again confronted with the need to please the very wealthiest of clients. In consequence, walking into the small chapel is like stepping into a jewel box. The walls are decked with the brilliance of colour and gold that one sees in the most lavish creations of the Gothic painter Simone Martini at the Lower Church of St Francis of Assisi, a hundred years earlier. Yet Fra Angelico has succeeded in creating designs which continue to reveal his own preoccupation with humanity, with humility and with piety. The figures, in their lavish gilded robes, have the sweetness and gentleness for which his works are famous. According to Vasari:
In their bearing and expression, the saints painted by Fra Angelico come nearer to the truth than the figures done by any other artist.

It is probable that much of the actual painting was done by his assistants to his design. Both Benozzo Gozzoli and Gentile da Fabriano were highly accomplished painters. Benozzo took his art further towards the fully developed Renaissance style with his expressive and lifelike portraits in his masterpiece depicting the Journey of the Magi, painted in the Medici's private chapel at their palazzo.

Through Fra Angelico's pupil Benozzo Gozzoli's careful portraiture and technical expertise in the art of fresco we see a link to Domenico Ghirlandaio, who in turn painted extensive schemes for the wealthy patrons of Florence, and through Ghirlandaio to his pupil Michelangelo and the High Renaissance.

Apart from the lineal connection, superficially there may seem little to link the humble priest with his sweetly pretty Madonnas and timeless Crucifixions to the dynamic expressions of Michelangelo's larger-than-life creations. But both these artists received their most important commissions from the wealthiest and most powerful of all patrons, the Vatican.

When Michelangelo took up the Sistine Chapel commission, he was working within a space that had already been extensively decorated by other artists. Around the walls the "Life of Christ" and "Life of Moses" were depicted by a range of artists including his teacher Ghirlandaio, Raphael's teacher Perugino and Botticelli. They were works of large scale and exactly the sort of lavish treatment to be expected in a Vatican commission, vying with each other in complexity of design, number of figures, elaboration of detail and skillful use of gold leaf. Above these works stood a row of painted Popes in brilliant brocades and gold tiaras. None of these splendours have any place in the work which Michelangelo created. Michelangelo, when asked by Pope Julius II to ornament the robes of the Apostles in the usual way, responded that they were very poor men.

Within the cells of San’Marco, Fra Angelico had demonstrated that painterly skill and the artist's personal interpretation were sufficient to create memorable works of art, without the expensive trappings of blue and gold. In the use of the unadorned fresco technique, the clear bright pastel colours, the careful arrangement of a few significant figures and the skillful use of expression, motion and gesture, Michelangelo showed himself to be the artistic descendant of Fra Angelico. Frederick Hartt describes Fra Angelico as "prophetic of the mysticism" of painters such as Rembrandt, El Greco and Zurbarán.

Rome
Cortona
Fiesole
Florence, Santa Trinita 
Florence, Santa Maria degli Angeli 
Florence, Santa Maria Novella 



Each cell is decorated with a fresco which matches in size and shape the single round-headed window beside it. The frescoes are apparently for contemplative purpose. They have a pale, serene, unearthly beauty. Many of Fra Angelico's finest and most reproduced works are among them. There are, particularly in the inner row of cells, some of less inspiring quality and of more repetitive subject, perhaps completed by assistants. Many pictures include Dominican saints as witnesses of scene each in one of the nine traditional prayer postures depicted in De Modo Orandi.

Each cell is decorated with a fresco which matches in size and shape the single round-headed window beside it. The frescoes are apparently for contemplative purpose. They have a pale, serene, unearthly beauty. Many of Fra Angelico's finest and most reproduced works are among them. There are, particularly in the inner row of cells, some of less inspiring quality and of more repetitive subject, perhaps completed by assistants.☃☃ Many pictures include Dominican saints as witnesses of scene each in one of the nine traditional prayer postures depicted in De Modo Orandi. The friar using the cell could place himself in the scene.


Orvieto Cathedral

Three segments of the ceiling in the Cappella Nuova, with the assistance of Benozzo Gozzoli.

Niccoline Chapel

The Chapel of Pope Nicholas V, at the Vatican, was probably painted with much assistance from Benozzo Gozzoli and Gentile da Fabriano. The entire surface of wall and ceiling is sumptuously painted. There is much gold leaf for borders and decoration, and a great use of brilliant blue made from lapis lazuli.

Worldwide press coverage reported in November 2006 that two missing masterpieces by Fra Angelico had turned up, having hung in the spare room of the late Jean Preston, in her terrace house in Oxford, England. Her father had bought them for £100 each in the 1960s then bequeathed them to her when he died. Preston, an expert medievalist, recognised them as being high quality Florentine renaissance, but did not realize that they were works by Fra Angelico until they were identified in 2005 by Michael Liversidge of Bristol University. There was almost no demand at all for medieval art during the 1960s and no dealers showed any interest, so Preston's father bought them almost as an afterthought along with some manuscripts. Coincidentally the manuscripts turned out to be high quality Victorian forgeries by The Spanish Forger. The paintings are two of eight side panels of a large altarpiece painted in 1439 for Fra Angelico's monastery at San Marco, which was later split up by Napoleon's army. While the centre section is still at the monastery, the other six small panels are in German and US museums. These two panels were presumed lost forever. The Italian Government had hoped to purchase them but they were outbid at auction on 20 April 2007 by a private collector for £1.7M. Both panels are now restored and exhibited in the San Marco Museum in Florence.





</doc>
<doc id="11458" url="https://en.wikipedia.org/wiki?curid=11458" title="Fra Bartolomeo">
Fra Bartolomeo

Fra Bartolomeo or Bartolommeo OP (28 March 1472 – 31 October 1517), also known as Bartolommeo di Pagholo, Bartolommeo di S. Marco, and his original name Baccio della Porta, was an Italian Renaissance painter of religious subjects. He spent all his career in Florence until his mid-forties, when he travelled to work in various cities, as far south as Rome. He trained with Cosimo Roselli and in the 1490s fell under the influence of Savonarola, which led him to become a Dominican friar in 1500, renouncing painting for several years.

He was instructed to resume painting for the benefit of his order in 1504, and then developed an idealized High Renaissance style, seen in his "Vision of St Bernard" of that year, now in poor condition but whose "figures and drapery move with a seraphic grace that must have struck the young Raphael with the force of revelation". He remained friends with Raphael, and each influenced the other.

His portrait of Savonarola remains the most famous image of the reformer. Fra Bartolomeo painted both in oils and fresco, and some of his drawings are pure landscape sketches that are the earliest of this type from Italy.

He was born in Savignano di Prato, Tuscany. He received the nickname of Baccio della Porta for his house was near the Gate of San Pier Gattolini.

Starting from 1483 or 1484, by recommendation of Benedetto da Maiano, he apprenticed in the workshop of Cosimo Rosselli. He was one of the greatest painters of his time. In 1490 or 1491 he began a collaboration with Mariotto Albertinelli. In the late 1490s Baccio was drawn to the teachings of Fra Girolamo Savonarola, who denounced what he viewed as vain and corrupt contemporary art. Savonarola argued for art serving as a direct visual illustration of the Bible to educate those unable to read the book. From 1498 is his famous portrait of Savonarola, now in the Museo Nazionale di San Marco in Florence. The following year he was commissioned a fresco of the "Universal Judgement" for the Ospedale di Santa Maria Nuova, completed by Albertinelli and Giuliano Bugiardini when Baccio became a Dominican friar on July 26, 1500. The following year he entered the convent of San Marco.

He renounced painting for several years, not resuming until 1504 when he became the head of the monastery workshop in obedience to his superior. In that year he began a "Vision of St. Bernard" for Bernardo Bianco's family chapel in the Badia Fiorentina, finished in 1507.
Soon thereafter, Raphael visited Florence and befriended the friar. Bartolomeo learned perspective from the younger artist, while Raphael added skills in coloring and handling of drapery, which was noticeable in the works he produced after their meeting. With Raphael, he remained on the friendliest terms, and when he departed from Rome, left in his hands two unfinished pictures which Raphael completed.

At the beginning of 1508 Bartolomeo moved to Venice to paint a "Holy Father, St. Mary Magdalene and St. Catherine of Siena" for the Dominicans of San Pietro Martire in Murano, influenced somewhat by Venetian colorism. As the Dominicans did not pay for the work, he took it back to Lucca, where it can be seen now. Also in Lucca, in October 1509, he painted with Albertinelli an altarpiece of the "Madonna and Child with Saints" for the local cathedral. On November 26, 1510 Pier Soderini commissioned him an altarpiece for the Sala del Consiglio of Florence, now in the Museum of San Marco. Two years later he finished another altarpiece for the cathedral of Besançon.

In 1513 he went to Rome, where he painted a "Peter and Paul", now in the Pinacoteca Vaticana, while from the following years are the "St. Mark Evangelist" of Palazzo Pitti in Florence and the frescoes in the Dominican convent of Pian di Mugnone, a frazione of Fiesole, just outside Florence. After a promised "Feast of Venus" for Duke Alfonso I d'Este of Ferrara, of which only drawings remain, his last work is a fresco of "Noli me tangere" also in Pian di Mugnone.
He died in Florence in 1517.

Initially, his works showed the influence of Rosselli's assistant, Piero di Cosimo, and those of Domenico Ghirlandaio and Filippino Lippi. After his hiatus from 1500 to 1503, he seemed to change vision, taking from Raphael the representation of light and its effects over moving shapes.

Fra Bartolomeo's figures are generally small and draped. These qualities were alleged against him as defects, and to prove that his style was not the result of want of power, he painted the magnificent figure of the "St Mark Evangelist" (ranked as his masterpiece), and the undraped figure of Saint Sebastian. It is alleged that the latter was felt to be so strongly expressive of suffering and agony, that it was found necessary to remove it from the place where it had been exhibited in the chapel of a convent.

Fra Bartolomeo's compositions are remarkable for skill in the massing of light and shade, richness and delicacy of colouring, and for the admirable drapery of the figures, Bartolomeo having been the first to introduce and use the lay-figure with joints.

Among his pupils were Cecchino del Frate, Benedetto Ciamfanini, Gabriel Rustici, Ridolfo Ghirlandaio (the son of Domenico Ghirlandaio), and Fra Paolo Pistolese.



Attribution:



</doc>
<doc id="11459" url="https://en.wikipedia.org/wiki?curid=11459" title="Frédéric Bazille">
Frédéric Bazille

Jean Frédéric Bazille (December 6, 1841 – November 28, 1870) was a French Impressionist painter. Many of Bazille's major works are examples of figure painting in which he placed the subject figure within a landscape painted "en plein air".

Frédéric Bazille was born in Montpellier, Hérault, Languedoc-Roussillon, France, into a wealthy Protestant family. He became interested in painting after seeing some works of Eugène Delacroix. His family agreed to let him study painting, but only if he also studied medicine.

Bazille began studying medicine in 1859, and moved to Paris in 1862 to continue his studies. There he met Pierre-Auguste Renoir and Alfred Sisley, was drawn to Impressionist painting, and began taking classes in Charles Gleyre's studio. After failing his medical exam in 1864, he began painting full-time. His close friends included Claude Monet, Alfred Sisley, and Édouard Manet. Bazille was generous with his wealth, and helped support his less fortunate associates by giving them space in his studio and materials to use.

Bazille was just twenty-three years old when he painted several of his best-known works, including "The Pink Dress" (c. 1864, Musée d'Orsay, Paris). This painting combines a portrait-like depiction of Bazille's cousin, Thérèse des Hours, who is seen from behind—and the sunlit landscape at which she gazes. His best-known painting is "Family Reunion" of 1867–1868 (Musée d'Orsay, Paris).

Frédéric Bazille joined a Zouave regiment in August 1870, a month after the outbreak of the Franco-Prussian War. On November 28 of that year, he was with his unit at the Battle of Beaune-la-Rolande when, his officer having been injured, he took command and led an assault on the German position. He was hit twice in the failed attack and died on the battlefield at the age of twenty-eight. His father travelled to the battlefield a few days later to take his body back for burial at Montpellier over a week later.






</doc>
<doc id="11460" url="https://en.wikipedia.org/wiki?curid=11460" title="Ford Madox Brown">
Ford Madox Brown

Ford Madox Brown (16 April 1821 – 6 October 1893) was a French-born British painter of moral and historical subjects, notable for his distinctively graphic and often Hogarthian version of the Pre-Raphaelite style. Arguably, his most notable painting was "Work" (1852–1865). Brown spent the latter years of his life painting the twelve works known as "The Manchester Murals", depicting Mancunian history, for Manchester Town Hall.

Brown was the grandson of the medical theorist John Brown, founder of the Brunonian system of medicine. His great grandfather was a Scottish labourer. His father Ford Brown served as a purser in the Royal Navy, including a period serving under Sir Isaac Coffin and a period on HMS "Arethusa". He left the Navy after the end of the Napoleonic Wars.

In 1818, Ford Brown married Caroline Madox, of an old Kentish family, from which his middle name was taken. Brown's parents had limited financial resources, and they moved to Calais to seek cheaper lodgings, where their daughter Elizabeth Coffin was born in 1819 and their son Ford Madox Brown in 1821.

Brown's education was limited, as the family frequently moved between lodgings in the Pas-de-Calais and relatives in Kent, but he showed artistic talent in copying of old master prints. His father initially sought a naval career for his son, writing to his former captain Sir Isaac Coffin. The family moved to Bruges in 1835 so Brown could study at the academy under Albert Gregorius. Brown moved to Ghent in 1836 to continue his studies under Pieter van Hanselaere. He moved to Antwerp in 1837 to study under Gustaf Wappers. He continued to study in Antwerp after his mother's death in 1839. His sister died in 1840, and then his father in 1842.

The Tate Gallery holds an early example of Brown's work, a portrait of his father. He first exhibited at the Royal Academy in 1840, a work inspired by Lord Byron's poem "The Giaour" (now lost) and then completed a version of "The Execution of Mary, Queen of Scots", with his cousin and future wife Elisabeth Bromley as one of his models. He lived in Montmartre with his new wife and aging father in 1841. He painted "Manfred on the Jungfrau", inspired by Lord Byron's poem "Manfred" while he was in Paris.

In 1843 he submitted work to the Westminster Cartoon Competition, for compositions to decorate the new Palace of Westminster. His entry, "The Body of Harold Brought before William", was not successful. His early works were, however, greatly admired by the young Dante Gabriel Rossetti, who asked him to become his tutor. Through Rossetti, Brown came into contact with the artists who went on to form the Pre-Raphaelite Brotherhood. Though closely linked to them, he was never actually a member of the brotherhood itself, but adopted the bright colours and realistic style of William Holman Hunt and John Everett Millais. He was also influenced by the works of Holbein that he saw in Basel in 1845, and by Friedrich Overbeck and Peter Cornelius, whom he met in Rome in 1845-46.

Brown struggled to make his mark in the 1850s, with his paintings failing to find buyers, and he considered emigrating to India. In 1852 he started work on two of his most significant works.

One of his most famous images is "The Last of England", painted from 1852 to 1855, which was sold in March 1859 for 325 Guineas ("2010: £"). It depicts a pair of stricken emigrants as they sail away on the ship that will take them from England forever. It was inspired by the departure of the Pre-Raphaelite sculptor Thomas Woolner, who had left for Australia. In an unusual tondo format, the painting is structured with Brown's characteristic linear energy, and emphasis on apparently grotesque and banal details, such as the cabbages hanging from the ship's side. The husband and wife are portraits of Brown and his second wife Emma.
Brown's most important painting was "Work" (1852–1865), begun in Hampstead in 1852 and which he showed at his retrospective exhibition in 1865. Thomas Plint advanced funds to enable Brown to complete the work, in anticipation of obtaining the finished painting, but died in 1861 before the painting had been completed. In this painting, Brown attempted to depict the totality of the mid-Victorian social experience in a single image, depicting 'navvies' digging up a road (Heath Street in Hampstead, north London) and disrupting the old social hierarchies as they did so. The image erupts into proliferating details from the dynamic centre of the action, as the workers tear a hole in the road – and, symbolically, in the social fabric. Each character represents a particular social class and role in the modern urban environment. 

Brown wrote a catalogue to accompany the special exhibition of "Work". This publication included an extensive explanation of "Work" that nevertheless leaves many questions unanswered. Brown's concern with the social issues addressed in "Work" prompted him to open a soup kitchen for Manchester's hungry, and to attempt to aid the city's unemployed to find work by founding a labour exchange.

Brown found patrons in the north of England, including Plint, George Rae from Birkenhead, John Miller from Liverpool, and James Leathart from Newcastle. By the late 1850s he had lost patience with the poor reception he received at the Royal Academy and ceased to show his works there, rejecting an offer from Millais to support his becoming an associate member. He founded the Hogarth Club in 1858, with William Morris, Edward Burne-Jones, and his former pupil Rossetti. After a successful period of a few years, the club reached over 80 members, including several prominent members of the Royal Academy, but Brown resigned in 1860, and the club collapsed in 1861.

From the 1860s, Brown also designed furniture and stained glass. He was a founder partner of William Morris's design company, Morris, Marshall, Faulkner & Co., in 1861, which dissolved in 1874 with Morris continuing on his own. He was a close friend of the landscape artist Henry Mark Anthony.

Brown's major achievement after "Work" was "The Manchester Murals", a cycle of twelve paintings in the Great Hall of Manchester Town Hall depicting the history of the city. Brown would be 72 by the time he finished the murals. In total, he took six years perfecting the murals, which were his last major work.

Ford Madox Brown was married twice. His first wife Elizabeth Bromley was his first cousin, the daughter of his mother's sister Mary. They were married in Meopham in Kent in April 1841, shortly before his 20th birthday and less than a year after the sudden death of his sister Elizabeth. They lived in Montmartre in 1841 with Brown's invalid father who died the following summer.

Their first child died young as an infant in November 1842. Their daughter Emma Lucy was born in 1843 and the family moved back to England in 1844. They travelled to Rome in 1845 to alleviate the illness of his wife, who was suffering from consumption (pulmonary tuberculosis). She died in Paris in June 1846, aged 27, on the journey back to England from Rome.

Emma Hill became a frequent model for Brown from 1848; for example, she is the wife in "The Last of England". She became his mistress, and they shared a house in London, but social convention made him unable to marry an illiterate daughter of a bricklayer. Their daughter Catherine Emily was born in 1850, and eventually they were married at St Dunstan-in-the-West in April 1853.

Their son, Oliver Madox Brown (1855–1874) (known as Nolly) showed promise both as an artist and poet, but died of blood poisoning before his maturity. The death of Nolly was a crushing blow for Brown, and he kept a room for his son's belongings as a shrine. Another son Arthur was born in September 1856. Brown used Arthur as the model for the baby held by a ragged girl in the foreground of "Work", but he died aged only ten months old in July 1857.

His daughters Lucy and Catherine were also competent artists. Lucy married William Michael Rossetti in 1874. Catherine, married Francis Hueffer; through Catherine, Brown was the grandfather of novelist Ford Madox Ford and great-grandfather of Labour Home Secretary Frank Soskice.

Brown's second wife died in October 1890, and he died in Primrose Hill, north London, in 1893. He is buried in the St Pancras and Islington Cemetery in East Finchley. He was given a secular funeral, and the funeral oration was delivered by the American Moncure D. Conway, the secularist after whom Conway Hall was later named.

The J D Wetherspoon pub in Oxford Road, Manchester is named after Ford Madox Brown. It states on the Wetherspoon's website that "This J D Wetherspoon pub is named after the much-travelled artist Ford Madox Brown, a one-time resident of Victoria Park, a suburb south of the pub." The pub opened in 2007.





</doc>
<doc id="11461" url="https://en.wikipedia.org/wiki?curid=11461" title="Francis Crick">
Francis Crick

Francis Harry Compton Crick (8 June 1916 – 28 July 2004) was a British molecular biologist, biophysicist, and neuroscientist. In 1953, he co-authored with James Watson the academic paper proposing the double helix structure of the DNA molecule. Together with Watson and Maurice Wilkins, he was jointly awarded the 1962 Nobel Prize in Physiology or Medicine "for their discoveries concerning the molecular structure of nucleic acids and its significance for information transfer in living material". The results were based partly on fundamental studies done by Rosalind Franklin, Raymond Gosling and Wilkins.

Crick was an important theoretical molecular biologist and played a crucial role in research related to revealing the helical structure of DNA. He is widely known for the use of the term "central dogma" to summarize the idea that once information is transferred from nucleic acids (DNA or RNA) to proteins, it cannot flow back to nucleic acids. In other words, the final step in the flow of information from nucleic acids to proteins is irreversible.

During the remainder of his career, he held the post of J.W. Kieckhefer Distinguished Research Professor at the Salk Institute for Biological Studies in La Jolla, California. His later research centered on theoretical neurobiology and attempts to advance the scientific study of human consciousness. He remained in this post until his death; "he was editing a manuscript on his death bed, a scientist until the bitter end" according to Christof Koch.

Crick was the first son of Harry Crick (1887–1948) and Annie Elizabeth Crick (née Wilkins; 1879–1955). He was born on 8 June 1916 and raised in Weston Favell, then a small village near the English town of Northampton, in which Crick's father and uncle ran the family's boot and shoe factory. His grandfather, Walter Drawbridge Crick (1857–1903), an amateur naturalist, wrote a survey of local foraminifera (single-celled protists with shells), corresponded with Charles Darwin, and had two gastropods (snails or slugs) named after him.

At an early age, Francis was attracted to science and what he could learn about it from books. As a child, he was taken to church by his parents. But by about age 12, he said he did not want to go anymore, as he preferred a scientific search for answers over religious belief.

Walter Crick, his uncle, lived in a small house on the south side of Abington Avenue; he had a shed at the bottom of his little garden where he taught Crick to blow glass, do chemical experiments and to make photographic prints. When he was eight or nine he transferred to the most junior form of the Northampton Grammar School, on the Billing Road. This was about from his home so he could walk there and back, by Park Avenue South and Abington Park Crescent, but he more often went by bus or, later, by bicycle. The teacher – a Miss Holding – was an inspired teacher and made everything interesting. The teaching in the higher forms was satisfactory, but not as stimulating. After the age of 14, he was educated at Mill Hill School in London (on scholarship), where he studied mathematics, physics, and chemistry with his best friend John Shilston. He shared the Walter Knox Prize for Chemistry on Mill Hill School's Foundation Day, Friday, 7 July 1933. He declared that his success was inspired by the quality of teaching he received whilst a pupil at Mill Hill.

At the age of 21, Crick earned a Bachelor of Science degree in physics from University College, London. Crick had failed to gain a place at a Cambridge college, probably through failing their requirement for Latin. Crick began his PhD at UCL but was interrupted by World War II. He later became a PhD student and Honorary Fellow of Gonville and Caius College, Cambridge and mainly worked at the Cavendish Laboratory and the Medical Research Council (MRC) Laboratory of Molecular Biology in Cambridge. He was also an Honorary Fellow of Churchill College, Cambridge and of University College, London.

Crick began a Ph.D. research project on measuring the viscosity of water at high temperatures (which he later described as "the dullest problem imaginable") in the laboratory of physicist Edward Neville da Costa Andrade at University College London, but with the outbreak of World War II (in particular, an incident during the Battle of Britain when a bomb fell through the roof of the laboratory and destroyed his experimental apparatus), Crick was deflected from a possible career in physics. During his second year as a PhD student, however, he was awarded the Carey Foster Research Prize, a great honour. He did postdoctoral work at the Polytechnic Institute of Brooklyn.

During World War II, he worked for the Admiralty Research Laboratory, from which emerged a group of many notable scientists, including David Bates, Robert Boyd, George Deacon, John Gunn, Harrie Massey, and Nevill Mott; he worked on the design of magnetic and acoustic mines, and was instrumental in designing a new mine that was effective against German minesweepers.

In 1947, aged 31, Crick began studying biology and became part of an important migration of physical scientists into biology research. This migration was made possible by the newly won influence of physicists such as Sir John Randall, who had helped win the war with inventions such as radar. Crick had to adjust from the "elegance and deep simplicity" of physics to the "elaborate chemical mechanisms that natural selection had evolved over billions of years." He described this transition as, "almost as if one had to be born again." According to Crick, the experience of learning physics had taught him something important—hubris—and the conviction that since physics was already a success, great advances should also be possible in other sciences such as biology. Crick felt that this attitude encouraged him to be more daring than typical biologists who tended to concern themselves with the daunting problems of biology and not the past successes of physics.

For the better part of two years, Crick worked on the physical properties of cytoplasm at Cambridge's Strangeways Research Laboratory, headed by Honor Bridget Fell, with a Medical Research Council studentship, until he joined Max Perutz and John Kendrew at the Cavendish Laboratory. The Cavendish Laboratory at Cambridge was under the general direction of Sir Lawrence Bragg, who had won the Nobel Prize in 1915 at the age of 25. Bragg was influential in the effort to beat a leading American chemist, Linus Pauling, to the discovery of DNA's structure (after having been pipped at the post by Pauling's success in determining the alpha helix structure of proteins). At the same time Bragg's Cavendish Laboratory was also effectively competing with King's College London, whose Biophysics department was under the direction of Randall. (Randall had refused Crick's application to work at King's College.) Francis Crick and Maurice Wilkins of King's College were personal friends, which influenced subsequent scientific events as much as the close friendship between Crick and James Watson. Crick and Wilkins first met at King's College and not, as erroneously recorded by two authors, at the Admiralty during World War II.

Crick married twice, fathered three children and was the grandfather of six grandchildren; his brother Anthony (born in 1918) predeceased him in 1966.

Spouses:

Children:

Grandchildren


Crick died of colon cancer on the morning of 28 July 2004 at the University of California, San Diego (UCSD) Thornton Hospital in La Jolla; he was cremated and his ashes were scattered into the Pacific Ocean. A public memorial was held on 27 September 2004 at the Salk Institute, La Jolla, near San Diego, California; guest speakers included James Watson, Sydney Brenner, Alex Rich, Seymour Benzer, Aaron Klug, Christof Koch, Pat Churchland, Vilayanur Ramachandran, Tomaso Poggio, Leslie Orgel, Terry Sejnowski, his son Michael Crick, and his youngest daughter Jacqueline Nichols. A private memorial for family and colleagues was held on 3 August 2004.

Crick was interested in two fundamental unsolved problems of biology: how molecules make the transition from the non-living to the living, and how the brain makes a conscious mind. He realized that his background made him more qualified for research on the first topic and the field of biophysics. It was at this time of Crick's transition from physics to biology that he was influenced by both Linus Pauling and Erwin Schrödinger. It was clear in theory that covalent bonds in biological molecules could provide the structural stability needed to hold genetic information in cells. It only remained as an exercise of experimental biology to discover exactly which molecule was the genetic molecule. In Crick's view, Charles Darwin's theory of evolution by natural selection, Gregor Mendel's genetics and knowledge of the molecular basis of genetics, when combined, revealed the secret of life. Crick had the very optimistic view that life would very soon be created in a test tube. However, some people (such as fellow researcher and colleague Esther Lederberg) thought that Crick was unduly optimistic 

It was clear that some macromolecule such as a protein was likely to be the genetic molecule. However, it was well known that proteins are structural and functional macromolecules, some of which carry out enzymatic reactions of cells. In the 1940s, some evidence had been found pointing to another macromolecule, DNA, the other major component of chromosomes, as a candidate genetic molecule. In the 1944 Avery-MacLeod-McCarty experiment, Oswald Avery and his collaborators showed that a heritable phenotypic difference could be caused in bacteria by providing them with a particular DNA molecule.

However, other evidence was interpreted as suggesting that DNA was structurally uninteresting and possibly just a molecular scaffold for the apparently more interesting protein molecules. Crick was in the right place, in the right frame of mind, at the right time (1949), to join Max Perutz's project at the University of Cambridge, and he began to work on the X-ray crystallography of proteins. X-ray crystallography theoretically offered the opportunity to reveal the molecular structure of large molecules like proteins and DNA, but there were serious technical problems then preventing X-ray crystallography from being applicable to such large molecules.

Crick taught himself the mathematical theory of X-ray crystallography. During the period of Crick's study of X-ray diffraction, researchers in the Cambridge lab were attempting to determine the most stable helical conformation of amino acid chains in proteins (the alpha helix). Linus Pauling was the first to identify the 3.6 amino acids per helix turn ratio of the alpha helix. Crick was witness to the kinds of errors that his co-workers made in their failed attempts to make a correct molecular model of the alpha helix; these turned out to be important lessons that could be applied, in the future, to the helical structure of DNA. For example, he learned the importance of the structural rigidity that double bonds confer on molecular structures which is relevant both to peptide bonds in proteins and the structure of nucleotides in DNA.

In 1951 and 1952, together with William Cochran and Vladimir Vand, Crick assisted in the development of a mathematical theory of X-ray diffraction by a helical molecule. This theoretical result matched well with X-ray data for proteins that contain sequences of amino acids in the alpha helix conformation. Helical diffraction theory turned out to also be useful for understanding the structure of DNA.

Late in 1951, Crick started working with James Watson at Cavendish Laboratory at the University of Cambridge, England. Using "Photo 51" (the X-ray diffraction results of Rosalind Franklin and her graduate student Raymond Gosling of King's College London, given to them by Gosling and Franklin's colleague Wilkins), Watson and Crick together developed a model for a helical structure of DNA, which they published in 1953. For this and subsequent work they were jointly awarded the Nobel Prize in Physiology or Medicine in 1962 with Wilkins.

When Watson came to Cambridge, Crick was a 35-year-old graduate student (due to his work during WWII) and Watson was only 23, but he already had a Ph.D. They shared an interest in the fundamental problem of learning how genetic information might be stored in molecular form. Watson and Crick talked endlessly about DNA and the idea that it might be possible to guess a good molecular model of its structure. A key piece of experimentally-derived information came from X-ray diffraction images that had been obtained by Wilkins, Franklin, and Gosling. In November 1951, Wilkins came to Cambridge and shared his data with Watson and Crick. Alexander Stokes (another expert in helical diffraction theory) and Wilkins (both at King's College) had reached the conclusion that X-ray diffraction data for DNA indicated that the molecule had a helical structure—but Franklin vehemently disputed this conclusion. Stimulated by their discussions with Wilkins and what Watson learned by attending a talk given by Franklin about her work on DNA, Crick and Watson produced and showed off an erroneous first model of DNA. Their hurry to produce a model of DNA structure was driven in part by the knowledge that they were competing against Linus Pauling. Given Pauling's recent success in discovering the Alpha helix, they feared that Pauling might also be the first to determine the structure of DNA.

Many have speculated about what might have happened had Pauling been able to travel to Britain as planned in May 1952. As it was, his political activities caused his travel to be restricted by the United States government and he did not visit the UK until later, at which point he met none of the DNA researchers in England. At any rate he was preoccupied with proteins at the time, not DNA. Watson and Crick were not officially working on DNA. Crick was writing his Ph.D. thesis; Watson also had other work such as trying to obtain crystals of myoglobin for X-ray diffraction experiments. In 1952, Watson performed X-ray diffraction on tobacco mosaic virus and found results indicating that it had helical structure. Having failed once, Watson and Crick were now somewhat reluctant to try again and for a while they were forbidden to make further efforts to find a molecular model of DNA.
Of great importance to the model building effort of Watson and Crick was Rosalind Franklin's understanding of basic chemistry, which indicated that the hydrophilic phosphate-containing backbones of the nucleotide chains of DNA should be positioned so as to interact with water molecules on the outside of the molecule while the hydrophobic bases should be packed into the core. Franklin shared this chemical knowledge with Watson and Crick when she pointed out to them that their first model (from 1951, with the phosphates inside) was obviously wrong.

Crick described what he saw as the failure of Wilkins and Franklin to cooperate and work towards finding a molecular model of DNA as a major reason why he and Watson eventually made a second attempt to do so. They asked for, and received, permission to do so from both William Lawrence Bragg and Wilkins. In order to construct their model of DNA, Watson and Crick made use of information from unpublished X-ray diffraction images of Franklin's (shown at meetings and freely shared by Wilkins), including preliminary accounts of Franklin's results/photographs of the X-ray images that were included in a written progress report for the King's College laboratory of Sir John Randall from late 1952.

It is a matter of debate whether Watson and Crick should have had access to Franklin's results without her knowledge or permission, and before she had a chance to formally publish the results of her detailed analysis of her X-ray diffraction data which were included in the progress report. However, Watson and Crick found fault in her steadfast assertion that, according to her data, a helical structure was not the only possible shape for DNA—so they had a dilemma. In an effort to clarify this issue, Max Ferdinand Perutz later published what had been in the progress report, and suggested that nothing was in the report that Franklin herself had not said in her talk (attended by Watson) in late 1951. Further, Perutz explained that the report was to a Medical Research Council (MRC) committee that had been created in order to "establish contact between the different groups of people working for the Council". Randall's and Perutz's laboratories were both funded by the MRC.

It is also not clear how important Franklin's unpublished results from the progress report actually were for the model-building done by Watson and Crick. After the first crude X-ray diffraction images of DNA were collected in the 1930s, William Astbury had talked about stacks of nucleotides spaced at 3.4 angström (0.34 nanometre) intervals in DNA. A citation to Astbury's earlier X-ray diffraction work was one of only eight references in Franklin's first paper on DNA. Analysis of Astbury's published DNA results and the better X-ray diffraction images collected by Wilkins and Franklin revealed the helical nature of DNA. It was possible to predict the number of bases stacked within a single turn of the DNA helix (10 per turn; a full turn of the helix is 27 angströms [2.7 nm] in the compact A form, 34 angströms [3.4 nm] in the wetter B form). Wilkins shared this information about the B form of DNA with Crick and Watson. Crick did not see Franklin's B form X-ray images (Photo 51) until after the DNA double helix model was published.

One of the few references cited by Watson and Crick when they published their model of DNA was to a published article that included Sven Furberg's DNA model that had the bases on the inside. Thus, the Watson and Crick model was not the first "bases in" model to be proposed. Furberg's results had also provided the correct orientation of the DNA sugars with respect to the bases. During their model building, Crick and Watson learned that an antiparallel orientation of the two nucleotide chain backbones worked best to orient the base pairs in the centre of a double helix. Crick's access to Franklin's progress report of late 1952 is what made Crick confident that DNA was a double helix with antiparallel chains, but there were other chains of reasoning and sources of information that also led to these conclusions.

As a result of leaving King's College for Birkbeck College, Franklin was asked by John Randall to give up her work on DNA. When it became clear to Wilkins and the supervisors of Watson and Crick that Franklin was going to the new job, and that Linus Pauling was working on the structure of DNA, they were willing to share Franklin's data with Watson and Crick, in the hope that they could find a good model of DNA before Pauling was able. Franklin's X-ray diffraction data for DNA and her systematic analysis of DNA's structural features was useful to Watson and Crick in guiding them towards a correct molecular model. The key problem for Watson and Crick, which could not be resolved by the data from King's College, was to guess how the nucleotide bases pack into the core of the DNA double helix.
Another key to finding the correct structure of DNA was the so-called Chargaff ratios, experimentally determined ratios of the nucleotide subunits of DNA: the amount of guanine is equal to cytosine and the amount of adenine is equal to thymine. A visit by Erwin Chargaff to England, in 1952, reinforced the salience of this important fact for Watson and Crick. The significance of these ratios for the structure of DNA were not recognized until Watson, persisting in building structural models, realized that A:T and C:G pairs are structurally similar. In particular, the length of each base pair is the same. Chargaff had also pointed out to Watson that, in the aqueous, saline environment of the cell, the predominant tautomers of the pyrimidine (C and T) bases would be the amine and keto configurations of cytosine and thymine, rather than the imino and enol forms that Crick and Watson had assumed. They consulted Jerry Donohue who confirmed the most likely structures of the nucleotide bases. The base pairs are held together by hydrogen bonds, the same non-covalent interaction that stabilize the protein α-helix. The correct structures were essential for the positioning of the hydrogen bonds. These insights led Watson to deduce the true biological relationships of the A:T and C:G pairs. After the discovery of the hydrogen bonded A:T and C:G pairs, Watson and Crick soon had their anti-parallel, double helical model of DNA, with the hydrogen bonds at the core of the helix providing a way to "unzip" the two complementary strands for easy replication: the last key requirement for a likely model of the genetic molecule. As important as Crick's contributions to the discovery of the double helical DNA model were, he stated that without the chance to collaborate with Watson, he would not have found the structure by himself.

Crick did tentatively attempt to perform some experiments on nucleotide base pairing, but he was more of a theoretical biologist than an experimental biologist. There was another near-discovery of the base pairing rules in early 1952. Crick had started to think about interactions between the bases. He asked John Griffith to try to calculate attractive interactions between the DNA bases from chemical principles and quantum mechanics. Griffith's best guess was that A:T and G:C were attractive pairs. At that time, Crick was not aware of Chargaff's rules and he made little of Griffith's calculations, although it did start him thinking about complementary replication. Identification of the correct base-pairing rules (A-T, G-C) was achieved by Watson "playing" with cardboard cut-out models of the nucleotide bases, much in the manner that Linus Pauling had discovered the protein alpha helix a few years earlier. The Watson and Crick discovery of the DNA double helix structure was made possible by their willingness to combine theory, modelling and experimental results (albeit mostly done by others) to achieve their goal.

The DNA double helix structure proposed by Watson and Crick was based upon "Watson-Crick" bonds between the four bases most frequently found in DNA (A, C, T, G) and RNA (A, C, U, G). However, later research showed that triple-stranded, quadruple-stranded and other more complex DNA molecular structures required Hoogsteen base pairing. The entire field of synthetic biology began with work by researchers such as Erik T. Kool, in which bases other than A, C, T and G are used in a synthetic DNA. In addition to synthetic DNA there are also attempts to construct synthetic codons, synthetic endonucleases, synthetic proteins and synthetic zinc fingers. Using synthetic DNA, instead of there being 4 codons, if there are n new bases there could be as many as n codons. Research is currently being done to see if codons can be expanded to more than 3 bases. These new codons can code for new amino acids. These synthetic molecules can be used not only in medicine, but in creation of new materials.

The discovery was made on 28 February 1953; the first Watson/Crick paper appeared in "Nature" on 25 April 1953. Sir Lawrence Bragg, the director of the Cavendish Laboratory, where Watson and Crick worked, gave a talk at Guy's Hospital Medical School in London on Thursday 14 May 1953 which resulted in an article by Ritchie Calder in the "News Chronicle" of London, on Friday 15 May 1953, entitled "Why You Are You. Nearer Secret of Life." The news reached readers of "The New York Times" the next day; Victor K. McElheny, in researching his biography, "Watson and DNA: Making a Scientific Revolution", found a clipping of a six-paragraph New York Times article written from London and dated 16 May 1953 with the headline "Form of 'Life Unit' in Cell Is Scanned." The article ran in an early edition and was then pulled to make space for news deemed more important. ("The New York Times" subsequently ran a longer article on 12 June 1953). The university's undergraduate newspaper "Varsity" also ran its own short article on the discovery on Saturday 30 May 1953. Bragg's original announcement of the discovery at a Solvay conference on proteins in Belgium on 8 April 1953 went unreported by the British press.

In a seven-page, handwritten letter to his son at a British boarding school on 19 March 1953 Crick explained his discovery, beginning the letter ""My Dear Michael, Jim Watson and I have probably made a most important discovery..."". The letter was put up for auction at Christie's New York on 10 April 2013 with an estimate of $1 to $2 million, eventually selling for $6,059,750, the largest amount ever paid for a letter at auction.

Sydney Brenner, Jack Dunitz, Dorothy Hodgkin, Leslie Orgel, and Beryl M. Oughton, were some of the first people in April 1953 to see the model of the structure of DNA, constructed by Crick and Watson; at the time they were working at Oxford University's Chemistry Department. All were impressed by the new DNA model, especially Brenner who subsequently worked with Crick at Cambridge in the Cavendish Laboratory and the new Laboratory of Molecular Biology. According to the late Dr. Beryl Oughton, later Rimmer, they all travelled together in two cars once Dorothy Hodgkin announced to them that they were off to Cambridge to see the model of the structure of DNA. Orgel also later worked with Crick at the Salk Institute for Biological Studies.

Soon after Crick's death, there have been allegations about him having used LSD when he came to the idea of the helix structure of the DNA. While he almost certainly did use LSD, it is unlikely that he was doing that as early as 1953.

In 1954, at the age of 37, Crick completed his Ph.D. thesis: ""X-Ray Diffraction: Polypeptides and Proteins"" and received his degree. Crick then worked in the laboratory of David Harker at Brooklyn Polytechnic Institute, where he continued to develop his skills in the analysis of X-ray diffraction data for proteins, working primarily on ribonuclease and the mechanisms of protein synthesis. David Harker, the American X-ray crystallographer, was described as "the John Wayne of crystallography" by Vittorio Luzzati, a crystallographer at the Centre for Molecular Genetics in Gif-sur-Yvette near Paris, who had worked with Rosalind Franklin.

After the discovery of the double helix model of DNA, Crick's interests quickly turned to the biological implications of the structure. In 1953, Watson and Crick published another article in "Nature" which stated: "it therefore seems likely that the precise sequence of the bases is the code that carries the genetical information".

In 1956, Crick and Watson speculated on the structure of small viruses. They suggested that spherical viruses such as Tomato bushy stunt virus had icosahedral symmetry and were made from 60 identical subunits.

After his short time in New York, Crick returned to Cambridge where he worked until 1976, at which time he moved to California. Crick engaged in several X-ray diffraction collaborations such as one with Alexander Rich on the structure of collagen. However, Crick was quickly drifting away from continued work related to his expertise in the interpretation of X-ray diffraction patterns of proteins.

George Gamow established a group of scientists interested in the role of RNA as an intermediary between DNA as the genetic storage molecule in the nucleus of cells and the synthesis of proteins in the cytoplasm (the RNA Tie Club). It was clear to Crick that there had to be a code by which a short sequence of nucleotides would specify a particular amino acid in a newly synthesized protein. In 1956, Crick wrote an informal paper about the genetic coding problem for the small group of scientists in Gamow's RNA group. In this article, Crick reviewed the evidence supporting the idea that there was a common set of about 20 amino acids used to synthesize proteins. Crick proposed that there was a corresponding set of small "adaptor molecules" that would hydrogen bond to short sequences of a nucleic acid, and also link to one of the amino acids. He also explored the many theoretical possibilities by which short nucleic acid sequences might code for the 20 amino acids.
During the mid-to-late 1950s Crick was very much intellectually engaged in sorting out the mystery of how proteins are synthesized. By 1958, Crick's thinking had matured and he could list in an orderly way all of the key features of the protein synthesis process:

The adaptor molecules were eventually shown to be tRNAs and the catalytic "ribonucleic-protein complexes" became known as ribosomes. An important step was later realization (in 1960) that the messenger RNA was not the same as the ribosomal RNA. None of this, however, answered the fundamental theoretical question of the exact nature of the genetic code. In his 1958 article, Crick speculated, as had others, that a triplet of nucleotides could code for an amino acid. Such a code might be "degenerate", with 4×4×4=64 possible triplets of the four nucleotide subunits while there were only 20 amino acids. Some amino acids might have multiple triplet codes. Crick also explored other codes in which, for various reasons, only some of the triplets were used, "magically" producing just the 20 needed combinations. Experimental results were needed; theory alone could not decide the nature of the code. Crick also used the term "central dogma" to summarize an idea that implies that genetic information flow between macromolecules would be essentially one-way:

Some critics thought that by using the word "dogma", Crick was implying that this was a rule that could not be questioned, but all he really meant was that it was a compelling idea without much solid evidence to support it. In his thinking about the biological processes linking DNA genes to proteins, Crick made explicit the distinction between the materials involved, the energy required, and the information flow. Crick was focused on this third component (information) and it became the organizing principle of what became known as molecular biology. Crick had by this time become a highly influential theoretical molecular biologist.

Proof that the genetic code is a degenerate triplet code finally came from genetics experiments, some of which were performed by Crick. The details of the code came mostly from work by Marshall Nirenberg and others who synthesized synthetic RNA molecules and used them as templates for "in vitro" protein synthesis. Nirenberg first announced his results to a small audience in Moscow at a 1961 conference. Crick's reaction was to invite Nirenberg to deliver his talk to a larger audience.

An enduring controversy has been generated by Watson and Crick's use of DNA X-ray diffraction data collected by Franklin and Wilkins. The controversy arose from the fact that some of Franklin's unpublished data were used without her knowledge or consent by Watson and Crick in their construction of the double helix model of DNA. Of the four DNA researchers, only Franklin had a degree in chemistry; Wilkins and Crick had backgrounds in physics, Watson in biology.

Prior to publication of the double helix structure, Watson and Crick had little direct interaction with Franklin herself. They were, however, aware of her work, more aware than she herself realized. Watson was present at a lecture, given in November 1951, where Franklin presented the two forms of the molecule, type A and type B, and discussed the position of the phosphate units on the external part of the molecule. She also specified the amount of water to be found in the molecule in accordance with other parts of it, data that have considerable importance in terms of the stability of the molecule. She was the first to discover and formulate these facts, which in fact constituted the basis for all later attempts to build a model of the molecule. Before this, both Linus Pauling and Watson and Crick had generated erroneous models with the chains inside and the bases pointing outwards. Her identification of the space group for DNA crystals revealed to Crick that the two DNA strands were antiparallel.

In January 1953, Watson was shown an X-ray photograph of B-DNA (called photograph 51), by Wilkins. Wilkins had been given photograph 51 by Rosalind Franklin's Ph.D. student Raymond Gosling. Wilkins and Gosling had worked together in the Medical Research Council's (MRC) Biophysics Unit before director John Randall appointed Franklin to take over both DNA diffraction work and guidance of Gosling's thesis. It appears that Randall did not communicate effectively with them about Franklin's appointment, contributing to confusion and friction between Wilkins and Franklin.

In the middle of February 1953, Crick's thesis advisor, Max Perutz, gave Crick a copy of a report written for a Medical Research Council biophysics committee visit to King's in December 1952, containing data from the King's group, including some of Franklin's crystallographic calculations.

Franklin was unaware that photograph 51 and other information had been shared with Crick and Watson. She wrote a series of three draft manuscripts, two of which included a double helical DNA backbone. Her two A form manuscripts reached Acta Crystallographica in Copenhagen on 6 March 1953, one day before Crick and Watson had completed their model.

The X-ray diffraction images collected by Gosling and Franklin provided the best evidence for the helical nature of DNA. Franklin's experimental work thus proved crucial in Watson and Crick's discovery. Her experimental results provided estimates of the water content of DNA crystals, and these results were most consistent with the three sugar-phosphate backbones being on the outside of the molecule. Franklin's X-Ray photograph showed that the backbones had to be on the outside. Although she at first insisted vehemently that her data did not force one to conclude that DNA has a helical structure, in the drafts she submitted in 1953 she argues for a double helical DNA backbone. Her identification of the space group for DNA crystals revealed to Crick that the DNA strands were antiparallel, which helped Watson and Crick decide to look for DNA models with two antiparallel polynucleotide strands.

In summary, Watson and Crick had three sources for Franklin's unpublished data: 1) her 1951 seminar, attended by Watson, 2) discussions with Wilkins, who worked in the same laboratory with Franklin, 3) a research progress report that was intended to promote coordination of Medical Research Council-supported laboratories. Watson, Crick, Wilkins and Franklin all worked in MRC laboratories.

Crick and Watson felt that they had benefited from collaborating with Wilkins. They offered him a co-authorship on the article that first described the double helix structure of DNA. Wilkins turned down the offer, a fact that may have led to the terse character of the acknowledgement of experimental work done at King's College in the eventual published paper. Rather than make any of the DNA researchers at King's College co-authors on the Watson and Crick double helix article, the solution that was arrived at was to publish two additional papers from King's College along with the helix paper. Brenda Maddox suggests that because of the importance of her experimental results in Watson and Crick's model building and theoretical analysis, Franklin should have had her name on the original Watson and Crick paper in "Nature". Franklin and Gosling submitted their own joint 'second' paper to "Nature" at the same time as Wilkins, Stokes, and Wilson submitted theirs (i.e. the 'third' paper on DNA).

Watson's portrayal of Franklin in "The Double Helix" (written after Franklin's death when libel laws did not apply anymore) was negative and gave the appearance that she was Wilkins' assistant and was unable to interpret her own DNA data.

The X-ray diffraction images collected by Franklin provided the best evidence for the helical nature of DNA. While Franklin's experimental work proved important to Crick and Watson's development of a correct model, she herself could not realize it at the time. When she left King's College, Director Sir John Randall insisted that all DNA work belonged exclusively to King's and ordered Franklin to not even think about it. Franklin subsequently did superb work in J. D. Bernal's Lab at Birkbeck College with the tobacco mosaic virus extending ideas on helical construction.

Crick was often described as very talkative, with Watson – in "The Double Helix" – implying lack of modesty. His personality combined with his scientific accomplishments produced many opportunities for Crick to stimulate reactions from others, both inside and outside the scientific world, which was the centre of his intellectual and professional life. Crick spoke rapidly, and rather loudly, and had an infectious and reverberating laugh, and a lively sense of humour. One colleague from the Salk Institute described him as "a brainstorming intellectual powerhouse with a mischievous smile... Francis was never mean-spirited, just incisive. He detected microscopic flaws in logic. In a room full of smart scientists, Francis continually reearned his position as the heavyweight champ."

Crick occasionally expressed his views on eugenics, usually in private letters. For example, Crick advocated a form of positive eugenics in which wealthy parents would be encouraged to have more children. He once remarked, "In the long run, it is unavoidable that society will begin to worry about the character of the next generation... It is not a subject at the moment which we can tackle easily because people have so many religious beliefs and until we have a more uniform view of ourselves I think it would be risky to try and do anything in the way of eugenics... I would be astonished if, in the next 100 or 200 years, society did not come round to the view that they would have to try to improve the next generation in some extent or one way or another."

Crick referred to himself as a humanist, which he defined as the belief "that human problems can and must be faced in terms of human moral and intellectual resources without invoking supernatural authority." He publicly called for humanism to replace religion as a guiding force for humanity, writing:

The human dilemma is hardly new. We find ourselves through no wish of our own on this slowly revolving planet in an obscure corner of a vast universe. Our questioning intelligence will not let us live in cow-like content with our lot. We have a deep need to know why we are here. What is the world made of? More important, what are we made of? In the past religion answered these questions, often in considerable detail. Now we know that almost all these answers are highly likely to be nonsense, having sprung from man's ignorance and his enormous capacity for self-deception... The simple fables of the religions of the world have come to seem like tales told to children. Even understood symbolically they are often perverse, if not rather unpleasant... Humanists, then, live in a mysterious, exciting and intellectually expanding world, which, once glimpsed, makes the old worlds of the religions seem fake-cosy and stale... 

Crick was especially critical of Christianity:

I do not respect Christian beliefs. I think they are ridiculous. If we could get rid of them we could more easily get down to the serious problem of trying to find out what the world is all about.

Crick once joked, "Christianity may be OK between consenting adults in private but should not be taught to young children."

In his book "Of Molecules and Men", Crick expressed his views on the relationship between science and religion. After suggesting that it would become possible for a computer to be programmed so as to have a soul, he wondered: at what point during biological evolution did the first organism have a soul? At what moment does a baby get a soul? Crick stated his view that the idea of a non-material soul that could enter a body and then persist after death is just that, an imagined idea. For Crick, the mind is a product of physical brain activity and the brain had evolved by natural means over millions of years. He felt that it was important that evolution by natural selection be taught in schools and that it was regrettable that English schools had compulsory religious instruction. He also considered that a new scientific world view was rapidly being established, and predicted that once the detailed workings of the brain were eventually revealed, erroneous Christian concepts about the nature of humans and the world would no longer be tenable; traditional conceptions of the "soul" would be replaced by a new understanding of the physical basis of mind. He was sceptical of organized religion, referring to himself as a sceptic and an agnostic with "a strong inclination towards atheism".

In 1960, Crick accepted an honorary fellowship at Churchill College, Cambridge, one factor being that the new college did not have a chapel. Some time later a large donation was made to establish a chapel and the College Council decided to accept it. Crick resigned his fellowship in protest.

In October 1969 Crick participated in a celebration of the 100th year of the journal "Nature" in which he attempted to make some predictions about what the next 30 years would hold for molecular biology. His speculations were later published in "Nature". Near the end of the article, Crick briefly mentioned the search for life on other planets, but he held little hope that extraterrestrial life would be found by the year 2000. He also discussed what he described as a possible new direction for research, what he called "biochemical theology". Crick wrote "so many people pray that one finds it hard to believe that they do not get some satisfaction from it".

Crick suggested that it might be possible to find chemical changes in the brain that were molecular correlates of the act of prayer. He speculated that there might be a detectable change in the level of some neurotransmitter or neurohormone when people pray. He might have been imagining substances such as dopamine that are released by the brain under certain conditions and produce rewarding sensations. Crick's suggestion that there might someday be a new science of "biochemical theology" seems to have been realized under an alternative name: there is now the new field of neurotheology. Crick's view of the relationship between science and religion continued to play a role in his work as he made the transition from molecular biology research into theoretical neuroscience.

Crick asked in 1998 "and if some of the Bible is manifestly wrong, why should any of the rest of it be accepted automatically? ... And what would be more important than to find our true place in the universe by removing one by one these unfortunate vestiges of earlier beliefs?"

In 2003 he was one of 22 Nobel laureates who signed the "Humanist Manifesto".

Crick was a firm critic of Young Earth creationism. In the 1987 United States Supreme Court case "Edwards v. Aguillard", Crick joined a group of other Nobel laureates who advised, "'Creation-science' simply has no place in the public-school science classroom." Crick was also an advocate for the establishment of Darwin Day as a British national holiday.

During the 1960s, Crick became concerned with the origins of the genetic code. In 1966, Crick took the place of Leslie Orgel at a meeting where Orgel was to talk about the origin of life. Crick speculated about possible stages by which an initially simple code with a few amino acid types might have evolved into the more complex code used by existing organisms. At that time, everyone thought of proteins as the only kind of enzymes, and ribozymes had not yet been found. Many molecular biologists were puzzled by the problem of the origin of a protein replicating system that is as complex as that which exists in organisms currently inhabiting Earth. In the early 1970s, Crick and Orgel further speculated about the possibility that the production of living systems from molecules may have been a very rare event in the universe, but once it had developed it could be spread by intelligent life forms using space travel technology, a process they called "directed panspermia". In a retrospective article, Crick and Orgel noted that they had been overly pessimistic about the chances of abiogenesis on Earth when they had assumed that some kind of self-replicating protein system was the molecular origin of life.

In 1976 Crick addressed the origin of protein synthesis in a paper with Sydney Brenner, Aaron Klug, and George Pieczenik. In this paper, they speculate that code constraints on nucleotide sequences allow protein synthesis without the need for a ribosome. It, however, requires a five base binding between the mRNA and tRNA with a flip of the anti-codon creating a triplet coding, even though it is a five-base physical interaction. Thomas H. Jukes pointed out that the code constraints on the mRNA sequence required for this translation mechanism is still preserved.

Crick's period at Cambridge was the pinnacle of his long scientific career, but he left Cambridge in 1977 after 30 years, having been offered (and having refused) the Mastership of Gonville and Caius. James Watson claimed at a Cambridge conference marking the 50th anniversary of the discovery of the structure of DNA in 2003:

Now perhaps it's a pretty well kept secret that one of the most uninspiring acts of the University of Cambridge over this past century was to turn down Francis Crick when he applied to be the Professor of Genetics, in 1958. Now there may have been a series of arguments, which led them to reject Francis. It was really saying, don't push us to the frontier.

The apparently "pretty well kept secret" had already been recorded in Soraya De Chadarevian's "Designs For Life: Molecular Biology After World War II", published by Cambridge University Press in 2002. His major contribution to molecular biology in Cambridge is well documented in "The History of the University of Cambridge: Volume 4 (1870 to 1990)", which was published by CUP in 1992.

According to the University of Cambridge's genetics department official website, the electors of the professorship could not reach consensus, prompting the intervention of then University Vice-Chancellor Lord Adrian. Lord Adrian first offered the professorship to a compromise candidate, Guido Pontecorvo, who refused, and is said to have offered it then to Crick, who also refused.

In 1976, Crick took a sabbatical year at the Salk Institute for Biological Studies in La Jolla, California. Crick had been a nonresident fellow of the Institute since 1960. Crick wrote, "I felt at home in Southern California." After the sabbatical, Crick left Cambridge in order to continue working at the Salk Institute. He was also an adjunct professor at the University of California, San Diego. He taught himself neuroanatomy and studied many other areas of neuroscience research. It took him several years to disengage from molecular biology because exciting discoveries continued to be made, including the discovery of alternative splicing and the discovery of restriction enzymes, which helped make possible genetic engineering. Eventually, in the 1980s, Crick was able to devote his full attention to his other interest, consciousness. His autobiographical book, "", includes a description of why he left molecular biology and switched to neuroscience.

Upon taking up work in theoretical neuroscience, Crick was struck by several things:

Crick hoped he might aid progress in neuroscience by promoting constructive interactions between specialists from the many different subdisciplines concerned with consciousness. He even collaborated with neurophilosophers such as Patricia Churchland. In 1983, as a result of their studies of computer models of neural networks, Crick and Mitchison proposed that the function of REM sleep is to remove certain modes of interactions in networks of cells in the mammalian cerebral cortex; they called this hypothetical process 'reverse learning' or 'unlearning'. In the final phase of his career, Crick established a collaboration with Christof Koch that led to publication of a series of articles on consciousness during the period spanning from 1990 to 2005. Crick made the strategic decision to focus his theoretical investigation of consciousness on how the brain generates visual awareness within a few hundred milliseconds of viewing a scene. Crick and Koch proposed that consciousness seems so mysterious because it involves very short-term memory processes that are as yet poorly understood. Crick also published a book describing how neurobiology had reached a mature enough stage so that consciousness could be the subject of a unified effort to study it at the molecular, cellular and behavioural levels. Crick's book "The Astonishing Hypothesis" made the argument that neuroscience now had the tools required to begin a scientific study of how brains produce conscious experiences. Crick was sceptical about the value of computational models of mental function that are not based on details about brain structure and function.

In addition to his third share of the 1962 Nobel prize for Physiology or Medicine, he received many awards and honours, including the Royal and Copley medals of the Royal Society (1972 and 1975), and also the Order of Merit (on 27 November 1991); he refused an offer of a CBE in 1963, but was often referred to in error as 'Sir Francis Crick' and even on occasions as 'Lord Crick.' He was elected an EMBO Member in 1964.

The award of Nobel prizes to John Kendrew and Max Perutz, and to Crick, Watson, and Wilkins was satirised in a short sketch in the BBC TV programme "That Was The Week That Was" with the Nobel Prizes being referred to as 'The Alfred Nobel Peace Pools.'

The Francis Crick Medal and Lecture was established in 2003 following an endowment by his former colleague, Sydney Brenner, joint winner of the 2002 Nobel Prize in Physiology and Medicine. The lecture is delivered annually in any field of biological sciences, with preference given to the areas in which Francis Crick himself worked. Importantly, the lectureship is aimed at younger scientists, ideally under 40, or whose career progression corresponds to this age. , Crick lectures have been delivered by Julie Ahringer, Dario Alessi, Ewan Birney, Simon Boulton, Jason Chin, Simon Fisher, Matthew Hurles, Gilean McVean, Duncan Odom, Geraint Rees, Sarah Teichmann and Daniel Wolpert.

The Francis Crick Institute is a £660 million biomedical research centre located in north London, United Kingdom. The Francis Crick Institute is a partnership between Cancer Research UK, Imperial College London, King's College London, the Medical Research Council, University College London (UCL) and the Wellcome Trust. Completed in 2016, it is the largest centre for biomedical research and innovation in Europe.

The University of Cambridge Graduate School of Biological, Medical and Veterinary Sciences hosts The Francis Crick Graduate Lectures. The first two lectures were by John Gurdon and Tim Hunt.













</doc>
<doc id="11463" url="https://en.wikipedia.org/wiki?curid=11463" title="Francis van Aarssens">
Francis van Aarssens

Baron Francis van Aarssens or Baron François van Aerssen (27 September 1572 - 27 December 1641), from 1611 on lord of Sommelsdijk, was a diplomat and statesman of the United Provinces.

He was born in Brussels, the son of Cornelis van Aarsens, also a statesman. His talents commended him to the notice of Advocate Johan van Oldenbarnevelt, who sent him, at the age of 26 years, as a diplomatic agent of the states-general to the court of France. He took a considerable part in the negotiations of the Twelve Years' Truce in 1609.

His conduct of affairs having displeased the French king, he was recalled from his post by Oldenbarneveldt in 1614, after the French ambassador Benjamin Aubery du Maurier had demanded Aarsens recall. Such was the hatred he henceforth conceived against his former benefactor, that he did his very utmost to effect Oldebarneveldt's ruin. However, he was not a member of the court that convicted Oldenbarnevelt in the Trial of Oldenbarnevelt, Grotius and Hogerbeets as Chisholm mistakenly reports.

He afterwards became the confidential counselor of Maurice, Prince of Orange, and afterwards of Frederick Henry, Prince of Orange, in their conduct of the foreign affairs of the republic. He was sent on special embassies to Venice, Germany and England, and displayed so much diplomatic skill and finesse that Cardinal Richelieu ranked him among the three greatest politicians of his time. He died, aged 69, in The Hague.



</doc>
<doc id="11464" url="https://en.wikipedia.org/wiki?curid=11464" title="Frigate">
Frigate

A frigate () is a type of warship, having various sizes and roles over the last few centuries.

In the 17th century, a frigate was any warship built for speed and maneuverability, the description often used being "frigate-built". These could be warships carrying their principal batteries of carriage-mounted guns on a single deck or on two decks (with further smaller carriage-mounted guns usually carried on the forecastle and quarterdeck of the vessel). The term was generally used for ships too small to stand in the line of battle, although early line-of-battle ships were frequently referred to as frigates when they were built for speed.

In the 18th century, frigates were full-rigged ships, that is square-rigged on all three masts, they were built for speed and handiness, had a lighter armament than a ship of the line, and were used for patrolling and escort. In the definition adopted by the British Admiralty, they were rated ships of at least 28 guns, carrying their principal armaments upon a single continuous deck – the upper deck – while ships of the line possessed two or more continuous decks bearing batteries of guns.

In the late 19th century (beginning about 1858 with the construction of prototypes by the British and French navies), the armoured frigate was a type of ironclad warship that for a time was the most powerful type of vessel afloat. The term "frigate" was used because such ships still mounted their principal armaments on a single continuous upper deck.

In modern navies, frigates are used to protect other warships and merchant-marine ships, especially as anti-submarine warfare (ASW) combatants for amphibious expeditionary forces, underway replenishment groups, and merchant convoys. Ship classes dubbed "frigates" have also more closely resembled corvettes, destroyers, cruisers and even battleships. Some European navies such as the French, German or Spanish ones use the term "frigate" for both their destroyers and frigates. The rank "frigate captain" derives from the name of this type of ship.

The term "frigate" (Italian: "fregata"; Spanish/Catalan/Portuguese/Sicilian: "fragata"; Dutch: "fregat"; French: "frégate") originated in the Mediterranean in the late 15th century, referring to a lighter galley-type warship with oars, sails and a light armament, built for speed and maneuverability. The etymology of the word remains uncertain, although it may have originated as a corruption of "", a Latin word for an open vessel with no lower deck. "Aphractus", in turn, derived from the Ancient Greek phrase ἄφρακτος ναῦς ("aphraktos naus") - "undefended ship".

In 1583, during the Eighty Years' War of 1568-1648, Habsburg Spain recovered the southern Netherlands from the Protestant rebels. This soon resulted in the use of the occupied ports as bases for privateers, the "Dunkirkers", to attack the shipping of the Dutch and their allies. To achieve this the Dunkirkers developed small, maneuverable, sailing vessels that came to be referred to as frigates. The success of these Dunkirker vessels influenced the ship design of other navies contending with them, but because most regular navies required ships of greater endurance than the Dunkirker frigates could provide, the term soon came to apply less exclusively to any relatively fast and elegant sail-only warship. In French, the term "frigate" gave rise to a verb - "frégater", meaning 'to build long and low', and to an adjective, adding more confusion. Even the huge English could be described as "a delicate frigate" by a contemporary after her upper decks were reduced in 1651.

The navy of the Dutch Republic became the first navy to build the larger ocean-going frigates. The Dutch navy had three principal tasks in the struggle against Spain: to protect Dutch merchant ships at sea, to blockade the ports of Spanish-held Flanders to damage trade and halt enemy privateering, and to fight the Spanish fleet and prevent troop landings. The first two tasks required speed, shallowness of draft for the shallow waters around the Netherlands, and the ability to carry sufficient supplies to maintain a blockade. The third task required heavy armament, sufficient to stand up to the Spanish fleet. The first of the larger battle-capable frigates were built around 1600 at Hoorn in Holland. By the later stages of the Eighty Years' War the Dutch had switched entirely from the heavier ships still used by the English and Spanish to the lighter frigates, carrying around 40 guns and weighing around 300 tons.

The effectiveness of the Dutch frigates became most evident in the Battle of the Downs in 1639, encouraging most other navies, especially the English, to adopt similar designs.

The fleets built by the Commonwealth of England in the 1650s generally consisted of ships described as "frigates", the largest of which were two-decker "great frigates" of the third rate. Carrying 60 guns, these vessels were as big and capable as "great ships" of the time; however, most other frigates at the time were used as "cruisers": independent fast ships. The term "frigate" implied a long hull-design, which relates directly to speed (see hull speed) and which also, in turn, helped the development of the broadside tactic in naval warfare.

At this time, a further design evolved, reintroducing oars and resulting in galley frigates such as of 1676, which was rated as a 32-gun fifth-rate but also had a bank of 40 oars set below the upper deck which could propel the ship in the absence of a favourable wind.

In Danish, the word "fregat" often applies to warships carrying as few as 16 guns, such as , which the British classified as a sloop.

Under the rating system of the Royal Navy, by the middle of the 18th century, the term "frigate" was technically restricted to single-decked ships of the fifth rate, though small 28-gun frigates classed as sixth rate.

The classic sailing frigate, well-known today for its role in the Napoleonic wars, can be traced back to French developments in the second quarter of the 18th century. The French-built "Médée" of 1740 is often regarded as the first example of this type. These ships were square-rigged and carried all their main guns on a single continuous upper deck. The lower deck, known as the "gun deck", now carried no armament, and functioned as a "berth deck" where the crew lived, and was in fact placed below the waterline of the new frigates. The typical earlier cruiser had a partially armed lower deck, from which it was known as a 'half-battery' or "demi-batterie" ship. Removing the guns from this deck allowed the height of the hull upperworks to be lowered, giving the resulting 'true-frigate' much improved sailing qualities. The unarmed deck meant that the frigate's guns were carried comparatively high above the waterline; as a result, when seas were too rough for two-deckers to open their lower deck gun-ports, frigates were still able to fight with all their guns (see the Action of 13 January 1797, for an example when this was decisive).

A total of fifty-nine French sailing frigates were built between 1777 and 1790, with a standard design averaging a hull length of and an average draught of . The new frigates recorded sailing speeds of up to , significantly faster than their predecessor vessels. 

The Royal Navy captured a number of the new French frigates, including the "Médée", during the War of the Austrian Succession (1740–1748) and were impressed by them, particularly for their inshore handling capabilities. They soon built copies (ordered in 1747), based on a French privateer named "Tygre", and started to adapt the type to their own needs, setting the standard for other frigates as the leading naval power. The first British frigates carried 28 guns including an upper deck battery of twenty-four 9-pounder guns (the remaining four smaller guns were carried on the quarter deck) but soon developed into fifth-rate ships of 32 or 36 guns including an upper deck battery of twenty-six 12-pounder guns, with the remaining six or ten smaller guns carried on the quarter deck and forecastle.

In 1778, the British Admiralty introduced a larger "heavy" frigate, with a main battery of twenty-six or twenty-eight 18-pounder guns (with smaller guns carried on the quarter deck and forecastle). This move may reflect the naval conditions at the time, with both France and Spain as enemies the usual British preponderance in ship numbers was no longer the case and there was pressure on the British to produce cruisers of individually greater force. In reply, the first French 18-pounder frigates were laid down in 1781. The 18-pounder frigate eventually became the standard frigate of the French Revolutionary and Napoleonic Wars. The British produced larger, 38-gun, and a slightly smaller, 36-gun, versions and also a 32-gun design that can be considered an 'economy version'. The 32-gun frigates also had the advantage that they could be built by the many smaller, less-specialised shipbuilders.

Frigates could (and usually did) additionally carry smaller carriage-mounted guns on their quarter decks and forecastles (the superstructures above the upper deck). Technically, rated ships with fewer than 28 guns could not be classed as frigates but as "post ships"; however, in common parlance most post ships were often described as "frigates", the same casual misuse of the term being extended to smaller two-decked ships that were too small to stand in the line of battle. In 1778 the Carron Iron Company of Scotland produced a naval gun which would revolutionise the armament of smaller naval vessels, including the frigate. The carronade was a large calibre, short-barrelled naval cannon which was light, quick to reload and needed a smaller crew than a conventional long-gun. Due to its lightness it could be mounted on the forecastle and quarter deck of frigates. It greatly increased the firepower, measured in weight of metal (the combined weight of all projectiles fired in one broadside), of these vessels. The disadvantages of the carronade were that it had a much shorter range and was less accurate than a long-gun. The British quickly saw the advantages of the new weapon and soon employed it on a wide scale, the US Navy also copied the design soon after its appearance. The French and other nations eventually adopted variations of the weapon in succeeding decades. The typical heavy frigate had a main armament of 18-pounder long-guns, plus 32-pounder carronades mounted on its upper decks.

The first 'super-heavy frigates', armed with 24-pounder long guns, were built by the naval architect F H Chapman for the Swedish navy in 1782. Because of a shortage of ships-of-the-line, the Swedes wanted these frigates, the "Bellona" class, to be able to be able to stand in the battle line in an emergency. In the 1790s the French built a small number of large 24-pounder frigates, such as the "Forte" and "Egyptienne", they also cut-down (reduced the height of the hull to give only one continuous gun deck) a number of older ships-of-the-line (including "Diadème") to produce super-heavy frigates, the resulting ship was known as a "rasée". It is not known whether the French were seeking to produce very potent cruisers or merely to address stability problems in old ships. The British, alarmed by the prospect of these powerful heavy frigates, responded by rasée-ing three of the smaller 64-gun battleships, including the "Indefatigable", which went on to have a very successful career as a frigate. At this time the British also built a few 24-pounder-armed large frigates, the most successful of which was HMS "Endymion"

In 1797, three of the United States Navy's first six major ships were rated as 44-gun frigates, which operationally carried fifty-six to sixty 24-pounder long guns and 32-pounder or 42-pounder carronades on two decks; they were exceptionally powerful. These ships were so well-armed that they were often regarded as equal to ships of the line, and after a series of losses at the outbreak of the War of 1812, Royal Navy fighting instructions ordered British frigates (usually of 38 guns or less) to never engage the large American frigates at any less than a 2:1 advantage. , preserved as a museum ship by the US Navy, is the oldest commissioned warship afloat, and is a surviving example of a frigate from the Age of Sail. "Constitution" and her sister ships and were created in a response to deal with the Barbary Coast pirates and in conjunction with the Naval Act of 1794. The three big frigates, when built, had a distinctive building pattern which minimised "hogging" (in which the centre of the keel rises while both ends drop) and improves hydrodynamic efficiency.

Joshua Humphreys proposed that only live oak, a tree that grew only in America, should be used to build these ships. The method was to use diagonal riders, eight on each side that sat at a 45-degree angle. These beams of live oak were about wide and around thick and helped to maintain the shape of the hull, serving also to reduce flexibility and to minimize impacts.

The British, wounded by repeated defeats in single-ship actions, responded to the success of the American 44s in three ways. They built a class of conventional 40-gun, 24-pounder armed frigates on the lines of "Endymion". They cut down three old 74-gun battleships into rasées, producing frigates with a 32-pounder main armament, supplemented by 42-pounder carronades. These had an armament that far exceeded the power of the American ships. Finally, "Leander" and "Newcastle", 1,500 ton spar-decked frigates (with an enclosed waist, giving a continuous line of guns from bow to stern at the level of the quarter deck/forecastle), were built, which were an almost exact match in size and firepower to the American 44-gun frigates.

Frigates were perhaps the hardest-worked of warship types during the Age of Sail. While smaller than a ship-of-the-line, they were formidable opponents for the large numbers of sloops and gunboats, not to mention privateers or merchantmen. Able to carry six months' stores, they had very long range; and vessels larger than frigates were considered too valuable to operate independently.

Frigates scouted for the fleet, went on commerce-raiding missions and patrols, and conveyed messages and dignitaries. Usually, frigates would fight in small numbers or singly against other frigates. They would avoid contact with ships-of-the-line; even in the midst of a fleet engagement it was bad etiquette for a ship of the line to fire on an enemy frigate which had not fired first. Frigates were involved in fleet battles, often as "repeating frigates". In the smoke and confusion of battle, signals made by the fleet commander, whose flagship might be in the thick of the fighting, might be missed by the other ships of the fleet. Frigates were therefore stationed to windward or leeward of the main line of battle, and had to maintain a clear line of sight to the commander's flagship. Signals from the flagship were then repeated by the frigates, which themselves standing out of the line and clear from the smoke and disorder of battle, could be more easily seen by the other ships of the fleet. If damage or loss of masts prevented the flagship from making clear conventional signals, the repeating frigates could interpret them and hoist their own in the correct manner, passing on the commander's instructions clearly.

For officers in the Royal Navy, a frigate was a desirable posting. Frigates often saw action, which meant a greater chance of glory, promotion, and prize money.

Unlike larger ships that were placed in ordinary, frigates were kept in service in peacetime as a cost-saving measure and to provide experience to frigate captains and officers which would be useful in wartime. Frigates could also carry marines for boarding enemy ships or for operations on shore; in 1832, the frigate landed a party of 282 sailors and Marines ashore in the US Navy's first Sumatran expedition.

Frigates remained a crucial element of navies until the mid-19th century. The first ironclads were classified as "frigates" because of the number of guns they carried. However, terminology changed as iron and steam became the norm, and the role of the frigate was assumed first by the protected cruiser and then by the light cruiser.

Frigates are often the vessel of choice in historical naval novels due to their relative freedom compared to ships of the line (kept for fleet actions) and smaller vessels (generally assigned to a home port and less widely ranging). For example, the Patrick O'Brian Aubrey–Maturin series, C. S. Forester's Horatio Hornblower series and Alexander Kent's Richard Bolitho series. The motion picture "" features a reconstructed historic frigate, HMS "Rose", to depict Aubrey's frigate HMS "Surprise".

Vessels classed as frigates continued to play a great role in navies with the adoption of steam power in the 19th century. In the 1830s, navies experimented with large paddle steamers equipped with large guns mounted on one deck, which were termed "paddle frigates".

From the mid-1840s on, frigates which more closely resembled the traditional sailing frigate were built with steam engines and screw propellers. These "screw frigates", built first of wood and later of iron, continued to perform the traditional role of the frigate until late in the 19th century.

From 1859, armour was added to ships based on existing frigate and ship of the line designs. The additional weight of the armour on these first ironclad warships meant that they could have only one gun deck, and they were technically frigates, even though they were more powerful than existing ships-of-the-line and occupied the same strategic role. The phrase "armoured frigate" remained in use for some time to denote a sail-equipped, broadside-firing type of ironclad.

After 1875, the term "frigate" fell out of use. Vessels with armoured sides were designated as "battleships" or "armoured cruisers", while "protected cruisers" only possessed an armoured deck, and unarmoured vessels, including frigates and sloops, were classified as "unprotected cruisers".

Modern frigates are related to earlier frigates only by name. The term "frigate" was readopted during the Second World War by the British Royal Navy to describe an anti-submarine escort vessel that was larger than a corvette, while smaller than a destroyer. Equal in size and capability to the American destroyer escort, frigates are usually less expensive to build and maintain. Anti-submarine escorts had previously been classified as sloops by the Royal Navy, and the s of 1939–1945 were as large as the new types of frigate, and more heavily armed. Twenty-two of these were reclassified as frigates after the war, as were the remaining 24 smaller s.

The frigate was introduced to remedy some of the shortcomings inherent in the Flower-class corvette design: limited armament, a hull form not suited to open-ocean work, a single shaft which limited speed and manoeuvrability, and a lack of range. The frigate was designed and built to the same mercantile construction standards (scantlings) as the corvette, allowing manufacture by yards unused to warship construction. The first frigates of the (1941) were essentially two sets of corvette machinery in one larger hull, armed with the latest Hedgehog anti-submarine weapon.

The frigate possessed less offensive firepower and speed than a destroyer, but such qualities were not required for anti-submarine warfare. Submarines were slow while submerged, and ASDIC sets did not operate effectively at speeds of over . Rather, the frigate was an austere and weatherly vessel suitable for mass-construction and fitted with the latest innovations in anti-submarine warfare. As the frigate was intended purely for convoy duties, and not to deploy with the fleet, it had limited range and speed.

The contemporary German "Flottenbegleiter" ("fleet escorts"), also known as "F-Boats", were essentially frigates. They were based on a pre-war "Oberkommando der Marine" concept of vessels which could fill roles such as fast minesweeper, minelayer, merchant escort and anti-submarine vessel. Because of the Treaty of Versailles their displacement was officially limited to 600 tons, although in reality they exceeded this by about 100 tons. F-boats had two stacks and two 105 mm gun turrets. The design was flawed because of its narrow beam, sharp bow and unreliable high pressure steam turbines. F-boats were succeeded in operational duties by Type 35 and Elbing class torpedo boats. "Flottenbegleiter" remained in service as advanced training vessels.

It was not until the Royal Navy's of 1944 that a British design classified as a "frigate" was produced for fleet use, although it still suffered from limited speed. These anti-aircraft frigates, built on incomplete hulls, were similar to the United States Navy's destroyer escorts (DE), although the latter had greater speed and offensive armament to better suit them to fleet deployments. The destroyer escort concept came from design studies by the General Board of the United States Navy in 1940, as modified by requirements established by a British commission in 1941 prior to the American entry into the war, for deep-water escorts. The American-built destroyer escorts serving in the British Royal Navy were rated as Captain-class frigates. The U.S. Navy's two Canadian-built and 96 British-influenced, American-built frigates that followed originally were classified as "patrol gunboats" (PG) in the U.S. Navy but on 15 April 1943 were all reclassified as patrol frigates (PF).

The introduction of the surface-to-air missile after World War II made relatively small ships effective for anti-aircraft warfare: the "guided missile frigate". In the USN, these vessels were called "ocean escorts" and designated "DE" or "DEG" until 1975 – a holdover from the World War II destroyer escort or "DE". The Royal Canadian Navy and British Royal Navy maintained the use of the term "frigate"; likewise, the French Navy refers to missile-equipped ship, up to cruiser-sized ships (, , and es), by the name of "frégate", while smaller units are named "aviso". The Soviet Navy used the term "guard-ship" ("сторожевой корабль").

From the 1950s to the 1970s, the United States Navy commissioned ships classed as guided missile frigates (hull classification symbol DLG or DLGN, literally meaning guided missile destroyer leaders), which were actually anti-aircraft warfare cruisers built on destroyer-style hulls. These had one or two twin launchers per ship for the RIM-2 Terrier missile, upgraded to the RIM-67 Standard ER missile in the 1980s. This type of ship was intended primarily to defend aircraft carriers against anti-ship cruise missiles, augmenting and eventually replacing converted World War II cruisers (CAG/CLG/CG) in this role. The guided missile frigates also had an anti-submarine capability that most of the World War II cruiser conversions lacked. Some of these ships – and along with the and es – were nuclear-powered (DLGN). These "frigates" were roughly mid-way in size between cruisers and destroyers. This was similar to the use of the term "frigate" during the age of sail during which it referred to a medium-sized warship, but it was inconsistent with conventions used by other contemporary navies which regarded frigates as being smaller than destroyers. During the 1975 ship reclassification, the large American frigates were redesignated as guided missile cruisers or destroyers (CG/CGN/DDG), while ocean escorts (the American classification for ships smaller than destroyers, with hull symbol DE/DEG (destroyer escort)) were reclassified as frigates (FF/FFG), sometimes incorrectly called "fast frigates". In the late 1970s the US Navy introduced the 51-ship "Oliver Hazard Perry"-class guided missile frigates (FFG), the last of which was decommissioned in 2015, although some serve in other navies. By 1995 the older guided missile cruisers and destroyers were replaced by the s and s.

One of the most successful post-1945 designs was the British , which was used by several navies. Laid down in 1959, the "Leander"-class was based on the previous Type 12 anti-submarine frigate but equipped for anti-aircraft use as well. They were used by the UK into the 1990s, at which point some were sold onto other navies. The "Leander" design, or improved versions of it, were licence-built for other navies as well.

Nearly all modern frigates are equipped with some form of offensive or defensive missiles, and as such are rated as guided-missile frigates (FFG). Improvements in surface-to-air missiles (e.g., the Eurosam Aster 15) allow modern guided-missile frigates to form the core of many modern navies and to be used as a fleet defence platform, without the need for specialised anti-air warfare frigates.

The Royal Navy Type 61 "Salisbury" class were "air direction" frigates equipped to track aircraft. To this end they had reduced armament compared to the Type 41 "Leopard"-class air-defence frigates built on the same hull.

Multi-role frigates like the MEKO 200, and es are designed for navies needing warships deployed in a variety of situations that a general frigate class would not be able to fulfill and not requiring the need for deploying destroyers.

At the opposite end of the spectrum, some frigates are specialised for anti-submarine warfare. Increasing submarine speeds towards the end of World War II (see German Type XXI submarine) greatly reduced the margin of speed superiority of frigate over submarine. The frigate could no longer be slow and powered by mercantile machinery and consequently postwar frigates, such as the "Whitby" class, were faster.

Such ships carry improved sonar equipment, such as the variable depth sonar or towed array, and specialised weapons such as torpedoes, forward-throwing weapons such as Limbo and missile-carried anti-submarine torpedoes such as ASROC or Ikara. Surface-to-air missiles such as Sea Sparrow and surface-to-surface missiles such as Exocet give them defensive and offensive capabilities. The Royal Navy's original Type 22 frigate is an example of a specialised anti-submarine warfare frigate.

Especially for anti-submarine warfare, most modern frigates have a landing deck and hangar aft to operate helicopters, eliminating the need for the frigate to close with unknown sub-surface threats, and using fast helicopters to attack nuclear submarines which may be faster than surface warships. For this task the helicopter is equipped with sensors such as sonobuoys, wire-mounted dipping sonar and magnetic anomaly detectors to identify possible threats, and torpedoes or depth-charges to attack them.

With their onboard radar helicopters can also be used to reconnoitre over-the-horizon targets and, if equipped with anti-ship missiles such as Penguin or Sea Skua, to attack them. The helicopter is also invaluable for search and rescue operation and has largely replaced the use of small boats or the jackstay rig for such duties as transferring personnel, mail and cargo between ships or to shore. With helicopters these tasks can be accomplished faster and less dangerously, and without the need for the frigate to slow down or change course.

Some frigates are specialised in airdefense, because of the major developments in fighter jets and ballistic missiles.
An example is the De Zeven Provinciën-class Airdefense- and commandfrigate of the Royal Dutch Navy. These ships are armed with VL Standard Missile 2 Block IIIA, one or two Goalkeeper CIWS systems, ("HNLMS Evertsen" has two Goalkeepers, the rest of the ships have the capacity for another one.) VL Evolved Sea Sparrow Missiles, a special SMART-L Radar and a Thales APAR, all of whom are for airdefense. Another example is the Iver Huitfeldtclass of the Danish Navy.

Stealth technology has been introduced in modern frigate design by the French design. Frigate shapes are designed to offer a minimal radar cross section, which also lends them good air penetration; the maneuverability of these frigates has been compared to that of sailing ships. Examples are the Italy and French with the Aster 15 and Aster 30 missile for anti-missile capabilities, the German and s, the Turkish type frigates with the MK-41 VLS, and the Indian and es with the Brahmos missile system.

The modern French Navy applies the term first-class frigate and second-class frigate to both destroyers and frigates in service. Pennant numbers remain divided between F-series numbers for those ships internationally recognised as frigates and D-series pennant numbers for those more traditionally recognised as destroyers. This can result in some confusion as certain classes are referred to as frigates in French service while similar ships in other navies are referred to as destroyers. This also results in some recent classes of French ships such as the being among the largest in the world to carry the rating of frigate. 
In the German Navy, frigates were used to replace aging destroyers; however in size and role the new German frigates exceed the former class of destroyers. The future German F125-class frigate will be the largest class of frigates worldwide with a displacement of more than 7,200 tons. The same was done in the Spanish Navy, which went ahead with the deployment of the first Aegis frigates, the s.

Some new classes of ships similar to corvettes are optimized for high-speed deployment and combat with small craft rather than combat between equal opponents; an example is the U.S. littoral combat ship (LCS). As of 2015, all s in the United States Navy have been decommissioned, and their role partially being assumed by the new LCS. While the LCS class ships are smaller than the frigate class they will replace, they offer a similar degree of weaponry while requiring less than half the crew complement and offering a top speed of over . A major advantage for the LCS ships is that they are designed around specific mission modules allowing them to fulfill a variety of roles. The modular system also allows for most upgrades to be performed ashore and installed later into the ship, keeping the ships available for deployment for the maximum time.

The latest U.S. deactivation plans means that this is the first time that the U.S. Navy has been without a frigate class of ships since 1943 (technically is rated as a frigate and is still in commission, but does not count towards Navy force levels).

The remaining 20 LCSs to be acquired from 2019 and onwards that will be enhanced will be designated as frigates, and existing ships given modifications may also have their classification changed to "FF" as well.

A few nations have frigates on display as museum ships. They are:








</doc>
<doc id="11466" url="https://en.wikipedia.org/wiki?curid=11466" title="Francisco Franco">
Francisco Franco

Francisco Franco Bahamonde (; ; 4 December 1892 – 20 November 1975) was a Spanish general and politician who ruled over Spain as Head of State and dictator under the title "Caudillo" from 1939, after the nationalist victory in the Spanish Civil War, until his death in 1975. This period in Spanish history is commonly known as Francoist Spain.

During the 1924–1930 dictatorship of Miguel Primo de Rivera, Franco was promoted general at age 33, the youngest in Europe. As a conservative and a monarchist, Franco opposed the abolition of the monarchy and the establishment of a democratic secular republic in 1931. With the 1936 elections, the conservative CEDA lost by a narrow margin, and the leftist Popular Front came to power. Intending to overthrow the republic, Franco followed other generals in launching a coup the same year, but failed to take control of most of the country and precipitated the Spanish Civil War. With the death of the other generals, Franco became his faction's only leader. Franco gained military support from various authoritarian regimes and groups, especially Fascist Italy and Nazi Germany, while the Republican side included Spanish communists and anarchists, with support from the Soviet Union, Mexico and the international volunteers. In 1939, Franco won the war, which had claimed almost half a million lives. He established a military dictatorship and proclaimed himself Head of State and Government under the title "Caudillo". In April 1937, Franco merged the fascist and traditionalist political parties in the rebel zone (FE de las JONS and Traditionalist Communion), as well as other conservative and monarchist elements, into a single party: the FET y de las JONS. At the same time, he outlawed all other political parties, and thus Spain became a one-party state.

Upon his rise to power, Franco implemented policies that repressed political opponents and dissenters, whereby as many as between 60,000 and 400,000 died through the use of forced labor and executions in the concentration camps his regime operated. During World War II, he espoused neutrality as Spain's official wartime policy, but provided military support to the Axis in numerous ways. However, scholars consider Franco as conservative and authoritarian, rather than truly fascist. Historian Stanley G. Payne states, "scarcely any of the serious historians and analysts of Franco consider the Generalissimo to have been a core fascist."

Spain was isolated by many other countries for nearly a decade after World War II. By the 1950s, the nature of his regime changed from being openly totalitarian using severe repression to an authoritarian system with limited pluralism and was allowed to join the UN. During the Cold War, Franco was one of the world's foremost anti-Communist figures: his regime was assisted by the West, and it was asked to join NATO. After chronic economic depression in the late 1940s and early 1950s, Franco presided over the Spanish miracle, abandoning autarky and pursuing economic liberalization, delegating authority to liberal ministers. The Francoist dictatorship gradually softened over time and in 1975, Franco died at the age of 82. He restored the monarchy before his death, which made King Juan Carlos I his successor, who led the Spanish transition to democracy.

Franco was born on 4 December 1892 at 108 Calle Frutos Saavedra in Ferrol, Galicia. He was baptised thirteen days later at the military church of San Francisco, with the baptismal name Francisco Paulino Hermenegildo Teódulo; Francisco for his paternal grandfather, Paulino for his godfather, Hermenegildo for his maternal grandmother and godmother, and Teódulo for the saint day of his birth.
His father was of Andalusian ancestry. After relocating to Galicia, the family was strongly involved in the Spanish Navy, and over the span of two centuries produced naval officers for six uninterrupted generations, down to Franco's father Nicolás Franco y Salgado Araújo (22 November 1855 – 22 February 1942).

His mother was María del Pilar Bahamonde y Pardo de Andrade (15 October 1865 – 28 February 1934) and she was an upper middle-class Roman Catholic. His parents married in 1890. The young Franco spent much of his childhood with his two brothers, Nicolás (Ferrol, 1891–1977) and Ramón, and his two sisters, María del Pilar (Ferrol, 1894 – Madrid, 1989), and María de la Paz (Ferrol, 1899 – Ferrol, 1903). The latter died in infancy. Nicolás was later a naval officer and diplomat who in time married María Isabel Pascual del Pobil y Ravello. Ramón was a pioneer aviator, a Freemason with originally leftist political leanings who was killed in an air accident on a military mission in 1938. María del Pilar married Alonso Jaráiz y Jeréz.

Francisco was to follow his father into the Navy, but as a result of the Spanish–American War the country lost much of its navy as well as most of its colonies. Not needing any more officers, the Naval Academy admitted no new entrants from 1906 to 1913. To his father's chagrin, Francisco decided to try the Spanish Army. In 1907, he entered the Infantry Academy in Toledo, graduating in July 1910 as second lieutenant (251st out of 312 cadets). At 19, Franco was promoted to the rank of first lieutenant in June 1912. Two years later, he obtained a commission to Morocco. Spanish efforts to occupy their new African protectorate provoked the protracted Rif War (from 1909 to 1927) with native Moroccans. Their tactics resulted in heavy losses among Spanish military officers, and also provided an opportunity to earn promotion through merit. It was said that officers would receive either "la caja o la faja" (a coffin or a general's sash). Franco quickly gained a reputation as a good officer. In 1913, Franco transferred into the newly formed regulares: Moroccan colonial troops with Spanish officers, who acted as shock troops. This transfer into a perilous role may have been decided because Franco failed to win the hand of his first love, Sofía Subirán. (The letters between the two were found and she was questioned by journalists.)

In 1916, aged 23 and already a captain, he was shot by enemy machine gun fire. He was badly wounded in the abdomen, specifically the liver, in a skirmish at "El Biutz" and possibly lost a testicle. The physicians of the battle later concluded that his intestines were spared because he inhaled the moment he was shot. His survival marked him permanently in the eyes of the native troops as a man of "baraka" (good luck). He was recommended for Spain's highest honour for gallantry, the coveted "Cruz Laureada de San Fernando", but instead received the "Cross of Maria Cristina, First Class". With that he was promoted to major at the end of February 1917 at age 24. This made him the youngest major in the Spanish army. From 1917 to 1920, he served in Spain. In 1920, Lieutenant Colonel José Millán Astray, a histrionic but charismatic officer, founded the Spanish Foreign Legion, on similar lines to the French Foreign Legion. Franco became the Legion's second-in-command and returned to Africa. On 24 July 1921, the poorly commanded and overextended Spanish Army suffered a crushing defeat at Annual from Rif tribesmen led by the Abd el-Krim brothers. The Legion and supporting units relieved the Spanish enclave of Melilla after a three-day forced march led by Franco. In 1923, by now a lieutenant colonel, he was made commander of the Legion.

On 22 October 1923, Franco married María del Carmen Polo y Martínez-Valdès (11 June 1900 – 6 February 1988). Three years later the couple had a daughter, María del Carmen. Following his honeymoon Franco was summoned to Madrid to be presented to King Alfonso XIII. This and other occasions of royal attention would mark him during the Republic as a monarchical officer. Promoted to colonel, Franco led the first wave of troops ashore at Al Hoceima (Spanish: "Alhucemas") in 1925. This landing in the heartland of Abd el-Krim's tribe, combined with the French invasion from the south, spelled the beginning of the end for the short-lived Republic of the Rif. Franco's recognition eventually caught up with him and he was promoted to brigadier general on 3 February 1926. This made him the youngest general in Spain, and perhaps, along with Major-General Joe Sweeney of the Irish Army, one of the youngest generals in Europe. In 1928 Franco was appointed director of the newly created General Military Academy of Zaragoza, a new college for all army cadets, replacing the former separate institutions for young men seeking to become officers in infantry, cavalry, artillery, and other branches of the army. Franco was removed as Director of the Zaragoza Military Academy in 1931; about 95% of his former Zaragoza cadets later came to side with him in the Civil War.

With the fall of the monarchy in 1931, Franco did not take any notable stand. But the closing of the Academy in June by War Minister Manuel Azaña provoked his first clash with the Spanish Republic. Azaña found Franco's farewell speech to the cadets insulting. Franco stressed in his speech the Republic's need for discipline and respect. For six months Franco was without a post and under surveillance.

Franco was a subscriber to the journal of Acción Española, a monarchist organisation, and a firm believer in the Jewish-Masonic-Bolshevik conspiracy or "contubernio" (filthy cohabitation)—'one of Franco's favourite words': a conspiracy in which Jews, Freemasons, Communists, and other leftists alike allegedly sought the destruction of Christian Europe, with Spain the principal target.

On 5 February 1932, he was given a command in A Coruña. Franco avoided involvement in José Sanjurjo's attempted coup that year, and even wrote a hostile letter to Sanjurjo expressing his anger over the attempt. As a side result of Azaña's military reform, in January 1933, Franco was relegated from the first to the 24th in the list of brigadiers; the same year, on 17 February, he was given the military command of the Balearic Islands: a post above his rank, but Franco was still angered that he was purposely stuck in the positions he didn't want to be. Yet it was quite common for the Conservative Officers to be moved or demoted.

New elections held in October 1933 resulted in a centre-right majority. In opposition to this government, a revolutionary communist/anarchist movement broke out on 5 October 1934. This uprising was rapidly quelled in most of the country, but gained a stronghold in Asturias, with the support of the miners' unions. Franco, already General of Division and aide to the war minister, Diego Hidalgo, was put in command of the operations directed to suppress the insurgency. Troops of the Spanish Army of Africa carried this out, with General Eduardo López Ochoa as commander in the field. After two weeks of heavy fighting (and a death toll estimated between 1,200 and 2,000), the rebellion was suppressed.

The insurgency in Asturias (see Asturian miners' strike of 1934) sharpened the antagonism between Left and Right. Franco and López Ochoa (who, prior to the campaign in Asturias, had been seen as a left-leaning officer) emerged as officers prepared to use 'troops against Spanish civilians as if they were a foreign enemy'. Franco described the rebellion to a journalist in Oviedo as, 'a frontier war and its fronts are socialism, communism and whatever attacks civilisation in order to replace it with barbarism.' Though the colonial units sent to the north by the government at Franco's recommendation consisted of the Spanish Foreign Legion and the Moroccan Regulares Indigenas, the right wing press portrayed the Asturian rebels as lackeys of a foreign Jewish-Bolshevik conspiracy. At the start of the Civil War, López Ochoa was assassinated. Some time after these events, Franco was briefly commander-in-chief of the Army of Africa (from 15 February onwards), and from 19 May 1935, on, Chief of the General Staff.

After the ruling centre-right coalition collapsed amid the Straperlo corruption scandal, new elections were scheduled. Two wide coalitions formed: the Popular Front on the left, ranging from Republican Union to Communists, and the Frente Nacional on the right, ranging from the centre radicals to the conservative Carlists. On 16 February 1936, the left won by a narrow margin. Growing political bitterness surfaced again. The government and its supporters, the Popular Front, had launched a campaign against the Opposition whom they accused of plotting against the Republic. According to the right-wing opposition, the real enemies of the Republic were not on the Right but on the Left; Spain was in imminent danger of falling under a "Communist dictatorship", and therefore by fighting the democratically elected Popular Front, they were merely doing their duty in defence of law and order and of the freedom and the fundamental rights of the Spanish people.

On 23 February Franco was sent to the Canary Islands to serve as the islands' military commander, an appointment perceived by him as a "destierro" (banishment). Meanwhile, a conspiracy led by Emilio Mola was taking shape. In June, Franco was contacted and a secret meeting was held within the forest of La Esperanza on Tenerife to discuss starting a military coup. An obelisk commemorating this historic meeting was erected at the site in a clearing at Las Raíces.

Outwardly Franco maintained an ambiguous attitude almost until July. On 23 June 1936, he wrote to the head of the government, Casares Quiroga, offering to quell the discontent in the Spanish Republican Army, but received no reply. The other rebels were determined to go ahead "con Paquito o sin Paquito" (with "Paquito" or without "Paquito"; "Paquito" being a diminutive of "Paco", which in turn is short for "Francisco"), as it was put by José Sanjurjo, the honorary leader of the military uprising. After various postponements, 18 July was fixed as the date of the uprising. The situation reached a point of no return and, as presented to Franco by Mola, the coup was unavoidable and he had to choose a side. He decided to join the rebels and was given the task of commanding the Army of Africa. A privately owned DH 89 De Havilland Dragon Rapide, flown by two British pilots, Cecil Bebb and Hugh Pollard, was chartered in England on 11 July to take Franco to Africa.

The assassination of the right-wing opposition leader José Calvo Sotelo by government police troops, possibly in retaliation for the murder of José Castillo, precipitated the uprising. On 17 July, one day earlier than planned, the African Army rebelled, detaining their commanders. On 18 July, Franco published a manifesto and left for Africa, where he arrived the next day to take command.

A week later the rebels, who soon called themselves the "Nationalists", controlled a third of Spain; most naval units remained under control of the Republican loyalist forces, which left Franco isolated. The coup had failed in the attempt to bring a swift victory, but the Spanish Civil War had begun.

The Spanish Civil War began in July 1936 and officially ended with Franco's victory in April 1939, leaving 190,000 to 500,000 dead. Despite the Non-Intervention Agreement of August 1936, the war was marked by foreign intervention on behalf of both sides, leading to international repercussions. The nationalist side was supported by Fascist Italy, which sent the "Corpo Truppe Volontarie", and later by Nazi Germany, which assisted with the Condor Legion. They were opposed by the Soviet Union and communists, socialists and anarchists within Spain. The United Kingdom and France strictly adhered to the arms embargo, provoking dissensions within the French Popular Front coalition which was led by Léon Blum, but the Republican side was nonetheless supported by the Soviet Union and volunteers who fought in the International Brigades (see for example Ken Loach's "Land and Freedom").

Because Adolf Hitler and Joseph Stalin used the war as a testing ground for modern warfare, some historians, such as Ernst Nolte, have considered the Spanish Civil War, along with World War II, to be part of a European Civil War which lasted from 1936 to 1945 and was mainly characterised as a left/right ideological conflict. This interpretation has not been accepted by most historians, who consider the Spanish Civil War and the Second World War to be two distinct conflicts. Among other things, they point to the political heterogeneity on both sides ("See Spanish Civil War: other factions") and criticise a monolithic interpretation, which overlooks the local nuances of Spanish history.

Following 18 July 1936 "pronunciamiento", Franco assumed the leadership of the 30,000 soldiers of the Spanish Army of Africa. The first days of the insurgency were marked with a serious need to secure control over the Spanish Moroccan Protectorate. On one side, Franco had to win the support of the natives and their (nominal) authorities, and, on the other, had to ensure his control over the army. His method was the summary execution of some 200 senior officers loyal to the Republic (one of them his own cousin). His loyal bodyguard was shot by Manuel Blanco. Franco's first problem was how to move his troops to the Iberian Peninsula, since most units of the Navy had remained in control of the Republic and were blocking the Strait of Gibraltar. He requested help from Benito Mussolini, who responded with an unconditional offer of arms and planes; in Germany Wilhelm Canaris, the head of the "Abwehr" military intelligence, persuaded Hitler to support the Nationalists. From 20 July onward Franco was able, with a small group of 22 mainly German Junkers Ju 52 aircraft, to initiate an air bridge to Seville, where his troops helped to ensure the rebel control of the city. Through representatives, he started to negotiate with the United Kingdom, Germany, and Italy for more military support, and above all for more aircraft. Negotiations were successful with the last two on 25 July and aircraft began to arrive in Tetouan on 2 August. On 5 August Franco was able to break the blockade with the newly arrived air support, successfully deploying a ship convoy with some 2,000 soldiers.

In early August, the situation in western Andalusia was stable enough to allow him to organise a column (some 15,000 men at its height), under the command of then Lieutenant-Colonel Juan Yagüe, which would march through Extremadura towards Madrid. On 11 August Mérida was taken, and on 15 August Badajoz, thus joining both nationalist-controlled areas. Additionally, Mussolini ordered a voluntary army, the "Corpo Truppe Volontarie" (CTV) of some 12,000 Italians of fully motorised units to Seville and Hitler added to them a professional squadron from the Luftwaffe (2JG/88) with about 24 planes. All these planes had the Nationalist Spanish insignia painted on them, but were flown by Italian and German nationals. The backbone of Franco's aviation in those days were the Italian SM.79 and SM.81 bombers, the biplane Fiat CR.32 fighter and the German Junkers Ju 52 cargo-bomber and the Heinkel He 51 biplane fighter.

On 21 September, with the head of the column at the town of Maqueda (some 80 km away from Madrid), Franco ordered a detour to free the besieged garrison at the Alcázar of Toledo, which was achieved on 27 September. This controversial decision gave the Popular Front time to strengthen its defenses in Madrid and hold the city that year, but with Soviet support. Kennan alleges that, once Stalin had decided to assist the Spanish Republicans, the operation was put in place with remarkable speed and energy. The first load of arms and tanks arrives as early as 26 September and was secretly unloaded at night. Advisers accompanied the armaments. Soviert officers were in effective charge of military operations on the Madrid front. Kennan believes that this operation was originally conducted in good faith with no other purpose than saving the Republic. Effort was made to encourage the Spanish Communist Party to seize power but the holding of Alcázar was an important morale and propaganda success for the Nationalists, because we now know that Hitler's primary aim was not a Franco victory but to prolong the war by the active intervention of the Soviet Government as well as Italy, Britain, and France in the Civil War.

Hitler told his Generals on 5 November 1937: "A 100 per cent victory for Franco was not desirable either".

However, by February 1937 the Soviet Union's military help started to taper off, to be replaced by limited economic aid. A more likely motive was Stalin's instinct for self-preservation, because the Spanish Civil War had aroused a spirit of heroism in support of freedom more in line with Trotskyism and such ideas might be exported to the Soviet Union. Further proof of this is what Modin stated that Stalin decided to attack the extreme Left, particularly Trotskyites and militants of the POUM before liquidating Franco. Those who had served in Spain were tainted in Stalin's view and were singled out for harshness in the purges and were virtually all eliminated. The defector Orlov, who worked for the NVKD in Spain, confirms that he was told by a General, whom Orlov did not want to name, that when the General returned to Moscow to seek further instructions, he was told that the Politburo had adopted a new line towards Spain. Until then, the policy of the Politburo was to assist Republican Spain by supplying armaments, Soviet pilots and tanks in order to bring about a speedy victory over Franco; but now the Politburo had revised its strategy. Stalin had come to the conclusion that "It would be more advantageous to the Soviet Union if neither of the warring camps gained proponderant strength, and if the war in Spain dragged on as long as possible and thus tied up Hitler for a long time." The Soviet General who informed Orlov of this was shocked by the Machiavellian calculation of the Politburo which, in its desire to obtain time, wanted the Spanish people to bleed as long as possible.

The designated leader of the uprising, General José Sanjurjo, died on 20 July 1936, in a plane crash. Therefore, in the nationalist zone, "political life ceased." Initially, only military command mattered; this was divided into regional commands (Emilio Mola in the North, Gonzalo Queipo de Llano in Seville commanding Andalusia, Franco with an independent command and Miguel Cabanellas in Zaragoza commanding Aragon). The Spanish Army of Morocco itself was split into two columns, one commanded by General Juan Yagüe and the other commanded by Colonel José Varela.

From 24 July a coordinating "junta" was established, based at Burgos. Nominally led by Cabanellas, as the most senior general, it initially included Mola, three other generals, and two colonels; Franco was later added in early August. On 21 September it was decided that Franco was to be commander-in-chief (this unified command was opposed only by Cabanellas), and, after some discussion, with no more than a lukewarm agreement from Queipo de Llano and from Mola, also head of government. He was, doubtlessly, helped to this primacy by the fact that, in late July, Hitler had decided that all of Germany's aid to the nationalists would go to Franco.

Mola had been somewhat discredited as the main planner of the attempted coup that had now degenerated into a civil war, and was strongly identified with the Carlist monarchists and not at all with the Falange, a party with Fascist leanings and connections ("phalanx", a far-right Spanish political party founded by José Antonio Primo de Rivera), nor did he have good relations with Germany; Queipo de Llano and Cabanellas had both previously rebelled against the dictatorship of General Miguel Primo de Rivera and were therefore discredited in some nationalist circles; and Falangist leader José Antonio Primo de Rivera was in prison in Alicante (he would be executed a few months later) and the desire to keep a place open for him prevented any other Falangist leader from emerging as a possible head of state. Franco's previous aloofness from politics meant that he had few active enemies in any of the factions that needed to be placated, and also he had cooperated in recent months with both Germany and Italy.

On 1 October 1936, in Burgos, Franco was publicly proclaimed as "Generalísimo" of the National army and "Jefe del Estado" (Head of State). When Mola was killed in another air accident a year later (which some believe was an assassination) (2 June 1937), no military leader was left from those who organized the conspiracy against the Republic between 1933 and 1935.

Franco personally guided military operations from this time until the end of the war. After the failed assault on Madrid in November 1936, Franco settled on a piecemeal approach to winning the war, rather than bold maneuvering. As with his decision to relieve the garrison at Toledo, this approach has been subject of some debate; some of his decisions, such as in June 1938 when he preferred to head for Valencia instead of Catalonia, remain particularly controversial from a military viewpoint. Valencia, Castellon and Alicante saw the last Republican troops defeated by Franco.

Although both Germany and Italy provided military support to Franco, the degree of influence of both powers on his direction of the war seems to have been very limited. Nevertheless, the Italian troops, despite not being always effective, were present in most of the large operations in large numbers, while the German aircraft helped the Nationalist air force dominate the skies for most of the war.

Franco's direction of the German and Italian forces was limited, particularly in the direction of the Condor Legion, but he was by default their supreme commander, and they rarely made decisions on their own. For reasons of prestige it was decided to continue assisting Franco until the end of the war, and Italian and German troops paraded on the day of the final victory in Madrid.

The Nazis were disappointed with Franco's resistance to installing fascism. Historian James S. Corum states:
Historian Robert H. Whealey provides more detail:

From 1937 to 1948 the Franco regime was a hybrid as Franco fused the ideologically incompatible national-syndicalist Falange ("Phalanx", a fascist Spanish political party founded by José Antonio Primo de Rivera) and the Carlist monarchist parties into one party under his rule, dubbed "Falange Española Tradicionalista y de las Juntas de Ofensiva Nacional-Sindicalista" (FET y de las JONS), which became the only legal party in 1939. Unlike some other fascist movements, the Falangists had developed an official program in 1934, the "Twenty-Seven Points". In 1937, Franco assumed as the tentative doctrine of his regime 26 out of the original 27 points. Franco made himself "jefe nacional" (National Chief) of the new FET ("Falange Española Tradicionalista"; Traditionalist Spanish Phalanx) with a secretary, Junta Political and National Council to be named subsequently by himself. Five days later (24 April) the raised-arm salute of the Falange was made the official salute of the Nationalist regime. In 1939 the personalist style heavily predominated, with ritualistic invocations of "Franco, Franco, Franco." The Falangists' hymn, "Cara al Sol", became the semi-national anthem of Franco's not-yet-established regime.

This new political formation appeased the pro-German Falangists while tempering them with the anti-German Carlists. Franco's brother-in-law Ramón Serrano Súñer, who was his main political advisor, was able to turn the various parties under Franco against each other to absorb a series of political confrontations against Franco himself. Franco expelled the original leading members of both the Carlists (Manuel Fal Condé) and the Falangists (Manuel Hedilla) to secure his political future. Franco also appeased the Carlists by exploiting the Republicans' anti-clericalism in his propaganda, in particular concerning the "Martyrs of the war". While the loyalist forces presented the war as a struggle to defend the Republic against Fascism, Franco depicted himself as the defender of "Catholic Spain" against "atheist Communism."

By early 1939 only Madrid (see History of Madrid) and a few other areas remained under control of the government forces. On 27 February Chamberlain's Britain and Daladier's France officially recognised the Franco regime. On 28 March 1939, with the help of pro-Franco forces inside the city (the "fifth column" General Mola had mentioned in propaganda broadcasts in 1936), Madrid fell to the Nationalists. The next day, Valencia, which had held out under the guns of the Nationalists for close to two years, also surrendered. Victory was proclaimed on 1 April 1939, when the last of the Republican forces surrendered. On the same day, Franco placed his sword upon the altar of a church and in a vow, promised that he would never again take up his sword unless Spain itself was threatened with invasion.

Although Germany had recognised the Franco Government, Franco's policy towards Germany was extremely cautious until spectacular German victories at the beginning of the Second World War.

An early indication that Franco was going to keep his distance from Germany soon proved true. A rumoured state visit by Franco to Germany did not take place and a further rumour of a visit by Goering to Spain, after he had enjoyed a cruise in the Western Mediterranean, again did not materialise. Instead Goering had to return to Berlin.

This proved how right Eden was when he said "Whatever the final outcome of the strife ... the Spanish people will continue to display that proud independence, that arrogant individualism which is a characteristic of the race. There are twenty-four million reasons why Spain will never for long be dominated by the forces or controlled by the advice of any foreign power."

According to Paul Preston, 150,000 wartime civilian executions took place in the Francoist area, as well as 50,000 in the Republican area, in addition to 20,000 civilians executed by the Franco regime after the end of the war. According to Helen Graham, the Spanish working classes became to the Francoist project what the Jews were to German Volksgemeinschaft.

According to Stanley G. Payne, at least 70,000 people were executed during the civil war. Franco's victory was followed by thousands of summary executions (from 15,000 to 25,000 people) and imprisonments, while many were put to forced labour, building railways, drying out swamps, digging canals ("La Corchuela", the Canal of the Bajo Guadalquivir), construction of the Valle de los Caídos monument, etc. The 1940 ordered execution of the president of the Catalan government, Lluís Companys, was one of the most notable cases of this early suppression of opponents and dissenters. According to Gabriel Jackson, the number of victims of the "White Terror" (executions and hunger or illness in prisons) only between 1939 and 1943 was 200,000.
Stanley Payne approximates there were 50,000 Civil War executions by the Republicans and approximately 70,000 by the Nationalists. Payne further approximates there were 30,000 post-Civil War executions by the victorious Nationalists.

In his history of the Spanish Civil War, Antony Beevor "reckons Franco's ensuing 'white terror' claimed 200,000 lives. The 'red terror' had already killed 38,000." Julius Ruiz concludes that "although the figures remain disputed, a minimum of 37,843 executions were carried out in the Republican zone with a maximum of 150,000 executions (including 50,000 after the war) in Nationalist Spain."

Despite the official end of the war, guerrilla resistance to Franco (known as "the "maquis"") was widespread in many mountainous regions, and continued well into the 1950s. In 1944, a group of republican veterans, which also fought in the French resistance against the Nazis, invaded the Val d'Aran in northwest Catalonia, but they were quickly defeated.

The end of the war led to hundreds of thousands of exiles, mostly to France (but also Mexico, Chile, Cuba, the USA and so on.). On the other side of the Pyrenees, refugees were confined in internment camps of the French Third Republic, such as Camp Gurs or Camp Vernet, where 12,000 Republicans were housed in squalid conditions (mostly soldiers from the Durruti Division). The 17,000 refugees housed in Gurs were divided into four categories (Brigadists, pilots, "Gudaris" and ordinary 'Spaniards'). The "Gudaris" (Basques) and the pilots easily found local backers and jobs, and were allowed to quit the camp, but the farmers and ordinary people, who could not find relations in France, were encouraged by the Third Republic, in agreement with the Francoist government, to return to Spain. The great majority did so and were turned over to the Francoist authorities in Irún. From there they were transferred to the Miranda de Ebro camp for "purification" according to the Law of Political Responsibilities.

After the proclamation by Marshal Philippe Pétain of the Vichy France regime, the refugees became political prisoners, and the French police attempted to round up those who had been liberated from the camp. Along with other "undesirables", they were sent to the Drancy internment camp before being deported to Nazi Germany. 5,000 Spaniards thus died in Mauthausen concentration camp. The Chilean poet Pablo Neruda, who had been named by the Chilean President Pedro Aguirre Cerda special consul for immigration in Paris, was given responsibility for what he called "the noblest mission I have ever undertaken": shipping more than 2,000 Spanish refugees, who had been housed by the French in squalid camps, to Chile on an old cargo ship, the "Winnipeg".

In September 1939 World War II began. On 23 October 1940, Hitler and Franco met in Hendaye in France to discuss the possibility of Spain's entry on the side of the Axis. Franco's demands, including supplies of food and fuel, as well as Spanish control of Gibraltar and French North Africa, proved too much for Hitler. At the time Hitler did not want to risk damaging his relations with the new Vichy French government. (An oft-cited remark attributed to Hitler is that the German leader said that he would rather have some of his own teeth extracted than to have to personally deal further with Franco.) Franco had received important support from Adolf Hitler and Benito Mussolini during the Spanish Civil War, and he had signed the Anti-Comintern Pact. He described Spain as part of the Axis in official documents, while offering various kinds of support to Italy and Germany. He allowed Spanish soldiers to volunteer to fight in the German Army against the USSR (the Blue Division), but forbade Spaniards to fight in the West against the democracies. Franco's common ground with Hitler was particularly weakened by Hitler's propagation of Nazi mysticism and his attempts to manipulate Christianity, which went against Franco's fervent commitment to defending Catholicism. Contributing to the disagreement was an ongoing dispute over German mining rights in Spain. Some historians argue that Franco made demands he knew Hitler would not accede to in order to stay out of the war. Other historians argue that Franco, as the leader of a destroyed and bankrupt country in chaos following a brutal three-year civil war, simply had little to offer the Axis and that the Spanish armed forces were not ready for a major war.

Yet, after the Fall of France in June 1940, Spain did adopt a pro-Axis stance (for example, German and Italian ships and U-boats were allowed to use Spanish naval facilities) before returning to a more neutral position in late 1943 when the tide of the war had turned decisively against the Axis Powers, and Italy had changed sides. Franco was initially keen to join the war before the UK was defeated. In the winter of 1940–41 Franco toyed with the idea of a "Latin Bloc" formed by Spain, Portugal, Vichy France, the Vatican and Italy, without much consequence. Franco had cautiously decided to enter the war on the Axis side in June 1940, and to prepare his people for war, an anti-British and anti-French campaign was launched in the Spanish media that demanded French Morocco, Cameroon and the return of Gibraltar. On 19 June 1940, Franco pressed along a message to Hitler saying he wanted to enter the war, but Hitler was annoyed at Franco's demand for the French colony of Cameroon, which had been German before World War I, and which Hitler was planning on taking back for Plan Z. Franco seriously considered blocking allied access to the Mediterranean Sea by invading British-controlled Gibraltar, but he abandoned the idea after learning that the plan would have likely failed due to Gibraltar being too heavily defended, and it would have given the British the grounds to declare war on Spain and thus give the UK and its allies an excellent opportunity to take both the Canary Islands and Spanish Morocco, as well as possibly invade mainland Spain itself. Franco was aware that his air force would not be able to protect Spanish cities from attacks by the British Royal Air Force, and the British Royal Navy would be able to blockade Spain to prevent imports of crucial materials such as oil. Spain depended on oil imports from the United States, which were almost certain to be cut off if Spain formally joined the Axis. Franco and Serrano Suñer held a meeting with Mussolini and Ciano in Bordighera, Italy on 12 February 1941. Mussolini affected not to be interested in Franco's help due to the defeats his forces had suffered in North Africa and the Balkans, and he even told Franco that he wished he could find any way to leave the war. When the invasion of the Soviet Union began on 22 June 1941, Franco's foreign minister Ramón Serrano Suñer immediately suggested the formation of a unit of military volunteers to join the invasion. Volunteer Spanish troops (the "División Azul", or "Blue Division") fought on the Eastern Front under German command from 1941 to 1944. Some historians have argued that not all of the Blue Division were true volunteers and that Franco expended relatively small but significant resources to aid the Axis powers' battle against the Soviet Union.

Franco was initially disliked by Cuban President Fulgencio Batista, who, during World War II, suggested a joint U.S.-Latin American declaration of war on Spain in order to overthrow Franco's regime. Hitler may not have really wanted Spain to join the war, as he needed neutral harbors to import materials from countries in Latin America and elsewhere. In addition Hitler felt Spain would be a burden as it would be dependent on Germany for help. By 1941 Vichy French forces were proving their effectiveness in North Africa, reducing the need for Spanish help, and Hitler was wary about opening up a new front on the western coast of Europe as he struggled to reinforce the Italians in Greece and Yugoslavia. Franco signed a revised Anti-Comintern Pact on 25 November 1941.

After the war, the Spanish government tried to destroy all evidence of its cooperation with the Axis. In 2010 documents were discovered showing that on 13 May 1941, Franco ordered his provincial governors to compile a list of Jews while he negotiated an alliance with the Axis powers. Franco supplied Reichsführer-SS Heinrich Himmler, architect of the Nazis' Final Solution, with a list of 6,000 Jews in Spain.

On 14 June 1940, Spanish forces in Morocco occupied Tangier (a city under the rule of the League of Nations) and did not leave it until the war's end in 1945.

After the war, Franco allowed many former Nazis, such as Otto Skorzeny and Léon Degrelle, and other former Fascists, to flee to Spain.

According to "Anti-Semitism: A Historical Encyclopedia of Prejudice and Persecution" (2005):

Spain provided visas for thousands of French Jews to transit Spain en route to Portugal, to escape the Nazis. Spanish diplomats protected about 4,000 Jews living in Hungary, Romania, Bulgaria, Czechoslovakia and Austria. At least some 20,000–30,000 Jews were allowed to pass through Spain in the first half of the War. Jews who were not allowed to enter Spain however, were sent to the Miranda de Ebro concentration camp or deported to France. In January 1943, after the German embassy in Spain told Spanish government that it had two months to remove its Jewish citizens from Western Europe, Spain severely limited visas, and only 800 Jews were allowed to enter the country. After the war, Franco exaggerated his contribution in helping to save Jews in order to end Spain's isolation and to improve Spain's image in the world.

After the war, Franco refused to recognize Israel as a legitimate state, the regime's propaganda claimed that there was an international conspiracy of Jews, Freemasons, and Communists against Spain, under the Francoist regime, Jews, along with other non-Catholic communities, were heavily discriminated against, in 1945, the regime enacted the "Spanish Bill of Rights" ("Fuero de los Españoles"), which allowed the worship of non-Catholic religions, however worship of non-Catholic religions was only allowed in private, no signs to indicate they were places of worship were allowed, and only Catholic public ceremonies were allowed, making it a huge regression in comparison to the Republican Constitution of 1931, which granted Jews rights they did not enjoy in Spain since their expulsion in 1492, the situation improved with the 1967 Law on Religious Freedom, but nevertheless, discrimination still existed, non-Catholic groups were forced to register with the regime and to provide records of their members, freedom of religion would only be completely established in Spain in 1978, with the new Constitution of Spain, three years after Franco's death.

Despite this, however, on 16 December 1968, the regime formally revoked the 1492 Edict of Expulsion against Spain's Jewish population.

Franco was recognized as the Spanish head of state by Great Britain, France and Argentina in February 1939. Already proclaimed "Generalísimo" of the Nationalists and "Jefe del Estado" (Head of State) in October 1936, he thereafter assumed the official title of ""Su Excelencia el Jefe de Estado"" ("His Excellency the Head of State"). He was also referred to in state and official documents as ""Caudillo de España"" ("the Leader of Spain"), and sometimes called ""el Caudillo de la Última Cruzada y de la Hispanidad"" ("the Leader of the Last Crusade and of the Hispanic heritage") and ""el Caudillo de la Guerra de Liberación contra el Comunismo y sus Cómplices"" ("the Leader of the War of Liberation Against Communism and Its Accomplices").

On paper, Franco had more power than any Spanish leader before or since. For the first four years after taking Madrid, he ruled almost exclusively by decree. The "Law of the Head of State," passed in August 1939, "permanently confided" all governing power to Franco; he was not required to even consult the cabinet for most legislation or decrees. According to Payne, Franco possessed far more day-to-day power than Hitler or Stalin possessed at the respective heights of their power. He noted that while Hitler and Stalin maintained rubber-stamp parliaments, this was not the case in Spain in the early years after the war–a situation that nominally made Franco's regime "the most purely arbitrary in the world."

This changed in 1942, when Franco convened a parliament known as the Cortes Españolas. It was elected in accordance with corporatist principles, and had little real power. Notably, it had no control over government spending, and the government was not responsible to it; ministers were appointed and dismissed by Franco alone.

On 26 July 1947 Franco proclaimed Spain a monarchy, but did not designate a monarch. This gesture was largely done to appease the monarchists in the "Movimiento Nacional" (Carlists and Alfonsists). Franco left the throne vacant until 1969, proclaiming himself as a "de facto" regent for life. At the same time, Franco appropriated many of the privileges of a king. He wore the uniform of a Captain General (a rank traditionally reserved for the King) and resided in El Pardo Palace. In addition he began walking under a canopy, and his portrait appeared on most Spanish coins and postage stamps. He also added "by the grace of God", a phrase usually part of the styles of monarchs, to his style.

Franco initially sought support from various groups. His administration marginalised fascist ideologues in favor of technocrats, many of whom were linked with Opus Dei, who promoted economic modernisation.

Although Franco and Spain under his rule adopted some trappings of fascism, he, and Spain under his rule, are generally not considered to be fascist; among the distinctions, fascism entails a revolutionary aim to transform society, where Franco did not seek to do so, and, to the contrary, although authoritarian, he was by nature conservative and traditional. Stanley Payne notes that very few scholars consider him to be a "core fascist". The few consistent points in Franco's long rule were above all authoritarianism, nationalism, Catholicism, anti-Freemasonry, and anti-Communism.

With the end of World War II, Spain suffered from the consequences of its isolation from the international economy. Spain was excluded from the Marshall Plan, unlike other neutral countries in Europe. This situation ended in part when, in the light of Cold War tensions and of Spain's strategic location, the United States of America entered into a trade and military alliance with Franco. This historic alliance commenced with the visit of US President Dwight Eisenhower to Spain in 1953, which resulted in the Pact of Madrid. Spain was then admitted to the United Nations in 1955. American military facilities in Spain built since then include Naval Station Rota, Morón Air Base, and Torrejón Air Base.

The first decade of Franco's rule following the end of the Civil War in 1939 saw continued repression and the killing of an undetermined number of political opponents. Estimation is difficult and controversial, but the total number of people who were killed during this period probably lies somewhere between 15,000 and 50,000.

By the start of the 1950s Franco's state had become less violent, but during his entire rule, non-government trade unions and all political opponents across the political spectrum, from communist and anarchist organisations to liberal democrats and Catalan or Basque separatists, were either suppressed or tightly controlled with all means, up to and including violent police repression. The "Confederación Nacional del Trabajo" (CNT) and the "Unión General de Trabajadores" (UGT) trade unions were outlawed, and replaced in 1940 by the corporatist "Sindicato Vertical". The Spanish Socialist Workers' Party and the "Esquerra Republicana de Catalunya" (ERC) were banned in 1939, while the Communist Party of Spain (PCE) went underground. The Basque Nationalist Party (PNV) went into exile, and in 1959 the ETA armed group was created to wage a low-intensity war against Franco.

Franco's Spanish nationalism promoted a unitary national identity by repressing Spain's cultural diversity. Bullfighting and flamenco were promoted as national traditions while those traditions not considered "Spanish" were suppressed. Franco's view of Spanish tradition was somewhat artificial and arbitrary: while some regional traditions were suppressed, Flamenco, an Andalusian tradition, was considered part of a larger, national identity. All cultural activities were subject to censorship, and many, such as the Sardana, the national dance of Catalunya, were plainly forbidden (often in an erratic manner). This cultural policy was relaxed over time, most notably during the late 1960s and early 1970s.

Franco also used language politics in an attempt to establish national homogeneity. He promoted the use of Castilian Spanish and suppressed other languages such as Catalan, Galician, and Basque. The legal usage of languages other than Castilian was forbidden. All government, notarial, legal and commercial documents were to be drawn up exclusively in Castilian and any documents written in other languages were deemed null and void. The usage of any other language was forbidden in schools, in advertising, and on road and shop signs. For unofficial use, citizens continued to speak these languages. This was the situation throughout the 1940s and to a lesser extent during the 1950s, but after 1960 the non-Castilian Spanish languages were freely spoken and written, and they reached bookshops and stages, although they never received official status.

On the other hand, the Catholic Church was upheld as the established church of the Spanish State, and it regained many of the traditional privileges which it had lost under the Republic. Civil servants had to be Catholic, and some official jobs even required a "good behavior" statement by a priest. Civil marriages which had taken place in Republican Spain were declared null and void unless they had been confirmed by the Catholic Church. Divorce was forbidden, along with contraceptives and abortion.

Most country towns and rural areas were patrolled by pairs of "Guardia Civil", a military police force for civilians, which functioned as Franco's chief means of social control. Larger cities and capitals were mostly under the jurisdiction of the Policia Armada, or the "grises" ("greys", due to the colour of their uniforms) as they were called.

Student revolts at universities in the late 1960s and early 1970s were violently repressed by the heavily armed "Policía Armada" (Armed Police). Plain-clothed secret police worked inside Spanish universities.

The enforcement by public authorities of traditional Catholic values was a stated intent of the regime, mainly by using a law (the "Ley de Vagos y Maleantes", Vagrancy Act) enacted by Azaña. The remaining nomads of Spain (Gitanos and Mercheros like El Lute) were especially affected. Through this law, homosexuality and prostitution were made criminal offenses in 1954.

Francoism professed a devotion to the traditional role of a woman in society, that is being a loving daughter and sister to her parents and brothers, being a faithful wife to her husband, and residing with her family. Official propaganda confined the role of women to family care and motherhood. Immediately after the war most progressive laws passed by the Republic aimed at equality between the sexes were nullified. Women could not become judges, or testify in a trial. They could not become university professors. Their affairs and economic lives had to be managed by their fathers and husbands. Until the 1970s a woman could not have a bank account without a co-sign by her father or husband. In the 1960s and 1970s these restrictions were somewhat relaxed.

Spain attempted to retain control of its colonial empire throughout Franco's rule. During the Algerian War (1954–62), Madrid became the base of the "Organisation armée secrète" (OAS), a right-wing French Army group which sought to preserve French Algeria. Despite this, Franco was forced to make some concessions. When French Morocco became independent in 1956, he surrendered Spanish Morocco to Mohammed V, retaining only a few enclaves (the "Plazas de soberanía"). The year after, Mohammed V invaded Spanish Sahara during the Ifni War (known as the "Forgotten War" in Spain). Only in 1975, with the Green March, did Morocco take control of all of the former Spanish territories in the Sahara.

In 1968, under pressure from the United Nations, Franco granted Spain's colony of Equatorial Guinea its independence, and the next year it ceded the exclave of Ifni to Morocco. Under Franco, Spain also pursued a campaign to force a negotiation on the British overseas territory of Gibraltar, and closed its border with that territory in 1969. The border would not be fully reopened until 1985.

The Civil War ravaged the Spanish economy. Infrastructure had been damaged, workers killed, and daily business severely hampered. For more than a decade after Franco's victory, the devastated economy recovered very slowly. Franco initially pursued a policy of autarky, cutting off almost all international trade. The policy had devastating effects, and the economy stagnated. Only black marketeers could enjoy an evident affluence.

On the brink of bankruptcy, a combination of pressure from the United States, the IMF, managed to convince the regime to adopt a free market economy. Many of the old guard in charge of the economy were replaced by "technocrata", despite some initial opposition from Franco. From the mid-1950s there was modest acceleration in economic activity after some minor reforms and a relaxation of controls. But the growth proved too much for the economy, with shortages and inflation breaking out towards the end of the 1950s.

When Franco replaced his ideological ministers with the apolitical technocrats, the regime implemented several development policies that included deep economic reforms. After a recession, growth took off from 1959, creating an economic boom that lasted until 1974, and became known as the "Spanish Miracle".

Concurrent with the absence of social reforms, and the economic power shift, a tide of mass emigration commenced to other European countries, and to a lesser extent, to South America. Emigration helped the regime in two ways. The country got rid of populations it would not have been able to keep in employment, and the emigrants supplied the country with much needed monetary remittances.

During the 1960s, the wealthy classes of Francoist Spain experienced further increases in wealth, particularly those who remained politically faithful, while a burgeoning middle class became visible as the "economic miracle" progressed. International firms established factories in Spain where salaries were low, company taxes very low, strikes forbidden and workers' health or state protections almost unheard of. State-owned firms like the car manufacturer SEAT, truck builder Pegaso and oil refiner INH, massively expanded production. Furthermore, Spain was virtually a new mass market. Spain became the second-fastest growing economy in the world between 1959 and 1973, just behind Japan. By the time of Franco's death in 1975, Spain still lagged behind most of Western Europe but the gap between its per capita GDP and that of the leading Western European countries had narrowed greatly, and the country had developed a large industrialised economy.

Franco was reluctant to enact any form of administrative and legislative decentralisation and kept a fully centralised government with a similar administrative structure to that established by the House of Bourbon and General Miguel Primo de Rivera y Orbaneja. Such structures were based on the model of the French centralised state. The main drawback of this kind of management was that government attention and initiatives were irregular, and often depended more on the goodwill of regional government representatives than on regional needs. Thus, inequalities in schooling, health care and transport facilities among regions were patent: classically affluent regions like Madrid, Catalonia, or the Basque Country fared much better than Extremadura, Galicia or Andalusia. Some regions, like Extremadura or La Mancha did not have a university.

The Basque Country and Catalonia were among the regions that offered the strongest resistance to Franco in the Civil War. Franco dissolved the autonomy granted by the Second Spanish Republic to these two regions and to Galicia. Franco abolished the centuries-old fiscal privileges and autonomy (the "fueros") of two of the three Basque provinces: Guipuzcoa and Biscay, but kept them for Álava which had sided with the nationalists in the civil war.

Franco also decided to preserve Navarre's centuries old fiscal privileges and autonomy, the so-called Fueros of Navarre. Navarre, the northern half of which was Basque-speaking, was one of Franco's areas of greatest support during the civil war. The regional privileges for Álava and Navarre were kept because they had participated in the initial "coup d'état" against the Republican government on 18 July 1936.

Franco abolished the official statute and recognition of the Basque, Galician, and Catalan languages that the Second Spanish Republic had granted for the first time in the history of Spain. He returned to Castilian as the only official language of the state and education. The Franco era saw the popularisation of the compulsory national educational system and the development of modern mass media, both controlled by the state and both using the Castilian language, which significantly reduced the number of speakers of Basque, Catalan and Galician, as happened during the second half of the 20th century with other European minority languages which were not officially protected, such as Scottish Gaelic or French Breton. By the 1970s the majority of the population in urban areas could not speak the minority language or, as in some Catalan towns, their social use had been abandoned, leaving them limited to family use.

Because of the already fragile situation of the Basque language before the Civil War, it became the most endangered language in Spain. By the 1970s Basque lacked a sufficient number of new speakers to assure its future, and moved closer to extinction. It is now recognised that the Basque language would have disappeared in a few more decades if the same linguistic policies had been preserved. This was the main reason that drove the Francoist provincial government of Álava to create a network of Basque medium schools (Ikastola) in 1973 which were state-financed.

Franco decided to name a monarch to succeed his regency but the simmering tensions between the Carlists and the Alfonsoists continued. In a bid to avoid a repeat of the Carlist Wars, he offered the throne to the Habsburg Archduke Otto von Habsburg; by doing so he believed that he could eliminate the question of a Bourbon succession entirely since the Habsburg family which had ruled the Habsburg Spain during its golden age had an alternate claim to the Spanish throne before the War of the Spanish Succession. Archduke Otto declined, stating that he would be seen as a German ruling Spain and could never forget his Austrian identity. In 1969 Franco nominated as his heir-apparent Prince Juan Carlos de Borbón, who had been educated by him in Spain, with the new title of Prince of Spain. This designation came as a surprise to the Carlist pretender to the throne, as well as to Juan Carlos's father, Don Juan, the Count of Barcelona, who had a superior claim to the throne, but whom Franco feared to be too liberal.

However when Juan Carlos asked Franco if he could sit in on cabinet meetings, Franco would not permit him saying; "You would do things differently." Due to the spread of democracy excluding the Soviet block in Europe since the Second World War, Juan Carlos could or would not have been a dictator in the way Franco had been.

By 1973 Franco had surrendered the function of prime minister ("Presidente del Gobierno"), remaining only as head of state and commander in chief of the military.

As his final years progressed, tensions within the various factions of the "Movimiento" would consume Spanish political life, as varying groups jockeyed for position in an effort to win control of the country's future. The death of prime minister Luis Carrero Blanco in a 20 December 1973 bombing by ETA eventually gave an edge to the liberalizing faction. On 19 July 1974, the aged Franco fell ill from various health problems, and Juan Carlos took over as Acting Head of State. Franco soon recovered and on 2 September he resumed his duties as Head of State. A year later he fell ill again, afflicted with further health issues, including a long battle with Parkinson's disease. Franco's last public appearance was on 1 October 1975 when, despite his gaunt and frail appearance, he gave a speech to crowds from the balcony at the Royal Palace of El Pardo in Madrid. On 30 October 1975 he fell into a coma and was put on life support. Franco's family agreed to disconnect the life-support machines. Officially, he died a few minutes after midnight on 20 November 1975 from heart failure, at the age of 82 — the same date as the death of José Antonio Primo de Rivera, the founder of the Falange. Historian Ricardo de la Cierva claimed that he had been told around 6 pm on 19 November that Franco had already died. Juan Carlos was proclaimed King two days later.

Franco's body was interred at Valle de los Caídos, a colossal memorial built by the forced labour of political prisoners in order to honour the casualties of the Spanish Civil War. His funeral was attended by Prince Rainier III of Monaco, and Chilean dictator General Augusto Pinochet – who revered Franco and modelled his leadership style on the Spanish leader. Former US President Richard Nixon called Franco "a loyal friend and ally of the United States."

On 11 May 2017, the Congress of Deputies approved, by 198-1 with 140 abstentions, a motion driven by the Socialist Workers' Party ordering the Government to exhume Franco's remains.

On 24 August 2018, the Government of Prime Minister Pedro Sánchez approved legal amendments to the Historical Memory Law stating that only those who died during the Civil War will be buried at the Valle de los Caídos, resulting in plans to exhume Franco's remains for reburial elsewhere. Deputy Prime Minister Carmen Calvo Poyato stated that having Franco buried at the monument "shows a lack of respect ... for the victims buried there". The government gave Franco's family a 15-day deadline to decide Franco's final resting place, or else a "dignified place" will be chosen by the government.

On 13 September 2018, the Congress of Deputies voted 176–2, with 165 abstentions, to approve the government's plan to remove Franco's body from the monument.

Franco's family is opposed to the exhumation, and has made appeals to the Ombudsman's Office to stop it. If it proceeds regardless, the family has expressed their wish that Franco's remains be reinterred with full military honors at Almudena Cathedral in the centre of Madrid. The demand was rejected by the Spanish Government, which issued another 15-day deadline to choose another site. As the family refused to choose another location, the Spanish Government ultimately chose to rebury Franco at the cemetery at El Pardo next to his wife Carmen Polo. He was to be exhumed from the Valle de los Caídos on 10 June 2019, but the Supreme Court of Spain ruled that the exhumation would be delayed until the family has exhausted all possible appeals.

In Spain and abroad, the legacy of Franco remains controversial. The longevity of Franco's rule, his suppression of opposition, and the effective propaganda sustained through the years have made a detached evaluation difficult. For almost 40 years, Spaniards, and particularly children at school, were told that Divine Providence had sent Franco to save Spain from chaos, atheism, and poverty.

A highly controversial figure within Spain, Franco is seen as a divisive leader. Supporters credit him for keeping Spain neutral and uninvaded in World War II. They emphasize his strong anti-communist and nationalist views, economic policies, and opposition to socialism as major factors in Spain's post-war economic success and later international integration. Abroad he had support from Winston Churchill and many American Catholics, but was strongly opposed by the Truman Administration.

Conversely, critics on the left have denounced him as a tyrant responsible for hundreds of thousands of deaths in years-long political repression, and have called him complicit in atrocities committed by Axis forces during World War II due to his support of Axis governments.

When he died in 1975, the major parties of the left and the right agreed to follow the "Pact of Forgetting." In order to secure the transition to democracy, they agreed not to have investigations or prosecutions dealing with the civil war or Franco. The agreement effectively lapsed after 2000, the year the Association for the Recovery of Historical Memory was founded and the public debate started. In 2006, a poll indicated that almost two-thirds of Spaniards favored a "fresh investigation into the war."

The "Oxford Living Dictionary" uses Franco's regime as an example of fascism. Franco served as a role model for several anti-communist dictators in South America. Augusto Pinochet is known to have admired Franco. Similarly, as recently as 2006, Franco supporters in Spain have honored Pinochet.

In 2006, the BBC reported that Maciej Giertych, an MEP of the clerical-nationalist League of Polish Families, had expressed admiration for Franco, stating that the Spanish leader "guaranteed the maintenance of traditional values in Europe".

Spaniards who suffered under Franco's rule have sought to remove memorials of his regime. Most government buildings and streets that were named after Franco during his rule have been reverted to their original names. Owing to Franco's human-rights record, the Spanish government in 2007 banned all official public references to the Franco regime and began the removal of all statues, street names and memorials associated with the regime, with the last statue reportedly being removed in 2008 in the city of Santander. Churches that retain plaques commemorating Franco and the victims of his Republican opponents may lose state aid. Since 1978, the national anthem of Spain, the "Marcha Real", does not include lyrics introduced by Franco. Attempts to give the national anthem new lyrics have failed due to lack of consensus.
In March 2006, the Permanent Commission of the Parliamentary Assembly of the Council of Europe unanimously adopted a resolution "firmly" condemning the "multiple and serious violations" of human rights committed in Spain under the Francoist regime from 1939 to 1975. The resolution was at the initiative of Leo Brincat and of the historian Luis María de Puig, and was the first international official condemnation of the repression enacted by Franco's regime. The resolution also urged that historians (professional and amateur) be given access to the various archives of the Francoist regime, including those of the private "Fundación Francisco Franco" which, along with other Francoist archives, remain inaccessible to the public as of 2006. The "Fundación Francisco Franco" received various archives from the El Pardo Palace, and is alleged to have sold some of them to private individuals. Furthermore, the resolution urged the Spanish authorities to set up an underground exhibit in the Valle de los Caidos monument to explain the "terrible" conditions in which it was built. Finally, it proposed the construction of monuments to commemorate Franco's victims in Madrid and other important cities.

In Spain, a commission to "repair the dignity" and "restore the memory" of the "victims of Francoism" ("Comisión para reparar la dignidad y restituir la memoria de las víctimas del franquismo") was approved in 2004, and is directed by the socialist deputy Prime Minister María Teresa Fernández de la Vega.
Recently the Association for the Recovery of Historical Memory (ARHM) initiated a systematic search for mass graves of people executed during Franco's regime, which has been supported since the Spanish Socialist Workers' Party's (PSOE) victory during the 2004 elections by José Luis Rodríguez Zapatero's government. A "Ley de la memoria histórica de España" (Law on the Historical Memory of Spain) was approved on 28 July 2006, by the Council of Ministers, but it took until 31 October 2007, for the Congress of Deputies to approve an amended version as "The Bill to recognise and extend rights and to establish measures in favour of those who suffered persecution or violence during the Civil War and the Dictatorship" (in common parlance still known as Law of Historical Memory). The Senate approved the bill on 10 December 2007.

Official endeavors to preserve the historical memory of the Franco regime include exhibitions like the one the Museu d'Història de Catalunya (Museum of Catalan History) organised around the prison experience.

The accumulated wealth of Franco's family (including much real estate inherited from Franco, such as the "Pazo de Meirás", the "Canto del Pico" in Torrelodones and the Cornide Palace in A Coruña), and its provenance, have also become matters of public discussion. Estimates of the family's wealth have ranged from 350 million to 600 million euros. While Franco was dying, the francoist Cortes voted a large public pension for his wife Carmen Polo, which the later democratic governments kept paying. At the time of her death in 1988, Carmen Polo was receiving as a pension more than 12.5 million pesetas (four million more than the salary of Felipe González, then head of the government).








</doc>
<doc id="11467" url="https://en.wikipedia.org/wiki?curid=11467" title="Flash Crowd">
Flash Crowd

"Flash Crowd" is a 1973 English-language novella by science fiction author Larry Niven, one of a series about the social consequence of inventing an instant, practically free transfer booth.

One consequence not foreseen by the builders of the system was that with the almost immediate reporting of newsworthy events, tens of thousands of people worldwide — along with criminals — would teleport to the scene of anything interesting, thus creating disorder and confusion. The plot centers around a television journalist who, after being fired for his inadvertent role in inciting a post-robbery riot in Los Angeles, seeks to independently investigate the teleportation system for the flaws in its design allowing for such spontaneous riots to occur. His investigation takes him to destinations and people around the world within the matter of less than 12 hours before he gets his chance to plead his case on television, and he encounters the wide-ranging effects of displacements upon aspects of human behavior such as settlement, crime, natural resources, agriculture, waste management and tourism.



In various other books, for example "Ringworld", Niven suggests that easy transportation might be disruptive to traditional behavior and open the way for new forms of parties, spontaneous congregations, or shopping trips around the world. The central character in "Ringworld", celebrating his birthday, teleports across time-zones to "lengthen" his birthday multiple times (particularly notable since the first edition had the error of the character heading the wrong direction, increasing that edition's value).

Niven's essay "Exercise in Speculation: The Theory and Practice of Teleportation" was published in the collection "All the Myriad Ways" In it he discusses the ideas that underlie his teleportation stories.


On the World Wide Web, a similar phenomenon can occur, when a web site catches the attention of a large number of people, and gets an unexpected and overloading surge of traffic. This usage was first coined by John Pettitt of Beyond.com in 1996. Multiple other terms for the phenomenon exist, often coming from the name of a particular prominent, high-traffic site whose normal base of viewers can constitute a flash crowd when directed to a less famous website. Notorious examples include the "Slashdot effect", the "Instalanche" (when a smaller site gets links by the popular blog Instapundit), or a website being "Farked" or Drudged (where the target site is crashed due to the large number of hits in a short time).


</doc>
<doc id="11469" url="https://en.wikipedia.org/wiki?curid=11469" title="August Kekulé">
August Kekulé

Friedrich August Kekulé, later Friedrich August Kekule von Stradonitz (; ; 7 September 1829 – 13 July 1896), was a German organic chemist. From the 1850s until his death, Kekulé was one of the most prominent chemists in Europe, especially in theoretical chemistry. He was the principal founder of the theory of chemical structure.

Kekulé never used his first given name; he was known throughout his life as August Kekulé. After he was ennobled by the Kaiser in 1895, he adopted the name August Kekule von Stradonitz, without the French acute accent over the second "e". The French accent had apparently been added to the name by Kekulé's father during the Napoleonic occupation of Hesse by France, to ensure that French-speaking people pronounced the third syllable.

The son of a civil servant, Kekulé was born in Darmstadt, the capital of the Grand Duchy of Hesse. After graduating from secondary school (the Grand Ducal Gymnasium in Darmstadt), in the fall of 1847 he entered the University of Giessen, with the intention of studying architecture. After hearing the lectures of Justus von Liebig in his first semester, he decided to study chemistry. Following four years of study in Giessen and a brief compulsory military service, he took temporary assistantships in Paris (1851–52), in Chur, Switzerland (1852–53), and in London (1853–55), where he was decisively influenced by Alexander Williamson. His Giessen doctoral degree was awarded in the summer of 1852.

In 1856 Kekulé became Privatdozent at the University of Heidelberg. In 1858 he was hired as full professor at the University of Ghent, then in 1867 he was called to Bonn, where he remained for the rest of his career. Basing his ideas on those of predecessors such as Williamson, Edward Frankland, William Odling, Auguste Laurent, Charles-Adolphe Wurtz and others, Kekulé was the principal formulator of the theory of chemical structure (1857–58). This theory proceeds from the idea of atomic valence, especially the tetravalence of carbon (which Kekulé announced late in 1857) and the ability of carbon atoms to link to each other (announced in a paper published in May 1858), to the determination of the bonding order of all of the atoms in a molecule. Archibald Scott Couper independently arrived at the idea of self-linking of carbon atoms (his paper appeared in June 1858), and provided the first molecular formulas where lines symbolize bonds connecting the atoms. For organic chemists, the theory of structure provided dramatic new clarity of understanding, and a reliable guide to both analytic and especially synthetic work. As a consequence, the field of organic chemistry developed explosively from this point. Among those who were most active in pursuing early structural investigations were, in addition to Kekulé and Couper, Frankland, Wurtz, Alexander Crum Brown, Emil Erlenmeyer, and Alexander Butlerov.

Kekulé's idea of assigning certain atoms to certain positions within the molecule, and schematically connecting them using what he called their "Verwandtschaftseinheiten" ("affinity units", now called "valences" or "bonds"), was based largely on evidence from chemical reactions, rather than on instrumental methods that could peer directly into the molecule, such as X-ray crystallography. Such physical methods of structural determination had not yet been developed, so chemists of Kekulé's day had to rely almost entirely on so-called "wet" chemistry. Some chemists, notably Hermann Kolbe, heavily criticized the use of structural formulas that were offered, as he thought, without proof. However, most chemists followed Kekulé's lead in pursuing and developing what some have called "classical" structure theory, which was modified after the discovery of electrons (1897) and the development of quantum mechanics (in the 1920s).

The idea that the number of valences of a given element was invariant was a key component of Kekulé's version of structural chemistry. This generalization suffered from many exceptions, and was subsequently replaced by the suggestion that valences were fixed at certain oxidation states. For example, periodic acid according to Kekuléan structure theory could be represented by the chain structure I-O-O-O-O-H. By contrast, the modern structure of (meta) periodic acid has all four oxygen atoms surrounding the iodine in a tetrahedral geometry.

Kekulé's most famous work was on the structure of benzene. In 1865 Kekulé published a paper in French (for he was then still in Belgium) suggesting that the structure contained a six-membered ring of carbon atoms with alternating single and double bonds. The following year he published a much longer paper in German on the same subject.

The empirical formula for benzene had been long known, but its highly unsaturated structure was a challenge to determine. Archibald Scott Couper in 1858 and Joseph Loschmidt in 1861 suggested possible structures that contained multiple double bonds or multiple rings, but the study of aromatic compounds was in its earliest years, and too little evidence was then available to help chemists decide on any particular structure.

More evidence was available by 1865, especially regarding the relationships of aromatic isomers. Kekulé argued for his proposed structure by considering the number of isomers observed for derivatives of benzene. For every monoderivative of benzene (CHX, where X = Cl, OH, CH, NH, etc.) only one isomer was ever found, implying that all six carbons are equivalent, so that substitution on any carbon gives only a single possible product. For diderivatives such as the toluidines, CH(NH)(CH), three isomers were observed, for which Kekulé proposed structures with the two substituted carbon atoms separated by one, two and three carbon-carbon bonds, later named ortho, meta, and para isomers respectively.

The counting of possible isomers for diderivatives was however criticized by Albert Ladenburg, a former student of Kekulé, who argued that Kekulé's 1865 structure implied two distinct "ortho" structures, depending on whether the substituted carbons are separated by a single or a double bond. Since ortho derivatives of benzene were never actually found in more than one isomeric form, Kekulé modified his proposal in 1872 and suggested that the benzene molecule oscillates between two equivalent structures, in such a way that the single and double bonds continually interchange positions. This implies that all six carbon-carbon bonds are equivalent, as each is single half the time and double half the time. A firmer theoretical basis for a similar idea was later proposed in 1928 by Linus Pauling, who replaced Kekulé's oscillation by the concept of resonance between quantum-mechanical structures.

The new understanding of benzene, and hence of all aromatic compounds, proved to be so important for both pure and applied chemistry after 1865 that in 1890 the German Chemical Society organized an elaborate appreciation in Kekulé's honor, celebrating the twenty-fifth anniversary of his first benzene paper. Here Kekulé spoke of the creation of the theory. He said that he had discovered the ring shape of the benzene molecule after having a reverie or day-dream of a snake seizing its own tail (this is an ancient symbol known as the ouroboros).

A similar humorous depiction of benzene had appeared in 1886 in the "Berichte der Durstigen Chemischen Gesellschaft" (Journal of the Thirsty Chemical Society), a parody of the "Berichte der Deutschen Chemischen Gesellschaft", only the parody had monkeys seizing each other in a circle, rather than snakes as in Kekulé's anecdote. Some historians have suggested that the parody was a lampoon of the snake anecdote, possibly already well-known through oral transmission even if it had not yet appeared in print. Others have speculated that Kekulé's story in 1890 was a re-parody of the monkey spoof, and was a mere invention rather than a recollection of an event in his life. 

Kekulé's 1890 speech, in which these anecdotes appeared, has been translated into English. If one takes the anecdote as reflecting an accurate memory of a real event, circumstances mentioned in the story suggest that it must have happened early in 1862.

He told another autobiographical anecdote in the same 1890 speech, of an earlier vision of dancing atoms and molecules that led to his theory of structure, published in May 1858. This happened, he claimed, while he was riding on the upper deck of a horse-drawn omnibus in London. Once again, if one takes the anecdote as reflecting an accurate memory of a real event, circumstances related in the anecdote suggest that it must have occurred in the late summer of 1855.

In 1895 Kekulé was ennobled by Kaiser Wilhelm II of Germany, giving him the right to add "von Stradonitz" to his name, referring to a possession of his patrilineal ancestors in Stradonice, Bohemia. This title was used by his son, genealogist Stephan Kekulé von Stradonitz. Of the first five Nobel Prizes in Chemistry, Kekulé's students won three: van 't Hoff in 1901, Fischer in 1902 and Baeyer in 1905.

A larger-than-life size monument of Kekulé is situated in front of the former Chemical Institute at the University of Bonn. His monument is often decorated by students, e.g. for Valentine's Day.





</doc>
<doc id="11472" url="https://en.wikipedia.org/wiki?curid=11472" title="Frederick III, Holy Roman Emperor">
Frederick III, Holy Roman Emperor

Frederick III (21 September 1415 – 19 August 1493) was Holy Roman Emperor from 1452 until his death. He was the first emperor of the House of Habsburg, and the fourth member of the House of Habsburg to be elected King of Germany after Rudolf I of Germany, Albert I in the 13th century and his predecessor Albert II of Germany. He was the penultimate emperor to be crowned by the Pope, and the last to be crowned in Rome.

Prior to his imperial coronation, he was duke of the Inner Austrian lands of Styria, Carinthia and Carniola from 1424, and also acted as regent over the Duchy of Austria (as Frederick V) from 1439. He was elected and crowned King of Germany (as Frederick IV) in 1440. He was the longest-reigning German monarch when in 1493, after ruling his domains for more than 53 years, he was succeeded by his son Maximilian I.

During his reign, Frederick concentrated on re-uniting the Habsburg "hereditary lands" of Austria and took a lesser interest in Imperial affairs. Nevertheless, by his dynastic entitlement to Hungary as well as by the Burgundian inheritance, he laid the foundations for the later Habsburg Empire. Mocked as "Arch-Sleepyhead of the Holy Roman Empire" () during his lifetime, he is today increasingly seen as an efficient ruler.

Born at the Tyrolean residence of Innsbruck in 1415, Frederick was the eldest son of the Inner Austrian duke Ernest the Iron, a member of the Leopoldian line of the Habsburg dynasty, and his second wife Cymburgis of Masovia. According to the 1379 Treaty of Neuberg, the Leopoldinian branch ruled over the duchies of Styria, Carinthia and Carniola, or what was referred to as Inner Austria. Only three of Frederick's eight siblings survived childhood: his younger brother Albert (later to be Albert VI, archduke of Austria), and his sisters Margaret (later the electress of Saxony) and Catherine. In 1424, nine-year-old Frederick's father died, making Frederick the duke of Inner Austria, as Frederick V, with his uncle, Duke Frederick IV of Tyrol, acting as regent.

From 1431, Frederick tried to obtain majority (to be declared "of age", and thus allowed to rule) but for several years was denied by his relatives. Finally, in 1435, Albert V, duke of Austria (later Albert II, the king of Germany), awarded him the rule over his Inner Austrian heritage. Almost from the beginning, Frederick's younger brother Albert asserted his rights as a co-ruler, as the beginning of a long rivalry. Already in these years, Frederick had begun to use the symbolic A.E.I.O.U. signature as a kind of motto with various meanings. In 1436 he made a pilgrimage to the Holy Land, accompanied by numerous nobles knighted by the Order of the Holy Sepulchre, which earned him great reputation.

Upon the death of his uncle Duke Frederick IV in 1439, Frederick took over the regency of Tyrol and Further Austria for the duke's heir Sigismund. Again he had to ward off the claims raised by his brother Albert VI; he prevailed by the support of the Tyrolean aristocracy. Likewise he acted as regent for his nephew Ladislaus the Posthumous, son of late King Albert II and his consort Elizabeth of Luxembourg, in the duchy of Austria (Further Austria). (Ladislaus would die before coming of age). Frederick was now the undisputed head of the Habsburg dynasty, though his regency in the lands of the Albertinian Line (Further Austria) was still viewed with suspicion.

As a cousin of late King Albert II, Frederick became a candidate for the imperial election. On 2 February 1440, the prince-electors convened at Frankfurt and unanimously elected him King of the Romans as Frederick IV; his rule was still based on his hereditary lands of Styria, Carinthia and Carniola, or Inner Austria.

In 1442, Frederick allied himself with Rudolf Stüssi, burgomaster of Zurich, against the Old Swiss Confederacy in the Old Zurich War (Alter Zürichkrieg) but lost. In 1448, he entered into the Concordat of Vienna with the Holy See, which remained in force until 1806 and regulated the relationship between the Habsburgs and the Holy See.

In 1452, at the age of 37, Frederick III travelled to Italy to receive his bride and to be crowned Holy Roman Emperor. His fiancée, the 18-year-old "infanta" Eleanor, daughter of King Edward of Portugal, landed at Livorno (Leghorn) after a 104-day trip. Her dowry would help Frederick alleviate his debts and cement his power. The couple met at Siena on 24 February and proceeded together to Rome. As per tradition, they spent a night outside the walls of Rome before entering the city on 9 March, where Frederick and Pope Nicholas V exchanged friendly greetings. Because the emperor had been unable to retrieve the Iron Crown of Lombardy from the cathedral of Monza where it was kept, nor be crowned King of Italy by the archbishop of Milan (on account of Frederick's dispute with Francesco Sforza, lord of Milan), he convinced the pope to crown him as such with the German crown, which had been brought for the purpose. This coronation took place on the morning of 16 March, in spite of the protests of the Milanese ambassadors, and in the afternoon Frederick and Eleanor were married by the pope. Finally, on 19 March, Frederick and Eleanor were anointed in St Peter's Basilica by the Vice-Chancellor of the Holy Roman Church, Cardinal Francesco Condulmer, and Frederick was then crowned with the Imperial Crown by the pope. Frederick was the last Emperor to be crowned in Rome; his great-grandson Charles V was the last emperor to be crowned, but this was done in Bologna.

Frederick's style of rulership was marked by hesitation and a sluggish pace of decision making. The Italian humanist Enea Silvio Piccolomini, later Pope Pius II, who at one time worked at Frederick's court, described the Emperor as a person who wanted to conquer the world while remaining seated. Although this was regarded as a character flaw in older academic research, his delaying tactics are now viewed as a means of coping with political challenges in far-flung territorial possessions. Frederick is credited with having the ability to sit out difficult political situations patiently.

According to contemporary accounts, Frederick had difficulties developing emotional closeness to other persons, including his children and wife Eleanor. In general, Frederick kept himself away from women, the reasons for which are not known. As Frederick was rather distant to his family, Eleanor had a great influence on the raising and education of Frederick's children, and she therefore played an important role in the House of Habsburg's rise to prominence. Despite the fact that their marriage had been unhappy, when Eleanor died the Emperor was affected by her loss and remained widowed for the rest of his long life.

Frederick's political initiatives were hardly bold, but they were still successful. His first major opponent was his brother Albert VI, who challenged his rule. He did not manage to win a single conflict on the battlefield against him, and thus resorted to more subtle means. He held his second cousin once removed Ladislaus the Posthumous, the ruler of the Archduchy of Austria, Hungary and Bohemia, (born in 1440) as a prisoner and attempted to extend his guardianship over him in perpetuity to maintain his control over Lower Austria. Ladislaus was freed in 1452 by the Lower Austrian estates. He acted similarly towards his first cousin Sigismund of the Tyrolian line of the Habsburg family. Despite those efforts, he failed to gain control over Hungary and Bohemia in the Bohemian–Hungarian War (1468–78) and was even defeated in the Austrian–Hungarian War (1477–88) by the Hungarian King Matthias Corvinus in 1485, who managed to maintain residence in Vienna until his death five years later in the Siege of Vienna.

Ultimately, Frederick prevailed in all those conflicts by outliving his opponents and sometimes inheriting their lands, as was the case with Ladislaus, from whom he gained Lower Austria in 1457, and with his brother Albert VI, whom he succeeded in Upper Austria. In 1462, his brother Albert raised an insurrection against him in Vienna and the emperor was besieged in his residence by rebellious subjects. In this war between the brothers, Frederick received support from the King of Bohemia, George of Poděbrady. These conflicts forced him into an anachronistic itinerant existence, as he had to move his court between various places through the years, residing in Graz, Linz and . owes him its castle and the "New Monastery".

Still, in some ways his policies were astonishingly successful. In the Siege of Neuss (1474–75), he forced Charles the Bold of Burgundy to give up his daughter Mary of Burgundy as wife to Frederick's son Maximilian. With the inheritance of Burgundy, the House of Habsburg began to rise to predominance in Europe. This gave rise to the saying "Let others wage wars, but you, happy Austria, shall marry", which became a motto of the dynasty.

Frederick secured in 1486 the succession of the son in his own lifetime. On 16 February 1486 Maximilian was unanimously elected Roman-German king at the Frankfurt Reichstag by the six electors present. The Elector of Bohemia was not invited because the Bohemian spa law might have been claimed by the Hungarian King Corvinus. The choice of Maximilian violated the rules of the Golden Bull. Protests against the irregular election remained in the kingdom but out. Fearing that the Electors would take advantage of his son's political inexperience, Friedrich Maximilian did not equip him with government powers. On the occasion of the election of Maximilian, a ten-year land peace was decided. In order to safeguard the peace of the land and against the expansive territorial policy of the Wittelsbachs, numerous affected empire-related states of Swabia joined in 1488 on Frederick's initiative for the Swabian League. After the royal election Frederick accompanied his son to Aachen, where Maximilian was crowned on 9 April 9 1486.

The marriage of his daughter Kunigunde to Albert IV, Duke of Bavaria, was another result of intrigues and deception, but must be counted as a defeat for Frederick. Albert illegally took control of some imperial fiefs and then asked to marry Kunigunde (who lived in Innsbruck, far from her father), offering to give her the fiefs as a dower. Frederick agreed at first, but after Albert took over yet another fief, Regensburg, Frederick withdrew his consent. On 2 January 1487, however, before Frederick's change of heart could be communicated to his daughter, Kunigunde married Albert. A war was prevented only through the mediation of the Emperor's son, Maximilian.

In some smaller matters, Frederick was quite successful: in 1469 he managed to establish bishoprics in Vienna and , a step that no previous Duke of Austria had been able to achieve.

Frederick's personal motto was the mysterious string A.E.I.O.U., which he imprinted on all his belongings. He never explained its meaning, leading to many different interpretations being presented, although it has been claimed that shortly before his death he said it stands for ' or ' ("All the world is subject to Austria"). It may well symbolise his own understanding of the historical importance and meaning of his rule and of the early gaining of the Imperial title.

Frederick had five children from his marriage with Eleanor of Portugal:
For the last 10 years of Frederick's life, he and Maximilian ruled jointly.

In his last years Friedrich remained in the region on the Danube, in Vienna and in Linz. In 1492 he was elected Knight of the Order of the Golden Fleece. Since February 1493, Frederick's health deteriorated increasingly. In the Lent of 1493, Friedrich's personal physicians diagnosed Kaiser in the left leg as a symptom, usually referred to as age-burning, in the research literature, which according to current medical terminology is considered to be the result of arteriosclerosis. On 8 June 1493 he was amputated under the direction of the surgeon Hans Seyff in the Linz castle of the affected area of the leg. This leg amputation is considered one of the most famous and best-documented surgical procedures of the entire Middle Ages. Although Frederick initially survived the procedure well, he died on 19 August 1493 in Linz at the age of 77. The contemporaries cited as the cause of death the consequences of leg amputation, senility or rapid diarrhea caused by melon consumption. His bowels were probably buried separately on 24 August 1493 in the Linz parish church. The arrival of Turks in Carinthia and the Krain delayed the arrival of Maximilian and with it the funeral service. On 6 and 7 December 1493, the funeral took place in St. Stephen's Cathedral. [5]

His grave, built by Nikolaus Gerhaert von Leyden, in St. Stephen's Cathedral, Vienna, is one of the most important works of sculptural art of the late Middle Ages. (His amputated leg was buried with him.) The heavily adorned tomb was not completed until 1513, two decades after Frederick's death, and has survived in its original condition.




</doc>
<doc id="11475" url="https://en.wikipedia.org/wiki?curid=11475" title="Fuerteventura">
Fuerteventura

Fuerteventura () is one of the Canary Islands, in the Atlantic Ocean and is part of the North Africa region, politically part of Spain. At , it is the second largest of the Canary Islands, after Tenerife. Fuerteventura in 2018 had 113,275 inhabitants. It was declared a biosphere reserve by UNESCO in May 2009. Its capital is Puerto del Rosario.

The island's name is a compound word formed by the Spanish words for "strong" (fuerte) and "fortune" (ventura). Traditionally, Fuerteventura's name has been regarded as a reference to the strong winds around the island and the resulting danger to nautical adventurers. However, it might have referred instead (or also) to wealth, luck or destiny. 

In 1339 the Mallorcan navigator Angelino Dulcert, in the Planisferio de Angelino Dulcert, referred to the island as "Forte Ventura". 

Another theory is that the island's name derives from "Fortunatae Insulae" (Fortunate Islands), the name by which the Romans knew the Canary Islands.

The indigenous name of the island, before its conquest in the 15th century, was Erbania, divided into two regions (Jandía and Maxorata), from which the name majorero (originally majo or maxo) derives. However, it has been suggested that, at some point, Maxorata (which meant "the children of the country") was the aboriginal toponym of the entire island.

The first settlers of Fuerteventura are believed to have come from North Africa. The word "Mahorero" ("Majorero") or "Maho" is still used today to describe the people of Fuerteventura and is derived from the ancient word 'mahos', a type of goatskin shoe worn by these original inhabitants. They lived in caves and semi-subterranean dwellings, some of which have been excavated, revealing remnants of early tools and pottery. In antiquity, the island was known o.a. as "Planaria", in reference to the flatness of most of its terrain.

In the 11th century BC, Phoenician settlers landed in Fuerteventura and Lanzarote.

Several Spanish and Portuguese expeditions to the islands were organized around 1340, followed by Moors and European slave traders. At the end of the Iberian conquest, the island was divided into two Guanches kingdoms, one adhering to King Guize and the other to King Ayoze. The territories of these kingdoms were called Maxorata (in the North) and Jandía (in the South) respectively. They were separated by a wall, which traversed the La Pared isthmus. Some remains have been preserved. The ancient name for the island, Erbania, is derived from this wall's name.

The island's conquest began in earnest in 1402, commanded by French knights and crusaders Jean de Béthencourt and Gadifer de la Salle. They arrived with only 63 sailors out of the original 283, as many had deserted along the way. After arriving and settling in Lanzarote, the invaders made some first excursions to the neighboring islands. In 1404, Bethencourt and Gadifer founded Betancuria, on the West coast, the first settlement on the island. After numerous difficulties, Gadifer took charge of the invasion, while Bethencourt returned to Spain to seek the recognition and support of the Castilian king.
In 1405, de Béthencourt completed his conquest of the island, establishing its capital in Betancuria (Puerto Rosario took over the mantle as island capital in 1835).

In 1424 Pope Martin V, through the Betancuria Brief, edicted the establishment of the Bishopric of Fuerteventura, which encompassed all the Canary Islands save for the island of Lanzarote. The origin of this bishopric is directly related to the events that occurred after the Great Schism (1378-1417), in that the bishop of San Marcial del Rubicón of Lanzarote (at the time, the only diocese in the Canary Islands) did not recognize the papacy of Martin V, and instead adhered to anti-Pope Benedict XIII. The "Bishopric of Fuerteventura" was based in the "Parish of Santa María de Betancuria", bestowing upon the latter the status of Grant Cathedral. After the reabsorbtion of the "Diocese of San Marcial del Rubicón" by the papacy of Pope of Martin V, the Bishopric of Fuerteventura was abolished in 1431, only seven years after it was created.

The first census recorded a population of some 1,200 inhabitants. The population increased gradually thereafter. In 1476 the territory became the "Señorío Territorial de Fuerteventura", subjected to the Catholic Monarchs. In later years, the island was invaded by the Spanish, French and the English.

Over time, the island endured numerous pirate raids. A Berber-led expedition invaded in 1593, sweeping as far inland as the capital. Various castles were built along the coastline, to protect against these type of attacks. The population was moved inland as a second protective measure. Because of the raids, a first "Captain General" was dispatched to Fuerteventura, accompanied by a number of "Sergeant Majors", to defend the island in the name of the Crown. At that time Betancuria became the religious capital of the island.

Two major pirate attacks took place in 1740, within a month of each other. Two separate bands of English privateers attempted to loot the town of Tuineje. These attacks were however successfully averted by the local population and the island's militia. This successful repelling of the invaders is celebrated at a re-enactment that takes place in Gran Tarajal every year in October.

The island's garrison was officially instated in 1708. Its colonel assumed the title of "Governor at Arms", a hereditary, lifelong appointment which has remained in the Sánchez-Dumpiérrez family. In time, this family increasingly garnered power over the other islands through alliances with the family of Arias de Saavedra and the Lady of Fuerteventura. During the same year the "Assistant Parish of La Oliva and Pájara" was created, to become operational in 1711. On December 17, 1790 the "Assistant Parish of Tuineje" was created, which became a new parish division on June 23, 1792 under the bishop Tavira, with lands including part of the Jandía peninsular, and with a population of 1,670 inhabitants. 1780 saw the start of a barrilla plantation industry.

In 1852, a free trade zone was extended by Isabella II to the Canary Islands. Military island rule, which began in 1708, was finally dissolved in 1859, and Puerto de Cabras (now Puerto del Rosario) became the new capital.
The Canary Islands obtained self-governance in 1912. In 1927, Fuerteventura and Lanzarote became part of the province of Gran Canaria. The seat of the island's government ("cabildo insular") is located in Puerto del Rosario. A total of 74,983 people lived on the island in 2003.

By the 1940s the island had an airport (just west of Puerto del Rosario on the road to Tindaya, still visible today). Mass tourism began to arrive in the mid-1960s, facilitated by the construction of Fuerteventura Airport at El Matorral and the first tourist hotels.

The island's proximity (a mere 100 km) to the West African coast and the fact that it is part of the Schengen territory make it a prime target destination for undocumented immigrants. However, many have perished while attempting the crossing.

The flag of Fuerteventura is in proportions 1:2, divided vertically, green to the hoist and white to the fly end, with the coat of arms of the island in the centre.

The coat of arms of Fuerteventura was prescribed by a Decree adopted on 15 October 1998 by the Government of the Canary Islands and published on 11 November 1998 in the official gazette of the Canary Islands, No. 142, pp. 13,432-13,433. It was adopted on 24 April 1998 by the Island Council and validated on 18 September 1998 by the Heraldry Commission of the Canary Islands.

The heraldic description is "per pale and per fess. First, gules, a castle or, masoned sable, its gate and windows azure. 
Second, argent, lion gules, crowned, armed and langued or. Third, silver, three fesses chequy gules and or, in four rows, each one charged with a fess or. 
Bordure gules, with eight saltires or. Ensigned with a royal crown, open."

According to José Manuel Erbez (Banderas y escudos de Canarias, 2007), the coat of arms is based on the arms of the island's provincial militia. 
The upper quarters represent Castile (symbolized by a castle) and León (symbolized by a lion). The lower quarter alludes to the Saavedra family; various members of this family were lords of Fuerteventura.
The elongated island has an area of . The island is long and wide. It is part of the province of Las Palmas. It is divided into six municipalities:
100 individual settlements are distributed through these municipalities. A nearby islet, Islote de Lobos, is part of the municipality of La Oliva.

Located just off the coast of North Africa, it is the second biggest of the islands, after Tenerife, and has the longest white sand beaches in the archipelago. The island is a destination for sun, beach and watersports enthusiasts. It lies at the same latitude as Florida and Mexico and temperatures rarely fall below or rise above . It counts 152 separate beaches along its seaboard — of white sand and of black volcanic shingle.

The highest point in Fuerteventura is Pico de la Zarza (807 m) in the southwestern part of the island. Geographical features include Istmo de la Pared which is wide and is the narrowest part of Fuerteventura. The island is divided into two parts, the northern portion which is Maxorata and the southwestern part called the Jandía peninsula.

Fuerteventura is the oldest island in the Canary Islands dating back 20 million years to a volcanic eruption from the Canary hotspot. The majority of the island was created about 5 million years ago and since then has been eroded by wind and precipitation. On the seabed off the West coast of the island rests an enormous slab of bedrock long and wide, which appears to have slid off the island largely intact at some point in prehistory, similar to the predicted future collapse of Cumbre Vieja, a geological fault on another Canary Island, La Palma. The last volcanic activity in Fuerteventura occurred between 4,000 and 5,000 years ago.

Fuerteventura was chosen among 500 European destinations by the Quality Coast International Certification Program of the European Coastal and Marine Union as one of the most attractive tourist destinations for visitors interested in cultural heritage, environment and sustainability.

The climate on Fuerteventura is pleasant throughout the year. The island is hence referred to as "the island of eternal spring". The sea regulates air temperature, diverting hot Sahara winds away from the island. The island's name in English translates as "strong fortune" or "strong wind", the Spanish word for wind being "viento". During the winter months, temperatures average a high of and a low of around , whereas during the summer a mean high of and a low of can be expected. Precipitation is about per year, most of which falls in autumn and winter. December is the month with highest rainfall.

A sandstorm known as the Calima (similar to the Sirocco wind, which blows to the North of the Sahara, to Europe) may blow from the Sahara Desert to the Northwest, and can cause high temperatures, low visibility and drying air. Temperatures during this phenomenon rise temporarily by approximately 10 degrees Celsius. The wind brings in fine red dust, The fine white sand is not blown in from Sahara, It is made up of dead coral reef and local seabed upheaval. visibility can drop to between or even lower and can even bring African locusts to the island.

The island is home to one of the two surviving populations of the threatened Canarian Egyptian vulture. It is also inhabited by many wild dogs and cats. On the barren, rocky land there are Barbary ground squirrels and geckos. Fuerteventura also hosts several migratory and nesting birds. The island has significant populations of the collared dove, common swifts and several finch species especially in the vicinity of holiday developments.

Despite its arid climate, the island is also home to a surprisingly large insect fauna. Butterflies which commonly occur on the island include the clouded yellow ("Colias hyale") and the bath white ("Pontia daplidice") which feeds on xerophytic cruciferae. The island is also home to the monarch butterfly ("Danaus plexippus") and its close African relative "Danaus chrysippus". Around holiday developments such as Caleta de Fuste, water is relatively abundant, and dragonfly species including the blue emperor ("Anax imperator") and the scarlet darter ("Crocothemis erythraea") can be found. The island's sand dunes and shoreline are home to a number of bee and wasp species including the large eumenid caterpillar hunting wasp, "Delta dimidiatipenne" and the blue banded bee, ("Amegilla canifrons").

Hawkmoths also occur on the island. One of the more notable species is "Hyles tithymali" which feeds on endemic spurges such as "Euphorbia regis-jubae". "Acherontia atropos", the deaths-head hawkmoth also occurs on the island presumably feeding on members of the Solanaceae, for example, "Datura innoxia" and "Nicotiana glauca" which are common weeds in the vicinity of human habitation.

The official natural symbols associated with Fuerteventura are "Chlamydotis undulata fuertaventurae" (hubara or houbara) and "Euphorbia handiensis" (Cardón de Jandía).

The island has a population of 113,275. Throughout its long history, Fuerteventura has suffered from a population decline due to the economic situation and the climate, which have made it into a desert island. However, the development of tourism during the 1980s has caused the population to grow year on year since then, doubling it in a little less than a decade.

In 2005, with 86,642 registered inhabitants, the Fuerteventura population was formed by the following:

Comparing this data with the 2001 census shows that the number of permanent residents born on the island has increased by just 3,000. The number who have moved in from abroad has increased by 22,910, making this the biggest contributor to population growth in recent years.

The island has 116 schools, with a total of 14,337 pupils. Of these, 45 are primary schools, ten are secondary schools, six are for Baccalaureate students and four are vocational colleges.

Fuerteventura also has a centre linked with the National University of Distance Education, offering courses in many subjects including economics, business studies, law, history and tourism.

Fuerteventura is governed by the Island Department of the Government of Spain, which holds the rank of a Government Subdepartment. The government building is located in the centre of the capital city, in front of the parish church of the Virgin of Rosario, the patron saint of Puerto del Rosario municipality.

This institution is charged with representing the Government of Spain on the island, and managing all the functions that are not under control of the Canarian Government. This includes the following public services:

Since 30 June 2007, the island's governor has been Eustaquio Juan Santana Gil. 4

The councils, formed as part of the Councils Act of 1912, administer the Canary Islands and have two principal functions. On one hand, they perform services for the Autonomous Community, and on the other, they are the local government centre for the island. In the 2003 elections, Mario Cabrera González was elected as president representing the Canarian Coalition, with 31.02% of the votes, followed by the Spanish Socialist Workers' Party with 27.53%, represented by the Vice President Domingo Fuentes Curbelo.

The island is divided into six municipalities with their respective city councils which form part of the FECAM (Federation of Canarian Municipalities). They are governed by the basic legislation of the local regime and their respective organic rules. The populations of the municipalities are as follows:

In turn, these municipalities are organised into two associations: the "Mancomunidad de Municipios del Centro-Norte de Fuerteventura" formed from La Oliva and Puerto del Rosario, and the remaining municipalities make up the "Mancomunidad de Municipios del Centro-Sur de Fuerteventura".

The economy of Fuerteventura is mainly based on tourism. Primary tourist areas are located around the existing towns of Corralejo in the north and Morro Jable in Jandia, plus the purely tourist development of Caleta de Fuste, south of Puerto del Rosario. Other main industries are fishing and agriculture (cereals and vegetables). The famous Majorero cheese is locally made from the milk of the indigenous majorera goat.

In 2009, Fuerteventura recorded the highest EU regional unemployment rate at a NUTS3 level, at 29.2 percent.

The first tourist hotel was built in 1965 followed by the construction of Fuerteventura Airport at El Matorral, heralding the dawn of a new era for the island. Fuerteventura, with its 3,000 sunshine hours a year, was placed firmly on the world stage as a major European holiday destination.
While having fully developed tourist facilities, the island has not experienced the overdevelopment found on some other islands. Nonetheless, it remains a destination for predominantly but not exclusively European tourists.

The summer Trade Winds and winter swells of the Atlantic make this a year-round surfers' paradise, with more exposed areas on the north and west shores such as Corralejo and El Cotillo proving most popular. Wind surfing takes places at locations around the island. Sailors, scuba divers and big-game fishermen are all drawn to these clear blue Atlantic waters where whales, dolphins, marlin and turtles are all common sights. With many hills present throughout the Island, hikers are also attracted to this Island.

Excellent sandy beaches are found in many locations. Western beaches, such as those around El Cotillo, can experience strong surf. The beaches adjoining the extensive sand dunes east of Corralejo are popular, as are the more protected extensive sandy shores of the Playa de Sotavento de Jandia on the southeastern coast between Costa Calma and the Morro Jable. Naked sun bathing and swimming are the norm almost on all beaches.

Much of the interior, with its large plains, lavascapes and volcanic mountains, consists of protected areas, although there are organised tours and vehicular access across them.

Like the rest of the Canaries, Carnival is traditionally one of the biggest festivals celebrated on the island. It is celebrated in different ways in all the towns during February and March. These festivities have a different theme each year. They include activities such as parades and galas to choose the carnival king.

There are many concerts and festivals held in the auditoriums, such as the Festival of Canarian Music. They are also held in smaller venues across the island, featuring bands such as Estopa, Van Gogh's Ear, and King Afrhica.


Festival Internacional de Cometas/International Kite Festival is held on the second week of November each year centering on the Corralejo Beaches. It attracts kitefliers and kite surfers from all over Europe. It is popular because the winds are warm and constant and the beaches become filled with hundreds of colourful kites of all shapes and sizes.

Fuerteventura has three auditoriums. These are used for all types of performing art. They are also used for non-artistic purposes, such as conferences, charity galas and political meetings.


The Central Library of the Island is located in Antigua's city centre, in the public university. In addition to providing the traditional library services, it has a 180-seat multipurpose room, air conditioning, a wifi zone, and a multimedia room used for seminars, presentations, film festivals etc.

The island has several museums with different themes and plenty of exhibition spaces, both public and private. These include:


In addition to the museums, the capital Puerto del Rosario has an open-air sculpture park consisting of around 100 sculptures by different artists scattered across the city. Most of them were created for the International Symposium of Sculpture celebrated annually since 2001. During the festival, artists come from all over the world to erect their sculptures in the open air, in full view of passers by.

Sites of interest include Corralejo and El Jable to the north which are made up of fine sand dunes whilst the south is filled with long beaches and remote bays. The constant winds blowing onto the beaches provide a paradise for windsurfing. Surfing is common on the west and north coasts where there are large waves. Windsurfing is common around Corralejo and Playas de Sotavento and wave sailing (windsurfing on the waves) on the coast along the northern half of the island. El Cotillo is a small fishing village in the north-west of the Island famous for a very long beach to the south of the village and few very calm beaches to the north. The northern beaches frequented by snorkeling enthusiasts and sun worshippers alike are referred to as lakes by the locals. 

At Cofete on the western side of Jandía a remote and imposing house - Villa Winter - looks out to sea across wide beaches. It was reputedly built by a Mr Winter on land given by Generalisimo Franco.

For a time, the beaches were home to a popular accidental attraction. On 18 January 1994 the United States Lines ocean liner SS "American Star" (former "America", USS "West Point", "Australis") was beached in Playa de Garcey during a severe storm. Within a year, she broke in two and later lost her stern. By 2007 the rest of the severely deteriorated ship had collapsed onto her port side, gradually keeling over further and almost completely submerged. By 2008-2012, most of the remains finally slipped below the surface.

The cuisine is fairly basic due to the customs and climate conditions. They share this simplicity with the other Canary islands, and similarly to them, they use a large quantity of fish. They also use whatever they can grow in the near-barren land. This includes papas arrugadas, a dish of wrinkled potatoes usually served with mojo, which is a hot pepper sauce or with puchero canario, a meat stew.

Seafood is prepared in many ways traditionally, such as pejines (salted fish), jareas, or sancocho (a type of stew) made from fish, generally the grouper, corvina or sama, boiled after salting, and served with mojo, potatoes, or gofio (a type of grain). People are also very keen on the mussels and limpets collected on the island's coasts.

They also use meat such as beef and pork to make different dishes or simply to for braising, but their main meat is goat, both from the kids and from the older animals. They eat the goat roasted or stewed. Goats are not only useful for their meat - the Fuerteventurans also use the milk to make the cheese majorero, which has won many prizes. The majorero is mostly made of goats milk, and occasionally it is up to 15% ewes milk. It is cured in pimento oil or gofio meal. Majorero and palmero cheese are the only two Canarian cheeses with protected denomination of origin.

Many sports are commonly played in Fuerteventura, both in the open air and in sports centres across the island.

These are the Canarian sports found on the island:

The wrestling takes place in a ring of sand called the "terrero". Inside it, the two contestants try to knock each other over. Fuerteventura has 14 terreros distributed through all the towns except Betancuria.


The island also has a school wrestling league organized by the council and a programme to promote this sport in clubs. Twelve wrestling schools participate in this, based in Antigua, Costa Calma, El Matorral, La Lajita, Lajares, Las Playitas, Morro Jable, Puerto del Rosario, Tefía, Tetir, Unión Sur and Villaverde.

Juego del Palo is a Canarian martial art which literally translates as "game of the stick". It is played by two players both armed with sticks. They aim to defeat each other without making contact with their opponent's body. The origin of this game is unclear. All we know is that it is based on a method of combat used by the precolonial Canarian people.

Fuerteventura has the following Palo clubs:

This is a similar game to the French Pétanque which is actually played very little on the island, although there are a few teams and courts. Basically the game consists of scoring points by throwing a ball to get it as near as possible to an object called a "mingue" or "boliche". It is played on a rectangular sand or earth pitch which is long and wide.

http://www.playaboule.com/Simple_petanque_rules.aspx

The sea and climate conditions make the island the perfect place for a huge variety of watersports.

Many types of surfing are popular on the island, including traditional surfing, windsurfing (where the board is propelled by a sail) and most recently kitesurfing. The island has many schools and courses dedicated to teaching these sports.

The sports where Fuerteventura has the most impact internationally are windsurfing and kitesurfing, mainly due to the International Windsurfing and Kiteboarding Championship. This has run since 1985 and is held at Playas de Sotavento in Pájara municipality. Many important wind and kitesurfing figures compete in this championship, such as the several-times world windsurfing champion Björn Dunkerbeck and Gisela Pulido, the very young kiteboarding champion from Tarifa.

Many Canarian windsurfers are on the Canarian Waveriders circuit, which has been based in Corralejo since 2005.

Diving schools are just as frequent as surfing ones, all around the coast of Fuerteventura. Unlike the other islands of the archipelago, Fuerteventura has a shelf which at some points goes up to , making it an ideal place to practice this sport.

Two of the most useful points for diving are the coast off Playa del Matorral in the South, and the zone between Lobos Island and Corralejo in the north. It is here in Corralejo that the International Sea and Submarine Photography Festival takes places, known as Fimarsub Corralejo - Lobos. During the festival there are beginners' lessons, professional dives, lessons in underwater photography, screenings and other events related to the sport.

There are many swimming pools on the island but the most obvious place to swim is in the open sea. There is an annual swim from Lobos Island to Fuerteventura, held every year since 1999. The event attracts amateur swimmers from all over the Canaries and Spain, and also swimming professionals such as David Meca and Maarten van der Weijden, the paralympist Jesús Collado Alarcón who won gold medals for 100m backstroke and butterfly in Athens 2004, and Xavi Torres Ramis, the paralympic champion in Barcelona '92, Sydney and Atlanta.

The island holds competitions involving different types of boat, such as the lateen and the Optimist. An interesting event is the Tour of Fuerteventura by Kayak, which is organised as a series of stages rather than a competition, and is an easy way to explore the island.

The most notable competition here is the Gran Tarajal Fishing Open.

Since 2004 the Marcha Ciclotourista has been held in La Oliva and the Criterium Ciclista has been held in Corralejo (also part of the La Oliva municipality) since 2005. Participants include Euskaltel-Euskadi, T-Mobile and a team from Orbea. These competitions have contributed to local interest in the sport and the first professional local team, the Fuerteventura-Canarias, was formed, initially run by Óscar Guerrero, director of Kaiku, although they have not competed for the past few seasons.

There are various motocross circuits on the island, including "Los Alares" in Antigua and "Isla de Fuerteventura" in Puerto del Rosario municipality. They hold regular trials, some of which form part of the Canarian Regional Motocross Championship. Throughout the year there are gravel rally races. Two are part of the Canarian Dirt Rally Championship. These are the Antiguan Rally and the La Oliva Rally.

The island's main football clubs are CD Union Puerto and CD Cotillo, who play in Group XII of the Spanish Tercera División.

The resort Playitas on the south coast is since around 2008 equipped with a swimming pool and has become a destination for triathlon training camps for Europeans. An annual race called Challenge Fuerteventura is held there on the half ironman distance.





</doc>
<doc id="11476" url="https://en.wikipedia.org/wiki?curid=11476" title="Fairmount, Indiana">
Fairmount, Indiana

Fairmount is a town in Fairmount Township, Grant County in the east central part of the U.S. state of Indiana. The population was 2,954 at the 2010 census. It is ninety kilometers (fifty-five miles) northeast of Indianapolis. Largely a bedroom community for nearby Marion, Fairmount is best known as the boyhood home of actor James Dean, who is buried there.

Fairmount is located at (40.417702, −85.648942).

According to the 2010 census, Fairmount has a total area of , all land.

As of the census of 2010, there were 2,954 people, 1,241 households, and 837 families residing in the town. The population density was . There were 1,350 housing units at an average density of . The racial makeup of the town was 98.6% White, 0.1% African American, 0.2% Native American, 0.2% Asian, 0.2% from other races, and 0.7% from two or more races. Hispanic or Latino of any race were 0.9% of the population.

There were 1,241 households of which 31.2% had children under the age of 18 living with them, 48.6% were married couples living together, 14.1% had a female householder with no husband present, 4.8% had a male householder with no wife present, and 32.6% were non-families. 28.0% of all households were made up of individuals and 12% had someone living alone who was 65 years of age or older. The average household size was 2.38 and the average family size was 2.85.

The median age in the town was 40.3 years. 23.9% of residents were under the age of 18; 8.4% were between the ages of 18 and 24; 23.2% were from 25 to 44; 28% were from 45 to 64; and 16.5% were 65 years of age or older. The gender makeup of the town was 48.5% male and 51.5% female.

As of the census of 2000, there were 2,992 people, 1,226 households, and 859 families residing in the town. The population density was 2,033.0 people per square mile (785.9/km²). There were 1,325 housing units at an average density of 900.3 per square mile (348.0/km²). The racial makeup of the town was 98.30% White, 0.17% Black or African American, 0.70% Native American, 0.20% Asian, 0.07% from other races, and 0.57% from two or more races. Hispanic or Latino of any race were 0.43% of the population.

There were 1,226 households out of which 31.2% had children under the age of 18 living with them, 55.5% were married couples living together, 11.0% had a female householder with no husband present, and 29.9% were non-families. 26.5% of all households were made up of individuals and 12.5% had someone living alone who was 65 years of age or older. The average household size was 2.44 and the average family size was 2.91.

In the town, the population was spread out with 25.2% under the age of 18, 8.2% from 18 to 24, 28.2% from 25 to 44, 24.3% from 45 to 64, and 14.1% who were 65 years of age or older. The median age was 38 years. For every 100 females, there were 90.5 males. For every 100 females age 18 and over, there were 90.0 males.

The median income for a household in the town was $33,843, and the median income for a family was $44,033. Males had a median income of $31,136 versus $23,041 for females. The per capita income for the town was $18,029. About 7.4% of families and 9.1% of the population were below the poverty line, including 11.8% of those under age 18 and 7.8% of those age 65 or over.

The Fairmount area was settled in the 1830s mostly by Quakers from North Carolina. The town was laid out in 1850 and named for Fairmount Park in Philadelphia; it was formally incorporated in 1870.

After a large deposit of natural gas was found in 1887, Fairmount became part of the Indiana Gas Boom and a center of the glass industry for the rest of the 19th century. Shortly after the depletion of the gas in 1900 the automobile industry set up factories in the nearby large cities, and Fairmount became a bedroom community, restoring some of its lost prosperity.
In the 1940s, James Dean lived with an aunt and uncle, Ortense and Marcus Winslow on a farm north of Fairmount. He attended Fairmount High School, graduating in 1949. After his death in 1955, Dean was buried in Park Cemetery. In 1996, a small Memorial Park north of the town's business district was dedicated in his memory with a bronze bust by Hollywood artist Kenneth Kendall.

During the prosperity of the 1960s, Fairmount enjoyed a time of building with a new town hall, water works, post office and elementary school. At the end of the decade the local school district merged with a neighboring one, forming the Madison-Grant united school district. A new high school was built for this district, and Fairmount High School became a middle school. When a new junior high school was opened in 1986, the Fairmount High School building was permanently closed.

Fairmount was hit hard by the recession of 1980–1982, which brought the permanent loss of factory jobs and the failure of many farms, but rebounded later in the decade. Fairmount is still relatively prosperous despite the ill fortunes of nearby industrial cities and a steady loss of population.

In September 1988, The James Dean Gallery opened in a restored Victorian House on North Main Street. Over the years the Museum Exhibit has been toured by nearly 200,000 visitors who come from around the world to visit the hometown of James Dean. Also in 1988, English musician Morrissey filmed the music video for his single "Suedehead", a song inspired by his lifelong admiration of Dean, in the town.

The annual James Dean Festival takes place during the last full weekend in September and includes a Custom & Hot Rod Car Show, The Grand Parade, Street Fair, Carnival Rides, Live Entertainment, a 1950s Dance Contest and the James Dean lookalike Contest.

On September 30 of each year there is a Memorial Service for James Dean at The Back Creek Friends Church, south of The Winslow Farm.

The Baldwin Addition Historic District, Fairmount Commercial Historic District, and J.W. Patterson House are listed on the National Register of Historic Places.

Madison-Grant United School Corporation operates public schools.

Schools serving Fairmount:

The town has a lending library, the Fairmount Public Library.



</doc>
<doc id="11477" url="https://en.wikipedia.org/wiki?curid=11477" title="Epistles to the Thessalonians">
Epistles to the Thessalonians

There are two Epistles to the Thessalonians in the Bible:


</doc>
<doc id="11478" url="https://en.wikipedia.org/wiki?curid=11478" title="Free verse">
Free verse

Free verse is an open form of poetry which in its modern form arose through the French "vers libre" form. It does not use consistent meter patterns, rhyme, or any musical pattern. It thus tends to follow the rhythm of natural speech.

Poets have explained that free verse is not totally free: "Its only freedom is from the tyrant demands of the metered line." Free verse displays some elements of form. Most free verse maintains the poetic convention of the poetic line to some degree, at least in written representations, Donald Hall goes as far as to say that "the "form" of free verse is as binding and as liberating as the "form" of a rondeau," and T. S. Eliot wrote, "No verse is free for the man who wants to do a good job." 

Kenneth Allott, the poet and critic, said the adoption by some poets of "vers libre" arose from "mere desire for novelty, the imitation of Whitman, the study of Jacobean dramatic blank verse, and the awareness of what French poets had already done to the alexandrine in France." The American critic John Livingston Lowes in 1916 observed "Free verse may be written as very beautiful prose; prose may be written as very beautiful free verse. Which is which?"

Some poets have considered free verse restrictive in its own way. In 1922, Robert Bridges voiced his reservations in the essay "Humdrum and Harum-Scarum." William Carlos Williams said, "Being an art form, verse cannot be free in the sense of having no limitations or guiding principles." Yvor Winters, the poet and critic, said, "The free verse that is really verse, the best that is, of W.C. Williams, H. D., Marianne Moore, Wallace Stevens, and Ezra Pound is the antithesis of free."

Vers libre is a free verse poetic form of flexibility, complexity and naturalness created in the late 19th century in France, in 1886, largely through the activities of "La Vogue", a weekly journal founded by Gustave Kahn, and the appearance of a band of poets unequalled at any one time in the history of French poetry, the ‘Counter-Romanticism’ led by Baudelaire, Verlaine, Rimbaud, Mallarmé, Laforgue, Corbière, concerned with synaethesis (the harmony or equilibrium of sensation) later described as ‘the moment when French poetry began to take consciousness of itself as poetry’. Gustave Kahn was commonly supposed to have invented the term Vers libre and according to F. S. Flint 'was undoubtedly the first theorist of the techniques'. Later in 1912, Robert de Souza published his conclusion on the genre 'that a vers libre was possible which would keep all the essential characteristics of "vers classique", but would free it from the encumbrances which usage had made appear indispensable'. Thus the practice of verse libre was not the abandoning of pattern, but the creation of an original and complicated metrical form for each poem. 

The formal stimuli for vers libre were "vers libéré" (French verse of the late 19th century that liberated itself from classical rules of versification whilst observing the principle of isosyllabism and regular patterned rhyme), and "vers libre classique" (a minor French genre of the 17th and 18th century which conformed to classic concepts, but in which lines of different length were irregularly and unpredictable combined), and "vers populaire" (versification derived from oral aspects of popular song). Remy de Gourmont's "Livre des Masques" gave definition to the whole vers libre movement, noting there should arise, at regular intervals, a full and complete line, which reassures the ear and guides the rhythm.

The unit of vers libre is not the foot, the number of the syllables, the quantity, or the line. The unit is the strophe, which may be the whole poem, or only a part. Each strophe is a complete circle. in vers libre ‘verse-formal based upon cadence that allows the lines to flow as they will when read aloud by an intelligent reader’. 

Unrhymed cadence in vers libre is built upon 'organic rhythm,' or the rhythm of the speaking voice with its necessity for breathing, rather than upon a strict metrical system. for vers libre addresses the ear not the eye. Vers libre is liberated from traditional rules concerning metre, caesura and line end stopping, every syllable pronounced is of nearly equal value but is less strongly accented than in English, being less intense requires less discipline to mold the accents into the poem's rhythm. This new technique as defined by Kahn consisted of the denial of a regular number of syllables as the basis for versification, the length of line is long and short, oscillating with images used by the poet following the contours of his or her thoughts and is free rather than regular.

Vers libre, until 1912, had hardly been heard of outside France until T. E. Hulme and F. S. Flint shared their knowledge thereof in 1909 with the Poets Club in London which later became the heart of the Imagist movement and through Flint's advocacy of the genre and thus vers libre influenced Imagism in the discovery of new forms and rhythms.

Imagism in the wake of French Symbolism (i.e. vers libre of French Symbolist poets) was the wellspring out of which the main current of Modernism in English flowed, which T. S. Eliot later identified as ‘the point de repere usually taken as the starting point of modern poetry’, as hundreds of poets were led to adopt vers libre as their medium.

As the French-language term "vers libre" suggests, this technique of using more irregular cadences is often said to have its origin in the practices of 19th-century French poets such as Gustave Kahn and Jules Laforgue in his "Derniers vers" of 1890. Taupin, the US-based French poet and critic, concluded that free verse and "vers libre" are not synonymous, since "the French language tends to give equal weight to each spoken syllable, whereas English syllables vary in quantity according to whether stressed or unstressed."

The sort of cadencing that we now recognize in free verse can be traced back at least as far as the Biblical Hebrew psalmist poetry of the Bible. By referring to the , it is possible to argue that free verse in English first appeared in the 1380s in the John Wycliffe translation of the Psalms and was repeated in different form in most biblical translations ever since. 

Walt Whitman, who based his long lines in his poetry collection "Leaves of Grass" on the phrasing of the King James Bible, influenced later American free verse composers, notably Allen Ginsberg. One form of free verse was employed by Christopher Smart in his long poem "Jubilate Agno" (Latin: "Rejoice in the Lamb") , written some time between 1759 and 1763 but not published until 1939.

Many poets of the Victorian era experimented with free verse. Christina Rossetti, Coventry Patmore, and T. E. Brown all wrote examples of rhymed but unmetered verse, poems such as W. E. Henley's "Discharged" (from his "In Hospital" sequence). 

Free verse in English was persuasively advocated by critic T. E. Hulme in his "A Lecture on Modern Poetry" (1908). Later in the preface to "Some Imagist Poets" 1916, he comments, "Only the name is new, you will find something much like "vers libre" in Dryden's "Threnodia Augustalis"; a great deal of Milton's "Samson Agonistes", and the oldest in Chaucer's "House of Fame"."

In France, a few pieces in Arthur Rimbaud's prose poem collection "Illuminations" were arranged in manuscript in lines, rather than prose, and in the Netherlands, tachtiger (i.e., a member of the 1880s generation of innovative poets) Frederik van Eeden employed the form at least once in his poem "Waterlelie" ("Water Lily").

Goethe—particularly in some early poems, such as "Prometheus"—and Hölderlin used free verse occasionally, due in part to a misinterpretation of the meter used in Pindar's poetry; in Hölderlin's case, he also continued to write unmetered poems after discovering this error. 

The German poet Heinrich Heine made an important contribution to the development of free verse with 22 poems, written in two-poem cycles, called "Die Nordsee" ("The North Sea") (written 1825-1826). These were first published in "Buch der Lieder" ("Book of Songs") in 1827.

Although free verse requires no meter, rhyme, or other traditional poetic techniques, a poet can still use them to create some sense of structure. A clear example of this can be found in Walt Whitman's poems, where he repeats certain phrases and uses commas to create both a rhythm and structure. 

Pattern and discipline is to be found in good free verse: the internal pattern of sounds, the choice of exact words, and the effect of associations give free verse its beauty. With the Imagists free verse became a discipline and acquired status as a legitimate poetic form. Herbert Read, however, noted that "the Imagist Ezra Pound gave free verse its musical structure to an extent that parodoxically it was no longer free."

Unrestrained by traditional boundaries, Yvor Winters described this as "attempts to widen experience by establishing 'abnormal' conventions," the poet possesses more license to express, and has more control over the development of the poem. This can allow for a more spontaneous and individualized poetic art product.

Technically, free verse has been described as spaced prose, a mosaic of verse and prose experience.





</doc>
<doc id="11479" url="https://en.wikipedia.org/wiki?curid=11479" title="F. W. de Klerk">
F. W. de Klerk

Frederik Willem de Klerk (; born 18 March 1936) is a South African politician who served as State President of South Africa from 1989 to 1994 and as Deputy President from 1994 to 1996. As South Africa's last head of state from the era of white-minority rule, he and his government dismantled the apartheid system and introduced universal suffrage. Ideologically a conservative and an economic liberal, he led the National Party from 1989 to 1997.

Born in Johannesburg, British Dominion of South Africa, to an influential Afrikaner family, de Klerk studied at Potchefstroom University before pursuing a legal career. Joining the National Party, to which he had family ties, he was elected to parliament and sat in the white-minority government of P. W. Botha, holding a succession of ministerial posts. As a minister, he supported and enforced apartheid, a system of racial segregation that privileged white South Africans. After Botha resigned in 1989, de Klerk replaced him, first as leader of the National Party and then as State President. Although observers expected him to continue Botha's defence of apartheid, de Klerk decided to end the policy. He was aware that growing ethnic animosity and violence was leading South Africa into a racial civil war. Amid this violence, the state security forces committed widespread human rights abuses and encouraged violence between Xhosa and Zulu, although de Klerk later denied sanctioning such actions. He permitted anti-apartheid marches to take place, legalised a range of previously banned anti-apartheid political parties, and freed imprisoned anti-apartheid activists, including Nelson Mandela. He also dismantled South Africa's nuclear weapons program.

De Klerk negotiated with Mandela to fully dismantle apartheid and establish a transition to universal suffrage. In 1993, he publicly apologised for apartheid's harmful effects, although not for apartheid itself. He oversaw the 1994 non-racial election in which Mandela led the African National Congress (ANC) to victory; the National Party took second place with 20% of the vote. After the election, de Klerk became a Deputy President in Mandela's ANC-led coalition, the Government of National Unity. In this position, he supported the government's liberal economic policies. De Klerk had desired a total amnesty for political crimes committed under apartheid and opposed the Truth and Reconciliation Commission set up to investigate past human rights abuses by both pro and anti-apartheid groups. His working relationship with Mandela was strained, although he later spoke fondly of him. In May 1996, after the National Party objected to the new constitution, de Klerk withdrew it from the coalition government; the party disbanded the following year and reformed as the New National Party. In 1997, he retired from active politics and since then has lectured internationally.

De Klerk is a controversial figure. The recipient of a wide range of awards—including the Nobel Peace Prize—he was widely praised for dismantling apartheid and bringing universal suffrage to South Africa. Conversely, anti-apartheid activists criticised him for offering only a qualified apology for apartheid and for ignoring the human rights abuses carried out by his state security forces, while South Africa's white right-wing claimed that by abandoning apartheid he had betrayed the interests of the country's white minority.

F. W. de Klerk was born on 18 March 1936 in Mayfair, a suburb of Johannesburg. His parents were Johannes "Jan" de Klerk and Hendrina Cornelia Coetzer – "her forefather was a Kutzer who stems from Austria". He was his parents' second son, having a brother, Willem, who was eight years his senior. De Klerk's first language is Afrikaans and the earliest of his distant ancestors to arrive in what is now South Africa did so in the late 1680s.

De Klerk's family had played a leading role in Afrikaner society; they had longstanding affiliations with South Africa's National Party. His paternal great-grandfather, Jan van Rooy, had been a senator, while his paternal grandfather, Willem, had been a clergyman who fought in the Anglo-Boer War and who stood twice, unsuccessfully, as a National Party candidate. His paternal aunt's husband was J. G. Strijdom, a former Prime Minister. His own father, Jan de Klerk, was also a Senator, having served as the secretary of the National Party in Transvaal, president of the senate for seven years, and a member of the country's cabinet for fifteen years under three Prime Ministers. In this environment, de Klerk was exposed to politics from childhood. He and family members would be encouraged to hold family debates; his more conservative opinions would be challenged by his brother Willem, who was sympathetic to the more liberal, "enlightened" faction of the National Party. Willem became a political analyst and later split from the National Party to found the liberal Democratic Party.

The name "de Klerk" is derived from Le Clerc, Le Clercq and De Clercq, and is of French Huguenot origin (meaning "clergyman" or "literate" in old French). De Klerk noted that he is also of Dutch descent, with an Indian ancestor from the late 1600s or early 1700s. He is also said to be descended from the Khoi interpreter known as Krotoa or Eva.

De Klerk's upbringing was secure and comfortable.

When de Klerk was twelve years old, the apartheid system was officially institutionalised by the South African government; his father had been one of its originators. He therefore was, according to his brother, "one of a generation that grew up with the concept of apartheid". He was inculturated in the norms and values of Afrikaner society, including festivals like Kruger Day, loyalty to the Afrikaner nation, and stories of the "age of injustice" that the Afrikaner faced under the British. He was brought up in the Gereformeerde Kerk, the smallest and most socially conservative of South Africa's three Dutch Reformed Churches.

The de Klerk family moved around South Africa during his childhood, and he changed schools seven times over seven years. He eventually became a boarder at the Monument High School in Krugersdorp, where he graduated with a first-class pass in 1953. He was nevertheless disappointed not to get the four distinctions he was hoping for.

Between 1954 and 1958, de Klerk studied at Potchefstroom University, graduating with both a Bachelor of Arts and a Bachelor of Law. He later noted that during this legal training, he "became accustomed to thinking in terms of legal principles". While studying there, he became editor of the student newspaper, vice-chair of the student council, and a member of the Afrikaanse Studentebond's national executive council. At university, he was initiated into the Broederbond, a secret society for the Afrikaner social elite. As a student, he played both tennis and hockey and was known as "something of a ladies' man". At the university, he began a relationship with Marike Willemse, the daughter of a professor at the University of Pretoria. The couple married in 1959, when de Klerk was 23 and his wife 22.

After university, de Klerk pursued a legal career, becoming an articled clerk with the firm Pelser in Klerksdorp. Relocating to Pretoria, he became an articled clerk for another law firm, Mac-Robert.
In 1962, he set up his own law partnership in Vereeniging, Transvaal, which he built into a successful business over ten years.
During this period, he involved himself in a range of other activities. He was the national chair of the Junior Rapportryers for two years, and chair of the Law Society of Vaal Triangle. He was also on the council of the local technikon, on the council of his church, and on a local school board.

In 1972, his alma mater offered him a chair in its law faculty, which he accepted. Within a matter of days he was also approached by members of the National Party, who requested that he stand for the party at Vereeniging. De Klerk's candidature was successful and in November he was elected to the House of Assembly. There, he established a reputation as a formidable debater. He took on a number of roles in the party and government. He became the information officer of the Transvaal National Party, responsible for its propaganda output, and helped to establish a new National Party youth movement. He joined various party parliamentary study groups, including those on the Bantustans, labour, justice, and home affairs. As a member of various parliamentary groups, de Klerk went on several foreign visits, to Israel, Germany, the United Kingdom, and United States. It was in the latter in 1976 that he observed what he later described as the pervasive racism of U.S. society, later noting that he "saw more racial incidents in one month there than in South Africa in a year". In South Africa, de Klerk also played a senior role in two select committees, one formulating a policy on opening hotels to non-whites and the other formulating a new censorship law that was less strict than the one that had preceded it.

In 1975, Prime Minister John Vorster predicted that de Klerk would one day become leader of South Africa. Vorster planned to promote de Klerk to the position of a deputy minister in January 1976, but instead the job went to Andries Treurnicht. 
In April 1978, de Klerk was promoted to the position of Minister of Social Welfare and Pensions. In this role, he restored full autonomy to sporting control bodies which had for a time been under the jurisdiction of the government. As minister of Post and Telecommunications he finalised contracts that oversaw the electrification of that sector. As Minister of Mining he formalised a policy on coal exports and the structuring of Eskom and the Atomic Energy Corporation. He then became Minister of the Interior, he oversaw the repeal of the Mixed Marriages Act.
In 1981, de Klerk was awarded the Decoration for Meritorious Service for his work in the government. 
As education minister between 1984 and 1989 he upheld the apartheid system in South Africa's schools, and extended the department to cover all racial groups.

For most of his career, de Klerk had a very conservative reputation, and was seen as someone who would obstruct change in South Africa. He had been a forceful proponent of apartheid's system of racial segregation and was perceived as an advocate of the white minority's interests.
While serving under P. W. Botha's government, de Klerk was never part of Botha's inner circle.

P. W. Botha resigned as leader of the National Party after an apparent stroke, and de Klerk defeated Botha's preferred successor, finance minister Barend du Plessis, in the race to succeed him. On 2 February 1989, he was elected leader of the National Party. He defeated main rival Barend du Plessis to the position by a slim majority of eight votes, 69-61. Soon after, he called for the introduction of a new South African constitution, hinting that it would need to provide greater concession to non-white racial groups. After becoming party leader, de Klerk extended his foreign contacts. He travelled to London, where he met with British Prime Minister Margaret Thatcher. Although she opposed the anti-apartheid movement's calls for economic sanctions against South Africa, at the meeting she urged de Klerk to release the imprisoned anti-apartheid activist Nelson Mandela. He also expressed a desire to meet with representatives of the U.S. government in Washington D.C., although American Secretary of State James Baker informed him that the U.S. government considered it inopportune to have de Klerk meet with President George H. W. Bush.

Botha resigned on 14 August, and de Klerk was named acting state president until 20 September, when he was elected to a full five-year term as state president. After he became acting president, ANC leaders spoke out against him, believing that he would be no different from his predecessors; he was widely regarded as a staunch supporter of apartheid. The prominent anti-apartheid activist Desmond Tutu shared this assessment, stating: "I don't think we've got to even begin to pretend that there is any reason for thinking that we are entering a new phase. It's just musical chairs". Tutu and Allan Boesak had been planning a protest march in Cape Town, which the security chiefs wanted to prevent. De Klerk nevertheless turned down their proposal to ban it, agreeing to let the march proceed and stating that "the door to a new South Africa is open, it is not necessary to batter it down". The march took place and was attended by approximately 30,000 people. Further protest marches followed in Grahamstown, Johannesburg, Pretoria, and Durban. De Klerk later noted that his security forces could not have prevented the marchers from gathering: "The choice, therefore, was between breaking up an illegal march with all of the attendant risks of violence and negative publicity, or of allowing the march to continue, subject to conditions that could help to avoid violence and ensure good public order." This decision marked a clear departure from the approach of the Botha era.

As President, he authorised the continuation of secret talks in Geneva between his National Intelligence Service and two exiled ANC leaders, Thabo Mbeki and Jacob Zuma. In October, he personally agreed to meet with Tutu, Boesak, and Frank Chikane in a private meeting in Pretoria. That month, he also released a number of elderly anti-apartheid activists then imprisoned, including Walter Sisulu. He also ordered the closure of the National Security Management System.
In December he visited Mandela in prison, speaking with him for three hours about the idea of transitioning away from white-minority rule. The collapse of the Eastern Bloc and the dissolution of the Soviet Union meant that he no longer feared that Marxists would manipulate the ANC. As he later related, the collapse of "the Marxist economic system in Eastern Europe... serves as a warning to those who insist on persisting with it in Africa. Those who seek to force this failure of a system on South Africa should engage in a total revision of their point of view. It should be clear to all that it is not the answer here either."

On 2 February 1990 he gave an address to the country's parliament in which he announced plans for sweeping reforms of the political system. He announced that a number of banned political parties, including the ANC and Communist Party of South Africa, would be legalised, although stipulated that this did not constitute an endorsement of their socialist economic policies nor of violent actions carried out by their members. He also announced that the Separate Amenities Act of 1953, which governed the segregation of public facilities, would be lifted. His speech revealed that all of those who were imprisoned solely for belonging to a banned organisation would be freed. He declared that Mandela would be released from prison unconditionally; the latter was released a week later. The vision set forth in de Klerk's address was for South Africa to become a Western-style liberal democracy; it envisioned a market-oriented economy which privileged private enterprise and restricted the government's role in economics.

De Klerk later related that "that speech was mainly aimed at breaking our stalemate in Africa and the West. Internationally we were teetering on the edge of the abyss." Throughout South Africa and across the world, there was astonishment at de Klerk's move. Foreign press coverage was largely positive and de Klerk received messages of support from other governments. Tutu said that "It's incredible... Give him credit. Give him credit, I do." Some black radicals regarded it as a gimmick and that it would prove to be without substance. It was also received negatively by some on the white right-wing, including in the Conservative Party, who believed that de Klerk was betraying the white population. De Klerk believed that the sudden growth of the Conservatives and other white right-wing groups was a passing phase reflecting anxiety and insecurity. These white right-wing groups were aware that they would not get what they wanted through the forthcoming negotiations, and so increasingly tried to derail the negotiations using revolutionary violence. The white-dominated liberal Democratic Party found itself in limbo, as de Klerk embraced much of the platform it had espoused, leaving it without a clear purpose.

Further reforms followed; membership of the National Party was opened up to non-whites. In June, parliament approved new legislation that repealed the Natives Land Act, 1913 and Native Trust and Land Act, 1936. The Population Registration Act, which established the racial classificatory guidelines for South Africa, was rescinded.

In legislative terms, he enabled the gradual end of apartheid. De Klerk also opened the way for the negotiations of the government with the anti-apartheid-opposition about a new constitution for the country. Nevertheless, he was accused by Anthony Sampson of complicity in the violence among the ANC, the Inkatha Freedom Party and elements of the security forces. In "", Sampson accuses de Klerk of permitting his ministers to build their own criminal empires.

His presidency was dominated by the negotiation process, mainly between his NP government and the ANC, which led to the democratization of South Africa. Throughout the negotiations, de Klerk primarily sought to prevent majority rule to preserve power for the white South African minority. His efforts, however, were thwarted when the Boipatong massacre caused a resurgence of international pressure against South Africa, leading to a weaker position at the negotiation tables for the National party. In 1992, de Klerk held a whites-only referendum on ending apartheid, with the result being an overwhelming "yes" vote to continue negotiations to end apartheid. Nelson Mandela was distrustful of the role played by de Klerk in the negotiations, particularly as he believed that de Klerk was knowledgeable about 'third force' attempts to foment violence in the country and destabilize the negotiations.

In 1990, de Klerk gave orders to end South Africa's nuclear weapons programme; the process of nuclear disarmament was essentially completed in 1991. The existence of the programme was not officially acknowledged before 1993.

In 1993, de Klerk and Mandela were jointly awarded the Nobel Peace Prize for their work in ending apartheid. The awarding of the prize to de Klerk was controversial, especially in the light of de Klerk's reported admission that he ordered a massacre of supposed Azanian People's Liberation Army fighters, including teenagers, shortly before going to Oslo in 1993. It appears that this massacre may form part of the basis for criminal charges that the Anti-Racism Action Forum laid against de Klerk in early 2016. Further, de Klerk's role in the destabilization of the country during the negotiation process through the operation of a 'third force' came to the attention of the Truth and Reconciliation Commission, and was never ultimately clarified.

After the first universal elections in 1994, de Klerk became deputy president in the government of national unity under Nelson Mandela, a post he kept until 1996. In 1997 he resigned the leadership of the National Party and retired from politics.

In 1993, de Klerk issued an apology for the actions of the apartheid government, stating that: "It was not our intention to deprive people of their rights and to cause misery, but eventually apartheid led to just that. Insofar as that occurred we deeply regret it... Yes we are sorry". Tutu urged for people to accept the apology, stating that "saying sorry is not an easy thing to do... We should be magnanimous and accept it as a magnanimous act", although was privately frustrated that de Klerk's apology had been qualified and had not gone so far as to call apartheid an intrinsically evil policy.

De Klerk had been unhappy that changes had been made to the inauguration ceremony, rendering it multi-religious rather than reflecting the newly elected leader's particular denomination. When he was being sworn in, and the chief justice said "So help me God", de Klerk did not repeat this, instead stating, in Afrikaans: "So help me the triune God, Father, Son, and Holy Spirit".

Mandela reappointed de Klerk's finance minister, Derek Keys, and retained Chris Stals, a former member of the Broederbond, as the head of the Central Bank.
De Klerk supported the coalition's economic policies, stating that it "accepted a broad framework of responsible economic policies".

De Klerk's working relationship with Mandela was often strained, with the former finding it difficult adjusting to the fact that he was no longer president. De Klerk also felt that Mandela deliberately humiliated him, while Mandela found de Klerk to be needlessly provocative in cabinet. One dispute occurred in September 1995, after Mandela gave a Johannesburg speech criticising the National Party. Angered, de Klerk avoided Mandela until the latter requested they meet; when they ran into each other, they publicly argued in the street. Mandela later expressed regret for their disagreement but did not apologise for his original comments.
De Klerk was also having problems from within his own party, some of whose members claimed that he was neglecting the party while in the government.

Many in the National Party—including many members of its executive committee—were unhappy with the other parties' agreed upon new constitution in May 1996. The party had wanted the constitution to guarantee that it would be represented in the government until 2004, although it did not do this.
On 9 May, de Klerk announced that the National Party would withdraw from the coalition government. The decision shocked several of his six fellow Afrikaner cabinet colleagues; Pik Botha, for example, was left without a job as a result. Roelf Meyer reported feeling betrayed by de Klerk's act, while Leon Wessels thought that de Klerk had not tried hard enough to make the coalition work. De Klerk announced that he would lead the National Party in vigorous opposition to Mandela's government, stating that he wanted to ensure "a proper multi-party democracy, without which there may be a danger of South Africa lapsing into the African pattern of one-party states".

In de Klerk's view, his greatest defeat in the negotiations with Mandela had been his inability to secure a blanket amnesty for all those working for the government or state during the apartheid period. 
De Klerk was unhappy with the formation of the Truth and Reconciliation Commission (TRC). He had hoped that the TRC would be made up of an equal number of individuals from both the old and new governments, as there had been in the Chilean human rights commission. Instead, the TRC was designed to broadly reflect the wider diversity of South African society, and contained only two members who had explicitly supported apartheid, one a member of a right-wing group that had opposed de Klerk's National Party. De Klerk did not object to Tutu being selected as the TRC's chair for he regarded him as politically independent of Mandela's government, but he was upset that Alex Boraine had been selected as its deputy chair, later saying of Boraine: "beneath an urbane and deceptively affable exterior beat the heart of a zealot and an inquisitor."

De Klerk appeared before the TRC hearing to testify for Vlakplaas commanders who were accused of having committed human rights abuses during the apartheid era. He acknowledged that security forces had resorted to "unconventional strategies" in dealing with anti-apartheid revolutionaries, but that "within my knowledge and experience, they never included the authorisation of assassination, murder, torture, rape, assault or the like". After further evidence of said abuses was produced by the commission, de Klerk stated that he found the revelations to be "as shocking and as abhorrent as anybody else" but insisted that he and other senior party members were not willing to accept responsibility for the "criminal actions of a handful of operatives", stating that their behaviour was "not authorised [and] not intended" by his government. Given the widespread and systemic nature of the abuses that had taken place, as well as statements by security officers that their actions had been sanctioned by higher ranking figures, Tutu questioned how de Klerk and other government figures could not have been aware of them. Tutu had hoped that de Klerk or another senior white political figure from the apartheid era would openly accept responsibility for the human rights abuses, thereby allowing South Africa to move on; this was something that de Klerk would not do.

The TRC found de Klerk guilty of being an accessory to gross violations of human rights on the basis that as State President he had been told that P. W. Botha had authorised the bombing of Khotso House but had not revealed this information to the Committee. De Klerk challenged the TRC on this point, and it backed down. When the final TRC report was released 2002, it made a more limited accusation: that de Klerk had failed to give full disclosure about events that took place during his Presidency and that in view of his knowledge about the Khotso House bombing, his statement that none of his colleagues had authorised gross human rights abuses was "indefensible".
In his later autobiography, de Klerk acknowledged that the TRC did significant damage to his public image.

In 1996, de Klerk was offered the Harper Fellowship at Yale Law School. He declined, citing protests at the university. De Klerk did, however, speak at Central Connecticut State University the day before his fellowship would have begun.

In 1998, de Klerk and his wife of 38 years, Marike de Klerk, were divorced following the discovery of his affair with Elita Georgiades, then the wife of Tony Georgiades, a Greek shipping tycoon who had allegedly given de Klerk and the NP financial support. Soon after his divorce, de Klerk and Georgiades were married. His divorce and remarriage scandalised conservative South African opinion, especially among the Calvinist Afrikaners. In 1999, his autobiography, "The Last Trek – A New Beginning", was published. In 2001, following the murder of his former wife, the manuscript of her own autobiography, "A Place Where the Sun Shines Again", was submitted to de Klerk, who urged the publishers to suppress a chapter dealing with his infidelity.

In 1999, de Klerk established the pro-peace FW de Klerk Foundation of which he is the chairman. De Klerk is also chairman of the Global Leadership Foundation, headquartered in London, which he set up in 2004, an organisation which works to support democratic leadership, prevent and resolve conflict through mediation and promote good governance in the form of democratic institutions, open markets, human rights and the rule of law. It does so by making available, discreetly and in confidence, the experience of former leaders to today's national leaders. It is a not-for-profit organisation composed of former heads of government and senior governmental and international organisation officials who work closely with heads of government on governance-related issues of concern to them.

On 3 December 2001, Marike de Klerk was found stabbed and strangled to death in her Cape Town flat. De Klerk, who was on a brief visit to Stockholm, Sweden, to celebrate the 100-year anniversary of the Nobel Prize foundation, announced he would immediately return to mourn his dead ex-wife. The atrocity was reportedly condemned strongly by South African president Thabo Mbeki and Winnie Mandela, among others, who openly spoke in favour of Marike de Klerk. On 6 December, 21-year-old security guard Luyanda Mboniswa was arrested for the murder. On 15 May 2003, he received two life sentences for murder, as well as three years for breaking into Marike de Klerk's apartment.

In 2004, de Klerk announced that he was quitting the New National Party and seeking a new political home after it was announced that the NNP would merge with the ruling ANC. That same year, while giving an interview to US journalist Richard Stengel, de Klerk was asked whether South Africa had turned out the way he envisioned it back in 1990. His response was:

There are a number of imperfections in the new South Africa where I would have hoped that things would be better, but on balance I think we have basically achieved what we set out to achieve. And if I were to draw balance sheets on where South Africa stands now, I would say that the positive outweighs the negative by far. There is a tendency by commentators across the world to focus on the few negatives which are quite negative, like how are we handling AIDS, like our role vis-à-vis Zimbabwe. But the positives – the stability in South Africa, the adherence to well-balanced economic policies, fighting inflation, doing all the right things in order to lay the basis and the foundation for sustained economic growth – are in place.

In 2008, he repeated in a speech that "despite all the negatives facing South Africa, he is very positive about the country".

In 2006, he underwent surgery for a malignant tumour in his colon, discovered after an examination on 3 June. His condition deteriorated sharply, and he underwent a second operation after developing respiratory problems. On 13 June, it was announced that he was to undergo a tracheotomy. He recovered and on 11 September 2006 gave a speech at Kent State University Stark Campus.

In January 2007, de Klerk was a speaker promoting peace and democracy in the world at the "Towards a Global Forum on New Democracies" event in Taipei, Taiwan, along with other dignitaries including Poland's Lech Wałęsa and Taiwan's then president Chen Shui-Bian.

De Klerk is an Honorary Patron of the University Philosophical Society of Trinity College, Dublin, and Honorary Chairman of the Prague Society for International Cooperation. He has also received the Gold Medal for Outstanding Contribution to Public Discourse from the College Historical Society of Trinity College, Dublin, for his contribution to ending apartheid.

De Klerk is also a Member of the Advisory Board of the Global Panel Foundation based in Berlin, Copenhagen, New York, Prague, Sydney and Toronto – founded by the Dutch entrepreneur Bas Spuybroek in 1988, with the support of Dutch billionaire Frans Lurvink and former Dutch Foreign Minister Hans van den Broek. The Global Panel Foundation is known for its behind-the-scenes work in public policy and the annual presentation of the Hanno R. Ellenbogen Citizenship Award with the Prague Society for International Cooperation.

After the inauguration of Jacob Zuma as South Africa's president in May 2009, de Klerk said he is optimistic that Zuma and his government can "confound the prophets of doom".

In a BBC interview broadcast in April 2012, he said he lived in an all-white neighbourhood. He had five servants, three coloured and two black: "We are one great big family together; we have the best of relationships." About Nelson Mandela, he said, "When Mandela goes it will be a moment when all South Africans put away their political differences, will take hands, and will together honour maybe the biggest known South African that has ever lived."

Upon hearing of the death of Mandela, de Klerk said: "He was a great unifier and a very, very special man in this regard beyond everything else he did. This emphasis on reconciliation was his biggest legacy."

In 2015, de Klerk wrote to "The Times" newspaper in the UK criticising moves to remove a statue to Cecil Rhodes at Oriel College, Oxford. He was subsequently criticized by some activists who described it as "ironic" that the last apartheid President should be defending a statue of a man labelled by critics as the "architect of apartheid". The Economic Freedom Fighters called for him to be stripped of his Nobel Peace Prize.

De Klerk was widely regarded as a politically conservative figure in South Africa. At the same time, he was flexible rather than dogmatic in his approach to political issues. 
He often hedged his bets and sought to accommodate divergent perspectives, favouring compromise over confrontation.
Within the National Party, he continually strove for unity, coming to be regarded—according to his brother—as "a party man, a veritable Mr National Party". To stem defections from the right-wing end of the National Party, he made "ultra-conservative noises". This general approach led to the perception that he was "trying to be all things to all men".

De Klerk stated that within the party, he "never formed part of a political school of thought, and I deliberately kept out of the cliques and foments of the enlightened and conservative factions in the party. If the policy I propounded was ultra-conservative, then that was the policy; it was not necessarily I who was ultra-conservative. I saw my role in the party as that of an interpreter of the party's real median policy at any stage."
De Klerk stated that "The silver thread throughout my career was my advocacy of National Party policy in all its various formulations. I refrained from adjusting that policy or adapting it to my own liking or convictions. I analysed it as it was formulated, to the letter."

For much of his career, de Klerk believed in apartheid and its system of racial segregation.
According to his brother, de Klerk underwent a "political conversion" that took him from supporting apartheid to facilitating its demolition. This change was not "a dramatic event" however, but "was built... on pragmatism - it evolved as a process."
He did not believe that South Africa would become a "non-racial society", but rather sought to build a "non-racist society" in which ethnic divisions remained; in his view "I do not believe in the existence of anything like a non-racial society in the literal sense of the word", citing the example of the United States and United Kingdom where there was no legal racial segregation but that distinct racial groups continued to exist.

De Klerk accepted the principle of freedom of religion, although still believed that the state should promote Christianity.

Glad and Blanton stated that de Klerk's "political choices were undergirded by self-confidence and commitment to the common good." His brother Willem stated that de Klerk's demeanour was marked by "soberness, humility and calm", that he was an honest, intelligent, and open minded individual, and that he had a "natural cordiality" and a "solid sense of courtesy and good manners". He felt that de Klerk's "charisma" came not from an "exceptionally strong individualism" but from "his rationality, logic and balance". He was, according to de Klerk, "a man of compromise rather than a political innovator or entrepreneur".

Willem stated that "he keeps an ear to the ground and is sensitive to the slightest tremors", and that it was this which made him "a superb politician". Willem also stated that his brother was "a team-man who consults others, takes them into his confidence, honestly shares information with his colleagues, and has a knack of making people feel importance and at peace".
His former wife Marike described de Klerk as being "extremely sensitive to beautiful things", exhibiting something akin to an artistic temperament.

Willem also noted that "in the most profound sense", de Klerk was driven by his concern for Afrikanerdom and "the survival of his own people in their fatherland". De Klerk was deeply upset that many Afrikaners did not realise that his reforms to dismantle apartheid were carried out with the intention of preserving a future for the Afrikaner people in South Africa.

With Marike, de Klerk had three children: Jan, who became a farmer in Western Transvaal, Willem, who went into public relations, and Susan, who became a teacher. Willem stated that de Klerk had a close relationship with his children, and that he was "a loving man who hugs and cuddles".

De Klerk was a chain smoker and also enjoyed a glass of whisky or wine while relaxing. In adult life, he enjoyed playing golf and hunting, as well as going for brisk walks.

Glad and Blanton stated that de Klerk, along with Mandela, "accomplished the rare feat of bringing about systemic revolution through peaceful means." His brother noted that de Klerk's role in South African history was "to dismantle more than three centuries of white supremacy", and that in doing so his was "not a role of white surrender, but a role of white conversion to a new role" in society.
In September 1990, Potchefstroom University awarded de Klerk with an honorary doctorate.

South Africa's Conservative Party came to regard him as its most hated adversary.




</doc>
<doc id="11488" url="https://en.wikipedia.org/wiki?curid=11488" title="Furlong">
Furlong

A furlong is a measure of distance in imperial units and U.S. customary units equal to one eighth of a mile, equivalent to 660 feet, 220 yards, 40 rods, or 10 chains.

Using the international definition of the inch as exactly 25.4 millimetres, one furlong is 201.168 metres. However, the United States does not uniformly use this conversion ratio. Older ratios are in use for surveying purposes in some states, leading to variations in the length of the furlong of two parts per million, or about 0.4 millimetre ( inch). This variation is too small to have practical consequences in most applications. Five furlongs are about 1 kilometre ( is the exact value, according to the international conversion).

The name "furlong" derives from the Old English words ' (furrow) and ' (long). Dating back at least to early Anglo-Saxon times, it originally referred to the length of the furrow in one acre of a ploughed open field (a medieval communal field which was divided into strips). The furlong (meaning furrow length) was the distance a team of oxen could plough without resting. This was standardised to be exactly 40 rods or 10 chains. The system of long furrows arose because turning a team of oxen pulling a heavy plough was difficult. This offset the drainage advantages of short furrows and meant furrows were made as long as possible. An acre is an area that is one furlong long and one chain (66 feet or 22 yards) wide. For this reason, the furlong was once also called an acre's length, though in modern usage an area of one acre can be of any shape. The term furlong, or shot, was also used to describe a grouping of adjacent strips within an open field.

Among the early Anglo-Saxons, the rod was the fundamental unit of land measurement. A furlong was 40 rods; an acre 4 by 40 rods, or 4 rods by 1 furlong, and thus 160 square rods. At the time, the Saxons used the North German foot, which was 10 percent longer than the foot of today. When England changed to the shorter foot in the late 13th century, rods and furlongs remained unchanged, since property boundaries were already defined in rods and furlongs. The only thing that changed was the number of feet and yards in a rod or a furlong, and the number of square feet and square yards in an acre. The definition of the rod went from 15 old feet to new feet, or from 5 old yards to new yards. The furlong went from 600 old feet to 660 new feet, or from 200 old yards to 220 new yards. The acre went from 36,000 old square feet to 43,560 new square feet, or from 4,000 old square yards to 4,840 new square yards.

The furlong was historically viewed as being equivalent to the Roman stade ("stadium"), which in turn derived from the Greek system. For example, the King James Bible uses the term "furlong" in place of the Greek "stadion", although more recent translations often use miles or kilometres in the main text and give the original numbers in footnotes.

In the Roman system, there were 625 feet to the "stadium", eight "stadia" to the mile, and three miles to the league. A league was considered to be the distance a man could walk in one hour, and the mile (from "mille", "meaning thousand") consisted of 1,000 "passus" (paces, five feet, or double-step).

After the fall of the Western Roman Empire, medieval Europe continued with the Roman system, which the people proceeded to diversify, leading to serious complications in trade, taxation, etc. Around the year 1300, by royal decree England standardized a long list of measures. Among the important units of distance and length at the time were the foot, yard, rod (or pole), furlong, and the mile. The rod was defined as yards or feet, and the mile was eight furlongs, so the definition of the furlong became 40 rods and that of the mile became 5,280 feet (eight furlongs/mile times 40 rods/furlong times feet/rod).

A description from 1675 states, "Dimensurator or Measuring Instrument whereof the mosts usual has been the Chain, and the common length for English Measures four Poles, as answering indifferently to the Englishs Mile and Acre, 10 such Chains in length making a Furlong, and 10 single square Chains an Acre, so that a square Mile contains 640 square Acres." —John Ogilby, Britannia, 1675

The official use of the furlong was abolished in the United Kingdom under the Weights and Measures Act 1985, an act that also abolished the official use of many other traditional units of measurement.

In Myanmar, furlongs are currently used in conjunction with miles to indicate distances on highway signs. Mileposts on the Yangon–Mandalay Expressway use miles and furlongs.
In the rest of the world, the furlong has very limited use, with the notable exception of horse racing in most English-speaking countries, including Canada and the United States. The distances for horse racing in Australia were converted to metric in 1972, but in the United Kingdom, Ireland, Canada, and the United States, races are still given in miles and furlongs.

The city of Chicago's street numbering system allots a measure of 800 address units to each mile, in keeping with the city's system of eight blocks per mile. This means that every block in a typical Chicago neighborhood (in either North/South or East/West direction but rarely both) is approximately one furlong in length. Salt Lake City's blocks are also each a square furlong in the downtown area. The blocks become less regular in shape further from the center, but the numbering system (800 units to each mile) remains the same everywhere in Salt Lake County. Blocks in central Logan, Utah, and in large sections of Phoenix, Arizona, are similarly a square furlong in extent (eight to a mile, which explains the series of freeway exits: 19th Ave, 27th, 35th, 43rd, 51st, 59th ...). City blocks in the Hoddle Grid of Melbourne are also one furlong in length.

Much of Ontario, Canada, was originally surveyed on a ten-furlong grid, with major roads being laid out along the grid lines. Now that distances are shown on road signs in kilometres, these major roads are almost exactly two kilometres apart. The exits on highways running through Toronto, for example, are generally at intervals of two kilometres.

The furlong is also a base unit of the humorous FFF system of units.

The exact conversion of the furlong to SI units varies slightly among English-speaking countries. In Canada and the United Kingdom, which define the furlong in terms of the international yard of exactly 0.9144 metres, a furlong is 201.168 m.
Australia does not formally define the furlong, but it does define the chain and link in terms of the international yard.

In the United States, which defines the furlong, chain, rod, and link in terms of the U.S. survey foot of exactly metre, a furlong is approximately 201.1684 m long. The United States does not formally define a "survey yard". The difference of approximately two parts per million between the U.S. value and the "international" value is insignificant for most practical measurements.



</doc>
<doc id="11489" url="https://en.wikipedia.org/wiki?curid=11489" title="File">
File

File or filing may refer to:






</doc>
<doc id="11490" url="https://en.wikipedia.org/wiki?curid=11490" title="Fundamental frequency">
Fundamental frequency

The fundamental frequency, often referred to simply as the fundamental, is defined as the lowest frequency of a periodic waveform. In music, the fundamental is the musical pitch of a note that is perceived as the lowest partial present. In terms of a superposition of sinusoids, the fundamental frequency is the lowest frequency sinusoidal in the sum. In some contexts, the fundamental is usually abbreviated as f" (or FF), indicating the lowest frequency counting from zero. In other contexts, it is more common to abbreviate it as f", the first harmonic. (The second harmonic is then f = 2⋅f, etc. In this context, the zeroth harmonic would be 0 Hz.)

All sinusoidal and many non-sinusoidal waveforms repeat exactly over time – they are periodic. The period of a waveform is the formula_1 for which the following equation is true:

Where formula_3 is the value of the waveform at formula_4. This means that this equation and a definition of the waveform’s values over any interval of length formula_1 is all that is required to describe the waveform completely. Waveforms can be represented by Fourier series.

Every waveform may be described using any multiple of this period. There exists a smallest period over which the function may be described completely and this period is the fundamental period. The fundamental frequency is defined as its reciprocal:

Since the period is measured in units of time, then the units for frequency are 1/time. When the time units are seconds, the frequency is in formula_7, also known as Hertz.

For a tube of length formula_8 with one end closed and the other end open the wavelength of the fundamental harmonic is formula_9, as indicated by the first two animations. Hence,

Therefore, using the relation
where formula_12 is the speed of the wave, we can find the fundamental frequency in terms of the speed of the wave and the length of the tube:

If the ends of the same tube are now both closed or both opened as in the last two animations, the wavelength of the fundamental harmonic becomes formula_14. By the same method as above, the fundamental frequency is found to be

At 20 °C (68 °F) the speed of sound in air is 343 m/s (1129 ft/s). This speed is temperature dependent and increases at a rate of 0.6 m/s for each degree Celsius increase in temperature (1.1 ft/s for every increase of 1 °F).

The velocity of a sound wave at different temperatures:-

In music, the fundamental is the musical pitch of a note that is perceived as the lowest partial present. The fundamental may be created by vibration over the full length of a string or air column, or a higher harmonic chosen by the player. The fundamental is one of the harmonics. A harmonic is any member of the harmonic series, an ideal set of frequencies that are positive integer multiples of a common fundamental frequency. The reason a fundamental is also considered a harmonic is because it is 1 times itself.

The fundamental is the frequency at which the entire wave vibrates. Overtones are other sinusoidal components present at frequencies above the fundamental. All of the frequency components that make up the total waveform, including the fundamental and the overtones, are called partials. Together they form the harmonic series. Overtones which are perfect integer multiples of the fundamental are called harmonics. When an overtone is near to being harmonic, but not exact, it is sometimes called a harmonic partial, although they are often referred to simply as harmonics. Sometimes overtones are created that are not anywhere near a harmonic, and are just called partials or inharmonic overtones.

The fundamental frequency is considered the "first harmonic" and the "first partial." The numbering of the partials and harmonics is then usually the same; the second partial is the second harmonic, etc. But if there are inharmonic partials, the numbering no longer coincides. Overtones are numbered as they appear "above" the fundamental. So strictly speaking, the "first" overtone is the "second" partial (and usually the "second" harmonic). As this can result in confusion, only harmonics are usually referred to by their numbers, and overtones and partials are described by their relationships to those harmonics.

Consider a spring, fixed at one end and having a mass attached to the other; this would be a single degree of freedom (SDoF) oscillator. Once set into motion, it will oscillate at its natural frequency. For a single degree of freedom oscillator, a system in which the motion can be described by a single coordinate, the natural frequency depends on two system properties: mass and stiffness; (providing the system is undamped). The natural frequency, "ω", can be found using the following equation:

where:
"k" = stiffness of the spring
"m" = mass 
"ω" = natural frequency in radians per second.

If we desire the natural frequency expressed in Hertz, "f", we simply divide "ω" by 2"π". Or:

where:
"f" = natural frequency in Hertz (cycles/second)
"k" = stiffness of the spring (Newtons/metre or N/m)
"m" = mass (kg). 
While doing the modal analysis of structures and mechanical equipment, the frequency of the 1st mode is called the fundamental frequency.



</doc>
<doc id="11491" url="https://en.wikipedia.org/wiki?curid=11491" title="Fable">
Fable

Fable is a literary genre: a succinct fictional story, in prose or verse, that features animals, legendary creatures, plants, inanimate objects, or forces of nature that are anthropomorphized (given human qualities, such as the ability to speak human language) and that illustrates or leads to a particular moral lesson (a "moral"), which may at the end be added explicitly as a pithy maxim or saying.

A fable differs from a parable in that the latter "excludes" animals, plants, inanimate objects, and forces of nature as actors that assume speech or other powers of humankind.

Usage has not always been so clearly distinguished. In the King James Version of the New Testament, "" (""mythos"") was rendered by the translators as "fable" in the First Epistle to Timothy, the Second Epistle to Timothy, the Epistle to Titus and the First Epistle of Peter.

A person who writes fables is a fabulist.

The fable is one of the most enduring forms of folk literature, spread abroad, modern researchers agree, less by literary anthologies than by oral transmission. Fables can be found in the literature of almost every country.

The varying corpus denoted "Aesopica" or "Aesop's Fables" includes most of the best-known western fables, which are attributed to the legendary Aesop, supposed to have been a slave in ancient Greece around 550 BCE. When Babrius set down fables from the "Aesopica" in verse for a Hellenistic Prince "Alexander," he expressly stated at the head of Book II that this type of "myth" that Aesop had introduced to the "sons of the Hellenes" had been an invention of "Syrians" from the time of "Ninos" (personifying Nineveh to Greeks) and Belos ("ruler"). Epicharmus of Kos and Phormis are reported as having been among the first to invent comic fables. Many familiar fables of Aesop include "The Crow and the Pitcher", "The Tortoise and the Hare" and "The Lion and the Mouse". In ancient Greek and Roman education, the fable was the first of the "progymnasmata"—training exercises in prose composition and public speaking—wherein students would be asked to learn fables, expand upon them, invent their own, and finally use them as persuasive examples in longer forensic or deliberative speeches. The need of instructors to teach, and students to learn, a wide range of fables as material for their declamations resulted in their being gathered together in collections, like those of Aesop.

African oral culture has a rich story-telling tradition. As they have for thousands of years, people of all ages in Africa continue to interact with nature, including plants, animals and earthly structures such as rivers, plains, and mountains. Grandparents enjoy enormous respect in African societies and fill the new role of story-telling during retirement years. Children and, to some extent, adults are mesmerized by good story-tellers when they become animated in their quest to tell a good fable.

Joel Chandler Harris wrote African-American fables in the Southern context of slavery under the name of Uncle Remus. His stories of the animal characters Brer Rabbit, Brer Fox, and Brer Bear are modern examples of African-American story-telling, this though should not transcend critiques and controversies as to whether or not Uncle Remus was a racist or apologist for slavery. The Disney movie "Song of the South" introduced many of the stories to the public and others not familiar with the role that storytelling played in the life of cultures and groups without training in speaking, reading, writing, or the cultures to which they had been relocated to from world practices of capturing Africans and other indigenous populations to provide slave labor to colonized countries.

India has a rich tradition of fabulous novels, mostly explainable by the fact that the culture derives traditions and learns qualities from natural elements. Some of the gods are forms of animals with ideal qualities. Also, hundreds of fables were composed in ancient India during the first millennium BCE, often as stories within frame stories. Indian fables have a mixed cast of humans and animals. The dialogues are often longer than in fables of Aesop and often witty as the animals try to outwit one another by trickery and deceit. In Indian fables, man is not superior to the animals. The tales are often comical. The Indian fable adhered to the universally known traditions of the fable. The best examples of the fable in India are the Panchatantra and the Jataka tales. These included Vishnu Sarma's "Panchatantra", the "Hitopadesha", "Vikram and The Vampire", and Syntipas' "Seven Wise Masters", which were collections of fables that were later influential throughout the Old World. Ben E. Perry (compiler of the "Perry Index" of Aesop's fables) has argued controversially that some of the Buddhist "Jataka tales" and some of the fables in the "Panchatantra" may have been influenced by similar Greek and Near Eastern ones. Earlier Indian epics such as Vyasa's "Mahabharata" and Valmiki's "Ramayana" also contained fables within the main story, often as side stories or back-story. The most famous folk stories from the Near East were the "One Thousand and One Nights", also known as the "Arabian Nights".

Fables had a further long tradition through the Middle Ages, and became part of European high literature. During the 17th century, the French fabulist Jean de La Fontaine (1621–1695) saw the soul of the fable in the moral — a rule of behavior. Starting with the Aesopian pattern, La Fontaine set out to satirize the court, the church, the rising bourgeoisie, indeed the entire human scene of his time. La Fontaine's model was subsequently emulated by England's John Gay (1685–1732); Poland's Ignacy Krasicki (1735–1801); Italy's (1739–1812) and (1754–1827); Serbia's Dositej Obradović (1739–1811); Spain's Félix María de Samaniego (1745–1801) and Tomás de Iriarte y Oropesa (1750–1791); France's Jean-Pierre Claris de Florian (1755–94); and Russia's Ivan Krylov (1769–1844).

In modern times, while the fable has been trivialized in children's books, it has also been fully adapted to modern adult literature. Felix Salten's "Bambi" (1923) is a "Bildungsroman" — a story of a protagonist's coming-of-age — cast in the form of a fable. James Thurber used the ancient fable style in his books "Fables for Our Time" (1940) and "Further Fables for Our Time" (1956), and in his stories "The Princess and the Tin Box" in "The Beast in Me and Other Animals" (1948) and "The Last Clock: A Fable for the Time, Such As It Is, of Man" in "Lanterns and Lances" (1961). Władysław Reymont's "The Revolt" (1922), a metaphor for the Bolshevik Revolution of 1917, described a revolt by animals that take over their farm in order to introduce "equality." George Orwell's "Animal Farm" (1945) similarly satirized Stalinist Communism in particular, and totalitarianism in general, in the guise of animal fable.

In the 21st century, the Neapolitan writer Sabatino Scia is the author of more than two hundred fables that he describes as “western protest fables.” The characters are not only animals, but also things, beings, and elements from nature. Scia's aim is the same as in the traditional fable, playing the role of revealer of human society. In Latin America, the brothers Juan and Victor Ataucuri Garcia have contributed to the resurgence of the fable. But they do so with a novel idea: use the fable as a means of dissemination of traditional literature of that place. In the book ""Fábulas Peruanas" published in 2003, they have collected myths, legends, beliefs of Andean and Amazonian Peru, to write as fables. The result has been an extraordinary work rich in regional nuances. Here we discover the relationship between man and his origin, with nature, with its history, its customs and beliefs then become norms and values.







</doc>
