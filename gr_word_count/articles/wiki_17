<doc id="2493" url="https://en.wikipedia.org/wiki?curid=2493" title="Anthroposophy">
Anthroposophy

Anthroposophy is a philosophy founded by the 19th-century esotericist Rudolf Steiner that postulates the existence of an objective, intellectually comprehensible spiritual world, accessible to human experience. Followers of anthroposophy aim to develop mental faculties of spiritual discovery through a mode of thought independent of sensory experience. They also aim to present their ideas in a manner verifiable by rational discourse and specifically seek a precision and clarity in studying the spiritual world mirroring that obtained by natural historians in investigations of the physical world.

The philosophy has its roots in German idealist and mystical philosophies. Steiner chose the term "anthroposophy" (from "anthropo-", human, and "Sophia", wisdom) to emphasize his philosophy's humanistic orientation. Anthroposophical ideas have been employed in alternative movements in many areas including education (both in Waldorf schools and in the Camphill movement), agriculture, medicine, banking, organizational development, and the arts. The main organization for advocacy of Steiner's ideas, the Anthroposophical Society, is headquartered at the Goetheanum in Dornach, Switzerland.

The historian of religion Olav Hammer has termed anthroposophy "the most important esoteric society in European history." Authors, scientists, and physicians including Michael Shermer, Michael Ruse, Edzard Ernst, David Gorski, and Simon Singh have criticized anthroposophy's application in the areas of medicine, biology, agriculture, and education to be dangerous and pseudoscientific. Others including former Waldorf pupil Roger Rawlings, activist Dan Dugan, and historian Geoffrey Ahern have criticized anthroposophy itself as a dangerous cult that is fundamentally anti-rational and anti-scientific.

The early work of the founder of anthroposophy, Rudolf Steiner, culminated in his "Philosophy of Freedom" (also translated as "The Philosophy of Spiritual Activity" and "Intuitive Thinking as a Spiritual Path"). Here, Steiner developed a concept of free will based on inner experiences, especially those that occur in the creative activity of independent thought.

By the beginning of the twentieth century, Steiner's interests turned almost exclusively to spirituality. His work began to interest others interested in spiritual ideas; among these was the Theosophical Society. From 1900 on, thanks to the positive reception his ideas received from Theosophists, Steiner focused increasingly on his work with the Theosophical Society, becoming the secretary of its section in Germany in 1902. During his leadership, membership increased dramatically, from just a few individuals to sixty-nine lodges.

By 1907, a split between Steiner and the Theosophical Society became apparent. While the Society was oriented toward an Eastern and especially Indian approach, Steiner was trying to develop a path that embraced Christianity and natural science. The split became irrevocable when Annie Besant, then president of the Theosophical Society, presented the child Jiddu Krishnamurti as the reincarnated Christ. Steiner strongly objected and considered any comparison between Krishnamurti and Christ to be nonsense; many years later, Krishnamurti also repudiated the assertion. Steiner's continuing differences with Besant led him to separate from the Theosophical Society Adyar. He was subsequently followed by the great majority of the Theosophical Society's German members, as well as many members of other national sections.

By this time, Steiner, had reached considerable stature as a spiritual teacher and expert in the occult. He spoke about what he considered to be his direct experience of the Akashic Records (sometimes called the "Akasha Chronicle"), thought to be a spiritual chronicle of the history, pre-history, and future of the world and mankind. In a number of works, Steiner described a path of inner development he felt would let anyone attain comparable spiritual experiences. In Steiner's view, sound vision could be developed, in part, by practicing rigorous forms of ethical and cognitive self-discipline, concentration, and meditation. In particular, Steiner believed a person's spiritual development could only occur after a period of moral development.
In 1912, the Anthroposophical Society was founded. After World War I, the Anthroposophical movement took on new directions. Followers of Steiner's ideas soon began applying them to create counter-cultural movements in traditional and special education, farming, and medicine.

By 1923, a schism had formed between older members focused on inner development and younger members eager to become active in contemporary social transformations. In response, Steiner attempted to bridge the gap by establishing an overall School for "Spiritual Science". As a spiritual basis for the reborn movement, Steiner wrote a "" which remains a central touchstone of anthroposophical ideas.

Steiner died just over a year later, in 1925. The Second World War temporarily hindered the anthroposophical movement in most of Continental Europe, as the Anthroposophical Society and most of its practical counter-cultural applications were banned by the Nazi government. Though at least one prominent member of the Nazi Party, Rudolf Hess, was a strong supporter of anthroposophy, very few anthroposophists belonged to the National Socialist Party.

By 2007, national branches of the Anthroposophical Society had been established in fifty countries and about 10,000 institutions around the world were working on the basis of anthroposophical ideas.

"Anthroposophy" is an amalgam of the Greek terms ("anthropos" = "human") and ("sophia" = "wisdom"). An early English usage is recorded by Nathan Bailey (1742) as meaning "the knowledge of the nature of man."
The first known use of the term "anthroposophy" occurs within "Arbatel de magia veterum, summum sapientiae studium", a book published anonymously in 1575 and attributed to Heinrich Cornelius Agrippa. The work describes anthroposophy (as well as theosophy) variously as an understanding of goodness, nature, or human affairs. In 1648, the Welsh philosopher Thomas Vaughan published his "Anthroposophia Theomagica, or a discourse of the nature of man and his state after death." 

The term began to appear with some frequency in philosophical works of the mid- and late-nineteenth century. In the early part of that century, Ignaz Troxler used the term "anthroposophy" to refer to philosophy deepened to self-knowledge, which he suggested allows deeper knowledge of nature as well. He spoke of human nature as a mystical unity of God and world. Immanuel Hermann Fichte used the term "anthroposophy" to refer to "rigorous human self-knowledge," achievable through thorough comprehension of the human spirit and of the working of God in this spirit, in his 1856 work "Anthropology: The Study of the Human Soul". In 1872, the philosopher of religion Gideon Spicker used the term "anthroposophy" to refer to self-knowledge that would unite God and world: "the true study of the human being is the human being, and philosophy's highest aim is self-knowledge, or Anthroposophy." 

In 1882, the philosopher Robert Zimmermann published the treatise, "An Outline of Anthroposophy: Proposal for a System of Idealism on a Realistic Basis," proposing that idealistic philosophy should employ logical thinking to extend empirical experience. Steiner attended lectures by Zimmermann at the University of Vienna in the early 1880s, thus at the time of this book's publication.

In the early 1900s, Steiner began using the term "anthroposophy" (i.e. human wisdom) as an alternative to the term "theosophy" (i.e. divine wisdom).

Anthroposophical proponents aim to extend the clarity of the scientific method to phenomena of human soul-life and spiritual experiences. Steiner believed this required developing new faculties of objective spiritual perception, which he maintained was still possible for contemporary humans. The steps of this process of inner development he identified as consciously achieved "imagination", "inspiration" and "intuition". Steiner believed results of this form of spiritual research should be expressed in a way that can be understood and evaluated on the same basis as the results of natural science.

Steiner hoped to form a spiritual movement that would free the individual from any external authority. For Steiner, the human capacity for rational thought would allow individuals to comprehend spiritual research on their own and bypass the danger of dependency on an authority such as himself.

Steiner contrasted the anthroposophical approach with both conventional mysticism, which he considered lacking the clarity necessary for exact knowledge, and natural science, which he considered arbitrarily limited to what can be seen, heard, or felt with the outward senses.

In "Theosophy", Steiner suggested that human beings unite a physical body of substances gathered from (and that ultimately return to) the inorganic world; a life body (also called the etheric body), in common with all living creatures (including plants); a bearer of sentience or consciousness (also called the astral body), in common with all animals; and the ego, which anchors the faculty of self-awareness unique to human beings.

Anthroposophy describes a broad evolution of human consciousness. Early stages of human evolution possess an intuitive perception of reality, including a clairvoyant perception of spiritual realities. Humanity has progressively evolved an increasing reliance on intellectual faculties and a corresponding loss of intuitive or clairvoyant experiences, which have become atavistic. The increasing intellectualization of consciousness, initially a progressive direction of evolution, has led to an excessive reliance on abstraction and a loss of contact with both natural and spiritual realities. However, to go further requires new capacities that combine the clarity of intellectual thought with the imagination, and beyond this with consciously achieved inspiration and intuitive insights.

Anthroposophy speaks of the reincarnation of the human spirit: that the human being passes between stages of existence, incarnating into an earthly body, living on earth, leaving the body behind and entering into the spiritual worlds before returning to be born again into a new life on earth. After the death of the physical body, the human spirit recapitulates the past life, perceiving its events as they were experienced by the objects of its actions. A complex transformation takes place between the review of the past life and the preparation for the next life. The individual's karmic condition eventually leads to a choice of parents, physical body, disposition, and capacities that provide the challenges and opportunities that further development requires, which includes karmically chosen tasks for the future life.

Steiner described some conditions that determine the interdependence of a person's lives, or karma.

The anthroposophical view of evolution considers all animals to have evolved from an early, unspecialized form. As the least specialized animal, human beings have maintained the closest connection to the archetypal form; contrary to the Darwinian conception of human evolution, all other animals "devolve" from this archetype. The spiritual archetype originally created by spiritual beings was devoid of physical substance; only later did this descend into material existence on Earth. In this view, human evolution has accompanied the Earth's evolution throughout the existence of the Earth.

Anthroposophy adapted Theosophy's complex system of cycles of world development and human evolution. The evolution of the world is said to have occurred in cycles. The first phase of the world consisted only of heat. In the second phase, a more active condition, light, and a more condensed, gaseous state separate out from the heat. In the third phase, a fluid state arose, as well as a sounding, forming energy. In the fourth (current) phase, solid physical matter first exists. This process is said to have been accompanied by an evolution of consciousness which led up to present human culture.

The anthroposophical view is that good is found in the balance between two polar influences on world and human evolution. These are often described through their mythological embodiments as spiritual adversaries which endeavour to tempt and corrupt humanity, Lucifer and his counterpart Ahriman. These have both positive and negative aspects. Lucifer is the light spirit, which "plays on human pride and offers the delusion of divinity", but also motivates creativity and spirituality; Ahriman is the dark spirit that tempts human beings to "...deny [their] link with divinity and to live entirely on the material plane", but that also stimulates intellectuality and technology. Both figures exert a negative effect on humanity when their influence becomes misplaced or one-sided, yet their influences are necessary for human freedom to unfold.

Each human being has the task to find a balance between these opposing influences, and each is helped in this task by the mediation of the "Representative of Humanity", also known as the Christ being, a spiritual entity who stands between and harmonizes the two extremes.

The applications of anthroposophy to practical fields include:

This is a pedagogical movement with over 1000 Steiner or Waldorf schools (the latter name stems from the first such school, founded in Stuttgart in 1919) located in some 60 countries; the great majority of these are independent (private) schools. Sixteen of the schools have been affiliated with the United Nations' UNESCO Associated Schools Project Network, which sponsors education projects that foster improved quality of education throughout the world. Waldorf schools receive full or partial governmental funding in some European nations, Australia and in parts of the United States (as Waldorf method public or charter schools) and Canada.

The schools have been founded in a variety of communities: for example in the "favelas" of São Paulo to wealthy suburbs of major cities; in India, Egypt, Australia, the Netherlands, Mexico and South Africa. Though most of the early Waldorf schools were teacher-founded, the schools today are usually initiated and later supported by a parent community. Waldorf schools are among the most visible anthroposophical institutions.

Biodynamic agriculture, the first intentional form of organic farming, began in 1924, when Rudolf Steiner gave a series of lectures published in English as "The Agriculture Course". Steiner is considered one of the founders of the modern organic farming movement.

Steiner gave several series of lectures to physicians and medical students. Out of those grew an alternative medical movement intending to "extend the knowledge gained through the methods of the natural sciences of the present age with insights from spiritual science." This movement now includes hundreds of M.D.s, chiefly in Europe and North America, and has its own clinics, hospitals, and medical schools.

One of the most studied applications has been the use of mistletoe extracts in cancer therapy, but research has found no evidence of benefit.

In 1922, Ita Wegman founded an anthroposophical center for special needs education, the Sonnenhof, in Switzerland. In 1940, Karl König founded the Camphill Movement in Scotland. The latter in particular has spread widely, and there are now over a hundred Camphill communities and other anthroposophical homes for children and adults in need of special care in about 22 countries around the world. Both Karl König, Thomas Weihs and others have written extensively on these ideas underlying Special education.

Steiner designed around thirteen buildings in an organic—expressionist architectural style. Foremost among these are his designs for the two Goetheanum buildings in Dornach, Switzerland. Thousands of further buildings have been built by later generations of anthroposophic architects.

Architects who have been strongly influenced by the anthroposophic style include Imre Makovecz in Hungary, Hans Scharoun and Joachim Eble in Germany, Erik Asmussen in Sweden, Kenji Imai in Japan, Thomas Rau, Anton Alberts and Max van Huut in the Netherlands, Christopher Day and Camphill Architects in the UK, Thompson and Rose in America, Denis Bowman in Canada, and Walter Burley Griffin and Gregory Burgess in Australia.
ING House in Amsterdam is a contemporary building by an anthroposophical architect which has received awards for its ecological design and approach to a self-sustaining ecology as an autonomous building and example of sustainable architecture.

Together with Marie von Sivers, Steiner developed eurythmy, a performance art combining dance, speech, and music.

Around the world today are a number of banks, companies, charities, and schools for developing co-operative forms of business using Steiner's ideas about economic associations, aiming at harmonious and socially responsible roles in the world economy. The first anthroposophic bank was the "Gemeinschaftsbank für Leihen und Schenken" in Bochum, Germany, founded in 1974.
Socially responsible banks founded out of anthroposophy in the English-speaking world include Triodos Bank, founded in 1980 and active in the UK, Netherlands, Germany, Belgium, Spain and France.
Cultura Sparebank dates from 1982 when a group of Norwegian anthroposophists began an initiative for ethical banking but only began to operate as a savings bank in Norway in the late 90s.
La Nef in France and RSF Social Finance in San Francisco are other examples.

Harvard Business School historian Geoffrey Jones traced the considerable impact both Steiner and later anthroposophical entrepreneurs had on the creation of many businesses in organic food, ecological architecture and sustainable finance.

Bernard Lievegoed, a psychiatrist, founded a new method of individual and institutional development oriented towards humanizing organizations and linked with Steiner's ideas of the threefold social order. This work is represented by the NPI Institute for Organizational Development in the Netherlands and sister organizations in many other countries. Various forms of biographic and counselling work have been developed on the basis of anthroposophy.

There are also anthroposophical movements to renew speech and drama, the most important of which are based in the work of Marie Steiner-von Sivers ("speech formation", also known as "Creative Speech") and the "Chekhov Method" originated by Michael Chekhov (nephew of Anton Chekhov).

Anthroposophic painting, a style inspired by Rudolf Steiner, featured prominently in the first Goetheanum's cupola. The technique frequently begins by filling the surface to be painted with color, out of which forms are gradually developed, often images with symbolic-spiritual significance. Paints that allow for many transparent layers are preferred, and often these are derived from plant materials. Rudolf Steiner appointed the English sculptor Edith Maryon as head of the School of Fine Art at the Goetheanum. Together they carved the 9 metre tall sculpture ‘The Representative of Man’ which is on display at the Goetheanum.

Other applications include:

For a period after World War I, Steiner was extremely active and well known in Germany, in part because he lectured widely proposing social reforms. Steiner was a sharp critic of nationalism, which he saw as outdated, and a proponent of achieving social solidarity through individual freedom. A petition proposing a radical change in the German constitution and expressing his basic social ideas (signed by Herman Hesse, among others) was widely circulated. His main book on social reform is "Toward Social Renewal".

Anthroposophy continues to aim at reforming society through maintaining and strengthening the independence of the spheres of cultural life, human rights and the economy. It emphasizes a particular ideal in each of these three realms of society:

According to Steiner, a real spiritual world exists, evolving along with the material one. Steiner held that the spiritual world can be researched in the right circumstances through direct experience, by persons practicing rigorous forms of ethical and cognitive self-discipline. Steiner described many exercises he said were suited to strengthening such self-discipline; the most complete exposition of these is found in his book "How To Know Higher Worlds". The aim of these exercises is to develop higher levels of consciousness through meditation and observation. Details about the spiritual world, Steiner suggested, could on such a basis be discovered and reported, though no more infallibly than the results of natural science.

Steiner regarded his research reports as being important aids to others seeking to enter into spiritual experience. He suggested that a combination of spiritual exercises (for example, concentrating on an object such as a seed), moral development (control of thought, feelings and will combined with openness, tolerance and flexibility) and familiarity with other spiritual researchers' results would best further an individual's spiritual development. He consistently emphasised that any inner, spiritual practice should be undertaken in such a way as not to interfere with one's responsibilities in outer life. Steiner distinguished between what he considered were true and false paths of spiritual investigation.

In anthroposophy, artistic expression is also treated as a potentially valuable bridge between spiritual and material reality.

Steiner's stated prerequisites to beginning on a spiritual path include a willingness to take up serious cognitive studies, a respect for factual evidence, and a responsible attitude. Central to progress on the path itself is a harmonious cultivation of the following qualities:

Steiner sees meditation as a concentration and enhancement of the power of thought. By focusing consciously on an idea, feeling or intention the meditant seeks to arrive at pure thinking, a state exemplified by but not confined to pure mathematics. In Steiner's view, conventional sensory-material knowledge is achieved through relating perception and concepts. The anthroposophic path of esoteric training articulates three further stages of supersensory knowledge, which do not necessarily follow strictly sequentially in any single individual's spiritual progress.

Steiner described numerous exercises he believed would bring spiritual development; other anthroposophists have added many others. A central principle is that "for every step in spiritual perception, three steps are to be taken in moral development." According to Steiner, moral development reveals the extent to which one has achieved control over one's inner life and can exercise it in harmony with the spiritual life of other people; it shows the real progress in spiritual development, the fruits of which are given in spiritual perception. It also guarantees the capacity to distinguish between false perceptions or illusions (which are possible in perceptions of both the outer world and the inner world) and true perceptions: i.e., the capacity to distinguish in any perception between the influence of subjective elements (i.e., viewpoint) and objective reality.

Steiner built upon Goethe's conception of an imaginative power capable of synthesizing the sense-perceptible form of a thing (an image of its outer appearance) and the concept we have of that thing (an image of its inner structure or nature). Steiner added to this the conception that a further step in the development of thinking is possible when the thinker observes his or her own thought processes. "The organ of observation and the observed thought process are then identical, so that the condition thus arrived at is simultaneously one of perception through thinking and one of thought through perception."

Thus, in Steiner's view, we can overcome the subject-object divide through inner activity, even though all human experience begins by being conditioned by it. In this connection, Steiner examines the step from thinking determined by outer impressions to what he calls sense-free thinking. He characterizes thoughts he considers without sensory content, such as mathematical or logical thoughts, as free deeds. Steiner believed he had thus located the origin of free will in our thinking, and in particular in sense-free thinking.

Some of the epistemic basis for Steiner's later anthroposophical work is contained in the seminal work, Philosophy of Freedom. In his early works, Steiner sought to overcome what he perceived as the dualism of Cartesian idealism and Kantian subjectivism by developing Goethe's conception of the human being as a natural-supernatural entity, that is: natural in that humanity is a product of nature, supernatural in that through our conceptual powers we extend nature's realm, allowing it to achieve a reflective capacity in us as philosophy, art and science. Steiner was one of the first European philosophers to overcome the subject-object split in Western thought. Though not well known among philosophers, his philosophical work was taken up by Owen Barfield (and through him influenced the Inklings, an Oxford group of Christian writers that included J. R. R. Tolkien and C. S. Lewis).

Christian and Jewish mystical thought have also influenced the development of anthroposophy.

Steiner believed in the possibility of applying the clarity of scientific thinking to spiritual experience, which he saw as deriving from an objectively existing spiritual world. Steiner identified mathematics, which attains certainty through thinking itself, thus through inner experience rather than empirical observation, as the basis of his epistemology of spiritual experience.

Steiner's writing, though appreciative of all religions and cultural developments, emphasizes Western tradition as having evolved to meet contemporary needs. He describes Christ and his mission on earth of bringing individuated consciousness as having a particularly important place in human evolution, whereby:

Thus, anthroposophy considers there to be a being who unifies all religions, and who is not represented by any particular religious faith. This being is, according to Steiner, not only the Redeemer of the Fall from Paradise, but also the unique pivot and meaning of earth's evolutionary processes and of human history. To describe this being, Steiner periodically used terms such as the "Representative of Humanity" or the "good spirit" rather than any denominational term.

Steiner's views of Christianity diverge from conventional Christian thought in key places, and include gnostic elements:


Rudolf Steiner wrote and lectured on Judaism and Jewish issues over much of his adult life. He was a fierce opponent of popular antisemitism, but asserted that there was no justification for the existence of Judaism and Jewish culture in the modern world, a radical assimilationist perspective which saw the Jews completely integrating into the larger society. He also supported Émile Zola's position in the Dreyfus affair. Steiner emphasized Judaism's central importance to the constitution of the modern era in the West but suggested that to appreciate the spirituality of the future it would need to overcome its tendency toward abstraction.

In his later life, Steiner was accused by the Nazis of being a Jew, and Adolf Hitler called anthroposophy "Jewish methods". The anthroposophical institutions in Germany were banned during Nazi rule and several anthroposophists sent to concentration camps.

Important early anthroposophists who were Jewish included two central members on the executive boards of the precursors to the modern Anthroposophical Society, and Karl König, the founder of the Camphill movement, who had converted to Christianity. Martin Buber and Hugo Bergmann, who viewed Steiner's social ideas as a solution to the Arab–Jewish conflict, were also influenced by anthroposophy.

There are numerous anthroposophical organisations in Israel, including the anthroposophical kibbutz Harduf, founded by Jesaiah Ben-Aharon, forty Waldorf kindergartens and seventeen Waldorf schools (stand as of 2018). A number of these organizations are striving to foster positive relationships between the Arab and Jewish populations: The Harduf Waldorf school includes both Jewish and Arab faculty and students, and has extensive contact with the surrounding Arab communities, while the first joint Arab-Jewish kindergarten was a Waldorf program in Hilf near Haifa.

Towards the end of Steiner's life, a group of theology students (primarily Lutheran, with some Roman Catholic members) approached Steiner for help in reviving Christianity, in particular "to bridge the widening gulf between modern science and the world of spirit". They approached a notable Lutheran pastor, Friedrich Rittelmeyer, who was already working with Steiner's ideas, to join their efforts. Out of their co-operative endeavor, the "Movement for Religious Renewal", now generally known as The Christian Community, was born. Steiner emphasized that he considered this movement, and his role in creating it, to be independent of his anthroposophical work, as he wished anthroposophy to be independent of any particular religion or religious denomination.

Anthroposophy's supporters include Pulitzer Prize-winning and Nobel Laureate Saul Bellow, Nobel prize winner Selma Lagerlöf, Andrei Bely, Joseph Beuys, Owen Barfield, architect Walter Burley Griffin, Wassily Kandinsky, Andrei Tarkovsky, Bruno Walter, Right Livelihood Award winners Sir George Trevelyan, and Ibrahim Abouleish, and child psychiatrist Eva Frommer. Albert Schweitzer was a friend of Steiner's and was supportive of his ideals for cultural renewal.

The historian of religion Olav Hammer has termed anthroposophy "the most important esoteric society in European history." Authors, scientists, and physicians including Michael Shermer, Michael Ruse, Edzard Ernst, David Gorski, and Simon Singh have criticized anthroposophy's application in the areas of medicine, biology, agriculture, and education to be dangerous and pseudoscientific. Others including former Waldorf pupil Dan Dugan and historian Geoffrey Ahern have criticized anthroposophy itself as a dangerous quasi-religious movement that is fundamentally anti-rational and anti-scientific.

Though Rudolf Steiner studied natural science at the Vienna Technical University at the undergraduate level, his doctorate was in epistemology and very little of his work is directly concerned with the empirical sciences. In his mature work, when he did refer to science it was often to present phenomenological or Goethean science as an alternative to what he considered the materialistic science of his contemporaries.

Steiner's primary interest was in applying the methodology of science to realms of inner experience and the spiritual worlds (His appreciation that the essence of science is its method of inquiry is unusual among esotericists), and Steiner called anthroposophy "Geisteswissenschaft" (science of the mind, cultural/spiritual science), a term generally used in German to refer to the humanities and social sciences.

Whether this is a sufficient basis for anthroposophy to be considered a spiritual science has been a matter of controversy. As Freda Easton explained in her study of Waldorf schools, "Whether one accepts anthroposophy as a science depends upon whether one accepts Steiner's interpretation of a science that extends the consciousness and capacity of human beings to experience their inner spiritual world."

Sven Ove Hansson has disputed anthroposophy's claim to a scientific basis, stating that its ideas are not empirically derived and neither reproducible nor testable. Carlo Willmann points out that as, on its own terms, anthroposophical methodology offers no possibility of being falsified except through its own procedures of spiritual investigation, no intersubjective validation is possible by conventional scientific methods; it thus cannot stand up to empiricist critics. Peter Schneider describes such objections as untenable, asserting that that if a non-sensory, non-physical realm exists, then according to Steiner the experiences of pure thinking possible within the normal realm of consciousness would already be experiences of that, and it would be impossible to exclude the possibility of empirically grounded experiences of other supersensory content.

Olav Hammer suggests that anthroposophy carries scientism "to lengths unparalleled in any other Esoteric position" due to its dependence upon claims of clairvoyant experience, its subsuming natural science under "spiritual science." Hammer also asserts that the development of what she calls "fringe" sciences such as anthroposophic medicine and biodynamic agriculture are justified partly on the basis of the ethical and ecological values they promote, rather than purely on a scientific basis.

Though Steiner saw that spiritual vision itself is difficult for others to achieve, he recommended open-mindedly exploring and rationally testing the results of such research; he also urged others to follow a spiritual training that would allow them directly to apply his methods to achieve comparable results.

Anthony Storr stated about Rudolf Steiner's Anthroposophy: "His belief system is so eccentric, so unsupported by evidence, so manifestly bizarre, that rational skeptics are bound to consider it delusional... But, whereas Einstein's way of perceiving the world by thought became confirmed by experiment and mathematical proof, Steiner's remained intensely subjective and insusceptible of objective confirmation."

As an explicitly spiritual movement, anthroposophy has sometimes been called a religious philosophy. In 1998 People for Legal and Non-Sectarian Schools (PLANS) started a lawsuit alleging that anthroposophy is a religion for Establishment Clause purposes and therefore several California school districts should not be chartering Waldorf schools; the lawsuit was dismissed in 2012 for failure to show anthroposophy was a religion. In 2000, a French court ruled that a government minister's description of anthroposophy as a cult was defamatory.

Anthroposophical ideas have been criticized from both sides in the race debate:


In response to such critiques, the Anthroposophical Society in America published a statement clarifying its stance:
We explicitly reject any racial theory that may be construed to be part of Rudolf Steiner's writings. The Anthroposophical Society in America is an open, public society and it rejects any purported spiritual or scientific theory on the basis of which the alleged superiority of one race is justified at the expense of another race.





</doc>
<doc id="2494" url="https://en.wikipedia.org/wiki?curid=2494" title="Aurochs">
Aurochs

The aurochs ( or ; pl. aurochs, or rarely aurochsen, aurochses), also known as urus or ure ("Bos primigenius"), is an extinct species of large wild cattle that inhabited Europe, Asia, and North Africa. It is the ancestor of domestic cattle; it has also been suggested as an ancestor genetically to the modern European bison, which have been crossbred with steppe bison. The species survived in Europe until 1627, when the last recorded aurochs died in the Jaktorów Forest, Poland.

During the Neolithic Revolution, which occurred during the early Holocene, at least two aurochs domestication events occurred: one related to the Indian subspecies, leading to zebu cattle, and the other one related to the Eurasian subspecies, leading to taurine cattle. Other species of wild bovines were also domesticated, namely the wild water buffalo, gaur, wild yak and banteng. In modern cattle, numerous breeds share characteristics of the aurochs, such as a dark colour in the bulls with a light eel stripe along the back (the cows being lighter), or a typical aurochs-like horn shape.

The aurochs was variously classified as "Bos primigenius", "Bos taurus", or, in old sources, "Bos urus". However, in 2003, the International Commission on Zoological Nomenclature "conserved the usage of 17 specific names based on wild species, which are predated by or contemporary with those based on domestic forms", confirming "Bos primigenius" for the aurochs. Taxonomists who consider domesticated cattle a subspecies of the wild aurochs should use "B. primigenius taurus"; those who consider domesticated cattle to be a separate species may use the name "B. taurus", which the Commission has kept available for that purpose.

The words aurochs, urus, and wisent have all been used synonymously in English. But the extinct aurochs/urus is a completely separate species from the still-extant wisent, also known as European bison. The two were often confused, and some 16th-century illustrations of aurochs and wisents have hybrid features.
The word "urus" (; plural "uri") is a Latin word, but was borrowed into Latin from Germanic (cf. Old English/Old High German "ūr", Old Norse "úr"). In German, OHG "ūr" was compounded with "ohso" "ox", giving "ūrohso", which became early modern "Aurochs". The modern form is "Auerochse".

The word "aurochs" was borrowed from early modern German, replacing archaic "urochs", also from an earlier form of German. The word is invariable in number in English, though sometimes a back-formed singular "auroch" and/or innovated plural "aurochses" occur. The use in English of the plural form "" is nonstandard, but mentioned in "The Cambridge Encyclopedia of the English Language". It is directly parallel to the German plural "Ochsen" (singular "Ochse") and recreates by analogy the same distinction as English "ox" (singular) and "oxen" (plural).

During the Pliocene, the colder climate caused an extension of open grassland, which led to the evolution of large grazers, such as wild bovines. "Bos acutifrons" is an extinct species of cattle that has been suggested as an ancestor for the aurochs.

The oldest aurochs remains have been dated to about 2 million years ago, in India. The Indian subspecies was the first to appear. During the Pleistocene, the species migrated west into the Middle East (western Asia), as well as to the east. They reached Europe about 270,000 years ago. The South Asian domestic cattle, or zebu, descended from Indian aurochs at the edge of the Thar Desert; the zebu is resistant to drought. Domestic yak, gayal, and Bali cattle do not descend from aurochs.

The first complete mitochondrial genome (16,338 base pairs) DNA sequence analysis of "Bos primigenius" from an archaeologically verified and exceptionally well preserved aurochs bone sample was published in 2010, followed by the publication in 2015 of the complete genome sequence of "Bos primigenius" using DNA isolated from a 6,750-year-old British aurochs bone. Further studies using the "Bos primigenius" whole genome sequence have identified candidate microRNA-regulated domestication genes

Three wild subspecies of aurochs are recognised. Only the Eurasian subspecies survived until recent times.

The appearance of the aurochs has been reconstructed from skeletal material, historical descriptions, and contemporaneous depictions, such as cave paintings, engravings, or Sigismund von Herberstein’s illustration. The work by Charles Hamilton Smith is a copy of a painting owned by a merchant in Augsburg, which may date to the 16th century. Scholars have proposed that Smith's illustration was based on a cattle/aurochs hybrid, or an aurochs-like breed. The aurochs was depicted in prehistoric cave paintings and described in Julius Caesar's "The Gallic War, Book 6, Ch. 28".

The aurochs were one of the largest herbivores in postglacial Europe, comparable to the wisent (European bison). The size of an aurochs appears to have varied by region; in Europe, northern populations were bigger on average than those from the south. For example, during the Holocene, aurochs from Denmark and Germany had an average height at the shoulders of in bulls and in cows, while aurochs populations in Hungary had bulls reaching . The body mass of aurochs appears to have shown some variability. Some individuals were comparable in weight to the wisent and the banteng, reaching around , whereas those from the late-middle Pleistocene are estimated to have weighed up to , as much as the largest gaur (the largest extant bovid). The sexual dimorphism between bulls and cows was strongly expressed, with the cows being significantly shorter than bulls on average.

Because of the massive horns, the frontal bones of aurochs were elongated and broad. The horns of the aurochs were characteristic in size, curvature, and orientation. They were curved in three directions: upwards and outwards at the base, then swinging forwards and inwards, then inwards and upwards. Aurochs horns could reach in length and between in diameter. The horns of bulls were larger, with the curvature more strongly expressed than in cows. The horns grew from the skull at a 60° angle to the muzzle, facing forwards.

The proportions and body shape of the aurochs were strikingly different from many modern cattle breeds. For example, the legs were considerably longer and more slender, resulting in a shoulder height that nearly equalled the trunk length. The skull, carrying the large horns, was substantially larger and more elongated than in most cattle breeds. As in other wild bovines, the body shape of the aurochs was athletic, and especially in bulls, showed a strongly expressed neck and shoulder musculature. Therefore, the fore hand was larger than the rear, similar to the wisent, but unlike many domesticated cattle. Even in carrying cows, the udder was small and hardly visible from the side; this feature is equal to that of other wild bovines.
The coat colour of the aurochs can be reconstructed by using historical and contemporary depictions. In his letter to Conrad Gesner (1602), Anton Schneeberger describes the aurochs, a description that agrees with cave paintings in Lascaux and Chauvet. Calves were born a chestnut colour. Young bulls changed their coat colour at a few months old to a very deep brown or black, with a white eel stripe running down the spine. Cows retained the reddish-brown colour. Both sexes had a light-coloured muzzle. Some North African engravings show aurochs with a light-coloured "saddle" on the back, but otherwise no evidence of variation in coat colour is seen throughout its range. A passage from Mucante (1596), describing the “wild ox” as gray, but is ambiguous and may refer to the wisent. Egyptian grave paintings show cattle with a reddish-brown coat colour in both sexes, with a light saddle, but the horn shape of these suggest that they may depict domesticated cattle. Remains of aurochs hair were not known until the early 1980s.

Some primitive cattle breeds display similar coat colours to the aurochs, including the black colour in bulls with a light eel stripe, a pale mouth, and similar sexual dimorphism in colour. A feature often attributed to the aurochs is blond forehead hairs. Historical descriptions tell that the aurochs had long and curly forehead hair, but none mentions a certain colour for it. Cis van Vuure (2005) says that, although the colour is present in a variety of primitive cattle breeds, it is probably a discolouration that appeared after domestication. The gene responsible for this feature has not yet been identified. Zebu breeds show lightly coloured inner sides of the legs and belly, caused by the so-called zebu-tipping gene. It has not been tested if this gene is present in remains of the wild form of the zebu, the Indian aurochs.

Like many bovids, aurochs formed herds for at least a part of the year. These probably did not number much more than 30. If aurochs had social behaviour similar to their descendants, social status was gained through displays and fights, in which cows engaged as well as bulls. Indeed, aurochs bulls were reported to often have had severe fights. As in other wild cattle, ungulates that form unisexual herds, considerable sexual dimorphism was expressed. Ungulates that form herds containing animals of both sexes, such as horses, have more weakly developed sexual dimorphism.

During the mating season, which probably took place during the late summer or early autumn, the bulls had severe fights, and evidence from the forest of Jaktorów shows these could lead to death. In autumn, aurochs fed up for the winter and got fatter and shinier than during the rest of the year, according to Schneeberger. Calves were born in spring. According to Schneeberger, the calf stayed at the cow's side until it was strong enough to join and keep up with the herd on the feeding grounds.

Calves were vulnerable to wolves and, to an extent, bears, while healthy adult aurochs probably did not have to fear these predators. In prehistoric Europe, North Africa, and Asia, big cats, such as lions and tigers, and hyenas were additional predators that probably preyed on aurochs.

Historical descriptions, like Caesar's "Commentarii de Bello Gallico" or Schneeberger, tell that aurochs were swift and fast, and could be very aggressive. According to Schneeberger, aurochs were not concerned when a man approached, but when teased or hunted, an aurochs could get very aggressive and dangerous, and throw the teasing person into the air, as he described in a 1602 letter to Gesner.

No consensus exists concerning the habitat of the aurochs. While some authors think that the habitat selection of the aurochs was comparable to the African forest buffalo, others describe the species as inhabiting open grassland and helping maintain open areas by grazing, together with other large herbivores. With its hypsodont jaw, the aurochs was probably a grazer and had a food selection very similar to domesticated cattle. It was not a browser like many deer species, nor a semi-intermediary feeder like the wisent. Comparisons of the isotope levels of Mesolithic aurochs and domestic cattle bones showed that aurochs probably inhabited wetter areas than domestic cattle. Schneeberger describes that during winter, the aurochs ate twigs and acorns in addition to grasses.

After the beginning of the Common Era, the habitat of aurochs became more fragmented because of the steadily growing human population. During the last centuries of its existence, the aurochs was limited to remote regions, such as floodplain forests or marshes, with no competing domestic herbivores and less hunting pressure.

The aurochs, which ranged throughout much of Eurasia and Northern Africa during the late Pleistocene and early Holocene, is the wild ancestor of modern cattle. Archaeological evidence shows that domestication occurred independently in the Near East and the Indian subcontinent between 10,000 and 8,000 years ago, giving rise to the two major domestic taxa observed today: humpless "Bos taurus" (taurine) and humped "Bos indicus" (zebu), respectively. This is confirmed by genetic analyses of matrilineal mitochondrial DNA sequences, which reveal a marked differentiation between modern "B. taurus" and "B. indicus" haplotypes, demonstrating their derivation from two geographically and genetically divergent wild populations. A third domestication event possibly occurred from another form of the aurochs in Africa. The sanga cattle, a zebu-like cattle breed with no back hump, is commonly believed to originate from crosses between humped zebus with taurine cattle breeds. However, some archaeological evidence indicates these cattle were domesticated independently in Africa and that bloodlines of taurine and zebu cattle were introduced only within the last few hundreds years.

Domestication of the aurochs began in the southern Caucasus and northern Mesopotamia from about the sixth millennium BC. Genetic evidence suggests that aurochs were independently domesticated in India and possibly also in northern Africa. Domesticated cattle and aurochs are so different in size that they have been regarded as separate species; however, large ancient cattle and aurochs have more similar morphological characteristics, with significant differences only in the horns and some parts of the cranium.

A mitochondrial DNA study suggests that all domesticated taurine cattle originated from about 80 wild female aurochs in the Near East.

Comparison of aurochs bones with those of modern cattle has provided many insights about the aurochs. Remains of the beast, from specimens believed to have weighed more than a ton, have been found in Mesolithic sites around Goldcliff, Wales.
Though aurochs became extinct in Britain during the Bronze Age, analysis of bones from aurochs that lived about the same time as domesticated cattle traditionally suggested no genetic contribution to modern breeds. More recent work has pointed to substantial aurochs contributions to indigenous British cattle breeds, with the most material found in Kerry cattle.

Indian zebu, although domesticated eight to ten thousand years ago, are related to aurochs that diverged from the Near Eastern ones some 200,000 years ago. African cattle are thought to have descended from aurochs more closely related to the Near Eastern ones. The Near East and African aurochs groups are thought to have split some 25,000 years ago, probably 15,000 years before domestication. The "Turano-Mongolian" type of cattle now found in northern China, Mongolia, Korea, and Japan may represent a fourth domestication event (and a third event among "B. taurus"–type aurochs). This group may have diverged from the Near East group some 35,000 years ago. Whether these separate genetic populations would have equated to separate subspecies is unclear.

The maximum range of the aurochs was from Europe (excluding Ireland and northern Scandinavia), to northern Africa, the Middle East, India, and Central Asia. Until at least 3,000 years ago, the aurochs was also found in eastern China, where it is recorded at the Dingjiabao Reservoir in Yangyuan County. Most remains in China are known from the area east of 105°E, but the species has also been reported from the eastern margin of the Tibetan plateau, close to the Heihe River. In Japan, excavations in various locations, such as in Iwate and Tochigi prefectures, have found aurochs which may have herded with steppe bison.

By the time of Herodotus (fifth century BC), aurochs had disappeared from southern Greece, but remained common in the area north and east of the Echedorus River close to modern Thessaloniki. The last reports of the species in the southern tip of the Balkans date to the first century BC, when Varro reported that fierce wild oxen lived in Dardania (southern Serbia) and Thrace. By the 13th century AD, the aurochs' range was restricted to Poland, Lithuania, Moldavia, Transylvania, and East Prussia. The right to hunt large animals on any land was restricted first to nobles, and then gradually, to only the royal households. As the population of aurochs declined, hunting ceased, and the royal court used gamekeepers to provide open fields for grazing for the aurochs. The gamekeepers were exempted from local taxes in exchange for their service. Poaching aurochs was punishable by death.

According to a Polish royal survey in 1564, the gamekeepers knew of 38 animals. The last recorded live aurochs, a female, died in 1627 in the Jaktorów Forest, Poland, from natural causes. The causes of extinction were unrestricted hunting, a narrowing of habitat due to the development of farming, and diseases transmitted by domesticated cattle.

While all the wild subspecies are extinct, "B. primigenius" lives on in domesticated cattle, and attempts are being made to breed similar types suitable for filling the extinct subspecies' role in the wild.

The idea of breeding back the aurochs was first proposed in the 19th century by Feliks Paweł Jarocki. In the 1920s, a first attempt was undertaken by the Heck brothers in Germany with the aim of breeding an effigy (a look-alike) of the aurochs. Starting in the 1990s, grazing and rewilding projects brought new impetus to the idea and new breeding-back efforts came underway, this time with the aim of recreating an animal not only with the looks, but also with the behaviour and the ecological impact of the aurochs, to be able to fill the ecological role of the aurochs.
In the early 1920s, two German zoo directors (in Berlin and Munich), the brothers Heinz and Lutz Heck, began a selective breeding program to breed back the aurochs into existence from the descendant domesticated cattle. Their plan was based on the concept that a species is not extinct as long as all its genes are still present in a living population. The result is the breed called Heck cattle. It resembles what is known about the appearance of the aurochs in colour, and in some cases, also horn shape.

The "Arbeitsgemeinschaft Biologischer Umweltschutz", a conservation group in Germany, started to crossbreed Heck cattle with southern-European primitive breeds in 1996, with the goal of increasing the aurochs-likeness of certain Heck cattle herds. These crossbreeds are called Taurus cattle. It is intended to bring in aurochs-like features that are supposedly missing in Heck cattle using Sayaguesa Cattle and Chianina, and to a lesser extent Spanish Fighting Cattle (Lidia). The same breeding program is being carried out in Latvia, in Lille Vildmose National Park in Denmark, and in the Hungarian Hortobágy National Park. The program in Hungary also includes Hungarian Grey cattle and Watusi.

The Dutch-based Tauros Programme, (initially TaurOs Project) is trying to DNA-sequence breeds of primitive cattle to find gene sequences that match those found in "ancient DNA" from aurochs samples. The modern cattle would be selectively bred to try to produce the aurochs-type genes in a single animal. Starting around 2007, Tauros Programme selected a number of primitive breeds mainly from Iberia and Italy, such as Sayaguesa cattle, Maremmana primitivo, Pajuna cattle, Limia cattle, Maronesa cattle, Tudanca cattle, and others, which already bear considerable resemblance to the aurochs in certain features. Tauros Programme started collaborations with Rewilding Europe and European Wildlife, two European organizations for ecological restoration and rewilding, and now has breeding herds not only in the Netherlands but also in Portugal, Croatia, Romania, and the Czech Republic. Numerous crossbred calves of the first, second, and third offspring generations have already been born. An ecologist working on the Tauros programme has estimated it will take 7 generations for the project to achieve its aims, possibly by 2025.

A further back-breeding effort, the Uruz project, was started in 2013 by the True Nature Foundation, an organization for ecological restoration and rewilding. It differs from the other projects in that it is planning to make use of genome editing. Its preliminary plans called for the use of Sayaguesa, Maremmana primitive, or Hungarian Grey (Steppe) cattle, and Texas Longhorn with wildtype colour or Barrosã cattle. The finalised plans now call for setting up two breeding lines, Sayaguesa × Maremmana primitiva/Hungarian Steppe cattle and Watusi × Chianina, and later crossing these lines. Two Watusi × Chianina breeding herds have been set up in Boxmeer and Breda in the Netherlands, another herd using Barrosã is being set up in northern Portugal.

The newest of the back-breeding efforts, the "Auerrindprojekt", was started in 2015 as a conjoint effort of the Experimentalarchäologisches Freilichtlabor Lauresham (Lauresham Experimental-Archaeological Open-air Laboratory, run by Lorsch Abbey), the Förderkreis Große Pflanzenfresser im Kreis Bergstraße e.V. (Promoting Association Megaherbivores in Bergstraße District) and the Landschaftspflegebetrieb Hohmeyer (Landscape Preservation Company Hohmeyer). In accordance with the breeding aims, the Auerrindprojekt has already set up two breeding herds of Watusi × Chianina and one breeding herd of Sayaguesa x Podolian cattle; a second breeding herd of Sayaguesa × Podolian cattle will be started in 2017. Podolian breeds used include Maremmana and Hungarian Grey cattle. The project will not use 'Heck cattle' as they have been deemed too genetically dissimilar to the extinct Aurochs, and it will not use any fighting breeds of cattle, as an animal that has been bred for aggression cannot be released into the wild. The project aims to produce a very close facsimile of the wild Aurochs by 2028-2033.

Scientists of the Polish Foundation for Recreating the Aurochs (PFOT) in Poland hope to use DNA from bones in museums to recreate the aurochs. They plan to return this animal to the forests of Poland. The project has gained the support of the Polish Ministry of the Environment. They plan research on ancient preserved DNA. Other research projects have extracted "ancient" DNA over the past 20 years and their results have been published in such periodicals as "Nature" and "PNAS". Polish scientists Ryszard Słomski and Jacek A. Modliński believe that modern genetics and biotechnology make it possible to recreate an animal almost identical to the aurochs. They say this research will lead to examining the causes of the extinction of the aurochs, and help prevent a similar occurrence with domesticated cattle.

Approaches that aim to breed an aurochs-like phenotype do not equate to an aurochs-like genotype. In 2015, researchers mapped the draft genome of a British aurochs dated to 6,750 years before present. Researchers compared the genome to the genomes of 73 modern cattle populations and found that traditional or landrace cattle breeds of Scottish, Irish, Welsh, and English origin – such as Highland, Dexter, Kerry, Welsh Black, and White Park – carry the ancestry of the sequenced aurochs, but the other populations did not. Another study concluded that because of this genomic introgression of the aurochs into these breeds, if this reflects "the bigger picture across the aurochs/cattle range, perhaps several subpopulations of aurochs are not extinct at all." The study proposed that it will be possible to consider breeding back cattle "that are genetically akin to specific original aurochs populations, through selective cross-breeding of local cattle breeds bearing local aurochs-genome ancestry."

The aurochs was an important game animal appearing in both Paleolithic European and Mesopotamian cave paintings, such as those found at Lascaux and Livernon in France. Aurochs existed into the Iron Age in Anatolia and the Near East, where it was worshiped as a sacred animal, the Lunar Bull, associated with the Great Goddess and later with Mithras. In 2012, an archaeological mission of the British Museum, led by Lebanese archaeologist Claude Doumet Serhal, discovered at the site of the old American school in Sidon, Lebanon, the remains of wild animal bones, including those of an aurochs, dating from the late-fourth to early-third millennium. A 1999 archaeological dig in Peterborough, England, uncovered the skull of an aurochs. The front part of the skull had been removed, but the horns remained attached. The supposition is that the killing of the aurochs in this instance was a sacrificial act.

Also during antiquity, the aurochs was regarded as an animal of cultural value. Aurochs are depicted on the Ishtar Gate. In the Peloponnese there is a 15th-century BC depiction on the so-called violent cup of Vaphio, of hunters trying to capture with nets three wild bulls being probably aurochs, in a possibly Cretan date palm stand. The one of the bulls throws one hunter on the ground while attacking the second with its horns. The cup despite the older perception of being Minoan seems to be Mycenaean. Greeks and Paeonians were hunting aurochs (wild oxen/bulls) and used their huge horns as trophies, cups for wine, and offers to the gods and heroes. For example, as mentioned by Samus, Philippus of Thessalonica and Antipater when Philip V of Macedon killed an aurochs on the foothills of mountain Orvilos, he offered the horns which were 105 cm long and the skin to a temple of Hercules. Aurochs horns were often used by Romans as hunting horns. Aurochs were among those wild animals caught for fights ("venationes") in arenas. Julius Caesar described aurochs in Gaul:

They survived in the wild in Europe till late in the Roman Empire and were occasionally captured and exhibited live in shows in the colosseum.

The Hebrew Bible contains numerous references to the untameable strength of "re'em", translated as "bullock" or "wild-ox" in Jewish translations and translated rather poorly in the King James Version as "unicorn", but recognised from the last century by Hebrew scholars as the aurochs.

When the aurochs became rarer, hunting it became a privilege of the nobility and a sign of a high social status. The "Nibelungenlied" describes Siegfried killing aurochs: ""Darnach schlug er schiere einen Wisent und einen Elch, starker Ure viere und einen grimmen Schelch"", meaning "After that, he defeated one wisent and one elk, four aurochs, and one Schelch" - the background of the "Schelch" is dubious. Aurochs horns were commonly used as drinking horns by the nobility, which led to the fact that many aurochs horn sheaths are preserved today (albeit often discoloured). The drinking horn at Corpus Christi College, Cambridge, given to the college on its foundation in 1352, probably by the college's founders, the Guilds of Corpus Christi and the Blessed Virgin Mary, is thought to come from an aurochs. A painting by Willem Kalf depicts an aurochs horn. The horns of the last aurochs bulls, which died in 1620, were ornamented with gold and are located at the Livrustkammaren in Stockholm today.

Schneeberger writes that aurochs were hunted with arrows, nets, and hunting dogs. With immobilised aurochs, a ritual was practised that might be regarded as cruel nowadays: the curly hair on the forehead was cut from the skull of the living animal. Belts were made out of this hair and were believed to increase the fertility of women. When the aurochs was slaughtered, a cross-like bone ("os cardis") was extracted from the heart. This bone, which is also present in domesticated cattle, contributed to the mystique of the animal and magical powers have been attributed to it.
In eastern Europe, where it survived until nearly 400 years ago, the aurochs has left traces in fixed expressions. In Russia, a drunken person behaving badly was described as "behaving like an aurochs", whereas in Poland, big, strong people were characterized as being "a bloke like an aurochs".

In Central Europe, the aurochs features in toponyms and heraldic coats of arms. For example, the names Ursenbach and Aurach am Hongar are derived from the aurochs. An aurochs head, the traditional arms of the German region Mecklenburg, figures in the coat of arms of Mecklenburg-Vorpommern. The aurochs (Romanian "bour", from Latin "būbalus") was also the symbol of Moldavia; nowadays, they can be found in the coat of arms of both Romania and Moldova. An aurochs head is featured on an 1858 series of Moldavian stamps, the so-called Bull's Heads ("cap de bour" in Romanian), renowned for their rarity and price among collectors. In Romania there are still villages named Boureni, after the Romanian word for the auroch. The horn of the aurochs is a charge of the coat of arms of Tauragė, Lithuania, (the name of Tauragė is a compound of "taũras" "auroch" and "ragas" "horn"). It is also present in the emblem of Kaunas, Lithuania, and was part of the emblem of Bukovina during its time as an Austro-Hungarian "Kronland". The Swiss Canton of Uri is named after the aurochs; its yellow flag shows a black aurochs head. East Slavic surnames Turenin, Turishchev, Turov, and Turovsky originate from the Slavic name of the species "tur". In Slovakia, toponyms such as Turany, Turíčky, Turie, Turie Pole, Turík, Turová (villages), Turiec (river and region), Turská dolina (valley) and others are used. Turopolje, a large lowland floodplain south of the Sava River in Croatia, got its name from the once-abundant aurochs (Croatian: ). The ancient name of the Estonian town of Rakvere, "Tarwanpe" or "Tarvanpea", probably derives from "Aurochs head" ("Tarvan pea") in ancient Estonian.

In 2002, a 3.5-m-high and 7.1-m-long statue of an aurochs was erected in Rakvere, Estonia, for the town's 700th birthday. The sculpture, by artist Tauno Kangro, has become a symbol of the town.

Aurochs are frequently mentioned in the "A Song of Ice and Fire" series of fantasy novels by George R. R. Martin; in particular, roasted aurochs are sometimes served at banquets.

In the 2012 movie "Beasts of the Southern Wild", the six-year-old main character imagines aurochs, though the fantasy creatures are portrayed by "costumed" Vietnamese Pot-bellied piglets.


This article incorporates Creative Commons license CC BY-2.5 text from reference.




</doc>
<doc id="2499" url="https://en.wikipedia.org/wiki?curid=2499" title="Asynchronous transfer mode">
Asynchronous transfer mode

Asynchronous Transfer Mode (ATM) is, according to the ATM Forum, "a telecommunications concept defined by ANSI and ITU (formerly CCITT) standards for carriage of a complete range of user traffic, including voice, data, and video signals". ATM was developed to meet the needs of the Broadband Integrated Services Digital Network, as defined in the late 1980s, and designed to integrate telecommunication networks. Additionally, It was designed for networks that must handle both traditional high-throughput data traffic (e.g., file transfers), and real-time, low-latency content such as voice and video. The reference model for ATM approximately maps to the three lowest layers of the ISO-OSI reference model: network layer, data link layer, and physical layer. ATM is a core protocol used over the SONET/SDH backbone of the public switched telephone network (PSTN) and Integrated Services Digital Network (ISDN), but its use is declining in favour of all IP.

ATM provides functionality that is similar to both circuit switching and packet switching networks: ATM uses asynchronous time-division multiplexing, and encodes data into small, fixed-sized packets (ISO-OSI frames) called "cells." This differs from approaches such as the Internet Protocol or Ethernet that use variable sized packets and frames. ATM uses a connection-oriented model in which a virtual circuit must be established between two endpoints before the actual data exchange begins. These virtual circuits may be “permanent”, i.e. dedicated connections that are usually preconfigured by the service provider, or “switched”, i.e. set up on a per-call basis using signaling and disconnected when the call is terminated.

Use of ATM technology was eventually largely superseded by Internet Protocol (IP)-only technology. Wireless and mobile ATM never established a significant foothold.

In the ISO-OSI reference model data link layer (layer 2), the basic transfer units are generically called frames. In ATM these frames are of a fixed (53 octets or bytes) length and specifically called "cells".

If a speech signal is reduced to packets, and it is forced to share a link with bursty data traffic (traffic with some large data packets) then no matter how small the speech packets could be made, they would always encounter full-size data packets. Under normal queuing conditions the cells might experience maximum queuing delays. To avoid this issue, all ATM packets, or "cells," are the same small size. In addition, the fixed cell structure means that ATM can be readily switched by hardware without the inherent delays introduced by software switched and routed frames.

Thus, the designers of ATM utilized small data cells to reduce jitter (delay variance, in this case) in the multiplexing of data streams. Reduction of jitter (and also end-to-end round-trip delays) is particularly important when carrying voice traffic, because the conversion of digitized voice into an analogue audio signal is an inherently real-time process, and to do a good job, the decoder (codec) that does this needs an evenly spaced (in time) stream of data items. If the next data item is not available when it is needed, the codec has no choice but to produce silence or guess — and if the data is late, it is useless, because the time period when it should have been converted to a signal has already passed.

At the time of the design of ATM, 155 Mbit/s synchronous digital hierarchy (SDH) with 135 Mbit/s payload was considered a fast optical network link, and many plesiochronous digital hierarchy (PDH) links in the digital network were considerably slower, ranging from 1.544 to 45 Mbit/s in the US, and 2 to 34 Mbit/s in Europe.

At 155 Mbit/s, a typical full-length 1,500 byte (12,000-bit) data packet, sufficient to contain a maximum-sized IP packet for Ethernet, would take 77.42 µs to transmit. In a lower-speed link, such as a 1.544 Mbit/s T1 line, the same packet would take up to 7.8 milliseconds.

A queuing delay induced by several such data packets might exceed the figure of 7.8 ms several times over, in addition to any packet generation delay in the shorter speech packet. This was clearly unacceptable for speech traffic, which needs to have low jitter in the data stream being fed into the codec if it is to produce good-quality sound. A packet voice system can produce this low jitter in a number of ways:


The design of ATM aimed for a low-jitter network interface. However, "cells" were introduced into the design to provide short queuing delays while continuing to support datagram traffic. ATM broke up all packets, data, and voice streams into 48-byte chunks, adding a 5-byte routing header to each one so that they could be reassembled later. The choice of 48 bytes was political rather than technical. When the CCITT (now ITU-T) was standardizing ATM, parties from the United States wanted a 64-byte payload because this was felt to be a good compromise in larger payloads optimized for data transmission and shorter payloads optimized for real-time applications like voice; parties from Europe wanted 32-byte payloads because the small size (and therefore short transmission times) simplify voice applications with respect to echo cancellation. Most of the European parties eventually came around to the arguments made by the Americans, but France and a few others held out for a shorter cell length. With 32 bytes, France would have been able to implement an ATM-based voice network with calls from one end of France to the other requiring no echo cancellation. 48 bytes (plus 5 header bytes = 53) was chosen as a compromise between the two sides. 5-byte headers were chosen because it was thought that 10% of the payload was the maximum price to pay for routing information. ATM multiplexed these 53-byte cells instead of packets which reduced worst-case cell contention jitter by a factor of almost 30, reducing the need for echo cancellers.

An ATM cell consists of a 5-byte header and a 48-byte payload. The payload size of 48 bytes was chosen as described above.

ATM defines two different cell formats: user–network interface (UNI) and network–network (NNI). Most ATM links use UNI cell format.

ATM uses the PT field to designate various special kinds of cells for operations, administration and management (OAM) purposes, and to delineate packet boundaries in some ATM adaptation layers (AAL). If the most significant bit (MSB) of the PT field is 0, this is a user data cell, and the other two bits are used to indicate network congestion and as a general purpose header bit available for ATM adaptation layers. If the MSB is 1, this is a management cell, and the other two bits indicate the type. (Network management segment, network management end-to-end, resource management, and reserved for future use.)

Several ATM link protocols use the HEC field to drive a CRC-based framing algorithm, which allows locating the ATM cells with no overhead beyond what is otherwise needed for header protection. The 8-bit CRC is used to correct single-bit header errors and detect multi-bit header errors. When multi-bit header errors are detected, the current and subsequent cells are dropped until a cell with no header errors is found.

A UNI cell reserves the GFC field for a local flow control/submultiplexing system between users. This was intended to allow several terminals to share a single network connection, in the same way that two Integrated Services Digital Network (ISDN) phones can share a single basic rate ISDN connection. All four GFC bits must be zero by default.

The NNI cell format replicates the UNI format almost exactly, except that the 4-bit GFC field is re-allocated to the VPI field, extending the VPI to 12 bits. Thus, a single NNI ATM interconnection is capable of addressing almost 2 VPs of up to almost 2 VCs each (in practice some of the VP and VC numbers are reserved).

ATM supports different types of services via AALs. Standardized AALs include AAL1, AAL2, and AAL5, and the rarely used AAL3 and AAL4. AAL1 is used for constant bit rate (CBR) services and circuit emulation. Synchronization is also maintained at AAL1. AAL2 through AAL4 are used for variable bitrate (VBR) services, and AAL5 for data. Which AAL is in use for a given cell is not encoded in the cell. Instead, it is negotiated by or configured at the endpoints on a per-virtual-connection basis.

Following the initial design of ATM, networks have become much faster. A 1500 byte (12000-bit) full-size Ethernet frame takes only 1.2 µs to transmit on a 10 Gbit/s network, reducing the need for small cells to reduce jitter due to contention. Some consider that this makes a case for replacing ATM with Ethernet in the network backbone. The increased link speeds by themselves do not alleviate jitter due to queuing. Additionally, the hardware for implementing the service adaptation for IP packets is expensive at very high speeds. Specifically, at speeds of OC-3 and above, the cost of segmentation and reassembly (SAR) hardware makes ATM less competitive for IP than Packet Over SONET (POS); because of its fixed 48-byte cell payload, ATM is not suitable as a data link layer "directly" underlying IP (without the need for SAR at the data link level) since the OSI layer on which IP operates must provide a maximum transmission unit (MTU) of at least 576 bytes. SAR performance limits mean that the fastest IP router ATM interfaces are STM16 - STM64 which actually compares, while POS can operate at OC-192 (STM64) with higher speeds expected in the future, limits based on segmentation and reassembly (SAR).

On slower or congested links (622 Mbit/s and below), ATM does make sense, and for this reason most asymmetric digital subscriber line (ADSL) systems use ATM as an intermediate layer between the physical link layer and a Layer 2 protocol like PPP or Ethernet.

At these lower speeds, ATM provides a useful ability to carry multiple logical circuits on a single physical or virtual medium, although other techniques exist, such as Multi-link PPP and Ethernet VLANs, which are optional in VDSL implementations. DSL can be used as an access method for an ATM network, allowing a DSL termination point in a telephone central office to connect to many internet service providers across a wide-area ATM network. In the United States, at least, this has allowed DSL providers to provide DSL access to the customers of many internet service providers. Since one DSL termination point can support multiple ISPs, the economic feasibility of DSL is substantially improved.

ATM operates as a channel-based transport layer, using virtual circuits (VCs). This is encompassed in the concept of the virtual paths (VP) and virtual channels. Every ATM cell has an 8- or 12-bit virtual path identifier (VPI) and 16-bit virtual channel identifier (VCI) pair defined in its header. The VCI, together with the VPI, is used to identify the next destination of a cell as it passes through a series of ATM switches on its way to its destination. The length of the VPI varies according to whether the cell is sent on the user-network interface (on the edge of the network), or if it is sent on the network-network interface (inside the network).

As these cells traverse an ATM network, switching takes place by changing the VPI/VCI values (label swapping). Although the VPI/VCI values are not necessarily consistent from one end of the connection to the other, the concept of a circuit "is" consistent (unlike IP, where any given packet could get to its destination by a different route than the others). ATM switches use the VPI/VCI fields to identify the virtual channel link (VCL) of the next network that a cell needs to transit on its way to its final destination. The function of the VCI is similar to that of the data link connection identifier (DLCI) in frame relay and the logical channel number and logical channel group number in X.25.

Another advantage of the use of virtual circuits comes with the ability to use them as a multiplexing layer, allowing different services (such as voice, frame relay, n* 64 channels, IP). The VPI is useful for reducing the switching table of some virtual circuits which have common paths.

Another key ATM concept involves the traffic contract. When an ATM circuit is set up each switch on the circuit is informed of the traffic class of the connection.

ATM traffic contracts form part of the mechanism by which "quality of service" (QoS) is ensured. There are four basic types (and several variants) which each have a set of parameters describing the connection.


VBR has real-time and non-real-time variants, and serves for "bursty" traffic. Non-real-time is sometimes abbreviated to vbr-nrt.

Most traffic classes also introduce the concept of Cell-delay variation tolerance (CDVT), which defines the "clumping" of cells in time.

To maintain network performance, networks may apply traffic policing to virtual circuits to limit them to their traffic contracts at the entry points to the network, i.e. the user–network interfaces (UNIs) and network-to-network interfaces (NNIs): usage/network parameter control (UPC and NPC). The reference model given by the ITU-T and ATM Forum for UPC and NPC is the generic cell rate algorithm (GCRA), which is a version of the leaky bucket algorithm. CBR traffic will normally be policed to a PCR and CDVt alone, whereas VBR traffic will normally be policed using a dual leaky bucket controller to a PCR and CDVt and an SCR and Maximum Burst Size (MBS). The MBS will normally be the packet (SAR-SDU) size for the VBR VC in cells.

If the traffic on a virtual circuit is exceeding its traffic contract, as determined by the GCRA, the network can either drop the cells or mark the Cell Loss Priority (CLP) bit (to identify a cell as potentially redundant). Basic policing works on a cell by cell basis, but this is sub-optimal for encapsulated packet traffic (as discarding a single cell will invalidate the whole packet). As a result, schemes such as partial packet discard (PPD) and early packet discard (EPD) have been created that will discard a whole series of cells until the next packet starts. This reduces the number of useless cells in the network, saving bandwidth for full packets. EPD and PPD work with AAL5 connections as they use the end of packet marker: the ATM user-to-ATM user (AUU) indication bit in the payload-type field of the header, which is set in the last cell of a SAR-SDU.

Traffic shaping usually takes place in the network interface card (NIC) in user equipment, and attempts to ensure that the cell flow on a VC will meet its traffic contract, i.e. cells will not be dropped or reduced in priority at the UNI. Since the reference model given for traffic policing in the network is the GCRA, this algorithm is normally used for shaping as well, and single and dual leaky bucket implementations may be used as appropriate.

ATM can build virtual circuits and virtual paths either statically or dynamically. Static circuits (permanent virtual circuits or PVCs) or paths (permanent virtual paths or PVPs) require that the circuit is composed of a series of segments, one for each pair of interfaces through which it passes.

PVPs and PVCs, though conceptually simple, require significant effort in large networks. They also do not support the re-routing of service in the event of a failure. Dynamically built PVPs (soft PVPs or SPVPs) and PVCs (soft PVCs or SPVCs), in contrast, are built by specifying the characteristics of the circuit (the service "contract") and the two end points.

ATM networks create and remove switched virtual circuits (SVCs) on demand when requested by an end piece of equipment. One application for SVCs is to carry individual telephone calls when a network of telephone switches are inter-connected using ATM. SVCs were also used in attempts to replace local area networks with ATM.

Most ATM networks supporting SPVPs, SPVCs, and SVCs use the Private Network Node Interface or the Private Network-to-Network Interface (PNNI) protocol. PNNI uses the same shortest-path-first algorithm used by OSPF and IS-IS to route IP packets to share topology information between switches and select a route through a network. PNNI also includes a very powerful summarization mechanism to allow construction of very large networks, as well as a call admission control (CAC) algorithm which determines the availability of sufficient bandwidth on a proposed route through a network in order to satisfy the service requirements of a VC or VP.

A network must establish a connection before two parties can send cells to each other. In ATM this is called a virtual circuit (VC). It can be a permanent virtual circuit (PVC), which is created administratively on the end points, or a switched virtual circuit (SVC), which is created as needed by the communicating parties. SVC creation is managed by signaling, in which the requesting party indicates the address of the receiving party, the type of service requested, and whatever traffic parameters may be applicable to the selected service. "Call admission" is then performed by the network to confirm that the requested resources are available and that a route exists for the connection.

ATM specifies the following three layers:

ATM became popular with telephone companies and many computer makers in the 1990s. However, even by the end of the decade, the better price/performance of Internet Protocol-based products was competing with ATM technology for integrating real-time and bursty network traffic. Companies such as FORE Systems focused on ATM products, while other large vendors such as Cisco Systems provided ATM as an option. After the burst of the dot-com bubble, some still predicted that "ATM is going to dominate". However, in 2005 the ATM Forum, which had been the trade organization promoting the technology, merged with groups promoting other technologies, and eventually became the Broadband Forum.

Wireless ATM, or mobile ATM, consists of an ATM core network with a wireless access network. ATM cells are transmitted from base stations to mobile terminals. Mobility functions are performed at an ATM switch in the core network, known as "crossover switch", which is similar to the MSC (mobile switching center) of GSM networks. The advantage of wireless ATM is its high bandwidth and high speed handoffs done at layer 2. In the early 1990s, Bell Labs and NEC research labs worked actively in this field. Andy Hopper from Cambridge University Computer Laboratory also worked in this area. There was a wireless ATM forum formed to standardize the technology behind wireless ATM networks. The forum was supported by several telecommunication companies, including NEC, Fujitsu and AT&T. Mobile ATM aimed to provide high speed multimedia communications technology, capable of delivering broadband mobile communications beyond that of GSM and WLANs.





</doc>
<doc id="2500" url="https://en.wikipedia.org/wiki?curid=2500" title="Anus">
Anus

The anus (from Latin "anus" meaning "ring", "circle") is an opening at the opposite end of an animal's digestive tract from the mouth. Its function is to control the expulsion of feces, unwanted semi-solid matter produced during digestion, which, depending on the type of animal, may include: matter which the animal cannot digest, such as bones; food material after all the nutrients have been extracted, for example cellulose or lignin; ingested matter which would be toxic if it remained in the digestive tract; and dead or excess gut bacteria and other endosymbionts.

Amphibians, reptiles, and birds use the same orifice (known as the cloaca) for excreting liquid and solid wastes, for copulation and egg-laying. Monotreme mammals also have a cloaca, which is thought to be a feature inherited from the earliest amniotes via the therapsids. Marsupials have a single orifice for excreting both solids and liquids and, in females, a separate vagina for reproduction. Female placental mammals have completely separate orifices for defecation, urination, and reproduction; males have one opening for defecation and another for both urination and reproduction, although the channels flowing to that orifice are almost completely separate.

The development of the anus was an important stage in the evolution of multicellular animals. It appears to have happened at least twice, following different paths in protostomes and deuterostomes. This accompanied or facilitated other important evolutionary developments: the bilaterian body plan, the coelom, and metamerism, in which the body was built of repeated "modules" which could later specialize, such as the heads of most arthropods, which are composed of fused, specialized segments.

In animals at least as complex as an earthworm, the embryo forms a dent on one side, the blastopore, which deepens to become the archenteron, the first phase in the growth of the gut. In deuterostomes, the original dent becomes the anus while the gut eventually tunnels through to make another opening, which forms the mouth. The protostomes were so named because it was thought that in their embryos the dent formed the mouth first ("proto–" meaning "first") and the anus was formed later at the opening made by the other end of the gut. More recent research, however, shows that in protostomes the edges of the dent close up in the middle, leaving openings at the ends which become the mouth and anus.



</doc>
<doc id="2501" url="https://en.wikipedia.org/wiki?curid=2501" title="Appendix">
Appendix

Appendix may refer to:





</doc>
<doc id="2502" url="https://en.wikipedia.org/wiki?curid=2502" title="Acantharea">
Acantharea

The Acantharea (Acantharia) are a group of radiolarian protozoa, distinguished mainly by their strontium sulfate skeletons. 

Acantharian skeletons are composed of strontium sulfate crystals secreted by vacuoles surrounding each spicule or spine. Acantharians are the only marine organisms known to biomineralize strontium sulfate as the main component of their skeletons, making them quite unique. Unlike other radiolarians, whose skeletons are made of silica, acantharian skeletons do not fossilize, primarily because strontium sulfate is very scarce in seawater and the crystals dissolve after the acantharians die. The skeletons are made up of either ten diametric or twenty radial spicules. Diametric spicules cross the center of the cell, whereas radial spicules terminate at the center of the cell where they either form a tight or flexible junction depending on species. 

The cell is divided into two regions: the endoplasm and the ectoplasm. The endoplasm, at the core of the cell, contains the main organelles, including many nuclei, and is delineated from the ectoplasm by a capsular wall made of a microfibril mesh. In symbiotic species, the algal symbionts are maintained in the endoplasm. The ectoplasm consists of cytoplasmic extensions used for prey capture and also contains food vacuoles for prey digestion. The ectoplasm is surrounded by a periplasmic cortex, also made up of microfibrils, but arranged into twenty plates, each with a hole through which one spicule projects. The cortex is linked to the spines by contractile myonemes, which assist in buoyancy control by allowing the ectoplasm to expand and contract, increasing and decreasing the total volume of the cell. 

The arrangement of the spines is very precise, and is described by what is called the Müllerian law, which can be described in terms of lines of latitude and longitude – the spines lie on the intersections between five of the former, symmetric about an equator, and eight of the latter, spaced uniformly. Each line of longitude carries either two "tropical" spines or one "equatorial" and two "polar" spines, in alternation. The way that the spines are joined together at the center of the cell varies and is one of the primary characteristics by which acantharians are classified. Acantharians with diametric spicules or loosely attached radial spicules are able to rearrange or shed spicules and form cysts.


The morphological classification system roughly agrees with phylogenetic trees based on the alignment of ribosomal RNA genes, although the groups are mostly polyphyletic. Holacanthida seems to have evolved first and includes molecular clades A, B, and D. Chaunacanthida evolved second and includes only one molecular clade, clade C. Arthracanthida and Symphacanthida, which have the most complex skeletons, evolved most recently and constitute molecular clades E and F.

Many acantharians, including some in clade B (Holacanthida) and all in clades E & F (Symphiacanthida and Arthracanthida), host single-celled algae within their inner cytoplasm (endoplasm). By participating in this photosymbiosis, acantharians are essentially mixotrophs: they acquire energy through both heterotrophy and autotrophy. The relationship may make it possible for acantharians to be abundant in low-nutrient regions of the oceans and may also provide extra energy necessary to maintain their elaborate strontium sulfate skeletons. It is hypothesized that the acantharians provide the algae with nutrients (N & P) that they acquire by capturing and digesting prey in return for sugar that the algae produces during photosynthesis. It is not known, however, whether the algal symbionts benefit from the relationship or if they are simply being exploited and then digested by the acantharians. 

Symbiotic Holacanthida acantharians host diverse symbiont assemblages, including several genera of dinoflagellates ("Pelagodinium, Heterocapsa, Scrippsiella, Azadinium") and a haptophyte ("Chrysochromulina"). Clade E & F acantharians have a more specific symbiosis and primarily host symbionts from the haptophyte genus "Phaeocystis", although they sometimes also host "Chrysochromulina" symbionts. Clade F acantharians simultaneously host multiple species and strains of "Phaeocystis" and their internal symbiont community does not necessarily match the relative availability of potential symbionts in the surrounding environment. The mismatch between internal and external symbiont communities suggests that acantharians can be selective in choosing symbionts and probably do not continuously digest and recruit new symbionts, and maintain symbionts for extended periods of time instead.

Adults are usually multinucleated. Reproduction is thought to take place by formation of swarmer cells (formerly referred to as "spores"), which may be flagellate. Not all life cycle stages have been observed, and study of these organisms has been hampered mainly by an inability to maintain these organisms in culture through successive generations.


</doc>
<doc id="2503" url="https://en.wikipedia.org/wiki?curid=2503" title="African National Congress">
African National Congress

The African National Congress (ANC) is the Republic of South Africa's governing political party. It has been the ruling party of post-apartheid South Africa since the election of Nelson Mandela in the 1994 election, winning every election since then. Cyril Ramaphosa, the incumbent President of South Africa, has served as leader of the ANC since 18 December 2017.

Founded on 8 January 1912 by John Langalibalele Dube in Bloemfontein as the South African Native National Congress (SANNC), its primary mission was to bring all Africans together as one people, to defend their rights and freedoms. This included giving full voting rights to black South Africans and mixed-race South Africans and, from 1948 onwards, to end the system of apartheid introduced by the Nationalist Party government after their election (by White voters only) in that year. 

The ANC originally attempted to use non-violent protests to end apartheid; however, the Sharpeville massacre in March 1960, in which 69 black Africans were shot and killed by police and hundreds wounded during a peaceful protest, contributed to deteriorating relations with the South African government. On 8 April 1960, the administration of Charles Robberts Swart banned the ANC in South Africa. After the ban, the ANC formed the Umkhonto we Sizwe (Spear of the Nation) to fight against apartheid utilising guerrilla warfare and sabotage. 

After many years of struggle, during which many ANC members had been imprisoned or forced into exile, the country began its move towards full democracy. On 3 February 1990, State President F. W. de Klerk lifted the ban on the ANC and released Nelson Mandela from prison on 11 February 1990. On 17 March 1992, the apartheid referendum was passed by the voters, removing apartheid and allowing the ANC to run in the 1994 election, which for the first time allowed all South Africans to vote for their national government. Since the 1994 election the ANC has performed better than 55% in all general elections, including the most recent 2019 election. However the party has been embroiled in a number of controversies since 2011. 

The founding of the SANNC was in direct response to injustice against black South Africans at the hands of the government then in power. It can be said that the SANNC had its origins in a pronouncement by Pixley ka Isaka Seme who said in 1911, "Forget all the past differences among Africans and unite in one national organisation." The SANNC was founded the following year on 8 January 1912.

The government of the newly formed Union of South Africa began a systematic oppression of black people in South Africa. The Land Act was promulgated in 1913 forcing many black South Africans from their farms into the cities and towns to work, and to restrict their movement within South Africa.

By 1919, the SANNC was leading a campaign against passes (an ID which black South Africans had to possess). However, it then became dormant in the mid-1920s. During that time, black people were also represented by the ICU and the previously white-only Communist party. In 1923, the organisation became the African National Congress, and in 1929 the ANC supported a militant mineworkers' strike.

By 1927, J.T. Gumede (president of the ANC) proposed co-operation with the Communists in a bid to revitalise the organisation, but he was voted out of power in the 1930s. This led to the ANC becoming largely ineffectual and inactive, until the mid-1940s when the ANC was remodelled as a mass movement.

The ANC responded to attacks on the rights of black South Africans, as well as calling for strikes, boycotts, and defiance. This led to a later Defiance Campaign in the 1950s, a mass movement of resistance to apartheid. The government tried to stop the ANC by banning party leaders and enacting new laws to stop the ANC, however these measures ultimately proved to be ineffective.

In 1955, the Congress of the People officially adopted the Freedom Charter, stating the core principles of the South African Congress Alliance, which consisted of the African National Congress and its allies the South African Communist Party (SACP), the South African Indian Congress, the South African Congress of Democrats (COD) and the Coloured People's Congress. The government claimed that this was a communist document, and consequently leaders of the ANC and Congress were arrested. 1960 saw the Sharpeville massacre, in which 69 people were killed when police opened fire on anti-apartheid protesters.

uMkhonto we Sizwe or MK, translated "The Spear of the Nation", was the military wing of the ANC. Partly in response to the Sharpeville massacre of 1960, individual members of the ANC found it necessary to consider violence to combat what passive protests had failed to quell.

In co-operation with the South African Communist Party, MK was founded in 1961. MK commenced the military struggle against apartheid with acts of sabotage aimed at the installations of the state, and in the early stages was reluctant to target civilian targets. MK was responsible for the deaths of both civilians and members of the military. Acts committed by MK include the Church Street bombing, the Magoo's Bar bombing and bombing a branch of the Standard Bank in Roodepoort. It was integrated into the South African National Defence Force by 1994.

The ANC and its members were officially removed from the US terrorism watch list in 2008.

The ANC deems itself a force of national liberation in the post-apartheid era; it officially defines its agenda as the "National Democratic Revolution". The ANC is a member of the Socialist International. It also sets forth the redressing of socio-economic differences stemming from colonial- and apartheid-era policies as a central focus of ANC policy.

The National Democratic Revolution (NDR) is described as a process through which the National Democratic Society (NDS) is achieved; a society in which people are intellectually, socially, economically and politically empowered. The drivers of the NDR are also called the motive forces and are defined as the elements within society that gain from the success of the NDR. Using contour plots or concentric circles the centre represents the elements in society that gain the most out of the success of the NDR. Moving away from the centre results in the reduction of the gains that those elements derive. It is generally believed that the force that occupies the centre of those concentric circles in countries with low unemployment is the working class while in countries with higher levels of unemployment it is the unemployed. Some of the many theoreticians that have written about the NDR include Joe Slovo, Joel Netshitenzhe and Tshilidzi Marwala.

In 2004, the ANC declared itself to be a social democratic party.

The 53rd National Conference of the ANC, held in 2015, stated in its "Discussion Document" that "China economic development trajectory remains a leading example of the triumph of humanity over adversity. The exemplary role of the collective leadership of the Communist Party of China in this regard should be a guiding lodestar of our own struggle." It went on to state that "The collapse of the Berlin Wall and socialism in the Soviet Union and Eastern European States influenced our transition towards the negotiated political settlement in our country. The cause of events in the world changed tremendously in favour of the US led imperialism."

The ANC holds a historic alliance with the South African Communist Party (SACP) and Congress of South African Trade Unions (COSATU), known as the "Tripartite Alliance". The SACP and COSATU have not contested any election in South Africa, but field candidates through the ANC, hold senior positions in the ANC, and influence party policy and dialogue. During Mbeki's presidency, the government took a more pro-capitalist stance, often running counter to the demands of the SACP and COSATU.

Following Zuma's accession to the ANC leadership in 2007 and Mbeki's resignation as president in 2008, a number of former ANC leaders led by Mosiuoa Lekota split away from the ANC to form the Congress of the People.

On 20 December 2013, a special congress of the National Union of Metalworkers of South Africa (NUMSA), the country's biggest trade union with 338,000 members, voted to withdraw support from the ANC and SACP, and form a socialist party to protect the interests of the working class. NUMSA secretary general Irvin Jim condemned the ANC and SACP's support for big business and stated: "It is clear that the working class cannot any longer see the ANC or the SACP as its class allies in any meaningful sense."

The ANC flag comprises three equal horizontal stripes – black, green and gold. Black symbolises the native people of South Africa, green represents the land and gold represents the mineral and other natural wealth of South Africa.

This flag was also the battle flag of uMkhonto we Sizwe.

The Grand Duchy of Saxe-Weimar-Eisenach used an unrelated but identical flag from 1813 to 1897.
The black, green and gold tricolor was also used on the flag of the KwaZulu bantustan.

Although the colours of the new national Flag of South Africa since the transition from apartheid in 1994 have no official meaning, the three colours of the ANC flag were included in it, together with red, white and blue.

Politicians in the party win a place in parliament by being on the "Party List", which is drawn up before the elections and enumerates, in order, the party's preferred MPs. The number of seats allocated is proportional to the popular national vote, and this determines the cut-off point.

The ANC has also gained members through the controversial floor crossing process.

Although most South African parties announced their candidate list for provincial premierships in the 2009 election, the ANC did not, as it is not required for parties to do so.

In 2001, the ANC launched an online weekly web-based newsletter, "ANC Today – Online Voice of the African National Congress" to offset the alleged bias of the press. It consists mainly of updates on current programmes and initiatives of the ANC.

!Election
!Total votes
!Share of vote
!Seats
!Government
!1994
!1999
!2004
!2009
!2014
!2019

!Election
!Total # ofseats won
!1994
!1999
!2004
!2009
!2014
!2019

!rowspan=2|Election
!colspan=2|Eastern Cape
!colspan=2|Free State
!colspan=2|Gauteng
!colspan=2|Kwazulu-Natal
!colspan=2|Limpopo
!colspan=2|Mpumalanga
!colspan=2|North-West
!colspan=2|Northern Cape
!colspan=2|Western Cape
!%!!Seats
!%!!Seats
!%!!Seats
!%!!Seats
!%!!Seats
!%!!Seats
!%!!Seats
!%!!Seats
!%!!Seats
!1994
!1999
!2004
!2009
!2014
!2019

!Election
!Votes
!Change
!1995–96
!2000
!2006
!2011
!2016

The ANC represented the main opposition to the government during apartheid and therefore they played a major role in resolving the conflict through participating in the peacemaking and peace-building processes. Initially intelligence agents of the National Party met in secret with ANC leaders, including Nelson Mandela, to judge whether conflict resolution was possible. Discussions and negotiations took place leading to the eventual unbanning of the ANC and other opposing political parties by then President de Klerk on 2 February 1990.

The next official step towards rebuilding South Africa was the Groote Schuur Minute where the government and the ANC agreed on a common commitment towards the resolution of the existing climate of violence and intimidation, as well as a commitment to stability and to a peaceful process of negotiations. The ANC negotiated the release of political prisoners and the indemnity from prosecution for returning exiles and moreover channels of communication were established between the Government and the ANC.

Later the Pretoria Minute represented another step towards resolution where agreements at Groote Schuur were reconsolidated and steps towards setting up an interim government and drafting a new constitution were established as well as suspension of the military wing of the ANC – the Umkhonto we Sizwe. This step helped end much of the violence within South Africa. Another agreement that came out of the Pretoria Minute was that both parties would try and raise awareness that a new way of governance was being created for South Africa, and that further violence would only hinder this process. However, violence still continued in Kwazulu-Natal, which violated the trust between Mandela and de Klerk. Moreover, internal disputes in the ANC prolonged the war as consensus on peace was not reached.

The next significant steps towards resolution were the Repeal of the Population Registration Act, the repeal of the Group Areas and the Native Land Acts and a catch-all Abolition of Racially Based Land Measures Act was passed. These measures ensured no one could claim, or be deprived of, any land rights on the basis of race.

In December 1991 the Convention for a Democratic South Africa (CODESA) was held with the aim of establishing an interim government. However, a few months later in June 1992 the Boipatong massacre occurred and all negotiations crumbled as the ANC pulled out. After this negotiations proceeded between two agents, Cyril Ramaphosa of the ANC, and Roelf Meyer of the National Party. In over 40 sessions the two men discussed and negotiated over many issues including the nature of the future political system, the fate of over 40,000 government employees and if/how the country would be divided. The result of these negotiations was an interim constitution that meant the transition from apartheid to democracy was a constitutional continuation and that the rule of law and state sovereignty remained intact during the transition, which was vital for stability within the country. A date was set for the first democratic elections on 27 April 1994. The ANC won 62.5% of the votes and has been in power ever since.

The most prominent corruption case involving the ANC relates to a series of bribes paid to companies involved in the ongoing R55 billion Arms Deal saga, which resulted in a long term jail sentence to then Deputy President Jacob Zuma's legal adviser Schabir Shaik. Zuma, the former South African President, was charged with fraud, bribery and corruption in the Arms Deal, but the charges were subsequently withdrawn by the National Prosecuting Authority of South Africa due to their delay in prosecution. The ANC has also been criticised for its subsequent abolition of the Scorpions, the multidisciplinary agency that investigated and prosecuted organised crime and corruption, and was heavily involved in the investigation into Zuma and Shaik. Tony Yengeni, in his position as chief whip of the ANC and head of the Parliaments defence committee has recently been named as being involved in bribing the German company ThyssenKrupp over the purchase of four corvettes for the SANDF.

Other recent corruption issues include the sexual misconduct and criminal charges of Beaufort West municipal manager Truman Prince, and the Oilgate scandal, in which millions of Rand in funds from a state-owned company were funnelled into ANC coffers.

The ANC has also been accused of using government and civil society to fight its political battles against opposition parties such as the Democratic Alliance. The result has been a number of complaints and allegations that none of the political parties truly represent the interests of the poor. This has resulted in the "No Land! No House! No Vote!" Campaign which became very prominent during elections.
In 2018, the "New York Times" reported on the killings of ANC corruption whistleblowers.

In late 2011 the ANC was heavily criticised over the passage of the Protection of State Information Bill, which opponents claimed would improperly restrict the freedom of the press. Opposition to the bill included otherwise ANC-aligned groups such as COSATU. Notably, Nelson Mandela and other Nobel laureates Nadine Gordimer, Archbishop Desmond Tutu, and F. W. de Klerk have expressed disappointment with the bill for not meeting standards of constitutionality and aspirations for freedom of information and expression.

The ANC have been criticised for its role in failing to prevent 16 August 2012 massacre of Lonmin miners at Marikana in the North West. Some allege that Police Commissioner Riah Phiyega and Police Minister Nathi Mthethwa, a close confidant of Jacob Zuma, may have given the go ahead for the police action against the miners on that day.

Commissioner Phiyega of the ANC came under further criticism as being insensitive and uncaring when she was caught smiling and laughing during the Farlam Commission's video playback of the 'massacre'. Archbishop Desmond Tutu has announced that he no longer can bring himself to exercise a vote for the ANC as it is no longer the party that he and Nelson Mandela fought for, and that the party has now lost its way, and is in danger of becoming a corrupt entity in power.

The ANC has a growing list of constitutional failures. One of the most prominent relates to president of the ANC and of the Republic, Jacob Zuma, and his Nkandla homestead's security upgrades, valued at around R250 million. His swimming pool, for example, was termed a 'fire pool' and his amphitheatre an 'emergency meeting point', thus leaving the taxpayer to carry the costs. After the Public Protector released her report (Secure in Comfort) which found that Zuma must pay back the money spent on the non-security features, he refused to do so. In 2016 the Constitutional Court ruled that Zuma, as well as the National Assembly, had "breached the Constitution" and failed to uphold it. Zuma apologised to the nation as follows: “The matter has caused a lot of frustration and confusion for which I apologise on my behalf and on behalf of government.” However he claimed not to have asked nor known about the non-security upgrades, despite the media reporting on them almost daily.

There is also a growing trend for ANC members as well as those individuals appointed by the ANC to public positions of power to misrepresent their qualifications. The result of such lies typically lead to those appointed being unable to fulfill their obligations while being paid very large salaries, and typically cost the taxpayer large amount of money while attempting to defend themselves in court. A small selection follows:

Carl Niehaus, who served as ANC speaker, claimed to have a B.A., Masters and Doctorate degrees; in reality he never received the Masters or Doctoral degrees.

Pallo Jordan, who served as Minister of Arts and Culture claimed to be in possession of a PhD, when in reality he has no tertiary education at all.

Daniel Mtimkulu, who was employed as chief engineer at Passenger Rail Agency of South Africa (Prasa) claimed to have a PhD in engineering, which was a lie; he was merely qualified as an engineering technician. Under Mtimkulu's leadership, Prasa ordered 70 new locomotives, valued at R3.5 billion. The first 13 Afro 4000 diesel locomotives to arrive, at a cost of R600 million, were too tall to be of use on their intended routes.

Ellen Tshabalala, former chairperson of the South African Broadcasting Corporation (SABC), claimed to have a BComm degree. In reality her marks were so poor (13% for one module and 35% for another, amongst others) that she was not allowed to rewrite some of her exams. She later claimed that he degree certificate was stolen. Defending Tshabalala in court cost the SABC more than R1 million.

Hlaudi Motsoeneng, former COO of the SABC lied about being in possession of a Matric certificate. By his own admission, he simply invented marks for himself. He was appointed by Ellen Tshabalala, and his various court cases have cost the SABC more than R1.5 million. Further, under Motsoeneng's reign, the broadcaster recorded a net loss of R411 million in the 2015/16 financial year.

Dudu Myeni, chairperson of South African Airways (SAA) and good friend of Jacob Zuma, claimed to have a Bachelor's degree in administration. This was proven false. Under her leadership "SAA’s losses for the 2014/15 financial year were R5.6-billion – close to R1-billion more than the expected amount of R4.7-billion".

Sicelo Shiceka, Minister of Cooperative Governance and Traditional Affairs lied about being in possession of a Master's degree. He used taxpayer's money to fund a party for his mother and secured a government car for his girlfriend, whereafter he was appointed as a member of the inter-ministerial task team on corruption.

A 2016 statement issued by Zizi Kodwa, the ANC National Spokesperson states that "[t]he ANC rejects these [racist] comments with the contempt they deserve and calls on all South Africans to join in the rejection of all racists in our country, wherever they are. It is sad that well meaning South Africans have to contend with this backward attitude." In support of this statement, the ANC has publicly called for legal action to be taken against whites who have publicly made racist comments against blacks, usually through social media.

Penny Sparrow is one such high-profile case. She posted the following through her Facebook account:These monkeys that are allowed to be released on New Year’s eve and New Year’s day on to public beaches towns etc obviously have no education what so ever so to allow them loose is inviting huge dirt and troubles and discomfort to others. I’m sorry to say that I was among the revellers and all I saw were black on black skins what a shame. I do know some wonderful and thoughtful black people. This lot of monkeys just don’t want to even try. But think they can voice opinions about statute and get their way oh dear. From now I shall address the blacks of South Africa as monkeys as I see the cute little wild monkeys do the same, pick drop and litter.

Sparrow pleaded guilty to crimen injuria, and was presented with a choice of either paying a R5,000 fine or 12 months in jail, in addition to paying the legal fees incurred by the ANC, who brought the matter to court. In a separate instance, she was also ordered to pay R150,000 to the Oliver and Adelaide Tambo Trust.

In contrast to the ANC's swift and decisive action towards Sparrow and other white racists, they have mostly ignored racist comments voiced by blacks, in particular ANC members. For example, Kenny Barrel Nkosi, an ANC ward councillor (Govan Mbeki Municipality, Mpumalanga) posted the following on his Facebook account: "The first people that need to fokkof [fuck off] are whites, cubans never oppressed us. these are our true friends they were there in the times on needs. welcom cdes welcome [sic]" The municipality issued the following statement: “The matter has been investigated and at the time of the comment, the ward councillor was not representing the views of either the ANC or the Govan Mbeki Municipality, but merely as a personal opinion.” No further action was taken.

At a Gupta family wedding held at Sun City in 2013, various incidents of racism occurred. The family made clear that they wanted only white workers, including waiters, security, bar staff and cleaning staff. Black workers were told to wash before they interacted with guests. These allegations were denied by the Gupta family. Nonetheless, in the Gupta e-mail leak of 2017 these allegations were shown to be correct. Moreover, the e-mails also make clear that a black worker was called a monkey by a member of the Gupta family. That the Gupta family is a large, vocal and powerful supporter of the ANC and a personal friend of Jacob Zuma, may explain why no action was taken against them with regards to racism.

Lindiwe Sisulu, ANC member and Minister of Defence and Military Veterans (who demanded that the Estate Agency Affairs Board report to her regarding action taken against Sparrow) called the Democratic Alliance leader, Mmusi Maimane, a "hired native". Ironically – due to the fact that Chris Hart, prominent economist and investment strategist at Standard Bank, was forced to resign for his racist tweet stating that "[m]ore than 25 years after Apartheid ended, the victims are increasing along with a sense of entitlement and hatred towards minorities…." – Sisulu said the following, while discussing the 2.3 million housing backlog: "What makes an 18-year-old think the state owes them a house? It’s a culture of entitlement … we can’t continue with a dependency culture." No action has been taken against Sisulu.

Lulu Xingwana, former ANC Minister of Women, Children and People with Disabilities, stated that "[y]oung Afrikaner men are brought up in the Calvinist religion believing that they own a woman, they own a child, they own everything and therefore they can take that life because they own it". The minister apologised, and no further action was taken against her.

Jimmy Manyi, ANC director general of labour and later ANC spokesperson, is quotes as saying the following on a TV interview: “I think its very important for coloured people in this country to understand that South Africa belongs to them in totality, not just the Western Cape. So this over-concentration of coloureds in the Western Cape is not working for them. They should spread in the rest of the country ... so they must stop this over-concentration situation because they are in over-supply where they are so you must look into the country and see where you can meet the supply." No action has been taken against Manyi.

Julius Malema, former ANCYL leader and current EFF leader, stated at a political rally in 2016 that “We [the EFF] are not calling for the slaughter of white people‚ at least for now". When asked for comment by a news agency, the ANC spokesperson, Zizi Kodwa stated that there will be no comment from the ANC, as "[h]e [Malema] was addressing his own party supporters." While still the ANCYL leader, Malema was taken to the Equality Court by AfriForum for repeatedly singing “dubul’ ibhunu”, which translate as “shoot the boer [white farmer]”. The ANC supported Malema, though AfriForum and the ANC reached a settlement before the appeal case was due to be argued in the Supreme Court of Appeal.

In partial response to the Penny Sparrow case, Velaphi Khumalo, while working for the Department of Sport, Arts, Culture and Recreation, posted the following on his Facebook account:"I want to cleans this country of all white people. we must act as Hitler did to the Jews. I don't believe any more that the is a large number of not so racist whit people. I'm starting to be sceptical even of those within our Movement the ANC. I will from today unfriend all white people I have as friends from today u must be put under the same blanket as any other racist white because secretly u all are a bunch of racist fuck heads. as we have already seen 
[all sic]." He also posted:"Noo seriously though u oppressed us when u were a minority and then manje u call us monkeys and we supposed to let it slide . white people in south Africa deserve to be hacked and killed like Jews. U have the same venom moss . look at Palestine . noo u must be bushed alive and skinned and your off springs used as garden fertiliser [all sic]".

The Department of Sports, Arts, Culture and Recreation responded with a statement wherein it "views the hateful post by Velaphi Khumalo in a serious light. Our key mandate is nation-building and social cohesion. His sentiments take our country backwards and do not reflect what the Gauteng provincial government stands for.” Khumalo was suspended on full pay while an investigation was undertaken, was found to be guilty by an internal disciplinary procedure, and issued with a warning, whereafter he resumed his work at the department.

Esethu Hasane, Media and Communication Manager for the Department of Sport and Recreation tweeted the following during the severe droughts in the Western cape in 2017: "Only Western Cape still has dry dams. Please God, we have black people there, choose another way of punishing white people." Despite calls for his dismissal, no action was taken.




</doc>
<doc id="2504" url="https://en.wikipedia.org/wiki?curid=2504" title="Amphetamine">
Amphetamine

Amphetamine (contracted from alpha-methylphenethylamine) is a central nervous system (CNS) stimulant that is used in the treatment of attention deficit hyperactivity disorder (ADHD), narcolepsy, and obesity. Amphetamine was discovered in 1887 and exists as two enantiomers: levoamphetamine and dextroamphetamine. "Amphetamine" properly refers to a specific chemical, the racemic free base, which is equal parts of the two enantiomers, levoamphetamine and dextroamphetamine, in their pure amine forms. The term is frequently used informally to refer to any combination of the enantiomers, or to either of them alone. Historically, it has been used to treat nasal congestion and depression. Amphetamine is also used as an athletic performance enhancer and cognitive enhancer, and recreationally as an aphrodisiac and euphoriant. It is a prescription drug in many countries, and unauthorized possession and distribution of amphetamine are often tightly controlled due to the significant health risks associated with recreational use.

The first amphetamine pharmaceutical was Benzedrine, a brand which was used to treat a variety of conditions. Currently, pharmaceutical amphetamine is prescribed as racemic amphetamine, Adderall, dextroamphetamine, or the inactive prodrug lisdexamfetamine. Amphetamine increases monoamine and excitatory neurotransmission in the brain, with its most pronounced effects targeting the norepinephrine and dopamine neurotransmitter systems.

At therapeutic doses, amphetamine causes emotional and cognitive effects such as euphoria, change in desire for sex, increased wakefulness, and improved cognitive control. It induces physical effects such as improved reaction time, fatigue resistance, and increased muscle strength. Larger doses of amphetamine may impair cognitive function and induce rapid muscle breakdown. Addiction is a serious risk with heavy recreational amphetamine use, but is unlikely to occur from long-term medical use at therapeutic doses. Very high doses can result in psychosis (e.g., delusions and paranoia) which rarely occurs at therapeutic doses even during long-term use. Recreational doses are generally much larger than prescribed therapeutic doses and carry a far greater risk of serious side effects.

Amphetamine belongs to the phenethylamine class. It is also the parent compound of its own structural class, the substituted amphetamines, which includes prominent substances such as bupropion, cathinone, MDMA, and methamphetamine. As a member of the phenethylamine class, amphetamine is also chemically related to the naturally occurring trace amine neuromodulators, specifically phenethylamine and , both of which are produced within the human body. Phenethylamine is the parent compound of amphetamine, while is a positional isomer of amphetamine that differs only in the placement of the methyl group.

Long-term amphetamine exposure at sufficiently high doses in some animal species is known to produce abnormal dopamine system development or nerve damage, but, in humans with ADHD, pharmaceutical amphetamines appear to improve brain development and nerve growth. Reviews of magnetic resonance imaging (MRI) studies suggest that long-term treatment with amphetamine decreases abnormalities in brain structure and function found in subjects with ADHD, and improves function in several parts of the brain, such as the right caudate nucleus of the basal ganglia.

Reviews of clinical stimulant research have established the safety and effectiveness of long-term continuous amphetamine use for the treatment of ADHD. Randomized controlled trials of continuous stimulant therapy for the treatment of ADHD spanning 2 years have demonstrated treatment effectiveness and safety. Two reviews have indicated that long-term continuous stimulant therapy for ADHD is effective for reducing the core symptoms of ADHD (i.e., hyperactivity, inattention, and impulsivity), enhancing quality of life and academic achievement, and producing improvements in a large number of functional outcomes across 9 categories of outcomes related to academics, antisocial behavior, driving, non-medicinal drug use, obesity, occupation, self-esteem, service use (i.e., academic, occupational, health, financial, and legal services), and social function. One review highlighted a nine-month randomized controlled trial of amphetamine treatment for ADHD in children that found an average increase of 4.5 IQ points, continued increases in attention, and continued decreases in disruptive behaviors and hyperactivity. Another review indicated that, based upon the longest follow-up studies conducted to date, lifetime stimulant therapy that begins during childhood is continuously effective for controlling ADHD symptoms and reduces the risk of developing a substance use disorder as an adult.

Current models of ADHD suggest that it is associated with functional impairments in some of the brain's neurotransmitter systems; these functional impairments involve impaired dopamine neurotransmission in the mesocorticolimbic projection and norepinephrine neurotransmission in the noradrenergic projections from the locus coeruleus to the prefrontal cortex. Psychostimulants like methylphenidate and amphetamine are effective in treating ADHD because they increase neurotransmitter activity in these systems. Approximately 80% of those who use these stimulants see improvements in ADHD symptoms. Children with ADHD who use stimulant medications generally have better relationships with peers and family members, perform better in school, are less distractible and impulsive, and have longer attention spans. The Cochrane reviews on the treatment of ADHD in children, adolescents, and adults with pharmaceutical amphetamines stated that short-term studies have demonstrated that these drugs decrease the severity of symptoms, but they have higher discontinuation rates than non-stimulant medications due to their adverse side effects. A Cochrane review on the treatment of ADHD in children with tic disorders such as Tourette syndrome indicated that stimulants in general do not make tics worse, but high doses of dextroamphetamine could exacerbate tics in some individuals.

In 2015, a systematic review and a meta-analysis of high quality clinical trials found that, when used at low (therapeutic) doses, amphetamine produces modest yet unambiguous improvements in cognition, including working memory, long-term episodic memory, inhibitory control, and some aspects of attention, in normal healthy adults; these cognition-enhancing effects of amphetamine are known to be partially mediated through the indirect activation of both dopamine receptor D and adrenoceptor α in the prefrontal cortex. A systematic review from 2014 found that low doses of amphetamine also improve memory consolidation, in turn leading to improved recall of information. Therapeutic doses of amphetamine also enhance cortical network efficiency, an effect which mediates improvements in working memory in all individuals. Amphetamine and other ADHD stimulants also improve task saliency (motivation to perform a task) and increase arousal (wakefulness), in turn promoting goal-directed behavior. Stimulants such as amphetamine can improve performance on difficult and boring tasks and are used by some students as a study and test-taking aid. Based upon studies of self-reported illicit stimulant use, of college students use diverted ADHD stimulants, which are primarily used for enhancement of academic performance rather than as recreational drugs. However, high amphetamine doses that are above the therapeutic range can interfere with working memory and other aspects of cognitive control.

Amphetamine is used by some athletes for its psychological and athletic performance-enhancing effects, such as increased endurance and alertness; however, non-medical amphetamine use is prohibited at sporting events that are regulated by collegiate, national, and international anti-doping agencies. In healthy people at oral therapeutic doses, amphetamine has been shown to increase muscle strength, acceleration, athletic performance in anaerobic conditions, and endurance (i.e., it delays the onset of fatigue), while improving reaction time. Amphetamine improves endurance and reaction time primarily through reuptake inhibition and release of dopamine in the central nervous system. Amphetamine and other dopaminergic drugs also increase power output at fixed levels of perceived exertion by overriding a "safety switch", allowing the core temperature limit to increase in order to access a reserve capacity that is normally off-limits. At therapeutic doses, the adverse effects of amphetamine do not impede athletic performance; however, at much higher doses, amphetamine can induce effects that severely impair performance, such as rapid muscle breakdown and elevated body temperature.

According to the International Programme on Chemical Safety (IPCS) and United States Food and Drug Administration (USFDA), amphetamine is contraindicated in people with a history of drug abuse, cardiovascular disease, severe agitation, or severe anxiety. It is also contraindicated in people currently experiencing advanced arteriosclerosis (hardening of the arteries), glaucoma (increased eye pressure), hyperthyroidism (excessive production of thyroid hormone), or moderate to severe hypertension. These agencies indicate that people who have experienced allergic reactions to other stimulants or who are taking monoamine oxidase inhibitors (MAOIs) should not take amphetamine, although safe concurrent use of amphetamine and monoamine oxidase inhibitors has been documented. These agencies also state that anyone with anorexia nervosa, bipolar disorder, depression, hypertension, liver or kidney problems, mania, psychosis, Raynaud's phenomenon, seizures, thyroid problems, tics, or Tourette syndrome should monitor their symptoms while taking amphetamine. Evidence from human studies indicates that therapeutic amphetamine use does not cause developmental abnormalities in the fetus or newborns (i.e., it is not a human teratogen), but amphetamine abuse does pose risks to the fetus. Amphetamine has also been shown to pass into breast milk, so the IPCS and USFDA advise mothers to avoid breastfeeding when using it. Due to the potential for reversible growth impairments, the USFDA advises monitoring the height and weight of children and adolescents prescribed an amphetamine pharmaceutical.

At normal therapeutic doses, the physical side effects of amphetamine vary widely by age and from person to person. Cardiovascular side effects can include hypertension or hypotension from a vasovagal response, Raynaud's phenomenon (reduced blood flow to the hands and feet), and tachycardia (increased heart rate). Sexual side effects in males may include erectile dysfunction, frequent erections, or prolonged erections. Gastrointestinal side effects may include abdominal pain, constipation, diarrhea, and nausea. Other potential physical side effects include appetite loss, blurred vision, dry mouth, excessive grinding of the teeth, nosebleed, profuse sweating, rhinitis medicamentosa (drug-induced nasal congestion), reduced seizure threshold, tics (a type of movement disorder), and weight loss. Dangerous physical side effects are rare at typical pharmaceutical doses.

Amphetamine stimulates the medullary respiratory centers, producing faster and deeper breaths. In a normal person at therapeutic doses, this effect is usually not noticeable, but when respiration is already compromised, it may be evident. Amphetamine also induces contraction in the urinary bladder sphincter, the muscle which controls urination, which can result in difficulty urinating. This effect can be useful in treating bed wetting and loss of bladder control. The effects of amphetamine on the gastrointestinal tract are unpredictable. If intestinal activity is high, amphetamine may reduce gastrointestinal motility (the rate at which content moves through the digestive system); however, amphetamine may increase motility when the smooth muscle of the tract is relaxed. Amphetamine also has a slight analgesic effect and can enhance the pain relieving effects of opioids.

USFDA-commissioned studies from 2011 indicate that in children, young adults, and adults there is no association between serious adverse cardiovascular events (sudden death, heart attack, and stroke) and the medical use of amphetamine or other ADHD stimulants. However, amphetamine pharmaceuticals are contraindicated in individuals with cardiovascular disease.

At normal therapeutic doses, the most common psychological side effects of amphetamine include increased alertness, apprehension, concentration, initiative, self-confidence and sociability, mood swings (elated mood followed by mildly depressed mood), insomnia or wakefulness, and decreased sense of fatigue. Less common side effects include anxiety, change in libido, grandiosity, irritability, repetitive or obsessive behaviors, and restlessness; these effects depend on the user's personality and current mental state. Amphetamine psychosis (e.g., delusions and paranoia) can occur in heavy users. Although very rare, this psychosis can also occur at therapeutic doses during long-term therapy. According to the USFDA, "there is no systematic evidence" that stimulants produce aggressive behavior or hostility.

Amphetamine has also been shown to produce a conditioned place preference in humans taking therapeutic doses, meaning that individuals acquire a preference for spending time in places where they have previously used amphetamine.

Addiction is a serious risk with heavy recreational amphetamine use, but is unlikely to occur from long-term medical use at therapeutic doses; in fact, lifetime stimulant therapy for ADHD that begins during childhood reduces the risk of developing substance use disorders as an adult. Pathological overactivation of the mesolimbic pathway, a dopamine pathway that connects the ventral tegmental area to the nucleus accumbens, plays a central role in amphetamine addiction. Individuals who frequently self-administer high doses of amphetamine have a high risk of developing an amphetamine addiction, since chronic use at high doses gradually increase the level of accumbal ΔFosB, a "molecular switch" and "master control protein" for addiction. Once nucleus accumbens ΔFosB is sufficiently overexpressed, it begins to increase the severity of addictive behavior (i.e., compulsive drug-seeking) with further increases in its expression. While there are currently no effective drugs for treating amphetamine addiction, regularly engaging in sustained aerobic exercise appears to reduce the risk of developing such an addiction. Sustained aerobic exercise on a regular basis also appears to be an effective treatment for amphetamine addiction; exercise therapy improves clinical treatment outcomes and may be used as a combination therapy with cognitive behavioral therapy, which is currently the best clinical treatment available.

Chronic use of amphetamine at excessive doses causes alterations in gene expression in the mesocorticolimbic projection, which arise through transcriptional and epigenetic mechanisms. The most important transcription factors that produce these alterations are "Delta FBJ murine osteosarcoma viral oncogene homolog B" (ΔFosB), "cAMP response element binding protein" (CREB), and "nuclear factor-kappa B" (NF-κB). ΔFosB is the most significant biomolecular mechanism in addiction because ΔFosB overexpression (i.e., an abnormally high level of gene expression which produces a pronounced gene-related phenotype) in the D1-type medium spiny neurons in the nucleus accumbens is necessary and sufficient for many of the neural adaptations and regulates multiple behavioral effects (e.g., reward sensitization and escalating drug self-administration) involved in addiction. Once ΔFosB is sufficiently overexpressed, it induces an addictive state that becomes increasingly more severe with further increases in ΔFosB expression. It has been implicated in addictions to alcohol, cannabinoids, cocaine, methylphenidate, nicotine, opioids, phencyclidine, propofol, and substituted amphetamines, among others.

ΔJunD, a transcription factor, and G9a, a histone methyltransferase enzyme, both oppose the function of ΔFosB and inhibit increases in its expression. Sufficiently overexpressing ΔJunD in the nucleus accumbens with viral vectors can completely block many of the neural and behavioral alterations seen in chronic drug abuse (i.e., the alterations mediated by ΔFosB). ΔFosB also plays an important role in regulating behavioral responses to natural rewards, such as palatable food, sex, and exercise. Since both natural rewards and addictive drugs induce the expression of ΔFosB (i.e., they cause the brain to produce more of it), chronic acquisition of these rewards can result in a similar pathological state of addiction. Consequently, ΔFosB is the most significant factor involved in both amphetamine addiction and amphetamine-induced sexual addictions, which are compulsive sexual behaviors that result from excessive sexual activity and amphetamine use. These sexual addictions are associated with a dopamine dysregulation syndrome which occurs in some patients taking dopaminergic drugs.

The effects of amphetamine on gene regulation are both dose- and route-dependent. Most of the research on gene regulation and addiction is based upon animal studies with intravenous amphetamine administration at very high doses. The few studies that have used equivalent (weight-adjusted) human therapeutic doses and oral administration show that these changes, if they occur, are relatively minor. This suggests that medical use of amphetamine does not significantly affect gene regulation.

 there is no effective pharmacotherapy for amphetamine addiction. Reviews from 2015 and 2016 indicated that TAAR1-selective agonists have significant therapeutic potential as a treatment for psychostimulant addictions; however, the only compounds which are known to function as TAAR1-selective agonists are experimental drugs. Amphetamine addiction is largely mediated through increased activation of dopamine receptors and NMDA receptors in the nucleus accumbens; magnesium ions inhibit NMDA receptors by blocking the receptor calcium channel. One review suggested that, based upon animal testing, pathological (addiction-inducing) psychostimulant use significantly reduces the level of intracellular magnesium throughout the brain. Supplemental magnesium treatment has been shown to reduce amphetamine self-administration (i.e., doses given to oneself) in humans, but it is not an effective monotherapy for amphetamine addiction.

Cognitive behavioral therapy is currently the most effective clinical treatment for psychostimulant addictions. Additionally, research on the neurobiological effects of physical exercise suggests that daily aerobic exercise, especially endurance exercise (e.g., marathon running), prevents the development of drug addiction and is an effective adjunct therapy (i.e., a supplemental treatment) for amphetamine addiction. Exercise leads to better treatment outcomes when used as an adjunct treatment, particularly for psychostimulant addictions. In particular, aerobic exercise decreases psychostimulant self-administration, reduces the reinstatement (i.e., relapse) of drug-seeking, and induces increased dopamine receptor D (DRD2) density in the striatum. This is the opposite of pathological stimulant use, which induces decreased striatal DRD2 density. One review noted that exercise may also prevent the development of a drug addiction by altering ΔFosB or immunoreactivity in the striatum or other parts of the reward system.
Drug tolerance develops rapidly in amphetamine abuse (i.e., recreational amphetamine use), so periods of extended abuse require increasingly larger doses of the drug in order to achieve the same effect.
According to a Cochrane review on withdrawal in individuals who compulsively use amphetamine and methamphetamine, "when chronic heavy users abruptly discontinue amphetamine use, many report a time-limited withdrawal syndrome that occurs within 24 hours of their last dose." This review noted that withdrawal symptoms in chronic, high-dose users are frequent, occurring in roughly 88% of cases, and persist for  weeks with a marked "crash" phase occurring during the first week. Amphetamine withdrawal symptoms can include anxiety, drug craving, depressed mood, fatigue, increased appetite, increased movement or decreased movement, lack of motivation, sleeplessness or sleepiness, and lucid dreams. The review indicated that the severity of withdrawal symptoms is positively correlated with the age of the individual and the extent of their dependence. Mild withdrawal symptoms from the discontinuation of amphetamine treatment at therapeutic doses can be avoided by tapering the dose.

An amphetamine overdose can lead to many different symptoms, but is rarely fatal with appropriate care. The severity of overdose symptoms increases with dosage and decreases with drug tolerance to amphetamine. Tolerant individuals have been known to take as much as 5 grams of amphetamine in a day, which is roughly 100 times the maximum daily therapeutic dose. Symptoms of a moderate and extremely large overdose are listed below; fatal amphetamine poisoning usually also involves convulsions and coma. In 2013, overdose on amphetamine, methamphetamine, and other compounds implicated in an "" resulted in an estimated 3,788 deaths worldwide ( deaths, 95% confidence).

In rodents and primates, sufficiently high doses of amphetamine cause dopaminergic neurotoxicity, or damage to dopamine neurons, which is characterized by dopamine terminal degeneration and reduced transporter and receptor function. There is no evidence that amphetamine is directly neurotoxic in humans. However, large doses of amphetamine may indirectly cause dopaminergic neurotoxicity as a result of hyperpyrexia, the excessive formation of reactive oxygen species, and increased autoxidation of dopamine. Animal models of neurotoxicity from high-dose amphetamine exposure indicate that the occurrence of hyperpyrexia (i.e., core body temperature ≥ 40 °C) is necessary for the development of amphetamine-induced neurotoxicity. Prolonged elevations of brain temperature above 40 °C likely promote the development of amphetamine-induced neurotoxicity in laboratory animals by facilitating the production of reactive oxygen species, disrupting cellular protein function, and transiently increasing blood–brain barrier permeability.

An amphetamine overdose can result in a stimulant psychosis that may involve a variety of symptoms, such as delusions and paranoia. A Cochrane review on treatment for amphetamine, dextroamphetamine, and methamphetamine psychosis states that about of users fail to recover completely. According to the same review, there is at least one trial that shows antipsychotic medications effectively resolve the symptoms of acute amphetamine psychosis. Psychosis rarely arises from therapeutic use.

Many types of substances are known to interact with amphetamine, resulting in altered drug action or metabolism of amphetamine, the interacting substance, or both. Inhibitors of enzymes that metabolize amphetamine (e.g., CYP2D6 and FMO3) will prolong its elimination half-life, meaning that its effects will last longer. Amphetamine also interacts with , particularly monoamine oxidase A inhibitors, since both MAOIs and amphetamine increase plasma catecholamines (i.e., norepinephrine and dopamine); therefore, concurrent use of both is dangerous. Amphetamine modulates the activity of most psychoactive drugs. In particular, amphetamine may decrease the effects of sedatives and depressants and increase the effects of stimulants and antidepressants. Amphetamine may also decrease the effects of antihypertensives and antipsychotics due to its effects on blood pressure and dopamine respectively. Zinc supplementation may reduce the minimum effective dose of amphetamine when it is used for the treatment of ADHD.

In general, there is no significant interaction when consuming amphetamine with food, but the pH of gastrointestinal content and urine affects the absorption and excretion of amphetamine, respectively. Acidic substances reduce the absorption of amphetamine and increase urinary excretion, and alkaline substances do the opposite. Due to the effect pH has on absorption, amphetamine also interacts with gastric acid reducers such as proton pump inhibitors and H antihistamines, which increase gastrointestinal pH (i.e., make it less acidic).

Amphetamine exerts its behavioral effects by altering the use of monoamines as neuronal signals in the brain, primarily in catecholamine neurons in the reward and executive function pathways of the brain. The concentrations of the main neurotransmitters involved in reward circuitry and executive functioning, dopamine and norepinephrine, increase dramatically in a dose-dependent manner by amphetamine due to its effects on monoamine transporters. The reinforcing and motivational salience-promoting effects of amphetamine are mostly due to enhanced dopaminergic activity in the mesolimbic pathway. The euphoric and locomotor-stimulating effects of amphetamine are dependent upon the magnitude and speed by which it increases synaptic dopamine and norepinephrine concentrations in the striatum.

Amphetamine has been identified as a potent full agonist of trace amine-associated receptor 1 (TAAR1), a and G protein-coupled receptor (GPCR) discovered in 2001, which is important for regulation of brain monoamines. Activation of increases production via adenylyl cyclase activation and inhibits monoamine transporter function. Monoamine autoreceptors (e.g., D short, presynaptic α, and presynaptic 5-HT) have the opposite effect of TAAR1, and together these receptors provide a regulatory system for monoamines. Notably, amphetamine and trace amines possess high binding affinities for TAAR1, but not for monoamine autoreceptors. Imaging studies indicate that monoamine reuptake inhibition by amphetamine and trace amines is site specific and depends upon the presence of TAAR1 in the associated monoamine neurons. of TAAR1 and the dopamine transporter (DAT) has been visualized in rhesus monkeys, but of TAAR1 with the norepinephrine transporter (NET) and the serotonin transporter (SERT) has only been evidenced by messenger RNA (mRNA) expression.

In addition to the neuronal monoamine transporters, amphetamine also inhibits both vesicular monoamine transporters, VMAT1 and VMAT2, as well as SLC1A1, SLC22A3, and SLC22A5. SLC1A1 is excitatory amino acid transporter 3 (EAAT3), a glutamate transporter located in neurons, SLC22A3 is an extraneuronal monoamine transporter that is present in astrocytes, and SLC22A5 is a high-affinity carnitine transporter. Amphetamine is known to strongly induce cocaine- and amphetamine-regulated transcript (CART) gene expression, a neuropeptide involved in feeding behavior, stress, and reward, which induces observable increases in neuronal development and survival "in vitro". The CART receptor has yet to be identified, but there is significant evidence that CART binds to a unique . Amphetamine also inhibits monoamine oxidases at very high doses, resulting in less monoamine and trace amine metabolism and consequently higher concentrations of synaptic monoamines. In humans, the only post-synaptic receptor at which amphetamine is known to bind is the receptor, where it acts as an agonist with micromolar affinity.

The full profile of amphetamine's short-term drug effects in humans is mostly derived through increased cellular communication or neurotransmission of dopamine, serotonin, norepinephrine, epinephrine, histamine, CART peptides, endogenous opioids, adrenocorticotropic hormone, corticosteroids, and glutamate, which it effects through interactions with , , , , , , and possibly other biological targets.

Dextroamphetamine is a more potent agonist of than levoamphetamine. Consequently, dextroamphetamine produces greater stimulation than levoamphetamine, roughly three to four times more, but levoamphetamine has slightly stronger cardiovascular and peripheral effects.

In certain brain regions, amphetamine increases the concentration of dopamine in the synaptic cleft. Amphetamine can enter the presynaptic neuron either through or by diffusing across the neuronal membrane directly. As a consequence of DAT uptake, amphetamine produces competitive reuptake inhibition at the transporter. Upon entering the presynaptic neuron, amphetamine activates which, through protein kinase A (PKA) and protein kinase C (PKC) signaling, causes DAT phosphorylation. Phosphorylation by either protein kinase can result in DAT internalization ( reuptake inhibition), but phosphorylation alone induces the reversal of dopamine transport through DAT (i.e., dopamine efflux). Amphetamine is also known to increase intracellular calcium, an effect which is associated with DAT phosphorylation through an unidentified Ca2+/calmodulin-dependent protein kinase (CAMK)-dependent pathway, in turn producing dopamine efflux. Through direct activation of G protein-coupled inwardly-rectifying potassium channels, reduces the firing rate of dopamine neurons, preventing a hyper-dopaminergic state.

Amphetamine is also a substrate for the presynaptic vesicular monoamine transporter, . Following amphetamine uptake at VMAT2, amphetamine induces the collapse of the vesicular pH gradient, which results in the release of dopamine molecules from synaptic vesicles into the cytosol via dopamine efflux through VMAT2. Subsequently, the cytosolic dopamine molecules are released from the presynaptic neuron into the synaptic cleft via reverse transport at .

Similar to dopamine, amphetamine dose-dependently increases the level of synaptic norepinephrine, the direct precursor of epinephrine. Based upon neuronal expression, amphetamine is thought to affect norepinephrine analogously to dopamine. In other words, amphetamine induces TAAR1-mediated efflux and reuptake inhibition at phosphorylated , competitive NET reuptake inhibition, and norepinephrine release from .

Amphetamine exerts analogous, yet less pronounced, effects on serotonin as on dopamine and norepinephrine. Amphetamine affects serotonin via and, like norepinephrine, is thought to phosphorylate via . Like dopamine, amphetamine has low, micromolar affinity at the human 5-HT1A receptor.

Acute amphetamine administration in humans increases endogenous opioid release in several brain structures in the reward system. Extracellular levels of glutamate, the primary excitatory neurotransmitter in the brain, have been shown to increase in the striatum following exposure to amphetamine. This increase in extracellular glutamate presumably occurs via the amphetamine-induced internalization of EAAT3, a glutamate reuptake transporter, in dopamine neurons. Amphetamine also induces the selective release of histamine from mast cells and efflux from histaminergic neurons through . Acute amphetamine administration can also increase adrenocorticotropic hormone and corticosteroid levels in blood plasma by stimulating the hypothalamic–pituitary–adrenal axis.

The oral bioavailability of amphetamine varies with gastrointestinal pH; it is well absorbed from the gut, and bioavailability is typically over 75% for dextroamphetamine. Amphetamine is a weak base with a p"K" of 9.9; consequently, when the pH is basic, more of the drug is in its lipid soluble free base form, and more is absorbed through the lipid-rich cell membranes of the gut epithelium. Conversely, an acidic pH means the drug is predominantly in a water-soluble cationic (salt) form, and less is absorbed. Approximately of amphetamine circulating in the bloodstream is bound to plasma proteins. Following absorption, amphetamine readily distributes into most tissues in the body, with high concentrations occurring in cerebrospinal fluid and brain tissue.

The half-lives of amphetamine enantiomers differ and vary with urine pH. At normal urine pH, the half-lives of dextroamphetamine and levoamphetamine are  hours and  hours, respectively. Highly acidic urine will reduce the enantiomer half-lives to 7 hours; highly alkaline urine will increase the half-lives up to 34 hours. The immediate-release and extended release variants of salts of both isomers reach peak plasma concentrations at 3 hours and 7 hours post-dose respectively. Amphetamine is eliminated via the kidneys, with of the drug being excreted unchanged at normal urinary pH. When the urinary pH is basic, amphetamine is in its free base form, so less is excreted. When urine pH is abnormal, the urinary recovery of amphetamine may range from a low of 1% to a high of 75%, depending mostly upon whether urine is too basic or acidic, respectively. Following oral administration, amphetamine appears in urine within 3 hours. Roughly 90% of ingested amphetamine is eliminated 3 days after the last oral dose.

CYP2D6, dopamine β-hydroxylase (DBH), flavin-containing monooxygenase 3 (FMO3), butyrate-CoA ligase (XM-ligase), and glycine "N"-acyltransferase (GLYAT) are the enzymes known to metabolize amphetamine or its metabolites in humans. Amphetamine has a variety of excreted metabolic products, including , , , benzoic acid, hippuric acid, norephedrine, and phenylacetone. Among these metabolites, the active sympathomimetics are , , and norephedrine. The main metabolic pathways involve aromatic para-hydroxylation, aliphatic alpha- and beta-hydroxylation, "N"-oxidation, "N"-dealkylation, and deamination. The known metabolic pathways, detectable metabolites, and metabolizing enzymes in humans include the following:

Amphetamine has a very similar structure and function to the endogenous trace amines, which are naturally occurring neuromodulator molecules produced in the human body and brain. Among this group, the most closely related compounds are phenethylamine, the parent compound of amphetamine, and , an isomer of amphetamine (i.e., it has an identical molecular formula). In humans, phenethylamine is produced directly from by the aromatic amino acid decarboxylase (AADC) enzyme, which converts into dopamine as well. In turn, is metabolized from phenethylamine by phenylethanolamine "N"-methyltransferase, the same enzyme that metabolizes norepinephrine into epinephrine. Like amphetamine, both phenethylamine and regulate monoamine neurotransmission via ; unlike amphetamine, both of these substances are broken down by monoamine oxidase B, and therefore have a shorter half-life than amphetamine.

Amphetamine is a methyl homolog of the mammalian neurotransmitter phenethylamine with the chemical formula . The carbon atom adjacent to the primary amine is a stereogenic center, and amphetamine is composed of a racemic 1:1 mixture of two enantiomers. This racemic mixture can be separated into its optical isomers: levoamphetamine and dextroamphetamine. At room temperature, the pure free base of amphetamine is a mobile, colorless, and volatile liquid with a characteristically strong amine odor, and acrid, burning taste. Frequently prepared solid salts of amphetamine include amphetamine aspartate, hydrochloride, phosphate, saccharate, and sulfate, the last of which is the most common amphetamine salt. Amphetamine is also the parent compound of its own structural class, which includes a number of psychoactive derivatives. In organic chemistry, amphetamine is an excellent chiral ligand for the stereoselective synthesis of .

The substituted derivatives of amphetamine, or "substituted amphetamines", are a broad range of chemicals that contain amphetamine as a "backbone"; specifically, this chemical class includes derivative compounds that are formed by replacing one or more hydrogen atoms in the amphetamine core structure with substituents. The class includes amphetamine itself, stimulants like methamphetamine, serotonergic empathogens like MDMA, and decongestants like ephedrine, among other subgroups.

Since the first preparation was reported in 1887, numerous synthetic routes to amphetamine have been developed. The most common route of both legal and illicit amphetamine synthesis employs a non-metal reduction known as the Leuckart reaction (method 1). In the first step, a reaction between phenylacetone and formamide, either using additional formic acid or formamide itself as a reducing agent, yields . This intermediate is then hydrolyzed using hydrochloric acid, and subsequently basified, extracted with organic solvent, concentrated, and distilled to yield the free base. The free base is then dissolved in an organic solvent, sulfuric acid added, and amphetamine precipitates out as the sulfate salt.

A number of chiral resolutions have been developed to separate the two enantiomers of amphetamine. For example, racemic amphetamine can be treated with to form a diastereoisomeric salt which is fractionally crystallized to yield dextroamphetamine. Chiral resolution remains the most economical method for obtaining optically pure amphetamine on a large scale. In addition, several enantioselective syntheses of amphetamine have been developed. In one example, optically pure is condensed with phenylacetone to yield a chiral Schiff base. In the key step, this intermediate is reduced by catalytic hydrogenation with a transfer of chirality to the carbon atom alpha to the amino group. Cleavage of the benzylic amine bond by hydrogenation yields optically pure dextroamphetamine.

A large number of alternative synthetic routes to amphetamine have been developed based on classic organic reactions. One example is the Friedel–Crafts alkylation of benzene by allyl chloride to yield beta chloropropylbenzene which is then reacted with ammonia to produce racemic amphetamine (method 2). Another example employs the Ritter reaction (method 3). In this route, allylbenzene is reacted acetonitrile in sulfuric acid to yield an organosulfate which in turn is treated with sodium hydroxide to give amphetamine via an acetamide intermediate. A third route starts with which through a double alkylation with methyl iodide followed by benzyl chloride can be converted into acid. This synthetic intermediate can be transformed into amphetamine using either a Hofmann or Curtius rearrangement (method 4).

A significant number of amphetamine syntheses feature a reduction of a nitro, imine, oxime, or other nitrogen-containing functional groups. In one such example, a Knoevenagel condensation of benzaldehyde with nitroethane yields . The double bond and nitro group of this intermediate is reduced using either catalytic hydrogenation or by treatment with lithium aluminium hydride (method 5). Another method is the reaction of phenylacetone with ammonia, producing an imine intermediate that is reduced to the primary amine using hydrogen over a palladium catalyst or lithium aluminum hydride (method 6).

Amphetamine is frequently measured in urine or blood as part of a drug test for sports, employment, poisoning diagnostics, and forensics. Techniques such as immunoassay, which is the most common form of amphetamine test, may cross-react with a number of sympathomimetic drugs. Chromatographic methods specific for amphetamine are employed to prevent false positive results. Chiral separation techniques may be employed to help distinguish the source of the drug, whether prescription amphetamine, prescription amphetamine prodrugs, (e.g., selegiline), over-the-counter drug products that contain levomethamphetamine, or illicitly obtained substituted amphetamines. Several prescription drugs produce amphetamine as a metabolite, including benzphetamine, clobenzorex, famprofazone, fenproporex, lisdexamfetamine, mesocarb, methamphetamine, prenylamine, and selegiline, among others. These compounds may produce positive results for amphetamine on drug tests. Amphetamine is generally only detectable by a standard drug test for approximately 24 hours, although a high dose may be detectable for  days.

For the assays, a study noted that an enzyme multiplied immunoassay technique (EMIT) assay for amphetamine and methamphetamine may produce more false positives than liquid chromatography–tandem mass spectrometry. Gas chromatography–mass spectrometry (GC–MS) of amphetamine and methamphetamine with the derivatizing agent chloride allows for the detection of methamphetamine in urine. GC–MS of amphetamine and methamphetamine with the chiral derivatizing agent Mosher's acid chloride allows for the detection of both dextroamphetamine and dextromethamphetamine in urine. Hence, the latter method may be used on samples that test positive using other methods to help distinguish between the various sources of the drug.

Amphetamine was first synthesized in 1887 in Germany by Romanian chemist Lazăr Edeleanu who named it "phenylisopropylamine"; its stimulant effects remained unknown until 1927, when it was independently resynthesized by Gordon Alles and reported to have sympathomimetic properties. Amphetamine had no medical use until late 1933, when Smith, Kline and French began selling it as an inhaler under the brand name Benzedrine as a decongestant. Benzedrine sulfate was introduced 3 years later and was used to treat a wide variety of medical conditions, including narcolepsy, obesity, low blood pressure, low libido, and chronic pain, among others. During World War II, amphetamine and methamphetamine were used extensively by both the Allied and Axis forces for their stimulant and performance-enhancing effects. As the addictive properties of the drug became known, governments began to place strict controls on the sale of amphetamine. For example, during the early 1970s in the United States, amphetamine became a schedule II controlled substance under the Controlled Substances Act. In spite of strict government controls, amphetamine has been used legally or illicitly by people from a variety of backgrounds, including authors, musicians, mathematicians, and athletes.

Amphetamine is still illegally synthesized today in clandestine labs and sold on the black market, primarily in European countries. Among European Union (EU) member states 11.9 million adults of ages have used amphetamine or methamphetamine at least once in their lives and 1.7 million have used either in the last year. During 2012, approximately 5.9 metric tons of illicit amphetamine were seized within EU member states; the "street price" of illicit amphetamine within the EU ranged from  per gram during the same period. Outside Europe, the illicit market for amphetamine is much smaller than the market for methamphetamine and MDMA.

As a result of the United Nations 1971 Convention on Psychotropic Substances, amphetamine became a schedule II controlled substance, as defined in the treaty, in all 183 state parties. Consequently, it is heavily regulated in most countries. Some countries, such as South Korea and Japan, have banned substituted amphetamines even for medical use. In other nations, such as Canada (schedule I drug), the Netherlands (List I drug), the United States (schedule II drug), Australia (schedule 8), Thailand (category 1 narcotic), and United Kingdom (class B drug), amphetamine is in a restrictive national drug schedule that allows for its use as a medical treatment.

Several currently prescribed amphetamine formulations contain both enantiomers, including Adderall, Adderall XR, Mydayis, , Dyanavel XR, and Evekeo, the last of which contains racemic amphetamine sulfate. Amphetamine is also prescribed in enantiopure and prodrug form as dextroamphetamine and lisdexamfetamine respectively. Lisdexamfetamine is structurally different from amphetamine, and is inactive until it metabolizes into dextroamphetamine. The free base of racemic amphetamine was previously available as Benzedrine, Psychedrine, and Sympatedrine. Levoamphetamine was previously available as Cydril. Many current amphetamine pharmaceuticals are salts due to the comparatively high volatility of the free base. However, oral suspension and orally disintegrating tablet (ODT) dosage forms composed of the free base were introduced in 2015 and 2016, respectively. Some of the current brands and their generic equivalents are listed below.



</doc>
<doc id="2506" url="https://en.wikipedia.org/wiki?curid=2506" title="Asynchronous communication">
Asynchronous communication

In telecommunications, asynchronous communication is transmission of data, generally without the use of an external clock signal, where data can be transmitted intermittently rather than in a steady stream. Any timing required to recover data from the communication symbols is encoded within the symbols.

The most significant aspect of asynchronous communications is that data is not transmitted at regular intervals, thus making possible variable bit rate, and that the transmitter and receiver clock generators do not have to be exactly synchronized all the time. In asynchronous transmission, data is sent one byte at a time and each byte is preceded by start bit and stop bit.

In asynchronous serial communication the physical protocol layer, the data blocks are code words of a certain word length, for example octets (bytes) or ASCII characters, delimited by start bits and stop bits. A variable length space can be inserted between the code words. No bit synchronization signal is required. This is sometimes called character oriented communication. Examples are the RS-232C serial standard, and MNP2 and V.2 modems and older.

Asynchronous communication at the data link layer or higher protocol layers is known as statistical multiplexing, for example asynchronous transfer mode (ATM). In this case the asynchronously transferred blocks are called data packets, for example ATM cells. The opposite is circuit switched communication, which provides constant bit rate, for example ISDN and SONET/SDH.

The packets may be encapsulated in a data frame, with a frame synchronization bit sequence indicating the start of the frame, and sometimes also a bit synchronization bit sequence, typically 01010101, for identification of the bit transition times. Note that at the physical layer, this is considered as synchronous serial communication. Examples of packet mode data link protocols that can be/are transferred using synchronous serial communication are the HDLC, Ethernet, PPP and USB protocols.

An asynchronous communication service or application does not require a constant bit rate. Examples are file transfer, email and the World Wide Web. An example of the opposite, a synchronous communication service, is realtime streaming media, for example IP telephony, IP-TV and video conferencing.

Electronically mediated communication often happens asynchronously in that the participants do not communicate concurrently. Examples include email
and bulletin-board systems, where participants send or post messages at different times. The term "asynchronous communication" acquired currency in the field of online learning, where teachers and students often exchange information asynchronously instead of synchronously (that is, simultaneously), as they would in face-to-face or in telephone conversations.



</doc>
<doc id="2508" url="https://en.wikipedia.org/wiki?curid=2508" title="Artillery">
Artillery

Artillery is a class of heavy military ranged weapons built to launch munitions far beyond the range and power of infantry's small arms. Early artillery development focused on the ability to breach defensive walls and fortifications during sieges, and led to heavy, fairly immobile siege engines. As technology improved, lighter, more mobile field artillery cannons developed for battlefield use. This development continues today; modern self-propelled artillery vehicles are highly mobile weapons of great versatility providing the large share of an army's total firepower.

In its earliest sense, the word artillery referred to any group of soldiers primarily armed with some form of manufactured weapon or armour. Since the introduction of gunpowder and cannon, the word "artillery" has largely meant cannon, and in contemporary usage, it usually refers to shell-firing guns, howitzers, mortars, and rocket artillery. In common speech, the word artillery is often used to refer to individual devices, along with their accessories and fittings, although these assemblages are more properly called "equipments". However, there is no generally recognised generic term for a gun, howitzer, mortar, and so forth: the United States uses "artillery piece", but most English-speaking armies use "gun" and "mortar". The projectiles fired are typically either "shot" (if solid) or "shell" (if not). "Shell" is a widely used generic term for a projectile, which is a component of munitions.

By association, artillery may also refer to the arm of service that customarily operates such engines. In some armies one arm has operated field, coastal, anti-aircraft artillery and anti-tank artillery, in others these have been separate arms and in some nations coastal has been a naval or marine responsibility. In the 20th century technology based target acquisition devices, such as radar, and systems, such as sound ranging and flash spotting, emerged to acquire targets, primarily for artillery. These are usually operated by one or more of the artillery arms. The widespread adoption of indirect fire in the early 20th century introduced the need for specialist data for field artillery, notably survey and meteorological, in some armies provision of these are the responsibility of the artillery arm.

Artillery originated for use against ground targets—against infantry, cavalry and other artillery. An early specialist development was coastal artillery for use against enemy ships. The early 20th century saw the development of a new class of artillery for use against aircraft: anti-aircraft guns.

Artillery is arguably the most lethal form of land-based armament currently employed, and has been since at least the early Industrial Revolution. The majority of combat deaths in the Napoleonic Wars, World War I, and World War II were caused by artillery. In 1944, Joseph Stalin said in a speech that artillery was "the God of War".

Although not called as such, machines performing the role recognizable as artillery have been employed in warfare since antiquity. Historical references show artillery was first employed by the Roman legions at Syracuse in 399 BC. Until the introduction of gunpowder into western warfare, artillery was dependent upon mechanical energy which not only severely limited the kinetic energy of the projectiles, it also required the construction of very large engines to store sufficient energy. A 1st-century BC Roman catapult launching stones achieved a kinetic energy of 16,000 joules, compared to a mid-19th-century 12-pounder gun, which fired a round, with a kinetic energy of 240,000 joules, or a 20th century US battleship that fired a projectile from its main battery with an energy level surpassing 350,000,000 joules.

From the Middle Ages through most of the modern era, artillery pieces on land were moved by horse-drawn gun carriages. In the contemporary era, artillery pieces and their crew relied on wheeled or tracked vehicles as transportation. These land versions of artillery were dwarfed by railway guns, which includes the largest super-gun ever conceived, theoretically capable of putting a satellite into orbit. Artillery used by naval forces has also changed significantly, with missiles replacing guns in surface warfare.

Over the course of military history, projectiles were manufactured from a wide variety of materials, into a wide variety of shapes, using many different methods in which to target structural/defensive works and inflict enemy casualties. The engineering applications for ordnance delivery have likewise changed significantly over time, encompassing some of the most complex and advanced technologies in use today.

In some armies, the weapon of artillery is the projectile, not the equipment that fires it. The process of delivering fire onto the target is called gunnery. The actions involved in operating an artillery piece are collectively called "serving the gun" by the "detachment" or gun crew, constituting either direct or indirect artillery fire. The manner in which gunnery crews (or formations) are employed is called artillery support. At different periods in history this may refer to weapons designed to be fired from ground-, sea-, and even air-based weapons platforms.

The term "gunner" is used in some armed forces for the soldiers and sailors with the primary function of using artillery.

The gunners and their guns are usually grouped in teams called either "crews" or "detachments". Several such crews and teams with other functions are combined into a unit of artillery, usually called a battery, although sometimes called a company. In gun detachments, each role is numbered, starting with "1" the Detachment Commander, and the highest number being the Coverer, the second-in-command. "Gunner" is also the lowest rank and junior non-commissioned officers are "Bombardiers" in some artillery arms.

Batteries are roughly equivalent to a company in the infantry and are combined into larger military organizations for administrative and operational purposes, either battalions or regiments, depending on the army. These may be grouped into brigades; the Russian army also groups some brigades into artillery divisions, and the People's Liberation Army has artillery corps.

The term "artillery" is also applied to a combat arm of most military services when used organizationally to describe units and formations of the national armed forces that operate the weapons.

During military operations, the role of field artillery is to provide support to other arms in combat or to attack targets, particularly in depth. Broadly, these effects fall into two categories, either to suppress or neutralize the enemy, or to cause casualties, damage, and destruction. This is mostly achieved by delivering high-explosive munitions to suppress, or inflict casualties on the enemy from casing fragments and other debris and blast, or by destroying enemy positions, equipment, and vehicles. Non-lethal munitions, notably smoke, can also be used to suppress or neutralize the enemy by obscuring their view.

Fire may be directed by an artillery observer or other observer, including manned and unmanned aircraft pilots, or called onto map coordinates.

Military doctrine has played a significant influence on the core engineering design considerations of artillery ordnance through its history, in seeking to achieve a balance between delivered volume of fire with ordnance mobility. However, during the modern period, the consideration of protecting the gunners also arose due to the late-19th-century introduction of the new generation of infantry weapons using conoidal bullet, better known as the Minié ball, with a range almost as long as that of field artillery.

The gunners' increasing proximity to and participation in direct combat against other combat arms and attacks by aircraft made the introduction of a gun shield necessary. The problems of how to employ a fixed or horse-towed gun in mobile warfare necessitated the development of new methods of transporting the artillery into combat. Two distinct forms of artillery were developed: the towed gun, which was used primarily to attack or defend a fixed line; and the self-propelled gun, which was designed to accompany a mobile force and provide continuous fire support and/or suppression. These influences have guided the development of artillery ordnance, systems, organisations, and operations until the present, with artillery systems capable of providing support at ranges from as little as 100 m to the intercontinental ranges of ballistic missiles. The only combat in which artillery is unable to take part in is close quarters combat, with the possible exception of artillery reconnaissance teams.

The word as used in the current context originated in the Middle Ages. One suggestion is that it comes from the Old French "atellier", meaning "to arrange", and "attillement", meaning "equipment".

From the 13th century, an "artillier" referred to a builder of any war equipment; and, for the next 250 years, the sense of the word "artillery" covered all forms of military weapons. Hence, the naming of the Honourable Artillery Company, which was essentially an infantry unit until the 19th century. Another suggestion is that it comes from the Italian "arte de tirare" (art of shooting), coined by one of the first theorists on the use of artillery, Niccolò Tartaglia.

Mechanical systems used for throwing ammunition in ancient warfare, also known as "engines of war", like the catapult, onager, trebuchet, and ballista, are also referred to by military historians as artillery.

Early Chinese artillery had vase-like shapes. This includes the "long range awe inspiring" cannon dated from 1350 and found in the 14th century Ming Dynasty treatise "Huolongjing". With the development of better metallurgy techniques, later cannons abandoned the vase shape of early Chinese artillery. This change can be seen in the bronze "thousand ball thunder cannon," an early example of field artillery. These small, crude weapons diffused into the Middle East (the "madfaa") and reached Europe in the 13th century, in a very limited manner.

In Asia, Mongols adopted the Chinese artillery and used it effectively in the great conquest. By the late 14th century, Chinese rebels used organized artillery and cavalry to push Mongols out. The usage of cannons in the Mongol invasion of Java, led to deployment of cetbang cannons by Majapahit fleet in 1300s and subsequent near universal use of the swivel-gun and cannons in the Nusantaran archipelago.

As small smooth-bore tubes these were initially cast in iron or bronze around a core, with the first drilled bore ordnance recorded in operation near Seville in 1247. They fired lead, iron, or stone balls, sometimes large arrows and on occasions simply handfuls of whatever scrap came to hand. During the Hundred Years' War, these weapons became more common, initially as the bombard and later the cannon. Cannon were always muzzle-loaders. While there were many early attempts at breech-loading designs, a lack of engineering knowledge rendered these even more dangerous to use than muzzle-loaders.

In 1415, the Portuguese invaded the Mediterranean port town of Ceuta. While it is difficult to confirm the use of firearms in the siege of the city, it is known the Portuguese defended it thereafter with firearms, namely "bombardas", "colebratas", and "falconetes". In 1419, Sultan Abu Sa'id led an army to reconquer the fallen city, and Moroccans brought cannons and used them in the assault on Ceuta. Finally, hand-held firearms and riflemen appear in Morocco, in 1437, in an expedition against the people of Tangiers. It is clear these weapons had developed into several different forms, from small guns to large artillery pieces.

The artillery revolution in Europe caught on during the Hundred Years' War and changed the way that battles were fought. In the preceding decades, the English had even used a gunpowder-like weapon in military campaigns against the Scottish. However, at this time, the cannons used in battle were very small and not particularly powerful. Cannons were only useful for the defense of a castle, as demonstrated at Breteuil in 1356, when the besieged English used a cannon to destroy an attacking French assault tower. By the end of the 14th century, cannon were only powerful enough to knock in roofs, and could not penetrate castle walls.

However, a major change occurred between 1420 and 1430, when artillery became much more powerful and could now batter strongholds and fortresses quite efficiently. The English, French, and Burgundians all advanced in military technology, and as a result the traditional advantage that went to the defense in a siege was lost. The cannon during this period were elongated, and the recipe for gunpowder was improved to make it three times as powerful as before. These changes led to the increased power in the artillery weapons of the time.
Joan of Arc encountered gunpowder weaponry several times. When she led the French against the English at the Battle of Tourelles, in 1430, she faced heavy gunpowder fortifications, and yet her troops prevailed in that battle. In addition, she led assaults against the English-held towns of Jargeau, Meung, and Beaugency, all with the support of large artillery units. When she led the assault on Paris, Joan faced stiff artillery fire, especially from the suburb of St. Denis, which ultimately led to her defeat in this battle. In April 1430, she went to battle against the Burgundians, whose support was purchased by the English. At this time, the Burgundians had the strongest and largest gunpowder arsenal among the European powers, and yet the French, under Joan of Arc's leadership, were able to beat back the Burgundians and defend themselves. As a result, most of the battles of the Hundred Years' War that Joan of Arc participated in were fought with gunpowder artillery.

The army of Mehmet the Conqueror, which conquered Constantinople in 1453, included both artillery and foot soldiers armed with gunpowder weapons. The Ottomans brought to the siege sixty-nine guns in fifteen separate batteries and trained them at the walls of the city. The barrage of Ottoman cannon fire lasted forty days, and they are estimated to have fired 19,320 times. Artillery also played a decisive role in the Battle of St. Jakob an der Birs of 1444.
The new Ming Dynasty established the "Divine Engine Battalion" (神机营), which specialized in various types of artillery. Light cannons and cannons with multiple volleys were developed. In a campaign to suppress a local minority rebellion near today's Burmese border, "the Ming army used a 3-line method of arquebuses/muskets to destroy an elephant formation."

When Portuguese and Spanish arrived at Southeast Asia, they found that the local kingdoms already using cannons. Portuguese and Spanish invaders were unpleasantly surprised and even outgunned on occasion. Duarte Barbosa ca. 1510 said that the inhabitants of Java are great masters in casting artillery and very good artillerymen. They make many one-pounder cannons (cetbang or rentaka), long muskets, and other fire-works. Every place are considered excellent in casting artillery, and in the knowledge of using it. In 1513, the Javanese fleet led by Patih Yunus, when sailed to attack Portuguese Malacca "carried much artillery made in Java, for [the Javanese] are excellent founders". By early 16th century, the Javanese already locally-producing large guns, some of them still survived until the present day and dubbed as "sacred cannon" or "holy cannon". These cannons varied between 180-260 pounders, weighing anywhere between 3-8 tons, length of them between 3-6 m.

Between 1593 and 1597, about 200,000 Korean and Chinese troops which fought against Japan in Korea actively used heavy artillery in both siege and field combat. Korean forces mounted artillery in ships as naval guns, providing an advantage against Japanese navy which used "Kunikuzushi" (国崩し – Japanese breech-loading swivel gun) and "Ōzutsu" (大筒 – large size Tanegashima) as their largest firearms.

Bombards were of value mainly in sieges. A famous Turkish example used at the siege of Constantinople in 1453 weighed 19 tons, took 200 men and sixty oxen to emplace, and could fire just seven times a day. The Fall of Constantinople was perhaps "the first event of supreme importance whose result was determined by the use of artillery" when the huge bronze cannons of Mehmed II breached the city's walls, ending the Byzantine Empire, according to Sir Charles Oman.

Bombards developed in Europe were massive smoothbore weapons distinguished by their lack of a field carriage, immobility once emplaced, highly individual design, and noted unreliability (in 1460 James II, King of Scots, was killed when one exploded at the siege of Roxburgh). Their large size precluded the barrels being cast and they were constructed out of metal staves or rods bound together with hoops like a barrel, giving their name to the gun barrel.

The use of the word "cannon" marks the introduction in the 15th century of a dedicated field carriage with axle, trail and animal-drawn limber—this produced mobile field pieces that could move and support an army in action, rather than being found only in siege and static defences. The reduction in the size of the barrel was due to improvements in both iron technology and gunpowder manufacture, while the development of trunnions—projections at the side of the cannon as an integral part of the cast—allowed the barrel to be fixed to a more movable base, and also made raising or lowering the barrel much easier.
The first land-based mobile weapon is usually credited to Jan Žižka, who deployed his oxen-hauled cannon during the Hussite Wars of Bohemia (1418–1424). However cannons were still large and cumbersome. With the rise of musketry in the 16th century, cannon were largely (though not entirely) displaced from the battlefield—the cannon were too slow and cumbersome to be used and too easily lost to a rapid enemy advance.

The combining of shot and powder into a single unit, a cartridge, occurred in the 1620s with a simple fabric bag, and was quickly adopted by all nations. It speeded loading and made it safer, but unexpelled bag fragments were an additional fouling in the gun barrel and a new tool—a worm—was introduced to remove them. Gustavus Adolphus is identified as the general who made cannon an effective force on the battlefield—pushing the development of much lighter and smaller weapons and deploying them in far greater numbers than previously. The outcome of battles was still determined by the clash of infantry.

Shells, explosive-filled fused projectiles, were also developed in the 17th century. The development of specialized pieces—shipboard artillery, howitzers and mortars—was also begun in this period. More esoteric designs, like the multi-barrel "ribauldequin" (known as "organ guns"), were also produced.

The 1650 book by Kazimierz Siemienowicz "Artis Magnae Artilleriae pars prima" was one of the most important contemporary publications on the subject of artillery. For over two centuries this work was used in Europe as a basic artillery manual.

One of the most significant effects of artillery during this period was however somewhat more indirect—by easily reducing to rubble any medieval-type fortification or city wall (some which had stood since Roman times), it abolished millennia of siege-warfare strategies and styles of fortification building. This led, among other things, to a frenzy of new bastion-style fortifications to be built all over Europe and in its colonies, but also had a strong integrating effect on emerging nation-states, as kings were able to use their newfound artillery superiority to force any local dukes or lords to submit to their will, setting the stage for the absolutist kingdoms to come.

Modern rocket artillery can trace its heritage back to the Mysorean rockets of India. Their first recorded use was in 1780 during the battles of the Second, Third and Fourth Mysore Wars. The wars fought between the British East India Company and the Kingdom of Mysore in India made use of the rockets as a weapon. In the Battle of Pollilur, the Siege of Seringapatam (1792) and in Battle of Seringapatam in 1799 these rockets were used with considerable effect against the British." After the wars, several Mysore rockets were sent to England, but experiments with heavier payloads were unsuccessful. In 1804 William Congreve, considering the Mysorian rockets to have too short a range (less than 1,000 yards) developed rockets in numerous sizes with ranges up to 3,000 yards and eventually utilizing iron casing as the Congreve rocket which were used effectively during the Napoleonic Wars and the War of 1812.

Cannons continued to become smaller and lighter—Frederick II of Prussia deployed the first genuine light artillery during the Seven Years' War.

Jean-Baptiste de Gribeauval, a French artillery engineer, introduced the standardization of cannon design in the mid-18th century. He developed a field howitzer whose gun barrel, carriage assembly and ammunition specifications were made uniform for all French cannons. The standardized interchangeable parts of these cannons down to the nuts, bolts and screws made their mass production and repair much easier.

These improvements in the French artillery were essential for the later military successes of Napoleon. Napoleon, himself a former artillery officer, perfected the tactic of massed artillery batteries unleashed upon a critical point in his enemies' line as a prelude to a decisive infantry and cavalry assault.

The development of modern artillery occurred in the mid to late 19th century as a result of the convergence of various improvements in the underlying technology. Advances in metallurgy allowed for the construction of breech-loading rifled guns that could fire at a much greater muzzle velocity.

After the British artillery was shown up in the Crimean War as having barely changed since the Napoleonic Wars the industrialist William Armstrong was awarded a contract by the government to design a new piece of artillery. Production started in 1855 at the Elswick Ordnance Company and the Royal Arsenal at Woolwich, and the outcome was the revolutionary Armstrong Gun, which marked the birth of modern artillery. Three of its features particularly stand out.
First, the piece was rifled, which allowed for a much more accurate and powerful action. Although rifling had been tried on small arms since the 15th century, the necessary machinery to accurately rifle artillery was not available until the mid-19th century. Martin von Wahrendorff, and Joseph Whitworth independently produced rifled cannon in the 1840s, but it was Armstrong's gun that was first to see widespread use during the Crimean War. The cast iron shell of the Armstrong gun was similar in shape to a Minié ball and had a thin lead coating which made it fractionally larger than the gun's bore and which engaged with the gun's rifling grooves to impart spin to the shell. This spin, together with the elimination of windage as a result of the tight fit, enabled the gun to achieve greater range and accuracy than existing smooth-bore muzzle-loaders with a smaller powder charge.
His gun was also a breech-loader. Although attempts at breech-loading mechanisms had been made since medieval times, the essential engineering problem was that the mechanism couldn't withstand the explosive charge. It was only with the advances in metallurgy and precision engineering capabilities during the Industrial Revolution that Armstrong was able to construct a viable solution. The gun combined all the properties that make up an effective artillery piece. The gun was mounted on a carriage in such a way as to return the gun to firing position after the recoil.

What made the gun really revolutionary lay in the technique of the construction of the gun barrel that allowed it to withstand much more powerful explosive forces. The "built-up" method involved assembling the barrel with wrought-iron (later mild steel was used) tubes of successively smaller diameter. The tube would then be heated to allow it to expand and fit over the previous tube. When it cooled the gun would contract although not back to its original size, which allowed an even pressure along the walls of the gun which was directed inward against the outward forces that the gun's firing exerted on the barrel.

Another innovative feature, more usually associated with 20th-century guns, was what Armstrong called its "grip", which was essentially a squeeze bore; the 6 inches of the bore at the muzzle end was of slightly smaller diameter, which centered the shell before it left the barrel and at the same time slightly swaged down its lead coating, reducing its diameter and slightly improving its ballistic qualities.
Armstrong's system was adopted in 1858, initially for "special service in the field" and initially he produced only smaller artillery pieces, 6-pounder (2.5 in/64 mm) mountain or light field guns, 9-pounder (3 in/76 mm) guns for horse artillery, and 12-pounder (3 inches /76 mm) field guns.

The first cannon to contain all 'modern' features is generally considered to be the French 75 of 1897. It was the first field gun to include a hydro-pneumatic recoil mechanism, which kept the gun's trail and wheels perfectly still during the firing sequence. Since it did not need to be re-aimed after each shot, the crew could fire as soon as the barrel returned to its resting position. In typical use, the French 75 could deliver fifteen rounds per minute on its target, either shrapnel or melinite high-explosive, up to about 5 miles (8,500 m) away. Its firing rate could even reach close to 30 rounds per minute, albeit only for a very short time and with a highly experienced crew. These were rates that contemporary bolt action rifles could not match. The gun used cased ammunition, was breech-loading, and had modern sights, a self-contained firing mechanism and hydro-pneumatic recoil dampening.

Indirect fire, the firing of a projectile without relying on direct line of sight between the gun and the target, possibly dates back to the 16th century. Early battlefield use of indirect fire may have occurred at Paltzig in July 1759, when the Russian artillery fired over the tops of trees, and at the Battle of Waterloo, where a battery of the Royal Horse Artillery fired Shrapnel indirectly against advancing French troops.

In 1882, Russian Lieutenant Colonel KG Guk published "Indirect Fire for Field Artillery", which provided a practical method of using aiming points for indirect fire by describing, "all the essentials of aiming points, crest clearance, and corrections to fire by an observer".

A few years later, the Richtfläche (lining-plane) sight was invented in Germany and provided a means of indirect laying in azimuth, complementing the clinometers for indirect laying in elevation which already existed. Despite conservative opposition within the German army, indirect fire was adopted as doctrine by the 1890s. In the early 1900s, Goertz in Germany developed an optical sight for azimuth laying. It quickly replaced the lining-plane; in English, it became the 'Dial Sight' (UK) or 'Panoramic Telescope' (US).

The British halfheartedly experimented with indirect fire techniques since the 1890s, but with the onset of the Boer War, they were the first to apply the theory in practice in 1899, although they had to improvise without a lining-plane sight.

In the next 15 years leading up to World War I, the techniques of indirect fire became available for all types of artillery. Indirect fire was the defining characteristic of 20th-century artillery and led to undreamt of changes in the amount of artillery, its tactics, organisation, and techniques, most of which occurred during World War I.

An implication of indirect fire and improving guns was increasing range between gun and target, this increased the time of flight and the vertex of the trajectory. The result was decreasing accuracy (the increasing distance between the target and the mean point of impact of the shells aimed at it) caused by the increasing effects of non-standard conditions. Indirect firing data was based on standard conditions including a specific muzzle velocity, zero wind, air temperature and density, and propellant temperature. In practice, this standard combination of conditions almost never existed, they varied throughout the day and day to day, and the greater the time of flight, the greater the inaccuracy. An added complication was the need for survey to accurately fix the coordinates of the gun position and provide accurate orientation for the guns. Of course, targets had to be accurately located, but by 1916, air photo interpretation techniques enabled this, and ground survey techniques could sometimes be used.

In 1914, the methods of correcting firing data for the actual conditions were often convoluted, and the availability of data about actual conditions was rudimentary or non-existent, the assumption was that fire would always be ranged (adjusted). British heavy artillery worked energetically to progressively solve all these problems from late 1914 onwards, and by early 1918, had effective processes in place for both field and heavy artillery. These processes enabled 'map-shooting', later called 'predicted fire'; it meant that effective fire could be delivered against an accurately located target without ranging. Nevertheless, the mean point of impact was still some tens of yards from the target-centre aiming point. It was not precision fire, but it was good enough for concentrations and barrages. These processes remain in use into the 21st Century with refinements to calculations enabled by computers and improved data capture about non-standard conditions.

The British major-general Henry Hugh Tudor pioneered armour and artillery cooperation at the breakthrough Battle of Cambrai. The improvements in providing and using data for non-standard conditions (propellant temperature, muzzle velocity, wind, air temperature, and barometric pressure) were developed by the major combatants throughout the war and enabled effective predicted fire. The effectiveness of this was demonstrated by the British in 1917 (at Cambrai) and by Germany the following year (Operation Michael).

Major General J.B.A. Bailey, British Army (retired) wrote:
An estimated 75,000 French soldiers were casualties of friendly artillery fire in the four years of World War I.

Modern artillery is most obviously distinguished by its long range, firing an explosive shell or rocket and a mobile carriage for firing and transport. However, its most important characteristic is the use of indirect fire, whereby the firing equipment is aimed without seeing the target through its sights. Indirect fire emerged at the beginning of the 20th century and was greatly enhanced by the development of predicted fire methods in World War I. However, indirect fire was area fire; it was and is not suitable for destroying point targets; its primary purpose is area suppression. Nevertheless, by the late 1970s precision-guided munitions started to appear, notably the US 155 mm Copperhead and its Soviet 152 mm Krasnopol equivalent that had success in Indian service. These relied on laser designation to 'illuminate' the target that the shell homed onto. However, in the early 21st Century, the Global Positioning System (GPS) enabled relatively cheap and accurate guidance for shells and missiles, notably the US 155 mm Excalibur and the 227 mm GMLRS rocket. The introduction of these led to a new issue, the need for very accurate three dimensional target coordinates—the mensuration process.

Weapons covered by the term 'modern artillery' include "cannon" artillery (such as howitzer, mortar, and field gun) and rocket artillery. Certain smaller-caliber mortars are more properly designated small arms rather than artillery, albeit indirect-fire small arms. This term also came to include coastal artillery which traditionally defended coastal areas against seaborne attack and controlled the passage of ships. With the advent of powered flight at the start of the 20th century, artillery also included ground-based anti-aircraft batteries.

The term "artillery" has traditionally not been used for projectiles with internal guidance systems, preferring the term "missilery", though some modern artillery units employ surface-to-surface missiles. Advances in terminal guidance systems for small munitions has allowed large-caliber guided projectiles to be developed, blurring this distinction.

One of the most important roles of logistics is the supply of munitions as a primary type of artillery consumable, their storage (ammunition dump, arsenal, magazine
) and the provision of fuses, detonators and warheads at the point where artillery troops will assemble the charge, projectile, bomb or shell.

A round of artillery ammunition comprises four components:

Fuzes are the devices that initiate an artillery projectile, either to detonate its high explosive (HE) filling or eject its cargo (illuminating flare or smoke canisters being examples). The official military spelling is "fuze". Broadly there are four main types:

Most artillery fuzes are nose fuzes. However, base fuzes have been used with armour piercing shells and for squash head (HESH or HEP) anti-tank shells. At least one nuclear shell and its non-nuclear spotting version also used a multi-deck mechanical time fuze fitted into its base.

Impact fuzes were, and in some armies remain, the standard fuze for HE projectiles. Their default action is normally 'superquick', some have had a 'graze' action which allows them to penetrate light cover and others have 'delay'. Delay fuzes allow the shell to penetrate the ground before exploding. Armor- or concrete-piercing fuzes are specially hardened. During World War I and later, ricochet fire with delay or graze fuzed HE shells, fired with a flat angle of descent, was used to achieve airburst.

HE shells can be fitted with other fuzes. Airburst fuzes usually have a combined airburst and impact function. However, until the introduction of proximity fuzes, the airburst function was mostly used with cargo munitions—for example, shrapnel, illumination, and smoke. The larger calibers of anti-aircraft artillery are almost always used airburst. Airburst fuzes have to have the fuze length (running time) set on them. This is done just before firing using either a wrench or a fuze setter pre-set to the required fuze length.

Early airburst fuzes used igniferous timers which lasted into the second half of the 20th century. Mechanical time fuzes appeared in the early part of the century. These required a means of powering them. The Thiel mechanism used a spring and escapement (i.e. 'clockwork'), Junghans used centrifugal force and gears, and Dixi used centrifugal force and balls. From about 1980, electronic time fuzes started replacing mechanical ones for use with cargo munitions.

Proximity fuzes have been of two types: photo-electric or radar. The former was not very successful and seems only to have been used with British anti-aircraft artillery 'unrotated projectiles' (rockets) in World War II. Radar proximity fuzes were a big improvement over the mechanical (time) fuzes which they replaced. Mechanical time fuzes required an accurate calculation of their running time, which was affected by non-standard conditions. With HE (requiring a burst 20 to above the ground), if this was very slightly wrong the rounds would either hit the ground or burst too high. Accurate running time was less important with cargo munitions that burst much higher.

The first radar proximity fuzes (codenamed 'VT') were invented by the British and developed by the US and initially used against aircraft in World War II. Their ground use was delayed for fear of the enemy recovering 'blinds' (artillery shells which failed to detonate) and copying the fuze. The first proximity fuzes were designed to detonate about above the ground. These air-bursts are much more lethal against personnel than ground bursts because they deliver a greater proportion of useful fragments and deliver them into terrain where a prone soldier would be protected from ground bursts.

However, proximity fuzes can suffer premature detonation because of the moisture in heavy rain clouds. This led to 'controlled variable time' (CVT) after World War II. These fuzes have a mechanical timer that switched on the radar about 5 seconds before expected impact, they also detonated on impact.

The proximity fuze emerged on the battlefields of Europe in late December 1944. They have become known as the U.S. Artillery's "Christmas present", and were much appreciated when they arrived during the Battle of the Bulge. They were also used to great effect in anti-aircraft projectiles in the Pacific against "kamikaze" as well as in Britain against V-1 flying bombs.

Electronic multi-function fuzes started to appear around 1980. Using solid-state electronics they were relatively cheap and reliable, and became the standard fitted fuze in operational ammunition stocks in some western armies. The early versions were often limited to proximity airburst, albeit with height of burst options, and impact. Some offered a go/no-go functional test through the fuze setter.

Later versions introduced induction fuze setting and testing instead of physically placing a fuze setter on the fuze. The latest, such as Junghan's DM84U provide options giving, superquick, delay, a choice of proximity heights of burst, time and a choice of foliage penetration depths.

A new type of artillery fuze will appear soon. In addition to other functions these offer some course correction capability, not full precision but sufficient to significantly reduce the dispersion of the shells on the ground.

The projectile is the munition or "bullet" fired downrange. This may or may not be an explosive device.

Traditionally, projectiles have been classified as "shot" or "shell", the former being solid and the latter having some form of "payload".

Shells can also be divided into three configurations: bursting, base ejection or nose ejection. The latter is sometimes called the shrapnel configuration. The most modern is base ejection, which was introduced in World War I. Both base and nose ejection are almost always used with airburst fuzes. Bursting shells use various types of fuze depending on the nature of the payload and the tactical need at the time.

Payloads have included:


Most forms of artillery require a propellant to propel the projectile at the target. Propellant is always a low explosive, this means it deflagrates instead of detonating, as with high explosives. The shell is accelerated to a high velocity in a very short time by the rapid generation of gas from the burning propellant. This high pressure is achieved by burning the propellant in a contained area, either the chamber of a gun barrel or the combustion chamber of a rocket motor.

Until the late 19th century, the only available propellant was black powder. Black powder had many disadvantages as a propellant; it has relatively low power, requiring large amounts of powder to fire projectiles, and created thick clouds of white smoke that would obscure the targets, betray the positions of guns, and make aiming impossible. In 1846, nitrocellulose (also known as guncotton) was discovered, and the high explosive nitroglycerin was discovered at nearly the same time. Nitrocellulose was significantly more powerful than black powder, and was smokeless. Early guncotton was unstable, however, and burned very fast and hot, leading to greatly increased barrel wear. Widespread introduction of smokeless powder would wait until the advent of the double-base powders, which combine nitrocellulose and nitroglycerin to produce powerful, smokeless, stable propellant.

Many other formulations were developed in the following decades, generally trying to find the optimum characteristics of a good artillery propellant; low temperature, high energy, non-corrosive, highly stable, cheap, and easy to manufacture in large quantities. Broadly, modern gun propellants are divided into three classes: single-base propellants which are mainly or entirely nitrocellulose based, double-base propellants composed of a combination of nitrocellulose and nitroglycerin, and triple base composed of a combination of nitrocellulose and nitroglycerin and Nitroguanidine.

Artillery shells fired from a barrel can be assisted to greater range in three ways:

Propelling charges for tube artillery can be provided in one of two ways: either as cartridge bags or in metal cartridge cases. Generally, anti-aircraft artillery and smaller-caliber (up to 3" or 76.2 mm) guns use metal cartridge cases that include the round and propellant, similar to a modern rifle cartridge. This simplifies loading and is necessary for very high rates of fire. Bagged propellant allows the amount of powder to be raised or lowered, depending on the range to the target. It also makes handling of larger shells easier. Each requires a totally different type of breech to the other. A metal case holds an integral primer to initiate the propellant and provides the gas seal to prevent the gases leaking out of the breech; this is called obturation. With bagged charges, the breech itself provides obturation and holds the primer. In either case, the primer is usually percussion, but electrical is also used, and laser ignition is emerging. Modern 155 mm guns have a primer magazine fitted to their breech.
Artillery ammunition has four classifications according to use:

Because field artillery mostly uses indirect fire the guns have to be part of a system that enables them to attack targets invisible to them in accordance with the combined arms plan.

The main functions in the field artillery system are:

All these calculations to produce a quadrant elevation (or range) and azimuth were done manually using instruments, tablulated, data of the moment, and approximations until battlefield computers started appearing in the 1960s and 1970s. While some early calculators copied the manual method (typically substituting polynomials for tabulated data), computers use a different approach. They simulate a shell's trajectory by 'flying' it in short steps and applying data about the conditions affecting the trajectory at each step. This simulation is repeated until it produces a quadrant elevation and azimuth that lands the shell within the required 'closing' distance of the target coordinates.
NATO has a standard ballistic model for computer calculations and has expanded the scope of this into the NATO Armaments Ballistic Kernel (NABK) within the SG2 Shareable (Fire Control) Software Suite (S4).

Supply of artillery ammunition has always been a major component of military logistics. Up until World War I some armies made artillery responsible for all forward ammunition supply because the load of small arms ammunition was trivial compared to artillery. Different armies use different approaches to ammunition supply, which can vary with the nature of operations. Differences include where the logistic service transfers artillery ammunition to artillery, the amount of ammunition carried in units and extent to which stocks are held at unit or battery level. A key difference is whether supply is 'push' or 'pull'. In the former the 'pipeline' keeps pushing ammunition into formations or units at a defined rate. In the latter units fire as tactically necessary and replenish to maintain or reach their authorised holding (which can vary), so the logistic system has to be able to cope with surge and slack.

Artillery types can be categorised in several ways, for example by type or size of weapon or ordnance, by role or by organizational arrangements.

The types of cannon artillery are generally distinguished by the velocity at which they fire projectiles.
Types of artillery:



Modern field artillery can also be split into two other subcategories: towed and self-propelled. As the name suggests, towed artillery has a prime mover, usually an artillery tractor or truck, to move the piece, crew, and ammunition around. Towed artillery is in some cases equipped with an APU for small displacements. Self-propelled artillery is permanently mounted on a carriage or vehicle with room for the crew and ammunition and is thus capable of moving quickly from one firing position to another, both to support the fluid nature of modern combat and to avoid counter-battery fire. It includes mortar carrier vehicles, many of which allow the mortar to be removed from the vehicle and be used dismounted, potentially in terrain in which the vehicle cannot navigate, or in order to avoid detection.

At the beginning of the modern artillery period, the late 19th century, many armies had three main types of artillery, in some case they were sub-branches within the artillery branch in others they were separate branches or corps. There were also other types excluding the armament fitted to warships:


After World War I many nations merged these different artillery branches, in some cases keeping some as sub-branches. Naval artillery disappeared apart from that belonging to marines. However, two new branches of artillery emerged during that war and its aftermath, both used specialised guns (and a few rockets) and used direct not indirect fire, in the 1950s and 1960s both started to make extensive use of missiles:

However, the general switch by artillery to indirect fire before and during World War I led to a reaction in some armies. The result was accompanying or infantry guns. These were usually small, short range guns, that could be easily man-handled and used mostly for direct fire but some could use indirect fire. Some were operated by the artillery branch but under command of the supported unit. In World War II they were joined by self-propelled assault guns, although other armies adopted infantry or close support tanks in armoured branch units for the same purpose, subsequently tanks generally took on the accompanying role.

The three main types of artillery "gun" are guns, howitzers, and mortars. During the 20th century, guns and howitzers have steadily merged in artillery use, making a distinction between the terms somewhat meaningless. By the end of the 20th century, true guns with calibers larger than about 60 mm had become very rare in artillery use, the main users being tanks, ships, and a few residual anti-aircraft and coastal guns. The term "cannon" is a United States generic term that includes guns, howitzers, and mortars; it is not used in other English speaking armies.

The traditional definitions differentiated between guns and howitzers in terms of maximum elevation (well less than 45° as opposed to close to or greater than 45°), number of charges (one or more than one charge), and having higher or lower muzzle velocity, sometimes indicated by barrel length. These three criteria give eight possible combinations, of which guns and howitzers are but two. However, modern "howitzers" have higher velocities and longer barrels than the equivalent "guns" of the first half of the 20th century.

True guns are characterized by long range, having a maximum elevation significantly less than 45°, a high muzzle velocity and hence a relatively long barrel, smooth bore (no rifling) and a single charge. The latter often led to fixed ammunition where the projectile is locked to the cartridge case. There is no generally accepted minimum muzzle velocity or barrel length associated with a gun. 

Howitzers can fire at maximum elevations at least close to 45°; elevations up to about 70° are normal for modern howitzers. Howitzers also have a choice of charges, meaning that the same elevation angle of fire will achieve a different range depending on the charge used. They have rifled bores, lower muzzle velocities and shorter barrels than equivalent guns. All this means they can deliver fire with a steep angle of descent. Because of their multi-charge capability, their ammunition is mostly separate loading (the projectile and propellant are loaded separately).

That leaves six combinations of the three criteria, some of which have been termed gun howitzers. A term first used in the 1930s when howitzers with a relatively high maximum muzzle velocities were introduced, it never became widely accepted, most armies electing to widen the definition of "gun" or "howitzer". By the 1960s, most equipments had maximum elevations up to about 70°, were multi-charge, had quite high maximum muzzle velocities and relatively long barrels.

Mortars are simpler. The modern mortar originated in World War I and there were several patterns. After that war, most mortars settled on the Stokes pattern, characterized by a short barrel, smooth bore, low muzzle velocity, elevation angle of firing generally greater than 45°, and a very simple and light mounting using a "baseplate" on the ground. The projectile with its integral propelling charge was dropped down the barrel from the muzzle to hit a fixed firing pin. Since that time, a few mortars have become rifled and adopted breech loading.

There are other recognized typifying characteristics for artillery. One such characteristic is the type of obturation used to seal the chamber and prevent gases escaping through the breech. This may use a metal cartridge case that also holds the propelling charge, a configuration called "QF" or "quickfiring" by some nations. The alternative does not use a metal cartridge case, the propellant being merely bagged or in combustible cases with the breech itself providing all the sealing. This is called "BL" or "breech loading" by some nations.

A second characteristic is the form of propulsion. Modern equipment can either be towed or self-propelled (SP). A towed gun fires from the ground and any inherent protection is limited to a gun shield. Towing by horse teams lasted throughout World War II in some armies, but others were fully mechanized with wheeled or tracked gun towing vehicles by the outbreak of that war. The size of a towing vehicle depends on the weight of the equipment and the amount of ammunition it has to carry.

A variation of towed is portee, where the vehicle carries the gun which is dismounted for firing. Mortars are often carried this way. A mortar is sometimes carried in an armored vehicle and can either fire from it or be dismounted to fire from the ground. Since the early 1960s it has been possible to carry lighter towed guns and most mortars by helicopter. Even before that, they were parachuted or landed by glider from the time of the first airborne trials in the USSR in the 1930s.

In an SP equipment, the gun is an integral part of the vehicle that carries it. SPs first appeared during World War I, but did not really develop until World War II. They are mostly tracked vehicles, but wheeled SPs started to appear in the 1970s. Some SPs have no armor and carry little or no ammunition. Armoured SPs usually carry a useful ammunition load. Early armoured SPs were mostly a "casemate" configuration, in essence an open top armored box offering only limited traverse. However, most modern armored SPs have a full enclosed armored turret, usually giving full traverse for the gun. Many SPs cannot fire without deploying stabilizers or spades, sometimes hydraulic. A few SPs are designed so that the recoil forces of the gun are transferred directly onto the ground through a baseplate. A few towed guns have been given limited self-propulsion by means of an auxiliary engine.

Two other forms of tactical propulsion were used in the first half of the 20th century: Railways or transporting the equipment by road, as two or three separate loads, with disassembly and re-assembly at the beginning and end of the journey. Railway artillery took two forms, railway mountings for heavy and super-heavy guns and howitzers and armored trains as "fighting vehicles" armed with light artillery in a direct fire role. Disassembled transport was also used with heavy and super heavy weapons and lasted into the 1950s.

A third form of artillery typing is to classify it as "light", "medium", "heavy" and various other terms. It appears to have been introduced in World War I, which spawned a very wide array of artillery in all sorts of sizes so a simple categorical system was needed. Some armies defined these categories by bands of calibers. Different bands were used for different types of weapons—field guns, mortars, anti-aircraft guns and coastal guns.

List of countries in order of amount of artillery:


Artillery is used in a variety of roles depending on its type and caliber. The general role of artillery is to provide "fire support"—"the application of fire, coordinated with the manoeuvre of forces to destroy, "neutralize" or "suppress" the enemy". This NATO definition makes artillery a supporting arm although not all NATO armies agree with this logic. The "italicised" terms are NATO's.

Unlike rockets, guns (or howitzers as some armies still call them) and mortars are suitable for delivering "close supporting fire". However, they are all suitable for providing "deep supporting fire" although the limited range of many mortars tends to exclude them from the role. Their control arrangements and limited range also mean that mortars are most suited to "direct supporting fire". Guns are used either for this or "general supporting fire" while rockets are mostly used for the latter. However, lighter rockets may be used for direct fire support. These rules of thumb apply to NATO armies.

Modern mortars, because of their lighter weight and simpler, more transportable design, are usually an integral part of infantry and, in some armies, armor units. This means they generally do not have to "concentrate" their fire so their shorter range is not a disadvantage. Some armies also consider infantry operated mortars to be more responsive than artillery, but this is a function of the control arrangements and not the case in all armies. However, mortars have always been used by artillery units and remain with them in many armies, including a few in NATO.

In NATO armies artillery is usually assigned a tactical mission that establishes its relationship and responsibilities to the formation or units it is assigned to. It seems that not all NATO nations use the terms and outside NATO others are probably used. The standard terms are: "direct support", "general support", "general support reinforcing" and "reinforcing". These tactical missions are in the context of the command authority: "operational command", "operational control", "tactical command" or "tactical control".

In NATO direct support generally means that the directly supporting artillery unit provides observers and liaison to the manoeuvre troops being supported, typically an artillery battalion or equivalent is assigned to a brigade and its batteries to the brigade's battalions. However, some armies achieve this by placing the assigned artillery units under command of the directly supported formation. Nevertheless, the batteries' fire can be "concentrated" onto a single target, as can the fire of units in range and with the other tactical missions.

There are several dimensions to this subject. The first is the notion that fire may be against an "opportunity" target or may be "prearranged". If it is the latter it may be either "on-call" or "scheduled". Prearranged targets may be part of a "fire plan". Fire may be either "observed" or "unobserved", if the former it may be "adjusted", if the latter then it has to be "predicted". Observation of adjusted fire may be directly by a forward observer or indirectly via some other "target acquisition" system.

NATO also recognises several different types of fire support for tactical purposes:

These purposes have existed for most of the 20th century, although their definitions have evolved and will continue to do so, lack of "suppression" in "counterbattery" is an omission. Broadly they can be defined as either:

Two other NATO terms also need definition:

The tactical purposes also include various "mission verbs", a rapidly expanding subject with the modern concept of "effects based operations".

"Targeting" is the process of selecting target and matching the appropriate response to them taking account of operational requirements and capabilities. It requires consideration of the type of fire support required and the extent of coordination with the supported arm. It involves decisions about:

The "targeting" process is the key aspect of tactical fire control. Depending on the circumstances and national procedures it may all be undertaken in one place or may be distributed. In armies practicing control from the front, most of the process may be undertaken by a forward observer or other target acquirer. This is particularly the case for a smaller target requiring only a few fire units. The extent to which the process is formal or informal and makes use of computer based systems, documented norms or experience and judgement also varies widely armies and other circumstances.

Surprise may be essential or irrelevant. It depends on what effects are required and whether or not the target is likely to move or quickly improve its protective posture. During World War II UK researchers concluded that for impact fuzed munitions the relative risk were as follows:
Airburst munitions significantly increase the relative risk for lying men, etc. Historically most casualties occur in the first 10–15 seconds of fire, i.e. the time needed to react and improve protective posture, however, this is less relevant if airburst is used.

There are several ways of making best use of this brief window of maximum vulnerability:

Modern counter-battery fire developed in World War I, with the objective of defeating the enemy's artillery. Typically such fire was used to suppress enemy batteries when they were or were about to interfere with the activities of friendly forces (such as to prevent enemy defensive artillery fire against an impending attack) or to systematically destroy enemy guns. In World War I the latter required air observation. The first indirect counter-battery fire was in May 1900 by an observer in a balloon.

Enemy artillery can be detected in two ways, either by direct observation of the guns from the air or by ground observers (including specialist reconnaissance), or from their firing signatures. This includes radars tracking the shells in flight to determine their place of origin, sound ranging detecting guns firing and resecting their position from pairs of microphones or cross-observation of gun flashes using observation by human observers or opto-electronic devices, although the widespread adoption of 'flashless' propellant limited the effectiveness of the latter.

Once hostile batteries have been detected they may be engaged immediately by friendly artillery or later at an optimum time, depending on the tactical situation and the counter-battery policy. Air strike is another option. In some situations the task is to locate all active enemy batteries for attack using a counter-battery fire at the appropriate moment in accordance with a plan developed by artillery intelligence staff. In other situations counter-battery fire may occur whenever a battery is located with sufficient accuracy.

Modern counter-battery target acquisition uses unmanned aircraft, counter-battery radar, ground reconnaissance and sound-ranging. Counter-battery fire may be adjusted by some of the systems, for example the operator of an unmanned aircraft can 'follow' a battery if it moves. Defensive measures by batteries include frequently changing position or constructing defensive earthworks, the tunnels used by North Korea being an extreme example. Counter-measures include air defence against aircraft and attacking counter-battery radars physically and electronically.

'Field Artillery Team' is a US term and the following description and terminology applies to the US, other armies are broadly similar but differ in significant details. Modern field artillery (post–World War I) has three distinct parts: the forward observer (or FO), the fire direction center (FDC) and the actual guns themselves. The forward observer observes the target using tools such as binoculars, laser rangefinders, designators and call back fire missions on his radio, or relays the data through a portable computer via an encrypted digital radio connection protected from jamming by computerized frequency hopping. A lesser known part of the team is the FAS or Field Artillery Survey team which setups up the "Gun Line" for the cannons. Today most artillery battalions use a(n) "Aiming Circle" which allows for faster setup and more mobility. FAS teams are still used for checks and balances purposes and if a gun battery has issues with the "Aiming Circle" a FAS team will do it for them.

The FO can communicate directly with the battery FDC, of which there is one per each battery of 4–8 guns. Otherwise the several FOs communicate with a higher FDC such as at a Battalion level, and the higher FDC prioritizes the targets and allocates fires to individual batteries as needed to engage the targets that are spotted by the FOs or to perform preplanned fires.

The Battery FDC computes firing data—ammunition to be used, powder charge, fuse settings, the direction to the target, and the quadrant elevation to be fired at to reach the target, what gun will fire any rounds needed for adjusting on the target, and the number of rounds to be fired on the target by each gun once the target has been accurately located—to the guns. Traditionally this data is relayed via radio or wire communications as a warning order to the guns, followed by orders specifying the type of ammunition and fuse setting, direction, and the elevation needed to reach the target, and the method of adjustment or orders for fire for effect (FFE). However, in more advanced artillery units, this data is relayed through a digital radio link.

Other parts of the field artillery team include meteorological analysis to determine the temperature, humidity and pressure of the air and wind direction and speed at different altitudes. Also radar is used both for determining the location of enemy artillery and mortar batteries and to determine the precise actual strike points of rounds fired by battery and comparing that location with what was expected to compute a registration allowing future rounds to be fired with much greater accuracy.

A technique called Time on Target was developed by the British Army in North Africa at the end of 1941 and early 1942 particularly for counter-battery fire and other concentrations, it proved very popular. It relied on BBC time signals to enable officers to synchronize their watches to the second because this avoided the need to use military radio networks and the possibility of losing surprise, and the need for field telephone networks in the desert. With this technique the time of flight from each fire unit (battery or troop) to the target is taken from the range or firing tables, or the computer and each engaging fire unit subtracts its time of flight from the TOT to determine the time to fire. An executive order to fire is given to all guns in the fire unit at the correct moment to fire. When each fire unit fires their rounds at their individual firing time all the opening rounds will reach the target area almost simultaneously. This is especially effective when combined with techniques that allow fires for effect to be made without preliminary adjusting fires.

A modern version of the earlier "time on target" is a concept in which fire from different weapons was timed to arrive on target at the same time. It is possible for artillery to fire several shells per gun at a target and have all of them arrive simultaneously, which is called MRSI (Multiple Rounds Simultaneous Impact). This is because there is more than one trajectory for the rounds to fly to any given target: typically one is below 45 degrees from horizontal and the other is above it, and by using different size propelling charges with each shell, it is possible to create multiple trajectories. Because the higher trajectories cause the shells to arc higher into the air, they take longer to reach the target and so if the shells are fired on these trajectories for the first volleys (starting with the shell with the most propellant and working down) and then after the correct pause more volleys are fired on the lower trajectories, the shells will all arrive at the same time. This is useful because many more shells can land on the target with no warning. With traditional volleys along the same trajectory, anybody at the target area may have time (however long it takes to reload and re-fire the guns) to take cover between volleys. However, guns capable of burst fire can deliver several rounds in 10 seconds if they use the same firing data for each, and if guns in more than one location are firing on one target they can use Time on Target procedures so that all their shells arrive at the same time and target.

To engage targets using MRSI requires two things, firstly guns with the requisite rate of fire and sufficiently different size propelling charges, secondly a fire control computer that has been designed to compute such missions and the data handling capability that allows all the firing data to be produced, sent to each gun and then presented to the gun commander in the correct order. The number of rounds that can be delivered in MRSI depends primarily on the range to the target and the rate of fire, for maximum rounds the range is limited to that of lowest propelling charge that will reach the target.

Examples of guns with a rate of fire that makes them suitable for MRSI includes UK's AS-90, South Africa's Denel G6-52 (which can land six rounds simultaneously at targets at least away), Germany's Panzerhaubitze 2000 (which can land five rounds simultaneously at targets at least away), and Slovakia's 155 mm SpGH ZUZANA model 2000. The Archer project (developed by BAE-Systems in Sweden) is a 155 mm howitzer on a wheeled chassis which is claimed to be able to deliver up to six shells on target simultaneously from the same gun. The 120 mm twin barrel AMOS mortar system, joint developed by Hägglunds (Sweden) and Patria (Finland), is capable of 7 + 7 shells MRSI. The United States Crusader program (now cancelled) was slated to have MRSI capability. It is unclear how many fire control computers have the necessary capabilities.

Two-round MRSI firings were a popular artillery demonstration in the 1960s, where well trained detachments could show off their skills for spectators.

The destructiveness of artillery bombardments can be enhanced when some or all of the shells are set for airburst, meaning that they explode in the air above the target instead of upon impact. This can be accomplished either through time fuzes or proximity fuzes. Time fuses use a precise timer to detonate the shell after a preset delay. This technique is tricky and slight variations in the functioning of the fuse can cause it to explode too high and be ineffective, or to strike the ground instead of exploding above it. Since December 1944 (Battle of the Bulge), proximity fuzed artillery shells have been available that take the guesswork out of this process. These employ a miniature, low powered radar transmitter in the fuse to detect the ground and explode them at a predetermined height above it. The return of the weak radar signal completes an electrical circuit in the fuze which explodes the shell. The proximity fuse itself was developed by the British to increase the effectiveness of anti-aircraft warfare.

This is a very effective tactic against infantry and light vehicles, because it scatters the fragmentation of the shell over a larger area and prevents it from being blocked by terrain or entrenchments that do not include some form of robust overhead cover. Combined with TOT or MRSI tactics that give no warning of the incoming rounds, these rounds are especially devastating because many enemy soldiers are likely to be caught in the open. This is even more so if the attack is launched against an assembly area or troops moving in the open rather than a unit in an entrenched tactical position.

Numerous war memorials around the world incorporate an artillery piece which had been used in the specific war or battle commemorated.





</doc>
<doc id="2510" url="https://en.wikipedia.org/wiki?curid=2510" title="Arnulf of Carinthia">
Arnulf of Carinthia

Arnulf of Carinthia ( 850 – December 8, 899) was the duke of Carinthia who overthrew his uncle, Emperor Charles the Fat, became the Carolingian king of East Francia from 887, the disputed King of Italy from 894 and the disputed Holy Roman Emperor from February 22, 896 until his death at Regensburg, Bavaria.

Arnulf was the illegitimate son of Carloman of Bavaria, and Liutswind, who may have been the sister of Ernst, Count of the Bavarian Nordgau Margraviate in the area of the Upper Palatinate, or perhaps the burgrave of Passau, according to other sources. After Arnulf's birth, Carloman married, before 861, a daughter of that same Count Ernst, who died after 8 August 879. As it is mainly West-Franconian historiography that speaks of Arnulf's illegitimacy, it is quite possible that the two females are actually one and the same person and that Carloman married Arnulf's mother, thus legitimizing his son.

Arnulf was granted the rule over the Duchy of Carinthia, a Frankish vassal state and successor of the ancient Principality of Carantania by his father Carloman, after Carloman reconciled with his own father, king Louis the German and was made king in Duchy of Bavaria.

Arnulf spent his childhood in "Mosaburch" or Mosapurc, which is widely believed to be Moosburg in Carinthia, a few miles away from one of the Imperial residences, the Carolingian Kaiserpfalz at Karnburg (Krnski grad), which had been the residence of the Carantanian princes. Arnulf kept his seat here and from later events it may be inferred that the Carantanians, from an early time, treated him as their own Duke. Later, after he had been crowned King of East Francia, Arnulf turned his old territory of Carinthia into the March of Carinthia, a part of the Duchy of Bavaria.

After King Carloman was incapacitated by a stroke in 879, Louis the Younger inherited Bavaria, Charles the Fat was given the Kingdom of Italy and Arnulf was confirmed in Carinthia by an agreement with Carloman. However, Bavaria was more or less ruled by Arnulf. Arnulf already ruled Bavaria during the summer and autumn of 879 while his father arranged his succession and he himself was granted "Pannonia," in the words of the "Annales Fuldenses", or "Carantanum," in the words of Regino of Prüm. The division of the realm was confirmed in 880 after Carloman's death.

When Engelschalk II of Pannonia in 882 rebelled against Aribo, Margrave of Pannonia and ignited the Wilhelminer War, Arnulf supported him and accepted his and his brother's homage. This ruined Arnulf's relationship with his uncle the Emperor and put him at war with Svatopluk of Moravia. Pannonia was invaded, but Arnulf refused to give up the young Wilhelminers. Arnulf did not make peace with Svatopluk until late 885, by which time Moravian ruler was loyal to the emperor. Some scholars see this war as destroying Arnulf's hopes at succeeding Charles the Fat.

Arnulf took the leading role in the deposition of his uncle, Emperor Charles the Fat. With the support of the Frankish nobles, Arnulf called a Diet at Tribur and deposed Charles in November 887, under threat of military action. Charles peacefully agreed to this involuntary retirement, but not without first chastising his nephew for his treachery and asking for a few royal villas in Swabia, which Arnulf granted him, on which to live out his final months. Arnulf, having distinguished himself in the war against the Slavs, was then elected king by the nobles of East Francia (only the eastern realm, though Charles had ruled the whole of the Frankish Empire). West Francia, the Kingdom of Burgundy and the Kingdom of Italy at this point elected their own kings from the Carolingian family.

Like all early Germanic rulers, he was heavily involved in ecclesiastical disputes. In 895, at the Diet of Tribur, he presided over a dispute between the Episcopal sees of Bremen, Hamburg and Cologne over jurisdictional authority, which saw Bremen and Hamburg remain a combined see, independent of the see of Cologne.

Arnulf was a fighter, not a negotiator. In 890 he was successfully battling Slavs in Pannonia. In early/mid-891, Vikings invaded Lotharingia, and crushed an East Frankish army at Maastricht. Terms such as "Vikings", "Danes", "Northmen" and "Norwegians" have been used loosely and interchangeably to describe these invaders. At the subsequent Battle of Leuven (September 891), in Lotharingia, Arnulf repelled the Vikings, and essentially ended their attacks on that front. The "Annales Fuldenses" report that there were so many dead Northmen that their bodies blocked the run of the river. After this victory Arnulf built a new castle on an island in the Dijle river (Dutch: Dijle, English and French: Dyle).

Arnulf took advantage of the problems in West Francia after the death of Charles the Fat to secure the territory of Lotharingia, which he converted into a kingdom for his son Zwentibold. In 889 Arnulf supported the claim of Louis the Blind to the kingdom of Provence, after receiving a personal appeal from Louis' mother, Ermengard, who came to see Arnulf at Forchheim in May 889.

Recognising the superiority of Arnulf's position, in 888 king Odo of France formally accepted the suzerainty of Arnulf. In 893 Arnulf switched his support from Odo to Charles the Simple after being persuaded by Fulk, Archbishop of Reims, that it was in his best interests. Arnulf then took advantage of the following fighting between Odo and Charles in 894, taking more territory from West Francia. At one point, Charles the Simple was forced to flee to Arnulf and ask for his protection. His intervention soon forced Pope Formosus to get involved, as he was worried that a divided and war weary West Francia would be easy prey for the Vikings.

In 895 Arnulf summoned both Charles and Odo to his residence at Worms. Charles's advisers convinced him not to go, and he sent a representative in his place. Odo, on the other hand, personally attended, together with a large retinue, bearing many gifts for Arnulf. Angered by the non-appearance of Charles, he welcomed Odo at the Diet of Worms in May 895, and again supported Odo's claim to the throne of West Francia. In the same assembly he crowned his illegitimate son Zwentibold as the king of Lotharingia.

As early as 880 Arnulf had designs on Great Moravia, and had the Frankish bishop Wiching of Nitra interfere with the missionary activities of Eastern Orthodox priest Methodius, with the aim of preventing any potential for creating a unified Moravian state. Arnold communicated political relations with the ruler of the Moravian Kingdom Svatopluk, and learned military and political secrets of Svatopluk. Later were used these tactics to occupy the territory of the Greater Moravian state.

Arnulf failed to conquer the whole of Great Moravia in wars of 892, 893, and 899. Yet Arnulf did achieve some successes, in particular in 895, when Duchy of Bohemia broke away from Great Moravia and became his vassal state. An accord was reached between him and Duke of Bohemia Borivoj I (reigned 870-95). Bohemia was thus freed from the dangers of Frankish invasion. In 893 or 894 Great Moravia probably lost a part of its territory — present-day Western Hungary — to him. As a reward, Wiching became Arnulf's chancellor in 892. In his attempts to conquer Moravia, in 899 Arnulf reached out to Magyars who had settled in Pannonia, and with their help he imposed a measure of control over Moravia.

In Italy Guy III of Spoleto and Berengar of Friuli fought over the Iron Crown of Lombardy. Berengar had been crowned king in 887, but Guy was then crowned in 889. While Pope Stephen V supported Guy, even crowning him Roman Emperor in 891, Arnulf threw his support behind Berengar.

In 893 the new Pope Formosus, not trusting the newly crowned co-emperors Guy III of Spoleto and his son Lambert II of Spoleto, sent an embassy to Omuntesberch, where Arnulf was meeting with Svatopluk I of Moravia, to request that Arnulf come and liberate Italy, where he would be crowned emperor in Rome. Arnulf met the "Primores" of the Kingdom of Italy, dismissed them with gifts and promised to assist the pope. Arnulf then sent his son Zwentibold with a Bavarian army to join Berengar of Friuli. They defeated Guy, but were bought off and left in autumn.

When pope Formosus again asked Arnulf to invade, the duke personally led an army across the Alps early in 894. In January 894 Bergamo fell, and Count Ambrose, Guy's representative in the city, was hung from a tree by the city's gates. Conquering all of the territory north of the Po River, Arnulf forced the surrender of Milan and then drove Guy out of Pavia, where he was crowned King of Italy. Arnulf went no further before Guy died suddenly in late autumn, and a fever incapacitated his troops. His march northward through the Alps was interrupted by Rudolph I of Burgundy, and it was only with great difficulty that Arnulf crossed the mountain range. In retaliation, Arnulf ordered his illegitimate son Zwentibold to ravage Rudolph's kingdom. In the meantime, Lambert and his mother Ageltrude travelled to Rome to receive papal confirmation of his imperial succession, but when pope Formosus, still desiring to crown Arnulf, refused, he was imprisoned in Castel Sant'Angelo.

In September 895 a new papal embassy arrived in Regensburg beseeching Arnulf's aid. In October Arnulf undertook his second campaign into Italy. He crossed the Alps quickly and again, took Pavia, but then he continued slowly, garnering support among the nobility of Tuscany. First Maginulf, Count of Milan, and then Walfred of Friuli, joined him. Eventually even Adalbert II of Tuscany abandoned Lambert. Finding Rome locked against him and held by Ageltrude, Arnulf had to take the city by force on February 21, 896, freeing the pope. Arnulf was then greeted at the Ponte Milvio by the Roman Senate who escorted him into the Leonine City, where he was received by Pope Formosus on the steps of the Santi Apostoli.

On February 22, 896 Formosus led the king into the church of St.Peter, anointed and crowned him as emperor, and saluted him as "Augustus". Arnulf then proceeded to the Basilica of Saint Paul Outside the Walls, where he received the homage of the Roman people, who swore "never to hand over the city to Lambert or his mother Ageltrude". Arnulf then proceeded to exile to Bavaria two leading senators, Constantine and Stephen, who had helped Ageltrude to seize Rome.

Leaving one of his vassals, Farold, to hold Rome, two weeks later Arnulf marched on Spoleto, where Ageltrude had fled to join Lambert, but now Arnulf suffered a stroke, forcing him to call off the campaign and return to Bavaria. Rumours of the time made Arnulf's condition to be a result of poisoning at the hand of Ageltrude.

Arnulf retained power in Italy only as long as he was personally there. On his way north, he stopped at Pavia where he crowned his illegitimate son Ratold, as sub-King of Italy, after which he left Ratold in Milan in an attempt to preserve his hold on Italy. That same year pope Formosus died, leaving Lambert once again in power, and both he and Berengar proceeded to kill any officials who had been appointed by Arnulf, forcing Ratold to flee from Milan to Bavaria. For the rest of his life Arnulf excersised very little control in Italy, and his agents in Rome did not prevent the accession of Pope Stephen VI in 896. Pope initially gave his support to Arnulf, but eventually became a supporter of Lambert.

After 896 Arnulf's health – besides suffering a stroke he had morbus pediculosis, infestation of pubic lice of the eyelid – prevented him from effectively dealing with the problems besetting his reign. Italy was lost, raiders from Moravia and Magyars were continually raiding his lands, and Lotharingia was in revolt against Zwentibold. He was also plagued by escalating violence and power struggles between the lower Frankish nobility.

On December 8, 899 Arnulf died at Ratisbon in present-day Bavaria. He is entombed in St. Emmeram's Basilica at Regensburg, which is now known as Schloss Thurn und Taxis, the palace of the Princes of Thurn und Taxis.

He was succeeded as the king of East Francia by his only legitimate son from Ota (died 903), Louis the Child. After his death in 911 at age 17 or 18, the east Frankish branch of Carolingian dynasty ceased to exist. Arnulf had had the nobility to recognize the rights of his illegitimate sons Zwentibold and Ratold as his successors. Zwentibold, whom he had made King of Lotharingia in 895, continued to rule there until his murder in 900.




</doc>
<doc id="2511" url="https://en.wikipedia.org/wiki?curid=2511" title="Alexanderplatz">
Alexanderplatz

Alexanderplatz () is a large public square and transport hub in the central Mitte district of Berlin. The square is named after the Russian Tsar Alexander I and is often referred to simply as Alex, which also denotes the larger neighbourhood stretching from "Mollstraße" in the northeast to "Spandauer Straße" and the Rotes Rathaus in the southwest.

With more than 360,000 visitors daily, Alexanderplatz is, according to one study, the most visited area of Berlin, beating Friedrichstrasse and City West. It is a popular starting point for tourists, with many attractions including the Fernsehturm (TV tower), the Nikolai Quarter and the Rotes Rathaus (Red city hall) situated nearby. Alexanderplatz is still one of Berlin's major commercial areas, housing various shopping malls, department stores and other large retail locations.

During the post-war reconstruction of the 1960s, Alexanderplatz was completely pedestrianized. Since then, trams were reintroduced to the area in 1998.

Alexanderplatz station provides S-Bahn connections, access to the U2, U5 and U8 subway lines, regional train lines for DB Regio and ODEG services and, on weekends, the Harz-Berlin-Express (HBX). Several tram and bus lines also service the area.

The following main roads connect to Alexanderplatz:


Several arterial roads lead radially from Alexanderplatz to the outskirts of Berlin. These include (clockwise from north to southeast):


Karl-Marx-Allee (B 1 and B 5) - Strausberger Platz - Karl-Marx-Allee / Frankfurter Tor - Frankfurter Allee (B 1 and B 5 to Berlin-Hellersdorf junction at Berliner Ring)

A hospital stood at the location of present-day Alexanderplatz since the 13th century. Named "Heiliger Georg" (St. George), the hospital gave its name to the nearby Georgentor (George Gate) of the Berlin city wall. Outside of the city walls, this area was largely undeveloped until around 1400, when the first settlers began building thatched cottages. As a gallows was located close by, the area earned the nickname the "Teufels Lustgarten" (the Devil's Pleasure Garden).

The George Gate became the most important of Berlin's city gates during the 16th century, being the main entrance point for goods arriving along the roads to the north and north-east of the city, for example from Oderberg, Prenzlau and Bernau, and the big Hanseatic cities on the Baltic Sea.

After the Thirty Years' War, the city wall was strengthened. From 1658 to 1683, a citywide fortress was constructed to plans by the Linz master builder, Johann Gregor Memhardt. The new fortress contained 13 bastions connected by ramparts and was preceded by a moat measuring up to 50 meters wide. Within the new fortress, many of the historic city wall gates were closed. For example, the southeastern Stralauer Gate was closed but the Georgian Gate remained open, making the Georgian Gate an even more important entrance to the city.

In 1681, the trade of cattle and pig fattening was banned within the city. Frederick William, the Great Elector, granted cheaper plots of land, waiving the basic interest rate, in the area in front of the Georgian Gate. Settlements grew rapidly and a weekly cattle market was established on the square in front of the Gate.

The area developed into a suburb - the Georgenvorstadt - which continued to flourish into the late 17th century. Unlike the southwestern suburbs (Friedrichstadt, Dorotheenstadt) which were strictly and geometrically planned, the suburbs in the northeast (Georgenvorstadt, Spandauervorstadt and the Stralauer Vorstadt) proliferated without plan. Despite a building ban imposed in 1691, more than 600 houses existed in the area by 1700.

At that time, the George Gate was a rectangular gatehouse with a tower. Next to the tower stood a remaining tower from the original medieval city walls. The upper floors of the gatehouse served as the city jail. A drawbridge spanned the moat and the gate was locked at nightfall by the garrison using heavy oak planks.

A highway ran through the cattle market to the northeast towards Bernau. To the right stood the George chapel, an orphanage and a hospital that was donated by the Elector Sophie Dorothea in 1672. Next to the chapel stood a dilapidated medieval plague house which was demolished in 1716. Behind it was a rifleman's field and an inn, later named the "Stelzenkrug".

By the end of the 17th century, 600 to 700 families lived in this area. They included butchers, cattle herders, shepherds and dairy farmers. The George chapel was upgraded to the George church and received its own preacher.

After his coronation in Königsberg on May 6, 1701, the Prussian King Frederick I entered Berlin through the George Gate. This led to the gate being renamed the King's Gate, and the surrounding arena became known in official documents as "Königs Thor Platz" (King's Gate Square). The Georgenvorstadt suburb was renamed Königsvorstadt (or "royal city for" short).

In 1734, the Berlin Customs Wall, which initially consisted of a ring of palisade fences, was reinforced and grew to encompass the old city and its suburbs, including Königsvorstadt. This resulted in the King's Gate losing importance as an entry-point for goods into the city. The gate was finally demolished in 1746.

By the end of the 18th century, the basic structure of the royal suburbs of the Königsvorstadt had been developed. It consisted of irregular-shaped blocks of buildings running along the historic highways which once carried goods in various directions out of the gate. At this time, the area contained large factories (silk and wool), such as the "Kurprinz" (one of Berlin's first cloth factories, located in a former barn) and a workhouse established in 1758 for beggars and homeless people, where the inmates worked a man-powered treadmill to turn a mill.

Soon, military facilities came to dominate the area, such as the 1799-1800 military parade grounds designed by David Gilly. At this time, the residents of the platz were mostly craftsmen, petty bourgeois, retired soldiers and manufacturing workers. The southern part of the later Alexanderplatz was separated from traffic by trees and served as a parade ground, whereas the northern half remained a market. Beginning in the mid-18th century, the most important wool market in Germany was held in Alexanderplatz.

Between 1752 and 1755, the writer Gotthold Ephraim Lessing lived in a house on Alexanderplatz. In 1771, a new stone bridge (the "Königsbrücke") was built over the moat and in 1777 a colonnade-lined row of shops (Königskolonnaden) was constructed by architect Carl von Gontard. Between 1783 and 1784, seven three-storey buildings were erected around the square by Georg Christian Unger, including the famous "Gasthof zum Hirschen", where Karl Friedrich Schinkel lived as a permanent tenant and Heinrich von Kleist stayed in the days before his suicide.

On October 25, 1805, the Russian Tsar Alexander I was welcomed to the city on the parade grounds in front of the old King's Gate. To mark this occasion, on the 2nd November, King Frederick William III ordered the square to be renamed "Alexanderplatz":
In the southeast of the square, the cloth factory buildings were converted into the Königstädter Theater by Carl Theodor Ottmer at a cost of 120,000 Taler. The foundation stone was laid on August 31, 1823 and the opening ceremony occurred on August 4, 1824. Sales were poor, forcing the theatre to close on June 3, 1851. Thereafter, the building was used for wool storage, then as a tenement building, and finally as an inn called "Aschinger" until the building's demolition in 1932.

During these years, Alexanderplatz was populated by fish wives, water carriers, sand sellers, rag-and-bone men, knife sharpeners and day laborers.

Because of its importance as a transport hub, horse-drawn buses ran every 15 minutes between Alexanderplatz and Potsdamer Platz in 1847.

During the March Revolution of 1848, large-scale street fighting occurred on the streets of Alexanderplatz, where revolutionaries used barricades to block the route from Alexanderplatz to the city. Novelist and poet Theodor Fontane, who all worked in the vicinity in a nearby pharmacy, participated in the construction of barricades and later described how he used materials from the Königstädter Theater to barricade Neue Königstraße.

The Königsstadt continued to grow throughout the 19th century, with three-storey developments already existing at the beginning of the century and fourth storeys being constructed from the middle of the century. By the end of the century, most of the buildings were already five storeys high. The large factories and military facilities gave way to housing developments (mainly rental housing for the factory workers who had just moved into the city) and trading houses.

At the beginning of the 1870s, the Berlin administration had the former moat filled in order to build the Berlin city railway, which was opened in 1882 along with Bahnhof Alexanderplatz (Alexanderplatz Railway Station).

In 1883-1884, the Grand Hotel, a neo-Renaissance building with 185 rooms and shops beneath was constructed. From 1886 to 1890, Hermann Blankenstein built the Police headquarters, a huge brick building whose tower on the northern corner dominated the building. In 1890, a district court at Alexanderplatz was also established.

In 1886, the local authorities built a central market hall west of the rail tracks, which replaced the weekly market on the Alexanderplatz in 1896. During the end of the 19th century, the emerging private traffic and the first horse bus lines dominated the northern part of the square, the southern part (the former parade ground) remained quiet, having green space elements added by garden director Hermann Mächtig in 1889. The northwest of the square contained a second, smaller green space where, in 1895, the 7.5-meter copper Berolina statue by sculptor Emil Hundrieser was erected.

At the beginning of the 20th century, Alexanderplatz experienced its heyday. In 1901, Ernst von Wolzogen founded the first German cabaret, the Überbrettl, in the former Sezessionsbühne (Secession stage) at Alexanderstraße 40, initially under the name Bunte Brettl. It was announced as "Kabarett as upscale entertainment with artistic ambitions. Emperor-loyal and market-oriented stands the uncritical amusement in the foreground."

The merchants Hermann Tietz, Georg Wertheim and Hahn opened large department stores on Alexanderplatz: Tietz (1904-1911), Wertheim (1910–1911) and Hahn (1911). Tietz marketed itself as a department store for the Berlin people, whereas Wertheim modelled itself as a department store for the world.

In October 1905, the first section of the Tietz department store opened to the public. It was designed by architects Wilhelm Albert Cremer and Richard Wolffenstein, who had already won second prize in the competition for the construction of the Reichstag building. The Tietz department store underwent further construction phases and, in 1911, had a commercial space of 7,300 square meters and the longest department store facade in the world at 250 meters in length.

For the construction of the Wertheim department store, by architects Heinrich Joseph Kayser and Karl von Großheim, the Königskolonnaden were removed in 1910 and now stand in the Heinrich von Kleist Park in Schöneberg.

In October 1908, the Haus des Lehrers (house of teachers) was inaugurated next to the Bunte Brettl at Alexanderstraße 41. It was designed by Hans Toebelmann and Henry Gross. The building belonged to the Berliner Lehrererverein (teachers’ association), who rented space on the ground floor of the building out to a pastry shop and restaurant in order to raise funds for the association. The rear of the property contained the association's administrative building, a hotel for members and an exhibition hall. Notable events that took place in the hall include the funeral services for Karl Liebknecht and Rosa Luxemburg on February 2, 1919, and, on December 4, 1920, the Vereinigungsparteitag (Unification Party Congress) of the Communist Party and the USPD.

The teachers' library was also housed in this building. Surviving two world wars, today the library is integrated into the library for educational historical research.

Alexanderplatz's position as a main transport and traffic hub continued to fuel its development. In addition to the three U-Bahn underground lines, long-distance trains and S-Bahn trains ran along the Platz's viaduct arches. Omnibuses, horse-drawn from 1877 and, after 1898, also electric-powered trams, ran out of Alexanderplatz in all directions in a star shape. The subway station was designed by Alfred Grenander and followed the color-coded order of subway stations, which began with green at Leipziger Platz and ran through to dark red.

In the Golden Twenties, Alexanderplatz was the epitome of the lively, pulsating cosmopolitan city of Berlin, rivaled in the city only by Potsdamer Platz. Many of the buildings and rail bridges surrounding the platz bore large billboards that illuminated the night. The Berlin cigarette company Manoli had a famous billboard at the time which contained a ring of neon tubes that constantly circled a black ball. The proverbial "Berliner Tempo" of those years was characterized as "total manoli". Writer Kurt Tucholsky wrote a poem referencing the advert, and the composer Rudolf Nelson made the legendary Revue Total manoli with the dancer Lucie Berber. The writer Alfred Döblin named his novel, Berlin Alexanderplatz, after the square and Walter Ruttmann filmed his 1927 film Berlin: Die Sinfonie der Großstadt (Berlin: The symphony of the big city) at Alexanderplatz.

One of Berlin’s largest air-raid shelters during the Second World War was situated under Alexanderplatz. It was built between 1941 and 1943 for the Deutsche Reichsbahn by Philipp Holzmann.

The war reached Alexanderplatz in early April 1945. The Berolina statue had already been removed in 1944 and probably melted down for use in arms production. During the Battle of Berlin, Red Army artillery bombarded the area around Alexanderplatz. The battles of the last days of the war destroyed considerable parts of the historic Königsstadt, as well as many of the buildings around Alexanderplatz.

The Wehrmacht had entrenched itself within the tunnels of the underground system. Hours before fighting ended in Berlin on May 2, 1945, troops of the SS detonated explosives inside the north-south S-Bahn tunnel under the Landwehr Canal to slow the advance of the Red Army towards Berlin’s city center. The entire tunnel flooded, as well as large sections of the U-Bahn network via connecting passages at the Friedrichstraße underground station. Many of those seeking shelter in the tunnels were killed. Of the then 63.3 kilometers of subway tunnel, around 19.8 kilometers were flooded with more than one million cubic meters of water.

Before a planned reconstruction of the entire Alexanderplatz could take place, all of the war ruins needed to be demolished and cleared away. A popular black market emerged within the ruined area, which the police raided several times a day.

Reconstruction planning for post-war Berlin gave priority to the dedication space to accommodate the rapidly-growing motor traffic in inner-city thoroughfares. This idea of a traffic-orientated city was already based on considerations and plans by Hilbersheimer and Le Corbusier from the 1930s.

Alexanderplatz has been subject to redevelopment several times in its history, most recently during the 1960s, when it was turned into a pedestrian zone and enlarged as part of the German Democratic Republic's redevelopment of the city centre. It is surrounded by several notable structures including the Fernsehturm (TV Tower).

Ever since German reunification, Alexanderplatz has undergone a gradual process of change with many of the surrounding buildings being renovated. Despite the reconstruction of the tram line crossing, it has retained its socialist character, including the much-graffitied "Fountain of Friendship between Peoples" ("Brunnen der Völkerfreundschaft"), a popular venue.

In 1993, architect Hans Kollhoff's master plan for a major redevelopment including the construction of several skyscrapers was published. Due to a lack of demand it is unlikely these will be constructed. However, beginning with the reconstruction of the "Kaufhof" department store in 2004, and the biggest underground railway station of Berlin, some buildings were redesigned and new structures built on the square's south-eastern side. Sidewalks were expanded to shrink one of the avenues, a new underground garage was built, and commuter tunnels meant to keep pedestrians off the streets were removed. The surrounding buildings now house chain stores, fast-food restaurants, and fashion discounters. The "Alexa" shopping mall, with approximately 180 stores opened nearby in 2007, and a large "Saturn" electronic store was built and opened in 2008. The CUBIX multiplex cinema, which opened in November 2000, joined the team of Berlin International Film Festival cinemas in 2007, and the festival shows films on three of its screens. In January 2014, a 39-story residential tower designed by Frank Gehry was announced, but this project was put on hold in 2018.

Many historic buildings are located in the vicinity of Alexanderplatz. The traditional seat of city government, the Rotes Rathaus, or "Red City Hall", is located nearby, as was the former East German parliament building, the Palast der Republik. The Palast was demolished from 2006-2008 to make room for a full reconstruction of the Baroque Berlin Palace, or "Stadtschloss", which is set to open in 2019.

Alexanderplatz is also the name of the S-Bahn and U-Bahn stations there. It is one of Berlin's largest and most important transportation hubs, being a meetingplace of three subway (U-Bahn) lines, three S-Bahn lines, and many tram and bus lines, as well as regional trains.

It also accommodates the Park Inn Berlin and the World Time Clock, a continually rotating installation that shows the time throughout the globe, and Hermann Henselmann's "Haus des Lehrers". During the Peaceful Revolution of 1989, the Alexanderplatz demonstration on 4 November was the largest demonstration in the history of East Germany.

Alexanderplatz is the only existing square in front of one of the medieval gates of Berlin's city wall.




</doc>
<doc id="2512" url="https://en.wikipedia.org/wiki?curid=2512" title="Asian Development Bank">
Asian Development Bank

The Asian Development Bank (MMG) is a regional development bank established on 19 December 1966, which is headquartered in the Ortigas Center located in the city of Mandaluyong, Metro Manila, Philippines. The company also maintains 31 field offices around the world to promote social and economic development in Asia. The bank admits the members of the United Nations Economic and Social Commission for Asia and the Pacific (UNESCAP, formerly the Economic Commission for Asia and the Far East or ECAFE) and non-regional developed countries. From 31 members at its establishment, ADB now has 68 members, of which 49 are from within Asia and the Pacific and 19 from outside. 

The ADB was modeled closely on the World Bank, and has a similar weighted voting system where votes are distributed in proportion with members' capital subscriptions. ADB releases an annual report that summarizes its operations, budget and other materials for review by the public. The ADB-Japan Scholarship Program (ADB-JSP) enrolls about 300 students annually in academic institutions located in 10 countries within the Region. Upon completion of their study programs, scholars are expected to contribute to the economic and social development of their home countries. ADB is an official United Nations Observer.

As of 31 December 2016, Japan and United States hold the largest proportion of shares at 15.607%. China holds 6.444%, India holds 6.331%, and Australia holds 5.786%.

The highest policy-making body of the bank is the Board of Governors, composed of one representative from each member state. The Board of Governors, in turn, elect among themselves the twelve members of the Board of Directors and their deputies. Eight of the twelve members come from regional (Asia-Pacific) members while the others come from non-regional members.

The Board of Governors also elect the bank's president, who is the chairperson of the Board of Directors and manages ADB. The president has a term of office lasting five years, and may be reelected. Traditionally, and because Japan is one of the largest shareholders of the bank, the president has always been Japanese.

The current president is Takehiko Nakao, who succeeded Haruhiko Kuroda in 2013.

The headquarters of the bank is at 6 ADB Avenue, Mandaluyong, Metro Manila, Philippines, and it has 31 field offices in Asia and the Pacific and representative offices in Washington, Frankfurt, Tokyo and Sydney. The bank employs about 3,000 people, representing 60 of its 67 members.

As early as 1956, Japan Finance Minister Hisato Ichimada had suggested to United States Secretary of State John Foster Dulles that development projects in Southeast Asia could be supported by a new financial institution for the region. A year later, Japanese Prime Minister Nobusuke Kishi announced that Japan intended to sponsor the establishment of a regional development fund with resources largely from Japan and other industrial countries. But the US did not warm to the plan and the concept was shelved. See full account in "Banking on the Future of Asia and the Pacific: 50 Years of the Asian Development Bank," July 2017.

The idea came up again late in 1962 when Kaoru Ohashi, an economist from a research institute in Tokyo, visited Takeshi Watanabe, then a private financial consultant in Tokyo, and proposed a study group to form a development bank for the Asian region. The group met regularly in 1963, examining various scenarios for setting up a new institution and drew on Watanabe's experiences with the World Bank. However, the idea received a cool reception from the World Bank itself and the study group became discouraged.

In parallel, the concept was formally proposed at a trade conference organized by the Economic Commission for Asia and the Far East (ECAFE) in 1963 by a young Thai economist, Paul Sithi-Amnuai. (ESCAP, United Nations Publication March 2007, "The first parliament of Asia" pp. 65). Despite an initial mixed reaction, support for the establishment of a new bank soon grew.

An expert group was convened to study the idea, with Japan invited to contribute to the group. When Watanabe was recommended, the two streams proposing a new bank—from ECAFE and Japan—came together. Initially, the US was on the fence, not opposing the idea but not ready to commit financial support. But a new bank for Asia was soon seen to fit in with a broader program of assistance to Asia planned by U.S. President Lyndon B. Johnson in the wake of the escalating US military support for the government of South Vietnam.

As a key player in the concept, Japan hoped that the ADB offices would be in Tokyo. However, eight other cities had also expressed an interest—Bangkok, Colombo, Kabul, Kuala Lumpur, Manila, Phnom Penh, Singapore, and Tehran. To decide, the 18 prospective regional members of the new bank held three rounds of votes at a ministerial conference in Manila in November/December 1965. In the first round on 30 November, Tokyo failed to win a majority, so a second ballot was held the next day at noon. Although Japan was in the lead, it was still inconclusive, so a final vote was held after lunch. In the third poll, Tokyo gained eight votes to Manila's nine, with one abstention. Therefore, Manila was declared the host of the new development bank. The Japanese were mystified and deeply disappointed. Watanabe later wrote in his personal history of ADB: "I felt as if the child I had so carefully reared had been taken away to a distant country." (Asian Development Bank publication, "Towards a New Asia", 1977, p. 16)

As intensive work took place during 1966 to prepare for the opening of the new bank in Manila, high on the agenda was choice of president. Japanese Prime Minister Eisaku Sato asked Watanabe to be a candidate. Although he initially declined, pressure came from other countries and Watanabe agreed. In the absence of any other candidates, Watanabe was elected first President of the Asian Development Bank at its Inaugural Meeting on 24 November 1966.

By the end of 1972, Japan had contributed $173.7 million (22.6% of the total) to the ordinary capital resources and $122.6 million (59.6% of the total) to the special funds. In contrast, the United States contributed only $1.25 million to the special fund.

After its creation in the 1960s, ADB focused much of its assistance on food production and rural development. At the time, Asia was one of the poorest regions in the world.

Early loans went largely to Indonesia, Thailand, Malaysia, South Korea and the Philippines; these nations accounted for 78.48% of the total ADB loans between 1967 and 1972. Moreover, Japan received tangible benefits, 41.67% of the total procurements between 1967 and 1976. Japan tied its special funds contributions to its preferred sectors and regions and procurements of its goods and services, as reflected in its $100 million donation for the Agricultural Special Fund in April 1968.

Watanabe served as the first ADB president to 1972.

In the 1970s, ADB's assistance to developing countries in Asia expanded into education and health, and then to infrastructure and industry. The gradual emergence of Asian economies in the latter part of the decade spurred demand for better infrastructure to support economic growth. ADB focused on improving roads and providing electricity. When the world suffered its first oil price shock, ADB shifted more of its assistance to support energy projects, especially those promoting the development of domestic energy sources in member countries.

Following considerable pressure from the Reagan Administration in the 1980s, ADB reluctantly began working with the private sector in an attempt to increase the impact of its development assistance to poor countries in Asia and the Pacific. In the wake of the second oil crisis, ADB expanded its assistance to energy projects. In 1982, ADB opened its first field office, in Bangladesh, and later in the decade it expanded its work with non-government organizations (NGOs).

Japanese presidents Inoue Shiro (1972–76) and Yoshida Taroichi (1976–81) took the spotlight in the 1970s. Fujioka Masao, the fourth president (1981–90), adopted an assertive leadership style, launching an ambitious plan to expand the ADB into a high-impact development agency.

In the 1990s, ADB began promoting regional cooperation by helping the countries on the Mekong River to trade and work together. The decade also saw an expansion of ADB's membership with the addition of several Central Asian countries following the end of the Cold War.

In mid-1997, ADB responded to the financial crisis that hit the region with projects designed to strengthen financial sectors and create social safety nets for the poor. During the crisis, ADB approved its largest single loan – a $4 billion emergency loan to the South Korea. In 1999, ADB adopted poverty reduction as its overarching goal.

The early years of 2000s saw a dramatic expansion of private sector finance. While the institution had such operations since the 1980s (under pressure from the Reagan Administration) the early attempts were highly unsuccessful with low lending volumes, considerable losses and financial scandals associated with an entity named AFIC. However, beginning in 2002, the ADB undertook a dramatic expansion of private sector lending under a new team. Over the course of the next six years, the Private Sector Operations Department (PSOD) grew by a factor of 41 times the 2001 levels of new financings and earnings for the ADB. This culminated with the Board's formal recognition if these achievements in March 2008, when the Board of Directors formally adopted the Long Term Strategic Framework (LTSF). That document formally stated that assistance to private sector development was the lead priority of the ADB and that it should constitute 50% of the bank's lending by 2020.

In 2003, the severe acute respiratory syndrome (SARS) epidemic hit the region and ADB responded with programs to help the countries in the region work together to address infectious diseases, including avian influenza and HIV/AIDS. ADB also responded to a multitude of natural disasters in the region, committing more than $850 million for recovery in areas of India, Indonesia, Maldives, and Sri Lanka which were impacted by the December 2004 Asian tsunami. In addition, $1 billion in loans and grants was provided to the victims of the October 2005 earthquake in Pakistan.

In 2009, ADB's Board of Governors agreed to triple ADB's capital base from $55 billion to $165 billion, giving it much-needed resources to respond to the global economic crisis. The 200% increase is the largest in ADB's history, and was the first since 1994.

Asia moved beyond the economic crisis and by 2010 had emerged as a new engine of global economic growth though it remained home to two-thirds of the world's poor. In addition, the increasing prosperity of many people in the region created a widening income gap that left many people behind. ADB responded to this with loans and grants that encouraged economic growth.

In early 2012, the ADB began to re-engage with Myanmar in response to reforms initiated by the government. In April 2014, ADB opened an office in Myanmar and resumed making loans and grants to the country.

In 2017, ADB combined the lending operations of its Asian Development Fund (ADF) with its ordinary capital resources (OCR). The result was to expand the OCR balance sheet to permit increasing annual lending and grants to $20 billion by 2020 — 50% more than the previous level.

The ADB defines itself as a social development organization that is dedicated to reducing poverty in Asia and the Pacific through inclusive economic growth, environmentally sustainable growth, and regional integration. This is carried out through investments – in the form of loans, grants and information sharing – in infrastructure, health care services, financial and public administration systems, helping nations prepare for the impact of climate change or better manage their natural resources, as well as other areas.

Eighty percent of ADB's lending is concentrated public sector lending in five operational areas.

The ADB offers "hard" loans on commercial terms primarily to middle income countries in Asia and "soft" loans with lower interest rates to poorer countries in the region. Based on a new policy, both types of loans will be sourced starting January 2017 from the bank's ordinary capital resources (OCR), which functions as its general operational fund.

The ADB's Private Sector Department (PSOD) can and does offer a broader range of financings beyond commercial loans. They also have the capability to provide guarantees, equity and mezzanine finance (a combination of debt and equity).

In 2017, ADB lent $19.1 billion of which $3.2 billion went to private enterprises, as part of its "nonsovereign" operations. ADB's operations in 2017, including grants and cofinancing, totaled $28.9 billion.

ADB obtains its funding by issuing bonds on the world's capital markets. It also relies on the contributions of member countries, retained earnings from lending operations, and the repayment of loans.

ADB provides direct financial assistance, in the form of debt, equity and mezzanine finance to private sector companies, for projects that have clear social benefits beyond the financial rate of return. ADB's participation is usually limited but it leverages a large amount of funds from commercial sources to finance these projects by holding no more than 25% of any given transaction.

ADB partners with other development organizations on some projects to increase the amount of funding available. In 2014, $9.2 billion—or nearly half—of ADB's $22.9 billion in operations were financed by other organizations. According to Jason Rush, Principal Communication Specialist, the Bank communicates with many other multilateral organizations.

More than 50 financing partnership facilities, trust funds, and other funds – totalling several billion each year – are administered by ADB and put toward projects that promote social and economic development in Asia and the Pacific. ADB has raised Rs 5 billion or around Rs 500 crores from its issuance of 5-year offshore Indian rupee (INR) linked bonds. Also, plans to raise around $20 billion from the capital markets in 2016.

ADB has an information disclosure policy that presumes all information that is produced by the institution should be disclosed to the public unless there is a specific reason to keep it confidential. The police calls for accountability and transparency in operations and the timely response to requests for information and documents. ADB does not disclose information that jeopardizes personal privacy, safety and security, certain financial and commercial information, as well as other exceptions.

Since the ADB's early days, critics have charged that the two major donors, Japan and the United States, have had extensive influence over lending, policy and staffing decisions.

Oxfam Australia has criticized the Asian Development Bank for insensitivity to local communities. "Operating at a global and international level, these banks can undermine people's human rights through projects that have detrimental outcomes for poor and marginalized communities." The bank also received criticism from the United Nations Environmental Program, stating in a report that "much of the growth has bypassed more than 70 percent of its rural population, many of whom are directly dependent on natural resources for livelihoods and incomes."

There had been criticism that ADB's large scale projects cause social and environmental damage due to lack of oversight. One of the most controversial ADB-related projects is Thailand's Mae Moh coal-fired power station. Environmental and human rights activists say ADB's environmental safeguards policy as well as policies for indigenous peoples and involuntary resettlement, while usually up to international standards on paper, are often ignored in practice, are too vague or weak to be effective, or are simply not enforced by bank officials.

The bank has been criticized over its role and relevance in the food crisis. The ADB has been accused by civil society of ignoring warnings leading up the crisis and also contributing to it by pushing loan conditions that many say unfairly pressure governments to deregulate and privatize agriculture, leading to problems such as the rice supply shortage in Southeast Asia.

Indeed, whereas the Private Sector Operations Department (PSOD) closed out that year with financings of $2.4 billion, the ADB has significantly dropped below that level in the years since and is clearly not on the path to achieving its stated goal of 50% of financings to the private sector by 2020. Critics also point out that the PSOD is the only Department that actually makes money for the ADB. Hence, with the vast majority of loans going to concessionary (sub-market) loans to the public sector, the ADB is facing considerable financial difficulty and continuous operating losses.
The following table are amounts for 20 largest countries by subscribed capital and voting power at the Asian Development Bank as of December 2014.

ADB has 68 members (as of 23 March 2019): 49 members from the Asian and Pacific Region, 19 members from Other Regions. The year after a member's name indicates the year of membership. At the time a country ceases to be a member, the Bank shall arrange for the repurchase of such country's shares by the Bank as a part of the settlement of accounts with such country in accordance with the provisions of paragraphs 3 and 4 of Article 43.





</doc>
<doc id="2514" url="https://en.wikipedia.org/wiki?curid=2514" title="Aswan">
Aswan

Aswan (, ; ; ) is a city in the south of Egypt, and is the capital of the Aswan Governorate.

Aswan is a busy market and tourist centre located just north of the Aswan Dams on the east bank of the Nile at the first cataract. The modern city has expanded and includes the formerly separate community on the island of Elephantine.

The city is part of the UNESCO Creative Cities Network in the category of craft and folk art.

"Aswan" was formerly spelled "Assuan" or "Assouan". Spellings in other languages include ; Ancient Egyptian: ; ; .

Aswan is the ancient city of Swenett, later known as Syene, which in antiquity was the frontier town of Ancient Egypt facing the south. Swenett is supposed to have derived its name from an Egyptian goddess with the same name. This goddess later was identified as Eileithyia by the Greeks and Lucina by the Romans during their occupation of Ancient Egypt because of the similar association of their goddesses with childbirth, and of which the import is "the opener". The ancient name of the city also is said to be derived from the Egyptian symbol for "trade", or "market".

Because the Ancient Egyptians oriented themselves toward the origin of the life-giving waters of the Nile in the south, and as Swenett was the southernmost town in the country, Egypt always was conceived to "open" or begin at Swenett. The city stood upon a peninsula on the right (east) bank of the Nile, immediately below (and north of) the first cataract of the flowing waters, which extend to it from Philae. Navigation to the delta was possible from this location without encountering a barrier.

The stone quarries of ancient Egypt located here were celebrated for their stone, and especially for the granitic rock called Syenite. They furnished the colossal statues, obelisks, and monolithal shrines that are found throughout Egypt, including the pyramids; and the traces of the quarrymen who worked in these 3,000 years ago are still visible in the native rock. They lie on either bank of the Nile, and a road, in length, was cut beside them from Syene to Philae.

Swenett was equally important as a military station as a place of traffic. Under every dynasty it was a garrison town; and here tolls and customs were levied on all boats passing southwards and northwards. Around 330, the legion stationed here received a bishop from Alexandria; this later became the Coptic Diocese of Syene. The city is mentioned by numerous ancient writers, including Herodotus, Strabo, Stephanus of Byzantium, Ptolemy, Pliny the Elder, Vitruvius, and it appears on the Antonine Itinerary. It is also mentioned in the Book of Ezekiel and the Book of Isaiah.
The latitude of the city that would become Aswan – located at 24° 5′ 23″ – was an object of great interest to the ancient geographers. They believed that it was seated immediately under the tropic, and that on the day of the summer solstice, a vertical staff cast no shadow. They noted that the sun's disc was reflected in a well at noon. This statement is only approximately correct; at the summer solstice, the shadow was only of the staff, and so could scarcely be discerned, and the northern limb of the Sun's disc would be nearly vertical.
However, Eratosthenes used this information together with measurements of the shadow length on the solstice at Alexandria to perform the first known calculation of the circumference of the Earth.

The Nile is nearly wide above Aswan. From this frontier town to the northern extremity of Egypt, the river flows for more than without bar or cataract. The voyage from Aswan to Alexandria usually took 21 to 28 days in favourable weather.

Aswan has a hot desert climate (Köppen climate classification "BWh") like the rest of Egypt. Aswan and Luxor have the hottest summer days of any city in Egypt. Aswan is one of the hottest, sunniest and driest cities in the world. Average high temperatures are consistently above during summer (June, July, August and also September) while average low temperatures remain above . Summers are long, prolonged and extremely hot. Average high temperatures remain above during the coldest month of the year while average low temperatures remain above . Winters are short, brief and extremely warm. Wintertime is very pleasant and enjoyable while summertime is unbearably hot with blazing sunshine although desert heat is dry.

The climate of Aswan is extremely dry year-round, with less than of average annual precipitation. The desert city is one of the driest ones in the world, and rainfall doesn't occur every year, as of early 2001, the last rain there was seven years earlier. Aswan is one of the least humid cities on the planet, with an average relative humidity of only 26%, with a maximum mean of 42% during winter and a minimum mean of 16% during summer.

The weather of Aswan is extremely clear, bright and sunny year-round, in all seasons, with a low seasonal variation, with almost 4,000 hours of annual sunshine, very close to the maximum theoretical sunshine duration. Aswan is one of the sunniest places on Earth.

The highest record temperature was on July 4, 1918, and the lowest record temperature was on January 6, 1989.

In 1999, South Valley University was inaugurated and it has three branches; Aswan, Qena and Hurghada. The university grew steadily and now it is firmly established as a major institution of higher education in Upper Egypt. Aswan branch of Assiut University began in 1973 with the Faculty of Education and in 1975 the Faculty of Science was opened. Aswan branch has five faculties namely; Science, Education, Engineering, Arts, Social Works and Institute of Energy. The Faculty of Science in Aswan has six departments. Each department has one educational programme: Chemistry, Geology, Physics and Zoology. Except Botany Department, which has three educational programmes: Botany, Environmental Sciences and Microbiology; and Mathematics Department, which has two educational programmes: Mathematics and Computer Science. The Faculty of Science awards the following degrees: Bachelor of Science in nine educational programmes, Higher Diploma, Master of Science and Philosophy Doctor of Science.
Aswan also has Aswan Higher Institute of Social Work that was established in 1975 making it the oldest private higher institute of Social Work in Upper Egypt

Aswan is served by the Aswan International Airport. Train and bus service is also available. Taxi and rickshaw are used for transport here.

Aswan is twinned with:



</doc>
<doc id="2519" url="https://en.wikipedia.org/wiki?curid=2519" title="Adelaide of Italy">
Adelaide of Italy

Adelaide of Italy (93116 December 999 AD) (; ), also called Adelaide of Burgundy, was a Holy Roman Empress by marriage to Holy Roman Emperor Otto the Great; she was crowned as the Holy Roman Empress with him by Pope John XII in Rome on 2 February 962. She was regent of the Holy Roman Empire as the guardian of her grandson in 991-995.

Born in Orbe Castle, Orbe, Kingdom of Upper Burgundy (now in modern-day Switzerland), she was the daughter of Rudolf II of Burgundy, a member of the Elder House of Welf, and Bertha of Swabia. Her first marriage, at the age of fifteen, was to the son of her father's rival in Italy, Lothair II, the nominal King of Italy; the union was part of a political settlement designed to conclude a peace between her father and Hugh of Provence, the father of Lothair. Their daughter, Emma of Italy, was born about 948.

The Calendar of Saints states that her first husband was poisoned by the holder of real power, his successor, Berengar II of Italy, who attempted to cement his political power by forcing her to marry his son, Adalbert; when she refused and fled, she was tracked down and imprisoned for four months at Garda.

According to Adelaide's contemporary biographer, Odilo of Cluny, she managed to escape from captivity. After a time spent in the marshes nearby, she was rescued by a priest and taken to a "certain impregnable fortress," likely the fortified town of Canossa Castle near Reggio. She managed to send an emissary to Otto I, and asked the East Frankish king for his protection. The widow met Otto at the old Lombard capital of Pavia and they married in 951. Pope John XII crowned Otto Holy Roman Emperor in Rome on 2 February 962, and, breaking tradition, also crowned Adelaide as Holy Roman Empress.

In Germany, the crushing of a revolt in 953 by Liudolf, Otto's son by his first marriage, cemented Adelaide's position, for she retained all her dower lands. She and their eleven-year-old son, Otto II, accompanied Otto in 966 on his third expedition to Italy, where Otto restored the newly elected Pope John XIII to his throne (and executed some of the Roman rioters who had deposed him). Adelaide remained in Rome for six years while Otto ruled his kingdom from Italy. Their son Otto II was crowned co-emperor in 967, then married the Byzantine princess Theophanu in April 972, resolving the conflict between the two empires in southern Italy, as well as ensuring the imperial succession. Adelaide and her husband then returned to Germany, where Otto died in May 973, at the same Memleben palace where his father had died 37 years earlier.

In 983, her son Otto II died and was succeeded by her grandson Otto III under the regency of his mother Adelaide's daughter-in-law Dowager Empress Theophanu. When Theophanu died in 990, Adelaide assumed regency on behalf of her grandson the Emperor until he reached legal majority four years later. Adelaide resigned as regent when Otho III was declared of legal majority in 995.

Adelaide had long entertained close relations with Cluny, then the center of the movement for ecclesiastical reform, and in particular with its abbots Majolus and Odilo. She retired to a nunnery she had founded in c. 991 at Selz in Alsace.

On her way to Burgundy to support her nephew Rudolf III against a rebellion, she died at Selz Abbey on 16 December 999, days short of the millennium she thought would bring the Second Coming of Christ. She had constantly devoted herself to the service of the church and peace, and to the empire as guardian of both; she also interested herself in the conversion of the Slavs. She was thus a principal agent—almost an embodiment—of the work of the pre-schism Orthodox Catholic Church at the end of the Early Middle Ages in the construction of the religious culture of Central Europe.
Some of her relics are preserved in a shrine in Hanover. Her feast day, 16 December, is still kept in many German dioceses.

In 947, Adelaide was married to King Lothair II of Italy. The union produced one child:

In 951, Adelaide was married to King Otto I, the future Holy Roman Emperor. The union produced four children:







</doc>
<doc id="2524" url="https://en.wikipedia.org/wiki?curid=2524" title="Airbus A300">
Airbus A300

The Airbus A300 is a wide-body twin-engine jet airliner developed and manufactured by Airbus. Formally announced in 1969 and first flying in October 1972, it holds the distinction of being the world's first twin-engined widebody airliner; it was also the first product of Airbus Industrie, a consortium of European aerospace manufacturers, now known as Airbus. The A300 can typically seat 266 passengers in a two-class layout, with a maximum range of when fully loaded, depending on model.

Development of the A300 began during the 1960s as a European collaborative project between various aircraft manufacturers in the United Kingdom, France, and West Germany. In September 1967, the participating nations signed a Memorandum of Understanding to manufacture the aircraft. The British withdrew from the project on 10 April 1969. A new agreement was reached between Germany and France on 29 May 1969, and Airbus Industrie was formally created on 18 December 1970 to develop and produce the A300. The type first flew on 28 October 1972.

Air France, the launch customer for the A300, introduced the type into service on 30 May 1974. Following a period of limited customer demand, the A300 achieved several large sales in 1978, after which the type was viewed to have proven itself and orders came in at a steady rate across the next three decades. During the 1990s, the A300 became popular with various freight operators, and several different cargo aircraft variants were produced with many from former operators of passengers variants like Korean Air. Production of the A300 ceased in July 2007, along with its smaller A310 derivative. The freighter sales for which the A300 had previously competed in later life are instead fulfilled by the A330-200F, a derivative of the newer Airbus A330.

During the 1960s, European aircraft manufacturers such as Hawker Siddeley and the British Aircraft Corporation, based in the UK, and Sud Aviation of France, had ambitions to build a new 200-seat airliner for the growing civil aviation market. While studies were performed and considered, such as a stretched twin-engine variant of the Hawker Siddeley Trident and an expanded development of the British Aircraft Corporation BAC One-Eleven, designated the BAC Two-Eleven, it was recognized that if each of the European manufacturers were to launch similar aircraft into the market at the same time, neither would achieve sales volume needed to make them viable. In 1965, a British government study, known as the Plowden Report, had found British aircraft production costs to be between 10% and 20% higher than American counterparts due to shorter production runs, which was in part due to the fractured European market. To overcome this factor, the report recommended the pursuit of multinational collaborative projects between the region's leading aircraft manufacturers.

European manufacturers were keen to explore prospective programs; the proposed 260-seat wide-body "HBN 100" between Hawker Siddeley, Nord Aviation, and Breguet Aviation being one such example. National governments were also keen to support such efforts amid a belief that American manufacturers could dominate the European Economic Community; in particular, Germany had ambitions for a multinational airliner project to invigorate its aircraft industry, which had declined considerably following the Second World War. During the mid-1960s, both Air France and American Airlines had expressed interest in a short-haul twin-engine wide-body aircraft, indicating a market demand for such an aircraft to be produced. In July 1967, during a high-profile meeting between French, German, and British ministers, an agreement was made for greater cooperation between European nations in the field of aviation technology, and "for the joint development and production of an airbus". The word "airbus" at this point was a generic aviation term for a larger commercial aircraft, and was considered acceptable in multiple languages, including French.

Shortly after the July 1967 meeting, French engineer Roger Béteille was appointed as the technical director of what would become the A300 program, while Henri Ziegler, chief operating office of Sud Aviation, was appointed as the general manager of the organization and German politician Franz Josef Strauss became the chairman of the supervisory board. Béteille drew up an initial work share plan for the project, under which French firms would produce the aircraft's cockpit, the control systems, and lower-center portion of the fuselage, Hawker Siddeley would manufacture the wings, while German companies would produce the forward, rear and upper part of the center fuselage sections. Addition work included moving elements of the wings being produced in the Netherlands, and Spain producing the horizontal tail plane.

An early design goal for the A300 that Béteille had stressed the importance of was the incorporation of a high level of technology, which would serve as a decisive advantage over prospective competitors. As such, the A300 would feature the first use of composite materials of any passenger aircraft, the leading and trailing edges of the tail fin being composed of glass fibre reinforced plastic. Béteille opted for English as the working language for the developing aircraft, as well against using Metric instrumentation and measurements, as most airlines already had US-built aircraft. These decisions were partially influenced by feedback from various airlines, such as Air France and Lufthansa, as an emphasis had been placed on determining the specifics of what kind of aircraft that potential operators were seeking. According to Airbus, this cultural approach to market research had been crucial to the company's long term success.

On 26 September 1967, the British, French, and West German governments signed a Memorandum of Understanding to start development of the 300-seat Airbus A300. At this point, the A300 was only the second major joint aircraft programme in Europe, the first being the Anglo-French Concorde. Under the terms of the memorandum, Britain and France were each to receive a 37.5 per cent work share on the project, while Germany received a 25 per cent share. Sud Aviation was recognized as the lead company for A300, with Hawker Siddeley being selected as the British partner company. At the time, the news of the announcement had been clouded by the British Government's support for the Airbus, which coincided with its refusal to back BAC's proposed competitor, the BAC 2-11, despite a preference for the latter expressed by British European Airways (BEA). Another parameter was the requirement for a new engine to be developed by Rolls-Royce to power the proposed airliner; a derivative of the in-development Rolls-Royce RB211, the triple-spool RB207, capable of producing of 47,500 lbf.

In December 1968, the French and British partner companies (Sud Aviation and Hawker Siddeley) proposed a revised configuration, the 250-seat Airbus A250. It had been feared that the original 300-seat proposal was too large for the market, thus it had been scaled down to produce the A250. The dimensional changes involved in the shrink reduced the length of the fuselage by 5.62 meters and the diameter by 0.8 meters, reducing the overall weight by 25 tonnes. For increased flexibility, the cabin floor was raised so that standard LD3 freight containers could be accommodated side-by-side, allowing more cargo to be carried. Refinements made by Hawker Siddeley to the wing's design provided for greater lift and overall performance; this gave the aircraft the ability to climb faster and attain a level cruising altitude sooner than any other passenger aircraft. It was later renamed the A300B.

Perhaps the most significant change of the A300B was that it would not require new engines to be developed, being of a suitable size to be powered by Rolls-Royce's RB211, or alternatively the American Pratt & Whitney JT9D and General Electric CF6 powerplants; this switch was recognized as considerably reducing the project's development costs. To attract potential customers in the US market, it was decided that General Electric CF6-50 engines would power the A300 in place of the British RB207; these engines would be produced in co-operation with French firm Snecma. By this time, Rolls-Royce had been concentrating their efforts upon developing their RB211 turbofan engine instead and progress on the RB207's development had been slow for some time, the firm having suffered due to funding limitations, both of which had been factors in the engine switch decision.

On 10 April 1969, a few months after the decision to drop the RB207 had been announced, the British government announced that they would withdraw from the Airbus venture. In response, West Germany proposed to France that they would be willing to contribute up to 50% of the project's costs if France was prepared to do the same. Additionally, the managing director of Hawker Siddeley, Sir Arnold Alexander Hall, decided that his company would remain in the project as a favoured sub-contractor, developing and manufacturing the wings for the A300, which would later become pivotal in later versions' impressive performance from short domestic to long intercontinental flights. Hawker Siddeley spent £35 million of its own funds, along with a further £35 million loan from the West German government, on the machine tooling to design and produce the wings.

On 29 May 1969, during the Paris Air Show, French transport minister Jean Chamant and German economics minister Karl Schiller signed an agreement officially launching the Airbus A300, the world's first twin-engine widebody airliner. The intention of the project was to produce an aircraft that was smaller, lighter, and more economical than its three-engine American rivals, the McDonnell Douglas DC-10 and the Lockheed L-1011 TriStar. In order to meet Air France's demands for an aircraft larger than 250-seat A300B, it was decided to stretch the fuselage to create a new variant, designated as the A300B2, which would be offered alongside the original 250-seat A300B, henceforth referred to as the A300B1. On 3 September 1970, Air France signed a letter of intent for six A300s, marking the first order to be won for the new airliner.

In the aftermath of the Paris Air Show agreement, it was decided that, in order to provide effective management of responsibilities, a Groupement d'intérêt économique would be established, allowing the various partners to work together on the project while remaining separate business entities. On 18 December 1970, Airbus Industrie was formally established following an agreement between Aérospatiale (the newly merged Sud Aviation and Nord Aviation) of France and the antecedents to Deutsche Aerospace of Germany, each receiving a 50 per cent stake in the newly formed company. In 1971, the consortium was joined by a third full partner, the Spanish firm CASA, who received a 4.2 per cent stake, the other two members reducing their stakes to 47.9 per cent each. In 1979, Britain joined the Airbus consortium via British Aerospace, which Hawker Siddeley had merged into, which acquired a 20 per cent stake in Airbus Industrie with France and Germany each reducing their stakes to 37.9 per cent.

Airbus Industrie was initially headquartered in Paris, which is where design, development, flight testing, sales, marketing, and customer support activities were centered; the headquarters was relocated to Toulouse in January 1974. The final assembly line for the A300 was located adjacent to Toulouse Blagnac International Airport. The manufacturing process necessitated transporting each aircraft section being produced by the partner companies scattered across Europe to this one location. The combined use of ferries and roads were used for the assembly of the first A300, however this was time-consuming and not viewed as ideal by Felix Kracht, Airbus Industrie's production director. Kracht's solution was to have the various A300 sections brought to Toulouse by a fleet of Boeing 377-derived Aero Spacelines Super Guppy aircraft, by which means none of the manufacturing sites were more than two hours away. Having the sections airlifted in this manner made the A300 the first airliner to use just-in-time manufacturing techniques, and allowed each company to manufacture its sections as fully equipped, ready-to-fly assemblies.

In September 1969, construction of the first prototype A300 began. On 28 September 1972, this first prototype was unveiled to the public, it conducted its maiden flight from Toulouse–Blagnac International Airport on 28 October that year. This maiden flight, which was performed a month ahead of schedule, lasted for one hour and 25 minutes; the captain was Max Fischl and the first officer was Bernard Ziegler, son of Henri Ziegler. On 5 February 1973, the second prototype performed its maiden flight. The flight test program, which involved a total of four aircraft, was relatively problem-free, accumulating 1,580 flight hours throughout. In September 1973, as part of promotional efforts for the A300, the new aircraft was taken on a six-week tour around North America and South America, to demonstrate it to airline executives, pilots, and would-be customers. Amongst the consequences of this expedition, it had allegedly brought the A300 to the attention of Frank Borman of Eastern Airlines, one of the "big four" U.S. airlines.

On 15 March 1974, type certificates were granted for the A300 from both German and French authorities, clearing the way for its entry into revenue service. On 23 May 1974, Federal Aviation Administration (FAA) certification was received. The first production model, the A300B2, entered service in 1974, followed by the A300B4 one year later. Initially, the success of the consortium was poor, in part due to the economic consequences of the 1973 oil crisis, but by 1979 there were 81 A300 passenger liners in service with 14 airlines, alongside 133 firm orders and 88 options. Ten years after the official launch of the A300, the company had achieved a 26 per cent market share in terms of dollar value, enabling Airbus Industries to proceed with the development of its second aircraft, the Airbus A310. It was the launch of the Airbus A320 in 1987 that firmly established Airbus as a major player in the aircraft market – over 400 orders were placed before the narrow-body airliner had flown its first flight, compared to 15 for the A300 in 1972.

The Airbus A300 is a wide-body medium-to-long range airliner; it has the distinction of being the first twin-engine wide-body aircraft in the world. In 1977, the A300 became the first ETOPS-compliant aircraft, due to its high performance and safety standards. Another world-first of the A300 is the use of composite materials on a commercial aircraft, which was used on both secondary and later primary airframe structures, decreasing overall weight and improving cost-effectiveness. Other firsts included the pioneering use of center-of-gravity control, achieved by transferring fuel between various locations across the aircraft, and electrically signaled secondary flight controls.

The A300 is powered by a pair of underwing turbofan engines, either General Electric CF6 and Pratt & Whitney JT9D engines; the sole use of underwing engine pods allowed for any suitable turbofan engine to be more readily used. The lack of a third tail-mounted engine, as per the trijet configuration used by some competing airliners, allowed for the wings to be located further forwards and to reduce the size of the vertical stabilizer and elevator, which had the effect of increasing the aircraft's flight performance and fuel efficiency.

Airbus partners had employed the latest technology, some of which having been derived from Concorde, on the A300. According to Airbus, new technologies adopted for the airliner were selected principally for increased safety, operational capability, and profitability. Upon entry into service in 1974, the A300 was a very advanced plane, which went on to influence later airliner designs. The technological highlights include:

Later A300s incorporated other advanced features such as the Forward-Facing Crew Cockpit, which enabled a two-pilot flight crew to fly the aircraft alone without the need for a flight engineer, the functions of which were automated; this two-man cockpit concept was a world-first for a wide-body aircraft. Glass cockpit flight instrumentation, which used cathode ray tube (CRT) monitors to display flight, navigation, and warning information, along with fully digital dual autopilots and digital flight control computers for controlling the spoilers, flaps, and leading-edge slats, were also adopted upon later-built models. Additional composites were also made use of, such as carbon-fiber-reinforced polymer (CFRP), as well as their presence in an increasing proportion of the aircraft's components, including the spoilers, rudder, air brakes, and landing gear doors. Another feature of later aircraft were the addition of wingtip fences, which generated greater aerodynamic performance (first introduced on the A310-300).

In addition to passenger duties, the A300 became widely used by air freight operators; according to Airbus, it is the best selling freight aircraft of all time. Various variants of the A300 were built to meet customer demands, often for diverse roles such as aerial refueling tankers, freighter models (new-build and conversions), combi aircraft, military airlifter, and VIP transport. Perhaps the most visually unique of the variants is the A300-600ST Beluga, a oversize cargo-carrying model operated by Airbus to carry aircraft sections between their manufacturing facilities. The A300 was the basis for, and retained a high level of commonality with, the second airliner produced by Airbus, the smaller Airbus A310.

On 23 May 1974, the first A300 to enter service performed the first commercial flight of the type, flying from Paris to London, for Air France.

Immediately after the launch, sales of the A300 were weak for some years, with most orders going to airlines that had an obligation to favor the domestically made product – notably Air France and Lufthansa, the first two airlines to place orders for the type. Following the appointment of Bernard Lathière as Henri Ziegler's replacement, an aggressive sales approach was adopted. Indian Airlines was the world's first domestic airline to purchase the A300, ordering three aircraft with three options. However, between December 1975 and May 1977, there were no sales for the type. During this period a number of "whitetail" A300s – completed but unsold aircraft – were completed and stored at Toulouse, and production fell to half an aircraft per month amid calls to pause production completely.

During the flight testing of the A300B2, Airbus held a series of talks with Korean Air on the topic of developing a longer-range version of the A300, which would become the A300B4. In September 1974, Korean Air placed an order for 4 A300B4s with options for 2 further aircraft; this sale was viewed as significant as it was the first non-European international airline to order Airbus aircraft. Airbus had viewed South-East Asia as a vital market that was ready to be opened up and believed Korean Air to be the 'key'.

It was becoming clear that the whole concept of a short haul widebody was flawed. Airlines operating the A300 on short haul routes were forced to reduce frequencies to try and fill the aircraft. As a result, they lost passengers to airlines operating more frequent narrow body flights. The supposed widebody comfort which it was assumed passengers would demand was illusory. Eventually, Airbus had to build its own narrowbody aircraft (the A320) to compete with the Boeing 737 and McDonnell Douglas DC-9/MD-80. The savior of the A300 was the advent of Extended Range Twin Operations (ETOPS), a revised FAA rule which allows twin-engine jets to fly long-distance routes that were previously off-limits to them. This enabled Airbus to develop the aircraft as a medium/long range airliner.

In 1977, US carrier Eastern Air Lines leased four A300s as an in-service trial. Frank Borman, ex-astronaut and the then CEO of the airline, was impressed that the A300 consumed 30% less fuel, even more economical than expected, in contrast to his fleet of Tristars and proceeded to order 23 A300s, becoming the first U.S. customer for the type. This order is often cited as the point at which Airbus came to be seen as a serious competitor to the large American aircraft-manufacturers Boeing and McDonnell Douglas. Aviation author John Bowen alleged that various concessions, such as loan guarantees from European governments and compensation payments, were a factor in the decision as well. The Eastern Air Lines breakthrough was shortly followed by an order from Pan Am. From then on, the A300 family sold well, eventually reaching a total of 816 delivered aircraft.
In December 1977, Aerocondor Colombia became the first Airbus operator in Latin America, leasing one Airbus A300B4-2C, named "Ciudad de Barranquilla".

During the late 1970s, Airbus adopted a so-called 'Silk Road' strategy, targeting airlines in the Far East. As a result, The aircraft found particular favor with Asian airlines, being bought by Japan Air System, Korean Air, China Eastern Airlines, Thai Airways International, Singapore Airlines, Malaysia Airlines, Philippine Airlines, Garuda Indonesia, China Airlines, Pakistan International Airlines, Indian Airlines, Trans Australia Airlines and many others. As Asia did not have restrictions similar to the FAA 60-minutes rule for twin-engine airliners which existed at the time, Asian airlines used A300s for routes across the Bay of Bengal and South China Sea.

In 1977, the A300B4 became the first ETOPS compliant aircraft – its high performance and safety standards qualified it for Extended Twin Engine Operations over water, providing operators with more versatility in routing. In 1982 Garuda Indonesia became the first airline to fly the A300B4-200FF. By 1981, Airbus was growing rapidly, with over 300 aircraft sold and options for 200 more planes for over forty airlines.

In 1989, Chinese operator China Eastern Airlines received its first A300; by 2006, the airline operated around 18 A300s, making it the largest operator of both the A300 and the A310 at that time. On 31 May 2014, China Eastern officially retired the last A300-600 in its fleet, having begun drawing down the type in 2010.

From 1997 to 2014, a single A300, designated A300 Zero-G, was operated by the European Space Agency (ESA), centre national d'études spatiales (CNES) and the German Aerospace Center (DLR) as a reduced-gravity aircraft for conducting research into microgravity; the A300 is the largest aircraft to ever have been used in this capacity. A typical flight would last for two and a half hours, enabling up to 30 parabolas to be performed per flight.

By the 1990s, the A300 was being heavily promoted as a cargo freighter. The largest freight operator of the A300 is FedEx Express, which has 68 A300 aircraft in service. UPS Airlines also operates 52 freighter versions of the A300. The final version was the A300-600R and is rated for 180-minute ETOPS. The A300 has enjoyed renewed interest in the secondhand market for conversion to freighters; large numbers were being converted during the late 1990s. The freighter versions – either new-build A300-600s or converted ex-passenger A300-600s, A300B2s and B4s – account for most of the world freighter fleet after the Boeing 747 freighter.

The A300 provided Airbus the experience of manufacturing and selling airliners competitively. The basic fuselage of the A300 was later stretched (A330 and A340), shortened (A310), or modified into derivatives (A300-600ST "Beluga" Super Transporter). In March 2006, Airbus announced the impending closure of the A300/A310 final assembly line, making them the first Airbus aircraft to be discontinued. The final production A300, an A300F freighter, performed its initial flight on 18 April 2007, and was delivered to FedEx Express on 12 July 2007. Airbus has announced a support package to keep A300s flying commercially until at least 2025.

The useful life of the UPS fleet of 52 delivered from 2000 to 2006 will be extended to 2035 by a flight deck upgrade based around Honeywell Primus Epic avionics : new displays and flight management system (FMS), improved 3-D weather radar, a central maintenance system, and a new version of the current enhanced ground proximity warning system.
With a light usage of only two to three cycles per day, it will not reach the maximum number of cycles by then.
The first modification will be made at Airbus Toulouse in 2019 and certified in 2020.

As of July 2017, there are 211 A300's in service with 22 operators, with the largest operator being FedEx Express with 68 A300-600F aircraft.

Only two were built: the first prototype, registered F-WUAB, then F-OCAZ, and a second aircraft, F-WUAC, which was leased in November 1974 to Trans European Airways (TEA) and re-registered OO-TEF. TEA instantly subleased the aircraft for six weeks to Air Algérie, but continued to operate the aircraft until 1990. It had accommodation for 300 passengers (TEA) or 323 passengers (Air Algérie) with a maximum weight of 132,000 kg and two General Electric CF6-50A engines of 220 kN thrust. The A300B1 was five frames shorter than the later production versions, being only in length.

The first production version. Powered by General Electric CF6 or Pratt & Whitney JT9D engines (the same engines that powered the Boeing 747-100) of between 227 and 236 kN thrust, it entered service with Air France in May 1974. The prototype A300B2 made its first flight on 28 June 1973 and was certificated by the French and German authorities on 15 March 1974 and FAA approval followed on 30 May 1974. The first production A300B2 (A300 number 5) made its maiden flight on 15 April 1974 and was handed over to Air France a few weeks later on 10 May 1974. The A300B2 entered revenue service on 23 May 1974 between Paris and London.

The major production version features a centre fuel tank for increased fuel capacity (47,500 kg) and new wing-root Krüger flaps which were later made available as an option for the B2. Production of the B2 and B4 totalled 248. The first A300B4 (the 9th A300) flew on 25 December 1974 and was certified on 26 March 1975. The first delivery was made to Bavaria Germanair (which later merged into Hapag Lloyd) on 23 May 1975.

Officially designated A300B4-600, this version is nearly the same length as the B2 and B4 but has increased space because it uses the A310 rear fuselage and horizontal tail. It has higher-power CF6-80 or Pratt & Whitney PW4000 engines and uses the Honeywell 331-250 auxiliary power unit (APU). Other changes include an improved wing featuring a recambered trailing edge, the incorporation of simpler single-slotted Fowler flaps, the deletion of slat fences, and the removal of the outboard ailerons after they were deemed unnecessary on the A310. The A300-600 made its first flight on 8 July 1983 and entered service later that year with Saudi Arabian Airlines. A total of 313 A300-600s (all versions) have been sold. The A300-600 also has a similar cockpit to the A310, eliminating the need for a flight engineer. The FAA issues a single type rating which allows operation of both the A310 and A300-600.

Introduced a shorter fuselage, a new, higher aspect ratio wing, smaller horizontal tail and two-crew operation. It was available in standard −200 and the Extended range −300 with range in both passenger and full-cargo versions.

It was also available as a military tanker/transport serving the Canadian Forces and German Air Force. Sales total 260, although five of these (ordered by Iraqi Airways) were never built.

Commonly referred to as the Airbus Beluga or "Airbus Super Transporter," these five airframes are used by Airbus to ferry parts between the company's disparate manufacturing facilities, thus enabling workshare distribution. They replaced the four Aero Spacelines Super Guppys previously used by Airbus.

ICAO code: A3ST

As of September 2015, the A300 has been involved in 70 accidents and incidents, including 32 hull-losses and 1,435 fatalities.




Four A300s are currently preserved:



</doc>
<doc id="2526" url="https://en.wikipedia.org/wiki?curid=2526" title="Agostino Carracci">
Agostino Carracci

Agostino Carracci (or Caracci) (16 August 1557 – 22 March 1602) was an Italian painter, printmaker, tapestry designer, and art teacher. He was, together with his brother, Annibale Carracci, and cousin, Ludovico Carracci, one of the founders of the Accademia degli Incamminati (Academy of the Progressives) in Bologna. This teaching academy promoted the Carracci emphasized drawing from life. It promoted progressive tendencies in art and was a reaction to the Mannerist distortion of anatomy and space. The academy helped propel painters of the School of Bologna to prominence.

Agostino Carracci was born in Bologna as the son of a tailor. he was the elder brother of Annibale Carracci and the cousin of Ludovico Carracci. He initially trained as a goldsmith. He later studied painting, first with Prospero Fontana, who had been Lodovico's master, and later with Bartolomeo Passarotti. He traveled to Parma to study the works of Correggio. Accompanied by his brother Annibale, he spent a long time in Venice, where he trained as an engraver under the renowned Cornelis Cort. Starting from 1574 he worked as a reproductive engraver, copying works of 16th century masters such as Federico Barocci, Tintoretto, Antonio Campi, Veronese and Correggio. He also produced some original prints, including two etchings.

He traveled to Venice (1582, 1587–1589) and Parma (1586–1587). Together with Annibale and Ludovico he worked in Bologna on the fresco cycles in Palazzo Fava ("Histories of Jason and Medea", 1584) and Palazzo Magnani ("Histories of Romulus", 1590–1592). In 1592 he also painted the "Communion of St. Jerome", now in the Pinacoteca di Bologna and considered his masterwork. In 1620, Giovanni Lanfranco, a pupil of the Carracci, famously accused another Carracci student, Domenichino, of plagiarizing this painting. From 1586 is his altarpiece of the "Madonna with Child and Saints", in the National Gallery of Parma. In 1598 Carracci joined his brother Annibale in Rome, to collaborate on the decoration of the Gallery in Palazzo Farnese. From 1598–1600 is a "triple Portrait", now in Naples, an example of genre painting. In 1600 he was called to Parma by Duke Ranuccio I Farnese to begin the decoration of the Palazzo del Giardino, but he died before it was finished.

Agostino's son Antonio Carracci was also a painter, and attempted to compete with his father's Academy.

An engraving by Agostino Carraci after the painting "Love in the Golden Age" by the 16th-century Flemish painter Paolo Fiammingo was the inspiration for Matisse's "Le bonheur de vivre" (Joy of Life).



</doc>
<doc id="2528" url="https://en.wikipedia.org/wiki?curid=2528" title="Adenylyl cyclase">
Adenylyl cyclase

Adenylyl cyclase (, also commonly known as adenyl cyclase and adenylate cyclase, abbreviated AC) is an enzyme with key regulatory roles in essentially all cells. It is the most polyphyletic known enzyme: six distinct classes have been described, all catalyzing the same reaction but representing unrelated gene families with no known sequence or structural homology. The best known class of adenylyl cyclases is class III or AC-III (Roman numerals are used for classes). AC-III occurs widely in eukaryotes and has important roles in many human tissues.

All classes of adenylyl cyclase catalyse the conversion of adenosine triphosphate (ATP) to 3',5'-cyclic AMP (cAMP) and pyrophosphate. Magnesium ions are generally required and appears to be closely involved in the enzymatic mechanism. The cAMP produced by AC then serves as a regulatory signal via specific cAMP-binding proteins, either transcription factors, enzymes (e.g., cAMP-dependent kinases), or ion transporters.

The first class of adenylyl cyclases occur in many bacteria including "E. coli" (as CyaA [unrelated to the Class II enzyme]). This was the first class of AC to be characterized. It was observed that "E. coli" deprived of glucose produce cAMP that serves as an internal signal to activate expression of genes for importing and metabolizing other sugars. cAMP exerts this effect by binding the transcription factor CRP, also known as CAP. Class I AC's are large cytosolic enzymes (~100 kDa) with a large regulatory domain (~50 kDa) that indirectly senses glucose levels. , no crystal structure is available for class I AC.

Some indirect structural information is available for this class. It is known that the N-terminal half is the catalytic portion, and that it requires two Mg ions. S103, S113, D114, D116 and W118 are the five absolutely essential residues. The class I catalytic domain () belongs to the same superfamily () as the palm domain of DNA polymerase beta (). Aligning its sequence onto the structure onto a related archaeal CCA tRNA nucleotidyltransferase () allows for assignment of the residues to specific functions: γ-phosphate binding, structual stablization, DxD motif for metal ion binding, and finally ribose binding.

These adenylyl cyclases are toxins secreted by pathogenic bacteria such as "Bacillus anthracis", "Bordetella pertussis", "Pseudomonas aeruginosa", and "Vibrio vulnificus" during infections. These bacteria also secrete proteins that enable the AC-II to enter host cells, where the exogenous AC activity undermines normal cellular processes. The genes for Class II ACs are known as cyaA, one of which is anthrax toxin. Several crystal structures are known for AC-II enzymes.

These adenylyl cyclases are the most familiar based on extensive study due to their important roles in human health. They are also found in some bacteria, notably "Mycobacterium tuberculosis" where they appear to have a key role in pathogenesis. Most AC-III's are integral membrane proteins involved in transducing extracellular signals into intracellular responses. A Nobel Prize was awarded to Earl Sutherland in 1971 for discovering the key role of AC-III in human liver, where adrenaline indirectly stimulates AC to mobilize stored energy in the "fight or flight" response. The effect of adrenaline is via a G protein signaling cascade, which transmits chemical signals from outside the cell across the membrane to the inside of the cell (cytoplasm). The outside signal (in this case, adrenaline) binds to a receptor, which transmits a signal to the G protein, which transmits a signal to adenylyl cyclase, which transmits a signal by converting adenosine triphosphate to cyclic adenosine monophosphate (cAMP). cAMP is known as a second messenger.

Cyclic AMP is an important molecule in eukaryotic signal transduction, a so-called second messenger. Adenylyl cyclases are often activated or inhibited by G proteins, which are coupled to membrane receptors and thus can respond to hormonal or other stimuli. Following activation of adenylyl cyclase, the resulting cAMP acts as a second messenger by interacting with and regulating other proteins such as protein kinase A and cyclic nucleotide-gated ion channels.

Photoactivatable adenylyl cyclase (PAC) was discovered in "Euglena gracilis" and can be expressed in other organisms through genetic manipulation. Shining blue light on a cell containing PAC activates it and abruptly increases the rate of conversion of ATP to cAMP. This is a useful technique for researchers in neuroscience because it allows them to quickly increase the intracellular cAMP levels in particular neurons, and to study the effect of that increase in neural activity on the behavior of the organism. For example, PAC expression in certain neurons has been shown to alter the grooming behavior in fruit flies exposed to blue light. A green-light activated rhodopsin adenylyl cyclase (CaRhAC) has recently been engineered by modifying the nuclecotide binding pocket of rhodopsin guanylyl cyclase from the fungus "Catenaria anguillulae".

Most class III adenylyl cyclases are transmembrane proteins with 12 transmembrane segments. The protein is organized with 6 transmembrane segments, then the C1 cytoplasmic domain, then another 6 membrane segments, and then a second cytoplasmic domain called C2. The important parts for function are the N-terminus and the C1 and C2 regions. The C1a and C2a subdomains are homologous and form an intramolecular 'dimer' that forms the active site. In "Mycobacterium tuberculosis" and many other bacterial cases, the AC-III polypeptide is only half as long, comprising one 6-transmembrane domain followed by a cytoplasmic domain, but two of these form a functional homodimer that resembles the mammalian architecture with two active sites. In non-animal class III ACs, the catalytic cytoplasmic domain is seen associated with other (not necessarily transmembrane) domains.

Class III adenylyl cyclase domains can be further divided into four subfamilies, termed class IIIa through IIId. Animal membrane-bound ACs belong to class IIIa.

The reaction happens with two metal cofactors (Mg or Mn) coordinated to the two aspartate residues on C1. They perform a nucleophilic attack of the 3'-OH group of the ribose on the α-phosphoryl group of ATP. The two lysine and aspartate residues on C2 selects ATP over GTP for the substrate, so that the enzyme is not a guanylyl cyclase. A pair of arginine and asparagine residues on C2 stablizes the transition state. In many proteins, these residues are nevertheless mutated while retaining the adenylyl cyclase activity.

There are ten known isoforms of adenylyl cyclases in mammals:

These are also sometimes called simply AC1, AC2, etc., and, somewhat confusingly, sometimes Roman numerals are used for these isoforms that all belong to the overall AC class III. They differ mainly in how they are regulated, and are differentially expressed in various tissues throughout mammalian development.

Adenylyl cyclase is regulated by G proteins, which can be found in the monomeric form or the heterotrimeric form, consisting of three subunits. Adenylyl cyclase activity is controlled by heterotrimeric G proteins. The inactive or inhibitory form exists when the complex consists of alpha, beta, and gamma subunits, with GDP bound to the alpha subunit. In order to become active, a ligand must bind to the receptor and cause a conformational change. This conformational change causes the alpha subunit to dissociate from the complex and become bound to GTP. This G-alpha-GTP complex then binds to adenylyl cyclase and causes activation and the release of cAMP. Since a good signal requires the help of enzymes, which turn on and off signals quickly, there must also be a mechanism in which adenylyl cyclase deactivates and inhibits cAMP. The deactivation of the active G-alpha-GTP complex is accomplished rapidly by GTP hydrolysis due to the reaction being catalyzed by the intinsic enzymatic activity of GTPase located in the alpha subunit. It is also regulated by forskolin, as well as other isoform-specific effectors:


In neurons, calcium-sensitive adenylyl cyclases are located next to calcium ion channels for faster reaction to Ca influx; they are suspected of playing an important role in learning processes. This is supported by the fact that adenylyl cyclases are "coincidence detectors", meaning that they are activated only by several different signals occurring together. In peripheral cells and tissues adenylyl cyclases appear to form molecular complexes with specific receptors and other signaling proteins in an isoform-specific manner.

Adenylyl cyclase has been implicated in memory formation, functioning as a coincidence detector

AC-IV was first reported in the bacterium "Aeromonas hydrophila", and the structure of the AC-IV from "Yersinia pestis" has been reported. These are the smallest of the AC enzyme classes; the AC-IV (CyaB) from "Yersinia" is a dimer of 19 kDa subunits with no known regulatory components (). AC-IV forms a superfamily with mamallian thiamine-triphosphatase called CYTH (CyaB, thiamine triphosphatase).

These forms of AC have been reported in specific bacteria ("Prevotella ruminicola" and "Rhizobium etli" , respectively) and have not been extensively characterized. There are a few extra members (~400 in Pfam) known to be in class VI. Class VI enzymes possess a catalytic core similar to the one in Class III.



</doc>
<doc id="2529" url="https://en.wikipedia.org/wiki?curid=2529" title="Alexandra">
Alexandra

Alexandra (Greek: ) is the feminine form of the given name Alexander (Greek: , "Alexandros"). Etymologically, the name is a compound of the Greek verb ("alexein") "to defend" and ("anēr") "man" ( "andros"). Thus it may be roughly translated as "defender of man" or "protector of man". The name was one of the titles or epithets given to the Greek goddess Hera and as such is usually taken to mean "one who comes to save warriors". The earliest attested form of the name is the Mycenaean Greek , "a-re-ka-sa-da-ra", written in the Linear B syllabic script.









</doc>
<doc id="2536" url="https://en.wikipedia.org/wiki?curid=2536" title="Articolo 31">
Articolo 31

Articolo 31 was a band from Milan, Italy, formed in 1990 by J-Ax and DJ Jad, combining hip hop, funk, pop and traditional Italian musical forms. They are one of the most popular Italian hip hop groups.

Articolo 31 were formed by rapper J-Ax (real name Alessandro Aleotti) and DJ Jad (Vito Luca Perrini).
In the spoken intro of the album "Strade di Città" ("City Streets"), it is stated that the band is named after the article of the Irish constitution guaranteeing freedom of the press, although article 31 of the Irish constitution is not about the freedom of the press. They probably meant the Section 31 of the Broadcasting Authority Act.

Articolo 31 released one of the first Italian hip hop records, "Strade di città", in 1993. Soon, they signed with BMG Ricordi and started to mix rap with pop music - a move that earned them great commercial success but that alienated the underground hip hop scene, who perceived them as traitors.
In 1997, DJ Gruff dissed Articolo 31 in a track titled "1 vs 2" on the first album of the beatmaker Fritz da Cat, starting a feud that would go on for years. 

In 2001, Articolo 31 collaborated with the American old school rapper Kurtis Blow on the album "XChé SI!". In the same year, they made the film "Senza filtro" (in English, ""Without filter""). Their producer was Franco Godi, who also produced the music for the "Signor Rossi" animated series.

Their 2002 album "Domani smetto" represented a further departure from hip hop, increasingly relying on the formula of rapping over pop music samples. Several of their songs rotate around the theme of soft drugs legalization in Italy (pointing strongly in favour).

Following their 2003 album "Italiano medio", the band took a break. Both J Ax and DJ Jad have been involved with solo projects. In 2006, the group declared an indefinite hiatus.

Their posse, "Spaghetti Funk", includes other popular performers like Space One and pop rappers Gemelli DiVersi.



</doc>
<doc id="2543" url="https://en.wikipedia.org/wiki?curid=2543" title="Alexander Kerensky">
Alexander Kerensky

Alexander Fyodorovich Kerensky (, ; Original spelling: Александръ Ѳедоровичъ Керенскій; 4 May 1881 – 11 June 1970) was a Russian lawyer and revolutionist who was a key political figure in the Russian Revolution of 1917. After the February Revolution of 1917, he joined the newly formed Russian Provisional Government, first as Minister of Justice, then as Minister of War, and after July as the government's second Minister-Chairman. A leader of the moderate-socialist Trudovik faction of the Socialist Revolutionary Party, he was also vice-chairman of the powerful Petrograd Soviet. On 7 November, his government was overthrown by the Lenin-led Bolsheviks in the October Revolution. He spent the remainder of his life in exile, in Paris and New York City, and worked for the Hoover Institution.

Alexander Kerensky was born in Simbirsk (now Ulyanovsk) on the Volga River on 4 May 1881 and was the eldest son in the family. His father, Fyodor Mikhailovich Kerensky, was a teacher and director of the local gymnasium and was later promoted to Inspector of public schools. His maternal grandfather was head of the Topographical Bureau of the Kazan Military District. His mother, Nadezhda Aleksandrovna (née Adler), was the granddaughter of a former serf who had had to purchase his freedom before serfdom was abolished in 1861. He subsequently embarked upon a mercantile career, in which he prospered, allowing him to move his business to Moscow, where he continued his success, becoming a wealthy Moscow merchant.

Kerensky's father was the teacher of Vladimir Ulyanov (Lenin), and members of the Kerensky and Ulyanov families were friends. In 1889, when Kerensky was eight, the family moved to Tashkent, where his father had been appointed the main inspector of public schools (superintendent). Alexander graduated with honours in 1899. The same year he entered St. Petersburg University, where he studied history and philology. The next year he switched to law. He earned his law degree in 1904 and married Olga Lvovna Baranovskaya, the daughter of a Russian general, the same year. Kerensky joined the Narodnik movement and worked as a legal counsel to victims of the Revolution of 1905. At the end of 1904, he was jailed on suspicion of belonging to a militant group. Afterwards he gained a reputation for his work as a defence lawyer in a number of political trials of revolutionaries.

In 1912, Kerensky became widely known when he visited the goldfields at the Lena River and published material about the Lena Minefields incident. In the same year, Kerensky was elected to the Fourth Duma as a member of the Trudoviks, a moderate, non-Marxist labour party founded by Alexis Aladin that was associated with the Socialist-Revolutionary Party, and joined a Freemason society uniting the anti-monarchy forces that strived for the democratic renewal of Russia. In fact, the Socialist Revolutionary Party bought Kerensky a house, as he otherwise wouldn't be elective for the Duma, according to the Russian property-laws. He then soon became a significant Duma member of the "Progressive Block", which included several Socialist Parties, Mensheviks, and Liberals - but not the Bolsheviks. He was a brilliant orator and skilled parliamentary leader of the socialist opposition to the government of Tsar Nicholas II.

On May 28, 1914, Kerensky appealed to Rodzianko with a request from the Council of elders to inform the Tsar that to succeed in war he must:
1) change his domestic policy,
2) proclaim a General Amnesty for political prisoners,
3) restore the Constitution of Finland,
4) declare the autonomy of Poland,
5) provide national minorities autonomy in the field of culture,
6) abolish restrictions against Jews,
7) end religious intolerance,
8) stop the harassment of legal trade union organizations.

Kerensky was an active member of the irregular Freemasonic lodge, the Grand Orient of Russia's Peoples, which derived from the Grand Orient of France. Kerensky was Secretary General of the Grand Orient of Russia's Peoples and stood down following his ascent to government in July 1917. He was succeeded by the Menshevik, Alexander Halpern.

In response to bitter resentments held against the imperial favourite Grigori Rasputin in the midst of Russia's failing effort in World War I, Kerensky, at the opening of the Duma on 2 November 1916, called the imperial ministers "hired assassins" and "cowards", and alleged that they were "guided by the contemptible Grishka Rasputin!" Grand Duke Nikolai Mikhailovich, Prince Lvov, and general Mikhail Alekseyev attempted to persuade the emperor Nicholas II to send away the Empress Alexandra Feodorovna, Rasputin's steadfast patron, either to the Livadia Palace in Yalta or to England. Mikhail Rodzianko, Zinaida Yusupova (the mother of Felix Yusupov), Alexandra's sister Elisabeth, Grand Duchess Victoria and the empress's mother-in-law Maria Feodorovna also tried to influence and pressure the imperial couple to remove Rasputin from his position of influence within the imperial household, but without success. According to Kerensky, Rasputin had terrorised the empress by threatening to return to his native village.

Monarchists murdered Rasputin in December 1916, burying him near the imperial residence in Tsarskoye Selo. Shortly after the February Revolution of 1917, Kerensky ordered soldiers to re-bury the corpse at an unmarked spot in the countryside. However, the truck broke down or was forced to stop because of the snow on Lesnoe Road outside of St. Petersburg. It is likely the corpse was incinerated (between 3 and 7 in the morning) in the cauldrons of the nearby boiler shop of the Saint Petersburg State Polytechnical University, including the coffin, without leaving a single trace.

When the February Revolution broke out in 1917, Kerensky - together with Pavel Milyukov - was one of its most prominent leaders. As one of the Duma's most well-known speakers against the monarchy and as a lawyer and defender of many revolutionaries, Kerensky became a member of the Provisional Committee of the State Duma and was elected vice-chairman of the newly formed Petrograd Soviet. These two bodies, the Duma and the Petrograd Soviet, or - rather - their respective executive committees, soon became each other's antagonists on most matters except regarding the end of the Tsar's autocracy.

The Petrograd Soviet grew to include 3000 to 4000 members, and their meetings could drown in a blur of everlasting orations. At the meeting of to the Executive Committee of the Petrograd Soviet or Ispolkom formed - a self-appointed committee, with (eventually) three members from each of the parties represented in the Soviet. Kerensky became one of the members representing the Social Revolutionary party (the SRs).

On , without any consultation with the government, the Ispolkom of the Soviet issued the infamous Order No. 1, intended only for the 160,000-strong Petrograd garrison, but soon interpreted as applicable to all soldiers at the front. The order stipulated that all military units should form committees like the Petrograd Soviet. This led to confusion and "stripping of officers' authority"; further, "Order No. 3" stipulated that the military was subordinate to Ispolkom in the political hierarchy. The ideas came from a group of Socialists and aimed to limit the officers' power to military affairs. The socialist intellectuals believed the officers to be the most likely counterrevolutionary elements. Kerensky's role in these orders are unclear, but he participated in the decisions. But just as before the revolution he had defended many who disliked the Tsar, he now saved the lives of many of the Tsar's civil servants about to be lynched by mobs.

Additionally, the Duma formed an executive committee which eventually became the so-called Russian Provisional Government. As there was little trust between Ispolkom and this Government (and as he was about to accept the office of Attorney General in the Provisional Government), Kerensky gave a most passionate speech, not just to the Ispolkom, but to the entire Petrograd Soviet. He then swore, as Minister, never to violate democratic values, and ended his speech with the words "I cannot live without the people. In the moment you begin to doubt me, then kill me." The huge majority (workers and soldiers) gave him great applause, and Kerensky now became the first and "the only one" who participated in both the Provisional Government and the Ispolkom. As a link between Ispolkom and the Provisional Government, the quite ambitious Kerensky stood to benefit from this position.
After the first government crisis over Pavel Milyukov's secret note re-committing Russia to its original war-aims on 2–4 May, Kerensky became the Minister of War and the dominant figure in the newly-formed socialist-liberal coalition government. On 10 May (Julian calendar), Kerensky started for the front and visited one division after another, urging the men to do their duty. His speeches were impressive and convincing for the moment, but had little lasting effect. Under Allied pressure to continue the war, he launched what became known as the Kerensky Offensive against the Austro-Hungarian/German South Army on . At first successful, the offensive soon met strong resistance and the Central Powers riposted with a strong counter-attack. The Russian army retreated and suffered heavy losses, and it became clear from the many incidents of desertion, sabotage, and mutiny that the army was no longer willing to attack.

The military heavily criticised Kerensky for his liberal policies, which included stripping officers of their mandates and handing over control to revolutionary-inclined "soldier committees" () instead; the abolition of the death penalty; and allowing revolutionary agitators to be present at the front. Many officers jokingly referred to commander-in-chief Kerensky as the "persuader-in-chief"

On 2 July 1917 the Provisional Government's first coalition collapsed over the question of Ukraine's autonomy. Following the July Days unrest in Petrograd (3–7 July [16–20 July, N.S.] 1917) and the official suppression of the Bolsheviks, Kerensky succeeded Prince Lvov as Russia's Prime Minister on . Following the Kornilov Affair, an attempted military coup d'état at the end of August, and the resignation of the other ministers, he appointed himself Supreme Commander-in-Chief as well.

On 15 September Kerensky proclaimed Russia a republic, which was contrary to the non-socialists' understanding that the Provisional Government should hold power only until a Constituent Assembly should meet to decide Russia's form of government, but which was in line with the long-proclaimed aim of the Socialist Revolutionary Party. He formed a five-member Directory, which consisted of himself, Minister of Foreign Affairs Mikhail Tereshchenko, Minister of War General , Minister of the Navy Admiral Dmitry Verderevsky and Minister of Posts and Telegraphs . He retained his post in the final coalition government in October 1917 until the Bolsheviks overthrew it on .
Kerensky faced a major challenge: three years of participation in World War had exhausted Russia, while the provisional government offered little motivation for a victory outside of continuing Russia's obligations towards its allies. Russia's continued involvement in the war was not popular among the lower and middle classes, and especially not popular among the soldiers. They had all believed that Russia would stop fighting when the Provisional Government took power, and subsequently felt deceived. Furthermore, Vladimir Lenin and his Bolshevik party were promising "peace, land, and bread" under a communist system. The Russian army, war-weary, ill-equipped, dispirited and ill-disciplined, was disintegrating, with soldiers desertiing in large numbers. By autumn 1917, an estimated two million men had unofficially left the army.

Kerensky and the other political leaders continued Russia's involvement in World War I, thinking that nothing but a glorious victory was the only road forward, and fearing that the economy, already under huge stress from the war effort, might become increasingly unstable if vital supplies from France and from the United Kingdom ceased flowing. The dilemma of whether to withdraw was a great one, and Kerensky's inconsistent and impractical policies further destabilised the army and the country at large.

Furthermore, Kerensky adopted a policy that isolated the right-wing conservatives, both democratic and monarchist-oriented. His philosophy of "no enemies to the left" greatly empowered the Bolsheviks and gave them a free hand, allowing them to take over the military arm or "voyenka" () of the Petrograd and Moscow Soviets. His arrest of Lavr Kornilov and other officers left him without strong allies against the Bolsheviks, who ended up being Kerensky's strongest and most determined adversaries, as opposed to the right wing, which evolved into the White movement.

During the Kornilov Affair, Kerensky had distributed arms to the Petrograd workers, and by November most of these armed workers had gone over to the Bolsheviks. On 1917, the Bolsheviks launched the second Russian revolution of the year. Kerensky's government in Petrograd had almost no support in the city. Only one small force, a subdivision of the 2nd company of the First Petrograd Women's Battalion, also known as The Women's Death Battalion, was willing to fight for the government against the Bolsheviks, but this force was overwhelmed by the numerically superior pro-Bolshevik forces, defeated, and captured. The Bolsheviks took less than 20 hours to seize the government.

Kerensky escaped the Bolsheviks and fled to Pskov, where he rallied some loyal troops for an attempt to re-take the city. His troops managed to capture Tsarskoe Selo but were beaten the next day at Pulkovo. Kerensky narrowly escaped, and he spent the next few weeks in hiding before fleeing the country, eventually arriving in France. During the Russian Civil War, he supported neither side, as he opposed both the Bolshevik regime and the White Movement.

Kerensky was married to Olga Lvovna Baranovskaya and they had two sons, Oleg and Gleb, who both went on to become engineers. Kerensky's grandson (also named Oleg), according to IMDb.com, played his grandfather's role in the 1981 film "Reds". Kerensky and Olga were divorced in 1939 and soon after he settled in Paris, and while visiting the United States he met and married, in 1939, the Australian former journalist Lydia Ellen "Nell" Tritton (1899–1946). The marriage took place in Martins Creek, Pennsylvania.

When Germany invaded France in 1940, they emigrated to the United States. After the Nazi-led invasion of the Soviet Union in 1941, Kerensky offered his support to Joseph Stalin. When his wife Nell became terminally ill in 1945, Kerensky travelled with her to Brisbane, Australia, and lived there with her family. She suffered a stroke in February 1946, and he remained there until her death on 10 April 1946. Kerensky then returned to the United States, where he spent the rest of his life.

Kerensky eventually settled in New York City, living on the Upper East Side on 91st Street near Central Park but spent much of his time at the Hoover Institution at Stanford University in California, where he both used and contributed to the Institution's huge archive on Russian history, and where he taught graduate courses. He wrote and broadcast extensively on Russian politics and history.
Kerensky died of arteriosclerotic heart disease at St. Luke's Hospital in New York City in 1970, one of the last surviving major participants in the turbulent events of 1917. The local Russian Orthodox Churches in New York City refused to grant Kerensky burial because of his association with Freemasonry, and because they saw him as largely responsible for the Bolsheviks seizing power. A Serbian Orthodox Church also refused burial. Kerensky's body was flown to London, where he was buried at the non-denominational Putney Vale Cemetery.







</doc>
<doc id="2544" url="https://en.wikipedia.org/wiki?curid=2544" title="Ansgar">
Ansgar

Saint Ansgar (8 September 801 – 3 February 865), also known as Anskar, Saint Anschar or Oscar, was Archbishop of Hamburg-Bremen in the northern part of the Kingdom of the East Franks. Ansgar became known as the "Apostle of the North" because of his travels and the See of Hamburg received the missionary mandate to bring Christianity to Northern Europe.

Ansgar was the son of a noble Frankish family, born near Amiens. After his mother's early death, Ansgar was brought up in Corbie Abbey, and was educated at the Benedictine monastery in Picardy. According to the "Vita Ansgarii" ("Life of Ansgar"), when the little boy learned in a vision that his mother was in the company of Saint Mary, his careless attitude toward spiritual matters changed to seriousness. His pupil, successor, and eventual biographer Rimbert considered the visions (of which this was the first) to have been Ansgar's the main life motivator.

Ansgar was a product of the phase of Christianization of Saxony (present day Northern Germany) begun by Charlemagne and continued by his son and successor, Louis the Pious. In 822 Ansgar became one of many missionaries sent to found the abbey of Corvey (New Corbie) in Westphalia, where he became a teacher and preacher. A group of monks including Ansgar were sent further north to Jutland with the king Harald Klak, who had received baptism during his exile. With Harald's downfall in 827 and Ansgar's companion Autbert having died, their school for the sons of courtiers closed and Ansgar returned to Germany. Then in 829, after the Swedish king Björn at Hauge requested missionaries for his Swedes, King Louis sent Ansgar, now accompanied by friar Witmar from New Corbie as his assistant. Ansgar preached and made converts, particularly during six months at Birka, on Lake Mälaren, where the wealthy widow Mor Frideborg extended hospitality. Ansgar organized a small congregation with her and the king's steward, Hergeir, as its most prominent members.

In 831 Ansgar returned to Louis' court at Worms and was appointed to the Archbishopric of Bremen. This was a new archbishopric, combining the bishoprics of Bremen and Verden and with the right to send missions into all the northern lands, as well as to consecrate bishops for them. Ansgar received the mission of evangelizing pagan Denmark, Norway and Sweden. The King of Sweden decided to cast lots as to whether to admit the Christian missionaries into his kingdom. Ansgar recommended the issue to the care of God, and the lot was favorable. Ansgar was consecrated as a bishop in November 831, with the approval of Gregory IV. Before traveling north once again, Ansgar traveled to Rome to receive the pallium directly from the pope's hands, and was formally named legate for the northern lands. Ebbo, Archbishop of Reims had previously received a similar commission, but would be deposed twice before his death in 851, and never actually traveled so far north, so the jurisdiction was divided by agreement, with Ebbo retaining Sweden for himself. For a time Ansgar devoted himself to the needs of his own diocese, which was still missionary territory and had few churches. He founded a monastery and a school in Hamburg. Although intended to serve the Danish mission further north, it accomplished little.

After Louis the Pious died in 840, his empire was divided and Ansgar lost the abbey of Turholt, which Louis had given to endow Ansgar's work. Then in 845, the Danes unexpectedly raided Hamburg, destroying all the church's treasures and books. Ansgar now had neither see nor revenue, and many helpers deserted him. The new king, Louis' third son, Louis the German, did not re-endow Turholt to Ansgar, but in 847 he named the missionary to the vacant diocese of Bremen, where Ansgar moved in 848. However, since Bremen had been suffragan to the Bishop of Cologne, combining the sees of Bremen and Hamburg presented canonical difficulties. After prolonged negotiations, Pope Nicholas I would approve the union of the two dioceses in 864.

Through this political turmoil, Ansgar continued his northern mission. The Danish civil war compelled him to establish good relations with two kings, Horik the Elder and his son, Horik II. Both assisted him until his death; Ansgar was able to secure permission to build a church in Sleswick north of Hamburg and recognition of Christianity as a tolerated religion. Ansgar did not forget the Swedish mission, and spent two years there in person (848–850), averting a threatened pagan reaction. In 854, Ansgar returned to Sweden when king Olof ruled in Birka. According to Rimbert, he was well disposed to Christianity. On a Viking raid to Apuole (current village in Lithuania) in Courland, the Swedes plundered the Curonians.

Ansgar was buried in Bremen in 865. His successor as archbishop, Rimbert, wrote the "Vita Ansgarii". He noted that Ansgar wore a rough hair shirt, lived on bread and water, and showed great charity to the poor. Adam of Bremen attributed the "Vita et miracula of Willehad" (first bishop of Bremen) to Ansgar in "Gesta Hammenburgensis ecclesiæ"; Ansgar is also the reputed author of a collection of brief prayers "Pigmenta" (ed. J. M. Lappenberg, Hamburg, 1844). Pope Nicholas I declared Ansgar a saint shortly after the missionary's death. The first actual missionary in Sweden and the Nordic countries (and organizer of the Catholic church therein), Ansgar was later declared "Patron of Scandinavia".

Relics are located in Hamburg on two places: St. Mary's Cathedral (germ.: Domkirche St. Marien) and St. Ansgar's and St. Bernard's Church (germ.: St. Ansgar und St. Bernhard Kirche).
Statues of Bishop Ansgar stand in Hamburg, Copenhagen and Ribe, as well as a stone cross at Birka. A crater on the Moon, Ansgarius, has been named for him. His feast day is 3 February.

Although a historical document and primary source written by a man whose existence can be proven historically, the "Vita Ansgarii" ("The Life of Ansgar") aims above all to demonstrate Ansgar's sanctity. It is partly concerned with Ansgar's visions, which, according to the author Rimbert, encouraged and assisted Ansgar's remarkable missionary feats.

Through the course of this work, Ansgar repeatedly embarks on a new stage in his career following a vision. According to Rimbert, his early studies and ensuing devotion to the ascetic life of a monk were inspired by a vision of his mother in the presence of Saint Mary. Again, when the Swedish people were left without a priest for some time, he begged King Horik to help him with this problem; then after receiving his consent, consulted with Bishop Gautbert to find a suitable man. The two together sought the approval of King Louis, which he granted when he learned that they were in agreement on the issue. Ansgar was convinced he was commanded by heaven to undertake this mission and was influenced by a vision he received when he was concerned about the journey, in which he met a man who reassured him of his purpose and informed him of a prophet that he would meet, the abbot Adalhard, who would instruct him in what was to happen. In the vision, he searched for and found Adalhard, who commanded, "Islands, listen to me, pay attention, remotest peoples", which Ansgar interpreted as God's will that he go to the Scandinavian countries as "most of that country consisted of islands, and also, when 'I will make you the light of the nations so that my salvation may reach to the ends of the earth' was added, since the end of the world in the north was in Swedish territory".



<br>


</doc>
<doc id="2546" url="https://en.wikipedia.org/wiki?curid=2546" title="Automated theorem proving">
Automated theorem proving

Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. Automated reasoning over mathematical proof was a major impetus for the development of computer science.

While the roots of formalised logic go back to Aristotle, the end of the 19th and early 20th centuries saw the development of modern logic and formalised mathematics. Frege's "Begriffsschrift" (1879) introduced both a complete propositional calculus and what is essentially modern predicate logic. His "Foundations of Arithmetic", published 1884, expressed (parts of) mathematics in formal logic. This approach was continued by Russell and Whitehead in their influential "Principia Mathematica", first published 1910–1913, and with a revised second edition in 1927. Russell and Whitehead thought they could derive all mathematical truth using axioms and inference rules of formal logic, in principle opening up the process to automatisation. In 1920, Thoralf Skolem simplified a previous result by Leopold Löwenheim, leading to the Löwenheim–Skolem theorem and, in 1930, to the notion of a Herbrand universe and a Herbrand interpretation that allowed (un)satisfiability of first-order formulas (and hence the validity of a theorem) to be reduced to (potentially infinitely many) propositional satisfiability problems.

In 1929, Mojżesz Presburger showed that the theory of natural numbers with addition and equality (now called Presburger arithmetic in his honor) is decidable and gave an algorithm that could determine if a given sentence in the language was true or false.
However, shortly after this positive result, Kurt Gödel published "On Formally Undecidable Propositions of Principia Mathematica and Related Systems" (1931), showing that in any sufficiently strong axiomatic system there are true statements which cannot be proved in the system. This topic was further developed in the 1930s by Alonzo Church and Alan Turing, who on the one hand gave two independent but equivalent definitions of computability, and on the other gave concrete examples for undecidable questions.

Shortly after World War II, the first general purpose computers became available. In 1954, Martin Davis programmed Presburger's algorithm for a JOHNNIAC vacuum tube computer at the Princeton Institute for Advanced Study. According to Davis, "Its great triumph was to prove that the sum of two even numbers is even". More ambitious was the Logic Theory Machine in 1956, a deduction system for the propositional logic of the "Principia Mathematica", developed by Allen Newell, Herbert A. Simon and J. C. Shaw. Also running on a JOHNNIAC, the Logic Theory Machine constructed proofs from a small set of propositional axioms and three deduction rules: modus ponens, (propositional) variable substitution, and the replacement of formulas by their definition. The system used heuristic guidance, and managed to prove 38 of the first 52 theorems of the "Principia".

The "heuristic" approach of the Logic Theory Machine tried to emulate human mathematicians, and could not guarantee that a proof could be found for every valid theorem even in principle. In contrast, other, more systematic algorithms achieved, at least theoretically, completeness for first-order logic. Initial approaches relied on the results of Herbrand and Skolem to convert a first-order formula into successively larger sets of propositional formulae by instantiating variables with terms from the Herbrand universe. The propositional formulas could then be checked for unsatisfiability using a number of methods. Gilmore's program used conversion to disjunctive normal form, a form in which the satisfiability of a formula is obvious.

Depending on the underlying logic, the problem of deciding the validity of a formula varies from trivial to impossible. For the frequent case of propositional logic, the problem is decidable but co-NP-complete, and hence only exponential-time algorithms are believed to exist for general proof tasks. For a first order predicate calculus, Gödel's completeness theorem states that the theorems (provable statements) are exactly the logically valid well-formed formulas, so identifying valid formulas is recursively enumerable: given unbounded resources, any valid formula can eventually be proven. However, "invalid" formulas (those that are "not" entailed by a given theory), cannot always be recognized.

The above applies to first order theories, such as Peano arithmetic. However, for a specific model that may be described by a first order theory, some statements may be true but undecidable in the theory used to describe the model. For example, by Gödel's incompleteness theorem, we know that any theory whose proper axioms are true for the natural numbers cannot prove all first order statements true for the natural numbers, even if the list of proper axioms is allowed to be infinite enumerable. It follows that an automated theorem prover will fail to terminate while searching for a proof precisely when the statement being investigated is undecidable in the theory being used, even if it is true in the model of interest. Despite this theoretical limit, in practice, theorem provers can solve many hard problems, even in models that are not fully described by any first order theory (such as the integers).

A simpler, but related, problem is "proof verification", where an existing proof for a theorem is certified valid. For this, it is generally required that each individual proof step can be verified by a primitive recursive function or program, and hence the problem is always decidable.

Since the proofs generated by automated theorem provers are typically very large, the problem of proof compression is crucial and various techniques aiming at making the prover's output smaller, and consequently more easily understandable and checkable, have been developed.

Proof assistants require a human user to give hints to the system. Depending on the degree of automation, the prover can essentially be reduced to a proof checker, with the user providing the proof in a formal way, or significant proof tasks can be performed automatically. Interactive provers are used for a variety of tasks, but even fully automatic systems have proved a number of interesting and hard theorems, including at least one that has eluded human mathematicians for a long time, namely the Robbins conjecture. However, these successes are sporadic, and work on hard problems usually requires a proficient user.

Another distinction is sometimes drawn between theorem proving and other techniques, where a process is considered to be theorem proving if it consists of a traditional proof, starting with axioms and producing new inference steps using rules of inference. Other techniques would include model checking, which, in the simplest case, involves brute-force enumeration of many possible states (although the actual implementation of model checkers requires much cleverness, and does not simply reduce to brute force).

There are hybrid theorem proving systems which use model checking as an inference rule. There are also programs which were written to prove a particular theorem, with a (usually informal) proof that if the program finishes with a certain result, then the theorem is true. A good example of this was the machine-aided proof of the four color theorem, which was very controversial as the first claimed mathematical proof which was essentially impossible to verify by humans due to the enormous size of the program's calculation (such proofs are called non-surveyable proofs). Another example of a program-assisted proof is the one that shows that the game of Connect Four can always be won by first player.

Commercial use of automated theorem proving is mostly concentrated in integrated circuit design and verification. Since the Pentium FDIV bug, the complicated floating point units of modern microprocessors have been designed with extra scrutiny. AMD, Intel and others use automated theorem proving to verify that division and other operations are correctly implemented in their processors.

In the late 1960s agencies funding research in automated deduction began to emphasize the need for practical applications. One of the first fruitful areas was that of program verification whereby first-order theorem provers were applied to the problem of verifying the correctness of computer programs in languages such as Pascal, Ada, Java etc. Notable among early program verification systems was the Stanford Pascal Verifier developed by David Luckham at Stanford University. This was based on the Stanford Resolution Prover also developed at Stanford using John Alan Robinson's resolution principle. This was the first automated deduction system to demonstrate an ability to solve mathematical problems that were announced in the Notices of the American Mathematical Society before solutions were formally published.

First-order theorem proving is one of the most mature subfields of automated theorem proving. The logic is expressive enough to allow the specification of arbitrary problems, often in a reasonably natural and intuitive way. On the other hand, it is still semi-decidable, and a number of sound and complete calculi have been developed, enabling "fully" automated systems. More expressive logics, such as Higher-order logics, allow the convenient expression of a wider range of problems than first order logic, but theorem proving for these logics is less well developed.

The quality of implemented systems has benefited from the existence of a large library of standard benchmark examples — the Thousands of Problems for Theorem Provers (TPTP) Problem Library — as well as from the CADE ATP System Competition (CASC), a yearly competition of first-order systems for many important classes of first-order problems.

Some important systems (all have won at least one CASC competition division) are listed below.

The Theorem Prover Museum is an initiative to conserve the sources of theorem prover systems for future analysis, since they are important cultural/scientific artefacts. It has the sources of many of the systems mentioned above.









</doc>
<doc id="2547" url="https://en.wikipedia.org/wiki?curid=2547" title="Agent Orange">
Agent Orange

Agent Orange is a herbicide and defoliant chemical, one of the "tactical use" Rainbow Herbicides. It is widely known for its use by the U.S. military as part of its herbicidal warfare program, Operation Ranch Hand, during the Vietnam War from 1961 to 1971. It is a mixture of equal parts of two herbicides, 2,4,5-T and 2,4-D. In addition to its damaging environmental effects, traces of dioxin (mainly TCDD, the most toxic of its type) found in the mixture have caused major health problems for many individuals who were exposed.

Up to four million people in Vietnam were exposed to the defoliant. The government of Vietnam says as many as 3 million people have suffered illnesses because of Agent Orange. The Red Cross of Vietnam estimates that up to 1 million people are disabled or have health problems as a result of Agent Orange contamination. The United States government has challenged these figures as being unreliable. The U.S. government has documented higher cases of leukemia, Hodgkin's lymphoma, and various kinds of cancer in exposed veterans. Agent Orange also caused enormous environmental damage in Vietnam. Over 3,100,000 hectares (31,000 km or 11,969 mi) of forest were defoliated. Defoliants eroded tree cover and seedling forest stock, making reforestation difficult in numerous areas. Animal species diversity sharply reduced in contrast with unsprayed areas. 

The aftermath of the use of Agent Orange in Vietnam resulted in massive legal consequences. The United Nations ratified United Nations General Assembly Resolution 31/72 and the Environmental Modification Convention. Lawsuits filed on behalf of both US and Vietnamese veterans sought compensation for damages.

Agent Orange was to a lesser extent used outside Vietnam. It was first used by British Armed Forces in Malaysia during the Malayan Emergency. It was further used in neighbouring Laos and Cambodia was also sprayed with Agent Orange during the Vietnam War because forests on the border with Vietnam were used by the Viet Cong. Some countries, such as Canada, saw testing, while other countries, such as Brazil, used the herbicide to clear out sections of land for agriculture.

The active ingredient of Agent Orange was an equal mixture of two phenoxy herbicides – 2,4-dichlorophenoxyacetic acid (2,4-D) and 2,4,5-trichlorophenoxyacetic acid (2,4,5-T) – in iso-octyl ester form, which contained traces of the dioxin 2,3,7,8-tetrachlorodibenzo-"p"-dioxin (TCDD). 

TCDD was a trace (typically 2-3 ppm, but ranging from 50 ppb to 50 ppm), but significant contaminant of Agent Orange. TCDD is the most toxic of the dioxins, and is classified as a human carcinogen by the US Environmental Protection Agency. 

If not bound chemically to a biological surface such as soil, leaves or grass, Agent Orange dries quickly after spraying and breaks down within hours to days when exposed to sunlight and is no longer harmful. 

Due to its fat-soluble nature, TCDD enters the body through physical contact or ingestion. Dioxin easily accumulates in the food chain. Dioxin enters the body by attaching to a protein called the aryl hydrocarbon receptor (AhR), a transcription factor. When TCDD binds to AhR, the protein moves to the nucleus, where it influences gene expression. 

Several herbicides were discovered as part of efforts by the US and the British to develop herbicidal weapons for use during World War II. These included 2,4-D (2,4-dichlorophenoxyacetic acid), 2,4,5-T (coded LN-14, and also known as trioxone), MCPA (2-methyl-4-chlorophenoxyacetic acid, 1414B and 1414A, recoded LN-8 and LN-32), and isopropyl phenylcarbamate (1313, recoded LN-33).

In 1943, the U.S. Department of the Army contracted the botanist and bioethicist Arthur Galston, who discovered the defoliants later used in Agent Orange, and his employer University of Illinois at Urbana–Champaign to study the effects of 2,4-D and 2,4,5-T on cereal grains (including rice) and broadleaf crops. Galston, then a graduate student at the University of Illinois, in his research and 1943 Ph.D. dissertation focused on finding a chemical means to make soybeans flower and fruit earlier. He discovered both that 2,3,5-triiodobenzoic acid (TIBA) would speed up the flowering of soybeans and that in higher concentrations it would defoliate the soybeans. From these studies arose the concept of using aerial applications of herbicides to destroy enemy crops to disrupt their food supply. In early 1945, the U.S. Army ran tests of various 2,4-D and 2,4,5-T mixtures at the Bushnell Army Airfield in Florida. As a result, the U.S. began a full-scale production of 2,4-D and 2,4,5-T and would have used it against Japan in 1946 during Operation Downfall if the war had continued.

By the end of the war, the relationship between the two countries was well established. In the years after the war, the U.S. tested 1,100 compounds, and field trials of the more promising ones were done at British stations in India and Australia, in order to establish their effects in tropical conditions, as well as at the U.S.'s testing ground in Florida.

Between 1950 and 1952, trials were conducted in Tanganyika, at Kikore and Stunyansa, to test arboricides and defoliants under tropical conditions. The chemicals involved were 2,4-D, 2,4,5-T, and endothall (3,6-endoxohexahydrophthalic acid). During 1952–53, the unit supervised the aerial spraying of 2,4,5-T over the Waturi peninsula in Kenya to assess the value of defoliants in the eradication of tsetse fly.

During the Malayan Emergency (1948–1960), Britain was the first nation to employ the use of herbicides and defoliants to destroy bushes, trees, and vegetation to deprive insurgents of concealment and targeting food crops as part of a starvation campaign in the early 1950s. A detailed account of how the British experimented with the spraying of herbicides was written by two scientists, E.K. Woodford of Agricultural Research Council's Unit of Experimental Agronomy and H.G.H. Kearns of the University of Bristol.

After the Malayan conflict ended in 1960, the U.S. considered the British precedent in deciding that the use of defoliants was a legal tactic of warfare. Secretary of State Dean Rusk advised President John F. Kennedy that the British had established a precedent for warfare with herbicides in Malaya.

In mid-1961, President Ngo Dinh Diem of South Vietnam asked the United States to conduct aerial herbicide spraying in his country. In August of that year, the Republic of Vietnam Air Force conducted herbicide operations with American help. But Diem's request launched a policy debate in the White House and the State and Defense Departments. However, U.S. officials considered using it, pointing out that the British had already used herbicides and defoliants during the Malayan Emergency in the 1950s. In November 1961, President John F. Kennedy authorized the start of Operation Ranch Hand, the codename for the U.S. Air Force's herbicide program in Vietnam.

During the Vietnam War, between 1962 and 1971, the United States military sprayed nearly of various chemicals – the "rainbow herbicides" and defoliants – in Vietnam, eastern Laos, and parts of Cambodia as part of the aerial defoliation program known as Operation Ranch Hand, reaching its peak from 1967 to 1969. For comparison purposes, an olympic size pool holds approximately . As the British did in Malaya, the goal of the US was to defoliate rural/forested land, depriving guerrillas of food and concealment and clearing sensitive areas such as around base perimeters. The program was also a part of a general policy of forced draft urbanization, which aimed to destroy the ability of peasants to support themselves in the countryside, forcing them to flee to the U.S.-dominated cities, depriving the guerrillas of their rural support base.
Agent Orange was usually sprayed from helicopters or from low-flying C-123 Provider aircraft, fitted with sprayers and "MC-1 Hourglass" pump systems and chemical tanks. Spray runs were also conducted from trucks, boats, and backpack sprayers.

The first batch of herbicides was unloaded at Tan Son Nhut Air Base in South Vietnam, on January 9, 1962. U.S. Air Force records show at least 6,542 spraying missions took place over the course of Operation Ranch Hand. By 1971, 12 percent of the total area of South Vietnam had been sprayed with defoliating chemicals, at an average concentration of 13 times the recommended U.S. Department of Agriculture application rate for domestic use. In South Vietnam alone, an estimated of agricultural land was ultimately destroyed. In some areas, TCDD concentrations in soil and water were hundreds of times greater than the levels considered safe by the U.S. Environmental Protection Agency.

The campaign destroyed of upland and mangrove forests and thousands of square kilometres of crops. Overall, more than 20% of South Vietnam's forests were sprayed at least once over a nine-year period.

In 1965, members of the U.S. Congress were told "crop destruction is understood to be the more important purpose ... but the emphasis is usually given to the jungle defoliation in public mention of the program." Military personnel were told they were destroying crops because they were going to be used to feed guerrillas. They later discovered nearly all of the food they had been destroying was not being produced for guerrillas; it was, in reality, only being grown to support the local civilian population. For example, in Quang Ngai province, 85% of the crop lands were scheduled to be destroyed in 1970 alone. This contributed to widespread famine, leaving hundreds of thousands of people malnourished or starving.

The U.S. military began targeting food crops in October 1962, primarily using Agent Blue; the American public was not made aware of the crop destruction programs until 1965 (and it was then believed that crop spraying had begun that spring). In 1965, 42 percent of all herbicide spraying was dedicated to food crops. The first official acknowledgement of the programs came from the State Department in March 1966.

Many experts at the time, including Arthur Galston, opposed herbicidal warfare due to concerns about the side effects to humans and the environment by indiscriminately spraying the chemical over a wide area. As early as 1966, resolutions were introduced to the United Nations charging that the U.S. was violating the 1925 Geneva Protocol, which regulated the use of chemical and biological weapons. The U.S. defeated most of the resolutions, arguing that Agent Orange was not a chemical or a biological weapon as it was considered a herbicide and a defoliant and it was used in effort to destroy plant crops and to deprive the enemy of concealment and not meant to target human beings. The U.S. delegation argued that a weapon, by definition, is any device used to injure, defeat, or destroy living beings, structures, or systems, and Agent Orange did not qualify under that definition. It also argued that if the U.S. were to be charged for using Agent Orange, then Britain and its Commonwealth nations should be charged since they also used it widely during the Malayan Emergency in the 1950s. In 1969, Britain commented on the draft Resolution 2603 (XXIV): "The evidence seems to us to be notably inadequate for the assertion that the use in war of chemical substances specifically toxic to plants is prohibited by international law."

The government of Vietnam says that 4 million of its citizens were exposed to Agent Orange, and as many as 3 million have suffered illnesses because of it; these figures include their children who were exposed. The Red Cross of Vietnam estimates that up to 1 million people are disabled or have health problems due to contaminated Agent Orange. The United States government has challenged these figures as being unreliable.

According to a study by Dr. Nguyen Viet Nhan, children in the areas where Agent Orange was used have been affected and have multiple health problems, including cleft palate, mental disabilities, hernias, and extra fingers and toes. In the 1970s, high levels of dioxin were found in the breast milk of South Vietnamese women, and in the blood of U.S. military personnel who had served in Vietnam. The most affected zones are the mountainous area along Truong Son (Long Mountains) and the border between Vietnam and Cambodia. The affected residents are living in substandard conditions with many genetic diseases.

In 2006, Anh Duc Ngo and colleagues of the University of Texas Health Science Center published a meta-analysis that exposed a large amount of heterogeneity (different findings) between studies, a finding consistent with a lack of consensus on the issue. Despite this, statistical analysis of the studies they examined resulted in data that the increase in birth defects/relative risk (RR) from exposure to agent orange/dioxin "appears" to be on the order of 3 in Vietnamese-funded studies, but 1.29 in the rest of the world. There is data near the threshold of statistical significance suggesting Agent Orange contributes to still-births, cleft palate, and neural tube defects, with spina bifida being the most statistically significant defect. The large discrepancy in RR between Vietnamese studies and those in the rest of the world has been ascribed to bias in the Vietnamese studies.

It is estimated that about 400,000 Vietnamese were killed by agent orange poisoning.

Twenty-eight of the former U.S. military bases in Vietnam where the herbicides were stored and loaded onto airplanes may still have high levels of dioxins in the soil, posing a health threat to the surrounding communities. Extensive testing for dioxin contamination has been conducted at the former U.S. airbases in Danang, Phù Cát District and Biên Hòa. Some of the soil and sediment on the bases have extremely high levels of dioxin requiring remediation. The Da Nang Air Base has dioxin contamination up to 350 times higher than international recommendations for action. The contaminated soil and sediment continue to affect the citizens of Vietnam, poisoning their food chain and causing illnesses, serious skin diseases and a variety of cancers in the lungs, larynx, and prostate.

Starting in the early 1990s, the federal government directed the Institute of Medicine (IOM), now known as the National Academy of Medicine, to issue reports every 2 years on the health effects of Agent Orange and similar herbicides. First published in 1994 and titled Veterans and Agent Orange, the IOM reports assess the risk of both cancer and non-cancer health effects. Each health effect is categorized by evidence of association based on available research data.

In the last update, titled Veterans and Agent Orange: Update 2014 (and published in 2016), the links between Agent Orange exposure and cancer were listed as shown. (Note that this table shows only cancers.) Other health effects are listed in the next section.)

Soft tissue sarcoma; Non-Hodgkin lymphoma (NHL); Hodgkin disease; Chronic lymphocytic leukemia (CLL); including hairy cell leukemia and other chronic B-cell leukemias

Respiratory cancers (lung, bronchus, trachea, larynx); Prostate cancer; Multiple myeloma; Bladder cancer

Mouth, throat, and sinus cancers; Gastrointestinal cancers (esophagus, stomach, pancreas, colon, rectum); Liver, gallbladder, and bile duct cancers; Bone and joint cancers; Skin cancers; Breast cancer; Female reproductive cancers (cervical, ovarian, endometrial, uterine sarcoma); Testicular and penile cancers; Kidney cancer; Brain tumors; Cancers of endocrine glands (thyroid, thymus, etc.); Leukemia (other than CLL and hairy cell leukemia); Cancers at all other sites
Cancer (including leukemia) in the children of veteran

Publications by the Public Health Service have shown that Vietnam veterans, overall, have increased rates of cancer, and nerve, digestive, skin, and respiratory disorders. The Center for Disease Control and Prevention notes that in particular, there are higher rates of acute/chronic leukemia, Hodgkin's lymphoma and non-Hodgkin's lymphoma, throat cancer, prostate cancer, lung cancer, colon cancer, Ischemic heart disease, soft tissue sarcoma, and liver cancer. With the exception of liver cancer, these are the same conditions the U.S. Veterans Administration has determined may be associated with exposure to Agent Orange/dioxin, and are on the list of conditions eligible for compensation and treatment.

Military personnel who were involved in storage, mixture and transportation (including aircraft mechanics), and actual use of the chemicals were probably among those who received the heaviest exposures. Military members who served on Okinawa also claim to have been exposed to the chemical but there is no verifiable evidence to corroborate these claims.

Some studies have suggested that veterans exposed to Agent Orange may be more at risk of developing prostate cancer and potentially more than twice as likely to develop higher-grade, more lethal prostate cancers. However, a critical analysis of these studies and 35 others consistently found that there was no significant increase in prostate cancer incidence or mortality in those exposed to Agent Orange or 2,3,7,8-tetracholorodibenzo-"p"-dioxin, itself. Furthermore, the National Academy of Medicine (NAM, formerly the Institute of Medicine (IoM)), which since 1994 has been congressionally mandated to conduct a comprehensive evaluation every two years of any research and data related to the health outcomes associated with Agent Orange, has repeatedly concluded that any evidence suggestive of an association between Agent Orange and prostate cancer is, "limited because chance, bias, and confounding could not be ruled out with confidence."

While in Vietnam, the veterans were told not to worry, and were persuaded the chemical was harmless. After returning home, Vietnam veterans began to suspect their ill health or the instances of their wives having miscarriages or children born with birth defects might be related to Agent Orange and the other toxic herbicides to which they had been exposed in Vietnam. Veterans began to file claims in 1977 to the Department of Veterans Affairs for disability payments for health care for conditions they believed were associated with exposure to Agent Orange, or more specifically, dioxin, but their claims were denied unless they could prove the condition began when they were in the service or within one year of their discharge.
In order to qualify for compensation, veterans must have served on or near the perimeters of military bases in Thailand during the Vietnam Era, where herbicides were tested and stored outside of Vietnam, Veterans who were crew members on C-123 planes flown after the Vietnam War, or were associated with Department of Defense (DoD) projects to test, dispose of, or store herbicides in the U.S.

By April 1993, the Department of Veterans Affairs had compensated only 486 victims, although it had received disability claims from 39,419 soldiers who had been exposed to Agent Orange while serving in Vietnam.

About 17.8 percent——of the total forested area of Vietnam was sprayed during the war, which disrupted the ecological equilibrium. The persistent nature of dioxins, erosion caused by loss of tree cover, and loss of seedling forest stock meant that reforestation was difficult (or impossible) in many areas. Many defoliated forest areas were quickly invaded by aggressive pioneer species (such as bamboo and cogon grass), making forest regeneration difficult and unlikely. Animal-species diversity was also impacted; in one study a Harvard biologist found 24 species of birds and five species of mammals in a sprayed forest, while in two adjacent sections of unsprayed forest there were 145 and 170 species of birds and 30 and 55 species of mammals.

Dioxins from Agent Orange have persisted in the Vietnamese environment since the war, settling in the soil and sediment and entering the food chain through animals and fish which feed in the contaminated areas. The movement of dioxins through the food web has resulted in bioconcentration and biomagnification. The areas most heavily contaminated with dioxins are former U.S. air bases.

American policy during the Vietnam War was to destroy crops, accepting the sociopolitical impact that that would have. The RAND Corporation's "Memorandum 5446-ISA/ARPA" states: "the fact that the VC [the Vietcong] obtain most of their food from the neutral rural population dictates the destruction of civilian crops ... if they are to be hampered by the crop destruction program, it will be necessary to destroy large portions of the rural economy – probably 50% or more". Crops were deliberately sprayed with Agent Orange, areas were bulldozed clear of vegetation, and the rural population was subjected to bombing and artillery fire. In consequence, the urban population in South Vietnam nearly tripled, growing from 2.8 million people in 1958 to 8 million by 1971. The rapid flow of people led to a fast-paced and uncontrolled urbanization; an estimated 1.5 million people were living in Saigon slums due to people moving to cities.

The extensive environmental damage that resulted from usage of the herbicide prompted the United Nations to pass Resolution 31/72 and ratify the Environmental Modification Convention. Many states do not regard this as a complete ban on the use of herbicides and defoliants in warfare but it does require case-by-case consideration.

In the Conference on Disarmament, Article 2(4) Protocol III of the weaponry convention contains "The Jungle Exception", which prohibits states from attacking forests or jungles "except if such natural elements are used to cover, conceal or camouflage combatants or military objectives or are military objectives themselves". This exception voids any protection of any military and civilian personnel from a napalm attack or something like Agent Orange and is clear that it was designed to cover situations like U.S. tactics in Vietnam.

Since at least 1978, several lawsuits have been filed against the companies which produced Agent Orange, among them Dow Chemical, Monsanto, and Diamond Shamrock.

Attorney Hy Mayerson was an early pioneer in Agent Orange litigation, working with environmental attorney Victor Yannacone in 1980 on the first class-action suits against wartime manufacturers of Agent Orange. In meeting Dr. Ronald A. Codario, one of the first civilian doctors to see affected patients, Mayerson, so impressed by the fact a physician would show so much interest in a Vietnam veteran, forwarded more than a thousand pages of information on Agent Orange and the effects of dioxin on animals and humans to Codario's office the day after he was first contacted by the doctor. The corporate defendants sought to escape culpability by blaming everything on the U.S. government.

Mayerson, with Sgt. Charles E. Hartz as their principal client, filed the first US Agent Orange class-action lawsuit, in Pennsylvania in 1980, for the injuries military personnel in Vietnam suffered through exposure to toxic dioxins in the defoliant. Attorney Mayerson co-wrote the brief that certified the Agent Orange Product Liability action as a class action, the largest ever filed as of its filing. Hartz's deposition was one of the first ever taken in America, and the first for an Agent Orange trial, for the purpose of preserving testimony at trial, as it was understood that Hartz would not live to see the trial because of a brain tumor that began to develop while he was a member of Tiger Force, special forces, and LRRPs in Vietnam. The firm also located and supplied critical research to the Veterans' lead expert, Dr. Codario, including about 100 articles from toxicology journals dating back more than a decade, as well as data about where herbicides had been sprayed, what the effects of dioxin had been on animals and humans, and every accident in factories where herbicides were produced or dioxin was a contaminant of some chemical reaction.

The chemical companies involved denied that there was a link between Agent Orange and the veterans' medical problems. However, on May 7, 1984, seven chemical companies settled the class-action suit out of court just hours before jury selection was to begin. The companies agreed to pay $180 million as compensation if the veterans dropped all claims against them. Slightly over 45% of the sum was ordered to be paid by Monsanto alone. Many veterans who were victims of Agent Orange exposure were outraged the case had been settled instead of going to court, and felt they had been betrayed by the lawyers. "Fairness Hearings" were held in five major American cities, where veterans and their families discussed their reactions to the settlement, and condemned the actions of the lawyers and courts, demanding the case be heard before a jury of their peers. Federal Judge Jack B. Weinstein refused the appeals, claiming the settlement was "fair and just". By 1989, the veterans' fears were confirmed when it was decided how the money from the settlement would be paid out. A totally disabled Vietnam veteran would receive a maximum of $12,000 spread out over the course of 10 years. Furthermore, by accepting the settlement payments, disabled veterans would become ineligible for many state benefits that provided far more monetary support than the settlement, such as food stamps, public assistance, and government pensions. A widow of a Vietnam veteran who died of Agent Orange exposure would only receive $3700.

In 2004, Monsanto spokesman Jill Montgomery said Monsanto should not be liable at all for injuries or deaths caused by Agent Orange, saying: "We are sympathetic with people who believe they have been injured and understand their concern to find the cause, but reliable scientific evidence indicates that Agent Orange is not the cause of serious long-term health effects."

In 1980, New Jersey created the New Jersey Agent Orange Commission, the first state commission created to study its effects. The commission's research project in association with Rutgers University was called "The Pointman Project". It was disbanded by Governor Christine Todd Whitman in 1996.

During Pointman I, commission researchers devised ways to determine small dioxin levels in blood. Prior to this, such levels could only be found in the adipose (fat) tissue. The project studied dioxin (TCDD) levels in blood as well as in adipose tissue in a small group of Vietnam veterans who had been exposed to Agent Orange and compared them to those of a matched control group; the levels were found to be higher in the former group.

The second phase of the project continued to examine and compare dioxin levels in various groups of Vietnam veterans, including Army, Marines and brown water riverboat Navy personnel.

In 1991, Congress enacted the Agent Orange Act, giving the Department of Veterans Affairs the authority to declare certain conditions "presumptive" to exposure to Agent Orange/dioxin, making these veterans who served in Vietnam eligible to receive treatment and compensation for these conditions. The same law required the National Academy of Sciences to periodically review the science on dioxin and herbicides used in Vietnam to inform the Secretary of Veterans Affairs about the strength of the scientific evidence showing association between exposure to Agent Orange/dioxin and certain conditions. The authority for the National Academy of Sciences reviews and addition of any new diseases to the presumptive list by the VA is expiring in 2015 under the sunset clause of the Agent Orange Act of 1991. Through this process, the list of 'presumptive' conditions has grown since 1991, and currently the U.S. Department of Veterans Affairs has listed prostate cancer, respiratory cancers, multiple myeloma, type II diabetes mellitus, Hodgkin's disease, non-Hodgkin's lymphoma, soft tissue sarcoma, chloracne, porphyria cutanea tarda, peripheral neuropathy, chronic lymphocytic leukemia, and spina bifida in children of veterans exposed to Agent Orange as conditions associated with exposure to the herbicide. This list now includes B cell leukemias, such as hairy cell leukemia, Parkinson's disease and ischemic heart disease, these last three having been added on August 31, 2010. Several highly placed individuals in government are voicing concerns about whether some of the diseases on the list should, in fact, actually have been included.

In 2011, an appraisal of the 20 year long "Air Force Health Study" that began in 1982 indicates that the results of the AFHS as they pertain to Agent Orange, do not provide evidence of disease in the Ranch Hand veterans due to "their elevated levels of exposure to Agent Orange".

The VA denied the applications of post-Vietnam C-123 aircrew veterans because as veterans without "boots on the ground" service in Vietnam, they were not covered under VA's interpretation of "exposed". At the request of the VA, the Institute Of Medicine evaluated whether or not service in these C-123 aircraft could have plausibly exposed soldiers and been detrimental to their health. Their report "Post-Vietnam Dioxin Exposure in Agent Orange-Contaminated C-123 Aircraft" confirmed it. In June 2015 the Secretary of Veterans Affairs issued an Interim final rule providing presumptive service connection for post-Vietnam C-123 aircrews, maintenance staff and aeromedical evacuation crews. VA now provides medical care and disability compensation for the recognized list of Agent Orange illnesses.

In 2002, Vietnam and the U.S. held a joint conference on Human Health and Environmental Impacts of Agent Orange. Following the conference, the U.S. National Institute of Environmental Health Sciences (NIEHS) began scientific exchanges between the U.S. and Vietnam, and began discussions for a joint research project on the human health impacts of Agent Orange.

These negotiations broke down in 2005, when neither side could agree on the research protocol and the research project was canceled. More progress has been made on the environmental front. In 2005, the first U.S.-Vietnam workshop on remediation of dioxin was held.

Starting in 2005, the U.S. Environmental Protection Agency (EPA) began to work with the Vietnamese government to measure the level of dioxin at the Da Nang Air Base. Also in 2005, the Joint Advisory Committee on Agent Orange, made up of representatives of Vietnamese and U.S. government agencies, was established. The committee has been meeting yearly to explore areas of scientific cooperation, technical assistance and environmental remediation of dioxin.

A breakthrough in the diplomatic stalemate on this issue occurred as a result of United States President George W. Bush's state visit to Vietnam in November 2006. In the joint statement, President Bush and President Triet agreed "further joint efforts to address the environmental contamination near former dioxin storage sites would make a valuable contribution to the continued development of their bilateral relationship."

On May 25, 2007, President Bush signed the U.S. Troop Readiness, Veterans' Care, Katrina Recovery, and Iraq Accountability Appropriations Act, 2007 into law for the wars in Iraq and Afghanistan that included an earmark of $3 million specifically for funding for programs for the remediation of dioxin 'hotspots' on former U.S. military bases, and for public health programs for the surrounding communities; some authors consider this to be completely inadequate, pointing out that the U.S. airbase in Da Nang, alone, will cost $14 million to clean up, and that three others are estimated to require $60 million for cleanup. The appropriation was renewed in the fiscal year 2009 and again in FY 2010. An additional $12 million was appropriated in the fiscal year 2010 in the Supplemental Appropriations Act and a total of $18.5 million appropriated for fiscal year 2011.

Secretary of State Hillary Clinton stated during a visit to Hanoi in October 2010 that the U.S. government would begin work on the clean-up of dioxin contamination at the Da Nang airbase.

In June 2011, a ceremony was held at Da Nang airport to mark the start of U.S.-funded decontamination of dioxin hotspots in Vietnam. Thirty-two million dollars has so far been allocated by the U.S. Congress to fund the program.

A $43 million project began in the summer of 2012, as Vietnam and the U.S. forge closer ties to boost trade and counter China's rising influence in the disputed South China Sea.

On January 31, 2004, a victim's rights group, the Vietnam Association for Victims of Agent Orange/dioxin (VAVA), filed a lawsuit in the United States District Court for the Eastern District of New York in Brooklyn, against several U.S. companies for liability in causing personal injury, by developing, and producing the chemical, and claimed that the use of Agent Orange violated the 1907 Hague Convention on Land Warfare, 1925 Geneva Protocol, and the 1949 Geneva Conventions. Dow Chemical and Monsanto were the two largest producers of Agent Orange for the U.S. military, and were named in the suit, along with the dozens of other companies (Diamond Shamrock, Uniroyal, Thompson Chemicals, Hercules, etc.). On March 10, 2005, Judge Jack B. Weinstein of the Eastern District – who had presided over the 1984 U.S. veterans class-action lawsuit – dismissed the lawsuit, ruling there was no legal basis for the plaintiffs' claims. He concluded Agent Orange was not considered a poison under international law at the time of its use by the U.S.; the U.S. was not prohibited from using it as a herbicide; and the companies which produced the substance were not liable for the method of its use by the government. Weinstein used the British example to help dismiss the claims of people exposed to Agent Orange in their suit against the chemical companies that had supplied it.

George Jackson stated that "if the Americans were guilty of war crimes for using Agent Orange in Vietnam, then the British would be also guilty of war crimes as well since they were the first nation to deploy the use of herbicides and defoliants in warfare and used them on a large scale throughout the Malayan Emergency. Not only was there no outcry by other states in response to Britain's use, but the U.S. viewed it as establishing a precedent for the use of herbicides and defoliants in jungle warfare." The U.S. government was also not a party in the lawsuit, due to sovereign immunity, and the court ruled the chemical companies, as contractors of the U.S. government, shared the same immunity.
The case was appealed and heard by the Second Circuit Court of Appeals in Manhattan on June 18, 2007. Three judges on the Second Circuit Court of Appeals upheld Weinstein's ruling to dismiss the case. They ruled that, though the herbicides contained a dioxin (a known poison), they were not intended to be used as a poison on humans. Therefore, they were not considered a chemical weapon and thus not a violation of international law. A further review of the case by the whole panel of judges of the Court of Appeals also confirmed this decision. The lawyers for the Vietnamese filed a petition to the U.S. Supreme Court to hear the case. On March 2, 2009, the Supreme Court denied certiorari and refused to reconsider the ruling of the Court of Appeals.

In a November 2004 Zogby International poll of 987 people, 79% of respondents thought the U.S. chemical companies which produced Agent Orange defoliant should compensate U.S. soldiers who were affected by the toxic chemical used during the war in Vietnam. Also, 51% said they supported compensation for Vietnamese Agent Orange victims.

To assist those who have been affected by Agent Orange/dioxin, the Vietnamese have established "peace villages", which each host between 50 and 100 victims, giving them medical and psychological help. As of 2006, there were 11 such villages, thus granting some social protection to fewer than a thousand victims. U.S. veterans of the war in Vietnam and individuals who are aware and sympathetic to the impacts of Agent Orange have supported these programs in Vietnam. An international group of veterans from the U.S. and its allies during the Vietnam War working with their former enemy—veterans from the Vietnam Veterans Association—established the Vietnam Friendship Village outside of Hanoi.

The center provides medical care, rehabilitation and vocational training for children and veterans from Vietnam who have been affected by Agent Orange. In 1998, The Vietnam Red Cross established the Vietnam Agent Orange Victims Fund to provide direct assistance to families throughout Vietnam that have been affected. In 2003, the Vietnam Association of Victims of Agent Orange (VAVA) was formed. In addition to filing the lawsuit against the chemical companies, VAVA provides medical care, rehabilitation services and financial assistance to those injured by Agent Orange.

The Vietnamese government provides small monthly stipends to more than 200,000 Vietnamese believed affected by the herbicides; this totaled $40.8 million in 2008 alone. The Vietnam Red Cross has raised more than $22 million to assist the ill or disabled, and several U.S. foundations, United Nations agencies, European governments and nongovernmental organizations have given a total of about $23 million for site cleanup, reforestation, health care and other services to those in need.

Vuong Mo of the Vietnam News Agency described one of the centers:

May is 13, but she knows nothing, is unable to talk fluently, nor walk with ease due to for her bandy legs. Her father is dead and she has four elder brothers, all mentally retarded ... The students are all disabled, retarded and of different ages. Teaching them is a hard job. They are of the 3rd grade but many of them find it hard to do the reading. Only a few of them can. Their pronunciation is distorted due to their twisted lips and their memory is quite short. They easily forget what they've learned ... In the Village, it is quite hard to tell the kids' exact ages. Some in their twenties have a physical statures as small as the 7- or 8-years-old. They find it difficult to feed themselves, much less have mental ability or physical capacity for work. No one can hold back the tears when seeing the heads turning round unconsciously, the bandy arms managing to push the spoon of food into the mouths with awful difficulty ... Yet they still keep smiling, singing in their great innocence, at the presence of some visitors, craving for something beautiful.

On June 16, 2010, members of the U.S.-Vietnam Dialogue Group on Agent Orange/Dioxin unveiled a comprehensive 10-year Declaration and Plan of Action to address the toxic legacy of Agent Orange and other herbicides in Vietnam. The Plan of Action was released as an Aspen Institute publication and calls upon the U.S. and Vietnamese governments to join with other governments, foundations, businesses, and nonprofits in a partnership to clean up dioxin "hot spots" in Vietnam and to expand humanitarian services for people with disabilities there. On September 16, 2010, Senator Patrick Leahy (D-VT) acknowledged the work of the Dialogue Group by releasing a statement on the floor of the United States Senate. The statement urges the U.S. government to take the Plan of Action's recommendations into account in developing a multi-year plan of activities to address the Agent Orange/dioxin legacy.

In 2008, Australian researcher Jean Williams claimed that cancer rates in the town of Innisfail, Queensland were 10 times higher than the state average due to secret testing of Agent Orange by the Australian military scientists during the Vietnam War. Williams, who had won the Order of Australia medal for her research on the effects of chemicals on U.S. war veterans, based her allegations on Australian government reports found in the Australian War Memorial's archives. A former soldier, Ted Bosworth, backed up the claims, saying that he had been involved in the secret testing. Neither Williams or Bosworth have produced verifiable evidence to support their claims. The Queensland health department determined that cancer rates in Innisfail were no higher than those in other parts of the state.

The Brazilian government in the late 1960s used herbicides to defoliate a large section of the Amazon rainforest so that Alcoa could build the Tucuruí dam to power mining operations. Large areas of rainforest were destroyed, along with the homes and livelihoods of thousands of rural peasants and indigenous tribes.

Agent Orange was used as a defoliant in eastern Cambodia during the Vietnam War, but its impacts are difficult to assess due to the chaos caused by the Khmer Rouge regime.

The U.S. military, with the permission of the Canadian government, tested herbicides, including Agent Orange, in the forests near the Canadian Forces Base Gagetown in New Brunswick. In 2007, the government of Canada offered a one-time ex gratia payment of $20,000 as compensation for Agent Orange exposure at CFB Gagetown. On July 12, 2005, Merchant Law Group LLP on behalf of over 1,100 Canadian veterans and civilians who were living in and around the CFB Gagetown filed a lawsuit to pursue class action litigation concerning Agent Orange and Agent Purple with the Federal Court of Canada. On August 4, 2009, the case was rejected by the court due to lack of evidence. The ruling was appealed.
In 2007, the Canadian government announced that a research and fact-finding program initiated in 2005 had found the base was safe.

On February 17, 2011, the "Toronto Star" revealed that Agent Orange was employed to clear extensive plots of Crown land in Northern Ontario. The "Toronto Star" reported that, "records from the 1950s, 1960s and 1970s show forestry workers, often students and junior rangers, spent weeks at a time as human markers holding red, helium-filled balloons on fishing lines while low-flying planes sprayed toxic herbicides including an infamous chemical mixture known as Agent Orange on the brush and the boys below." In response to the "Toronto Star" article, the Ontario provincial government launched a probe into the use of Agent Orange.

An analysis of chemicals present in the island's soil, together with resolutions passed by Guam's legislature, suggest that Agent Orange was among the herbicides routinely used on and around military bases Anderson Air Force Base, Naval Air Station Agana, Guam. Despite the evidence, the Department of Defense continues to deny that Agent Orange was ever stored or used on Guam. Several Guam veterans have collected an enormous amount of evidence to assist in their disability claims for direct exposure to dioxin containing herbicides such as 2,4,5-T which are similar to the illness associations and disability coverage that has become standard for those who were harmed by the same chemical contaminant of Agent Orange used in Vietnam.

Agent Orange was used in Korea in the late 1960s.

The United States local press KPHO-TV in Phoenix, Arizona, alleged (in 2011) that the United States Army had in 1978 buried 250 drums of Agent Orange in Camp Carroll, the U.S. Army base in Gyeongsangbuk-do, Korea.

In 1999, about 20,000 South Koreans filed two separated lawsuits against U.S. companies, seeking more than $5 billion in damages. After losing a decision in 2002, they filed an appeal.

In January 2006, the South Korean Appeals Court ordered Dow Chemical and Monsanto to pay $62 million in compensation to about 6,800 people. The ruling acknowledged that "the defendants failed to ensure safety as the defoliants manufactured by the defendants had higher levels of dioxins than standard", and, quoting the U.S. National Academy of Science report, declared that there was a "causal relationship" between Agent Orange and a range of diseases, including several cancers. The judges failed to acknowledge "the relationship between the chemical and peripheral neuropathy, the disease most widespread among Agent Orange victims".

Currently, veterans who provide evidence meeting VA requirements for service in Vietnam, and who can medically establish that anytime after this 'presumptive exposure' they developed any medical problems on the list of presumptive diseases, may receive compensation from the VA. Certain veterans who served in Korea and are able to prove they were assigned to certain specified around the DMZ during a specific time frame are afforded similar presumption.

Parts of Laos were sprayed with Agent Orange during the Vietnam War.

The use of Agent Orange has been controversial in New Zealand, because of the exposure of New Zealand troops in Vietnam and because of the production of Agent Orange for Vietnam and other users at an Ivon Watkins-Dow chemical plant in Paritutu, New Plymouth. There have been continuing claims, as yet unproven, that the suburb of Paritutu has also been polluted; see New Zealand in the Vietnam War.
There are cases of New Zealand soldiers developing cancers such as bone cancer but none has been scientifically connected to exposure to herbicides.

Herbicide persistence studies of Agents Orange and White were conducted in the Philippines.

The U.S. Air Force operation to remove Herbicide Orange from Vietnam in 1972 was named Operation Pacer IVY, while the operation to destroy the Agent Orange stored at Johnston Atoll in 1977 was named Operation Pacer HO. Operation Pacer IVY (InVentorY) collected Agent Orange in South Vietnam and removed it in 1972 aboard the ship for storage on Johnston Atoll. The Environmental Protection Agency (EPA) reports that of Herbicide Orange was stored at Johnston Island in the Pacific and at Gulfport in Mississippi.

Research and studies were initiated to find a safe method to destroy the materials and it was discovered they could be incinerated safely under special conditions of temperature and dwell time. However, these herbicides were expensive and the Air Force wanted to resell its surplus instead of dumping it at sea. Among many methods tested, a possibility of salvaging the herbicides by reprocessing and filtering out the 2,3,7,8-tetrachlorodibenzo-p-dioxin (TCDD) contaminant with carbonized (charcoaled) coconut fibers. This concept was then tested in 1976 and a pilot plant constructed at Gulfport.

From July to September 1977 during Operation Pacer HO (Herbicide Orange), the entire stock of Agent Orange from both Herbicide Orange storage sites at Gulfport and Johnston Atoll was subsequently incinerated in four separate burns in the vicinity of Johnston Island aboard the Dutch-owned waste incineration ship .

As of 2004, some records of the storage and disposition of Agent Orange at Johnston Atoll have been associated with the historical records of Operation Red Hat.

There have been dozens of reports in the press about use and/or storage of military formulated herbicides on Okinawa that are based upon statements by former U.S. service members that had been stationed on the island, photographs, government records, and unearthed storage barrels. The U.S. Department of Defense (DoD) has denied these allegations with statements by military officials and spokespersons, as well as a January 2013 report authored by Dr. Alvin Young that was released in April 2013.

In particular, the 2013 report refuted articles written by journalist Jon Mitchell as well as a statement from "An Ecological Assessment of Johnston Atoll" a 2003 publication produced by the United States Army Chemical Materials Agency that states, "in 1972, the U.S. Air Force also brought about 25,000 200L drums of the chemical, Herbicide Orange (HO) to Johnston Island that originated from Vietnam and was stored on Okinawa." The 2013 report stated: "The authors of the [2003] report were not DoD employees, nor were they likely familiar with the issues surrounding Herbicide Orange or its actual history of transport to the Island." and detailed the transport phases and routes of Agent Orange from Vietnam to Johnston Atoll, none of which included Okinawa.

Further official confirmation of restricted (dioxin containing) herbicide storage on Okinawa appeared in a 1971 Fort Detrick report titled "Historical, Logistical, Political and Technical Aspects of the Herbicide/Defoliant Program", which mentioned that the environmental statement should consider "Herbicide stockpiles elsewhere in PACOM (Pacific Command) U.S. Government restricted materials Thailand and Okinawa (Kadena AFB)." The 2013 DoD report says that the environmental statement urged by the 1971 report was published in 1974 as "The Department of Air Force Final Environmental Statement", and that the latter did not find Agent Orange was held in either Thailand or Okinawa.

Agent Orange was tested by the United States in Thailand during the war in Southeast Asia. Buried drums were uncovered and confirmed to be Agent Orange in 1999. Workers who uncovered the drums fell ill while upgrading the airport near Hua Hin District, 100 km south of Bangkok.

Vietnam-era veterans whose service involved duty on or near the perimeters of military bases in Thailand anytime between February 28, 1961, and May 7, 1975, may have been exposed to herbicides and may qualify for VA benefits.

A declassified Department of Defense report written in 1973, suggests that there was a significant use of herbicides on the fenced-in perimeters of military bases in Thailand to remove foliage that provided cover for enemy forces.

In 2013, VA determined that herbicides used on the Thailand base perimeters may have been tactical and procured from Vietnam, or a strong, commercial type resembling tactical herbicides.

The University of Hawaii has acknowledged extensive testing of Agent Orange on behalf of the United States Department of Defense in Hawaii along with mixtures of Agent Orange on Kaua'i Island in 1967–68 and on Hawaii Island in 1966; testing and storage in other U.S. locations has been documented by the United States Department of Veterans Affairs.

In 1971, the C-123 aircraft used for spraying Agent Orange were returned to the United States and assigned various East Coast USAF Reserve squadrons, and then employed in traditional airlift missions between 1972 and 1982. In 1994, testing by the Air Force identified some former spray aircraft as "heavily contaminated" with dioxin residue. Inquiries by aircrew veterans in 2011 brought a decision by the U.S. Department of Veterans Affairs opining that not enough dioxin residue remained to injure these post-Vietnam War veterans. On 26 January 2012, the U.S. Center For Disease Control's Agency for Toxic Substances and Disease Registry challenged this with their finding that former spray aircraft were indeed contaminated and the aircrews exposed to harmful levels of dioxin. In response to veterans' concerns, the VA in February 2014 referred the C-123 issue to the Institute of Medicine for a special study, with results released on January 9, 2015.

In 1978, the U.S. Environmental Protection Agency suspended spraying of Agent Orange in National Forests.

A December 2006 Department of Defense report listed Agent Orange testing, storage, and disposal sites at 32 locations throughout the United States, as well as in Canada, Thailand, Puerto Rico, Korea, and in the Pacific Ocean. The Veteran Administration has also acknowledged that Agent Orange was used domestically by U.S. forces in test sites throughout the United States. Eglin Air Force Base in Florida was one of the primary testing sites throughout the 1960s.

In February 2012, Monsanto agreed to settle a case covering Dioxin contamination around a plant in Nitro, West Virginia, that had manufactured Agent Orange. Monsanto agreed to pay up to $9 million for cleanup of affected homes, $84 million for medical monitoring of people affected, and the community's legal fees.

On 9 August 2012, the United States and Vietnam began a cooperative cleaning up of the toxic chemical on part of Danang International Airport, marking the first time Washington has been involved in cleaning up Agent Orange in Vietnam. Danang was the primary storage site of the chemical. Two other cleanup sites the United States and Vietnam are looking at is Biên Hòa, in the southern province of Đồng Nai—a "hotspot" for dioxin—and Phù Cát airport in the central province of Bình Định, says U.S. Ambassador to Vietnam David Shear. According to the Vietnamese newspaper "Nhân Dân", the U.S. government provided $41 million to the project, which will reduce the contamination level in 73,000 cubic meters of soil by late 2016. Some 45,000 cubic meters were "cleaned", an equal amount began in October 2016 scheduled for completion in mid 2017.

The Seabee's Naval Construction Battalion Center at Gulfport, Mississippi was the largest storage site in the United States for agent orange. It was 30 odd acres in size and was still being cleaned up in 2013. 
Due to the fact that destruction requires high temperatures (over 1000 °C), the destruction process is energy intensive.








</doc>
<doc id="2551" url="https://en.wikipedia.org/wiki?curid=2551" title="Astronomical year numbering">
Astronomical year numbering

Astronomical year numbering is based on AD/CE year numbering, but follows normal decimal integer numbering more strictly. Thus, it has a year 0; the years before that are designated with negative numbers and the years after that are designated with positive numbers. Astronomers use the Julian calendar for years before 1582, including the year 0, and the Gregorian calendar for years after 1582, as exemplified by Jacques Cassini (1740), Simon Newcomb (1898) and Fred Espenak (2007).

The prefix AD and the suffixes CE, BC or BCE (Common Era, Before Christ or Before Common Era) are dropped. The year 1 BC/BCE is numbered 0, the year 2 BC is numbered −1, and in general the year "n" BC/BCE is numbered "−("n" − 1)" (a negative number equal to 1 − "n"). The numbers of AD/CE years are not changed and are written with either no sign or a positive sign; thus in general "n" AD/CE is simply "n" or +"n". For normal calculation a number zero is often needed, here most notably when calculating the number of years in a period that spans the epoch; the end years need only be subtracted from each other.

The system is so named due to its use in astronomy. Few other disciplines outside history deal with the time before year 1, some exceptions being dendrochronology, archaeology and geology, the latter two of which use 'years before the present'. Although the absolute numerical values of astronomical and historical years only differ by one before year 1, this difference is critical when calculating astronomical events like eclipses or planetary conjunctions to determine when historical events which mention them occurred.

In his Rudolphine Tables (1627), Johannes Kepler used a prototype of year zero which he labeled "Christi" (Christ's) between years labeled "Ante Christum" (Before Christ) and "Post Christum" (After Christ) on the mean motion tables for the Sun, Moon, Saturn, Jupiter, Mars, Venus and Mercury. In 1702, the French astronomer Philippe de la Hire used a year he labeled at the end of years labeled "ante Christum" (BC), and immediately before years labeled "post Christum" (AD) on the mean motion pages in his "Tabulæ Astronomicæ", thus adding the designation "0" to Kepler's "Christi". Finally, in 1740 the French astronomer Jacques Cassini , who is traditionally credited with the invention of year zero, completed the transition in his "Tables astronomiques", simply labeling this year "0", which he placed at the end of Julian years labeled "avant Jesus-Christ" (before Jesus Christ or BC), and immediately before Julian years labeled "après Jesus-Christ" (after Jesus Christ or AD).

Cassini gave the following reasons for using a year 0:
Fred Espanak of NASA lists 50 phases of the moon within year 0, showing that it is a full year, not an instant in time. Jean Meeus gives the following explanation:
Although he used the usual French terms "avant J.-C." (before Jesus Christ) and "après J.-C." (after Jesus Christ) to label years elsewhere in his book, the Byzantine historian Venance Grumel used negative years (identified by a minus sign, −) to label BC years and unsigned positive years to label AD years in a table. He did so possibly to save space and put no year 0 between them.

Version 1.0 of the XML Schema language, often used to describe data interchanged between computers in XML, includes built-in primitive datatypes date and dateTime. Although these are defined in terms of ISO 8601 which uses the proleptic Gregorian calendar and therefore should include a year 0, the XML Schema specification states that there is no year zero. Version 1.1 of the defining recommendation realigned the specification with ISO 8601 by including a year zero, despite the problems arising from the lack of backward compatibility.



</doc>
<doc id="2552" url="https://en.wikipedia.org/wiki?curid=2552" title="Adam of Bremen">
Adam of Bremen

Adam of Bremen (; ) (Before 1050 – 12 October 1081/1085) was a German medieval chronicler. He lived and worked in the second half of the eleventh century. Adamus is most famous for his chronicle "Gesta Hammaburgensis Ecclesiae Pontificum" ("Deeds of Bishops of the Hamburg Church").

Little is known of his life other than hints from his own chronicles. He is believed to have come from Meissen (Latin "Misnia") in Saxony. The dates of his birth and death are uncertain, but he was probably born before 1050 and died on 12 October of an unknown year (possibly 1081, at the latest 1085). From his chronicles it is apparent that he was familiar with a number of authors. The honorary name of "Magister Adam" shows that he had passed through all the stages of a higher education. It is probable that he was taught at the "Magdeburger Domschule".

In 1066 or 1067 he was invited by archbishop Adalbert of Hamburg to join the Church of Bremen. Adam was accepted among the capitulars of Bremen, and by 1069 he appeared as director of the cathedral's school. Soon thereafter he began to write the history of Bremen/Hamburg and of the northern lands in his "Gesta".

His position and the missionary activity of the church of Bremen allowed him to gather information on the history and the geography of Northern Germany. A stay at the court of Svend Estridsen gave him the opportunity to find information about the history and geography of Denmark and the other Scandinavian countries. Among other things he wrote about in Scandinavia were the sailing passages across Øresund such as today's Elsinore to Helsingborg route.




</doc>
<doc id="2553" url="https://en.wikipedia.org/wiki?curid=2553" title="Ab urbe condita">
Ab urbe condita

Ab urbe condita (), or Anno urbis conditæ (), often abbreviated as AUC in either case, is a convention that was used in antiquity and by classical historians to refer to a given year in Ancient Rome. "Ab urbe condita" literally means "from the founding of the City", while "anno urbis conditæ" means "in the year since the City's founding". Therefore, the traditional year of the foundation of Rome, 753 BC, would be written AUC 1, while AD 1 would be AUC 754. The foundation of the Empire in 27 BC would be AUC 727.

Usage of the term was more common during the Renaissance, when editors sometimes added AUC to Roman manuscripts they published, giving the false impression that the convention was commonly used in antiquity. In reality, the dominant method of identifying years in Roman times was to name the two consuls who held office that year. In late antiquity, regnal years were also in use, as was the Diocletian era in Roman Egypt after AD 293, and in the Byzantine Empire after AD 537, following a decree by Justinian.

The traditional date for the founding of Rome, 21 April 753 BC, is due to Marcus Terentius Varro (First Century BC). Varro may have used the consular list (with its mistakes) and called the year of the first consuls ""ab urbe condita" 245," accepting the 244-year interval from Dionysius of Halicarnassus for the kings after the foundation of Rome. The correctness of this calculation has not been confirmed, but it is still used worldwide.

From the time of Claudius (ruled AD 41 to AD 54) onward, this calculation superseded other contemporary calculations. Celebrating the anniversary of the city became part of imperial propaganda. Claudius was the first to hold magnificent celebrations in honor of the anniversary of the city, in AD 48, the eight hundredth year from the founding of the city. Hadrian and Antoninus Pius held similar celebrations, in AD 121, and in AD 147 and AD 148, respectively.

In AD 248, Philip the Arab celebrated Rome's first millennium, together with Ludi saeculares for Rome's alleged tenth sæculum. Coins from his reign commemorate the celebrations. A coin by a contender for the imperial throne, Pacatianus, explicitly states "[y]ear one thousand and first", which is an indication that the citizens of the empire had a sense of the beginning of a new era, a "Sæculum Novum".

The Anno Domini (AD) year numbering was developed by a monk named Dionysius Exiguus in Rome in AD 525, as a result of his work on calculating the date of Easter. 
Dionysius did not use the AUC convention, but instead based his calculations on the 
Diocletian era.
This convention had been in use since AD 293, the year of the tetrarchy, as it became impractical to use regnal years of the current emperor.
In his Easter table, the year AD 532 was equated with the 248th regnal year of Diocletian. The table counted the years starting from the presumed birth of Christ, rather than the accession of the emperor Diocletian on 20 November AD 284, or as stated by Dionysius: ""sed magis elegimus ab incarnatione Domini nostri Jesu Christi annorum tempora praenotare"" ("but rather we choose to name the times of the years from the incarnation of our Lord Jesus Christ"). Blackburn and Holford-Strevens review interpretations of Dionysius which place the Incarnation in 2 BC, 1 BC, or AD 1. 

It has later been calculated (from the historical record of the succession of Roman consuls) that the year AD 1 corresponds to AUC 754, based on the epoch of Varro. 
Thus, 



</doc>
<doc id="2559" url="https://en.wikipedia.org/wiki?curid=2559" title="Arapaoa Island">
Arapaoa Island

Arapaoa Island, formerly known as Arapawa Island, is a small island located in the Marlborough Sounds, at the north east tip of the South Island of New Zealand.
The island has a land area of . Queen Charlotte Sound defines its western side, while to the south lies Tory Channel, which is on the sea route from Wellington in the North Island to Picton. Cook Strait's narrowest point is between Arapaoa Island's Perano Head and Cape Terawhiti in the North Island.

According to Māori oral tradition, the island was where the great navigator Kupe killed the octopus Te Wheke-a-Muturangi.

It was from a hill on Arapaoa Island in 1770 that Captain James Cook first saw the sea passage from the Pacific Ocean to the Tasman Sea, which was named Cook Strait. This discovery banished the fond notion of geographers that there existed a great southern continent, Terra Australis. A monument at Cook's Lookout was erected in 1970.

From the late 1820s until the mid-1960s, Arapaoa Island was a base for whaling in the Sounds. John Guard established a shore station at Te Awaiti in 1827 for right whales. Later, the station at Perano Head on the east coast of the island was used to hunt humpback whales from 1911 to 1964 (see Whaling in New Zealand). The houses built by the Perano family are now operated as tourist accommodations.

In August 2014, the spelling of the island's name was officially altered from "Arapawa" to "Arapaoa".

The 11,000-volt power lines linking the mainland and Arapaoa Island over Tory Channel was struck by an Air Albatross Cessna 402 commuter aircraft in 1985. The crash was witnessed by many passengers on an inter-island Cook Strait ferry. The ferry immediately stopped to dispatch a rescue lifeboat. Along with the two pilots, one entire family died, and all but a young girl from the other. No bodies were ever found. The sole survivor (Cindy Mosey) was travelling with her family and the other family from Nelson to Wellington to attend a gymnastics competition. The Arapaoa Island crash caused public confidence in Air Albatross to falter, contributing to the company going into liquidation in December of that year.

Parts of the island have been heavily cleared of native vegetation in the past through burning and logging, A number of pine forests were planted on the island. Wilding pines, an invasive species in some parts of New Zealand, are being poisoned on the island to allow the regenerating native vegetation to grow. About at Ruaomoko Point on the south-eastern portion of the island will be killed by drilling holes into the trees and injecting poison.

Arapaoa Island is known for the breeds of pigs, sheep and goats found only on the island. These became established in the 19th century, but the origin of these breeds is uncertain, and a matter of some speculation. Common suggestions are that they are old English breeds introduced by the early whalers, or by Captain Cook or other early explorers. These breeds are now extinct in England, and the goats surviving in a sanctuary on the island are now also bred in other parts of New Zealand and in the northern hemisphere.

The small Brothers Islands, which lie off the northeast coast of Arapaoa Island, are a sanctuary for the rare Brothers Island tuatara.




</doc>
<doc id="2560" url="https://en.wikipedia.org/wiki?curid=2560" title="Administrative law">
Administrative law

Administrative law is the body of law that governs the activities of administrative agencies of government. Government agency action can include rule making, adjudication, or the enforcement of a specific regulatory agenda. Administrative law is considered a branch of public law. 

Administrative law deals with the decision-making of such administrative units of government as tribunals, boards or commissions that are part of a national regulatory scheme in such areas as police law, international trade, manufacturing, the environment, taxation, broadcasting, immigration and transport. 

Administrative law expanded greatly during the twentieth century, as legislative bodies worldwide created more government agencies to regulate the social, economic and political spheres of human interaction.

Civil law countries often have specialized administrative courts that review these decisions.
Unlike most common-law jurisdictions, the majority of civil law jurisdictions have specialized courts or sections to deal with administrative cases which, as a rule, will apply procedural rules specifically designed for such cases and distinct from those applied in private-law proceedings, such as contract or tort claims.

In Brazil, unlike most Civil-law jurisdictions, there is no specialized court or section to deal with administrative cases. In 1998, a constitutional reform, led by the government of President Fernando Henrique Cardoso, introduced regulatory agencies as a part of the executive branch. Since 1988, Brazilian administrative law has been strongly influenced by the judicial interpretations of the constitutional principles of public administration (art. 37 of Federal Constitution): legality, impersonality, publicity of administrative acts, morality and efficiency.

In Chile the President of the Republic exercises the administrative function, in collaboration with several Ministries or other authorities with "ministerial rank". Each Ministry has one or more under-secretary that performs through public services the actual satisfaction of public needs. There is not a single specialized court to deal with actions against the Administrative entities, but instead there are several specialized courts and procedures of review.

In France, most claims against the national or local governments as well as claims against private bodies providing public services are handled by administrative courts, which use the "Conseil d'État" (Council of State) as a court of last resort for both ordinary and special courts. The main administrative courts are the "tribunaux administratifs" and appeal courts are the "cours administratives d'appel". Special administrative courts include the National Court of Asylum Right as well as military, medical and judicial disciplinary bodies. The French body of administrative law is called ""droit administratif"".

Over the course of their history, France's administrative courts have developed an extensive and coherent case law ("jurisprudence constante") and legal doctrine ("principes généraux du droit" and "principes fondamentaux reconnus par les lois de la République"), often before similar concepts were enshrined in constitutional and legal texts. These principes include:


French administrative law, which is the founder of Continental administrative law, has a strong influence on administrative laws in several other countries such as Belgium, Greece, Turkey and Tunisia.

In Germany administrative law is called "Verwaltungsrecht" , which generally rules the relationship between authorities and the citizens. It establishes citizens' rights and obligations against the
authorities. It is a part of the public law, which deals with the organization, the tasks and the acting of the public administration. It also contains rules, regulations, orders and decisions created by and related to administrative agencies, such as federal agencies, federal state authorities, urban administrations, but also admission offices and fiscal authorities etc. Administrative law in Germany follows three basic principles.


Administrative law in Germany can be divided into general administrative law and special administrative law.

The general administration law is basically ruled in the administrative procedures law ("Verwaltungsverfahrensgesetz" [VwVfG]). Other legal sources are the Rules of the Administrative Courts (Verwaltungsgerichtsordnung [VwGO]), the social security code (Sozialgesetzbuch [SGB]) and the general fiscal law (Abgabenordnung [AO]).

The "Verwaltungsverfahrensgesetz" (VwVfG), which was enacted in 1977, regulates the main administrative procedures of the federal government. It serves the purpose to ensure a treatment in accordance with the rule of law by the public authority. Furthermore, it contains the regulations for mass processes and expands the legal protection against the authorities. The VwVfG basically applies for the entire public administrative activities of federal agencies as well as federal state authorities, in case of making federal law. One of the central clause is § 35 VwVfG. It defines the administrative act, the most common form of action in which the public administration occurs against a citizen. The definition in § 35 says, that an administration act is characterized by the following features:

It is an official act of an authority in the field of public law to resolve an individual case with effect to the outside.

§§ 36 – 39, §§ 58 – 59 and § 80 VwV––fG rule the structure and the necessary elements of the
administrative act. § 48 and § 49 VwVfG have a high relevance in practice, as well. In these
paragraphs, the prerequisites for redemption of an unlawful administration act (§ 48 VwVfG ) and
withdrawal of a lawful administration act (§ 49 VwVfG ), are listed.

Administration procedural law (Verwaltungsgerichtsordnung [VwGO]), which was enacted in 1960, rules the court procedures at the administrative court. The VwGO is divided into five parts, which are the constitution of the courts, action, remedies and retrial, costs and enforcement15 and final clauses and temporary arrangements.

In absence of a rule, the VwGO is supplemented by the code of civil procedure (Zivilprozessordnung [ZPO]) and the judicature act (Gerichtsverfassungsgesetz [GVG]). In addition to the regulation of the administrative procedure, the VwVfG also constitutes the legal protection in administrative law beyond the court procedure. § 68 VwVGO rules the preliminary proceeding, called "Vorverfahren" or "Widerspruchsverfahren", which is a stringent prerequisite for the administrative procedure, if an action for rescission or a writ of mandamus against an authority is aimed. The preliminary proceeding gives each citizen, feeling unlawfully mistreated by an authority, the possibility to object and to force a review of an administrative act without going to court. The prerequisites to open the public law remedy are listed in § 40 I VwGO. Therefore, it is necessary to have the existence of a conflict in public law without any constitutional aspects and no assignment to another jurisdiction.

The social security code (Sozialgesetzbuch [SGB]) and the general fiscal law are less important for the administrative law. They supplement the VwVfG and the VwGO in the fields of taxation and social legislation, such as social welfare or financial support for students (BaFÖG) etc.

The special administrative law consists of various laws. Each special sector has its own law. The most important ones are the


In Germany, the highest administrative court for most matters is the federal administrative court Bundesverwaltungsgericht. There are federal courts with special jurisdiction in the fields of social security law (Bundessozialgericht) and tax law (Bundesfinanzhof).

In Italy administrative law is known as ""'Diritto amministrativo"", a branch of public law whose rules govern the organization of the public administration and the activities of the pursuit of the public interest of the public administration and the relationship between this and the citizens.
Its genesis is related to the principle of division of powers of the State. The administrative power, originally called "executive", is to organize resources and people whose function is devolved to achieve the public interest objectives as defined by the law.

In the Netherlands administrative law provisions are usually contained in separate laws. There is however a single General Administrative Law Act ("Algemene wet bestuursrecht" or Awb) that applies both to the making of administrative decisions and the judicial review of these decisions in courts. On the basis of the Awb, citizens can oppose a decision ('besluit') made by an administrative agency ('bestuursorgaan') within the administration and apply for judicial review in courts if unsuccessful.

Unlike France or Germany, there are no special administrative courts of first instance in the Netherlands, but regular courts have an administrative "chamber" which specializes in administrative appeals. The courts of appeal in administrative cases however are specialized depending on the case, but most administrative appeals end up in the judicial section of the Council of State (Raad van State).

Before going to court, citizens must usually first object to the decision with the administrative body who made it. This is called "bezwaar". This procedure allows for the administrative body to correct possible mistakes themselves and is used to filter cases before going to court. Sometimes, instead of bezwaar, a different system is used called "administratief beroep" (administrative appeal). The difference with bezwaar is that administratief beroep is filed with a different administrative body, usually a higher ranking one, than the administrative body that made the primary decision. Administratief beroep is available only if the law on which the primary decision is based specifically provides for it. An example involves objecting to a traffic ticket with the district attorney ("officier van justitie"), after which the decision can be appealed in court.

In addition, Netherlands General Administrative Law Act (GALA) is a rather good sample of procedural laws in Europe

Administrative law in the People's Republic of China was virtually non-existent before the economic reform era initiated by Deng Xiaoping. Since the 1980s, the People's Republic of China has constructed a new legal framework for administrative law, establishing control mechanisms for overseeing the bureaucracy and disciplinary committees for the Communist Party of China. However, many have argued that the usefulness of these laws is vastly inadequate in terms of controlling government actions, largely because of institutional and systemic obstacles like a weak judiciary, poorly trained judges and lawyers, and corruption.

In 1990, the Administrative Supervision Regulations (行政检查条例) and the Administrative Reconsideration Regulations (行政复议条例) were passed. The 1993 State Civil Servant Provisional Regulations (国家公务员暂行条例) changed the way government officials were selected and promoted, requiring that they pass exams and yearly appraisals, and introduced a rotation system. The three regulations have been amended and upgraded into laws. In 1994, the State Compensation Law (国家赔偿法) was passed, followed by the Administrative Penalties Law (行政处罚法) in 1996. Administrative Compulsory Law was enforced in 2012. Administrative Litigation Law was amended in 2014. The General Administrative Procedure Law is under way.

In the Republic of China the recently enacted "Constitutional Procedure Act" (憲法訴訟法) in 2019 (former "Constitutional Interpretation Procedure Act, 1993"), the Justices of the Constitutional Court of Judicial Yuan of Taiwan is in charge of judicial interpretation. This council has made 757 interpretations to date .

In Sweden, there is a system of administrative courts that considers only administrative law cases, and is completely separate from the system of general courts. This system has three tiers, with 12 county administrative courts ("förvaltningsrätt") as the first tier, four administrative courts of appeal ("kammarrätt") as the second tier, and the Supreme Administrative Court of Sweden ("Högsta Förvaltningsdomstolen") as the third tier.

Migration cases are handled in a two-tier system, effectively within the system general administrative courts. Three of the administrative courts serve as migration courts ("migrationsdomstol") with the Administrative Court of Appeal in Stockholm serving as the Migration Court of Appeal ("Migrationsöverdomstolen").

In Turkey, the lawsuits against the acts and actions of the national or local governments and public bodies are handled by administrative courts which are the main administrative courts. The decisions of the administrative courts are checked by the Regional Administrative Courts and Council of State. Council of State as a court of last resort is exactly similar to Conseil d'État in France.

Administrative law in the Ukraine is a homogeneous legal substance isolated in a system of jurisprudence characterized as: (1) a branch of law; (2) a science; (3) a discipline.

Generally speaking, most countries that follow the principles of common law have developed procedures for judicial review that limit the reviewability of decisions made by administrative law bodies. Often these procedures are coupled with legislation or other common law doctrines that establish standards for proper rulemaking. Administrative law may also apply to review of decisions of so-called semi-public bodies, such as non-profit corporations, disciplinary boards, and other decision-making bodies that affect the legal rights of members of a particular group or entity.

While administrative decision-making bodies are often controlled by larger governmental units, their decisions could be reviewed by a court of general jurisdiction under some principle of judicial review based upon due process (United States) or fundamental justice (Canada). Judicial review of administrative decisions is different from an administrative appeal. When sitting in review of a decision, the Court will only look at the method in which the decision was arrived at, whereas in an administrative appeal the correctness of the decision itself will be examined, usually by a higher body in the agency. This difference is vital in appreciating administrative law in common law countries.

The scope of judicial review may be limited to certain questions of fairness, or whether the administrative action is "ultra vires". In terms of ultra vires actions in the broad sense, a reviewing court may set aside an administrative decision if it is unreasonable (under Canadian law, following the rejection of the "Patently Unreasonable" standard by the Supreme Court in Dunsmuir v New Brunswick), "Wednesbury" unreasonable (under British law), or arbitrary and capricious (under U.S. Administrative Procedure Act and New York State law). Administrative law, as laid down by the Supreme Court of India, has also recognized two more grounds of judicial review which were recognized but not applied by English Courts, namely legitimate expectation and proportionality.

The powers to review administrative decisions are usually established by statute, but were originally developed from the royal prerogative writs of English law, such as the writ of mandamus and the writ of certiorari. In certain common law jurisdictions, such as India or Pakistan, the power to pass such writs is a Constitutionally guaranteed power. This power is seen as fundamental to the power of judicial review and an aspect of the independent judiciary.

In the United States, many government agencies are organized under the executive branch of government, although a few are part of the judicial or legislative branches.

In the federal government, the executive branch, led by the president, controls the federal executive departments, which are led by secretaries who are members of the United States Cabinet. The many independent agencies of the United States government created by statutes enacted by Congress exist outside of the federal executive departments but are still part of the executive branch.

Congress has also created some special judicial bodies known as Article I tribunals to handle some areas of administrative law.

The actions of executive agencies and independent agencies are the main focus of American administrative law. In response to the rapid creation of new independent agencies in the early twentieth century (see discussion below), Congress enacted the Administrative Procedure Act (APA) in 1946. Many of the independent agencies operate as miniature versions of the tripartite federal government, with the authority to "legislate" (through rulemaking; see Federal Register and Code of Federal Regulations), "adjudicate" (through administrative hearings), and to "execute" administrative goals (through agency enforcement personnel). Because the United States Constitution sets no limits on this tripartite authority of administrative agencies, Congress enacted the APA to establish fair administrative law procedures to comply with the constitutional requirements of due process. Agency procedures are drawn from four sources of authority: the APA, organic statutes, agency rules, and informal agency practice. It is important to note, though, that agencies can only act within their congressionally delegated authority, and must comply with the requirements of the APA.

The American Bar Association's official journal concerning administrative law is the "Administrative Law Review", a quarterly publication that is managed and edited by students at the Washington College of Law.

Stephen Breyer, a U.S. Supreme Court Justice since 1994, divides the history of administrative law in the United States into six discrete periods, in his book, "Administrative Law & Regulatory Policy" (3d Ed., 1992):


The agricultural sector is one of the most heavily regulated sectors in the U.S. economy, as it is regulated in various ways at the international, federal, state, and local levels. Consequently, administrative law is a significant component of the discipline of agricultural law. The United States Department of Agriculture and its myriad agencies such as the Agricultural Marketing Service are the primary sources of regulatory activity, although other administrative bodies such as the Environmental Protection Agency play a significant regulatory role as well.



</doc>
<doc id="2563" url="https://en.wikipedia.org/wiki?curid=2563" title="Arthur Phillip">
Arthur Phillip

Admiral Arthur Phillip (11 October 1738 – 31 August 1814) was a Royal Navy officer and the first Governor of New South Wales who founded the British penal colony that later became the city of Sydney, Australia.

After much experience at sea, Phillip sailed with the First Fleet as Governor-designate of the proposed British penal colony of New South Wales. In January 1788, he selected its location to be Port Jackson (encompassing Sydney Harbour).

Phillip was a far-sighted governor who soon saw that New South Wales would need a civil administration and a system for emancipating the convicts. But his plan to bring skilled tradesmen on the voyage had been rejected, and he faced immense problems of labour, discipline and supply. 

The arrival of the Second and Third Fleets placed new pressures on the scarce local resources, but by the time Phillip sailed home in December 1792, the colony was taking shape, with official land-grants and systematic farming and water-supply.

Phillip retired in 1805, but continued to correspond with his friends in New South Wales and to promote the colony's interests.

Captain Arthur Phillip was born on 11 October 1738, the youngest of two children to Jacob Phillip and Elizabeth Breach. His father Jacob was born in Frankfurt, Germany. He was a languages teacher who may also have served in the Royal Navy as an able seaman and purser's steward. His mother Elizabeth was the widow of an ordinary seaman, John Herbert, who had served in Jamaica aboard HMS "Tartar" and died of disease on 13 August 1732. At the time of Arthur Phillip's birth, his family maintained a modest existence as tenants near Cheapside in the City of London.

There are no surviving records of Phillip's early childhood. His father Jacob died in 1739, after which the Phillip family may have fallen on hard times. On 22 June 1751 he was accepted into the Greenwich Hospital School, a charity school for the sons of indigent seafarers. In keeping with the school's curriculum, his education was focused on literacy, arithmetic and navigational skills, including cartography. He was a competent student and something of a perfectionist. His headmaster, Reverend Francis Swinden observed that in personality Phillip was "unassuming, reasonable, business-like to the smallest degree in everything he undertakes".

Phillip remained at the Greenwich School for two and a half years, considerably longer than the average student stay of twelve months. At the end of 1753 he was granted a seven-year indenture as an apprentice aboard "Fortune", a 210-ton whaling vessel commanded by merchant mariner Wiliam Readhead. He left the Greenwich School on 1 December and spent the winter aboard the "Fortune" awaiting the commencement of the 1754 whaling season.

Phillip spent the summer of 1754 hunting whales near Svalbard in the Barents Sea. As an apprentice, his responsibilities included stripping blubber from whale carcasses and helping to pack it into barrels. Food was scarce and "Fortune"s thirty crew members supplemented their diet with bird's eggs, scurvy grass and where possible, reindeer. The ship returned to England on 20 July 1754. The whaling crew were paid off and replaced with twelve sailors for a winter voyage to the Mediterranean. As an apprentice, Phillip remained aboard as "Fortune" undertook an outward trading voyage to Barcelona and Livorno carrying salt and raisins, returning via Rotterdam with a cargo of grains and citrus. The ship returned to England in April 1755 and sailed immediately for Svalbard for that year's whale hunt. Phillip was still a member of the crew, but abandoned his apprenticeship when the ship returned to England on 27 July. On 16 October he enlisted in the Royal Navy and was assigned the rank of ordinary seaman aboard the 68-gun .
As a member of "Buckingham"s crew, Phillip saw action in the Seven Years' War, including the Battle of Minorca in 1756. By 1762 he had transferred to , and was promoted to Lieutenant in recognition of active service in the Battle of Havana. The War ended in 1763 and Phillip returned to England on half pay. In July 1763 he married Margaret Denison, a widow 16 years his senior, and moved to Glasshayes in Lyndhurst, Hampshire, establishing a farm there. The marriage was unhappy, and the couple separated in 1769 when Phillip returned to the Navy. The following year he was posted as second lieutenant aboard , a newly built 74-gun ship of the line.

In 1774 Phillip joined the Portuguese Navy as a captain, serving in the War against Spain. While with the Portuguese Navy, Phillip commanded a frigate, the "Nossa Senhora do Pilar." On this ship he took a detachment of troops from Rio de Janeiro to Colonia do Sacramento on the Río de la Plata (opposite Buenos Aires) to relieve the garrison there. This voyage also conveyed a consignment of convicts assigned to carry out work at Colonia. During a storm encountered in the course of the voyage, the convicts assisted in working the ship and, on arrival at Colonia, Phillip recommended that they be rewarded for saving the ship by remission of their sentences. A garbled version of this eventually found its way into the English press when Phillip was appointed in 1786 to lead the expedition to Sydney. Phillip played a leading part in the capture of the Spanish ship San Agustín, on 19 April 1777, off Santa Catarina. The "San Agustin" was commissioned into the Portuguese Navy as the "Santo Agostinho", and command of her was given to Phillip. The action was reported in the English press: 
Madrid, Aug. 28. Letters from Lisbon bring the following Account from Rio Janeiro: That the St. Augustine, of 70 Guns, having been separated from the Squadron of M. Casa Tilly, was attacked by two Portugueze Ships, against which they defended themselves for a Day and a Night, but being next Day surrounded by the Portugueze Fleet, was obliged to surrender.

In 1778 Britain was again at war, and Phillip was recalled to active service, and in 1779 obtained his first command, HMS "Basilisk". He was promoted to post-captain on 30 November 1781 and given command of .

In July 1782, in a change of government, Thomas Townshend became Secretary of State for Home and American Affairs, and assumed responsibility for organising an expedition against Spanish America. Like his predecessor, Lord Germain, he turned for advice to Arthur Phillip. A letter from Phillip to Sandwich of 17 January 1781 records Phillip's loan to Sandwich of his charts of the Plata and Brazilian coasts for use in organising the expedition. Phillip's plan was for a squadron of three ships of the line and a frigate to mount a raid on Buenos Aires and Monte Video, then to proceed to the coasts of Chile, Peru and Mexico to maraud, and ultimately to cross the Pacific to join the British Navy's East India squadron for an attack on Manila. The expedition, consisting of the "Grafton," 70 guns, "Elizabeth," 74 guns, "Europe," 64 guns, and the frigate "Iphigenia", sailed on 16 January 1783, under the command of Commodore Robert Kingsmill. Phillip was given command of the 64-gun , or "Europe". Shortly after sailing, an armistice was concluded between Great Britain and Spain. Phillip learnt of this in April when he put in for storm repairs at Rio de Janeiro. Phillip wrote to Townshend from Rio de Janeiro on 25 April 1783, expressing his disappointment that the ending of the American War had robbed him of the opportunity for naval glory in South America.

After his return to England from India in April 1784, Phillip remained in close contact with Townshend, now Lord Sydney, and the Home Office Under Secretary, Evan Nepean. From October 1784 to September 1786 he was employed by Nepean, who was in charge of the Secret Service relating to the Bourbon Powers, France and Spain, to spy on the French naval arsenals at Toulon and other ports. There was fear that Britain would soon be at war with these powers as a consequence of the Batavian Revolution in the Netherlands.

Portraits of the time depict Phillip as shorter than average, with an olive complexion, dark eyes and a "smooth pear of a skull". His features were dominated by a large and fleshy nose, and by a pronounced lower lip.

At this time, Lord Sandwich, together with the President of the Royal Society, Sir Joseph Banks, was advocating establishment of a British colony in New South Wales. A colony there would be of great assistance to the British Navy in facilitating attacks on the Spanish possessions in Chile and Peru, as Banks's collaborators, James Matra, Captain Sir George Young and Sir John Call pointed out in written proposals on the subject. The British Government took the decision to settle what is now Australia and found the Botany Bay colony in August 1786. Lord Sydney, as Secretary of State for the Home Office, was the minister in charge, and in September 1786 he appointed Phillip commodore of the fleet which was to transport the convicts and soldiers who were to be the new settlers to Botany Bay. Upon arrival there, Phillip was to assume the powers of Captain General and Governor in Chief of the new colony. A subsidiary colony was to be founded on Norfolk Island, as recommended by Sir John Call, to take advantage for naval purposes of that island's native flax (harakeke) and timber.

In October 1786, Phillip was appointed captain of and named Governor-designate of New South Wales, the proposed British colony on the east coast of Australia, by Lord Sydney, the Home Secretary.

Phillip had a very difficult time assembling the fleet which was to make the eight-month sea voyage to Australia. Everything a new colony might need had to be taken, since Phillip had no real idea of what he might find when he got there. There were few funds available for equipping the expedition. His suggestion that people with experience in farming, building and crafts be included was rejected. Most of the 772 convicts (of whom 732 survived the voyage) were petty thieves from the London slums. Phillip was accompanied by a contingent of marines and a handful of other officers who were to administer the colony.

The 11 ships of the First Fleet set sail from Portsmouth on 13 May 1787. The fleet called at Rio de Janeiro for supplies from 6 August to 4 September. The leading ship, reached Botany Bay setting up camp on the Kurnell Peninsula, on 18 January 1788. Phillip soon decided that this site, chosen on the recommendation of Sir Joseph Banks, who had accompanied James Cook in 1770, was not suitable, since it had poor soil, no secure anchorage and no reliable water source. After some exploration Phillip decided to go on to Port Jackson, and on 26 January the marines and convicts landed at Sydney Cove, which Phillip named after Lord Sydney.

Shortly after landing and establishing the settlement at Port Jackson, on 15 February 1788, Phillip sent Lieutenant Philip Gidley King with eight free men and a number of convicts to establish the second British colony in the Pacific at Norfolk Island. This was partly in response to a perceived threat of losing Norfolk Island to the French and partly to establish an alternative food source for the mainland colony.

The early days of the settlement in New South Wales were chaotic and difficult. With limited supplies, the cultivation of food was imperative, but the soils around Sydney were poor, the climate was unfamiliar, and moreover very few of the convicts had any knowledge of agriculture. The colony was on the verge of outright starvation for an extended period. The marines, poorly disciplined themselves in many cases, were not interested in convict discipline. Almost at once, therefore, Phillip had to appoint overseers from among the ranks of the convicts to get the others working. This was the beginning of the process of convict emancipation which was to culminate in the reforms of Lachlan Macquarie after 1811.

Phillip showed in other ways that he recognised that New South Wales could not be run simply as a prison camp. Lord Sydney, often criticised as an ineffectual incompetent, had made one fundamental decision about the settlement that was to influence it beneficially from the start. Instead of just establishing it as a military prison, he provided for a civil administration, with courts of law. Two convicts, Henry and Susannah Kable, sought to sue Duncan Sinclair, the captain of "Alexander", for stealing their possessions during the voyage. Convicts in Britain had no right to sue, and Sinclair had boasted that he could not be sued by them. Despite this, the court found for the plaintiffs and ordered the captain to make restitution for the loss of their possessions.

Further, soon after Lord Sydney appointed him governor of New South Wales Arthur Phillip drew up a detailed memorandum of his plans for the proposed new colony. In one paragraph he wrote: "The laws of this country [England] will of course, be introduced in [New] South Wales, and there is one that I would wish to take place from the moment his Majesty's forces take possession of the country: That there can be no slavery in a free land, and consequently no slaves." Nevertheless, Phillip believed in severe discipline; floggings and hangings were commonplace, although Philip commuted many death sentences.

Phillip also had to adopt a policy towards the Eora Aboriginal people, who lived around the waters of Sydney Harbour. Phillip ordered that they must be well treated, and that anyone killing Aboriginal people would be hanged. Phillip befriended an Eora man called Bennelong, and later took him to England. On the beach at Manly, a misunderstanding arose and Phillip was speared in the shoulder: but he ordered his men not to retaliate. Phillip went some way towards winning the trust of the Eora, although they remained wary of the settlers. Soon, a virulent disease, smallpox that was believed to be on account of the white settlers, and other European-introduced epidemics, ravaged the Eora population.

The Governor's main problem was with his own military officers, who wanted large grants of land, which Phillip had not been authorised to grant. Scurvy broke out, and in October 1788 Phillip had to send "Sirius" to Cape Town for supplies, and strict rationing was introduced, with thefts of food punished by hanging. He recorded: "The living conditions need to improve or my men won't work as hard, so I have come to a conclusion that I must hire surgeons to fix the convicts."

Phillip insisted that no retaliation be taken to avenge his own non-fatal spearing. Convict John MacIntyre had been fatally speared during a hunting expedition by unknown Aboriginal people apparently without provocation. MacIntyre swore on his death bed that he had done them no harm, but marine officer Watkin Tench was suspicious of the claim. Tench was sent on a punitive expedition but finding no Aboriginal people other than Bennelong took no action.

Phillip, growing frustrated with the burdens of upholding a colony and his health suffering, resigned soon after this episode.

By 1790 the situation had stabilised. The population of about 2,000 was adequately housed and fresh food was being grown. Phillip assigned a convict, James Ruse, land at Rose Hill (now Parramatta) to establish proper farming, and when Ruse succeeded he received the first land grant in the colony. Other convicts followed his example. "Sirius" was wrecked in March 1790 at the satellite settlement of Norfolk Island, depriving Phillip of vital supplies. In June 1790 the Second Fleet arrived with hundreds more convicts, most of them too sick to work.
By December 1790 Phillip was ready to return to England, but the colony had largely been forgotten in London and no instructions reached him, so he carried on. In 1791 he was advised that the government would send out two convoys of convicts annually, plus adequate supplies. But July, when the vessels of the Third Fleet began to arrive, with 2,000 more convicts, food again ran short, and he had to send the ship "Atlantic" to Calcutta for supplies.

By 1792 the colony was well established, though Sydney remained an unplanned huddle of wooden huts and tents. The whaling industry was established, ships were visiting Sydney to trade, and convicts whose sentences had expired were taking up farming. John Macarthur and other officers were importing sheep and beginning to grow wool. The colony was still very short of skilled farmers, craftsmen and tradesmen, and the convicts continued to work as little as possible, even though they were working mainly to grow their own food.

In late 1792, Phillip, whose health was suffering, relinquished his governorship and sailed for England on the ship "Atlantic", taking with him many specimens of plants and animals. He also took Bennelong and his friend Yemmerrawanne, another young Indigenous Australian who, unlike Bennelong, would succumb to English weather and disease and not live to make the journey home. The European population of New South Wales at his departure was 4,221, of whom 3,099 were convicts. The early years of the colony had been years of struggle and hardship, but the worst was over, and there were no further famines in New South Wales. Phillip arrived in London in May 1793. He tendered his formal resignation and was granted a pension of £500 a year.

Phillip's estranged wife, Margaret, had died in 1792 and was buried in St Beuno's Churchyard, Llanycil, Bala, Merionethshire. In 1794 Phillip married Isabella Whitehead, and lived for a time at Bath. His health gradually recovered and in 1796 he went back to sea, holding a series of commands and responsible posts in the wars against the French. In January 1799 he became a Rear-Admiral. In 1805, aged 67, he retired from the Navy with the rank of Admiral of the Blue, and spent most of the rest of his life in Bath. He continued to correspond with friends in New South Wales and to promote the colony's interests with government officials. He died in Bath in 1814. His Last Will & Testament has been transcribed and is on-line.

Phillip was buried in St Nicholas's Church, Bathampton. Forgotten for many years, the grave was discovered in 1897 and the Premier of New South Wales, Sir Henry Parkes, had it restored. An annual service of remembrance is held here around Phillip's birthdate by the Britain–Australia Society to commemorate his life.

In 2007, Geoffrey Robertson QC alleged that Phillip's remains are no longer in St Nicholas Church, Bathampton and have been lost: "Captain Arthur Phillip is not where the ledger stone says he is: it may be that he is buried somewhere outside, it may simply be that he is simply lost. But he is not where Australians have been led to believe that he now lies."

A number of places in Australia bear Phillip's name, including Port Phillip, Phillip Island (Victoria), Phillip Island (Norfolk Island), Phillip Street in Sydney, the federal electorate of Phillip (1949–1993), the suburb of Phillip in Canberra, the Governor Phillip Tower building in Sydney, and many streets, parks and schools including a state high school in Parramatta. A monument to Phillip in Bath Abbey Church was unveiled in 1937. Another was unveiled at St Mildred's Church, Bread St, London, in 1932; that church was destroyed in the London Blitz in 1940, but the principal elements of the monument were re-erected at the west end of Watling Street, near Saint Paul's Cathedral, in 1968. A different bust and memorial is inside the nearby church of St Mary-le-Bow. There is a statue of him in the Botanic Gardens, Sydney. There is a portrait of him by Francis Wheatley in the National Portrait Gallery, London.

Percival Serle wrote of Phillip in his "Dictionary of Australian Biography": 
Michael Pembroke's biography of Phillip adds that he was also a highly skilled international spy employed by the British government.

As part of a series of events on the bicentenary of his death, a memorial was dedicated in Westminster Abbey on 9 July 2014. In the service the Dean of Westminster, Very Reverend Dr John Hall, described Phillip as: "This modest, yet world-class seaman, linguist, and patriot, whose selfless service laid the secure foundations on which was developed the Commonwealth of Australia, will always be remembered and honoured alongside other pioneers and inventors here in the Nave: David Livingstone, Thomas Cochrane, and Isaac Newton."

A similar memorial was unveiled by the outgoing 37th Governor of New South Wales, Marie Bashir, in St James' Church, Sydney on 31 August 2014.

A bronze bust was installed at the Museum of Sydney, and a full-day symposium planned on his contributions to the founding of modern Australia.

Phillip is a prominent character in Timberlake Wertenbaker's play "Our Country's Good", in which he commissions Lieutenant Ralph Clark to stage a production of "The Recruiting Officer". He is shown as compassionate and just, but receives little support from his fellow officers. He is also prominent in "Banished" and is played by David Wenham.

Phillip is referred to in the John Williamson song "Chains around my ankle".

Phillip is a prominent character in a 2005 film "The Incredible Journey of Mary Bryant" where he is portrayed by Sam Neill.

Kate Grenville's 2008 novel "The Lieutenant" portrays Phillip through the character Commodore James Gilbert.





</doc>
<doc id="2564" url="https://en.wikipedia.org/wiki?curid=2564" title="April 10">
April 10





</doc>
<doc id="2573" url="https://en.wikipedia.org/wiki?curid=2573" title="Angus, Scotland">
Angus, Scotland

Angus () is one of the 32 local government council areas of Scotland, a registration county and a lieutenancy area. The council area borders Aberdeenshire, Dundee City and Perth and Kinross. Main industries include agriculture and fishing. Global pharmaceuticals company GSK has a significant presence in Montrose in the north of the county.

Angus was historically a county, known officially as Forfarshire from the 18th century until 1928, bordering Kincardineshire to the north-east, Aberdeenshire to the north and Perthshire to the west; southwards it faced Fife across the Firth of Tay (essentially the same border as today minus Dundee). It remains a registration county and a lieutenancy area. In 1975 some of its administrative functions were transferred to the council district of the Tayside Region, and in 1995 further reform resulted in the establishment of the unitary Angus Council.

The area that now comprises Angus has been occupied since at least the Neolithic period. Material taken from postholes from an enclosure at Douglasmuir, near Friockheim, about five miles north of Arbroath has been radiocarbon dated to around 3500 BC. The function of the enclosure is unknown, but may have been for agriculture or for ceremonial purposes.

Bronze age archaeology is to be found in abundance in the area. Examples include the short-cist burials found near West Newbigging, about a mile to the North of the town. These burials included pottery urns, a pair of silver discs and a gold armlet. Iron Age archaeology is also well represented, for example in the souterrain nearby Warddykes cemetery and at West Grange of Conan, as well as the better-known examples at Carlungie and Ardestie.

The county is traditionally associated with the Pictish kingdom of Circinn, which is thought to have encompassed Angus and the Mearns. Bordering it were the kingdoms of Ce (Mar and Buchan) to the North, Fotla (Atholl) to the West, and Fib (Fife) to the South.

The most visible remnants of the Pictish age are the numerous sculptured stones that can be found throughout Angus. Of particular note are the collections found at Aberlemno, St Vigeans, Kirriemuir and Monifieth.

Angus is marketed as the birthplace of Scotland. The signing of the Declaration of Arbroath at Arbroath Abbey in 1320 marked Scotland's establishment as an independent nation. It is an area of rich history from Pictish times onwards. Notable historic sites in addition to Arbroath Abbey include Glamis Castle, Arbroath Signal Tower museum and the Bell Rock Light House.

Angus can be split into three geographic areas. To the north and west, the topography is mountainous. This is the area of the Grampian Mountains, Mounth hills and Five Glens of Angus, which is sparsely populated and where the main industry is hill farming. Glas Maol - the highest point in Angus at 1,068 m (3,504 ft) - can be found here, on the tripoint boundary with Perthshire and Aberdeenshire. To the south and east the topography consists of rolling hills (such as the Sidlaws) bordering the sea; this area is well populated, with the larger towns. In between lies Strathmore ("the Great Valley"), which is a fertile agricultural area noted for the growing of potatoes, soft fruit and the raising of Angus cattle. Montrose in the north east of the county is notable for its tidal basin. Angus's coast is fairly regular, the most prominent features being the headlands of Scurdie Ness and Buddon Ness. The main bodies of water in the county are Loch Lee, Loch Brandy, Carlochy, Loch Wharral, Den of Ogil Reservoir, Loch of Forfar, Loch Fithie, Rescobie Loch, Balgavies Loch, Crombie Reservoir, Monikie Reservoirs, Long Loch, Lundie Loch, Loch of Kinnordy, Loch of Lintrathen, Backwater Reservoir, Auchintaple Loch, Loch Shandra and Loch Esk.

In the 2001 census the population of Angus was recorded as 108,400. 20.14% were under the age of 16, 63.15% were between 16 and 65 and 18.05% were aged 65 or above.

Of the 16 to 74 age group, 32.84% had no formal qualifications, 27.08% were educated to 'O' Grade/Standard Grade level, 14.38% to Higher level, 7.64% to HND or equivalent level and 18.06% to degree level.

The most recent available census results (2001) show that Gaelic is spoken by 0.45% of the Angus population. This, similar to other lowland areas, is lower than the national average of 1.16%. These figures are self-reported and are not broken down into levels of fluency.

Historically, the dominant language in Angus was Pictish until the sixth to seventh centuries AD when the area became progressively gaelicised, with Pictish extinct by the mid-ninth century. Gaelic/Middle Irish began to retreat from lowland areas in the late-eleventh century and was absent from the Eastern lowlands by the fourteenth century. It was replaced there by Middle Scots, the contemporary local South Northern dialect of Modern Scots, while Gaelic persisted as a majority language in the highland Glens until the 19th century. Scottish English is now increasingly replacing Scots.

Angus Council are planning to raise the status of Gaelic in the county by adopting a series of measures, including bilingual road signage, communications, vehicle livery and staffing.

Angus Council is one of the 32 local government council areas of Scotland. In 1996, the two-tier local government council was abolished and Angus was established as one of the replacement single-tier Council Areas. Prior to 1974 the county had been served by Angus District Council and Tayside Regional Council. As of May 2017 there are 28 seats on the council. From the May 2017 elections the seats are held as follows — Independent 9, SNP 9, Conservative 8, Liberal Democrat 2.

The council's civic head is the Provost of Angus. There have been five Provosts since its establishment in 1996 — Frances Duncan, Bill Middleton, Ruth Leslie-Melville, Helen Oswald and Alex King. On 16 May 2017 a new provost will be appointed from the councillors elected in Angus at the 2017 elections. As Angus is a county area the Lord Lieutenant of Angus is separate role.

The council has had four Chief Executives since its formation — Sandy Watson 1996–2006, David Sawers 2006–2011, Richard Stiff 2011–2017 and Margo Williamson 2017 to date. Margo Williamson is the first female Chief Executive since the Council was formed. The council's main offices are located at Angus House at Orchardbank in Forfar and at Bruce House in Arbroath while council meetings are held in the Town and County Hall in central Forfar. The council's offices include the historic County Buildings in Forfar adjacent to the Sheriff Court.

The boundaries of the present council area are the same as those of the historic county minus the City of Dundee.

The council area borders Aberdeenshire, Dundee City and Perth and Kinross.

Angus is represented by three MPs for the UK Parliament.


Angus is represented by two constituency MSPs for the Scottish Parliament.


In addition to the two constituency MSPs, Angus is also represented by MSPs from the North East Scotland Region

The Edinburgh-Aberdeen railway line runs along the coast and through the towns of Dundee, Arbroath and Montrose.

There is a small airport at Dundee, which at presents operates flights to London Stansted only.



Most common surnames in Angus (Forfarshire) at the time of the United Kingdom Census of 1881:





</doc>
<doc id="2575" url="https://en.wikipedia.org/wiki?curid=2575" title="André the Giant">
André the Giant

André René Roussimoff (May 19, 1946 – January 27, 1993), best known as André the Giant, was a French professional wrestler and actor.

He famously feuded with Hulk Hogan, culminating at WrestleMania III in 1987. His best-remembered film role was that of Fezzik, the giant in "The Princess Bride". His size was a result of gigantism caused by excess growth hormone, which later resulted in acromegaly. It also led to his being called "The Eighth Wonder of the World".

In the World Wrestling Federation (WWF, now known as WWE), Roussimoff was a one-time WWF World Heavyweight Champion and a one-time WWF Tag Team Champion. In 1993, he was the inaugural inductee into the newly created WWF Hall of Fame and he was later a charter member of the Professional Wrestling Hall of Fame and the "Wrestling Observer Newsletter" Hall of Fame.

André Roussimoff was born in Molien, in the canton of La Ferté-sous-Jouarre, of Slavic heritage, the son of Boris and Mariann Roussimoff. His parents were immigrants to France; his father was Bulgarian and his mother was Polish. His nickname growing up was "Dédé". As a child, he displayed symptoms of gigantism very early, reaching a height of and a weight of by the age of 12.

Roussimoff was a good student, particularly in mathematics, but he dropped out after the eighth grade since he did not think having a high school education was necessary for a farm labourer. He spent years working on his father's farm, where, according to his brother, Jacques, he could perform the work of three men. He also completed an apprenticeship in woodworking, and next worked in a factory that manufactured engines for hay balers. None of these occupations, however, brought him any satisfaction.

At the age of 18, Roussimoff moved to Paris and was taught professional wrestling by a local promoter who recognized the earning potential of Roussimoff's size. He trained at night and worked as a mover during the day to pay living expenses. Roussimoff was billed as "Géant Ferré", a name based on the French folk hero Grand Ferré, and began wrestling in Paris and nearby areas. Canadian promoter and wrestler Frank Valois met Roussimoff in 1966, becoming his business manager and adviser. Roussimoff began making a name for himself wrestling in the United Kingdom, Germany, Australia, New Zealand, and Africa.

He made his Japanese debut in 1970, billed as "Monster Roussimoff", wrestling for the International Wrestling Enterprise. Wrestling as both a singles and tag-team competitor, he quickly was made the company's tag-team champion alongside Michael Nador. During his time in Japan, doctors first informed Roussimoff that he suffered from acromegaly.

Roussimoff next moved to Montreal, Canada, where he became an immediate success, regularly selling out the Montreal Forum. However, promoters eventually ran out of plausible opponents for him and, as the novelty of his size wore off, the gate receipts dwindled. Roussimoff was defeated by Adnan Al-Kaissie in Baghdad in 1971, and wrestled numerous times in 1972 for Verne Gagne's American Wrestling Association (AWA) as a special attraction until Valois appealed to Vince McMahon Sr., founder of the World Wide Wrestling Federation (WWWF), for advice. McMahon suggested several changes. He felt Roussimoff should be portrayed as a large, immovable monster, and to enhance the perception of his size, McMahon discouraged Roussimoff from performing maneuvers such as dropkicks (although he was capable of performing such agile maneuvers before his health deteriorated in later life). He also began billing Roussimoff as "André the Giant" and set up a travel-intensive schedule, lending him to wrestling associations around the world, to keep him from becoming overexposed in any area. Promoters had to guarantee Roussimoff a certain amount of money as well as pay McMahon's WWWF booking fee.

On March 26, 1973, Roussimoff debuted in the World Wide Wrestling Federation (later World Wrestling Federation) as a fan favorite, defeating Buddy Wolfe in New York's Madison Square Garden.

Roussimoff was one of professional wrestling's most beloved "babyfaces" throughout the 1970s and early 1980s. As such, Gorilla Monsoon often stated that Roussimoff had not been defeated in 15 years by pinfall or submission prior to WrestleMania III; however, he had lost in matches outside of the WWF: a pinfall loss in Mexico to Canek in 1984 and a submission loss in Japan to Antonio Inoki in 1986. He also had sixty-minute time-limit draws with the two other major world champions of the day, Harley Race and Nick Bockwinkel.

In 1976, Roussimoff fought professional boxer Chuck Wepner in an unscripted boxer-versus-wrestler fight. The wild fight was shown via telecast as part of the undercard of the Muhammad Ali versus Antonio Inoki fight and ended when he threw Wepner over the top rope and outside the ring and won via count out.

In 1980, he feuded with Hulk Hogan, where unlike their more famous matches in the late 1980s, Hogan was the villain and Roussimoff was the hero, wrestling him at Shea Stadium's Showdown at Shea and in Pennsylvania, where after Roussimoff pinned Hogan to win the match, Hogan bodyslammed him much like their legendary WrestleMania III match in 1987. The feud continued in Japan in 1982 and 1983 with their roles reversed and with Antonio Inoki also involved.

In 1982, Vince McMahon, Sr. sold the World Wide Wrestling Federation to his son, Vince McMahon, Jr. As McMahon began to expand his newly acquired promotion to the national level, he required his wrestlers to appear exclusively for him. McMahon signed Roussimoff to these terms in 1984, although he still allowed him to work in Japan for New Japan Pro Wrestling (NJPW).

One of Roussimoff's feuds pitted him against the "Mongolian Giant" Killer Khan. According to the storyline, Khan had snapped Roussimoff's ankle during a match on May 2, 1981, in Rochester, New York, by leaping off the top rope and crashing down upon it with his knee-drop. In reality, he had broken his ankle getting out of bed the morning before the match. The injury and subsequent rehabilitation was worked into the existing Roussimoff/Khan storyline. After a stay at Beth Israel Hospital in Boston, Roussimoff returned with payback on his mind. The two battled on July 20, 1981, at Madison Square Garden in a match that resulted in a double disqualification. Their feud continued as fans filled arenas up and down the east coast to witness their matches. On November 14, 1981, at the Philadelphia Spectrum, he decisively defeated Khan in what was billed as a "Mongolian stretcher match", in which the loser must be taken to the dressing room on a stretcher. The same type of match was also held in Toronto. In early 1982 the two also fought in a series of matches in Japan with Arnold Skaaland in Roussimoff's corner.
Another feud involved a man who considered himself to be the "true giant" of wrestling: Big John Studd. Throughout the early to mid-1980s, Roussimoff and Studd fought all over the world, battling to try to determine who the real giant of wrestling was. In 1984, Studd took the feud to a new level when he and partner Ken Patera knocked out Roussimoff during a televised tag-team match and proceeded to cut off his hair. After gaining revenge on Patera, Roussimoff met Studd in a "body slam challenge" at the first WrestleMania, held March 31, 1985, at Madison Square Garden in New York City. Roussimoff slammed Studd to win the match and collect the $15,000 prize, then proceeded to throw cash to the fans before having the bag taken from him by Studd's manager, Bobby "The Brain" Heenan.

The following year, at WrestleMania 2, on April 7, 1986, Roussimoff continued to display his dominance by winning a twenty-man battle royal which featured top National Football League stars and wrestlers. He last eliminated Bret Hart to win the contest.

After WrestleMania 2, Roussimoff continued his feud with Studd and King Kong Bundy. Around this time, Roussimoff requested a leave of absence to tend to his health, effects from his acromegaly that were beginning to take their toll, as well as tour Japan. He had also been cast in the film "The Princess Bride". To explain his absence, a storyline was developed in which Heenan—suggesting that Roussimoff was secretly afraid of Studd and Bundy, whom Heenan bragged were unbeatable—challenged Roussimoff and a partner of his choosing to wrestle Studd and Bundy in a televised tag-team match. When Roussimoff failed to show, WWF president Jack Tunney indefinitely suspended him. Later in the summer of 1986, upon Roussimoff's return to the United States, he began wearing a mask and competing as the "Giant Machine" in a stable known as the Machines. (Big Machine and Super Machine were the other members, (Hulk Hogan (as "Hulk Machine") and Roddy Piper (as "Piper Machine") were also one-time members). The WWF's television announcers sold the Machines—a gimmick that was copied from the New Japan Pro Wrestling character "Super Strong Machine", played by Japanese wrestler Junji Hirata, —as "a new tag-team from Japan" and claimed not to know the identities of the wrestlers, even though it was obvious to fans that it was Roussimoff competing as the Giant Machine. Heenan, Studd, and Bundy complained to Tunney, who eventually told Heenan that if it could be proven that Roussimoff and the Giant Machine were the same person, Roussimoff would be fired. Roussimoff thwarted Heenan, Studd, and Bundy at every turn. Then, in late 1986, the Giant Machine "disappeared," and Roussimoff was reinstated. Foreshadowing Roussimoff's heel turn, Heenan expressed his approval of the reinstatement but did not explain why.

Roussimoff agreed to turn heel in early 1987 to be the counter to the biggest "babyface" in professional wrestling at that time, Hulk Hogan. On an edition of "Piper's Pit" in 1987, Hogan was presented a trophy for being the WWF World Heavyweight Champion for three years; Roussimoff came out to congratulate him, shaking Hogan's hand with a strong grip, which surprised the Hulkster. On the following week's "Piper's Pit", Roussimoff was presented a slightly smaller trophy for being "the only undefeated wrestler in wrestling history." Although he had suffered a handful of countout and disqualification losses in WWF, he had never been pinned or forced to submit in a WWF ring. Hogan came out to congratulate him and ended up being the focal point of the interview. Apparently annoyed, he walked out in the midst of Hogan's speech. A discussion between Roussimoff and Hogan was scheduled, and on a "Piper's Pit" that aired February 7, 1987, the two met. Hogan was introduced first, followed by Roussimoff, who was led by longtime rival Bobby Heenan.

Speaking on behalf of his new protégé, Heenan accused Hogan of being Roussimoff's friend only so he would not have to defend his title against him. Hogan tried to reason with Roussimoff, but his pleas were ignored as he challenged Hogan to a match for the WWF World Heavyweight Championship at WrestleMania III. Hogan was still seemingly in disbelief as to what Roussimoff was doing, prompting Heenan to say "You can't believe it, maybe you'll believe this, Hogan" before Roussimoff ripped off the T-shirt and crucifix from Hogan, with the crucifix scratching Hogan's chest, causing him to bleed.

Following Hogan's acceptance of his challenge on a later edition of "Piper's Pit", the two were part of a 20-man over-the-top rope battle-royal on the 14 March edition of "Saturday Night's Main Event" at the Joe Louis Arena in Detroit. Although the battle royal was won by Hercules, Roussimoff claimed to have gained a psychological advantage over Hogan when he threw the WWF World Heavyweight Champion over the top rope. The match, which was actually taped on February 21, 1987, aired only two weeks before WrestleMania III to make it seem like Hogan had met his match in André the Giant.

At WrestleMania III, he was billed at , and the stress of such immense weight on his bones and joints resulted in constant pain. After recent back surgery, he was also wearing a brace underneath his wrestling singlet. In front of a record crowd, Hogan won the match after body-slamming Roussimoff (later dubbed "the bodyslam heard around the world"), followed by Hogan's running leg drop finisher. Years later, Hogan claimed that Roussimoff was so heavy, he felt more like , and that he tore his latissimus dorsi muscle when slamming him.

Another myth about the match is that no one, not even WWF owner Vince McMahon, knew until the day of the event whether Roussimoff would lose the match. In reality, he had agreed to lose the match some time before, mostly for health reasons. Contrary to popular belief, it was not the first time that Hogan had successfully body-slammed him in a WWF match. A then-heel Hogan had slammed a then-face Roussimoff following their match at the "Showdown at Shea" on August 9, 1980, though Roussimoff was much lighter (around ) and more athletic at the time (Hogan also slammed him in a match in Hamburg, Pennsylvania, a month later). This took place in the territorial days of American wrestling three years before WWF began national expansion, so many of those who watched WrestleMania III had never seen the Giant slammed (Roussimoff had also previously allowed Harley Race, El Canek and Stan Hansen, among others, to slam him).

By the time of WrestleMania III, the WWF had gone national, giving more meaning to the Roussimoff–Hogan match that took place then. The feud between Roussimoff and Hogan simmered during the summer of 1987, as Roussimoff's health declined. The feud began heating up again when wrestlers were named the captains of rival teams at the inaugural Survivor Series event. During their approximately one minute of battling each other during the match, Hogan dominated Roussimoff and was on the brink of knocking him from the ring, but was tripped up by his partners, Bundy and One Man Gang, and would be counted out. Roussimoff went on to be the sole survivor of the match, pinning Bam Bam Bigelow before Hogan returned to the ring to attack André and knock him out of the ring. Roussimoff later got revenge when, after Hogan won a match against Bundy on "Saturday Night's Main Event", he snuck up from behind and began choking Hogan to the brink of unconsciousness, not letting go even after an army of seven face-aligned wrestlers ran to the ring to try to pull him away; it took Hacksaw Jim Duggan breaking a piece of wood over his back (which he no-sold) for him to let go, after which Hogan was pulled to safety. As was the case with the "SNME" battle royal a year earlier, the series of events was one of the pieces that helped build interest in a possible one-on-one rematch between Hogan and Roussimoff, and to make it seem that Roussimoff was certain to win easily when they did meet.

In the meantime, the "Million Dollar Man" Ted DiBiase failed to persuade Hogan to sell him the WWF World Heavyweight Championship. After failing to defeat Hogan in a subsequent series of matches, DiBiase turned to Roussimoff to win it for him. He and DiBiase had teamed several times in the past, including in Japan and in the WWF in the late 1970s and early 1980s when both were faces, but this was not acknowledged during this new storyline. The earlier attack and DiBiase's insertion into the feud set up the Hogan-Roussimoff rematch on "The Main Event", to air 5 February 1988, on a live broadcast on NBC. Acting as his hired gun, Roussimoff won the WWF World Heavyweight Championship from Hogan (his first singles title) in a match where it was later revealed that appointed referee Dave Hebner was "detained backstage", and a replacement (whom Hogan afterwards initially accused of having been paid by DiBiase to get plastic surgery to look like Dave, but was revealed to have been his evil twin brother, Earl Hebner), made a three count on Hogan while his shoulders were off the mat.

After winning, Roussimoff "sold" the title to DiBiase; the transaction was declared invalid by then-WWF president Jack Tunney and the title was declared vacant. This was shown on WWF's NBC program "The Main Event". At WrestleMania IV, Roussimoff and Hulk Hogan fought to a double disqualification in a WWF title tournament match (with the idea in the storyline saying that Roussimoff was again working on DiBiase's behalf in giving DiBiase a clearer path in the tournament). Afterward, Roussimoff and Hogan's feud died down after a steel cage match held at "WrestleFest" on July 31, 1988, in Milwaukee.

At the inaugural SummerSlam pay-per-view held at Madison Square Garden, Roussimoff and DiBiase (billed as The Mega Bucks) faced Hogan and WWF World Heavyweight Champion "Macho Man" Randy Savage (known as The Mega Powers) in the main event, with Jesse "The Body" Ventura as the special guest referee. During the match, the Mega Powers' manager, Miss Elizabeth, distracted the Mega Bucks and Ventura when she climbed up on the ring apron, removed her yellow skirt and walked around in a pair of red panties. This allowed Hogan and Savage time to recover and eventually win the match with Hogan pinning DiBiase. Savage forced Ventura's hand down for the final three-count, due to Ventura's character historically being at odds with Hogan, and his unwillingness to count the fall.

Concurrent with the developing feud with the Mega Powers, Roussimoff was placed in a feud with Jim Duggan, which began after Duggan knocked out Roussimoff with a two-by-four board during a television taping. Despite Duggan's popularity with fans, Roussimoff regularly got the upper hand in the feud.
Roussimoff's next major feud was against Jake "The Snake" Roberts. In this storyline, it was said Roussimoff was afraid of snakes, something Roberts exposed on "Saturday Night's Main Event" when he threw his snake, Damien, on the frightened Roussimoff; as a result, he suffered a kayfabe mild heart attack and vowed revenge. During the next few weeks, Roberts frequently walked to ringside during Roussimoff's matches, causing him to run from the ring in fright (since he knew what was inside the bag). Throughout their feud (which culminated at WrestleMania V), Roberts constantly used Damien to gain a psychological edge over the much larger and stronger Roussimoff.

In 1989, Roussimoff and the returning Big John Studd briefly reprised their feud, beginning at WrestleMania V, when Studd was the referee in the match with Roberts, this time with Studd as a face and Roussimoff as the heel. During the late summer and Autumn of 1989, he engaged in a brief feud, consisting almost entirely of house shows (non-televised events), with then-Intercontinental Champion The Ultimate Warrior. The younger Warrior, WWF's rising star, regularly squashed the aging Roussimoff in an attempt to showcase his star quality and promote him as the "next big thing".

In late 1989, Roussimoff was joined with fellow Heenan Family member Haku to form a new tag team called the Colossal Connection, in part to fill a void left by the departure of Tully Blanchard and Arn Anderson (the Brain Busters, who were also members of Heenan's stable) from the WWF, and also to continue to keep the aging Roussimoff in the main event spotlight. The Colossal Connection immediately targeted WWF Tag Team Champions Demolition (who had recently won the belts from the Brain Busters). At a television taping on December 13, 1989, the Colossal Connection defeated Demolition to win the titles. Roussimoff and Haku successfully defended their title, mostly against Demolition, until WrestleMania VI on April 1, 1990, when Demolition took advantage of a mistimed move by the champions to regain the belts. After the match, a furious Heenan blamed Roussimoff for the title loss and after shouting at him, slapped him in the face; an angry Roussimoff responded with a slap of his own that sent Heenan staggering from the ring. Roussimoff also caught Haku's kick attempt, sending him reeling from the ring as well, prompting support for Roussimoff and turning him face for the first time since 1987. Due to his ongoing health issues, Roussimoff was not able to wrestle at the time of Wrestlemania VI and Haku actually wrestled the entire match against Demolition without tagging him in.

On weekend television shows following WrestleMania VI, Bobby Heenan vowed to spit in Roussimoff's face when he came crawling back to the Heenan Family. However Roussimoff would wrestle one more time with Haku, teaming up to face Demolition on a house show in Honolulu, HI, on April 10, Roussimoff was knocked out of the ring and The Colossal Connection lost via countout. After the match, Roussimoff and Haku would fight each other, marking the end of the team. His final match of 1990 came at a combined WWF/All Japan/New Japan show on April 13 in Tokyo, Japan when teamed with Giant Baba to defeat Demolition in a non-title match. Roussimoff would win by gaining the pinfall on Smash.

Roussimoff returned in the winter of 1990, but it was not to the World Wrestling Federation. Instead, Roussimoff made an interview appearance for Herb Abrams' fledgling Universal Wrestling Federation on October 11 in Reseda, California. (the segment aired in 1991). He appeared in an interview segment with Captain Lou Albano and put over the UWF. The following month, on November 30 at a house show in Miami, Florida, the World Wrestling Federation announced his return as a participant in the 1991 Royal Rumble (to be held in Miami, FL two months later). Roussimoff was also mentioned as a participant on television but would ultimately back out due to a leg injury.

His on-air return finally took place at the WWF's "Super-Stars & Stripes Forever" USA Network special on March 17, 1991, when he came out to shake the hand of The Big Boss Man after an altercation with Mr. Perfect. The following week, at WrestleMania VII, he came to the aid of the Boss Man in his match against Mr. Perfect. Roussimoff finally returned to action on April 26, 1991, in a six-man tag-team matchup when he teamed with the Rockers in a winning effort against Mr. Fuji and the Orient Express at a house show in Belfast, Northern Ireland. On May 10 he participated in a 17-man battle-royal at a house show in Detroit. (won by Kerry Von Erich). His last major WWF storyline following WrestleMania VII had the major heel managers (Bobby Heenan, Sensational Sherri, Slick, and Mr. Fuji) trying to recruit Roussimoff one-by-one, only to be turned down in various humiliating ways (e.g. Heenan had his hand crushed, Sherri received a spanking, Slick got locked in the trunk of the car he was offering to Roussimoff and Mr. Fuji got a pie in his face). Finally, Jimmy Hart appeared live on "WWF Superstars" to announce that he had successfully signed Roussimoff to tag-team with Earthquake. However, when asked to confirm this by Gene Okerlund, Roussimoff denied the claims. This led to Earthquake's attacking Roussimoff from behind (injuring his knee). Jimmy Hart would later get revenge for the humiliation by secretly signing Tugboat and forming the Natural Disasters. This led to Roussimoff's final major WWF appearance at SummerSlam '91, where he seconded the Bushwhackers in their match against the Disasters. Roussimoff was on crutches at ringside, and after the Disasters won the match, they set out to attack him, but the Legion of Doom made their way to ringside and got in between them and the Giant, who was preparing to defend himself with one of his crutches. The Disasters left the ringside area as they were outnumbered by the Legion of Doom, the Bushwhackers and Roussimoff, who struck both Earthquake and Typhoon (the former Tugboat) with the crutch as they left. His final WWF appearance came at a house show in Paris, France, on October 9. He was in Davey Boy Smith's corner as the Bulldog faced Earthquake. Davey Boy hit Earthquake with Roussimoff's crutch, allowing Smith to win.

His last U.S. television appearance was in a brief interview on World Championship Wrestling's (WCW) "" special that aired on TBS on 2 September 1992.

After WrestleMania VI, Roussimoff spent the rest of his in-ring career in All Japan Pro Wrestling (AJPW) and Mexico's Universal Wrestling Association, where he performed under the name "André el Gigante." He toured with AJPW three times per year, from 1990 to 1992, usually teaming with Giant Baba in tag-team matches. He also made a couple of guest appearances for Herb Abrams' Universal Wrestling Federation, in 1991, feuding with Big John Studd, though he never had a match in the promotion. He did his final tour of Mexico in 1992 in a selection of six-man tag matches alongside Bam Bam Bigelow and a variety of Lucha Libre stars facing among others Bad News Allen and future WWF Champions Mick Foley & Yokozuna. Roussimoff wrestled his final match for AJPW in 1992, after which he retired from professional wrestling.

Roussimoff branched out into acting again in the 1970s and 1980s, after a 1967 French boxing film, making his USA acting debut playing a Sasquatch ("Bigfoot") in a two-part episode aired in 1976 on the television series "The Six Million Dollar Man". He appeared in other television shows, including "The Greatest American Hero", "B. J. and the Bear", "The Fall Guy" and 1990's "Zorro".

Towards the end of his career, Roussimoff starred in several films. He had an uncredited appearance in the 1984 film "Conan the Destroyer" as Dagoth, the resurrected horned giant god who is killed by Conan (Arnold Schwarzenegger). That same year, he also made an appearance in "Micki & Maude" (billed as André Rousimmoff). He appeared most notably as Fezzik, his own favorite role, in the 1987 film "The Princess Bride". Both the film and his performance retain a devoted following. In shoot interviews, wrestlers have stated that he was so proud of being in "Princess Bride", he carried a copy of the movie everywhere he went to watch whenever he could.

In his last film, he appeared in a cameo role as a circus giant in the comedy "Trading Mom", which was released in 1994, a year after his death.


Roussimoff was mentioned in the "1974 Guinness Book of World Records" as the highest-paid wrestler in history at that time. He had earned US$400,000 in one year during the early 1970s.

Robin Christensen is Roussimoff's only child. Her mother Jean (who died in 2008) became acquainted with her dad through the wrestling business around 1972 or 1973. Robin had almost no connection with her father and saw him only five times in her life, despite occasional televised and printed news pieces criticizing his absentee fatherhood. While she gave some interviews about the subject in her childhood, Robin is reportedly reluctant to discuss her father publicly today.

Roussimoff has been unofficially crowned "the greatest drunk on Earth" for once consuming 119 beers (over 41 litres/72 pints) in six hours. On an episode of WWE's "Legends of Wrestling", Mike Graham said Roussimoff once drank 156 beers (over 73 litres/126 pints) in one sitting, which was confirmed by Dusty Rhodes. The Fabulous Moolah wrote in her autobiography that Roussimoff drank 127 beers in a Reading, Pennsylvania, hotel bar and later passed out in the lobby. The staff could not move him and had to leave him there until he awoke. In a shoot interview, Ken Patera recalled an occasion where Roussimoff was challenged by Dick Murdoch to a beer drinking contest. After nine or so hours, Roussimoff had drank 116 beers. A tale recounted by Cary Elwes in his book about the making of "The Princess Bride" has Roussimoff falling on top of somebody while drunk, after which the NYPD sent an undercover officer to follow Roussimoff around whenever he went out drinking in their city to make sure he did not fall on anyone again. Another story also says prior to his famous WrestleMania III match, Roussimoff drank 14 bottles of wine.

An urban legend exists surrounding Roussimoff's 1987 surgery in which his size made it impossible for the anesthesiologist to estimate a dosage via standard methods; consequently, his alcohol tolerance was used as a guideline instead, which has since become a widely used measuring tool in medicine.

Roussimoff was arrested in 1989 by the sheriff of Linn County, Iowa; and charged with assault after he allegedly roughed up a local television cameraman.

William Goldman, the author of the novel and the screenplay of "The Princess Bride", wrote in his nonfiction work "Which Lie Did I Tell?" that Roussimoff was one of the gentlest and most generous people he ever knew. Whenever Roussimoff ate with someone in a restaurant, he would pay, but he would also insist on paying when he was a guest. On one occasion, after Roussimoff attended a dinner with Arnold Schwarzenegger and Wilt Chamberlain, Schwarzenegger had quietly moved to the cashier to pay before Roussimoff could, but then found himself being physically lifted, carried from his table and deposited on top of his car by Roussimoff and Chamberlain.

Roussimoff owned a ranch in Ellerbe, North Carolina, looked after by two of his close friends, when he was not on the road. He loved spending time at the ranch tending to his cattle, playing with his dogs and entertaining company. While there were custom-made chairs and a few other modifications in his home to account for his size, tales that everything in his home was custom-made for a large man are said to be exaggerated. Since Roussimoff could not easily go shopping due to his fame and size, he was known to spend hours watching QVC and made frequent purchases from the shopping channel. Roussimoff had a passion for card games, mainly cribbage.

Roussimoff died in his sleep of congestive heart failure on the night of January 27, 1993, in a Paris hotel room. He was found by his chauffeur. He was in Paris to attend his father's funeral. While there, Roussimoff decided to stay in France longer to be with his mother on her birthday. He spent the day before his death visiting and playing cards with some of his oldest friends in Molien.

Roussimoff had finalized his will in New York on October 30, 1990, with his lawyer. In the will, he specified that his remains be cremated and "disposed of". Upon his death in Paris, his family in France held a funeral for him, intending to bury him near his father. When they learned of his wish to be cremated, his body was flown to the United States, where he was cremated according to his wishes. His ashes were scattered at his ranch () in Ellerbe, North Carolina. In addition, as per his will, he left his estate to his sole beneficiary: his daughter Robin.

Roussimoff made numerous appearances as himself in video games, starting with "WWF WrestleMania". He also appears posthumously in "WWF Superstars", "WWF No Mercy", "WWE SmackDown! vs. Raw", "WWE All Stars", WWE 2K14, WWE 2K16, "WWE 2K17", "WWE 2K18", "WWE 2K19" and many others.

In January 2005, WWE released "André The Giant", a DVD focusing on the life and career of Roussimoff. The DVD is a reissue of the out-of-print "André The Giant" VHS made by Coliseum Video in 1985, with commentary by Michael Cole and Tazz replacing Gorilla Monsoon and Jesse Ventura's commentary on his WrestleMania match with Big John Studd. The video is hosted by Lord Alfred Hayes. Later matches, including his battles against Hulk Hogan while a heel, are not included on this VHS.


On 9 May 2016, it was announced that a movie based on the 2015 authorized graphic novel biography "André the Giant: Closer to Heaven" was in the plans made by Lion Forge Comics along with producers Scott Steindorff, Dylan Russell and consulted by Roussimoff's daughter, Robin Christensen-Roussimoff.

On April 10, 2018, HBO aired a documentary film called "André the Giant".






</doc>
<doc id="2577" url="https://en.wikipedia.org/wiki?curid=2577" title="Adrastea (moon)">
Adrastea (moon)

Adrastea ( ; ), also known as , is the second by distance, and the smallest of the four inner moons of Jupiter. It was discovered in photographs taken by "Voyager 2" in 1979, making it the first natural satellite to be discovered from images taken by an interplanetary spacecraft, rather than through a telescope. It was officially named after the mythological Adrasteia, foster mother of the Greek god Zeus—the equivalent of the Roman god Jupiter.

Adrastea is one of the few moons in the Solar System known to orbit its planet in less than the length of that planet's day. It orbits at the edge of Jupiter's Main Ring and is thought to be the main contributor of material to the Rings of Jupiter. Despite observations made in the 1990s by the "Galileo" spacecraft, very little is known about the moon's physical characteristics other than its size and the fact that it is tidally locked to Jupiter.

Adrastea was discovered by David C. Jewitt and G. Edward Danielson in "Voyager 2" probe photographs taken on July 8, 1979, and received the designation . Although it appeared only as a dot, it was the first moon to be discovered by an interplanetary spacecraft. Soon after its discovery, two other of the inner moons of Jupiter (Thebe and Metis) were observed in the images taken a few months earlier by "Voyager 1". The "Galileo" spacecraft was able to determine the moon's shape in 1998, but the images remain poor. In 1983, Adrastea was officially named after the Greek nymph Adrastea, the daughter of Zeus and his lover Ananke.

Although the "Juno" orbiter, which arrived at Jupiter in 2016, has a camera called JunoCam, it is almost entirely focused on observations of Jupiter itself. However, if all goes well should be able to capture some limited images of the Jupiter moons Metis and Adrastea.

Adrastea has an irregular shape and measures 20×16×14 km across. A surface area estimate would be between 840 and 1,600 (~1,200) km. This makes it the smallest of the four inner moons. The bulk, composition and mass of Adrastea are not known, but assuming that its mean density is like that of Amalthea, around 0.86 g/cm, its mass can be estimated at about 2 kg. Amalthea's density implies that the moon is composed of water ice with a porosity of 10–15%, and Adrastea may be similar.

No surface details of Adrastea are known, due to the low resolution of available images.

Adrastea is the smallest and second-closest member of the inner Jovian satellite family. It orbits Jupiter at a radius of about 129,000 km (1.806 Jupiter radii) at the exterior edge of the planet's Main Ring. Adrastea is one of only three moons in the Solar System known to orbit its planet in less than the length of that planet's day—the other two being Jupiter's innermost moon Metis, and Mars' moon Phobos. The orbit has very small eccentricity and inclination—around 0.0015 and 0.03°, respectively. Inclination is relative to the equator of Jupiter.

Due to tidal locking, Adrastea rotates synchronously with its orbital period, keeping one face always looking toward the planet. Its long axis is aligned towards Jupiter, this being the lowest energy configuration.

The orbit of Adrastea lies inside Jupiter's synchronous orbit radius (as does Metis's), and as a result, tidal forces are slowly causing its orbit to decay so that it will one day impact Jupiter. If its density is similar to Amalthea's then its orbit would actually lie within the fluid Roche limit. However, since it is not breaking up, it must still lie outside its rigid Roche limit.

Adrastea is the second-fastest-moving of Jupiter's moons, with an orbital speed of 31.378 km/s.

Adrastea is the largest contributor to material in Jupiter's rings. This appears to consist primarily of material that is ejected from the surfaces of Jupiter's four small inner satellites by meteorite impacts. It is easy for the impact ejecta to be lost from these satellites into space. This is due to the satellites' low density and their surfaces lying close to the edge of their Roche spheres.

It seems that Adrastea is the most copious source of this ring material, as evidenced by the densest ring (the Main Ring) being located at and within Adrastea's orbit. More precisely, the orbit of Adrastea lies near the outer edge of Jupiter's Main Ring. The exact extent of visible ring material depends on the phase angle of the images: in forward-scattered light Adrastea is firmly outside the Main Ring, but in back-scattered light (which reveals much bigger particles) there appears to also be a narrow ringlet outside Adrastea's orbit.

Cited sources



</doc>
<doc id="2578" url="https://en.wikipedia.org/wiki?curid=2578" title="Amalthea">
Amalthea

Amalthea can refer to:


</doc>
<doc id="2580" url="https://en.wikipedia.org/wiki?curid=2580" title="Ananke (disambiguation)">
Ananke (disambiguation)

Ananke () is the Greek goddess of fate. Ananke may also refer to:



</doc>
<doc id="2581" url="https://en.wikipedia.org/wiki?curid=2581" title="Apache HTTP Server">
Apache HTTP Server

The Apache HTTP Server, colloquially called Apache ( ), is free and open-source cross-platform web server software, released under the terms of Apache License 2.0. Apache is developed and maintained by an open community of developers under the auspices of the Apache Software Foundation.

The vast majority of Apache HTTP Server instances run on a Linux distribution, but current versions also run on Microsoft Windows and a wide variety of Unix-like systems. Past versions also ran on OpenVMS, NetWare, OS/2 and other operating systems.

Originally based on the NCSA HTTPd server, development of Apache began in early 1995 after work on the NCSA code stalled. Apache played a key role in the initial growth of the World Wide Web, quickly overtaking NCSA HTTPd as the dominant HTTP server, and has remained most popular since April 1996. In 2009, it became the first web server software to serve more than 100 million websites. , it was estimated to serve 39% of all active websites and 35% of the top million websites.

A number of explanations for the origin of the Apache name have been offered over the years.

From the inception of the Apache project in 1995 the official documentation stated:

In an April 2000 interview, Brian Behlendorf, one of the creators of Apache said:

Since 2013 the Apache Foundation has explained the origin of the name as:

When Apache is running under Unix, its process name is httpd, which is short for "HTTP daemon".

Apache supports a variety of features, many implemented as compiled modules which extend the core functionality. These can range from authentication schemes to supporting server-side programming languages such as Perl, Python, Tcl and PHP. Popular authentication modules include mod_access, mod_auth, mod_digest, and mod_auth_digest, the successor to mod_digest. A sample of other features include Secure Sockets Layer and Transport Layer Security support (mod_ssl), a proxy module (mod_proxy), a URL rewriting module (mod_rewrite), custom log files (mod_log_config), and filtering support (mod_include and mod_ext_filter).

Popular compression methods on Apache include the external extension module, mod_gzip, implemented to help with reduction of the size (weight) of web pages served over HTTP. ModSecurity is an open source intrusion detection and prevention engine for Web applications. Apache logs can be analyzed through a Web browser using free scripts, such as AWStats/W3Perl or Visitors.

Virtual hosting allows one Apache installation to serve many different websites. For example, one computer with one Apache installation could simultaneously serve codice_1, codice_2, codice_3, etc.

Apache features configurable error messages, DBMS-based authentication databases, content negotiation and supports several graphical user interfaces (GUIs).

It supports password authentication and digital certificate authentication. Because the source code is freely available, anyone can adapt the server for specific needs, and there is a large public library of Apache add-ons.

A more detailed list of features is provided below:

Instead of implementing a single architecture, Apache provides a variety of MultiProcessing Modules (MPMs), which allow it to run in either a process-based mode, a hybrid (process and thread) mode, or an event-hybrid mode, in order to better match the demands of each particular infrastructure. Choice of MPM and configuration is therefore important. Where compromises in performance must be made, Apache is designed to reduce latency and increase throughput relative to simply handling more requests, thus ensuring consistent and reliable processing of requests within reasonable time-frames.

For delivering static pages, Apache 2.2 series was considered significantly slower than nginx and varnish. To address this issue, the Apache developers created the Event MPM, which mixes the use of several processes and several threads per process in an asynchronous event-based loop. This architecture as implemented in the Apache 2.4 series performs at least as well as event-based web servers, according to Jim Jagielski and other independent sources. However, some independent but significantly outdated benchmarks show that it is still half as fast as nginx, e.g.

The Apache HTTP Server codebase was relicensed to the Apache 2.0 License (from the previous 1.1 license) in January 2004, and Apache HTTP Server 1.3.31 and 2.0.49 were the first releases using the new license.

The OpenBSD project did not like the change and continued the use of pre-2.0 Apache versions, effectively forking Apache 1.3.x for its purposes. They initially replaced it with Nginx, and soon after made their own replacement, OpenBSD Httpd, based on the relayd project.

Version 1.1:
The Apache License 1.1 was approved by the ASF in 2000: The primary change from the 1.0 license is in the 'advertising clause' (section 3 of the 1.0 license); derived products are no longer required to include attribution in their advertising materials, only in their documentation.

Version 2.0:
The ASF adopted the Apache License 2.0 in January 2004. The stated goals of the license included making the license easier for non-ASF projects to use, improving compatibility with GPL-based software, allowing the license to be included by reference instead of listed in every file, clarifying the license on contributions, and requiring a patent license on contributions that necessarily infringe a contributor's own patents.

The Apache HTTP Server Project is a collaborative software development effort aimed at creating a robust, commercial-grade, feature-rich and freely available source code implementation of an HTTP (Web) server. The project is jointly managed by a group of volunteers located around the world, using the Internet and the Web to communicate, plan, and develop the server and its related documentation. This project is part of the Apache Software Foundation. In addition, hundreds of users have contributed ideas, code, and documentation to the project.

Apache 2.4 dropped support for BeOS, TPF and even older platforms.



</doc>
<doc id="2582" url="https://en.wikipedia.org/wiki?curid=2582" title="Alph">
Alph

Alph may refer to:



</doc>
<doc id="2583" url="https://en.wikipedia.org/wiki?curid=2583" title="Arbroath Abbey">
Arbroath Abbey

Arbroath Abbey, in the Scottish town of Arbroath, was founded in 1178 by King William the Lion for a group of Tironensian Benedictine monks from Kelso Abbey. It was consecrated in 1197 with a dedication to the deceased Saint Thomas Becket, whom the king had met at the English court. It was William's only personal foundation — he was buried before the high altar of the church in 1214.

The last Abbot was Cardinal David Beaton, who in 1522 succeeded his uncle James to become Archbishop of St Andrews. The Abbey is cared for by Historic Environment Scotland and is open to the public throughout the year (entrance charge). The distinctive red sandstone ruins stand at the top of the High Street in Arbroath.

King William gave the Abbey independence from its mother church and endowed it generously, including income from 24 parishes, land in every royal burgh and more. The Abbey's monks were allowed to run a market and build a harbour. King John of England gave the Abbey permission to buy and sell goods anywhere in England (except London) toll-free.

The Abbey, which was the richest in Scotland, is most famous for its association with the 1320 Declaration of Scottish Independence believed to have been drafted by Abbot Bernard, who was the Chancellor of Scotland under King Robert I.

The Abbey fell into ruin after the Reformation. From 1590 onward, its stones were raided for buildings in the town of Arbroath. This continued until 1815 when steps were taken to preserve the remaining ruins.

On Christmas Day 1950, the Stone of Destiny was stolen from Westminster Abbey. On April 11, 1951, the missing stone was found lying on the site of the Abbey's altar.

Since 1947, a major historical re-enactment commemorating the Declaration's signing has been held within the roofless remains of the Abbey church. The celebration is run by the local Arbroath Abbey Pageant Society, and tells the story of the events which led up to the signing. This is not an annual event (most recent performance 2005; next August 2009). However, a special event to mark the signing is held every year on the 6th of April and involves a street procession and short piece of street theatre.

In 2005 The Arbroath Abbey campaign was launched. The campaign seeks to gain World Heritage Status for the iconinc Angus landmark that was the birthplace of one of Scotland's most significant document, The Declaration of Arbroath. Campaigners believe that the Abbey's historical pronouncement makes it a prime candidate to achieve World Heritage Status. MSP Alex Johnstone wrote "Clearly, the Declaration of Arbroath is a literary work of outstanding universal significance by any stretch of the imagination" In 2008, the Campaign Group Chairman, Councillor Jim Millar launched a public petition to reinforce the bid explaining "We're simply asking people to, local people especially, to sign up to the campaign to have the Declaration of Arbroath and Arbroath Abbey recognised by the United Nations. Essentially we need local people to sign up to this campaign simply because the United Nations demand it."

The Abbey was built over some sixty years using local red sandstone, but gives the impression of a single coherent, mainly 'Early English' architectural design, though the round-arched processional doorway in the western front looks back to late Norman or transitional work. The triforium (open arcade) above the door is unique in Scottish medieval architecture. It is flanked by twin towers decorated with blind arcading. The cruciform church measured long by wide. What remains of it today are the sacristy, added by Abbot Paniter in the 15th century, the southern transept, which features Scotland's largest lancet windows, part of the choir and presbytery, the southern half of the nave, parts of the western towers and the western doorway.
The church originally had a central tower and (probably) a spire. These would once have been visible for many miles over the surrounding countryside, and no doubt once acted as a sea-mark for ships. The soft sandstone of the walls was originally protected by plaster internally and render externally. These coatings are long gone and much of the architectural detail is sadly eroded, though detached fragments found in the ruins during consolidation give an impression of the original refined, rather austere, architectural effect.

The distinctive round window high in the south transept was originally lit up at night as a beacon for mariners. It is known locally as the 'Round O', and from this tradition inhabitants of Arbroath are colloquially known as 'Reid Lichties' (Scots reid = red).

Little remains of the claustral buildings of the Abbey except for the impressive gatehouse, which stretches between the south-west corner of the church and a defensive tower on the High Street, and the still complete Abbot's House, a building of the 13th, 15th and 16th centuries, which is the best-preserved of its type in Scotland.

In the summer of 2001 a new visitors' centre was opened to the public beside the Abbey's west front. This red sandstone-clad building, with its distinctive 'wave-shaped' organic roof, planted with sedum, houses displays on the history of the Abbey and some of the best surviving stonework and other relics. The upper storey features a scale model of the Abbey complex, a computer-generated 'fly-through' reconstruction of the church as it was when complete, and a viewing gallery with excellent views of the ruins. The centre won the 2002 Angus Design Award. An archaeological investigation of the site of the visitors' centre before building started revealed the foundations of the medieval precinct wall, with a gateway, and stonework discarded during manufacture, showing that the area was the site of the masons' yard while the Abbey was being built.




</doc>
<doc id="2593" url="https://en.wikipedia.org/wiki?curid=2593" title="Accounting">
Accounting

Accounting or accountancy is the measurement, processing, and communication of financial and non financial information about economic entities such as businesses and corporations. The modern field was established by the Benedikt Kotruljevic in 1458, (Italian: Benedetto Cotrugli; 1416–1469) merchant, economist, scientist, diplomat and humanist from Dubrovnik (Croatia), and Italian mathematician Luca Pacioli in 1494. Accounting, which has been called the "language of business", measures the results of an organization's economic activities and conveys this information to a variety of users, including investors, creditors, management, and regulators. Practitioners of accounting are known as accountants. The terms "accounting" and "financial reporting" are often used as synonyms.

Accounting can be divided into several fields including financial accounting, management accounting, external auditing, tax accounting and cost accounting. Accounting information systems are designed to support accounting functions and related activities. Financial accounting focuses on the reporting of an organization's financial information, including the preparation of financial statements, to the external users of the information, such as investors, regulators and suppliers; and management accounting focuses on the measurement, analysis and reporting of information for internal use by management. The recording of financial transactions, so that summaries of the financials may be presented in financial reports, is known as bookkeeping, of which double-entry bookkeeping is the most common system.

Accounting is facilitated by such as standard-setters, accounting firms and professional bodies. Financial statements are usually audited by accounting firms, and are prepared in accordance with generally accepted accounting principles (GAAP). GAAP is set by various standard-setting organizations such as the Financial Accounting Standards Board (FASB) in the United States and the Financial Reporting Council in the United Kingdom. As of 2012, "all major economies" have plans to converge towards or adopt the International Financial Reporting Standards (IFRS).

The history of accounting is thousands of years old and can be traced to ancient civilizations. The early development of accounting dates back to ancient Mesopotamia, and is closely related to developments in writing, counting and money; there is also evidence of early forms of bookkeeping in ancient Iran, and early auditing systems by the ancient Egyptians and Babylonians. By the time of Emperor Augustus, the Roman government had access to detailed financial information.

Double-entry bookkeeping was pioneered in the Jewish community of the early-medieval Middle East and was further refined in medieval Europe. With the development of joint-stock companies, accounting split into financial accounting and management accounting. 

The first work on a double-entry bookkeeping system was published in Italy, by Luca Pacioli ("Father of Accounting"). Accounting began to transition into an organized profession in the nineteenth century, with local professional bodies in England merging to form the Institute of Chartered Accountants in England and Wales in 1880.

Both the words accounting and accountancy were in use in Great Britain by the mid-1800s, and are derived from the words "accompting" and "accountantship" used in the 18th century. In Middle English (used roughly between the 12th and the late 15th century) the verb "to account" had the form "accounten", which was derived from the Old French word "aconter", which is in turn related to the Vulgar Latin word "computare", meaning "to reckon". The base of "computare" is "putare", which "variously meant to prune, to purify, to correct an account, hence, to count or calculate, as well as to think."

The word "accountant" is derived from the French word , which is also derived from the Italian and Latin word . The word was formerly written in English as "accomptant", but in process of time the word, which was always pronounced by dropping the "p", became gradually changed both in pronunciation and in orthography to its present form.

Accounting has variously been defined as the keeping or preparation of the financial records of an entity, the analysis, verification and reporting of such records and "the principles and procedures of accounting"; it also refers to the job of being an accountant.

Accountancy refers to the occupation or profession of an accountant, particularly in British English.

Accounting has several subfields or subject areas, including financial accounting, management accounting, auditing, taxation and accounting information systems.

Financial accounting focuses on the reporting of an organization's financial information to external users of the information, such as investors, potential investors and creditors. It calculates and records business transactions and prepares financial statements for the external users in accordance with generally accepted accounting principles (GAAP). GAAP, in turn, arises from the wide agreement between accounting theory and practice, and change over time to meet the needs of decision-makers.

Financial accounting produces past-oriented reports—for example the financial statements prepared in 2006 reports on performance in 2005—on an annual or quarterly basis, generally about the organization as a whole.

This branch of accounting is also studied as part of the board exams for qualifying as an actuary. These two types of professionals, accountants and actuaries, have created a culture of being archrivals.

Management accounting focuses on the measurement, analysis and reporting of information that can help managers in making decisions to fulfill the goals of an organization. In management accounting, internal measures and reports are based on cost-benefit analysis, and are not required to follow the generally accepted accounting principle (GAAP). In 2014 CIMA created the Global Management Accounting Principles (GMAPs). The result of research from across 20 countries in five continents, the principles aim to guide best practice in the discipline.

Management accounting produces future-oriented reports—for example the budget for 2006 is prepared in 2005—and the time span of reports varies widely. Such reports may include both financial and non financial information, and may, for example, focus on specific products and departments.

Auditing is the verification of assertions made by others regarding a payoff, and in the context of accounting it is the "unbiased examination and evaluation of the financial statements of an organization". Audit is a professional service that is systematic and conventional.
An audit of financial statements aims to express or disclaim an opinion on the financial statements. The auditor expresses an opinion on the fairness with which the financial statements presents the financial position, results of operations, and cash flows of an entity, in accordance with the generally acceptable accounting principle (GAAP) and "in all material respects". An auditor is also required to identify circumstances in which the generally acceptable accounting principles (GAAP) has not been consistently observed.

An accounting information system is a part of an organization's information system that focuses on processing accounting data.
Many corporations use artificial intelligence-based information systems. Banking and finance industry is using AI as fraud detection. Retail industry is using AI for customer services. AI is also used in cybersecurity industry. It involves computer hardware and software systems and using statistics and modeling.

Tax accounting in the United States concentrates on the preparation, analysis and presentation of tax payments and tax returns. The U.S. tax system requires the use of specialised accounting principles for tax purposes which can differ from the generally accepted accounting principles (GAAP) for financial reporting. U.S. tax law covers four basic forms of business ownership: sole proprietorship, partnership, corporation, and limited liability company. Corporate and personal income are taxed at different rates, both varying according to income levels and including varying marginal rates (taxed on each additional dollar of income) and average rates (set as a percentage of overall income).

Forensic accounting is a specialty practice area of accounting that describes engagements that result from actual or anticipated disputes or litigation. "Forensic" means "suitable for use in a court of law," and it is to that standard and potential outcome that forensic accountants generally have to work.

Professional accounting bodies include the American Institute of Certified Public Accountants (AICPA) and the other 179 members of the International Federation of Accountants (IFAC), including Institute of Chartered Accountants of Scotland (ICAS), CPA Australia, Association of Chartered Certified Accountants (ACCA) and Institute of Chartered Accountants in England and Wales (ICAEW). Professional bodies for subfields of the accounting professions also exist, for example the Chartered Institute of Management Accountants (CIMA). Many of these professional bodies offer education and training including qualification and administration for various accounting designations, such as certified public accountant and chartered accountant.

Depending on its size, a company may be legally required to have their financial statements audited by a qualified auditor, and audits are usually carried out by accounting firms.

Accounting firms grew in the United States and Europe in the late nineteenth and early twentieth century, and through several mergers there were large international accounting firms by the mid-twentieth century. Further large mergers in the late twentieth century led to the dominance of the auditing market by the "Big Five" accounting firms: Arthur Andersen, Deloitte, Ernst & Young, KPMG and PricewaterhouseCoopers. The demise of Arthur Andersen following the Enron scandal reduced the Big Five to the Big Four.

Generally accepted accounting principles (GAAP) are accounting standards issued by national regulatory bodies. In addition, the International Accounting Standards Board (IASB) issues the International Financial Reporting Standards (IFRS) implemented by 147 countries. While standards for international audit and assurance, ethics, education, and public sector accounting are all set by independent standard settings boards supported by IFAC. The International Auditing and Assurance Standards Board sets international standards for auditing, assurance, and quality control; the International Ethics Standards Board for Accountants (IESBA) sets the internationally appropriate principles- based "Code of Ethics for Professional Accounts" the International Accounting Education Standards Board (IAESB) sets professional accounting education standards; International Public Sector Accounting Standards Board (IPSASB) sets accrual-based international public sector accounting standards 

Organizations in individual countries may issue accounting standards unique to the countries. For example, in the United States the Financial Accounting Standards Board (FASB) issues the Statements of Financial Accounting Standards, which form the basis of US GAAP, and in the United Kingdom the Financial Reporting Council (FRC) sets accounting standards. However, as of 2012 "all major economies" have plans to converge towards or adopt the IFRS.

At least a bachelor's degree in accounting or a related field is required for most accountant and auditor job positions, and some employers prefer applicants with a master's degree. A degree in accounting may also be required for, or may be used to fulfill the requirements for, membership to professional accounting bodies. For example, the education during an accounting degree can be used to fulfill the American Institute of CPA's (AICPA) 150 semester hour requirement, and associate membership with the Certified Public Accountants Association of the UK is available after gaining a degree in finance or accounting.

A doctorate is required in order to pursue a career in accounting academia, for example to work as a university professor in accounting. The Doctor of Philosophy (PhD) and the Doctor of Business Administration (DBA) are the most popular degrees. The PhD is the most common degree for those wishing to pursue a career in academia, while DBA programs generally focus on equipping business executives for business or public careers requiring research skills and qualifications.

Professional accounting qualifications include the Chartered Accountant designations and other qualifications including certificates and diplomas. In Scotland, chartered accountants of ICAS undergo Continuous Professional Development and abide by the ICAS code of ethics. In England and Wales, chartered accountants of the ICAEW undergo annual training, and are bound by the ICAEW's code of ethics and subject to its disciplinary procedures. In the United States, the requirements for joining the AICPA as a Certified Public Accountant are set by the Board of Accountancy of each state, and members agree to abide by the AICPA's Code of Professional Conduct and Bylaws. In India the Apex Accounting body constituted by parliament of India is "Institute of Chartered Accountants of India" (ICAI) was known for its rigorous training and study methodology for granting the Qualification. The ACCA is the largest global accountancy body with over 320,000 members and the organisation provides an ‘IFRS stream’ and a ‘UK stream’. Students must pass a total of 14 exams, which are arranged across three papers.

Accounting research is research in the effects of economic events on the process of accounting, the effects of reported information on economic events, and the roles of accounting in organizations and society.. It encompasses a broad range of research areas including financial accounting, management accounting, auditing and taxation.

Accounting research is carried out both by academic researchers and practicing accountants. Methodologies in academic accounting research include archival research, which examines "objective data collected from repositories"; experimental research, which examines data "the researcher gathered by administering treatments to subjects"; analytical research, which is "based on the act of formally modeling theories or substantiating ideas in mathematical terms"; interpretive research, which emphasizes the role of language, interpretation and understanding in accounting practice, "highlighting the symbolic structures and taken-for-granted themes which pattern the world in distinct ways"; critical research, which emphasizes the role of power and conflict in accounting practice; case studies; computer simulation; and field research.

Empirical studies document that leading accounting journals publish in total fewer research articles than comparable journals in economics and other business disciplines, and consequently, accounting scholars are relatively less successful in academic publishing than their business school peers. Due to different publication rates between accounting and other business disciplines, a recent study based on academic author rankings concludes that the competitive value of a single publication in a top-ranked journal is highest in accounting and lowest in marketing.

Many accounting practices have been simplified with the help of accounting computer-based software. An Enterprise resource planning (ERP) system is commonly used for a large organisation and it provides a comprehensive, centralized, integrated source of information that companies can use to manage all major business processes, from purchasing to manufacturing to human resources.

Accounting information systems have reduced the cost of accumulating, storing, and reporting managerial accounting information and have made it possible to produce a more detailed account of all data that is entered into any given system.

The year 2001 witnessed a series of financial information frauds involving Enron, auditing firm Arthur Andersen, the telecommunications company WorldCom, Qwest and Sunbeam, among other well-known corporations. These problems highlighted the need to review the effectiveness of accounting standards, auditing regulations and corporate governance principles. In some cases, management manipulated the figures shown in financial reports to indicate a better economic performance. In others, tax and regulatory incentives encouraged over-leveraging of companies and decisions to bear extraordinary and unjustified risk.

The Enron scandal deeply influenced the development of new regulations to improve the reliability of financial reporting, and increased public awareness about the importance of having accounting standards that show the financial reality of companies and the objectivity and independence of auditing firms.

In addition to being the largest bankruptcy reorganization in American history, the Enron scandal undoubtedly is the biggest audit failure. It involved a financial scandal of Enron Corporation and their auditors Arthur Andersen, which was revealed in late 2001. The scandal caused the dissolution of Arthur Andersen, which at the time was one of the five largest accounting firms in the world. After a series of revelations involving irregular accounting procedures conducted throughout the 1990s, Enron filed for Chapter 11 bankruptcy protection in December 2001.

One consequence of these events was the passage of Sarbanes–Oxley Act in the United States 2002, as a result of the first admissions of fraudulent behavior made by Enron. The act significantly raises criminal penalties for securities fraud, for destroying, altering or fabricating records in federal investigations or any scheme or attempt to defraud shareholders.




</doc>
<doc id="2594" url="https://en.wikipedia.org/wiki?curid=2594" title="Ant">
Ant

Ants are eusocial insects of the family Formicidae and, along with the related wasps and bees, belong to the order Hymenoptera. Ants evolved from wasp-like ancestors in the Cretaceous period, about 140 million years ago, and diversified after the rise of flowering plants. More than 12,500 of an estimated total of 22,000 species have been classified. They are easily identified by their elbowed antennae and the distinctive node-like structure that forms their slender waists.

Ants form colonies that range in size from a few dozen predatory individuals living in small natural cavities to highly organised colonies that may occupy large territories and consist of millions of individuals. Larger colonies consist of various castes of sterile, wingless females, most of which are workers (ergates), as well as soldiers (dinergates) and other specialised groups. Nearly all ant colonies also have some fertile males called "drones" (aner) and one or more fertile females called "queens" (gynes). The colonies are described as superorganisms because the ants appear to operate as a unified entity, collectively working together to support the colony.
Ants have colonised almost every landmass on Earth. The only places lacking indigenous ants are Antarctica and a few remote or inhospitable islands. Ants thrive in most ecosystems and may form 15–25% of the terrestrial animal biomass. Their success in so many environments has been attributed to their social organisation and their ability to modify habitats, tap resources, and defend themselves. Their long co-evolution with other species has led to mimetic, commensal, parasitic, and mutualistic relationships.

Ant societies have division of labour, communication between individuals, and an ability to solve complex problems. These parallels with human societies have long been an inspiration and subject of study. Many human cultures make use of ants in cuisine, medication, and rituals. Some species are valued in their role as biological pest control agents. Their ability to exploit resources may bring ants into conflict with humans, however, as they can damage crops and invade buildings. Some species, such as the red imported fire ant ("Solenopsis invicta"), are regarded as invasive species, establishing themselves in areas where they have been introduced accidentally.

The word "ant" and its chiefly dialectal form "emmet" come from ', ' of Middle English, which come from ' of Old English, and these are all related to the dialectal Dutch ' and the Old High German ', from which comes the modern German '. All of these words come from West Germanic "*", and the original meaning of the word was "the biter" (from Proto-Germanic ', "off, away" + ' "cut"). The family name Formicidae is derived from the Latin ' ("ant") from which the words in other Romance languages, such as the Portuguese ', Italian ', Spanish ', Romanian ', and French ' are derived. It has been hypothesised that a Proto-Indo-European word *morwi- was used, cf. Sanskrit vamrah, Latin formīca, Greek μύρμηξ "mýrmēx", Old Church Slavonic "mraviji", Old Irish "moirb", Old Norse "maurr", Dutch "mier".

The family Formicidae belongs to the order Hymenoptera, which also includes sawflies, bees, and wasps. Ants evolved from a lineage within the stinging wasps, and a 2013 study suggests that they are a sister group of the Apoidea. In 1966, E. O. Wilson and his colleagues identified the fossil remains of an ant ("Sphecomyrma") that lived in the Cretaceous period. The specimen, trapped in amber dating back to around 92 million years ago, has features found in some wasps, but not found in modern ants. "Sphecomyrma" was possibly a ground forager, while "Haidomyrmex" and "Haidomyrmodes", related genera in subfamily Sphecomyrminae, are reconstructed as active arboreal predators. Older ants in the genus "Sphecomyrmodes" have been found in 99 million year-old amber from Myanmar. A 2006 study suggested that ants arose tens of millions of years earlier than previously thought, up to 168 million years ago. After the rise of flowering plants about 100 million years ago they diversified and assumed ecological dominance around 60 million years ago. Some groups, such as the Leptanillinae and Martialinae, are suggested to have diversified from early primitive ants that were likely to have been predators underneath the surface of the soil.
During the Cretaceous period, a few species of primitive ants ranged widely on the Laurasian supercontinent (the Northern Hemisphere). They were scarce in comparison to the populations of other insects, representing only about 1% of the entire insect population. Ants became dominant after adaptive radiation at the beginning of the Paleogene period. By the Oligocene and Miocene, ants had come to represent 20–40% of all insects found in major fossil deposits. Of the species that lived in the Eocene epoch, around one in 10 genera survive to the present. Genera surviving today comprise 56% of the genera in Baltic amber fossils (early Oligocene), and 92% of the genera in Dominican amber fossils (apparently early Miocene).

Termites live in colonies and are sometimes called ‘white ants’, but termites are not ants. They are the sub-order Isoptera, and together with cockroaches they form the order Blattodea. Blattodeans are related to mantids, crickets, and other winged insects that do not undergo full metamorphosis. Like ants, termites are eusocial, with sterile workers, but they differ greatly in the genetics of reproduction. The similarity of their social structure to that of ants is attributed to convergent evolution. Velvet ants look like large ants, but are wingless female wasps.

Ants are found on all continents except Antarctica, and only a few large islands, such as Greenland, Iceland, parts of Polynesia and the Hawaiian Islands lack native ant species. Ants occupy a wide range of ecological niches and exploit many different food resources as direct or indirect herbivores, predators and scavengers. Most ant species are omnivorous generalists, but a few are specialist feeders. Their ecological dominance is demonstrated by their biomass: ants are estimated to contribute 15–20 % (on average and nearly 25% in the tropics) of terrestrial animal biomass, exceeding that of the vertebrates.

Ants range in size from , the largest species being the fossil "Titanomyrma giganteum", the queen of which was long with a wingspan of . Ants vary in colour; most ants are red or black, but a few species are green and some tropical species have a metallic lustre. More than 12,000 species are currently known (with upper estimates of the potential existence of about 22,000) (see the article List of ant genera), with the greatest diversity in the tropics. Taxonomic studies continue to resolve the classification and systematics of ants. Online databases of ant species, including AntBase and the Hymenoptera Name Server, help to keep track of the known and newly described species. The relative ease with which ants may be sampled and studied in ecosystems has made them useful as indicator species in biodiversity studies.

Ants are distinct in their morphology from other insects in having elbowed antennae, metapleural glands, and a strong constriction of their second abdominal segment into a node-like petiole. The head, mesosoma, and metasoma are the three distinct body segments (formally tagmata). The petiole forms a narrow waist between their mesosoma (thorax plus the first abdominal segment, which is fused to it) and gaster (abdomen less the abdominal segments in the petiole). The petiole may be formed by one or two nodes (the second alone, or the second and third abdominal segments).

Like other insects, ants have an exoskeleton, an external covering that provides a protective casing around the body and a point of attachment for muscles, in contrast to the internal skeletons of humans and other vertebrates. Insects do not have lungs; oxygen and other gases, such as carbon dioxide, pass through their exoskeleton via tiny valves called spiracles. Insects also lack closed blood vessels; instead, they have a long, thin, perforated tube along the top of the body (called the "dorsal aorta") that functions like a heart, and pumps haemolymph toward the head, thus driving the circulation of the internal fluids. The nervous system consists of a ventral nerve cord that runs the length of the body, with several ganglia and branches along the way reaching into the extremities of the appendages.

An ant's head contains many sensory organs. Like most insects, ants have compound eyes made from numerous tiny lenses attached together. Ant eyes are good for acute movement detection, but do not offer a high resolution image. They also have three small ocelli (simple eyes) on the top of the head that detect light levels and polarization. Compared to vertebrates, most ants have poor-to-mediocre eyesight and a few subterranean species are completely blind. However, some ants, such as Australia's bulldog ant, have excellent vision and are capable of discriminating the distance and size of objects moving nearly a metre away.

Two antennae ("feelers") are attached to the head; these organs detect chemicals, air currents, and vibrations; they also are used to transmit and receive signals through touch. The head has two strong jaws, the mandibles, used to carry food, manipulate objects, construct nests, and for defence. In some species, a small pocket (infrabuccal chamber) inside the mouth stores food, so it may be passed to other ants or their larvae.

Both the legs and wings of the ant are attached to the mesosoma ("thorax"). The legs terminate in a hooked claw which allows them to hook on and climb surfaces. Only reproductive ants, queens, and males, have wings. Queens shed their wings after the nuptial flight, leaving visible stubs, a distinguishing feature of queens. In a few species, wingless queens (ergatoids) and males occur.

The metasoma (the "abdomen") of the ant houses important internal organs, including those of the reproductive, respiratory (tracheae), and excretory systems. Workers of many species have their egg-laying structures modified into stings that are used for subduing prey and defending their nests.

In the colonies of a few ant species, there are physical castes—workers in distinct size-classes, called minor, median, and major ergates. Often, the larger ants have disproportionately larger heads, and correspondingly stronger mandibles. These are known as macrergates while smaller workers are known as micrergates. Although formally known as dinergates, such individuals are sometimes called "soldier" ants because their stronger mandibles make them more effective in fighting, although they still are workers and their "duties" typically do not vary greatly from the minor or median workers. In a few species, the median workers are absent, creating a sharp divide between the minors and majors. Weaver ants, for example, have a distinct bimodal size distribution. Some other species show continuous variation in the size of workers. The smallest and largest workers in "Pheidologeton diversus" show nearly a 500-fold difference in their dry-weights.

Workers cannot mate; however, because of the haplodiploid sex-determination system in ants, workers of a number of species can lay unfertilised eggs that become fully fertile, haploid males. The role of workers may change with their age and in some species, such as honeypot ants, young workers are fed until their gasters are distended, and act as living food storage vessels. These food storage workers are called "repletes". For instance, these replete workers develop in the North American honeypot ant "Myrmecocystus mexicanus". Usually the largest workers in the colony develop into repletes; and, if repletes are removed from the colony, other workers become repletes, demonstrating the flexibility of this particular polymorphism. This polymorphism in morphology and behaviour of workers initially was thought to be determined by environmental factors such as nutrition and hormones that led to different developmental paths; however, genetic differences between worker castes have been noted in "Acromyrmex" sp. These polymorphisms are caused by relatively small genetic changes; differences in a single gene of "Solenopsis invicta" can decide whether the colony will have single or multiple queens. The Australian jack jumper ant ("Myrmecia pilosula") has only a single pair of chromosomes (with the males having just one chromosome as they are haploid), the lowest number known for any animal, making it an interesting subject for studies in the genetics and developmental biology of social insects.

The life of an ant starts from an egg. If the egg is fertilised, the progeny will be female diploid; if not, it will be male haploid. Ants develop by complete metamorphosis with the larva stages passing through a pupal stage before emerging as an adult. The larva is largely immobile and is fed and cared for by workers. Food is given to the larvae by trophallaxis, a process in which an ant regurgitates liquid food held in its crop. This is also how adults share food, stored in the "social stomach". Larvae, especially in the later stages, may also be provided solid food, such as trophic eggs, pieces of prey, and seeds brought by workers.

The larvae grow through a series of four or five moults and enter the pupal stage. The pupa has the appendages free and not fused to the body as in a butterfly pupa. The differentiation into queens and workers (which are both female), and different castes of workers, is influenced in some species by the nutrition the larvae obtain. Genetic influences and the control of gene expression by the developmental environment are complex and the determination of caste continues to be a subject of research. Winged male ants, called drones, emerge from pupae along with the usually winged breeding females. Some species, such as army ants, have wingless queens. Larvae and pupae need to be kept at fairly constant temperatures to ensure proper development, and so often, are moved around among the various brood chambers within the colony.

A new ergate spends the first few days of its adult life caring for the queen and young. She then graduates to digging and other nest work, and later to defending the nest and foraging. These changes are sometimes fairly sudden, and define what are called temporal castes. An explanation for the sequence is suggested by the high casualties involved in foraging, making it an acceptable risk only for ants who are older and are likely to die soon of natural causes.

Ant colonies can be long-lived. The queens can live for up to 30 years, and workers live from 1 to 3 years. Males, however, are more transitory, being quite short-lived and surviving for only a few weeks. Ant queens are estimated to live 100 times as long as solitary insects of a similar size.

Ants are active all year long in the tropics, but, in cooler regions, they survive the winter in a state of dormancy known as hibernation. The forms of inactivity are varied and some temperate species have larvae going into the inactive state (diapause), while in others, the adults alone pass the winter in a state of reduced activity.

A wide range of reproductive strategies have been noted in ant species. Females of many species are known to be capable of reproducing asexually through thelytokous parthenogenesis. Secretions from the male accessory glands in some species can plug the female genital opening and prevent females from re-mating. Most ant species have a system in which only the queen and breeding females have the ability to mate. Contrary to popular belief, some ant nests have multiple queens, while others may exist without queens. Workers with the ability to reproduce are called "gamergates" and colonies that lack queens are then called gamergate colonies; colonies with queens are said to be queen-right.

Drones can also mate with existing queens by entering a foreign colony. When the drone is initially attacked by the workers, it releases a mating pheromone. If recognized as a mate, it will be carried to the queen to mate. Males may also patrol the nest and fight others by grabbing them with their mandibles, piercing their exoskeleton and then marking them with a pheromone. The marked male is interpreted as an invader by worker ants and is killed.

Most ants are univoltine, producing a new generation each year. During the species-specific breeding period, winged females and winged males, known to entomologists as alates, leave the colony in what is called a nuptial flight. The nuptial flight usually takes place in the late spring or early summer when the weather is hot and humid. Heat makes flying easier and freshly fallen rain makes the ground softer for mated queens to dig nests. Males typically take flight before the females. Males then use visual cues to find a common mating ground, for example, a landmark such as a pine tree to which other males in the area converge. Males secrete a mating pheromone that females follow. Males will mount females in the air, but the actual mating process usually takes place on the ground. Females of some species mate with just one male but in others they may mate with as many as ten or more different males, storing the sperm in their spermathecae.

Mated females then seek a suitable place to begin a colony. There, they break off their wings and begin to lay and care for eggs. The females can selectively fertilise future eggs with the sperm stored to produce diploid workers or lay unfertilized haploid eggs to produce drones. The first workers to hatch are known as nanitics, and are weaker and smaller than later workers, but they begin to serve the colony immediately. They enlarge the nest, forage for food, and care for the other eggs. Species that have multiple queens may have a queen leaving the nest along with some workers to found a colony at a new site, a process akin to swarming in honeybees.

Ants communicate with each other using pheromones, sounds, and touch. The use of pheromones as chemical signals is more developed in ants, such as the red harvester ant, than in other hymenopteran groups. Like other insects, ants perceive smells with their long, thin, and mobile antennae. The paired antennae provide information about the direction and intensity of scents. Since most ants live on the ground, they use the soil surface to leave pheromone trails that may be followed by other ants. In species that forage in groups, a forager that finds food marks a trail on the way back to the colony; this trail is followed by other ants, these ants then reinforce the trail when they head back with food to the colony. When the food source is exhausted, no new trails are marked by returning ants and the scent slowly dissipates. This behaviour helps ants deal with changes in their environment. For instance, when an established path to a food source is blocked by an obstacle, the foragers leave the path to explore new routes. If an ant is successful, it leaves a new trail marking the shortest route on its return. Successful trails are followed by more ants, reinforcing better routes and gradually identifying the best path.

Ants use pheromones for more than just making trails. A crushed ant emits an alarm pheromone that sends nearby ants into an attack frenzy and attracts more ants from farther away. Several ant species even use "propaganda pheromones" to confuse enemy ants and make them fight among themselves. Pheromones are produced by a wide range of structures including Dufour's glands, poison glands and glands on the hindgut, pygidium, rectum, sternum, and hind tibia. Pheromones also are exchanged, mixed with food, and passed by trophallaxis, transferring information within the colony. This allows other ants to detect what task group (e.g., foraging or nest maintenance) other colony members belong to. In ant species with queen castes, when the dominant queen stops producing a specific pheromone, workers begin to raise new queens in the colony.

Some ants produce sounds by stridulation, using the gaster segments and their mandibles. Sounds may be used to communicate with colony members or with other species.

Ants attack and defend themselves by biting and, in many species, by stinging, often injecting or spraying chemicals, such as formic acid in the case of formicine ants, alkaloids and piperidines in fire ants, and a variety of protein components in other ants. Bullet ants ("Paraponera"), located in Central and South America, are considered to have the most painful sting of any insect, although it is usually not fatal to humans. This sting is given the highest rating on the Schmidt Sting Pain Index.

The sting of jack jumper ants can be fatal, and an antivenom has been developed for it.

Fire ants, "Solenopsis" spp., are unique in having a venom sac containing piperidine alkaloids. Their stings are painful and can be dangerous to hypersensitive people.
Trap-jaw ants of the genus "Odontomachus" are equipped with mandibles called trap-jaws, which snap shut faster than any other predatory appendages within the animal kingdom. One study of "Odontomachus bauri" recorded peak speeds of between , with the jaws closing within 130 microseconds on average.
The ants were also observed to use their jaws as a catapult to eject intruders or fling themselves backward to escape a threat. Before striking, the ant opens its mandibles extremely widely and locks them in this position by an internal mechanism. Energy is stored in a thick band of muscle and explosively released when triggered by the stimulation of sensory organs resembling hairs on the inside of the mandibles. The mandibles also permit slow and fine movements for other tasks. Trap-jaws also are seen in the following genera: "Anochetus", "Orectognathus", and "Strumigenys", plus some members of the Dacetini tribe, which are viewed as examples of convergent evolution.

A Malaysian species of ant in the "Camponotus" "cylindricus" group has enlarged mandibular glands that extend into their gaster. If combat takes a turn for the worse, a worker may perform a final act of suicidal altruism by rupturing the membrane of its gaster, causing the content of its mandibular glands to burst from the anterior region of its head, spraying a poisonous, corrosive secretion containing acetophenones and other chemicals that immobilise small insect attackers. The worker subsequently dies.

Suicidal defences by workers are also noted in a Brazilian ant, "Forelius pusillus", where a small group of ants leaves the security of the nest after sealing the entrance from the outside each evening.
In addition to defence against predators, ants need to protect their colonies from pathogens. Some worker ants maintain the hygiene of the colony and their activities include undertaking or "necrophory", the disposal of dead nest-mates. Oleic acid has been identified as the compound released from dead ants that triggers necrophoric behaviour in "Atta mexicana" while workers of "Linepithema humile" react to the absence of characteristic chemicals (dolichodial and iridomyrmecin) present on the cuticle of their living nestmates to trigger similar behaviour.

Nests may be protected from physical threats such as flooding and overheating by elaborate nest architecture. Workers of "Cataulacus muticus", an arboreal species that lives in plant hollows, respond to flooding by drinking water inside the nest, and excreting it outside. "Camponotus anderseni", which nests in the cavities of wood in mangrove habitats, deals with submergence under water by switching to anaerobic respiration.

Many animals can learn behaviours by imitation, but ants may be the only group apart from mammals where interactive teaching has been observed. A knowledgeable forager of "Temnothorax albipennis" will lead a naive nest-mate to newly discovered food by the process of tandem running. The follower obtains knowledge through its leading tutor. The leader is acutely sensitive to the progress of the follower and slows down when the follower lags and speeds up when the follower gets too close.

Controlled experiments with colonies of "Cerapachys biroi" suggest that an individual may choose nest roles based on her previous experience. An entire generation of identical workers was divided into two groups whose outcome in food foraging was controlled. One group was continually rewarded with prey, while it was made certain that the other failed. As a result, members of the successful group intensified their foraging attempts while the unsuccessful group ventured out fewer and fewer times. A month later, the successful foragers continued in their role while the others had moved to specialise in brood care.

Complex nests are built by many ant species, but other species are nomadic and do not build permanent structures. Ants may form subterranean nests or build them on trees. These nests may be found in the ground, under stones or logs, inside logs, hollow stems, or even acorns. The materials used for construction include soil and plant matter, and ants carefully select their nest sites; "Temnothorax albipennis" will avoid sites with dead ants, as these may indicate the presence of pests or disease. They are quick to abandon established nests at the first sign of threats.

The army ants of South America, such as the "Eciton burchellii" species, and the driver ants of Africa do not build permanent nests, but instead, alternate between nomadism and stages where the workers form a temporary nest (bivouac) from their own bodies, by holding each other together.

Weaver ant ("Oecophylla" spp.) workers build nests in trees by attaching leaves together, first pulling them together with bridges of workers and then inducing their larvae to produce silk as they are moved along the leaf edges. Similar forms of nest construction are seen in some species of "Polyrhachis".

"Formica polyctena", among other ant species, constructs nests that maintain a relatively constant interior temperature that aids in the development of larvae. The ants maintain the nest temperature by choosing the location, nest materials, controlling ventilation and maintaining the heat from solar radiation, worker activity and metabolism, and in some moist nests, microbial activity in the nest materials.

Some ant species, such as those that use natural cavities, can be opportunistic and make use of the controlled micro-climate provided inside human dwellings and other artificial structures to house their colonies and nest structures.

Most ants are generalist predators, scavengers, and indirect herbivores, but a few have evolved specialised ways of obtaining nutrition. It is believed that many ant species that engage in indirect herbivory rely on specialized symbiosis with their gut microbes to upgrade the nutritional value of the food they collect and allow them to survive in nitrogen poor regions, such as rainforest canopies. Leafcutter ants ("Atta" and "Acromyrmex") feed exclusively on a fungus that grows only within their colonies. They continually collect leaves which are taken to the colony, cut into tiny pieces and placed in fungal gardens. Ergates specialise in related tasks according to their sizes. The largest ants cut stalks, smaller workers chew the leaves and the smallest tend the fungus. Leafcutter ants are sensitive enough to recognise the reaction of the fungus to different plant material, apparently detecting chemical signals from the fungus. If a particular type of leaf is found to be toxic to the fungus, the colony will no longer collect it. The ants feed on structures produced by the fungi called "gongylidia". Symbiotic bacteria on the exterior surface of the ants produce antibiotics that kill bacteria introduced into the nest that may harm the fungi.

Foraging ants travel distances of up to from their nest and scent trails allow them to find their way back even in the dark. In hot and arid regions, day-foraging ants face death by desiccation, so the ability to find the shortest route back to the nest reduces that risk. Diurnal desert ants of the genus "Cataglyphis" such as the Sahara desert ant navigate by keeping track of direction as well as distance travelled. Distances travelled are measured using an internal pedometer that keeps count of the steps taken and also by evaluating the movement of objects in their visual field (optical flow). Directions are measured using the position of the sun.
They integrate this information to find the shortest route back to their nest.
Like all ants, they can also make use of visual landmarks when available as well as olfactory and tactile cues to navigate. Some species of ant are able to use the Earth's magnetic field for navigation. The compound eyes of ants have specialised cells that detect polarised light from the Sun, which is used to determine direction.
These polarization detectors are sensitive in the ultraviolet region of the light spectrum. In some army ant species, a group of foragers who become separated from the main column may sometimes turn back on themselves and form a circular ant mill. The workers may then run around continuously until they die of exhaustion.

The female worker ants do not have wings and reproductive females lose their wings after their mating flights in order to begin their colonies. Therefore, unlike their wasp ancestors, most ants travel by walking. Some species are capable of leaping. For example, Jerdon's jumping ant ("Harpegnathos saltator") is able to jump by synchronising the action of its mid and hind pairs of legs. There are several species of gliding ant including "Cephalotes atratus"; this may be a common trait among arboreal ants with small colonies. Ants with this ability are able to control their horizontal movement so as to catch tree trunks when they fall from atop the forest canopy.

Other species of ants can form chains to bridge gaps over water, underground, or through spaces in vegetation. Some species also form floating rafts that help them survive floods. These rafts may also have a role in allowing ants to colonise islands. "Polyrhachis sokolova", a species of ant found in Australian mangrove swamps, can swim and live in underwater nests. Since they lack gills, they go to trapped pockets of air in the submerged nests to breathe.

Not all ants have the same kind of societies. The Australian bulldog ants are among the biggest and most basal of ants. Like virtually all ants, they are eusocial, but their social behaviour is poorly developed compared to other species. Each individual hunts alone, using her large eyes instead of chemical senses to find prey.

Some species (such as "Tetramorium caespitum") attack and take over neighbouring ant colonies. Others are less expansionist, but just as aggressive; they invade colonies to steal eggs or larvae, which they either eat or raise as workers or slaves. Extreme specialists among these slave-raiding ants, such as the Amazon ants, are incapable of feeding themselves and need captured workers to survive. Captured workers of enslaved "Temnothorax" species have evolved a counter strategy, destroying just the female pupae of the slave-making "Temnothorax americanus", but sparing the males (who don't take part in slave-raiding as adults).
Ants identify kin and nestmates through their scent, which comes from hydrocarbon-laced secretions that coat their exoskeletons. If an ant is separated from its original colony, it will eventually lose the colony scent. Any ant that enters a colony without a matching scent will be attacked. Also, the reason why two separate colonies of ants will attack each other even if they are of the same species is because the genes responsible for pheromone production are different between them. The Argentine ant, however, does not have this characteristic, due to lack of genetic diversity, and has become a global pest because of it.

Parasitic ant species enter the colonies of host ants and establish themselves as social parasites; species such as "Strumigenys xenos" are entirely parasitic and do not have workers, but instead, rely on the food gathered by their "Strumigenys perplexa" hosts. This form of parasitism is seen across many ant genera, but the parasitic ant is usually a species that is closely related to its host. A variety of methods are employed to enter the nest of the host ant. A parasitic queen may enter the host nest before the first brood has hatched, establishing herself prior to development of a colony scent. Other species use pheromones to confuse the host ants or to trick them into carrying the parasitic queen into the nest. Some simply fight their way into the nest.

A conflict between the sexes of a species is seen in some species of ants with these reproducers apparently competing to produce offspring that are as closely related to them as possible. The most extreme form involves the production of clonal offspring. An extreme of sexual conflict is seen in "Wasmannia auropunctata", where the queens produce diploid daughters by thelytokous parthenogenesis and males produce clones by a process whereby a diploid egg loses its maternal contribution to produce haploid males who are clones of the father.

Ants form symbiotic associations with a range of species, including other ant species, other insects, plants, and fungi. They also are preyed on by many animals and even certain fungi. Some arthropod species spend part of their lives within ant nests, either preying on ants, their larvae, and eggs, consuming the food stores of the ants, or avoiding predators. These inquilines may bear a close resemblance to ants. The nature of this ant mimicry (myrmecomorphy) varies, with some cases involving Batesian mimicry, where the mimic reduces the risk of predation. Others show Wasmannian mimicry, a form of mimicry seen only in inquilines.
Aphids and other hemipteran insects secrete a sweet liquid called honeydew, when they feed on plant sap. The sugars in honeydew are a high-energy food source, which many ant species collect. In some cases, the aphids secrete the honeydew in response to ants tapping them with their antennae. The ants in turn keep predators away from the aphids and will move them from one feeding location to another. When migrating to a new area, many colonies will take the aphids with them, to ensure a continued supply of honeydew. Ants also tend mealybugs to harvest their honeydew. Mealybugs may become a serious pest of pineapples if ants are present to protect mealybugs from their natural enemies.

Myrmecophilous (ant-loving) caterpillars of the butterfly family Lycaenidae (e.g., blues, coppers, or hairstreaks) are herded by the ants, led to feeding areas in the daytime, and brought inside the ants' nest at night. The caterpillars have a gland which secretes honeydew when the ants massage them. Some caterpillars produce vibrations and sounds that are perceived by the ants. A similar adaptation can be seen in Grizzled skipper butterflies that emit vibrations by expanding their wings in order to communicate with ants, which are natural predators of these butterflies. Other caterpillars have evolved from ant-loving to ant-eating: these myrmecophagous caterpillars secrete a pheromone that makes the ants act as if the caterpillar is one of their own larvae. The caterpillar is then taken into the ant nest where it feeds on the ant larvae. A number of specialized bacterial have been found as endosymbionts in ant guts. Some of the dominant bacteria belong to the order Rhizobiales whose members are known for being nitrogen-fixing symbionts in legumes but the species found in ant lack the ability to fix nitrogen. Fungus-growing ants that make up the tribe Attini, including leafcutter ants, cultivate certain species of fungus in the genera "Leucoagaricus" or "Leucocoprinus" of the family Agaricaceae. In this ant-fungus mutualism, both species depend on each other for survival. The ant "Allomerus decemarticulatus" has evolved a three-way association with the host plant, "Hirtella physophora" (Chrysobalanaceae), and a sticky fungus which is used to trap their insect prey.

Lemon ants make devil's gardens by killing surrounding plants with their stings and leaving a pure patch of lemon ant trees, ("Duroia hirsuta"). This modification of the forest provides the ants with more nesting sites inside the stems of the "Duroia" trees. Although some ants obtain nectar from flowers, pollination by ants is somewhat rare, one example being of the pollination of the orchid "Leporella fimbriata" which induces male "Myrmecia urens" to pseudocopulate with the flowers, transferring pollen in the process. One theory that has been proposed for the rarity of pollination is that the secretions of the metapleural gland inactivate and reduce the viability of pollen. Some plants have special nectar exuding structures, extrafloral nectaries, that provide food for ants, which in turn protect the plant from more damaging herbivorous insects. Species such as the bullhorn acacia ("Acacia cornigera") in Central America have hollow thorns that house colonies of stinging ants ("Pseudomyrmex ferruginea") who defend the tree against insects, browsing mammals, and epiphytic vines. Isotopic labelling studies suggest that plants also obtain nitrogen from the ants. In return, the ants obtain food from protein- and lipid-rich Beltian bodies. In Fiji "Philidris nagasau" (Dolichoderinae) are known to selectively grow species of epiphytic "Squamellaria" (Rubiaceae) which produce large domatia inside which the ant colonies nest. The ants plant the seeds and the domatia of young seedling are immediately occupied and the ant faeces in them contribute to rapid growth. Similar dispersal associations are found with other dolichoderines in the region as well. Another example of this type of ectosymbiosis comes from the "Macaranga" tree, which has stems adapted to house colonies of "Crematogaster" ants.

Many plant species have seeds that are adapted for dispersal by ants. Seed dispersal by ants or myrmecochory is widespread, and new estimates suggest that nearly 9% of all plant species may have such ant associations. Often, seed-dispersing ants perform directed dispersal, depositing the seeds in locations that increase the likelihood of seed survival to reproduction. Some plants in arid, fire-prone systems are particularly dependent on ants for their survival and dispersal as the seeds are transported to safety below the ground. Many ant-dispersed seeds have special external structures, elaiosomes, that are sought after by ants as food.

A convergence, possibly a form of mimicry, is seen in the eggs of stick insects. They have an edible elaiosome-like structure and are taken into the ant nest where the young hatch.
Most ants are predatory and some prey on and obtain food from other social insects including other ants. Some species specialise in preying on termites ("Megaponera" and "Termitopone") while a few Cerapachyinae prey on other ants. Some termites, including "Nasutitermes corniger", form associations with certain ant species to keep away predatory ant species. The tropical wasp "Mischocyttarus drewseni" coats the pedicel of its nest with an ant-repellent chemical. It is suggested that many tropical wasps may build their nests in trees and cover them to protect themselves from ants. Other wasps, such as "A. multipicta", defend against ants by blasting them off the nest with bursts of wing buzzing. Stingless bees ("Trigona" and "Melipona") use chemical defences against ants.

Flies in the Old World genus "Bengalia" (Calliphoridae) prey on ants and are kleptoparasites, snatching prey or brood from the mandibles of adult ants. Wingless and legless females of the Malaysian phorid fly ("Vestigipoda myrmolarvoidea") live in the nests of ants of the genus "Aenictus" and are cared for by the ants.

Fungi in the genera "Cordyceps" and "Ophiocordyceps" infect ants. Ants react to their infection by climbing up plants and sinking their mandibles into plant tissue. The fungus kills the ants, grows on their remains, and produces a fruiting body. It appears that the fungus alters the behaviour of the ant to help disperse its spores in a microhabitat that best suits the fungus. Strepsipteran parasites also manipulate their ant host to climb grass stems, to help the parasite find mates.

A nematode ("Myrmeconema neotropicum") that infects canopy ants ("Cephalotes atratus") causes the black-coloured gasters of workers to turn red. The parasite also alters the behaviour of the ant, causing them to carry their gasters high. The conspicuous red gasters are mistaken by birds for ripe fruits, such as "Hyeronima alchorneoides", and eaten. The droppings of the bird are collected by other ants and fed to their young, leading to further spread of the nematode.
South American poison dart frogs in the genus "Dendrobates" feed mainly on ants, and the toxins in their skin may come from the ants.

Army ants forage in a wide roving column, attacking any animals in that path that are unable to escape. In Central and South America, "Eciton burchellii" is the swarming ant most commonly attended by "ant-following" birds such as antbirds and woodcreepers. This behaviour was once considered mutualistic, but later studies found the birds to be parasitic. Direct kleptoparasitism (birds stealing food from the ants' grasp) is rare and has been noted in Inca doves which pick seeds at nest entrances as they are being transported by species of "Pogonomyrmex". Birds that follow ants eat many prey insects and thus decrease the foraging success of ants. Birds indulge in a peculiar behaviour called anting that, as yet, is not fully understood. Here birds rest on ant nests, or pick and drop ants onto their wings and feathers; this may be a means to remove ectoparasites from the birds.

Anteaters, aardvarks, pangolins, echidnas and numbats have special adaptations for living on a diet of ants. These adaptations include long, sticky tongues to capture ants and strong claws to break into ant nests. Brown bears ("Ursus arctos") have been found to feed on ants. About 12%, 16%, and 4% of their faecal volume in spring, summer, and autumn, respectively, is composed of ants.

Ants perform many ecological roles that are beneficial to humans, including the suppression of pest populations and aeration of the soil. The use of weaver ants in citrus cultivation in southern China is considered one of the oldest known applications of biological control. On the other hand, ants may become nuisances when they invade buildings, or cause economic losses.

In some parts of the world (mainly Africa and South America), large ants, especially army ants, are used as surgical sutures. The wound is pressed together and ants are applied along it. The ant seizes the edges of the wound in its mandibles and locks in place. The body is then cut off and the head and mandibles remain in place to close the wound. The large heads of the dinergates (soldiers) of the leafcutting ant "Atta cephalotes" are also used by native surgeons in closing wounds.

Some ants have toxic venom and are of medical importance. The species include "Paraponera clavata" (tocandira) and "Dinoponera" spp. (false tocandiras) of South America and the "Myrmecia" ants of Australia.

In South Africa, ants are used to help harvest the seeds of rooibos ("Aspalathus linearis"), a plant used to make a herbal tea. The plant disperses its seeds widely, making manual collection difficult. Black ants collect and store these and other seeds in their nest, where humans can gather them "en masse". Up to half a pound (200 g) of seeds may be collected from one ant-heap.

Although most ants survive attempts by humans to eradicate them, a few are highly endangered. These tend to be island species that have evolved specialized traits and risk being displaced by introduced ant species. Examples include the critically endangered Sri Lankan relict ant ("Aneuretus simoni") and "Adetomyrma venatrix" of Madagascar.

It has been estimated by E.O. Wilson that the total number of individual ants alive in the world at any one time is between one and ten quadrillion (short scale) (i.e., between 10 and 10). According to this estimate, the total biomass of all the ants in the world is approximately equal to the total biomass of the entire human race. Also, according to this estimate, there are approximately 1 million ants for every human on Earth.

Ants and their larvae are eaten in different parts of the world. The eggs of two species of ants are used in Mexican "escamoles". They are considered a form of insect caviar and can sell for as much as US$40 per pound ($90/kg) because they are seasonal and hard to find. In the Colombian department of Santander, "hormigas culonas" (roughly interpreted as "large-bottomed ants") "Atta laevigata" are toasted alive and eaten.
In areas of India, and throughout Burma and Thailand, a paste of the green weaver ant ("Oecophylla smaragdina") is served as a condiment with curry. Weaver ant eggs and larvae, as well as the ants, may be used in a Thai salad, "yam" (), in a dish called "yam khai mot daeng" () or red ant egg salad, a dish that comes from the Issan or north-eastern region of Thailand. Saville-Kent, in the "Naturalist in Australia" wrote "Beauty, in the case of the green ant, is more than skin-deep. Their attractive, almost sweetmeat-like translucency possibly invited the first essays at their consumption by the human species". Mashed up in water, after the manner of lemon squash, "these ants form a pleasant acid drink which is held in high favor by the natives of North Queensland, and is even appreciated by many European palates".

In his "First Summer in the Sierra", John Muir notes that the Digger Indians of California ate the tickling, acid gasters of the large jet-black carpenter ants. The Mexican Indians eat the replete workers, or living honey-pots, of the honey ant ("Myrmecocystus").

Some ant species are considered as pests, primarily those that occur in human habitations, where their presence is often problematic. For example, the presence of ants would be undesirable in sterile places such as hospitals or kitchens. Some species or genera commonly categorized as pests include the Argentine ant, pavement ant, yellow crazy ant, banded sugar ant, Pharaoh ant, carpenter ants, odorous house ant, red imported fire ant, and European fire ant. Some ants will raid stored food, others may damage indoor structures, some can damage agricultural crops directly (or by aiding sucking pests), and some will sting or bite. The adaptive nature of ant colonies make it nearly impossible to eliminate entire colonies and most pest management practices aim to control local populations and tend to be temporary solutions. Ant populations are managed by a combination of approaches that make use of chemical, biological and physical methods. Chemical methods include the use of insecticidal bait which is gathered by ants as food and brought back to the nest where the poison is inadvertently spread to other colony members through trophallaxis. Management is based on the species and techniques can vary according to the location and circumstance.

Observed by humans since the dawn of history, the behaviour of ants has been documented and the subject of early writings and fables passed from one century to another. Those using scientific methods, myrmecologists, study ants in the laboratory and in their natural conditions. Their complex and variable social structures have made ants ideal model organisms. Ultraviolet vision was first discovered in ants by Sir John Lubbock in 1881. Studies on ants have tested hypotheses in ecology and sociobiology, and have been particularly important in examining the predictions of theories of kin selection and evolutionarily stable strategies. Ant colonies may be studied by rearing or temporarily maintaining them in "formicaria", specially constructed glass framed enclosures. Individuals may be tracked for study by marking them with dots of colours.

The successful techniques used by ant colonies have been studied in computer science and robotics to produce distributed and fault-tolerant systems for solving problems, for example Ant colony optimization and Ant robotics. This area of biomimetics has led to studies of ant locomotion, search engines that make use of "foraging trails", fault-tolerant storage, and networking algorithms.

From the late 1950s through the late 1970s, ant farms were popular educational children's toys in the United States. Some later commercial versions use transparent gel instead of soil, allowing greater visibility at the cost of stressing the ants with unnatural light.

Anthropomorphised ants have often been used in fables and children's stories to represent industriousness and cooperative effort. They also are mentioned in religious texts. In the Book of Proverbs in the Bible, ants are held up as a good example for humans for their hard work and cooperation. Aesop did the same in his fable The Ant and the Grasshopper. In the Quran, Sulayman is said to have heard and understood an ant warning other ants to return home to avoid being accidentally crushed by Sulayman and his marching army. In parts of Africa, ants are considered to be the messengers of the deities. Some Native American mythology, such as the Hopi mythology, considers ants as the very first animals. Ant bites are often said to have curative properties. The sting of some species of "Pseudomyrmex" is claimed to give fever relief. Ant bites are used in the initiation ceremonies of some Amazon Indian cultures as a test of endurance.

Ant society has always fascinated humans and has been written about both humorously and seriously. Mark Twain wrote about ants in his 1880 book "A Tramp Abroad". Some modern authors have used the example of the ants to comment on the relationship between society and the individual. Examples are Robert Frost in his poem "Departmental" and T. H. White in his fantasy novel "The Once and Future King". The plot in French entomologist and writer Bernard Werber's "Les Fourmis" science-fiction trilogy is divided between the worlds of ants and humans; ants and their behaviour is described using contemporary scientific knowledge. H.G. Wells wrote about intelligent ants destroying human settlements in Brazil and threatening human civilization in his 1905 science-fiction short story, "The Empire of the Ants." In more recent times, animated cartoons and 3-D animated films featuring ants have been produced including "Antz", "A Bug's Life", "The Ant Bully", "The Ant and the Aardvark", "Ferdy the Ant" and "Atom Ant." Renowned myrmecologist E. O. Wilson wrote a short story, "Trailhead" in 2010 for "The New Yorker" magazine, which describes the life and death of an ant-queen and the rise and fall of her colony, from an ants' point of view. The French neuroanatomist, psychiatrist and eugenicist Auguste Forel believed that ant societies were models for human society. He published a five volume work from 1921 to 1923 that examined ant biology and society.

In the early 1990s, the video game "SimAnt", which simulated an ant colony, won the 1992 Codie award for "Best Simulation Program".

Ants also are quite popular inspiration for many science-fiction insectoids, such as the Formics of "Ender's Game", the Bugs of "Starship Troopers", the giant ants in the films "Them!" and "Empire of the Ants," Marvel Comics' super hero Ant-Man, and ants mutated into super-intelligence in "Phase IV". In computer strategy games, ant-based species often benefit from increased production rates due to their single-minded focus, such as the Klackons in the "Master of Orion" series of games or the ChCht in "Deadlock II". These characters are often credited with a hive mind, a common misconception about ant colonies.






</doc>
<doc id="2597" url="https://en.wikipedia.org/wiki?curid=2597" title="Arbitration in the United States">
Arbitration in the United States

Arbitration, in the context of United States law, is a form of alternative dispute resolution. Specifically, arbitration is an alternative to litigation through which the parties to a dispute agree to submit their respective positions (through agreement or hearing) to a neutral third party (the arbitrator(s) or arbiter(s)) for resolution. In practice arbitration is generally used as a substitute for litigation, particularly when the judicial process is perceived as too slow, expensive or biased. In some context, an arbitrator may be described as an umpire.

Agreements to arbitrate were not enforceable at common law, traced back to dictum by Lord Coke in "Vynor’s Case", 8 Co. Rep. 81b, 77 Eng. Rep. 597 (1609), that agreements to arbitrate were revocable by either party.

During the Industrial Revolution, large corporations became increasingly opposed to this policy. They argued that too many valuable business relationships were being destroyed through years of expensive adversarial litigation, in courts whose rules differed significantly from the informal norms and conventions of businesspeople (the private law of commerce, or "jus merchant"). Arbitration was promoted as being faster, less adversarial, and cheaper.

The result was the New York Arbitration Act of 1920, followed by the United States Arbitration Act of 1925 (now known as the Federal Arbitration Act). Both made agreements to arbitrate valid and enforceable (unless one party could show fraud or unconscionability or some other ground for rescission which undermined the validity of the entire contract). Due to the subsequent judicial expansion of the meaning of interstate commerce, the U.S. Supreme Court reinterpreted the FAA in a series of cases in the 1980s and 1990s to cover almost the full scope of interstate commerce. In the process, the Court held that the FAA preempted many state laws covering arbitration, some of which had been passed by state legislatures to protect their consumers against powerful corporations.

Since commercial arbitration is based upon either contract law or the law of treaties, the agreement between the parties to submit their dispute to arbitration is a legally binding contract. All arbitral decisions are considered to be "final and binding." This does not, however, void the requirements of law. Any dispute not excluded from arbitration by virtue of law (for example, criminal proceedings) may be submitted to arbitration.

Furthermore, arbitration agreements can only bind parties who have agreed, expressly or impliedly to arbitrate. Arbitration cannot bind nonsignatories to an arbitration contract, even if those nonsignatories later become involved with a signatory to a contract by accident (usually through the commission of a tort).

Arbitration may be used as a means of resolving labor disputes, an alternative to strikes and lockouts . Labor arbitration comes in two varieties:

Arbitration has also been used as a means of resolving labor disputes for more than a century. Labor organizations in the United States, such as the National Labor Union, called for arbitration as early as 1866 as an alternative to strikes to resolve disputes over the wages, benefits and other rights that workers would enjoy.

Governments have relied on arbitration to resolve particularly large labor disputes, such as the Coal Strike of 1902. This type of arbitration, wherein a neutral arbitrator decides the terms of the collective bargaining agreement, is commonly known as interest arbitration. The United Steelworkers of America adopted an elaborate form of interest arbitration, known as the Experimental Negotiating Agreement, in the 1970s as a means of avoiding the long and costly strikes that had made the industry vulnerable to foreign competition. Major League Baseball uses a variant of interest arbitration, in which an arbitrator chooses between the two sides' final offers, to set the terms for contracts for players who are not eligible for free agency. Interest arbitration is now most frequently used by public employees who have no right to strike (for example, law enforcement and firefighters).

Unions and employers have also employed arbitration to resolve employee and union grievances arising under a collective bargaining agreement. The Amalgamated Clothing Workers of America made arbitration a central element of the "Protocol of Peace" it negotiated with garment manufacturers in the second decade of the twentieth century. Grievance arbitration became even more popular during World War II, when most unions had adopted a no-strike pledge. The War Labor Board, which attempted to mediate disputes over contract terms, pressed for inclusion of grievance arbitration in collective bargaining agreements. The Supreme Court subsequently made labor arbitration a key aspect of federal labor policy in three cases which came to be known as the Steelworkers' Trilogy. The Court held that grievance arbitration was a preferred dispute resolution technique and that courts could not overturn arbitrators' awards unless the award does not draw its essence from the collective bargaining agreement. State and federal statutes may allow vacating an award on narrow grounds ("e.g.", fraud). These protections for arbitrator awards are premised on the union-management system, which provides both parties with due process. Due process in this context means that both parties have experienced representation throughout the process, and that the arbitrators practice only as neutrals. "See" National Academy of Arbitrators.

In the United States securities industry, arbitration has long been the preferred method of resolving disputes between brokerage firms, and between firms and their customers. The arbitration process operates under its own rules, as defined by contract. Securities arbitrations are held primarily by the Financial Industry Regulatory Authority.

The securities industry uses pre-dispute arbitration agreements, through which the parties agree to arbitrate their disputes before any such dispute arises. Those agreements were upheld by the United States Supreme Court in Shearson v. MacMahon, 482 U.S. 220 (1987) and today nearly all disputes involving brokerage firms, other than Securities class action claims, are resolved in arbitration.

The SEC has come under fire from members of the Senate Judiciary Committee for not fulfilling statutory duty to protect individual investors, because all brokers require arbitration, and arbitration does not provide a court-supervised discovery process, require arbitrators to follow rules of evidence or result in written opinions establishing precedence, or case law, or provide the efficiency gains it once did. Arbitrator selection bias, hidden conflicts of interest, and a case where an arbitration panel refused to follow instructions handed down from a judge, were also raised as issues.

Some state court systems have promulgated court-ordered arbitration; family law (particularly child custody) is the most prominent example. Judicial arbitration is often merely advisory dispute resolution technique, serving as the first step toward resolution, but not binding either side and allowing for trial de novo. Litigation attorneys present their side of the case to an independent tertiary lawyer, who issues an opinion on settlement. Should the parties in question decide to continue to dispute resolution process, there can be some sanctions imposed from the initial arbitration per terms of the contract.

Although properly drafted arbitration clauses are generally valid, they are subject to challenge in court for compliance with laws and public policy. Arbitration clauses may potentially be challenged as unconscionable and, therefore, unenforceable.

Typically, the validity of an arbitration clause is decided by a court rather than an arbitrator. However, if the validity of the entire arbitration agreement is in dispute, then the issue may remain subject to arbitration. For example, in "Rent-A-Center, West, Inc. v. Jackson", the Supreme Court of the United States held that "under the FAA, where an agreement to arbitrate includes an agreement that the arbitrator will determine the enforceability of the agreement, if a party challenges specifically the enforceability of that particular agreement, the district court considers the challenge, but if a party challenges the enforceability of the agreement as a whole, the challenge is for the arbitrator."

In other words, the law typically allows federal courts to decide these types of "gateway" or validity questions, but the Supreme Court ruled that since Jackson targeted the entire contract rather than a specific clause, the arbitrator decided the validity. Public Citizen, an advocacy organization opposed to the enforcement of pre-dispute arbitration agreements, characterized the decision negatively: "the court said that companies can write their contracts so that the companies' own arbitrator decides whether it's fair to submit a case to that arbitrator."

In insurance law, arbitration is complicated by the fact that insurance is regulated at the state level under the McCarran–Ferguson Act. From a federal perspective, however, a circuit court ruling has determined that McCarran-Ferguson requires a state statute rather than administrative interpretations. The Missouri Department of Insurance attempted to block a binding arbitration agreement under its state authority, but since this action was based only on a policy of the department and not on a state statute, the United States district court found that the Department of Insurance did not have the authority to invalidate the arbitration agreement.

In "AT&T Mobility v. Concepcion" (2011), the Supreme Court of the United States upheld an arbitration clause in a consumer standard form contract which waived the right to a lawsuit and class action. However, this clause was relatively generous in that the business paid all fees unless the action was determined to be frivolous and a small-claims court action remained available; these types of protections are recommended for the contract to remain enforceable and not unconscionable.

Various bodies of rules have been developed that can be used for arbitration proceedings. The rules to be followed by the arbitrator are specified by the agreement establishing the arbitration.

In some cases, a party may comply with an award voluntarily. However, in other cases a party will have to petition to receive a court judgment for enforcement through various means such as a writ of execution, garnishment, or lien. If the property is in another state, then a sister-state judgment (relying on the Full Faith and Credit Clause) can be received by filing a form in the state where the property is located.

Under the Federal Arbitration Act, courts can only vacate awards for limited reasons set out in statute with similar language in the state model Uniform Arbitration Act.

The court will generally not change the arbitrator's findings of fact but will decide only whether the arbitrator was guilty of malfeasance, or whether the arbitrator exceeded the limits of his or her authority in the arbitral award or whether the award was made in manifest disregard of law or conflicts with well-established public policy.

Arbitrators have wide latitude in crafting remedies in the arbitral decision, with the only real limitation being that they may not exceed the limits of their authority in their award. An example of exceeding arbitral authority might be awarding one party to a dispute the personal automobile of the other party when the dispute concerns the specific performance of a business-related contract.

It is open to the parties to restrict the possible awards that the arbitrator can make. If this restriction requires a straight choice between the position of one party or the position of the other, then it is known as "pendulum arbitration" or "final offer arbitration". It is designed to encourage the parties to moderate their initial positions so as to make it more likely they receive a favorable decision.

No definitive statement can be made concerning the credentials or experience levels of arbitrators, although some jurisdictions have elected to establish standards for arbitrators in certain fields. Some independent organizations, such as the American Arbitration Association offer arbitrator training programs, and arbitrators may cite their completion of that training as a credential. Generally speaking, however, the credibility of an arbitrator rests upon reputation, experience level in arbitrating particular issues, or expertise/experience in a particular field. Arbitrators are generally not required to be members of the legal profession.

To ensure effective arbitration and to increase the general credibility of the arbitral process, arbitrators will sometimes sit as a panel, usually consisting of three arbitrators. Often the three consist of an expert in the legal area within which the dispute falls (such as contract law in the case of a dispute over the terms and conditions of a contract), an expert in the industry within which the dispute falls (such as the construction industry, in the case of a dispute between a homeowner and his general contractor), and an experienced arbitrator.

The "judge shows" that have become popular in many countries, especially the United States, are actually binding arbitration. "The People's Court" and Judge Judy are notable examples.

For the relevant conflict of laws elements, see contract, forum selection clause, choice of law clause, proper law, and "lex loci arbitri"




</doc>
<doc id="2598" url="https://en.wikipedia.org/wiki?curid=2598" title="Adversarial system">
Adversarial system

The adversarial system or adversary system is a legal system used in the common law countries where two advocates represent their parties' case or position before an impartial person or group of people, usually a jury or judge, who attempt to determine the truth and pass judgment accordingly. It is in contrast to the inquisitorial system used in some civil law systems (i.e. those deriving from Roman law or the Napoleonic code) where a judge investigates the case.

The adversarial system is the two-sided structure under which criminal trial courts operate, putting the prosecution against the defense.

As an accused is not compelled to give evidence in a criminal adversarial proceeding, they may not be questioned by a prosecutor or judge unless they choose to do so. However, should they decide to testify, they are subject to cross-examination and could be found guilty of perjury. As the election to maintain an accused person's right to silence prevents any examination or cross-examination of that person's position, it follows that the decision of counsel as to what evidence will be called is a crucial tactic in any case in the adversarial system and hence it might be said that it is a lawyer's manipulation of the truth. Certainly, it requires the skills of counsel on both sides to be fairly equally pitted and subjected to an impartial judge.

By contrast, while defendants in most civil law systems can be compelled to give a statement, this statement is not subject to cross-examination by the prosecutor and not given under oath. This allows the defendant to explain his side of the case without being subject to cross-examination by a skilled opposition. However, this is mainly because it is not the prosecutor but the judges who question the defendant. The concept of "cross"-examination is entirely due to adversarial structure of the common law.

Judges in an adversarial system are impartial in ensuring the fair play of due process, or fundamental justice. Such judges decide, often when called upon by counsel rather than of their own motion, what evidence is to be admitted when there is a dispute; though in some common law jurisdictions judges play more of a role in deciding what evidence to admit into the record or reject. At worst, abusing judicial discretion would actually pave the way to a biased decision, rendering obsolete the judicial process in question—rule of law being illicitly subordinated by rule of man under such discriminating circumstances.

The rules of evidence are also developed based upon the system of objections of adversaries and on what basis it may tend to prejudice the trier of fact which may be the judge or the jury. In a way the rules of evidence can function to give a judge limited inquisitorial powers as the judge may exclude evidence he/she believes is not trustworthy or irrelevant to the legal issue at hand.

All evidence must be relevant and not hearsay evidence.

Peter Murphy in his "Practical Guide to Evidence" recounts an instructive example. A frustrated judge in an English (adversarial) court finally asked a barrister after witnesses had produced conflicting accounts, 'Am I never to hear the truth?' 'No, my lord, merely the evidence', replied counsel.

The name "adversarial system" may be misleading in that it implies it is only within this type of system in which there are opposing prosecution and defense. This is not the case, and both modern adversarial and inquisitorial systems have the powers of the state separated between a prosecutor and the judge and allow the defendant the right to counsel. Indeed, the European Convention on Human Rights and Fundamental Freedoms in Article 6 requires these features in the legal systems of its signatory states.

The right to counsel in criminal trials was initially not accepted in some adversarial systems. It was believed that the facts should speak for themselves, and that lawyers would just blur the matters. As a consequence, it was only in 1836 that England gave suspects of felonies the formal right to have legal counsel (the Prisoners' Counsel Act 1836), although in practice English courts routinely allowed defendants to be represented by counsel from the mid-18th century. During the second half of the 18th century advocates like Sir William Garrow and Thomas Erskine, 1st Baron Erskine helped usher in the adversarial court system used in most common law countries today. In the United States, however, personally retained counsel have had a right to appear in all federal criminal cases since the adoption of the Constitution and in state cases at least since the end of the Civil War, although nearly all provided this right in their state constitutions or laws much earlier. Appointment of counsel for indigent defendants was nearly universal in federal felony cases, though it varied considerably in state cases. It was not until 1963 that the U.S. Supreme Court declared that legal counsel must be provided at the expense of the state for indigent felony defendants, under the federal Sixth Amendment, in state courts. See "Gideon v. Wainwright", .

One of the most significant differences between the adversarial system and the inquisitorial system occurs when a criminal defendant admits to the crime. In an adversarial system, there is no more controversy and the case proceeds to sentencing; though in many jurisdictions the defendant must have allocution of her or his crime; an obviously false confession will not be accepted even in common law courts. By contrast, in an inquisitorial system, the fact that the defendant has confessed is merely one more fact that is entered into evidence, and a confession by the defendant does not remove the requirement that the prosecution present a full case. This allows for plea bargaining in adversarial systems in a way that is difficult or impossible in inquisitional system, and many felony cases in the United States are handled without trial through such plea bargains.

In some adversarial legislative systems, the court is permitted to make inferences on an accused's failure to face cross-examination or to answer a particular question. This obviously limits the usefulness of silence as a tactic by the defense. In England the Criminal Justice and Public Order Act 1994 allowed such inferences to be made for the first time in England and Wales (it was already possible in Scotland under the rule of criminative circumstances). This change was disparaged by critics as an end to the 'right to silence', though in fact an accused still has the right to remain silent and cannot be compelled to take the stand. The criticism reflects the idea that if the accused can be inferred to be guilty by exercising their right to silence, it no longer confers the protection intended by such a right. In the United States, the Fifth Amendment has been interpreted to prohibit a jury from drawing a negative inference based on the defendant's invocation of his right not to testify, and the jury must be so instructed if the defendant requests.

Lord Devlin in "The Judge" said: "It can also be argued that two prejudiced searchers starting from opposite ends of the field will between them be less likely to miss anything than the impartial searcher starting at the middle."

There are many differences in the way cases are reviewed. It is questionable that the results would be different if cases were conducted under the differing approaches; in fact no statistics exist that can show whether or not these systems would come to the same results. However, these approaches are often a matter of national pride and there are opinions amongst jurists about the merits of the differing approaches and their drawbacks as well.

Proponents of the adversarial system often argue that the system is more fair and less prone to abuse than the inquisitional approach, because it allows less room for the state to be biased against the defendant. It also allows most private litigants to settle their disputes in an amicable manner through discovery and pre-trial settlements in which non-contested facts are agreed upon and not dealt with during the trial process.

In addition, adversarial procedure defenders argue that the inquisitorial court systems are overly institutionalized and removed from the average citizen. The common law trial lawyer has ample opportunity to uncover the truth in the courtroom. Most cases that go to trial are carefully prepared through a discovery process that aids in the review of evidence and testimony before it is presented to judge or jury. The lawyers involved have a very good idea of the scope of agreement and disagreement of the issues to present at trial which develops much in the same way as the role of investigative judges.

Proponents of inquisitorial justice dispute these points. They point out that many cases in adversarial systems, and most cases in the United States, are actually resolved by plea bargain or settlement. Plea bargain as a system does not exist in an inquisitorial system. Many legal cases in adversarial systems, and most in the United States, do not go to trial, which may lead to injustice when the defendant has an unskilled or overworked attorney, which is likely to be the case when the defendant is poor. In addition, proponents of inquisitorial systems argue that the plea bargain system causes the participants in the system to act in perverse ways, in that it encourages prosecutors to bring charges far in excess of what is warranted and defendants to plead guilty even when they believe that they are not.



</doc>
<doc id="2602" url="https://en.wikipedia.org/wiki?curid=2602" title="Abano Terme">
Abano Terme

Abano Terme (known as "Abano Bagni" until 1924) is a town and "comune" in the province of Padua, in the Veneto region, Italy, on the eastern slope of the Colli Euganei; it is southwest by rail from Padua. Abano Terme's population is 19,062 (2001) (in 1901 it was only 4,556).

The town's hot springs and mud baths are an important economic resource. The waters have a temperature of about .

The baths were known to the Romans as "Aponi fons" or "Aquae Patavinae". A description of them is given in a letter to Theodoric, the king of the Ostrogoths, from Cassiodorus. Some remains of the ancient baths have been discovered (S. Mandruzzato, "Trattato dei Bagni d'Abano," Padua, 1789). An oracle of Geryon lay near, and the so-called "sortes Praenestinae" (C.I.L. i., Berlin, 1863; 1438–1454), small bronze cylinders inscribed, and used as oracles, were perhaps found here in the 16th century.

The baths were destroyed by the Lombards in the 6th century, but they were rebuilt and enlarged when Abano became an autonomous comune in the 12th century and, again, in the late 14th century. The city was under the Republic of Venice from 1405 to 1797.


Just outside the city is San Daniele Abbey (11th century). 6 km from the city is also Praglia Abbey, founded in the 11th century by Benedictine monks and rebuilt in 1496–1550. The abbey church of the Assumption, with a marble portal from 1548, has a Renaissance style interior. Noteworthy is the four cloister complex.





</doc>
<doc id="2604" url="https://en.wikipedia.org/wiki?curid=2604" title="Abated">
Abated

Abated, an ancient technical term applied in masonry and metal work to those portions which are sunk beneath the surface, as in inscriptions where the ground is sunk round the letters so as to leave the letters or ornament in relief.


</doc>
<doc id="2605" url="https://en.wikipedia.org/wiki?curid=2605" title="Abati">
Abati

Abati is a surname. It was used by an ancient noble family of Florence. 

Notable people with the surname include:




</doc>
<doc id="2606" url="https://en.wikipedia.org/wiki?curid=2606" title="Abatis">
Abatis

An abatis, abattis, or abbattis is a field fortification consisting of an obstacle formed (in the modern era) of the branches of trees laid in a row, with the sharpened tops directed outwards, towards the enemy. The trees are usually interlaced or tied with wire. Abatis are used alone or in combination with wire entanglements and other obstacles.

There is evidence it was used as early as the Roman Imperial period, and as recently as the American Civil War.

A classic use of an abatis was at the Battle of Carillon during the Seven Years' War. The 3,600 French troops defeated a massive army of 16,000 British and Colonial troops by fronting their defensive positions with an extremely dense abatis. The British found the defences almost impossible to breach and were forced to withdraw with some 2,600 casualties. Other uses of an abatis can be found at the Battle of the Chateauguay, 26 October 1813, when approximately 1,300 Canadian voltigeurs, under the command of Charles-Michel de Salaberry, defeated an American corps of approximately 4,000 men, or at the Battle of Plattsburgh.

An important weakness of abatis, in contrast to barbed wire, is that it can be destroyed by fire. Also, if laced together with rope instead of wire, the rope can be very quickly destroyed by such fires, after which the abatis can be quickly pulled apart by grappling hooks thrown from a safe distance.

An important advantage is that an improvised abatis can be quickly formed in forested areas. This can be done by simply cutting down a row of trees so that they fall with their tops toward the enemy. An alternative is to place explosives so as to blow the trees down.

Abatis are rarely seen nowadays, having been largely replaced by wire obstacles. However, it may be used as a replacement or supplement when barbed wire is in short supply. A form of giant abatis, using whole trees instead of branches, can be used as an improvised anti-tank obstacle.

Though rarely used by modern conventional military units, abatises are still officially maintained in United States Army and Marine Corps training. Current US training instructs engineers or other constructors of such obstacles to fell trees, leaving a stump, in such a manner as the trees fall interlocked pointing at a 45-degree angle towards the direction of approach of the enemy. Furthermore, it is recommended that the trees remain connected to the stumps and the length of roadway covered be at least . US military maps record an abatis by use of an inverted "V" with a short line extending from it to the right.




</doc>
<doc id="2607" url="https://en.wikipedia.org/wiki?curid=2607" title="Antoine Thomson d'Abbadie">
Antoine Thomson d'Abbadie

Antoine Thomson d'Abbadie d'Arrast (3 January 181019 March 1897) was an Irish-born French explorer, geographer, ethnologist, linguist and astronomer notable for his travels in Ethiopia during the first half of the 19th century. He was the older brother of Arnaud Michel d'Abbadie, with whom he travelled.

d'Arrast was born a British subject, in Dublin, Ireland, from a partially Basque noble family of the French province of Soule. His father, Michel Abbadie, was born in Arrast-Larrebieu and his mother was Irish. His grandfather Jean-Pierre was an abbot and a notary in Soule. The family moved to France in 1818 where the brothers received a careful scientific education. In 1827, Antoine received a bachelier (bachelor) degree in Toulouse. Starting in 1829, he began his education in Paris, where he studied law.

He married Virginie Vincent de Saint-Bonnet on 21 February 1859, and settled in Hendaye where he purchased 250ha to build a castle, and became the mayor of the city from 1871 to 1875.

Abbadie was a knight of the Legion of Honour, which he received on 27 September 1850, and a member of the French Academy of Sciences. He died in 1897, and bequeathed the Abbadi domain and castle in Hendaye, yielding 40,000 francs a year, to the Academy of Sciences.

In 1835 the French Academy sent Antoine on a scientific mission to Brazil, the results being published at a later date (1873) under the title of "Observations relatives à la physique du globe faites au Brésil et en Éthiopie". In 1837, the two brothers started for Ethiopia, landing at Massawa in February 1838. They journeyed throughout Ethiopia, travelling as far south as the Kingdom of Kaffa, sometimes together and sometimes separately. In addition to his studies in the sciences, he delved into the political fray exerting influence in favour of France and the Catholic missionaries. While in Ethiopia they returned to France in 1848 with notes on the geography, geology, archaeology, and natural history of the region.

Antoine became involved in various controversies relating both to his geographical results and his political intrigues. He was especially attacked by Charles Tilstone Beke, who impugned his veracity, especially with reference to the journey to Kana. But time and the investigations of subsequent explorers have shown that Abbadie was quite trustworthy as to his facts, though wrong in his contention—hotly contested by Beke—that the Blue Nile was the main stream. The topographical results of his explorations were published in Paris between 1860 and 1873 in "Géodésie d'Éthiopie", full of the most valuable information and illustrated by ten maps. Of the "Géographie de l'Éthiopie" (Paris, 1890) only one volume was published. In "Un Catalogue raisonné de manuscrits éthiopiens" (Paris, 1859) is a description of 234 Ethiopian manuscripts collected by Antoine. He also compiled various vocabularies, including a "Dictionnaire de la langue amariñña" (Paris, 1881), and prepared an edition of the "Shepherd of Hermas", with the Latin version, in 1860. He published numerous papers dealing with the geography of Ethiopia, Ethiopian coins and ancient inscriptions. Under the title of "Reconnaissances magnétiques" he published in 1890 an account of the magnetic observations made by him in the course of several journeys to the Red Sea and the Levant. The general account of the travels of the two brothers was published by Arnaud in 1868 under the title of "Douze ans dans la Haute Ethiopie".

Antoine was responsible for streamlining techniques towards geodesy, along with inventing a new theodolite for measuring angles.

Basque through his father, Abbadie developed a particular interest about the Basque Language after meeting the Prince Louis Lucien Bonaparte in London. He started his academic work on Basque in 1852.

A speaker of both Souletin and Lapurdian, a resident of Lapurdi, Abbadie considered himself a Basque from Soule. The popularity of the motto Zazpiak Bat is attributed to Abbadie, coined in the framework of the "Lore Jokoak" Basque festivals, fostered by himself.

Abbadie gave his castle home the name "Abbadia", which is the name still used in Basque. However, in French it is usually referred to as "Chateau d'Abbadie" or "Domaine d'Abbadia", and locally it is not unusual for it to be called "le Chateau d'Antoine d'Abbadie".

The château was built between 1864 and 1879 on a cliff by the Atlantic Ocean, and was designed by Viollet Le Duc in the Neo Gothic style, and is considered one of the most important examples of French Gothic Revival Architecture. It is divided in three parts : the observatory and library, the chapel, and the living quarters.

Nowadays the château still belongs to the Academy of Science to which it was bequeathed in 1895 on condition of its producing a catalogue of half-a-million stars within fifty years' time, with the work to be carried out by members of religious orders.

The château was classified as a protected historical monument by France in 1984. Most of the château property now belongs to the Coastal Protection Agency, and is managed by the city of Hendaye.

Antoine received the French Legion of Honor on 27 September 1850 with the order of chevalier or knight. He was a member of the Bureau des Longitudes and also the French Academy of Sciences. Both brothers received the grand medal of the Paris Geographical Society in 1850.



</doc>
<doc id="2608" url="https://en.wikipedia.org/wiki?curid=2608" title="Abba Mari">
Abba Mari

Abba Mari ben Moses ben Joseph, was a Provençal rabbi, born at Lunel, near Montpellier, towards the end of the 13th century. He is also known as Yarhi from his birthplace (Hebrew "Yerah", i.e. moon, lune), and he further took the name Astruc, Don Astruc or En Astruc of Lunel from the word "astruc" meaning lucky (see Astruc).

The descendant of men learned in rabbinic lore, Abba Mari devoted himself to the study of theology and philosophy, and made himself acquainted with the writings of Moses Maimonides and Nachmanides as well as with the "Talmud".

In Montpellier, where he lived from 1303 to 1306, he was much distressed by the prevalence of Aristotelian rationalism, which in his opinion, through the medium of the works of Maimonides, threatened the authority of the Old Testament, obedience to the law, and the belief in miracles and revelation. He therefore, in a series of letters (afterwards collected under the title "Minhat Kenaot", i.e., "Offering of Zealotry") called upon the famous rabbi Solomon ben Aderet of Barcelona to come to the aid of orthodoxy. Ben Adret, with the approval of other prominent Spanish rabbis, sent a letter to the community at Montpellier proposing to forbid the study of philosophy to those who were less than twenty-five years of age, and, in spite of keen opposition from the liberal section, a decree in this sense was issued by Ben Adret in 1305. The result was a great schism among the Jews of Spain and southern France, and a new impulse was given to the study of philosophy by the unauthorized interference of the Spanish rabbis.

On the expulsion of the Jews from France by Philip IV in 1306, Abba Mari settled at Perpignan, where he published the letters connected with the controversy. His subsequent history is unknown. Beside the letters, he was the author of liturgical poetry and works on civil law.

(Graetz and others have, incorrectly, En Duran): Leader of the opposition to the rationalism of the Maimonists in the Montpellier controversy of 1303-1306; born at Lunel—hence his name, Yarḥi (from Yeraḥ = Moon = Lune). He was a descendant of Meshullam ben Jacob of Lunel, one of whose five sons was Joseph, the grandfather of Abba Mari, who, like his son Moses, the father of Abba Mari, was highly respected for both his rabbinical learning and his general erudition. Abba Mari moved to Montpellier, where, to his chagrin, he found the study of rabbinical lore greatly neglected by the young, who devoted all of their time and zeal to science and philosophy. The rationalistic method pursued by the new school of Maimonists (including Levi ben Abraham ben Chayyim of Villefranche, near the town of Perpignan, and Jacob Anatolio) especially provoked his indignation; for the sermons preached and the works published by them seemed to resolve the entire Scriptures into allegory and threatened to undermine the Jewish faith and the observance of the Law and tradition. He was not without some philosophical training. He mentions even with reverence the name of Maimonides, whose work he possessed and studied; but he was more inclined toward the mysticism of Nachmanides. Above all, he was a thorough believer in revelation and in a divine providence, and was a sincere, law-observing follower of rabbinical Judaism. He would not allow Aristotle, "the searcher after God among the heathen," to be ranked with Moses.

Abba Mari possessed considerable Talmudic knowledge and some poetical talent; but his zeal for the Law made him an agitator and a persecutor of all the advocates of liberal thought. Being himself without sufficient authority, he appealed in a number of letters, afterward published under the title of "Minḥat Ḳenaot" ("Jealousy Offering"), to Solomon ben Adret of Barcelona, the most influential rabbi of the time, to use his powerful authority to check the source of evil by hurling his anathema against both the study of philosophy and the allegorical interpretations of the Bible, which did away with all belief in miracles. Ben Adret, while reluctant to interfere in the affairs of other congregations, was in perfect accord with Abba Mari as to the danger of the new rationalistic systems, and advised him to organize the conservative forces in defense of the Law. Abba Mari, through Ben Adret's aid, obtained allies eager to take up his cause, among whom were Don Bonafoux Vidal of Barcelona and his brother, Don Crescas Vidal, then in Perpignan. The proposition of the latter to prohibit, under penalty of excommunication, the study of philosophy and any of the sciences except medicine, by one under thirty years of age, met with the approval of Ben Adret. Accordingly, Ben Adret addressed to the congregation of Montpellier a letter, signed by fifteen other rabbis, proposing to issue a decree pronouncing the anathema against all those who should pursue the study of philosophy and science before due maturity in age and in rabbinical knowledge. On a Sabbath in September, 1304, the letter was to be read before the congregation, when Jacob Machir Don Profiat Tibbon, the renowned astronomical and mathematical writer, entered his protest against such unlawful interference by the Barcelona rabbis, and a schism ensued. Twenty-eight members signed Abba Mari's letter of approval; the others, under Tibbon's leadership, addressed another letter to Ben Adret, rebuking him and his colleagues for condemning a whole community without knowledge of the local conditions. Finally, the agitation for and against the liberal ideas brought about a schism in the entire Jewish population in southern France and Spain.

Encouraged, however, by letters signed by the rabbis of Argentière and Lunel, and particularly by the support of Kalonymus ben Todros, the "nasi" of Narbonne, and of the eminent Talmudist Asheri of Toledo, Ben Adret issued a decree, signed by thirty-three rabbis of Barcelona, excommunicating those who should, within the next fifty years, study physics or metaphysics before their thirtieth year of age (basing his action on the principle laid down by Maimonides, "Guide for the Perplexed" part one chapter 34), and had the order promulgated in the synagogue on Sabbath, July 26, 1305. When this heresy-decree, to be made effective, was forwarded to other congregations for approval, the friends of liberal thought, under the leadership of the Tibbonites, issued a counter-ban, and the conflict threatened to assume a serious character, as blind party zeal (this time on the liberal side) did not shrink from asking the civil powers to intervene. But an unlooked-for calamity brought the warfare to an end. The expulsion of the Jews from France by Philip IV ("the Fair"), in, caused the Jews of Montpellier to take refuge, partly in Provence, partly in Perpignan and partly in Majorca. Consequently, Abba Mari removed first to Arles, and, within the same year, to Perpignan, where he finally settled and disappeared from public view. There he published his correspondence with Ben Adret and his colleagues.

Abba Mari collected the correspondence and added to each letter a few explanatory notes. Of this collection, called "Minḥat Ḳenaot," there are several manuscript copies extant; namely, at Oxford (Neubauer, "Cat. Bodl. Hebr. MSS.," Nos. 2182 and 2221); Paris, Bibl. Nat. No. 976; Günzburg Libr., Saint Petersburg; Parma; Ramsgate Montefiore College Library (formerly Halberstam, No. 192); and Turin. Some of these (Oxford, No. 2221, and Paris, Bibl. Nat.) are mere fragments. The printed edition (Presburg, 1838), prepared by M. L. Bislichis, contains: (1) Preface; (2) a treatise of eighteen chapters on the incorporeality of God; (3) correspondence; (4) a treatise, called "Sefer ha-Yarḥi," included also in letter 58; (5) a defense of "The Guide" and its author by Shem-Tob Palquera (Grätz, "Gesch. d. Juden," vii. 173). As the three cardinal doctrines of Judaism, Abba Mari accentuates: (1) That of the recognition of God's existence and of His absolute sovereignty, eternity, unity, and incorporeality, as taught in revelation, especially in the "Decalogue"; (2) that of the world's creation by Him out of nothing, as evidenced particularly by the Sabbath; (3) that of the special providence of God, as manifested in the Biblical miracles. In the preface, Abba Mari explains his object in collecting the correspondence; and in the treatise which follows he shows that the study of philosophy, useful in itself as a help toward the acquisition of the knowledge of God, requires great caution, lest we be misled by the Aristotelian philosophy or its false interpretation, as regards the principles of creation "ex nihilo" and divine individual providence. The manuscripts include twelve letters which are not included in the printed edition of "Minḥat Ḳenaot."

The correspondence refers mainly to the proposed restriction of the study of the Aristotelian philosophy. Casually, other theological questions are discussed. For example, letters 1, 5, and 8 contain a discussion on the question, whether the use of a piece of metal with the figure of a lion, as a talisman, is permitted by Jewish law for medicinal purposes, or is prohibited as idolatrous. In letter 131, Abba Mari mourns the death of Ben Adret, and in letter 132 he sends words of sympathy to the congregation of Perpignan, on the death of Don Vidal Shlomo (the Meiri) and Rabbi Meshullam. Letter 33 contains the statement of Abba Mari that two letters which he desired to insert could not be discovered by him. MS. Ramsgate, No. 52, has the same statement, but also the two letters missing in the printed copies. In the "Sefer ha-Yarḥi", Abba Mari refers to the great caution shown by the rabbis of old as regards the teaching of the mysteries of philosophy, and recommended by men like the Hai Gaon, Maimonides, and David Kimhi. A response of Abba Mari on a ritual question is contained in MS. Ramsgate, No. 136; and Zunz ("Literaturgeschichte der Synagogalen Poesie," p. 498), mentions a "ḳinah" composed by Abba Mari.

The "Minḥat Ḳenaot" is instructive reading for the historian because it throws much light upon the deeper problems which agitated Judaism, the question of the relation of religion to the philosophy of the age, which neither the zeal of the fanatic nor the bold attitude of the liberal-minded could solve in any fixed dogmatic form or by any anathema, as the independent spirit of the congregations refused to accord to the rabbis the power possessed by the Church of dictating to the people what they should believe or respect. At the close of the work are added several eulogies written by Abba Mari on Ben Adret (who died in 1310), and on Don Vidal, Solomon of Perpignan, and Don Bonet Crescas of Lunel.


</doc>
<doc id="2609" url="https://en.wikipedia.org/wiki?curid=2609" title="Abbas II of Egypt">
Abbas II of Egypt

Abbas II Helmy Bey (also known as "‘Abbās Ḥilmī Pasha", ) (14 July 1874 – 19 December 1944) was the last Khedive (Ottoman viceroy) of Egypt and Sudan, ruling from 8 January 1892 to 19 December 1914. In 1914, after the Ottoman Empire joined the Central Powers in World War I, the nationalist Khedive was removed by the British, then ruling Egypt, in favor of his more pro-British uncle, Hussein Kamel, marking the "de jure" end of Egypt's four-century era as a province of the Ottoman Empire, which had begun in 1517.

Abbas II (full name: Abbas Hilmy), the great-great-grandson of Muhammad Ali, was born in Alexandria, Egypt on 14 July 1874. He succeeded his father, Tewfik Pasha, as Khedive of Egypt and Sudan on 8 January 1892. In 1887 he was ceremonially circumcised together with his younger brother Mohammed Ali Tewfik. The festivities lasted for three weeks and were carried out under great pomp. As a boy he visited the United Kingdom, and he had a number of British tutors in Cairo including a governess who taught him English. In a profile of Abbas II, the boys' annual, "Chums", gives a lengthy account of his education. His father established a small school near the Abdin Palace in Cairo where European, Arab and Turkish masters taught Abbas and his brother Mohammed Ali Tewfik. An American officer in the Egyptian army took charge of his military training. He attended school at Lausanne, Switzerland; then, at the age of twelve he was sent to the Haxius School in Geneva, in preparation for his entry into the Theresianum in Vienna. In addition to Turkish, he had good conversational knowledge of English, French and German.

He was still in college in Vienna when he assumed the throne of the Khedivate of Egypt upon the sudden death of his father, 8 January 1892. He was barely of age according to Egyptian law; normally, eighteen in cases of succession to the throne. For some time he did not cooperate very cordially with the British, whose army had occupied Egypt in 1882. As he was young and eager to exercise his new power, he resented the interference of the British Agent and Consul General in Cairo, Sir Evelyn Baring, later made Lord Cromer. At the outset of his reign, Khedive Abbas II surrounded himself with a coterie of European advisers who opposed the British occupation of Egypt and Sudan and encouraged the young khedive to challenge Cromer by replacing his ailing prime minister with an Egyptian nationalist. At Cromer's behest, Lord Rosebery, the British foreign secretary, sent Abbas II a letter stating that the Khedive was obliged to consult the British consul on such issues as cabinet appointments. In January 1894 Abbas II made an inspection tour of Sudanese and Egyptian frontier troops stationed near the southern border, the Mahdists being at the time still in control of the Sudan itself. At Wadi Halfa the Khedive made public remarks disparaging the Egyptian army units commanded by British officers. The British commander of the Egyptian army, Sir Herbert Kitchener, immediately threatened to resign. Kitchener further insisted on the dismissal of a nationalist under-secretary of war appointed by Abbas II and that an apology be made for the Khedive's criticism of the army and its officers.

By 1899 he had come to accept British counsels. Also in 1899 British diplomat Alfred Mitchell-Innes was appointed Under-Secretary of State for Finance in Egypt, and in 1900 Abbas II paid a second visit to Britain, during which he said he thought the British had done good work in Egypt, and declared himself ready to cooperate with the British officials administering Egypt and Sudan. He gave his formal approval for the establishment of a sound system of justice for Egyptian nationals, a great reduction in taxation, increased affordable and sound education, the inauguration of the substantial irrigation works such as the Aswan Low Dam and the Assiut Barrage, and the reconquest of Sudan. He displayed more interest in agriculture than in statecraft. His farm of cattle and horses at Qubbah, near Cairo, was a model for agricultural science in Egypt, and he created a similar establishment at Muntazah, just east of downtown Alexandria. He married the Princess Ikbal Hanem and had several children. Muhammad Abdul Mun'im, the heir-apparent, was born on 20 February 1899. 

Although Abbas II no longer "publicly" opposed the British, he secretly created, supported, and sustained the Egyptian nationalist movement, which came to be led by Mustafa Kamil. He also funded the anti-British newspaper Al-Mu'ayyad. As Kamil's thrust was increasingly aimed at winning popular support for a National Party, Khedive Abbas publicly distanced himself from the Nationalists. Their demand for a constitutional government in 1906 was rebuffed by Abbas II, and the following year he formed the National Party, led by Mustafa Kamil Pasha, to counter the Ummah Party of the Egyptian moderates. However, in general, he had no real political power. When the Egyptian Army was sent to fight Abd al-Rahman al-Mahdi in Sudan in 1896, he only found out about it because the Austro-Hungarian Archduke Francis Ferdinand was in Egypt and told him after being informed of it by a British Army officer.

His relations with Cromer's successor, Sir Eldon Gorst, however, were excellent, and they co-operated in appointing the cabinets headed by Butrus Ghali in 1908 and Muhammad Sa'id in 1910 and in checking the power of the Nationalist Party. The appointment of Kitchener to succeed Gorst in 1912 displeased Abbas II, and relations between the Khedive and the British deteriorated. Kitchener, who exiled or imprisoned the leaders of the National party, often complained about "that wicked little Khedive" and wanted to depose him.

On 25 July 1914, at the onset of World War I, Abbas II was in Constantinople and was wounded in his hands and cheeks during a failed assassination attempt. On 5 November 1914 when Great Britain declared war on Turkey, he was accused of deserting Egypt by not returning home forthwith. The British also believed that he was plotting against their rule, as he had attempted to appeal to Egyptians and Sudanese to support the Central Powers against the British, so when the Ottoman Empire joined the Central Powers in World War I, the United Kingdom declared Egypt a Sultanate under British protection on 18 December 1914 and deposed Abbas II. During the war, Abbas II supported the Ottomans, including leading an attack on the Suez Canal. He was replaced by the British by his uncle Hussein Kamel from 1914 to 1917, with the title of sultan. Hussein Kamel issued a series of restrictive orders to strip Abbas II of property in Egypt and Sudan and forbade contributions to him. These also barred Abbas from entering Egyptian territory and stripped him of the right to sue in Egyptian courts. This did not prevent his progeny, however, from exercising their rights. Abbas II finally accepted the new order on 12 May 1931 and formally abdicated. He retired to Switzerland, where he wrote "The Anglo-Egyptian Settlement" (1930). He died at Geneva on 19 December 1944, aged 70, 30 years to the day after the end of his reign as khedive.

His first marriage in Cairo on 19 February 1895 was to Ikbal Hanem (Crimean Peninsula, Russian Empire, 22 October 1876Jerusalem, 10 February 1941), and they had six children - two sons and four daughters: 

His second marriage in Çubuklu, Turkey on 1 March 1910 was to Hungarian noblewoman Marianna Török de Szendrö, who took the name Zübeyde Cavidan Hanım (Philadelphia, Pennsylvania, U.S., 8 January 1874after 1951). They divorced in 1913 without issue.





</doc>
<doc id="2610" url="https://en.wikipedia.org/wiki?curid=2610" title="Abbas Mirza">
Abbas Mirza

Abbas Mirza (; August 20, 1789October 25, 1833) was a Qajar crown prince of Persia. He developed a reputation as a military commander during the Russo-Persian War of 1804-1813 and the Russo-Persian War of 1826-1828 with neighbouring Imperial Russia, as well as through the Ottoman-Persian War of 1821-1823 with the Ottoman Empire. He is furthermore noted as an early modernizer of Persia's armed forces and institutions, and for his death before his father, Fath Ali Shah. Abbas was an intelligent prince, possessed some literary taste, and is noteworthy on account of the comparative simplicity of his life.

Nevertheless, with Abbas Mirza as the military commander of the Persian forces, Iran lost all of its territories in the Caucasus comprising Transcaucasia and parts of the North Caucasus (Dagestan) to Russia in conformity with the 1813 Treaty of Gulistan and the 1828 Treaty of Turkmenchay, following the outcomes of the 1804–1813 and 1826–1828 wars.

Abbas Mirza was born on August 20, 1789 in Nava, Mazandaran. He was a younger son of Fath Ali Shah, but on account of his mother's royal birth was destined by his father to succeed him. Considered the favorite son by his father, he was named governor ("beglarbeg") of the Azerbaijan region of Persia, in approximately 1798, when he was 10 years old. In 1801, three years after Agha Mohammad Khan's death, the Russians capitalized on the moment, and annexed Kartli-Kakheti. As (Eastern) Georgia had been under intermittent Iranian suzerainty since the early 16th century, this act by the Russians was seen as intrusion into Iranian territory. In 1804, eager to take the rest of Iran's territories, the Russian army led by general Pavel Tsitsianov, besieged, captured and sacked the city of Ganja, thereby initiating the Russo-Persian War (1804–13). Fath-Ali Shah appointed Abbas Mirza as commander of the expeditionary force of 30,000 men. His aid was eagerly solicited by both England and Napoleon, anxious to checkmate one another in the East, especially as Persia bordered a common rival, namely Imperial Russia. Preferring the friendship of France, Abbas Mirza continued the war against Russia's young General Kotlyarevsky, aged only twenty-nine but his new ally could give him very little assistance.

The early stages of the war following Fath Ali Shah's orders to invade and regain Georgia and the northern parts of the contemporary Azerbaijani Republic ended up in years of relatively territorial stale warfare. However, as Prof. Alexander Mikaberidze adds, Abbas Mirza led the army in an overall disastrous campaign against the Russians, suffering defeats at Gyumri, Kalagiri, the Zagam River (1805), Karakapet (1806), Karababa (1808), Ganja (1809), Meghri, the Aras River, and Akhalkalaki (1810). The tide started to decisively turn as Russia was sending more and more advanced weaponry and increasing numbers of soldiers. Commanding the southernmost Russian divisions during the long war, Kotlyarevsky defeated the numerically superior Persian army in the Battle of Aslanduz (1812) and in early 1813 stormed and took Lankaran. The Russians were encamped on the opposite bank of River Aras when his two British advisers Capt Christie and Lt Pottinger told him to post sentry pickets in short order, but Mirza ignored the warnings. Christie and other British officers tried to rally an army retreating in panic; for days the Russians launched fierce assaults, but at last Christie fell, and Mirza ordered a full retreat. Complacency cost 10,000 Persian lives; Mirza believing wrongly in the weight of superior numbers. In spite of the absence of leadership, The Persians at Lenkoran held out for weeks, until breaking through the Russians slaughtered the garrison of 4,000 officers and men.

In October 1813, with Abbas Mirza still commander-in-chief, Persia was compelled to make a severely disadvantageous peace known as the Treaty of Gulistan, irrevocably ceding swaths of its territory in the Caucasus, comprising present-day Georgia, Dagestan, and most of what most recently became the Republic of Azerbaijan. The only promise the Shah received in return was a lukewarm guarantee the Mirza would succeed to his throne, without let or hindrance. Persia's dire losses attracted the attention of the British Empire; following the reversal of initial successes, the Russians now posed a serious threat from the Caucasus.

The drastic losses suffered by his forces made him realize that he needed to train Persia's military in the European style of war, and he started sending his students to Europe for military training. By introducing European-style regiments, Abbas Mirza believed it would enable Iran to gain the upper hand over Russia and to reclaim its lost territories. Influenced by Sultan Selim III's reforms, Abbas Mirza set out to create an Iranian version of the Ottoman "Nizam-ı Cedid", and reduce the Qajar dependence on tribal and provincial forces. In 1811 and 1815, two groups were sent to Britain, and in 1812 a printing press was finished in Tabriz as a means to reproduce European military handbooks. Tabriz also saw a gunpowder factory and a munitions depot. The training continued with constant drilling by British advisers, with a focus on the infantry and artillery.
He received his opportunity to test his newly reformed military when the Ottoman–Persian War (1821–1823) began, and they proved themselves adept with several victories. This resulted in a peace treaty signed in 1823 after the Battle of Erzurum. The war was a victory for Persia, especially considering they were outnumbered, and this gave much needed confidence to his forces. His second war with Russia, which began in 1826, started off on a good note as he won back most of the territory lost in the Russo-Persian War (1804–13); however it ended in a string of costly defeats after which Persia was forced to cede the last of its Caucasian territories, comprising all of what is modern day Armenia, Nakhchivan, the rest of the remainder of the contemporary Azerbaijani Republic that was still in Iranian hands, and Igdir Province, all conform the 1828 Treaty of Turkmenchay. The eventual loss was due less to his and his armies skill and more to do with lack of reinforcements and overwhelming superiority in numbers. The irrevocable losses, which in total amounted up for all of Qajar Iran's territories in the North Caucasus and the South Caucasus, affected Abbas Mirza severely and his health began to suffer. He also lost enthusiasm for any more military reform. In 1833, he sought to restore order in the province of Khorasan, which was nominally under Persian supremacy, and while engaged in the task died at Mashhad in 1833. In 1834 his eldest son, Mohammed Mirza, succeeded Fath Ali Shah as the next king. R. G. Watson (History of Persia, 128-9) describes him as “the noblest of the Qajar race”.

He is most remembered for his valor in battle and his failed attempts to modernize the Persian army. He was not successful in part due to the lack of government centralization in Iran during the era. Furthermore, it was Abbas Mirza who first dispatched Iranian students to Europe for a western education. He was unable to prove successful in the long run in his wars with Russia as he ended up losing more territory than he gained.





</doc>
<doc id="2613" url="https://en.wikipedia.org/wiki?curid=2613" title="George Abbot (bishop)">
George Abbot (bishop)

George Abbot (29 October 15624 August 1633) was an English divine who was Archbishop of Canterbury from 1611 to 1633. He also served as the fourth Chancellor of Trinity College, Dublin, from 1612 to 1633.

The Chambers Biographical Dictionary describes him as "[a] sincere but narrow-minded Calvinist". Among his five brothers, Robert became Bishop of Salisbury and Maurice became Lord Mayor of London. He was a translator of the King James Version.

Born at Guildford in Surrey, where his father Maurice Abbot (died 1606) was a cloth-worker, he was taught at the Royal Grammar School, Guildford. According to an eighteenth century biographical dictionary, when Abbot's mother was pregnant with him she had a dream in which she was told that if she ate a pike her child would be a son and rise to great prominence. Some time afterwards she accidentally caught a pike while fetching water from the River Wey and it "being reported to some gentlemen in the neighbourhood, they offered to stand sponsors for the child, and afterwards shewed him many marks of favour." He later studied, and then taught, at Balliol College, Oxford, was chosen Master of University College in 1597, and appointed Dean of Winchester in 1600. He was three times Vice-Chancellor of the University, and took a leading part in preparing the authorised version of the New Testament. In 1608, he went to Scotland with George Home, 1st Earl of Dunbar to arrange for a union between the churches of England and Scotland. He so pleased King James in this affair that he was made Bishop of Lichfield and Coventry in 1609 and was translated to the see of London a month afterwards.

On 4 March 1611, Abbot was raised to the position of Canterbury. As archbishop, he defended the apostolic succession of the Anglican archbishops and bishops and the validity of the Church's priesthood in 1614. In consequence of the Nag's Head Fable, the archbishop invited certain Roman Catholics to inspect the register in the presence of six of his own episcopal colleagues, the details of which inspection were preserved. It was agreed by all parties that:
"The register agrees in every particular with what we know of the history of the times, and there exists not the semblance of a reason for pronouncing it a forgery."

In spite of his defence of the catholic nature of the priesthood, his Puritan instincts frequently led him not only into harsh treatment of Roman Catholics, but also into courageous resistance to the royal will, such as when he opposed the scandalous divorce suit of the Lady Frances Howard against the Earl of Essex, and again in 1618 when, at Croydon, he forbade the reading of the Declaration of Sports listing the permitted Sunday recreations.
He was naturally, therefore, a promoter of the match between the king's daughter, Princess Elizabeth, and Frederick V, Elector Palatine, and a firm opponent of the projected marriage of the new Prince of Wales (later Charles I) and the Spanish Infanta, Maria Anna. This policy brought upon the archbishop the hatred of William Laud (with whom he had previously come into collision at Oxford) and the king's court, although the King himself never forsook Abbot.

In July 1621, while hunting in Lord Zouch's park at Bramshill in Hampshire, a bolt from his cross-bow aimed at a deer happened to strike one of the keepers, who died within an hour, and Abbot was so greatly distressed by the event that he fell into a state of settled melancholia.
His enemies maintained that the fatal issue of this accident disqualified him for his office, and argued that, though the homicide was involuntary, the sport of hunting which had led to it was one in which no clerical person could lawfully indulge.
The King had to refer the matter to a commission of ten, though he said that "an angel might have miscarried after this sort."
The commission was equally divided, and the King gave a casting vote in the Archbishop's favour, though signing also a formal pardon or dispensation. Gustavus Paine notes that Abbot was both the "only translator of the 1611 Bible and the only Archbishop of Canterbury ever to kill a human being."

After this the Archbishop seldom appeared at the Council, chiefly on account of his infirmities. In 1625 he attended the King constantly, however, in his last illness, and performed the ceremony of the coronation of King Charles I as king of England. His refusal to license the assize sermon preached by Dr Robert Sibthorp at Northampton on 22 February 1627, in which cheerful obedience was urged to the king's demand for a general loan, and the duty proclaimed of absolute non-resistance even to the most arbitrary royal commands, led Charles to deprive him of his functions as primate, putting them in commission. The need of summoning parliament, however, soon brought about a nominal restoration of the Archbishop's powers. His presence being unwelcome at court, he lived from that time in retirement, leaving Laud and his party in undisputed ascendancy.
He died at Croydon on 5 August 1633, and was buried at Guildford, his native place, where he had endowed a hospital with lands to the value of £300 a year.

Abbot was a conscientious prelate, though narrow in view and often harsh towards both separatists and Roman Catholics. He wrote a large number of works, the most interesting being his discursive "Exposition on the Prophet Jonah" (1600), which was reprinted in 1845. His "Geography, or a Brief Description of the Whole World" (1599), passed through numerous editions. The newest edition, edited by the current Master of the Abbot's Hospital, was published by Goldenford Publishers Ltd on 20 June 2011, to commemorate the 400th anniversary of his enthronement as Archbishop of Canterbury.

Guildford remembers the Archbishop with his hospital, a statue in the High Street, a pub and also a secondary school (George Abbot School) named after him. His tomb can be seen in Holy Trinity Church.

The best account of Abbot is in Samuel Rawson Gardiner's "History of England".




</doc>
<doc id="2616" url="https://en.wikipedia.org/wiki?curid=2616" title="Adware">
Adware

Adware, or advertising-supported software, is software that generates revenue for its developer by automatically generating online advertisements in the user interface of the software or on a screen presented to the user during the installation process. The software may generate two types of revenue: one is for the display of the advertisement and another on a "pay-per-click" basis, if the user clicks on the advertisement. The software may implement advertisements in a variety of ways, including a static box display, a banner display, full screen, a video, pop-up ad or in some other form.

The 2003 "Microsoft Encyclopedia of Security" and some other sources use the term "adware" differently: "any software that installs itself on your system without your knowledge and displays advertisements when the user browses the Internet", i.e., a form of malware.

Some software developers offer their software free of charge, and rely on revenue from advertising to recoup their expenses and generate income. Some also offer a version of the software at a fee without advertising.

The software's functions may be designed to analyze the user's location and which Internet sites the user visits and to present advertising pertinent to the types of goods or services featured there.

In legitimate software, the advertising functions are integrated into or bundled with the program. Adware is usually seen by the developer as a way to recover development costs, and to generate revenue. In some cases, the developer may provide the software to the user free of charge or at a reduced price. The income derived from presenting advertisements to the user may allow or motivate the developer to continue to develop, maintain and upgrade the software product. The use of advertising-supported software in business is becoming increasingly popular, with a third of IT and business executives in a 2007 survey by McKinsey & Company planning to be using ad-funded software within the following two years. Advertisement-funded software is also one of the business models for open-source software.

Some software is offered in both an advertising-supported mode and a paid, advertisement-free mode. The latter is usually available by an online purchase of a license or registration code for the software that unlocks the mode, or the purchase and download of a separate version of the software.

Some software authors offer advertising-supported versions of their software as an alternative option to business organizations seeking to avoid paying large sums for software licenses, funding the development of the software with higher fees for advertisers.

Examples of advertising-supported software include Adblock Plus ("Acceptable Ads"), the Windows version of the Internet telephony application Skype, and the Amazon Kindle 3 family of e-book readers, which has versions called "Kindle with Special Offers" that display advertisements on the home page and in sleep mode in exchange for substantially lower pricing.

In 2012, Microsoft and its advertising division, Microsoft Advertising, announced that Windows 8, the major release of the Microsoft Windows operating system, would provide built-in methods for software authors to use advertising support as a business model. The idea had been considered since as early as 2005.

Support by advertising is a popular business model of software as a service (SaaS) on the Web. Notable examples include the email service Gmail and other Google Apps (now G Suite) products, and the social network Facebook. Microsoft has also adopted the advertising-supported model for many of its social software SaaS offerings. The Microsoft Office Live service was also available in an advertising-supported mode.

In the view of Federal Trade Commission staff, there appears to be general agreement that software should be considered "spyware" only if it is downloaded or installed on a computer without the user's knowledge and consent. However, unresolved issues remain concerning how, what, and when consumers need to be told about software installed on their computers for consent to be adequate. For instance, distributors often disclose in an end-user license agreement that there is additional software bundled with primary software, but some panelists and commenters did not view such disclosure as sufficient to infer consent to the installation of the bundled software.

The term "adware" is frequently used to describe a form of malware (malicious software) which presents unwanted advertisements to the user of a computer. The advertisements produced by adware are sometimes in the form of a pop-up or sometimes in an "unclosable window".

When the term is used in this way, the severity of its implication varies. While some sources rate adware only as an "irritant", others classify it as an "online threat" or even rate it as seriously as computer viruses and trojans. The precise definition of the term in this context also varies. Adware that observes the computer user's activities without their consent and reports it to the software's author is called spyware. However most adware operates legally and some adware manufacturers have even sued antivirus companies for blocking adware.

Programs have been developed to detect, quarantine, and remove advertisement-displaying malware, including Ad-Aware, Malwarebytes' Anti-Malware, Spyware Doctor and Spybot – Search & Destroy. In addition, almost all commercial antivirus software currently detect adware and spyware, or offer a separate detection module.

A new wrinkle is adware (using stolen certificates) that disables anti-malware and virus protection; technical remedies are available.

Adware has also been discovered in certain low-cost Android devices, particularly those made by small Chinese firms running on Allwinner systems-on-chip. There are even cases where adware code is embedded deep into files stored on the system and boot partitions, to which removal involves extensive (and complex) modifications to the firmware.



</doc>
<doc id="2618" url="https://en.wikipedia.org/wiki?curid=2618" title="Aeacus">
Aeacus

Aeacus (; also spelled Eacus; Ancient Greek: Αἰακός "Aiakos" or "Aiacos") was a mythological king of the island of Aegina in the Saronic Gulf.

Aeacus was the son of Zeus by Aegina, a daughter of the river-god Asopus, and thus, brother of Damocrateia. In some accounts, his mother was Europa and thus possible brother to Minos, Rhadamanthus and Sarpedon. He was the father of Peleus, Telamon and Phocus and was the grandfather of the Trojan war warriors Achilles and Telemonian Ajax. In some accounts, Aeacus had a daughter called Alcimache who bore Medon to Oileus of Locris.

Aeacus was born on the island of Oenone or Oenopia, where Aegina had been carried by Zeus to secure her from the anger of her parents; afterward, this island became known as Aegina. Some traditions related that, at the time when Aeacus was born, Aegina was not yet inhabited, and that Zeus either changed the ants () of the island into the men (Myrmidons) over whom Aeacus ruled, or he made the men grow up out of the earth. Ovid, on the other hand, supposed that the island was not uninhabited at the time of the birth of Aeacus, instead stating that during the reign of Aeacus, Hera, jealous of Aegina, ravaged the island bearing the name of the latter by sending a plague or a fearful dragon into it, by which nearly all its inhabitants were carried off. Afterward, Zeus restored the population by changing the ants into men.These legends seem to be a mythical account of the colonization of Aegina, which seems to have been originally inhabited by Pelasgians, and afterwards received colonists from Phthiotis, the seat of the Myrmidons, and from Phlius on the Asopus. While he reigned in Aegina, Aeacus was renowned in all Greece for his justice and piety, and was frequently called upon to settle disputes not only among men, but even among the gods themselves. He was such a favourite with the latter, that when Greece was visited by a drought as a consequence of a murder that had been committed, the oracle of Delphi declared that the calamity would not cease unless Aeacus prayed to the gods to end it. Aeacus prayed, and as a result, the drought ceased. Aeacus then demonstrated his gratitude by erecting a temple to "Zeus Panhellenius" on Mount Panhellenion, and afterward, the Aeginetans built a sanctuary on their island called Aeaceum, which was a square temple enclosed by walls of white marble. Aeacus was believed in later times to be buried under the altar of this sacred enclosure.

A legend preserved in Pindar relates that Apollo and Poseidon took Aeacus as their assistant in building the walls of Troy. When the work was completed, three dragons rushed against the wall, and though the two that attacked the sections of the wall built by the gods fell down dead, the third forced its way into the city through the portion of the wall built by Aeacus. Thereafter, Apollo prophesied that Troy would fall at the hands of Aeacus's descendants, the Aeacidae (i.e. his son Telamon joined Heracles when he sieged the city during Laomedon's rule. Later, his great grandson Neoptolemus was present in the wooden horse).

Aeacus was also believed by the Aeginetans to have surrounded their island with high cliffs in order to protect it against pirates. Several other incidents connected to the story of Aeacus are mentioned by Ovid. By Endeïs Aeacus had two sons, Telamon (father of Ajax and Teucer) and Peleus (father of Achilles), and by Psamathe a son, Phocus, whom he preferred to the former two sons, both of whom conspired to kill Phocus during a contest, and then subsequently fled from their native island.

After his death, Aeacus became one of the three judges in Hades (along with the Cretan brothers Rhadamanthus and Minos) and, according to Plato, was specifically concerned with the shades of Europeans upon their arrival to the underworld. In works of art he was depicted bearing a sceptre and the keys of Hades. Aeacus had sanctuaries in both Athens and in Aegina, and the Aeginetans regarded him as the tutelary deity of their island by celebrating the Aeacea in his honor.

In "The Frogs" (405 BC) by Aristophanes, Dionysus descends to Hades and proclaims himself to be Heracles. Aeacus, lamenting the fact that Heracles had stolen Cerberus, sentences Dionysus to Acheron to be tormented by the hounds of Cocytus, the Echidna, the Tartesian eel, and Tithrasian Gorgons.

Alexander the Great traced his ancestry through his mother to Aeacus.


</doc>
<doc id="2619" url="https://en.wikipedia.org/wiki?curid=2619" title="Aeclanum">
Aeclanum

Aeclanum (also spelled Aeculanum, , ) was an ancient town of Samnium, southern Italy, about 25 km east-southeast of Beneventum, on the Via Appia. It lies in Passo di Mirabella, near the modern Mirabella Eclano.

Aeclanum was on a promontory naturally defended, to some extent, by a steep slope on the south side down to the river Calore, while the north side lay open towards the crest of the ridge that carried what under the Roman Empire became the Via Appia. This led through Lacus Ampsanctus to Aquilonia and Venusia. Another route to Apulia, the Via Aurelia Aeclanensis diverged here, leading through modern Ariano to Herdoniae. The road from Aeclanum to Abellinum (mod. Avellino) may also follow an ancient line. Today there are ruins of the city walls, of an aqueduct, baths and an amphitheatre; nearly 400 inscriptions have also been discovered. Excavation has revealed a long history of pre-Roman settlement.

Aeclanum became the chief town of the Hirpini, after Beneventum had become a Roman colony. Sulla captured it in 89 BC by setting on fire the wooden breastwork by which it was defended, and sacked it. It quickly recovered, new fortifications were erected, and it became a "municipium". Hadrian, who repaired the Via Appia from Beneventum to this point, made it a "colonia". With the Lombard invasion of Italy it was annexed to the Duchy of Benevento, but was captured and destroyed by Byzantine Empire under Constans II in 663 and never recovered, being reduced to a small hamlet known as Quintodecimo, a name that referred to its distance of 15 miles from Benevento.

Aeclanum became a Christian episcopal see, whose best known bishop was Julian of Eclanum, who was consecrated by Pope Innocent I in about 417. He refused to sign the condemnation of Pelagianism issued by Pope Innocent's successor, Pope Zosimus, and carried on a war of writings against Augustine of Hippo. It has been thought that the diocese was united to that of Frequentium as early as the 5th century, but there is mention of Quintodecimo as a suffragan see of Benevento in 969 and 1058. From 1059 it was definitively united with Frequentium. No longer a residential bishopric, Aeclanum is today listed by the Catholic Church as a titular see.



</doc>
<doc id="2620" url="https://en.wikipedia.org/wiki?curid=2620" title="Aedesius">
Aedesius

Aedesius (, died 355 AD) was a Neoplatonist philosopher and mystic born of a noble Cappadocian family.

Aedesius was born into a wealthy Cappadocian family, but he moved to Syria, where he was apprenticed to Iamblichos. He quickly became his best pupil and the two became friends. Aedesius's own philosophical doctrine, however, was somewhere between Platonism and eclecticism and, according to Eunapius, he differed from Iamblichus on certain points connected with theurgy and magic.

After the death of his master, the school of Syria was dispersed and Aedesius seems to have modified his doctrines out of fear of Constantine II, and took refuge in divination. An oracle in hexameter verse represented a pastoral life as his only retreat, but his disciples, perhaps calming his fears by a metaphorical interpretation, compelled him to resume his instructions.

Aedesius founded a school of philosophy at Pergamon, which emphasized theurgy and the revival of polytheism, and where he numbered among his pupils Eusebius of Myndus, Maximus of Ephesus, and the Roman emperor Julian. After the accession of the latter to the imperial purple he invited Aedesius to continue his instructions, but the declining strength of the sage being unequal to the task, two of his most learned disciples, Chrysanthius and the aforementioned Eusebius, were by his own desire appointed to supply his place.

None of his writings have survived, but there is an extant biography by Eunapius, a Greek sophist and historian of the 4th century who wrote a collection of biographies titled "Lives of the Sophists".


</doc>
<doc id="2621" url="https://en.wikipedia.org/wiki?curid=2621" title="Aedicula">
Aedicula

In ancient Roman religion, an aedicula (plural aediculae) is a small shrine. The word "aedicula" is the diminutive of the Latin "aedes", a temple building.

Many aediculae were household shrines that held small altars or statues of the Lares and Penates. The Lares were Roman deities protecting the house and the family household gods. The Penates were originally patron gods (really genii) of the storeroom, later becoming household gods guarding the entire house.

Other aediculae were small shrines within larger temples, usually set on a base, surmounted by a pediment and surrounded by columns. In Roman architecture the aedicula has this representative function in the society. They are installed in public buildings like the Triumphal arch, City gate, or Thermes. The Celsus Library in Ephesus (2. c. AD) is a good example. From the 4th century Christianization of the Roman Empire onwards such shrines, or the framework enclosing them, are often called by the Biblical term tabernacle, which becomes extended to any elaborated framework for a niche, window or picture.

As in Classical architecture, in Gothic architecture, too, an aedicule or tabernacle frame is a structural framing device that gives importance to its contents, whether an inscribed plaque, a cult object, a bust or the like, by assuming the tectonic vocabulary of a little building that sets it apart from the wall against which it is placed. A tabernacle frame on a wall serves similar hieratic functions as a free-standing, three-dimensional architectural baldaquin or a ciborium over an altar.

In Late Gothic settings, altarpieces and devotional images were customarily crowned with gables and canopies supported by clustered-column piers, echoing in small the architecture of Gothic churches. Painted ædicules frame figures from sacred history in initial letters of illuminated manuscripts.

Classicizing architectonic structure and decor "all'antica", in the "ancient [Roman] mode", became a fashionable way to frame a painted or bas-relief portrait, or protect an expensive and precious mirror during the High Renaissance; Italian precedents were imitated in France, then in Spain, England and Germany during the later 16th century.

Aedicular door surrounds that are architecturally treated, with pilasters or columns flanking the doorway and an entablature even with a pediment over it came into use with the 16th century. In the neo-Palladian revival in Britain, architectonic aedicular or tabernacle frames, carved and gilded, are favourite schemes for English Palladian mirror frames of the late 1720s through the 1740s, by such designers as William Kent.

Similar small shrines, called "naiskoi", are found in Greek religion, but their use was strictly religious.

Aediculae exist today in Roman cemeteries as a part of funeral architecture.

Presently the most famous aedicule is situated inside the Church of the Holy Sepulchre in city of Jerusalem.

Contemporary American architect Charles Moore uses the concept of aediculae in his work to create spaces within spaces and to evoke the spiritual significance of the home.





</doc>
<doc id="2622" url="https://en.wikipedia.org/wiki?curid=2622" title="Aedui">
Aedui

The Aedui, Haedui, or Hedui () were a Gallic people of Gallia Lugdunensis, who inhabited the country between the Arar (Saône) and Liger (Loire), in today's France. Their territory thus included the greater part of the modern departments of Saône-et-Loire, Côte-d'Or and Nièvre.

The country of the Aedui is defined by reports of them in ancient writings. The upper Loire formed their western border, separating them from the Bituriges. The Saône formed their eastern border, separating them from the Sequani. The Sequani did not reside in the region of the confluence of the Doubs into the Saône and of the latter into the Rhône, as Caesar says that the Helvetii, following the pass between the Jura Mountains and the Rhône southwards, which belonged to the Sequani, plundered the territory of the Aedui. These circumstances explain an apparent contradiction in Strabo, who in one sentence says that the Aedui lived between the Saône and the Doubs, and in the next, that the Sequani lived across the Saône (eastward). Both statements are true, the first in the south, and the second to the north.

Outside of the Roman province and prior to Roman rule, Independent Gaul was occupied by self-governing tribes divided into cantons, and each canton was further divided into communes. The Aedui, like other powerful tribes in the region (the Arverni, the Sequani, and the Helvetii), had replaced their monarchy with a council of magistrates called grand-judges. The grand-judges were under the authority of the senate. The senate was made up of the descendants of ancient royal families. Free men in the tribes were vassals to the heads of these families in exchange for military, financial and political interests.

According to Livy (v. 34), they took part in the expedition of Bellovesus into Italy in the 6th century BC.

Before Julius Caesar's time, they had attached themselves to the Romans and were honoured with the title of brothers and kinsmen of the Roman people.

When the Sequani, their hereditary rivals, with the assistance of a Germanic chieftain named Ariovistus, defeated and massacred the Aedui at the Battle of Magetobriga, the Aedui sent Diviciacus, the druid, to Rome to appeal to the senate for help, but his mission was unsuccessful.

On his arrival in Gaul (58 BC), Caesar restored their independence. In spite of this, the Aedui joined the Gallic coalition against Caesar ("B. G." vii. 42), but after the surrender of Vercingetorix at the Battle of Alesia, were glad to return to their allegiance. Augustus dismantled their native capital Bibracte on Mont Beuvray and substituted a new town with a half-Roman, half-Gaulish name, Augustodunum (modern Autun).

In 21, during the reign of Tiberius, they revolted under Julius Sacrovir, and seized Augustodunum, but they were soon put down by Gaius Silius (Tacitus "Ann." iii. 43-46). The Aedui were the first of the Gauls to receive from the emperor Claudius the distinction of "jus honorum", thus being the first Gauls permitted to become senators.

The oration of Eumenius, in which he pleaded for the restoration of the schools of his native place Augustodunum, shows that the district was neglected. The chief magistrate of the Aedui in Caesar's time was called Vergobretus (according to Mommsen, "judgment-worker"), who was elected annually, possessed powers of life and death but was forbidden to go beyond the frontier. Certain clientes, or small communities, were also dependent upon the Aedui.

It is possible that the Aedui adopted many of the governmental practices of the Romans, such as electing magistrates and other officials or perhaps it was a natural development in their political system. It is thought that other Celtic tribes, such as the Remi and the Baiocasses, also elected their leaders.




</doc>
<doc id="2623" url="https://en.wikipedia.org/wiki?curid=2623" title="Aegadian Islands">
Aegadian Islands

The Aegadian Islands (; , , ) are a group of five small mountainous islands in the Mediterranean Sea off the northwest coast of Sicily, Italy, near the cities of Trapani and Marsala, with a total area of .

The Island of Favignana ("Aegusa"), the largest, lies southwest of Trapani; Levanzo ("Phorbantia") lies west; and Marettimo, the ancient "Hiera Nesos", west of Trapani, is now reckoned as a part of the group. There are also two minor islands, Formica and Maraone, lying between Levanzo and Sicily. For administrative purposes the archipelago constitutes the comune of Favignana in the Province of Trapani.

The overall population in 2017 was 4,292. Winter frost is unknown and rainfall is low. The main occupation of the islanders is fishing, and the largest tuna fishery in Sicily is there.

There is evidence of Neolithic and even Paleolithic paintings in caves on Levanzo, and to a lesser extent on Favignana.

The islands were the scene of the Battle of the Aegates of 241 BC, in which the Carthaginian fleet was defeated by the Roman fleet led by Lutatius Catulus; the engagement ended the First Punic War. After the end of Western Roman power in the first millennium AD, the islands, to the extent that they were governed at all, were part of territories of Goths, Vandals, Saracens, before the Normans fortified Favignana in 1081.

The islands belonged to the Pallavicini-Rusconi family of Genoa until 1874, when the Florio family of Palermo bought them.




</doc>
<doc id="2624" url="https://en.wikipedia.org/wiki?curid=2624" title="Aegean civilization">
Aegean civilization

Aegean civilization is a general term for the Bronze Age civilizations of Greece around the Aegean Sea. There are three distinct but communicating and interacting geographic regions covered by this term: Crete, the Cyclades and the Greek mainland. Crete is associated with the Minoan civilization from the Early Bronze Age. The Cyclades converge with the mainland during the Early Helladic ("Minyan") period and with Crete in the Middle Minoan period. From ca. 1450 BC (Late Helladic, Late Minoan), the Greek Mycenaean civilization spreads to Crete.




Commerce was practiced to some extent in very early times, as is proved by the distribution of Melian obsidian over all the Aegean area. We find Cretan vessels exported to Melos, Egypt and the Greek mainland. Melian vases came in their turn to Crete. After 1600 BC there is very close commerce with Egypt, and Aegean things find their way to all coasts of the Mediterranean. No traces of currency have come to light, unless certain axeheads, too slight for practical use, had that character. Standard weights have been found, as well as representations of ingots. The Aegean written documents have not yet proved (by being found outside the area) to be epistolary (letter writing) correspondence with other countries. Representations of ships are not common, but several have been observed on Aegean gems, gem-sealings, frying pans and vases. They are vessels of low free-board, with masts and oars. Familiarity with the sea is proved by the free use of marine motifs in decoration. The most detailed illustrations are to be found on the 'ship fresco' at Akrotiri on the island of Thera (Santorini) preserved by the ash fall from the volcanic eruption which destroyed the town there.

Discoveries, later in the 20th century, of sunken trading vessels such as those at Uluburun and Cape Gelidonya off the south coast of Turkey have brought forth an enormous amount of new information about that culture.

For details of monumental evidence the articles on Crete, Mycenae, Tiryns, Troad, Cyprus, etc., must be consulted. The most representative site explored up to now is Knossos (see Crete) which has yielded not only the most various but the most continuous evidence from the Neolithic age to the twilight of classical civilization. Next in importance come Hissarlik, Mycenae, Phaestus, Hagia Triada, Tiryns, Phylakope, Palaikastro and Gournia.


Mycenae and Tiryns are the two principal sites on which evidence of a prehistoric civilization was remarked long ago by the ancient Greeks.

The curtain-wall and towers of the Mycenaean citadel, its gate with heraldic lions, and the great "Treasury of Atreus" had borne silent witness for ages before Heinrich Schliemann's time; but they were supposed only to speak to the Homeric, or, at farthest, a rude Heroic beginning of purely Hellenic civilization. It was not until Schliemann exposed the contents of the graves which lay just inside the gate, that scholars recognized the advanced stage of art which prehistoric dwellers in the Mycenaean citadel had attained.

There had been, however, a good deal of other evidence available before 1876, which, had it been collated and seriously studied, might have discounted the sensation that the discovery of the citadel graves eventually made. Although it was recognized that certain tributaries, represented for example, in the XVIIIth Dynasty tomb of Rekhmara at Egyptian Thebes as bearing vases of peculiar forms, were of some Mediterranean race, neither their precise habitat nor the degree of their civilization could be determined while so few actual prehistoric remains were known in the Mediterranean lands. Nor did the Aegean objects which were lying obscurely in museums in 1870, or thereabouts, provide a sufficient test of the real basis underlying the Hellenic myths of the Argolid, the Troad and Crete, to cause these to be taken seriously. Aegean vases have been exhibited both at Sèvres and Neuchatel since about 1840, the provenance (i.e. source or origin) being in the one case Phylakope in Melos, in the other Cephalonia.

Ludwig Ross, the German archaeologist appointed Curator of the Antiquities of Athens at the time of the establishment of the Kingdom of Greece, by his explorations in the Greek islands from 1835 onwards, called attention to certain early intaglios, since known as Inselsteine; but it was not until 1878 that C. T. Newton demonstrated these to be no strayed Phoenician products. In 1866 primitive structures were discovered on the island of Therasia by quarrymen extracting pozzolana, a siliceous volcanic ash, for the Suez Canal works. When this discovery was followed up in 1870, on the neighbouring Santorini (Thera), by representatives of the French School at Athens, much pottery of a class now known immediately to precede the typical late Aegean ware, and many stone and metal objects, were found. These were dated by the geologist Ferdinand A. Fouqué, somewhat arbitrarily, to 2000 BC, by consideration of the superincumbent eruptive stratum.

Meanwhile, in 1868, tombs at Ialysus in Rhodes had yielded to Alfred Biliotti many fine painted vases of styles which were called later the third and fourth "Mycenaean"; but these, bought by John Ruskin, and presented to the British Museum, excited less attention than they deserved, being supposed to be of some local Asiatic fabric of uncertain date. Nor was a connection immediately detected between them and the objects found four years later in a tomb at Menidi in Attica and a rock-cut "bee-hive" grave near the Argive Heraeum.

Even Schliemann's first excavations at Hissarlik in the Troad did not excite surprise. But the "Burnt City" of his second stratum, revealed in 1873, with its fortifications and vases, and a hoard of gold, silver and bronze objects, which the discoverer connected with it, began to arouse a curiosity which was destined presently to spread far outside the narrow circle of scholars. As soon as Schliemann came on the Mycenae graves three years later, light poured from all sides on the prehistoric period of Greece. It was recognized that the character of both the fabric and the decoration of the Mycenaean objects was not that of any well-known art. A wide range in space was proved by the identification of the Inselsteine and the Ialysus vases with the new style, and a wide range in time by collation of the earlier Theraean and Hissarlik discoveries. A relationship between objects of art described by Homer and the Mycenaean treasure was generally allowed, and a correct opinion prevailed that, while certainly posterior, the civilization of the Iliad was reminiscent of the Mycenaean.

Schliemann got to work again at Hissarlik in 1878, and greatly increased our knowledge of the lower strata, but did not recognize the Aegean remains in his "Lydian" city of the sixth stratum. These were not to be fully revealed until Dr. Wilhelm Dorpfeld, who had become Schliemann's assistant in 1879, resumed the work at Hissarlik in 1892 after the first explorer's death. But by laying bare in 1884 the upper stratum of remains on the rock of Tiryns, Schliemann made a contribution to our knowledge of prehistoric domestic life which was amplified two years later by Christos Tsountas's discovery of the palace at Mycenae. Schliemann's work at Tiryns was not resumed till 1905, when it was proved, as had long been suspected, that an earlier palace underlies the one he had exposed.

From 1886 dates the finding of Mycenaean sepulchres outside the Argolid, from which, and from the continuation of Tsountas's exploration of the buildings and lesser graves at Mycenae, a large treasure, independent of Schliemann's princely gift, has been gathered into the National Museum at Athens. In that year tholos-tombs, most already pillaged but retaining some of their furniture, were excavated at Arkina and Eleusis in Attica, at Dimini near Volos in Thessaly, at Kampos on the west of Mount Taygetus, and at Maskarata in Cephalonia. The richest grave of all was explored at Vaphio in Laconia in 1889, and yielded, besides many gems and miscellaneous goldsmiths' work, two golden goblets chased with scenes of bull-hunting, and certain broken vases painted in a large bold style which remained an enigma until the excavation of Knossos.

In 1890 and 1893, Staes cleared out certain less rich tholos-tombs at Thoricus in Attica; and other graves, either rock-cut "bee-hives" or chambers, were found at Spata and Aphidna in Attica, in Aegina and Salamis, at the Argive Heraeum and Nauplia in the Argolid, near Thebes and Delphi, and not far from the Thessalian Larissa. During the Acropolis excavations in Athens, which terminated in 1888, many potsherds of the Mycenaean style were found; but Olympia had yielded either none, or such as had not been recognized before being thrown away, and the temple site at Delphi produced nothing distinctively Aegean (in dating). The American explorations of the Argive Heraeum, concluded in 1895, also failed to prove that site to have been important in the prehistoric time, though, as was to be expected from its neighbourhood to Mycenae itself, there were traces of occupation in the later Aegean periods.

Prehistoric research had now begun to extend beyond the Greek mainland. Certain central Aegean islands, Antiparos, Ios, Amorgos, Syros and Siphnos, were all found to be singularly rich in evidence of the Middle-Aegean period. The series of Syran-built graves, containing crouching corpses, is the best and most representative that is known in the Aegean. Melos, long marked as a source of early objects but not systematically excavated until taken in hand by the British School at Athens in 1896, yielded at Phylakope remains of all the Aegean periods, except the Neolithic.

A map of Cyprus in the later Bronze Age (such as is given by J. L. Myres and M. O. Richter in Catalogue of the Cyprus Museum) shows more than 25 settlements in and about the Mesaorea district alone, of which one, that at Enkomi, near the site of Salamis, has yielded the richest Aegean treasure in precious metal found outside Mycenae. E. Chantre in 1894 picked up lustreless ware, like that of Hissariik, in central Phtygia and at Pteria, and the English archaeological expeditions, sent subsequently into north-western Anatolia, have never failed to bring back ceramic specimens of Aegean appearance from the valleys of the Rhyndncus, Sangarius and Halys.

In Egypt in 1887, Flinders Petrie found painted sherds of Cretan style at Kahun in the Fayum, and farther up the Nile, at Tell el-Amarna, chanced on bits of no fewer than 800 Aegean vases in 1889. There have now been recognized in the collections at Cairo, Florence, London, Paris and Bologna several Egyptian imitations of the Aegean style which can be set off against the many debts which the centres of Aegean culture owed to Egypt. Two Aegean vases were found at Sidon in 1885, and many fragments of Aegean and especially Cypriot pottery have been found during recent excavations of sites in Philistia by the Palestine Fund.

Sicily, ever since P. Orsi excavated the Sicel cemetery near Lentini in 1877, has proved a mine of early remains, among which appear in regular succession Aegean fabrics and motives of decoration from the period of the second stratum at Hissarlik. Sardinia has Aegean sites, for example, at Abini near Teti; and Spain has yielded objects recognized as Aegean from tombs near Cadiz and from Saragossa.

One land, however, has eclipsed all others in the Aegean by the wealth of its remains of all the prehistoric ages— Crete; and so much so that, for the present, we must regard it as the fountainhead of Aegean civilization, and probably for long its political and social centre. The island first attracted the notice of archaeologists by the remarkable archaic Greek bronzes found in a cave on Mount Ida in 1885, as well as by epigraphic monuments such as the famous law of Gortyna (also called Gortyn). But the first undoubted Aegean remains reported from it were a few objects extracted from Cnossus by Minos Kalokhairinos of Candia in 1878. These were followed by certain discoveries made in the S. plain Messara by F. Halbherr. Unsuccessful attempts at Cnossus were made by both W. J. Stillman and H. Schliemann, and A. J. Evans, coming on the scene in 1893, travelled in succeeding years about the island picking up trifles of unconsidered evidence, which gradually convinced him that greater things would eventually be found. He obtained enough to enable him to forecast the discovery of written characters, till then not suspected in Aegean civilization. The revolution of 1897–1898 opened the door to wider knowledge, and much exploration has ensued, for which see Crete.

Thus the "Aegean Area" has now come to mean the Archipelago with Crete and Cyprus, the Hellenic peninsula with the Ionian islands, and Western Anatolia. Evidence is still wanting for the Macedonian and Thracian coasts. Offshoots are found in the western Mediterranean area, in Sicily, Italy, Sardinia and Spain, and in the eastern Mediterranean area in Syria and Egypt. Regarding the Cyrenaica, we are still insufficiently informed.

About 1000 BC there happened a final catastrophe. The palace at Knossus was once more destroyed, and never rebuilt or re-inhabited. Iron took the place of Bronze, and Aegean art, as a living thing, ceased on the Greek mainland and in the Aegean isles including Crete, together with Aegean writing. In Cyprus, and perhaps on the south-west Anatolian coasts, there is some reason to think that the cataclysm was less complete, and Aegean art continued to languish, cut off from its fountain-head. Such artistic faculty as survived elsewhere issued in the lifeless geometric style which is reminiscent of the later Aegean, but wholly unworthy of it. Cremation took the place of burial of the dead. This great disaster, which cleared the ground for a new growth of local art, was probably due to yet another incursion of northern tribes, possessed of superior iron weaponsthose tribes which later Greek tradition and Homer knew as the Dorians. They crushed a civilization already hard hit; and it took two or three centuries for the artistic spirit, instinct in the Aegean area, and probably preserved in suspended animation by the survival of Aegean racial elements, to blossom anew. On this conquest seems to have ensued a long period of unrest and popular movements, known to Greek tradition as the Ionian Migration and the Aeolic and Dorian "colonizations", and when once more we see the Aegean area clearly, it is dominated by Hellenes, though it has not lost all memory of its earlier culture.





</doc>
<doc id="2626" url="https://en.wikipedia.org/wiki?curid=2626" title="Aegeus">
Aegeus

In Greek mythology, Aegeus (; ) was an archaic figure in the founding myth of Athens. The "goat-man" who gave his name to the Aegean Sea was, next to Poseidon, the father of Theseus, the founder of Athenian institutions and one of the kings of Athens. 
Aegeus was the son of Pandion II, king of Athens and Pylia, daughter of King Pylas of Megara and thus, brother to Pallas, Nysus and Lykos. But, in some accounts, he was regarded as the son of Scyrius or Phemius and was not of the stock of the Erechtheids, since he was only an adopted son of Pandion. 

Aegeus' first wife was Meta, daughter of Hoples and his second wife was Chalciope, daughter of Rhexenor, neither of whom bore him any children.

Aegeus was born in Megara where his father Pandion had settled after being expelled from Athens by the sons of Metion who seized the throne. After the death of Pandion, now king of Megara, Aegeus in conjunction with his three brothers successfully attacked Athens, took control over the government and expelled the usurpers, the Metionids. Then, they divide the power among themselves but Aegeus obtained the sovereignty of Attica, succeeding Pandion to the throne. It has been said that Megara was at the time a part of Attica, and that Nisus received his part when he became king of that city. Lycus became king of Euboea whereas Pallas received the southern part of the territory. Aegeus, being the eldest of the brothers, received what they all regarded as the best part: Athens.

The division of the land was explained further in the following text by the geographer Strabo:
Later on, Lycus was driven from the territory by Aegeus himself, and had to seek refuge in Arene, Messenia. Pallas and his fifty sons revolted at a later time, being crushed by Aegeus' son Theseus.

Still without a male heir with his previous marriages, Aegeus asked the oracle at Delphi for advice. According to Pausanias, Aegeus ascribed this misfortune to the anger of Aphrodite and in order to conciliate her introduced her worship as Aphrodite Urania (Heavenly) in Athens.

The cryptic words of the oracle were ""Do not loosen the bulging mouth of the wineskin until you have reached the height of Athens, lest you die of grief."" Aegeus did not understand the prophecy and was disappointed. This puzzling oracle forced Aegeus to visit Pittheus, king of Troezen, who was famous for his wisdom and skill at expounding oracles. Pittheus understood the prophecy and introduced Aegeus to his daughter, Aethra, when Aegeus was drunk. They lay with each other, and then in some versions, Aethra waded to the island of Sphairia (a.k.a. Calauria) and bedded Poseidon. When Aethra became pregnant, Aegeus decided to return to Athens. Before leaving, he buried his sandal, shield, and sword under a huge rock and told her that, when their son grew up, he should move the rock and bring the weapons to his father, who would acknowledge him. Upon his return to Athens, Aegeus married Medea, who had fled from Corinth and the wrath of Jason. Aegeus and Medea had one son named Medus.

While visiting in Athens, King Minos' son, Androgeus managed to defeat Aegeus in every contest during the Panathenaic Games. Out of envy, Aegeus sent him to conquer the Marathonian Bull, which killed him. Minos was angry and declared war on Athens. He offered the Athenians peace, however, under the condition that Athens would send seven young men and seven young women every nine years to Crete to be fed to the Minotaur, a vicious monster. This continued until Theseus killed the Minotaur with the help of Ariadne, Minos' daughter.

In Troezen, Theseus grew up and became a brave young man. He managed to move the rock and took his father's weapons. His mother then told him the identity of his father and that he should take the weapons back to him at Athens and be acknowledged. Theseus decided to go to Athens and had the choice of going by sea, which was the safe way, or by land, following a dangerous path with thieves and bandits all the way. Young, brave and ambitious, Theseus decided to go to Athens by land.

When Theseus arrived, he did not reveal his true identity. He was welcomed by Aegeus, who was suspicious about the stranger who came to Athens. Medea tried to have Theseus killed by encouraging Aegeus to ask him to capture the Marathonian Bull, but Theseus succeeded. She tried to poison him, but at the last second, Aegeus recognized his son and knocked the poisoned cup out of Theseus' hand. Father and son were thus reunited, and Medea was sent away to Asia.

Theseus departed for Crete. Upon his departure, Aegeus told him to put up white sails when returning if he was successful in killing the Minotaur. However, when Theseus returned, he forgot these instructions. When Aegeus saw the black sails coming into Athens, mistaken in his belief that his son had been slain, he killed himself by jumping from a height : according to some, from the Acropolis or another unnamed rock; according to some Latin authors, into the sea which was therefore known as the Aegean Sea.

Sophocles' tragedy "Aegeus" has been lost, but Aegeus features in Euripides' "Medea".

At Athens, the traveller Pausanias was informed in the second-century CE that the cult of Aphrodite Urania above the Kerameikos was so ancient that it had been established by Aegeus, whose sisters were barren, and he still childless himself.



 


</doc>
<doc id="2627" url="https://en.wikipedia.org/wiki?curid=2627" title="Aegina">
Aegina

Aegina (; , "Aígina" ; ) is one of the Saronic Islands of Greece in the Saronic Gulf, from Athens. Tradition derives the name from Aegina, the mother of the hero Aeacus, who was born on the island and became its king. During ancient times Aegina was a rival of Athens, the great sea power of the era.

The municipality of Aegina consists of the island of Aegina and a few offshore islets. It is part of the Islands regional unit, Attica region. The municipality is subdivided into the following five communities (population in 2011 in parentheses ):

The capital is the town of Aegina, situated at the northwestern end of the island. Due to its proximity to Athens, it is a popular vacation place during the summer months, with quite a few Athenians owning second houses on the island.

The province of Aegina () was one of the provinces of the Piraeus Prefecture. Its territory corresponded with that of the current municipalities Aegina and Agkistri. It was abolished in 2006.

<mapframe latitude="37.7235" longitude="23.4819" zoom="10" width="200" height="131" align="left" />Aegina is roughly triangular in shape, approximately from east to west and from north to south, with an area of .

An extinct volcano constitutes two-thirds of Aegina. The northern and western sides consist of stony but fertile plains, which are well cultivated and produce luxuriant crops of grain, with some cotton, vines, almonds, olives and figs, but the most characteristic crop of Aegina today (2000s) is pistachio. Economically, the sponge fisheries are of notable importance. The southern volcanic part of the island is rugged and mountainous, and largely barren. Its highest rise is the conical Mount Oros (531 m) in the south, and the Panhellenian ridge stretches northward with narrow fertile valleys on either side.

The beaches are also a popular tourist attraction. Hydrofoil ferries from Piraeus take only forty minutes to reach Aegina; the regular ferry takes about an hour, with ticket prices for adults within the 4–15 euro range. There are regular bus services from Aegina town to destinations throughout the island such as Agia Marina. Portes is a fishing village on the east coast.

Aegina, according to Herodotus, was a colony of Epidaurus, to which state it was originally subject. Its placement between Attica and the Peloponnesus made it a site of trade even earlier, and its earliest inhabitants allegedly came from Asia Minor. Minoan ceramics have been found in contexts of . The famous Aegina Treasure, now in the British Museum is estimated to date between 1700 and 1500 BC. The discovery on the island of a number of gold ornaments belonging to the last period of Mycenaean art suggests that Mycenaean culture existed in Aegina for some generations after the Dorian conquest of Argos and Lacedaemon. It is probable that the island was not doricised before the 9th century BC.

One of the earliest historical facts is its membership in the Amphictyony or League of Calauria, attested around the 8th century BC. This ostensibly religious league included—besides Aegina—Athens, the Minyan (Boeotian) Orchomenos, Troezen, Hermione, Nauplia, and Prasiae. It was probably an organisation of city-states that were still Mycenaean, for the purpose of suppressing piracy in the Aegean that began as a result of the decay of the naval supremacy of the Mycenaean princes.

Aegina seems to have belonged to the Eretrian league during the Lelantine War; this, perhaps, may explain the war with Samos, a major member of the rival Chalcidian league during the reign of King Amphicrates (Herod. iii. 59), i.e. not later than the earlier half of the 7th century BC.

Its early history reveals that the maritime importance of the island dates back to pre-Dorian times. It is usually stated on the authority of Ephorus, that Pheidon of Argos established a mint in Aegina, the first city-state to issue coins in Europe, the Aeginetic stater. One stamped stater (having the mark of some authority in the form of a picture or words) can be seen in the Bibliothèque Nationale of Paris. It is an electrum stater of a turtle, an animal sacred to Aphrodite, struck at Aegina that dates from 700 BC. Therefore, it is thought that the Aeginetes, within 30 or 40 years of the invention of coinage in Asia Minor by the Ionian Greeks or the Lydians (c. 630 BC), might have been the ones to introduce coinage to the Western world. The fact that the Aeginetic standard of weights and measures (developed during the mid-7th century) was one of the two standards in general use in the Greek world (the other being the Euboic-Attic) is sufficient evidence of the early commercial importance of the island. The Aeginetic weight standard of about 12.3 grams was widely adopted in the Greek world during the 7th century BC. The Aeginetic stater was divided into three drachmae of 4.1 grams of silver. Staters depicting a sea-turtle were struck up to the end of the 5th century BC. Following the end of the Peloponnesian War, 404 BC, it was replaced by the land tortoise.

During the naval expansion of Aegina during the Archaic Period, Kydonia was an ideal maritime stop for Aegina's fleet on its way to other Mediterranean ports controlled by the emerging sea-power Aegina. During the next century Aegina was one of the three principal states trading at the emporium of Naucratis in Egypt, and it was the only Greek state near Europe that had a share in this factory. At the beginning of the 5th century BC it seems to have been an entrepôt of the Pontic grain trade, which, at a later date, became an Athenian monopoly.

Unlike the other commercial states of the 7th and 6th centuries BC, such as Corinth, Chalcis, Eretria and Miletus, Aegina did not found any colonies. The settlements to which Strabo refers (viii. 376) cannot be regarded as any real exceptions to this statement.

The known history of Aegina is almost exclusively a history of its relations with the neighbouring state of Athens, which began to compete with the thalassocracy (sea power) of Aegina about the beginning of the 6th century BC. Solon passed laws limiting Aeginetan commerce in Attica. The legendary history of these relations, as recorded by Herodotus (v. 79–89; vi. 49–51, 73, 85–94), involves critical problems of some difficulty and interest. He traces the hostility of the two states back to a dispute about the images of the goddesses Damia and Auxesia, which the Aeginetes had carried off from Epidauros, their parent state.

The Epidaurians had been accustomed to make annual offerings to the Athenian deities Athena and Erechtheus in payment for the Athenian olive-wood of which the statues were made. Upon the refusal of the Aeginetes to continue these offerings, the Athenians endeavoured to carry away the images. Their design was frustrated miraculously – according to the Aeginetan version, the statues fell upon their knees – and only a single survivor returned to Athens. There he became victim to the fury of his comrades' widows who pierced him with their brooch-pins. No date is assigned by Herodotus for this "old feud"; recent writers, such as J. B. Bury and R. W. Macan, suggest the period between Solon and Peisistratus, . It is possible that the whole episode is mythical. A critical analysis of the narrative seems to reveal little else than a series of aetiological traditions (explanatory of cults and customs), such as of the kneeling posture of the images of Damia and Auxesia, of the use of native ware instead of Athenian in their worship, and of the change in women's dress at Athens from the Dorian to the Ionian style.

The account which Herodotus gives of the hostilities between the two states during the early years of the 5th century BC is to the following effect. The Thebans, after the defeat by Athens about 507 BC, appealed to Aegina for assistance. The Aeginetans at first contented themselves with sending the images of the Aeacidae, the tutelary heroes of their island. Subsequently, however, they contracted an alliance, and ravaged the seaboard of Attica. The Athenians were preparing to make reprisals, in spite of the advice of the Delphic oracle that they should desist from attacking Aegina for thirty years, and content themselves meanwhile with dedicating a precinct to Aeacus, when their projects were interrupted by the Spartan intrigues for the restoration of Hippias.

In 491 BC Aegina was one of the states which gave the symbols of submission ("earth and water") to Achaemenid Persia. Athens at once appealed to Sparta to punish this act of medism, and Cleomenes I, one of the Spartan kings, crossed over to the island, to arrest those who were responsible for it. His attempt was at first unsuccessful; but, after the deposition of Demaratus, he visited the island a second time, accompanied by his new colleague Leotychides, seized ten of the leading citizens and deposited them at Athens as hostages.

After the death of Cleomenes and the refusal of the Athenians to restore the hostages to Leotychides, the Aeginetes retaliated by seizing a number of Athenians at a festival at Sunium. Thereupon the Athenians concerted a plot with Nicodromus, the leader of the democratic party in the island, for the betrayal of Aegina. He was to seize the old city, and they were to come to his aid on the same day with seventy vessels. The plot failed owing to the late arrival of the Athenian force, when Nicodromus had already fled the island. An engagement followed in which the Aeginetes were defeated. Subsequently, however, they succeeded in winning a victory over the Athenian fleet.

All the incidents subsequent to the appeal of Athens to Sparta are referred expressly by Herodotus to the interval between the sending of the heralds in 491 BC and the invasion of Datis and Artaphernes in 490 BC (cf. Herod. vi. 49 with 94).

There are difficulties with this story, of which the following are the principal elements:
As the final victory of Athens over Aegina was in 458 BC, the thirty years of the oracle would carry us back to the year 488 BC as the date of the dedication of the precinct and the beginning of hostilities. This inference is supported by the date of the building of the 200 triremes "for the war against Aegina" on the advice of Themistocles, which is given in the "Constitution of Athens" as 483–482 BC. It is probable, therefore, that Herodotus is in error both in tracing back the beginning of hostilities to an alliance between Thebes and Aegina () and in claiming the episode of Nicodromus occurred prior to the battle of Marathon.

Overtures were unquestionably made by Thebes for an alliance with Aegina , but they came to nothing. The refusal of Aegina was in the diplomatic guise of "sending the Aeacidae." The real occasion of the beginning of the war was the refusal of Athens to restore the hostages some twenty years later. There was but one war, and it lasted from 488 to 481 BC. That Athens had the worst of it in this war is certain. Herodotus had no Athenian victories to record after the initial success, and the fact that Themistocles was able to carry his proposal to devote the surplus funds of the state to the building of so large a fleet seems to imply that the Athenians were themselves convinced that a supreme effort was necessary.

It may be noted, in confirmation of this opinion, that the naval supremacy of Aegina is assigned by the ancient writers on chronology to precisely this period, i.e. the years 490–480 BC.

In the repulse of Xerxes I it is possible that the Aeginetes played a larger part than is conceded to them by Herodotus. The Athenian tradition, which he follows in the main, would naturally seek to obscure their services. It was to Aegina rather than Athens that the prize of valour at Salamis was awarded, and the destruction of the Persian fleet appears to have been as much the work of the Aeginetan contingent as of the Athenian (Herod. viii. 91). There are other indications, too, of the importance of the Aeginetan fleet in the Greek scheme of defence. In view of these considerations it becomes difficult to credit the number of the vessels that is assigned to them by Herodotus (30 as against 180 Athenian vessels, cf. Greek History, sect. Authorities). During the next twenty years the Philo-Laconian policy of Cimon secured Aegina, as a member of the Spartan league, from attack. The change in Athenian foreign policy, which was consequent upon the ostracism of Cimon in 461 BC, resulted in what is sometimes called the First Peloponnesian War, during which most of the fighting was experienced by Corinth and Aegina. The latter state was forced to surrender to Athens after a siege, and to accept the position of a subject-ally (). The tribute was fixed at 30 talents.

By the terms of the Thirty Years' Peace (445 BC) Athens promised to restore to Aegina her autonomy, but the clause remained ineffective. During the first winter of the Peloponnesian War (431 BC) Athens expelled the Aeginetans and established a cleruchy in their island. The exiles were settled by Sparta in Thyreatis, on the frontiers of Laconia and Argolis. Even in their new home they were not safe from Athenian rancour. A force commanded by Nicias landed in 424 BC, and killed most of them. At the end of the Peloponnesian War Lysander restored the scattered remnants of the old inhabitants to the island, which was used by the Spartans as a base for operations against Athens during the Corinthian War. Its greatness, however, was at an end. The part which it plays henceforward is insignificant.

It would be a mistake to attribute the demise of Aegina solely to the development of the Athenian navy. It is probable that the power of Aegina had steadily declined during the twenty years after Salamis, and that it had declined absolutely, as well as relatively to that of Athens. Commerce was the source of Aegina's greatness, and her trade, which seems to have been principally with the Levant, must have suffered seriously from the war with Persia. Aegina's medism in 491 is to be explained by its commercial relations with the Persian Empire. It was forced into patriotism in spite of itself, and the glory won by the battle of Salamis was paid for by the loss of its trade and the decay of its marine. The completeness of the ruin of so powerful a state is explained by the economic conditions of the island, the prosperity of which was based on slave labour. It is impossible, indeed, to accept Aristotle's (cf. Athenaeus vi. 272) estimate of 470,000 as the number of the slave population; it is clear, however, that the number must have been much greater than that of the free inhabitants. In this respect the history of Aegina does but anticipate the history of Greece as a whole.

The constitutional history of Aegina is unusually simple. So long as the island retained its independence the government was an oligarchy. There is no trace of heroic monarchy and no tradition of a "tyrannis". The story of Nicodromus, while it proves the existence of a democratic party, suggests, at the same time, that it could count upon little support.

Aegina with the rest of Greece became dominated successively by the Macedonians (322–229 BC), the Achaeans (229–211 BC), Aetolians (211–210  BC), Attalus of Pergamum (210–133 BC) and the Romans (after 133 BC). A sign at the Archaeological Museum of Aegina is reported to say that a Jewish community is believed to have been established in Aegina "at the end of the second and during the 3rd century AD" by Jews fleeing the barbarian invasions of the time in Greece. However, the first phases of those invasions began in the 4th century. Local Christian tradition has it that a Christian community was established there in the 1st century, having as its bishop Crispus, the ruler of the Corinthian synagogue, who became a Christian, and was baptised by Paul the Apostle. There are written records of participation by later bishops of Aegina, Gabriel and Thomas, in the Councils of Constantinople in 869 and 879. The see was at first a suffragan of the metropolitan see of Corinth, but was later given the rank of archdiocese. No longer a residential bishopric, Aegina is today listed by the Catholic Church as a titular see.

Aegina belonged to the East Roman (Byzantine) Empire after the division of the Roman Empire in 395. It remained Eastern Roman during the period of crisis of the 7th–8th centuries, when most of the Balkans and the Greek mainland were overrun by Slavic invasions. Indeed, according to the "Chronicle of Monemvasia", the island served as a refuge for the Corinthians fleeing these incursions. The island flourished during the early 9th century, as evidenced by church construction activity, but suffered greatly from Arab raids originating from Crete. Various hagiographies record a large-scale raid , that resulted in the flight of much of the population to the Greek mainland. During that time, some of the population sought refuge in the island's hinterland, establishing the settlement of Palaia Chora.

According to the 12th-century bishop of Athens, Michael Choniates, by his time the island had become a base for pirates. This is corroborated by Benedict of Peterborough's graphic account of Greece, as it was in 1191; he states that many of the islands were uninhabited for fear of pirates and that Aegina, along with Salamis and Makronisos, were their strongholds.

After the dissolution and partition of the Byzantine Empire by the Fourth Crusade in 1204, Aegina was accorded to the Republic of Venice. In the event, it became controlled by the Duchy of Athens. The Catalan Company seized control of Athens, and with it Aegina, in 1317, and in 1425 the island became controlled by the Venetians, when Alioto Caopena, at that time ruler of Aegina, placed himself by treaty under the Republic's protection to escape the danger of a Turkish raid. The island must then have been fruitful, for one of the conditions by which Venice accorded him protection was that he should supply grain to Venetian colonies. He agreed to surrender the island to Venice if his family became extinct. Antonio II Acciaioli opposed the treaty for one of his adopted daughters had married the future lord of Aegina, Antonello Caopena.

In 1451, Aegina became Venetian. The islanders welcomed Venetian rule; the claims of Antonello's uncle Arnà, who had lands in Argolis, were satisfied by a pension. A Venetian governor ("rettore") was appointed, who was dependent on the authorities of Nauplia. After Arnà's death, his son Alioto renewed his claim to the island but was told that the republic was resolved to keep it. He and his family were pensioned and one of them aided in the defence of Aegina against the Turks in 1537, was captured with his family, and died in a Turkish dungeon.

In 1463 the Turco-Venetian war began, which was destined to cost the Venetians Negroponte (Euboea), the island of Lemnos, most of the Cyclades islands, Scudra and their colonies in the Morea. Peace was concluded in 1479. Venice still retained Aegina, Lepanto (Naupactus), Nauplia, Monemvasia, Modon, Navarino, Coron, and the islands Crete, Mykonos and Tinos. Aegina remained subject to Nauplia.

Aegina obtained money for its defences by reluctantly sacrificing its cherished relic, the head of St. George, which had been carried there from Livadia by the Catalans. In 1462, the Venetian Senate ordered the relic to be removed to St. Giorgio Maggiore in Venice and on 12 November, it was transported from Aegina by Vettore Cappello, the famous Venetian commander. In return, the Senate gave the Aeginetes 100 ducats apiece towards fortifying the island.

In 1519, the government was reformed. The system of having two rectors was found to result in frequent quarrels and the republic thenceforth sent out a single official styled Bailie and Captain, assisted by two councillors, who performed the duties of camerlengo by turns. The Bailie's authority extended over the rector of Aegina, whereas Kastri (opposite the island Hydra) was granted to two families, the Palaiologoi and the Alberti.

Society at Nauplia was divided into three classes: nobles, citizens and plebeians, and it was customary for nobles alone to possess the much-coveted local offices, such as the judge of the inferior court and inspector of weights and measures. The populace now demanded its share and the home government ordered that at least one of the three inspectors should be a non-noble.

Aegina had always been exposed to the raids of corsairs and had oppressive governors during these last 30 years of Venetian rule. Venetian nobles were not willing to go to this island. In 1533, three rectors of Aegina were punished for their acts of injustice and there is a graphic account of the reception given by the Aeginetans to the captain of Nauplia, who came to command an enquiry into the administration of these delinquents (vid. inscription over the entrance of St. George the Catholic in Paliachora). The rectors had spurned their ancient right to elect an islander to keep one key of the money-chest. They had also threatened to leave the island en masse with the commissioner, unless the captain avenged their wrongs. To spare the economy of the community, it was ordered that appeals from the governor's decision should be made on Crete, instead of in Venice. The republic was to pay a bakshish to the Turkish governor of the Morea and to the voivode who was stationed at the frontier of Thermisi (opposite Hydra). The fortifications too, were allowed to become decrepit and were inadequately guarded.

After the end of the Duchy of Athens and the principality of Achaia, the only Latin possessions left on the mainland of Greece were the papal city of Monemvasia, the fortress of Vonitsa, the Messenian stations Coron and Modon, Lepanto, Pteleon, Navarino, and the castles of Argos and Nauplia, to which the island of Aegina was subordinate.

In 1502–03, the new peace treaty left Venice with nothing but Cephalonia, Monemvasia and Nauplia, with their appurtenances in the Morea. And against the sack of Megara, it had to endure the temporary capture of the castle of Aegina by Kemal Reis and the abduction of 2000 inhabitants. This treaty was renewed in 1513 and 1521. All supplies of grain from Nauplia and Monemvasia had to be imported from Turkish possessions, while corsairs rendered dangerous all traffic by sea.

In 1537, sultan Suleiman declared war upon Venice and his admiral Hayreddin Barbarossa devastated much of the Ionian Islands, and in October invaded the island of Aegina. On the fourth day Palaiochora was captured, but the Latin church of St George was spared. Hayreddin Barbarossa had the adult male population massacred and took away 6,000 surviving women and children as slaves. Then Barbarossa sailed to Naxos, whence he carried off an immense booty, compelling the Duke of Naxos to purchase his further independence by paying a tribute of 5000 ducats.

With the peace of 1540, Venice ceded Nauplia and Monemvasia. For nearly 150 years afterwards, Venice ruled no part of the mainland of Greece except Parga and Butrinto (subordinate politically to the Ionian Islands), but it still retained its insular dominions Cyprus, Crete, Tenos and six Ionian islands.

The island was attacked and left desolate by Francesco Morosini during the Cretan War (1654).

In 1684, the beginning of the Morean War between Venice and the Ottoman Empire resulted in the temporary reconquest of a large part of the country by the Republic. In 1687 the Venetian army arrived in Piraeus and captured Attica. The number of the Athenians at that time exceeded 6,000, the Albanians from the villages of Attica excluded, whilst in 1674 the population of Aegina did not seem to exceed 3,000 inhabitants, two thirds of which were women. The Aeginetans had been reduced to poverty to pay their taxes. The most significant plague epidemic began in Attica during 1688, an occasion that caused the massive migration of Athenians toward the south; most of them settled in Aegina. In 1693 Morosini resumed command, but his only acts were to refortify the castle of Aegina, which he had demolished during the Cretan war in 1655, the cost of upkeep being paid as long as the war lasted by the Athenians, and to place it and Salamis under Malipiero as Governor. This caused the Athenians to send him a request for the renewal of Venetian protection and an offer of an annual tribute. He died in 1694 and Zeno was appointed at his place.

In 1699, thanks to English mediation, the war ended with the peace of Karlowitz by which Venice retained possession of the 7 Ionian islands as well as Butrinto and Parga, the Morea, Spinalonga and Suda, Tenos, Santa Maura and Aegina and ceased to pay a tribute for Zante, but which restored Lepanto to the Ottoman sultan. Cerigo and Aegina were united administratively since the peace with Morea, which not only paid all the expenses of administration but furnished a substantial balance for the naval defence of Venice, in which it was directly interested.

During the early part of the Ottoman–Venetian War of 1714–1718 the Ottoman Fleet commanded by Canum Hoca captured Aegina. Ottomans rule in Aegina and the Morea was resumed and confirmed by the Treaty of Passarowitz, and they retained control of the island with the exception of a brief Russian occupation Orlov Revolt (early 1770s), until the beginning of the Greek War of Independence in 1821.

During the Greek War of Independence, Aegina became an administrative centre for the Greek revolutionary authorities. Ioannis Kapodistrias was briefly established here.


In Greek mythology, Aegina was a daughter of the river god Asopus and the nymph Metope. She bore at least two children: Menoetius by Actor, and Aeacus by the god Zeus. When Zeus abducted Aegina, he took her to Oenone, an island close to Attica. Here, Aegina gave birth to Aeacus, who would later become king of Oenone; thenceforth, the island's name was Aegina.

Aegina was the gathering place of Myrmidons; in Aegina they gathered and trained. Zeus needed an elite army and at first thought that Aegina, which at the time did not have any villagers, was a good place. So he changed some ants (, Myrmigia) into warriors who had six hands and wore black armour. Later, the Myrmidons, commanded by Achilles, were known as the most fearsome fighting unit in Greece.







</doc>
<doc id="2628" url="https://en.wikipedia.org/wiki?curid=2628" title="Aegis">
Aegis

The aegis ( ; "aigis"), as stated in the "Iliad", is carried by Athena and Zeus, but its nature is uncertain. It had been interpreted as an animal skin or a shield, sometimes bearing the head of a Gorgon. There may be a connection with a deity named Aex "or Aix", a daughter of Helios and a nurse of Zeus or alternatively a mistress of Zeus (Hyginus, "Astronomica" 2. 13). The aegis of Athena is referred to in several places in the "Iliad". "It produced a sound as from a myriad roaring dragons ("Iliad", 4.17) and was borne by Athena in battle ... and among them went bright-eyed Athene, holding the precious aegis which is ageless and immortal: a hundred tassels of pure gold hang fluttering from it, tight-woven each of them, and each the worth of a hundred oxen."

The modern concept of doing something "under someone's "aegis"" means doing something under the protection of a powerful, knowledgeable, or benevolent source. The word "aegis" is identified with protection by a strong force with its roots in Greek mythology and adopted by the Romans; there are parallels in Norse mythology and in Egyptian mythology as well, where the Greek word "aegis" is applied by extension.

Virgil imagines the Cyclopes in Hephaestus' forge, who "busily burnished the aegis Athena wears in her angry moods—a fearsome thing with a surface of gold like scaly snake-skin, and the linked serpents and the Gorgon herself upon the goddess's breast—a severed head rolling its eyes", furnished with golden tassels and bearing the "Gorgoneion" (Medusa's head) in the central boss. Some of the Attic vase-painters retained an archaic tradition that the tassels had originally been serpents in their representations of the aegis. When the Olympian deities overtook the older deities of Greece and she was born of Metis (inside Zeus who had swallowed the goddess) and "re-born" through the head of Zeus fully clothed, Athena already wore her typical garments.

When the Olympian shakes the aegis, Mount Ida is wrapped in clouds, the thunder rolls and men are struck down with fear. "Aegis-bearing Zeus", as he is in the "Iliad", sometimes lends the fearsome aegis to Athena. In the "Iliad" when Zeus sends Apollo to revive the wounded Hector, Apollo, holding the aegis, charges the Achaeans, pushing them back to their ships drawn up on the shore. According to Edith Hamilton's "Mythology: Timeless Tales of Gods and Heroes", the Aegis is the breastplate of Zeus, and was "awful to behold". However, Zeus is normally portrayed in classical sculpture holding a thunderbolt or lightning, bearing neither a shield nor a breastplate.

Classical Greece interpreted the Homeric aegis usually as a cover of some kind borne by Athena. It was supposed by Euripides ("Ion", 995) that the aegis borne by Athena was the skin of the slain Gorgon, yet the usual understanding is that the "Gorgoneion" was "added" to the aegis, a votive offering from a grateful Perseus.

In a similar interpretation, Aex, a daughter of Helios, represented as a great fire-breathing chthonic serpent similar to the Chimera, was slain and flayed by Athena, who afterwards wore its skin, the aegis, as a cuirass (Diodorus Siculus iii. 70), or as a chlamys. The Douris cup shows that the aegis was represented exactly as the skin of the great serpent, with its scales clearly delineated.

John Tzetzes says that aegis was the skin of the monstrous giant Pallas whom Athena overcame and whose name she attached to her own.

In a late rendering by Gaius Julius Hyginus ("Poetical Astronomy" ii. 13), Zeus is said to have used the skin of a pet goat owned by his nurse Amalthea ("aigis" "goat-skin") which suckled him in Crete, as a shield when he went forth to do battle against the Titans.
The aegis appears in works of art sometimes as an animal's skin thrown over Athena's shoulders and arms, occasionally with a border of snakes, usually also bearing the Gorgon head, the "gorgoneion". In some pottery it appears as a tasselled cover over Athena's dress. It is sometimes represented on the statues of Roman emperors, heroes, and warriors, and on cameos and vases. A vestige of that appears in a portrait of Alexander the Great in a fresco from Pompeii dated to the first century BC, which shows the image of the head of a woman on his armor that resembles the Gorgon.

Herodotus thought he had identified the source of the ægis in ancient Libya, which was always a distant territory of ancient magic for the Greeks. "Athene's garments and ægis were borrowed by the Greeks from the Libyan women, who are dressed in exactly the same way, except that their leather garments are fringed with thongs, not serpents."

Robert Graves in "The Greek Myths" (1955; 1960) asserts that the ægis in its Libyan sense had been a shamanic pouch containing various ritual objects, bearing the device of a monstrous serpent-haired visage with tusk-like teeth and a protruding tongue which was meant to frighten away the uninitiated. In this context, Graves identifies the aegis as clearly belonging first to Athena.

One current interpretation is that the Hittite sacral hieratic hunting bag ("kursas"), a rough and shaggy goatskin that has been firmly established in literary texts and iconography by H.G. Güterbock, was a source of the aegis.

The Greek "aigis", has many meanings including:

The original meaning may have been the first, and "Zeus Aigiokhos" = "Zeus who holds the aegis" may have originally meant "Sky/Heaven, who holds the thunderstorm". The transition to the meaning "shield" or "goatskin" may have come by folk etymology among a people familiar with draping an animal skin over the left arm as a shield.



</doc>
<doc id="2629" url="https://en.wikipedia.org/wiki?curid=2629" title="Aegisthus">
Aegisthus

Aegisthus (; ; also transliterated as Aigisthos, ) was a figure in Greek mythology. Aegisthus is known from two primary sources of Greek mythology. The first is Homer's "Odyssey", believed to have been first written down by Homer at the end of the 8th century BC, and the second from Aeschylus's "Oresteia", written in the 5th century, BC.

Aegisthus was the son of Thyestes and Thyestes' own daughter Pelopia, an incestuous union motivated by his father's rivalry with the house of Atreus for the throne of Mycenae. Aegisthus murdered Atreus in order to restore his father to power, ruling jointly with him only to be driven from power by Atreus' son Agamemnon.

While Agamemnon lay siege to Troy, his estranged queen Clytemnestra took Aegisthus as a lover. The couple killed Agamemnon upon the king's return, making Aegisthus king of Mycenae once more. Aegisthus ruled for seven more years before his death at the hands of Agamemnon's son Orestes.

Thyestes felt he had been deprived of the Mycenean throne unfairly by his brother, Atreus. The two battled back and forth several times. In addition, Thyestes had an affair with Atreus' wife, Aerope. In revenge, Atreus killed Thyestes' sons and served them to him unknowingly. After realizing he had eaten his own sons' corpses, Thyestes asked an oracle how best to gain revenge. The advice was to father a son with his own daughter, Pelopia, and that son would kill Atreus.

Thyestes raped Pelopia after she performed a sacrifice, hiding his identity from her. When Aegisthus was born, his mother abandoned him, ashamed of his origin, and he was raised by shepherds and suckled by a goat, hence his name Aegisthus (from , male goat). Atreus, not knowing the baby's origin, took Aegisthus in and raised him as his own son.

In the night in which Pelopia had been raped by her father, she had taken from him his sword which she afterwards gave to Aegisthus. When she discovered that the sword belonged to her own father, she realised that her son was the product of incestuous intercourse. In despair, she killed herself. Atreus in his enmity towards his brother sent Aegisthus to kill him; but the sword which Aegisthus carried was the cause of the recognition between Thyestes and his son, and the latter returned and slew his uncle Atreus, while he was offering a sacrifice on the seacoast. Aegisthus and his father now took possession of their lawful inheritance from which they had been expelled by Atreus.

Aegisthus and Thyestes thereafter ruled over Mycenae jointly, exiling Atreus' sons Agamemnon and Menelaus to Sparta, where King Tyndareus gave the pair his daughters, Clytemnestra and Helen, to take as wives. Agamemnon and Clytemnestra had four children: one son, Orestes, and three daughters, Iphigenia, Electra and Chrysothemis.

After the death of Tyndareus, Meneleaus became king of Sparta. He used the Spartan army to drive out Aegisthus and Thyestes from Mycenae and place Agamemnon on the throne. Agamemnon extended his dominion by conquest and became the most powerful ruler in Greece. After Helen's abduction to Troy, Agamemnon was forced to sacrifice his own daughter Iphigenia in order to appease the gods before setting off for Ilium. While Agamemnon was away fighting in the Trojan War, Clytemnestra turned against her husband and took Aegisthus as a lover. Upon Agamemnon's return to Mycenae, Aegisthus and Clytemnestra worked together to kill Agamemnon with certain accounts recording Aegisthus committing the murder while others record Clytemnestra herself exacting revenge on Agamemnon for his murder of Iphigenia.

Following Agamemnon's death, Aegisthus reigned over Mycenae for seven years. He and Clytemnestra had a son, Aletes, and two daughters, Erigone and Helen. In the eighth year of his reign Orestes, the son of Agamemnon, returned to Mycenae and avenged the death of his father by killing Aegisthus and Clytemnestra. The impiety of matricide was such that Orestes was forced to flee from Mycenae, pursued by the Furies. Aletes became king until Orestes returned several years later and killed him. Orestes later married Aegisthus' daughter Erigone.

Homer gives no information about Aegisthus' back-story. We learn from him only that, after the death of Thyestes, Aegisthus ruled as king at Mycenae and took no part in the Trojan expedition. While Agamemnon was absent on his expedition against Troy, Aegisthus seduced Clytemnestra, and was so wicked as to offer up thanks to the gods for the success with which his criminal exertions were crowned. In order not to be surprised by the return of Agamemnon, he sent out spies, and when Agamemnon came, Aegisthus invited him to a repast at which he had him treacherously murdered.

In Aeschylus's "Oresteia", Aegisthus is a minor figure. In the first play, "Agamemnon", he appears at the end to claim the throne, after Clytemnestra herself has killed Agamemnon and Cassandra. Clytemnestra wields the axe she has used to quell dissent. In "The Libation Bearers" he is killed quickly by Orestes, who then struggles over having to kill his mother. Aegisthus is referred to as a "weak lion", plotting the murders but having his lover commit the deeds. According to Johanna Leah Braff, he "takes the traditional female role, as one who devises but is passive and does not act." Christopher Collard describes him as the foil to Clytemnestra, his brief speech in "Agamemnon" revealing him to be "cowardly, sly, weak, full of noisy threats - a typical 'tyrant figure' in embryo."

Aeschylus's portrayal of Aegisthus as a weak, implicitly feminised figure, influenced later writers and artists who often depict him as an effeminate or decadent individual, either manipulating or dominated by the more powerful Clytemnestra. He appears in Seneca's "Agamemnon", enticing her to murder. In Richard Strauss's and Hugo von Hofmannsthal's opera, "Elektra" his voice is "a decidedly high-pitched tenor, punctuated by irrational upward leaps, that rises to high pitched squeals during his death colloquy with Elektra." In the first production he was depicted as "an epicene...with long curly locks and rouged lips, half-cringing, half-posturing seductively."

An ancient tomb in Mycenae is fancifully known as the 'Tomb of Aigisthus'. It dates from around 1470 BC.


</doc>
<doc id="2630" url="https://en.wikipedia.org/wiki?curid=2630" title="Aegospotami">
Aegospotami

Aegospotami () or Aegospotamos (i.e. "Goat Streams") is the ancient Greek name for a small river issuing into the Hellespont (Modern Turkish "Çanakkale Boğazı"), northeast of Sestos.

At its mouth was the scene of the decisive battle in 405 BC in which Lysander destroyed the Athenian fleet, ending the Peloponnesian War. The ancient Greek township of the same name, whose existence is attested by coins of the 5th and 4th centuries, and the river itself were located in ancient Thrace in the Chersonese.

According to ancient sources including Pliny the Elder and Aristotle, in 467 BC a large meteorite landed near Aegospotami. It was described as brown in colour and the size of a wagon load; it was a local landmark for more than 500 years. A comet, tentatively identified as Halley's Comet, was reported at the time the meteorite landed. This is possibly the first European record of Halley's comet.

Aegospotami is located on the Dardanelles, northeast of the modern Turkish town of .


</doc>
<doc id="2632" url="https://en.wikipedia.org/wiki?curid=2632" title="Aelia Capitolina">
Aelia Capitolina

Aelia Capitolina (; Latin in full: ) was a Roman colony, built under the emperor Hadrian on the site of Jerusalem, which was in ruins following the siege of 70 AD, leading in part to the Bar Kokhba revolt of 132–136 AD. "Aelia Capitolina" remained the official name of Jerusalem until 638 AD, when the Arabs conquered the city and kept the first part of it as 'إلياء' (Iliyā').

"Aelia" came from Hadrian's "nomen gentile", "Aelius", while "Capitolina" meant that the new city was dedicated to "Jupiter Capitolinus", to whom a temple was built on the site of the former Jewish temple, the Temple Mount, but which had before Herod been reconsecrated to Zeus under Antiochus IV Epiphanes and caused the Maccabean Revolt—which resulted in the Jewish-Roman alliance.

The Latin name "Aelia" is the source of the much later Arabic term Iliyā' (إلياء), a 7th-century Islamic name for Jerusalem.

Jerusalem, once heavily rebuilt by Herod, was still in ruins following the decisive siege of the city, as part of the First Jewish–Roman War in 70 AD. Josephus—a contemporary historian and proponent of the Judean cause who was born in Jerusalem and fought the Romans in that war—reports that "Jerusalem ... was so thoroughly razed to the ground by those that demolished it to its foundations, that nothing was left that could ever persuade visitors that it had once been a place of habitation." The Talmud (Makkot) tells of Rabbi Akiva and several other sages visiting the ruins of Jerusalem. His colleagues were aggrieved at seeing a fox scuttling out of what had been the Temple's Holy of Holies as an indication of the desolation, while Akiva laughed, telling them through what many believe to be divine inspiration that one day the Temple will be rebuilt. 

When the Roman Emperor Hadrian vowed to rebuild Jerusalem from the wreckage in 130 AD, he considered reconstructing Jerusalem as a gift to the Jewish people. The Jews awaited with hope, but after Hadrian visited Jerusalem, he was discouraged from doing so by a Samaritan (according to rabbinic sources). He then decided to rebuild the city as a Roman colony, which would be inhabited by his legionaries. Hadrian's new city was to be dedicated to himself and certain Roman gods, in particular Jupiter.

The Jewish Bar Kokhba revolt, which took the Romans three years to suppress, enraged Hadrian, and he became determined to erase Judaism from the province. Circumcision was forbidden and Jews were expelled from the city. Hadrian renamed Iudaea Province to "Syria Palaestina", dispensing with the name of Judea. There is controversy as to whether the anti-Jewish decrees followed the Bar Kokhba revolt or preceded it and were the cause of the revolt.

Jerusalem was renamed "Aelia Capitolina" and rebuilt in the style of a typical Roman town. Jews were prohibited from entering the city on pain of death, except for one day each year, during the holiday of Tisha B'Av. Taken together, these measures (which also affected Jewish Christians) essentially secularized the city. The ban was maintained until the 7th century, though Christians would soon be granted an exemption: during the 4th century, the Roman Emperor Constantine I ordered the construction of Christian holy sites in the city, including the Church of the Holy Sepulchre. Burial remains from the Byzantine period are exclusively Christian, suggesting that the population of Jerusalem in Byzantine times probably consisted only of Christians.

In the fifth century, the eastern continuation of the Roman Empire that was ruled from the recently renamed Constantinople, maintained control of the city. Within the span of a few decades, the city shifted from Byzantine to Persian rule, then back to Roman-Byzantine dominion. Following Sassanid Khosrau II's early seventh century push through Syria, his generals Shahrbaraz and Shahin attacked Jerusalem ("") aided by the Jews of Palaestina Prima, who had risen up against the Byzantines.

In the Siege of Jerusalem of 614 AD, after 21 days of relentless siege warfare, Jerusalem was captured. Byzantine chronicles relate that the Sassanids and Jews slaughtered tens of thousands of Christians in the city, many at the Mamilla Pool, and destroyed their monuments and churches, including the Church of the Holy Sepulchre. The conquered city would remain in Sassanid hands for some fifteen years until the Byzantine Emperor Heraclius reconquered it in 629.

Byzantine Jerusalem was conquered by the Arab armies of Umar ibn al-Khattab in 638 AD, which resulted in the removal of the restrictions on Jews living in the city. Among Muslims of Islam's earliest era it was referred to as "Madinat bayt al-Maqdis" ('City of the Temple') which was restricted to the Temple Mount. The rest of the city was called "Iliya", reflecting the Roman name Aelia Capitolina.

According to Eusebius, the Jerusalem church was scattered twice, in 70 and 135, with the difference that from 70–130 the bishops of Jerusalem have evidently Jewish names, whereas after 135 the bishops of Aelia Capitolina appear to be Greeks. Eusebius' evidence for continuation of a church at Aelia Capitolina is confirmed by the Bordeaux Pilgrim.

Near the Struthion Pool, Hadrian built a triple-arched gateway as an entrance to the eastern forum of Aelia Capitolina. Traditionally, this was thought to be the gate of Herod's Antonia Fortress, which itself was alleged to be the location of Jesus' trial and Pontius Pilate's "Ecce homo" speech.

When later constructions narrowed the "Via Dolorosa", the two arches on either side of the central arch became incorporated into a succession of more modern buildings. The Basilica of Ecce Homo now preserves the northern arch, and the southern arch was incorporated into a monastery for Naqshbandi Uzbek dervishes in the 16th century. This was later demolished, taking the arch with it.

The city was without walls, protected by a light garrison of the Tenth Legion, during the Late Roman Period. The detachment at Jerusalem, which apparently encamped all over the city's western hill, was responsible for preventing Jews from returning to the city. Roman enforcement of this prohibition continued through the 4th century.
The urban plan of Aelia Capitolina was that of a typical Roman town wherein main thoroughfares crisscrossed the urban grid lengthwise and widthwise. The urban grid was based on the usual central north-south road ("cardo") and central east-west route ("decumanus"). However, as the main cardo ran up the western hill, and the Temple Mount blocked the eastward route of the main decumanus, a second pair of main roads was added; the secondary cardo ran down the Tyropoeon Valley, and the secondary decumanus ran just to the north of the Temple Mount. The main Hadrianic cardo terminated not far beyond its junction with the decumanus, where it reached the Roman garrison's encampment, but in the Byzantine era it was extended over the former camp to reach the southern walls of the city.

The two cardines converged near the "Damascus Gate", and a semicircular piazza covered the remaining space; in the piazza a columnar monument was constructed, hence the Arabic name for the gate - "Bab el-Amud" ("Gate of the Column"). Tetrapylones were constructed at the other junctions between the main roads.

This street pattern has been preserved in the Old City of Jerusalem to the present. The original thoroughfare, flanked by rows of columns and shops, was about 73 feet (22 meters) wide, but buildings have extended onto the streets over the centuries, and the modern lanes replacing the ancient grid are now quite narrow. The substantial remains of the western cardo have now been exposed to view near the junction with Suq el-Bazaar, and remnants of one of the tetrapylones are preserved in the 19th century Franciscan chapel at the junction of the Via Dolorosa and Suq Khan ez-Zeit.

As was standard for new Roman cities, Hadrian placed the city's main forum at the junction of the main cardo and decumanus, now the location for the (smaller) Muristan. Adjacent to the Forum, at the junction of the same cardo, and the other decumanus, Hadrian built a large temple to Venus, which later became the Church of the Holy Sepulchre; despite 11th century destruction, which resulted in the modern Church having a much smaller footprint, several boundary walls of Hadrian's temple have been found among the archaeological remains beneath the Church. The "Struthion Pool" lay in the path of the northern decumanus, so Hadrian placed vaulting over it, added a large pavement on top, and turned it into a secondary forum; the pavement can still be seen under the Convent of the Sisters of Zion.


Footnotes
Citations


</doc>
<doc id="2633" url="https://en.wikipedia.org/wiki?curid=2633" title="Aelian">
Aelian

Aelian or Aelianus may refer to:



</doc>
<doc id="2634" url="https://en.wikipedia.org/wiki?curid=2634" title="Aelianus Tacticus">
Aelianus Tacticus

Aelianus Tacticus (; fl. 2nd century AD), also known as Aelian (), was a Greek military writer who lived in Rome.

Aelian's military treatise in fifty-three chapters on the tactics of the Greeks, titled "On Tactical Arrays of the Greeks" (), is dedicated to the Emperor Hadrian, though this is probably a mistake for Trajan, and the date 106 has been assigned to it. It is a handbook of Greek, i.e. Macedonian, drill and tactics as practiced by the Hellenistic successors of Alexander the Great. The author claims to have consulted all the best authorities, the most important of which was a lost treatise on the subject by Polybius. Perhaps the chief value of Aelian's work lies in his critical account of preceding works on the art of war, and in the fullness of his technical details in matters of drill.

Aelian also gives a brief account of the constitution of a Roman army at that time. The work arose, he says, from a conversation he had with the emperor Nerva at Frontinus's house at Formiae. He promises a work on Naval Tactics also; but this, if it was written, is lost.

Critics of the 18th century — Guichard Folard and the Prince de Ligne — were unanimous in thinking Aelian greatly inferior to Arrian, but Aelian exercised a great influence both on his immediate successors, the Byzantines, and later on the Arabs, (who translated the text for their own use). The author of the "Strategikon" ascribed to the Emperor Maurice selectively used Aelian's work as a conceptional model, especially its preface. Emperor Leo VI the Wise incorporated much of Aelian's text in his own "Taktika". The Arabic version of Aelian was made about 1350. It was first translated into Latin by Theodore Gaza, published at Rome in 1487. The Greek editio princeps was edited by Francesco Robortello and published at Venice in 1552.

In spite of its academic nature, the copious details to be found in the treatise rendered it of the highest value to the army organisers of the 16th century, who were engaged in fashioning a regular military system out of the semi-feudal systems of previous generations. The Macedonian phalanx of Aelian had many points of resemblance to the solid masses of pikemen and the squadrons of cavalry of the Spanish and Dutch systems, and the translations made in the 16th century formed the groundwork of numerous books on drill and tactics.

The first significant reference to the influence of Aelian in the 16th century is a letter to Maurice of Nassau, Prince of Orange from his cousin William Louis, Count of Nassau-Dillenburg on December 8, 1594. The letter is influential in supporting the thesis of the early-modern Military Revolution. In the letter William Louis discusses the use of ranks by soldiers of Imperial Rome as discussed in Aelian's Tactica. Aelian was discussing the use of the counter march in the context of the Roman sword gladius and spear pilum. William Louis in a 'crucial leap' realised that the same technique could work for men with firearms.



</doc>
<doc id="2635" url="https://en.wikipedia.org/wiki?curid=2635" title="Agarose">
Agarose

Agarose is a polysaccharide, generally extracted from certain red seaweed. It is a linear polymer made up of the repeating unit of agarobiose, which is a disaccharide made up of -galactose and 3,6-anhydro--galactopyranose. Agarose is one of the two principal components of agar, and is purified from agar by removing agar's other component, agaropectin.

Agarose is frequently used in molecular biology for the separation of large molecules, especially DNA, by electrophoresis. Slabs of agarose gels (usually 0.7 - 2%) for electrophoresis are readily prepared by pouring the warm, liquid solution into a mold. A wide range of different agaroses of varying molecular weights and properties are commercially available for this purpose. Agarose may also be formed into beads and used in a number of chromatographic methods for protein purification.

Agarose is a linear polymer with a molecular weight of about 120,000, consisting of alternating -galactose and 3,6-anhydro--galactopyranose linked by α-(1→3) and β-(1→4) glycosidic bonds. The 3,6-anhydro--galactopyranose is an -galactose with an anhydro bridge between the 3 and 6 positions, although some -galactose units in the polymer may not contain the bridge. Some -galactose and -galactose units can be methylated, and pyruvate and sulfate are also found in small quantities.

Each agarose chain contains ~800 molecules of galactose, and the agarose polymer chains form helical fibres that aggregate into supercoiled structure with a radius of 20-30 nm. The fibers are quasi-rigid, and have a wide range of length depending on the agarose concentration. When solidified, the fibres form a three-dimensional mesh of channels of diameter ranging from 50 nm to >200 nm depending on the concentration of agarose used - higher concentrations yield lower average pore diameters. The 3-D structure is held together with hydrogen bonds and can therefore be disrupted by heating back to a liquid state.

Agarose is available as a white powder which dissolves in near-boiling water, and forms a gel when it cools. Agarose exhibits the phenomenon of thermal hysteresis in its liquid-to-gel transition, i.e. it gels and melts at different temperatures. The gelling and melting temperatures vary depending on the type of agarose. Standard agaroses derived from "Gelidium" has a gelling temperature of and a melting temperature of , while those derived from "Gracilaria", due to its higher methoxy substituents, has a gelling temperature of and melting temperature of . The melting and gelling temperatures may be dependent on the concentration of the gel, particularly at low gel concentration of less than 1%. The gelling and melting temperatures are therefore given at a specified agarose concentration.

Natural agarose contains uncharged methyl groups and the extent of methylation is directly proportional to the gelling temperature. Synthetic methylation however have the reverse effect, whereby increased methylation lowers the gelling temperature. A variety of chemically modified agaroses with different melting and gelling temperatures are available through chemical modifications.

The agarose in the gel forms a meshwork that contains pores, and the size of the pores depends on the concentration of agarose added. On standing the agarose gels are prone to syneresis (extrusion of water through the gel surface), but the process is slow enough to not interfere with the use of the gel.

Agarose gel can have high gel strength at low concentration, making it suitable as an anti-convection medium for gel electrophoresis. Agarose gels as dilute as 0.15% can form slabs for gel electrophoresis. The agarose polymer contains charged groups, in particular pyruvate and sulfate. These negatively charged groups can slow down the movement of DNA molecules in a process called electroendosmosis (EEO), and low EEO agarose is therefore generally preferred for use in agarose gel electrophoresis of nucleic acids. Zero EEO agaroses are also available but these may be undesirable for some applications as they may be made by adding positively charged groups that can affect subsequent enzyme reactions. Electroendosmosis is a reason agarose is used preferentially over agar as agaropectin in agar contains a significant amount of negatively charged sulphate and carboxyl groups. The removal of agaropectin in agarose substantially reduces the EEO, as well as reducing the non-specific adsorption of biomolecules to the gel matrix. However, for some applications such as the electrophoresis of serum protein, a high EEO may be desirable, and agaropectin may be added in the gel used.

The melting and gelling temperatures of agarose can be modified by chemical modifications, most commonly by hydroxyethylation, which reduces the number of intrastrand hydrogen bonds, resulting in lower melting and setting temperatures than standard agaroses. The exact temperature is determined by the degree of substitution, and many available low-melting-point (LMP) agaroses can remain fluid at range. This property allows enzymatic manipulations to be carried out directly after the DNA gel electrophoresis by adding slices of melted gel containing DNA fragment of interest to a reaction mixture. The LMP agarose contains fewer sulphates which can affect some enzymatic reactions, and is therefore preferably used for some applications. Hydroxyethylation may reduce the pore size by reducing the packing density of the agarose bundles, therefore LMP gel can also have an effect on the time and separation during electrophoresis. Ultra-low melting or gelling temperature agaroses may gel only at .

Agarose is a preferred matrix for work with proteins and nucleic acids as it has a broad range of physical, chemical and thermal stability, and its lower degree of chemical complexity also makes it less likely to interact with biomolecules. Agarose is most commonly used as the medium for analytical scale electrophoretic separation in agarose gel electrophoresis. Gels made from purified agarose have a relatively large pore size, making them useful for separation of large molecules, such as proteins and protein complexes >200 kilodaltons, as well as DNA fragments >100 basepairs. Agarose is also used widely for a number of other applications, for example immunodiffusion and immunoelectrophoresis, as the agarose fibers functions as an anchor for immunocomplexes.

Agarose gel electrophoresis is the routine method for resolving DNA in the laboratory. Agarose gels have lower resolving power for DNA than acrylamide gels, but they have greater range of separation, and are therefore usually used for DNA fragments with lengths of 50-20,000 bp (base pairs), although resolution of over 6 Mb is possible with pulsed field gel electrophoresis (PFGE). It can also be used to separate large protein molecules, and it is the preferred matrix for the gel electrophoresis of particles with effective radii larger than 5-10 nm.

The pore size of the gel affects the size of the DNA that can be sieved. The lower the concentration of the gel, the larger the pore size, and the larger the DNA that can be sieved. However low-concentration gels (0.1 - 0.2%) are fragile and therefore hard to handle, and the electrophoresis of large DNA molecules can take several days. The limit of resolution for standard agarose gel electrophoresis is around 750 kb. This limit can be overcome by PFGE, where alternating orthogonal electric fields are applied to the gel. The DNA fragments reorientate themselves when the applied field switches direction, but larger molecules of DNA take longer to realign themselves when the electric field is altered, while for smaller ones it is quicker, and the DNA can therefore be fractionated according to size.

Agarose gels are cast in a mold, and when set, usually run horizontally submerged in a buffer solution. Tris-acetate-EDTA and Tris-Borate-EDTA buffers are commonly used, but other buffers such as Tris-phosphate, barbituric acid-sodium barbiturate or Tris-barbiturate buffers may be used in other applications. The DNA is normally visualized by staining with ethidium bromide and then viewed under a UV light, but other methods of staining are available, such as SYBR Green, GelRed, methylene blue, and crystal violet. If the separated DNA fragments are needed for further downstream experiment, they can be cut out from the gel in slices for further manipulation.

Agarose gel matrix is often used for protein purification, for example, in column-based preparative scale separation as in gel filtration chromatography, affinity chromatography and ion exchange chromatography. It is however not used as a continuous gel, rather it is formed into porous beads or resins of varying fineness. The beads are highly porous so that protein may flow freely through the beads. These agarose-based beads are generally soft and easily crushed, so they should be used under gravity-flow, low-speed centrifugation, or low-pressure procedures. The strength of the resins can be improved by increased cross-linking and chemical hardening of the agarose resins, however such changes may also result in a lower binding capacity for protein in some separation procedures such as affinity chromatography.

Agarose is a useful material for chromatography because it does not absorb biomolecules to any significant extent, has good flow properties, and can tolerate extremes of pH and ionic strength as well as high concentration of denaturants such as 8M urea or 6M guanidine HCl. Examples of agarose-based matrix for gel filtration chromatography are Sepharose and WorkBeads 40 SEC (cross-linked beaded agarose), "Praesto" and Superose (highly cross-linked beaded agaroses), and Superdex (dextran covalently linked to agarose).

For affinity chromatography, beaded agarose is the most commonly used matrix resin for the attachment of the ligands that bind protein. The ligands are linked covalently through a spacer to activated hydroxyl groups of agarose bead polymer. Proteins of interest can then be selectively bound to the ligands to separate them from other proteins, after which it can be eluted. The agarose beads used are typically of 4% and 6% densities with a high binding capacity for protein.

Agarose plate may sometimes be used instead of agar for culturing organisms as agar may contain impurities that can affect the growth of the organism or some downstream procedures such as polymerase chain reaction (PCR). Agarose is also harder than agar and may therefore be preferable where greater gel strength is necessary, and its lower gelling temperature may prevent causing thermal shock to the organism when the cells are suspended in liquid before gelling. It may be used for the culture of strict autotrophic bacteria, plant protoplast, "Caenorhabditis elegans", other organisms and various cell lines.

Agarose is often used as a support for the tri-dimensional culture of human and animal cells. Because agarose forms a non-cytotoxic hydrogels, it can be utilized to reproduce the natural environment of cells in the human body, the extracellular matrix. However, agarose forms a stiff inert hydrogel that does not carry any biological information, thus the human and animal cells can not adhere to the polysaccharide. Because of these specifics properties, agarose hydrogel mimics the natural environment of cartilage cells and have been shown to be support the differentiation of chondrocytes into cartilage. In order to modify the mechanical properties of agarose to reproduce the natural environment of other human cells, agarose can be chemically modified through the precise oxidation of the primary alcohol of the D-galactose into carboxylic acid. This chemical modification provides a novel class of materials named carboxylated agarose. Through the control over the number of carboxylated D-galactose on the polysaccharide backbone, the mechanical properties of the resulting hydrogel can be precisely controlled. These carboxylated agarose hydrogels can be then covalently bond to peptides to form hydrogel on which cells can adhere. These carboxylated agarose hydrogels have been shown to direct the organization of human endothelial cells into polarized lumens.
Mixing of fully carboxylated agarose with natural agarose can be used to make hydrogels that span a whole range of mechanical properties.

Agarose is sometimes used instead of agar to measure microorganism motility and mobility. Motile species will be able to migrate, albeit slowly, throughout the porous gel and infiltration rates can then be visualized. The gel's porosity is directly related to the concentration of agar or agarose in the medium, so different concentration gels may be used to assess a cell's swimming, swarming, gliding and twitching motility. Under-agarose cell migration assay may be used to measure chemotaxis and chemokinesis. A layer of agarose gel is placed between a cell population and a chemoattractant. As a concentration gradient develops from the diffusion of the chemoattractant into the gel, various cell populations requiring different stimulation levels to migrate can then be visualized over time using microphotography as they tunnel upward through the gel against gravity along the gradient.



</doc>
<doc id="2637" url="https://en.wikipedia.org/wiki?curid=2637" title="Atomic absorption spectroscopy">
Atomic absorption spectroscopy

Atomic absorption spectroscopy (AAS) and atomic emission spectroscopy (AES) is a spectroanalytical procedure for the quantitative determination of chemical elements using the absorption of optical radiation (light) by free atoms in the gaseous state. Atomic absorption spectroscopy is based on absorption of light by free metallic ions.

In analytical chemistry the technique is used for determining the concentration of a particular element (the analyte) in a sample to be analyzed. AAS can be used to determine over 70 different elements in solution, or directly in solid samples via electrothermal vaporization, and is used in pharmacology, biophysics,
archaeology and toxicology research.

Atomic emission spectroscopy was first used as an analytical technique, and the underlying principles were established in the second half of the 19th century by Robert Wilhelm Bunsen and Gustav Robert Kirchhoff, both professors at the University of Heidelberg, Germany.

The modern form of AAS was largely developed during the 1950s by a team of Australian chemists. They were led by Sir Alan Walsh at the Commonwealth Scientific and Industrial Research Organisation (CSIRO), Division of Chemical Physics, in Melbourne, Australia.

Atomic absorption spectrometry has many uses in different areas of chemistry such as clinical analysis of metals in biological fluids and tissues such as whole blood, plasma, urine, saliva, brain tissue, liver, hair, muscle tissue, semen, in some pharmaceutical manufacturing processes, minute quantities of a catalyst that remain in the final drug product, and analyzing water for its metal content.

The technique makes use of the atomic absorption spectrum of a sample in order to assess the concentration of specific analytes within it. It requires standards with known analyte content to establish the relation between the measured absorbance and the analyte concentration and relies therefore on the Beer-Lambert Law.

In order to analyze a sample for its atomic constituents, it has to be atomized. The atomizers most commonly used nowadays are flames and electrothermal (graphite tube) atomizers. The atoms should then be irradiated by optical radiation, and the radiation source could be an element-specific line radiation source or a continuum radiation source. The radiation then passes through a monochromator in order to separate the element-specific radiation from any other radiation emitted by the radiation source, which is finally measured by a detector.

The atomizers most commonly used nowadays are (spectroscopic) flames and electrothermal (graphite tube) atomizers. Other atomizers, such as glow-discharge atomization, hydride atomization, or cold-vapor atomization might be used for special purposes.

The oldest and most commonly used atomizers in AAS are flames, principally the air-acetylene flame with a temperature of about 2300 °C and the nitrous oxide system (NO)-acetylene flame with a temperature of about 2700 °C. The latter flame, in addition, offers a more reducing environment, being ideally suited for analytes with high affinity to oxygen.

Liquid or dissolved samples are typically used with flame atomizers. The sample solution is aspirated by a pneumatic analytical nebulizer, transformed into an aerosol, which is introduced into a spray chamber, where it is mixed with the flame gases and conditioned in a way that only the finest aerosol droplets (< 10 μm) enter the flame. This conditioning process reduces interference, but only about 5% of the aerosolized solution reaches the flame because of it.

On top of the spray chamber is a burner head that produces a flame that is laterally long (usually 5–10 cm) and only a few mm deep. The radiation beam passes through this flame at its longest axis, and the flame gas flow-rates may be adjusted to produce the highest concentration of free atoms. The burner height may also be adjusted, so that the radiation beam passes through the zone of highest atom cloud density in the flame, resulting in the highest sensitivity.

The processes in a flame include the stages of desolvation (drying) in which the solvent is evaporated and the dry sample nano-particles remain, vaporization (transfer to the gaseous phase) in which the solid particles are converted into gaseous molecule, atomization in which the molecules are dissociated into free atoms, and ionization where (depending on the ionization potential of the analyte atoms and the energy available in a particular flame) atoms may be in part converted to gaseous ions.

Each of these stages includes the risk of interference in case the degree of phase transfer is different for the analyte in the calibration standard and in the sample. Ionization is generally undesirable, as it reduces the number of atoms that are available for measurement, i.e., the sensitivity.

In flame AAS a steady-state signal is generated during the time period when the sample is aspirated. This technique is typically used for determinations in the mg L range, and may be extended down to a few μg L for some elements.

Electrothermal AAS (ET AAS) using graphite tube atomizers was pioneered by Boris V. L’vov at the Saint Petersburg Polytechnical Institute, Russia, since the late 1950s, and investigated in parallel by Hans Massmann at the Institute of Spectrochemistry and Applied Spectroscopy (ISAS) in Dortmund, Germany.

Although a wide variety of graphite tube designs have been used over the years, the dimensions nowadays are typically 20–25 mm in length and 5–6 mm inner diameter. With this technique liquid/dissolved, solid and gaseous samples may be analyzed directly. A measured volume (typically 10–50 μL) or a weighed mass (typically around 1 mg) of a solid sample are introduced into the graphite tube and subject to a temperature program. This typically consists of stages, such as drying – the solvent is evaporated; pyrolysis – the majority of the matrix constituents are removed; atomization – the analyte element is released to the gaseous phase; and cleaning – eventual residues in the graphite tube are removed at high temperature.

The graphite tubes are heated via their ohmic resistance using a low-voltage high-current power supply; the temperature in the individual stages can be controlled very closely, and temperature ramps between the individual stages facilitate separation of sample components. Tubes may be heated transversely or longitudinally, where the former ones have the advantage of a more homogeneous temperature distribution over their length. The so-called stabilized temperature platform furnace (STPF) concept, proposed by Walter Slavin, based on research of Boris L’vov, makes ET AAS essentially free from interference. The major components of this concept are atomization of the sample from a graphite platform inserted into the graphite tube (L’vov platform) instead of from the tube wall in order to delay atomization until the gas phase in the atomizer has reached a stable temperature; use of a chemical modifier in order to stabilize the analyte to a pyrolysis temperature that is sufficient to remove the majority of the matrix components; and integration of the absorbance over the time of the transient absorption signal instead of using peak height absorbance for quantification.

In ET AAS a transient signal is generated, the area of which is directly proportional to the mass of analyte (not its concentration) introduced into the graphite tube. This technique has the advantage that any kind of sample, solid, liquid or gaseous, can be analyzed directly. Its sensitivity is 2–3 orders of magnitude higher than that of flame AAS, so that determinations in the low μg L range (for a typical sample volume of 20 µL) and ng g range (for a typical sample mass of 1 mg) can be carried out. It shows a very high degree of freedom from interferences, so that ET AAS might be considered the most robust technique available nowadays for the determination of trace elements in complex matrices.

While flame and electrothermal vaporizers are the most common atomization techniques, several other atomization methods are utilized for specialized use.

A glow-discharge device (GD) serves as a versatile source, as it can simultaneously introduce and atomize the sample. The glow discharge occurs in a low-pressure argon gas atmosphere between 1 and 10 torr. In this atmosphere lies a pair of electrodes applying a DC voltage of 250 to 1000 V to break down the argon gas into positively charged ions and electrons. These ions, under the influence of the electric field, are accelerated into the cathode surface containing the sample, bombarding the sample and causing neutral sample atom ejection through the process known as sputtering. The atomic vapor produced by this discharge is composed of ions, ground state atoms, and fraction of excited atoms. When the excited atoms relax back into their ground state, a low-intensity glow is emitted, giving the technique its name.

The requirement for samples of glow discharge atomizers is that they are electrical conductors. Consequently, atomizers are most commonly used in the analysis of metals and other conducting samples. However, with proper modifications, it can be utilized to analyze liquid samples as well as nonconducting materials by mixing them with a conductor (e.g. graphite).

Hydride generation techniques are specialized in solutions of specific elements. The technique provides a means of introducing samples containing arsenic, antimony, selenium, bismuth, and lead into an atomizer in the gas phase. With these elements, hydride atomization enhances detection limits by a factor of 10 to 100 compared to alternative methods. Hydride generation occurs by adding an acidified aqueous solution of the sample to a 1% aqueous solution of sodium borohydride, all of which is contained in a glass vessel. The volatile hydride generated by the reaction that occurs is swept into the atomization chamber by an inert gas, where it undergoes decomposition. This process forms an atomized form of the analyte, which can then be measured by absorption or emission spectrometry.

The cold-vapor technique is an atomization method limited to only the determination of mercury, due to it being the only metallic element to have a large enough vapor pressure at ambient temperature. Because of this, it has an important use in determining organic mercury compounds in samples and their distribution in the environment. The method initiates by converting mercury into Hg by oxidation from nitric and sulfuric acids, followed by a reduction of Hg with tin(II) chloride. The mercury, is then swept into a long-pass absorption tube by bubbling a stream of inert gas through the reaction mixture. The concentration is determined by measuring the absorbance of this gas at 253.7 nm. Detection limits for this technique are in the parts-per-billion range making it an excellent mercury detection atomization method.

We have to distinguish between line source AAS (LS AAS) and continuum source AAS (CS AAS). In classical LS AAS, as it has been proposed by Alan Walsh, the high spectral resolution required for AAS measurements is provided by the radiation source itself that emits the spectrum of the analyte in the form of lines that are narrower than the absorption lines. Continuum sources, such as deuterium lamps, are only used for background correction purposes. The advantage of this technique is that only a medium-resolution monochromator is necessary for measuring AAS; however, it has the disadvantage that usually a separate lamp is required for each element that has to be determined. In CS AAS, in contrast, a single lamp, emitting a continuum spectrum over the entire spectral range of interest is used for all elements. Obviously, a high-resolution monochromator is required for this technique, as will be discussed later.

Hollow cathode lamps (HCL) are the most common radiation source in LS AAS. Inside the sealed lamp, filled with argon or neon gas at low pressure, is a cylindrical metal cathode containing the element of interest and an anode. A high voltage is applied across the anode and cathode, resulting in an ionization of the fill gas. The gas ions are accelerated towards the cathode and, upon impact on the cathode, sputter cathode material that is excited in the glow discharge to emit the radiation of the sputtered material, i.e., the element of interest. In the majority of cases single element lamps are used, where the cathode is pressed out of predominantly compounds of the target element. Multi-element lamps are available with combinations of compounds of the target elements pressed in the cathode. Multi element lamps produce slightly less sensitivity than single element lamps and the combinations of elements have to be selected carefully to avoid spectral interferences. Most multi-element lamps combine a handful of elements, e.g.: 2 - 8. Atomic Absorption Spectrometers can feature as few as 1-2 hollow cathode lamp positions or in automated multi-element spectrometers, a 8-12 lamp positions may be typically available.

Electrodeless discharge lamps (EDL) contain a small quantity of the analyte as a metal or a salt in a quartz bulb together with an inert gas, typically argon gas, at low pressure. The bulb is inserted into a coil that is generating an electromagnetic radio frequency field, resulting in a low-pressure inductively coupled discharge in the lamp. The emission from an EDL is higher than that from an HCL, and the line width is generally narrower, but EDLs need a separate power supply and might need a longer time to stabilize.

Deuterium HCL or even hydrogen HCL and deuterium discharge lamps are used in LS AAS for background correction purposes. The radiation intensity emitted by these lamps decreases significantly with increasing wavelength, so that they can be only used in the wavelength range between 190 and about 320 nm.

When a continuum radiation source is used for AAS, it is necessary to use a high-resolution monochromator, as will be discussed later. In addition, it is necessary that the lamp emits radiation of intensity at least an order of magnitude above that of a typical HCL over the entire wavelength range from 190 nm to 900 nm. A special high-pressure xenon short arc lamp, operating in a hot-spot mode has been developed to fulfill these requirements.

As already pointed out above, there is a difference between medium-resolution spectrometers that are used for LS AAS and high-resolution spectrometers that are designed for CS AAS. The spectrometer includes the spectral sorting device (monochromator) and the detector.

In LS AAS the high resolution that is required for the measurement of atomic absorption is provided by the narrow line emission of the radiation source, and the monochromator simply has to resolve the analytical line from other radiation emitted by the lamp.This can usually be accomplished with a band pass between 0.2 and 2 nm, i.e., a medium-resolution monochromator. Another feature to make LS AAS element-specific is modulation of the primary radiation and the use of a selective amplifier that is tuned to the same modulation frequency, as already postulated by Alan Walsh. This way any (unmodulated) radiation emitted for example by the atomizer can be excluded, which is imperative for LS AAS. Simple monochromators of the Littrow or (better) the Czerny-Turner design are typically used for LS AAS. Photomultiplier tubes are the most frequently used detectors in LS AAS, although solid state detectors might be preferred because of their better signal-to-noise ratio.

When a continuum radiation source is used for AAS measurement it is indispensable to work with a high-resolution monochromator. The resolution has to be equal to or better than the half width of an atomic absorption line (about 2 pm) in order to avoid losses of sensitivity and linearity of the calibration graph. The research with high-resolution (HR) CS AAS was pioneered by the groups of O’Haver and Harnly in the US, who also developed the (up until now) only simultaneous multi-element spectrometer for this technique. The break-through, however, came when the group of Becker-Ross in Berlin, Germany, built a spectrometer entirely designed for HR-CS AAS. The first commercial equipment for HR-CS AAS was introduced by Analytik Jena (Jena, Germany) at the beginning of the 21st century, based on the design proposed by Becker-Ross and Florek. These spectrometers use a compact double monochromator with a prism pre-monochromator and an echelle grating monochromator for high resolution. A linear charge coupled device (CCD) array with 200 pixels is used as the detector. The second monochromator does not have an exit slit; hence the spectral environment at both sides of the analytical line becomes visible at high resolution. As typically only 3–5 pixels are used to measure the atomic absorption, the other pixels are available for correction purposes. One of these corrections is that for lamp flicker noise, which is independent of wavelength, resulting in measurements with very low noise level; other corrections are those for background absorption, as will be discussed later.

The relatively small number of atomic absorption lines (compared to atomic emission lines) and their narrow width (a few pm) make spectral overlap rare; there are only few examples known that an absorption line from one element will overlap with another. Molecular absorption, in contrast, is much broader, so that it is more likely that some molecular absorption band will overlap with an atomic line. This kind of absorption might be caused by un-dissociated molecules of concomitant elements of the sample or by flame gases. We have to distinguish between the spectra of di-atomic molecules, which exhibit a pronounced fine structure, and those of larger (usually tri-atomic) molecules that don't show such fine structure. Another source of background absorption, particularly in ET AAS, is scattering of the primary radiation at particles that are generated in the atomization stage, when the matrix could not be removed sufficiently in the pyrolysis stage.

All these phenomena, molecular absorption and radiation scattering, can result in artificially high absorption and an improperly high (erroneous) calculation for the concentration or mass of the analyte in the sample. There are several techniques available to correct for background absorption, and they are significantly different for LS AAS and HR-CS AAS.

In LS AAS background absorption can only be corrected using instrumental techniques, and all of them are based on two sequential measurements, firstly, total absorption (atomic plus background), secondly, background absorption only, and the difference of the two measurements gives the net atomic absorption. Because of this, and because of the use of additional devices in the spectrometer, the signal-to-noise ratio of background-corrected signals is always significantly inferior compared to uncorrected signals. It should also be pointed out that in LS AAS there is no way to correct for (the rare case of) a direct overlap of two atomic lines. In essence there are three techniques used for background correction in LS AAS:

This is the oldest and still most commonly used technique, particularly for flame AAS. In this case, a separate source (a deuterium lamp) with broad emission is used to measure the background absorption over the entire width of the exit slit of the spectrometer. The use of a separate lamp makes this technique the least accurate one, as it cannot correct for any structured background. It also cannot be used at wavelengths above about 320 nm, as the emission intensity of the deuterium lamp becomes very weak. The use of deuterium HCL is preferable compared to an arc lamp due to the better fit of the image of the former lamp with that of the analyte HCL.

This technique (named after their inventors) is based on the line-broadening and self-reversal of emission lines from HCL when high current is applied. Total absorption is measured with normal lamp current, i.e., with a narrow emission line, and background absorption after application of a high-current pulse with the profile of the self-reversed line, which has little emission at the original wavelength, but strong emission on both sides of the analytical line. The advantage of this technique is that only one radiation source is used; among the disadvantages are that the high-current pulses reduce lamp lifetime, and that the technique can only be used for relatively volatile elements, as only those exhibit sufficient self-reversal to avoid dramatic loss of sensitivity. Another problem is that background is not measured at the same wavelength as total absorption, making the technique unsuitable for correcting structured background.

An alternating magnetic field is applied at the atomizer (graphite furnace) to split the absorption line into three components, the π component, which remains at the same position as the original absorption line, and two σ components, which are moved to higher and lower wavelengths, respectively. Total absorption is measured without magnetic field and background absorption with the magnetic field on. The π component has to be removed in this case, e.g. using a polarizer, and the σ components do not overlap with the emission profile of the lamp, so that only the background absorption is measured. The advantages of this technique are that total and background absorption are measured with the same emission profile of the same lamp, so that any kind of background, including background with fine structure can be corrected accurately, unless the molecule responsible for the background is also affected by the magnetic field and using a chopper as a polariser reduces the signal to noise ratio. While the disadvantages are the increased complexity of the spectrometer and power supply needed for running the powerful magnet needed to split the absorption line.

In HR-CS AAS background correction is carried out mathematically in the software using information from detector pixels that are not used for measuring atomic absorption; hence, in contrast to LS AAS, no additional components are required for background correction.

It has already been mentioned that in HR-CS AAS lamp flicker noise is eliminated using correction pixels. In fact, any increase or decrease in radiation intensity that is observed to the same extent at all pixels chosen for correction is eliminated by the correction algorithm. This obviously also includes a reduction of the measured intensity due to radiation scattering or molecular absorption, which is corrected in the same way. As measurement of total and background absorption, and correction for the latter, are strictly simultaneous (in contrast to LS AAS), even the fastest changes of background absorption, as they may be observed in ET AAS, do not cause any problem. In addition, as the same algorithm is used for background correction and elimination of lamp noise, the background corrected signals show a much better signal-to-noise ratio compared to the uncorrected signals, which is also in contrast to LS AAS.

The above technique can obviously not correct for a background with fine structure, as in this case the absorbance will be different at each of the correction pixels. In this case HR-CS AAS is offering the possibility to measure correction spectra of the molecule(s) that is (are) responsible for the background and store them in the computer. These spectra are then multiplied with a factor to match the intensity of the sample spectrum and subtracted pixel by pixel and spectrum by spectrum from the sample spectrum using a least-squares algorithm. This might sound complex, but first of all the number of di-atomic molecules that can exist at the temperatures of the atomizers used in AAS is relatively small, and second, the correction is performed by the computer within a few seconds. The same algorithm can actually also be used to correct for direct line overlap of two atomic absorption lines, making HR-CS AAS the only AAS technique that can correct for this kind of spectral interference.




</doc>
<doc id="2639" url="https://en.wikipedia.org/wiki?curid=2639" title="Arthur St. Clair">
Arthur St. Clair

Arthur St. Clair ( – August 31, 1818) was a Scottish-American soldier and politician. Born in Thurso, Scotland, he served in the British Army during the French and Indian War before settling in Pennsylvania, where he held local office. During the American Revolutionary War, he rose to the rank of major general in the Continental Army, but lost his command after a controversial retreat from Fort Ticonderoga.

After the war, he served as President of the Continental Congress, which during his term passed the Northwest Ordinance. He was then made governor of the Northwest Territory in 1788, and then the portion that would become Ohio in 1800. In 1791, St. Clair commanded the American forces in what was the United States's worst ever defeat by the American Indians. Politically out-of-step with the Jefferson administration, he was replaced as governor in 1802.

St. Clair was born in Thurso, Caithness, Scotland. Little is known of his early life. Early biographers estimated his year of birth as 1734, but subsequent historians uncovered a birth date of March 23, 1736, which in the modern calendar system means that he was born in 1737. His parents, unknown to early biographers, were probably William Sinclair, a merchant, and Elizabeth Balfour. He reportedly attended the University of Edinburgh before being apprenticed to the renowned physician William Hunter.

In 1757, St. Clair purchased a commission in the British Army, Royal American Regiment, and came to America with Admiral Edward Boscawen's fleet for the French and Indian War. He served under General Jeffery Amherst at the capture of Louisburg, Nova Scotia on July 26, 1758. On April 17, 1759, he received a lieutenant's commission and was assigned under the command of General James Wolfe, under whom he served at the Battle of the Plains of Abraham which resulted in the capture of Quebec City.

On April 16, 1762, he resigned his commission, and, in 1764, he settled in Ligonier Valley, Pennsylvania, where he purchased land and erected mills. He was the largest landowner in Western Pennsylvania.

In 1770, St. Clair became a justice of the court, of quarter sessions and of common pleas, a member of the proprietary council, a justice, recorder, and clerk of the orphans' court, and prothonotary of Bedford and Westmoreland counties.

In 1774, the colony of Virginia took claim of the area around Pittsburgh, Pennsylvania, and some residents of Western Pennsylvania took up arms to eject them. St. Clair issued an order for the arrest of the officer leading the Virginia troops. Lord Dunmore's War eventually settled the boundary dispute.

By the mid-1770s, St. Clair considered himself more of an American than a British subject. In January 1776, he accepted a commission in the Continental Army as a colonel of the 3rd Pennsylvania Regiment. He first saw service in the later days of the Quebec invasion, where he saw action in the Battle of Trois-Rivières. He was appointed a brigadier general in August 1776, and was sent by Gen. George Washington to help organize the New Jersey militia. He took part in George Washington's crossing of the Delaware River on the night of December 25–26, 1776, before the Battle of Trenton on the morning of December 26. Many biographers credit St. Clair with the strategy that led to Washington's capture of Princeton, New Jersey on January 3, 1777. St. Clair was promoted to major general in February 1777.

In April 1777, St. Clair was sent to defend Fort Ticonderoga. His small garrison could not resist British General John Burgoyne's larger force in the Saratoga campaign. St. Clair was forced to retreat at the Siege of Fort Ticonderoga on July 5, 1777. He withdrew his forces and played no further part in the campaign. In 1778 he was court-martialed for the loss of Ticonderoga. The court exonerated him and he returned to duty, although he was no longer given any battlefield commands. He still saw action, however, as an aide-de-camp to General Washington, who retained a high opinion of him. St. Clair was at Yorktown when Lord Cornwallis surrendered his army.

St. Clair was a member of the Pennsylvania Council of Censors in 1783, and was elected a delegate to the Confederation Congress, serving from November 2, 1785, until November 28, 1787. Chaos ruled the day in early 1787 with Shays's Rebellion in full force and the states refusing to settle land disputes or contribute to the now six-year-old federal government. On February 2, 1787, the delegates finally gathered into a quorum and elected St. Clair to a one-year term as President of the Continental Congress. Congress enacted its most important piece of legislation, the Northwest Ordinance, during St. Clair's tenure as president. Time was running out for the Confederation Congress, however; during St. Clair's presidency, the Philadelphia Convention was drafting a new United States Constitution, which would abolish the old Congress.

Under the Northwest Ordinance of 1787, which created the Northwest Territory, General St. Clair was appointed governor of what is now Ohio, Indiana, Illinois, Michigan, along with parts of Wisconsin and Minnesota. He named Cincinnati, Ohio, after the Society of the Cincinnati, and it was there that he established his home.

As Governor, he formulated Maxwell's Code (named after its printer, William Maxwell), the first written laws of the territory. He also sought to end Native American claims to Ohio land and clear the way for white settlement. In 1789, he succeeded in getting certain Indians to sign the Treaty of Fort Harmar, but many native leaders had not been invited to participate in the negotiations, or had refused to do so. Rather than settling the Indians' claims, the treaty provoked them to further resistance in what is also sometimes known as the "Northwest Indian War" (or "Little Turtle's War"). Mutual hostilities led to a campaign by General Josiah Harmar, whose 1,500 militiamen were defeated by the Indians in October 1790.

In March 1791, St. Clair succeeded Harmar as commander of the United States Army and was commissioned as a major general. He personally led a punitive expedition involving two Regular Army regiments and some militia. In October 1791 as an advance post for his campaign, Fort Jefferson (Ohio) was built under the direction of General Arthur St. Clair. Located in present-day Darke County in far western Ohio, the fort was built of wood and intended primarily as a supply depot; accordingly, it was originally named Fort Deposit.

One month later, near modern-day Fort Recovery, his force advanced to the location of Indian settlements near the headwaters of the Wabash River, but on November 4 they were routed in battle by a tribal confederation led by Miami Chief Little Turtle and Shawnee chief Blue Jacket. They were aided by British collaborators Alexander McKee and Simon Girty. More than 600 soldiers and scores of women and children were killed in the battle, which has since borne the name "St. Clair's Defeat", also known as the "Battle of the Wabash", the "Columbia Massacre," or the "Battle of a Thousand Slain". It remains the greatest defeat of a US Army by Native Americans in history, with about 623 American soldiers killed in action and about 50 Native Americans killed. The wounded were many, including St. Clair and Capt. Robert Benham.

Although an investigation exonerated him, St. Clair resigned his army commission in March 1792 at the request of President Washington, but he continued to serve as Governor of the Northwest Territory.
A Federalist, St. Clair hoped to see two states made of the Ohio Territory in order to increase Federalist power in Congress. However, he was opposed by Ohio Democratic-Republicans for what were perceived as his partisanship, high-handedness, and arrogance in office. In 1802, St. Clair remarked the U.S. Congress had no power to interfere in the affairs of those in the Ohio Territory. He also stated the people of the territory "are no more bound by an act of Congress than we would be bound by an edict of the first consul of France." This led President Thomas Jefferson to remove him from office as territorial governor. He thus played no part in the organizing of the state of Ohio in 1803.

The first Ohio Constitution provided for a weak governor and a strong legislature, in part as a reaction to St. Clair's method of governance.

St. Clair met Phoebe Bayard, a member of one of the most prominent families in Boston, and they were married in 1760. Miss Bayard's mother's maiden name was Bowdoin and she was the sister of James Bowdoin, colonial governor of Massachusetts.

In retirement St. Clair lived with his daughter, Louisa St. Clair Robb, and her family on the ridge between Ligonier and Greensburg.

Arthur St. Clair died in poverty in Greensburg, Pennsylvania, on August 31, 1818, at the age of 81. His remains are buried under a Masonic monument in St. Clair Park in downtown Greensburg. St Clair had been a petitioner for a Charter for Nova Caesarea
Lodge #10 in Cincinnati, Ohio in 1791. This Lodge exists today, as Nova Caesarea Harmony #2. His wife Phoebe died shortly after and is buried beside him.

A portion of the Hermitage, St. Clair's home in Oak Grove, Pennsylvania (north of Ligonier), was later moved to Ligonier, Pennsylvania, where it is now preserved, along with St. Clair artifacts and memorabilia at the Fort Ligonier Museum.

An American Civil War steamer was named USS "St. Clair".

Places named in honor of Arthur St. Clair include:

In Pennsylvania:

In Ohio:
Other States:

In Scotland:

Notes
Books



</doc>
<doc id="2640" url="https://en.wikipedia.org/wiki?curid=2640" title="Ajaccio">
Ajaccio

Ajaccio (, , , ; ; ) is a French commune, prefecture of the department of Corse-du-Sud, and head office of the "Collectivité territoriale de Corse" (capital city of Corsica). It is also the largest settlement on the island. Ajaccio is located on the west coast of the island of Corsica, southeast of Marseille.

The original city went into decline in the Middle Ages, but began to prosper again after the Genoese built a citadel in 1492 to the south of the earlier settlement. After the Corsican Republic was declared in 1755 the Genoese continued to hold several citadels, including Ajaccio, until the French took control of the island.

The inhabitants of the commune are known as "Ajacciens" or "Ajacciennes". The most famous of these is Napoleon Bonaparte who was born in Ajaccio in 1769, and whose ancestral home, the Maison Bonaparte, is now a museum. Other dedications to him in the city include Ajaccio Napoleon Bonaparte Airport.

Ajaccio is located on the west coast of the island of Corsica, southeast of Marseille. The commune occupies a sheltered position at the foot of wooded hills on the northern shore of the Gulf of Ajaccio between Gravona and the "pointe de la Parata" and includes the "îles Sanguinaires" (Bloody Islands). The harbour lies to the east of the original citadel below a hill overlooking a peninsula which protects the harbour in the south where the Quai de la Citadelle and the Jettée de la Citadelle are. The modern city not only encloses the entire harbour but takes up the better part of the Gulf of Ajaccio and in suburban form extends for some miles up the valley of the Gravona River. The flow from that river is nearly entirely consumed as the city's water supply. Many beaches and coves border its territory and the terrain is particularly rugged in the west where the highest point is .

Although the commune of Ajaccio has a large area (82.03 km), only a small portion of this is urbanized. Therefore, the urban area of Ajaccio is located in the east of the commune on a narrow coastal strip forming a densely populated arc. The rest of the territory is natural with habitation of little importance and spread thinly. Suburbanization occurs north and east of the main urban area.

The original urban core, close to the old marshy plain of "Cannes" was abandoned in favour of the current city which was built near the "Punta della Lechia". It has undergone various improvements, particularly under Napoleon, who originated the two current major structural arteries (the "Cours Napoleon" oriented north-south and the "Cours Grandval" oriented east-west).

Ajaccio experienced a demographic boom in the 1960s, which explains why 85% of dwellings are post-1949. This is reflected in the layout of the city which is marked by very large areas of low-rise buildings and concrete towers, especially on the heights ("Jardins de l'Empereur") and in the north of the city - e.g. the waterfront, "Les Cannes", and "Les Salines". A dichotomy appears in the landscape between the old city and the imposing modern buildings. Ajaccio gives the image of a city built on two different levels.

The city has a Mediterranean climate which is "Csa" in the Köppen climate classification. The average annual sunshine is 2726 hours.

There are important local climatic variations, especially with wind exposure and total precipitation, between the city centre, the airport, and the "îles Sanguinaires". The annual average rainfall is at the "Campo dell'Oro" weather station (as per the chart) and at the "Parata": the third-driest place in metropolitan France. The heat and dryness of summer are somewhat tempered by the proximity of the Mediterranean Sea except when the sirocco is blowing. In autumn and spring, heavy rain-storm episodes may occur. Winters are mild and snow is rare. Ajaccio is the French city which holds the record for the number of thunderstorms in the reference period 1971-2000 with an average of 39 thunderstorm days per year.

On 14 September 2009, the city was hit by a tornado with an intensity of F1 on the Fujita scale. There was little damage except torn billboards, flying tiles, overturned cars, and broken windows but no casualties. 

Weather Data for Ajaccio
Several hypotheses have been advanced as to the etymology of the name "Ajaccio" ("Aiacciu" in Corsican, "Addiazzo" on old documents). Among these, the most prestigious suggests that the city was founded by the Greek legendary hero "Ajax" and named after him. Other more realistic explanations are, for example, that the name could be related to the Tuscan "agghiacciu" meaning "sheep pens". Another explanation, supported by Byzantine sources from around the year 600AD called the city "Agiation" which suggests a possible Greek origin for the word, "agathè" could mean "good luck" or "good mooring" (this was also the root of the name of the city of Agde).

The city was not mentioned by the Greek geographer Ptolemy of Alexandria in the 2nd century AD despite the presence of a place called "Ourkinion" in the "Cinarca" area. It is likely that the city of Ajaccio had its first development at this time. The 2nd century was a period of prosperity in the Mediterranean basin (the Pax Romana) and there was a need for a proper port at the head of the several valleys that lead to the Gulf able to accommodate large ships. Some important underwater archaeological discoveries recently made of Roman ships tend to confirm this. 

Further excavations conducted recently led to the discovery of important early Christian remains likely to significantly a reevaluation upwards of the size of Ajaccio city in Late Antiquity and the beginning of the Middle Ages. The city was in any case already significant enough to be the seat of a diocese, mentioned by Pope Gregory the Great in 591. The city was then further north than the location chosen later by the Genoese - in the location of the existing quarters of "Castel Vecchio" and "Sainte-Lucie".

The earliest certain written record of a settlement at Ajaccio with a name ancestral to its name was the exhortation in Epistle 77 written in 601AD by Gregory the great to the Defensor Boniface, one of two known rectors of the early Corsican church, to tell him not to leave Aléria and Adjacium without bishops. There is no earlier use of the term and Adjacium is not an attested Latin word, which probably means that it is a Latinization of a word in some other language. The Ravenna Cosmography of about 700 AD cites Agiation, which sometimes is taken as evidence of a prior Greek city, as -ion appears to be a Greek ending. There is, however, no evidence at all of a Greek presence on the west coast and the Ionians at Aléria on the east coast had been expelled by the Etruscans long before Roman domination.

Ptolemy, who must come the closest to representing indigenous names, lists the Lochra River just south of a feature he calls the "sandy shore" on the southwest coast. If the shore is the Campo dell'Oro (Place of Gold) the Lochra would seem to be the combined mouth of the Gravona and Prunelli Rivers, neither one of which sounds like Lochra.

North of there was a Roman city, Ourchinion. The western coastline was so distorted, however, that it is impossible to say where Adjacium was; certainly, he would have known its name and location if he had had any first-hand knowledge of the island and if in fact it was there. Ptolemy's Ourchinion is further north than Ajaccio and does not have the same name. It could be Sagone. The lack of correspondence between Ptolemaic and historical names known to be ancient has no defense except in the case of the two Roman colonies, Aleria and Mariana. In any case the population of the region must belong to Ptolemy's Tarabeni or Titiani people, neither of which are ever heard about again. 

The population of the city throughout the centuries maintained an oral tradition that it had originally been Roman. Travellers of the 19th century could point to the Hill of San Giovanni on the northwest shore of the Gulf of Ajaccio, which still had a cathedral said to have been the 6th-century seat of the Bishop of Ajaccio. The Castello Vecchio ("old castle"), a ruined citadel, was believed to be Roman but turned out to have Gothic features. The hill was planted with vines. The farmers kept turning up artifacts and terracotta funerary urns that seemed to be Roman.

In the 20th century the hill was covered over with buildings and became a part of downtown Ajaccio. In 2005 construction plans for a lot on the hill offered the opportunity to the Institut national de recherches archéologiques preventatives (Inrap) to excavate. They found the baptistry of a 6th-century cathedral and large amounts of pottery dated to the 6th and 7th centuries AD; in other words, an early Christian town. A cemetery had been placed over the old church. In it was a single Roman grave covered over with roof tiles bearing short indecipherable inscriptions. The finds of the previous century had included Roman coins. This is the only evidence so far of a Roman city continuous with the early Christian one.

It has been established that after the 8th century the city, like most other Corsican coastal communities, strongly declined and disappeared almost completely. Nevertheless, a castle and a cathedral were still in place in 1492 which last was not demolished until 1748. 

Towards the end of the 15th century, the Genoese were eager to assert their dominance in the south of the island and decided to rebuild the city of Ajaccio. Several sites were considered: the "Pointe de la Parata" (not chosen because it was too exposed to the wind), the ancient city (finally considered unsafe because of the proximity of the salt ponds), and finally the "Punta della Lechia" which was finally selected.

Work began on the town on 21 April 1492 south of the Christian village by the Bank of Saint George at Genoa, who sent Cristoforo of Gandini, an architect, to build it. He began with a castle on Capo di Bolo, around which he constructed residences for several hundred people.
The new city was essentially a colony of Genoa. The Corsicans were restricted from the city for some years.

Nevertheless, the town grew rapidly and became the administrative capital of the province of "Au Delà Des Monts" (more or less the current "Corse-du-Sud"). Bastia remained the capital of the entire island.

Although at first populated exclusively by the Genoese, the city slowly opened to the Corsicans while the Ajaccians, almost to the French conquest, were legally citizens of the Republic of Genoa and were happy to distinguish themselves from the insular "paesani" who lived mainly in "Borgu", a suburb outside the city walls (the current "rue Fesch" was the main street).

Ajaccio was occupied from 1553 to 1559 by the French, but it again fell to the Genoese after the Treaty of Cateau Cambresis in the latter year.

Subsequently, the Republic of Genoa was strong enough to keep Corsica until 1755, the year Pasquale Paoli proclaimed the Corsican Republic. Paoli took most of the island for the republic, but he was unable to force Genoese troops out of the citadels of Saint-Florent, Calvi, Ajaccio, Bastia and Algajola. Leaving them there, he went on to build the nation, while the Republic of Genoa was left to ponder prospects and solutions. Their ultimate solution was to sell Corsica to France in 1768 and French troops of the Ancien Régime replaced Genoese ones in the citadels, including Ajaccio's.

Corsica was formally annexed to France in 1780.

Napoleon Bonaparte (born as Nabulione Buonaparte) was born at Ajaccio in the same year as the Battle of Ponte Novu, 1769. The Bonapartes at the time had a modest four-story home in town (now a museum known as Maison Bonaparte) and a rarely used country home in the hills north of the city (now site of the Arboretum des Milelli). The father of the family, attorney Charles-Marie Buonaparte, was secretary to Pasquale Paoli during the Corsican Republic.
After the defeat of Paoli, the Comte de Marbeuf began to meet with some leading Corsicans to outline the shape of the future and enlist their assistance. The Comte was among a delegation from Ajaccio in 1769, offered his loyalty and was appointed assessor.

Marbeuf also offered Charles-Marie Buonaparte an appointment for one of his sons to the Military College of Brienne, but the child had to be under 10. There is a dispute concerning Napoleon's age because of this requirement; the emperor is known to have altered the civic records at Ajaccio concerning himself and it is possible that he was born in Corte in 1768 when his father was there on business. In any case Napoleon went to Brienne from 1779–1784.

At Brienne Napoleon concentrated on studies. He wrote a boyish history of Corsica. He did not share his father's views but held Pasquale Paoli in high esteem and was at heart a Corsican nationalist. The top students were encouraged to go into the artillery. After graduation and a brief sojourn at the Military School of Paris Napoleon applied for a second-lieutenancy in the artillery regiment of La Fère at Valence and after a time was given the position. Meanwhile, his father died and his mother was cast into poverty in Corsica, still having four children to support. Her only income was Napoleon's meagre salary. 

The regiment was in Auxonne when the revolution broke out in the summer of 1789. Napoleon returned on leave to Ajaccio in October, became a Jacobin and began to work for the revolution. The National Assembly in Paris united Corsica to France and pardoned its exiles. Paoli returned in 1790 after 21 years and kissed the soil on which he stood. He and Napoleon met and toured the battlefield of Paoli's defeat. A national assembly at Orezza created the department of Corsica and Paoli was subsequently elected president. He commanded the national guard raised by Napoleon. After a brief return to his regiment Napoleon was promoted to First Lieutenant and came home again on leave in 1791. The death of a rich uncle relieved the family's poverty. 

All officers were recalled from leave in 1792, intervention threatened and war with Austria (Marie-Antoinette's homeland) began. Napoleon returned to Paris for review, was exonerated, then promoted to Captain and given leave to escort his sister, a schoolgirl, back to Corsica at state expense. His family was prospering; his estate increased.

Napoleon became a Lieutenant-Colonel in the Corsican National Guard. Paoli sent him off on an expedition to Sardinia, ordered by France, under Paolis's nephew but the nephew had secret orders from Paoli to make sure the expedition failed. Paoli was now a conservative, opposing the execution of the king and supporting an alliance with Great Britain. Returning from Sardinia Napoleon with his family and all his supporters were instrumental in getting Paoli denounced at the National Convention in Paris in 1793. Napoleon earned the hatred of the Paolists by pretending to support Paoli and then turning against him (payment, one supposes, for Sardinia).

Paoli was convicted in absentia, a warrant was issued for his arrest (which could not be served) and Napoleon was dispatched to Corsica as Inspector General of Artillery to take the citadel of Ajaccio from the royalists who had held it since 1789. The Paolists combining with the royalists defeated the French in two pitched battles and Napoleon and his family went on the run, hiding by day, while the Paolists burned their estate. Napoleon and his mother, Laetitia, were taken out by ship in June 1793, by friends while two of the girls found refuge with other friends. They landed in Toulon with only Napoleon's pay for their support.

The Bonapartes moved to Marseille but in August Toulon offered itself to the British and received the protection of a fleet under Admiral Hood. The Siege of Toulon began in September under revolutionary officers mainly untrained in the art of war. Napoleon happened to present socially one evening and during a casual conversation over a misplaced 24-pounder explained the value of artillery. Taken seriously he was allowed to bring up over 100 guns from coastal emplacements but his plan for the taking of Toulon was set aside as one incompetent officer superseded another. By December they decided to try his plan and made him a Colonel. Placing the guns at close range he used them to keep the British fleet away while he battered down the walls of Toulon. As soon as the Committee of Public Safety heard of the victory Napoleon became a Brigadier General, the start of his meteoric rise to power.

The Bonapartes were back in Ajaccio in 1797 under the protection of General Napoleon. Soon after Napoleon became First Consul and then emperor, using his office to spread revolution throughout Europe. In 1811 he made Ajaccio the capital of the new Department of Corsica. Despite his subsequent defeat by the Prussians, Russians, and British, his exile and his death, no victorious power reversed that decision or tried to remove Corsica from France. Among the natives, though Corsican nationalism is strong, and feeling often runs high in favour of a union with Italy; loyalty to France, however, as evidenced by elections, remains stronger.

In the 19th century Ajaccio became a popular winter resort of the high society of the time, especially for the English, in the same way as Monaco, Cannes, and Nice. An Anglican Church was even built.

The first prison in France for children was built in Ajaccio in 1855: the Horticultural colony of Saint Anthony. It was a correctional colony for juvenile delinquents (from 8 to 20 years old), established under Article 10 of the Act of 5 August 1850. Nearly 1,200 children from all over France stayed there until 1866, when it was closed. Sixty percent of them perished, the victims of poor sanitation and malaria which infested the unhealthy areas that they were responsible to clean.

On 9 September 1943, the people of Ajaccio rose up against the Nazi occupiers and became the first French town to be liberated from the domination of the Germans. General Charles de Gaulle went to Ajaccio on 8 October 1943 and said: "We owe it to the field of battle the lesson of the page of history that was written in French Corsica. Corsica to her fortune and honour is the first morsel of France to be liberated; which was done intentionally and willingly, in the light of its liberation, this demonstrates that these are the intentions and the will of the whole nation." 

Throughout this period, no Jew was executed or deported from Corsica through the protection afforded by its people and its government. This event now allows Corsica to aspire to the title "righteous among the nations", as no region except for the commune Le Chambon-sur-Lignon in Haute-Loire carries this title. Their case is being investigated .

Since the middle of the 20th century, Ajaccio has seen significant development. The city has seen population growth and considerable urban sprawl. Today Ajaccio is the capital of Corsica and the main town of the island and seeks to establish itself as a true regional centre.

The city is, with Bastia, the economic, commercial and administrative centre of Corsica. Its urban area of nearly 90,000 inhabitants is spread over a large part of the Corse-du-Sud, on either side of the Gulf of Ajaccio and up the valley of the Gravona. Its business is primarily oriented towards the services sector.

The services sector is by far the main source of employment in the city. Ajaccio is an administrative centre comprising communal, intercommunal, departmental, regional, and prefectural services.

It is also a shopping centre with the commercial streets of the city centre and the areas of peripheral activities such as that of "Mezzavia" (hypermarket "Géant Casino") and along the ring road (hypermarket Carrefour and E. Leclerc).

Tourism is one of the most vital aspects of the economy, split between the seaside tourism of summer, cultural tourism, and fishing. A number of hotels, varying from one star to five star, are present across the commune.

Ajaccio is the seat of the "Chamber of Commerce and Industry of Ajaccio and Corsica South". It manages the ports of Ajaccio, Bonifacio, Porto-Vecchio, Propriano and the Tino Rossi marina. It also manages Ajaccio airport and Figari airport as well as the convention centre and the "Centre of Ricanto".

Secondary industry is underdeveloped, apart from the aeronautical company "Corsica Aerospace Composites CCA", the largest company on the island with 135 employees at two sites. The storage sites of GDF Suez (formerly Gaz de France) and Antargaz in the district of "Vazzio" are classified as high risk.

The "Centrale EDF du Vazzio", a heavy oil power station, provides the south of the island with electricity. The Gravona Canal delivers water for consumption by the city.

By road, the city is accessible from National Route NR194 from Bastia and NR193 via NR196 from Bonifacio.

These two main axes, as well as the roads leading to suburban villages, connect Ajaccio from the north - the site of Ajaccio forming a dead end blocked by the sea to the south. Only the "Cours Napoleon" and the "Boulevard du Roi Jerome" cross the city.

Along with the high urban density, this explains the major traffic and parking problems especially during peak hours and during the summer tourist season. A bypass through several neighbourhoods is nearing completion.

The "Transports en commun d'Ajaccio" (TCA) provide services on 21 urban routes, one "city" route for local links and 20 suburban lines. The frequency varies according to demand with intervals of 30 minutes for the most important routes:

A park and ride with 300 spaces was built at "Mezzana" in the neighbouring commune of Sarrola-Carcopino in order to promote intermodality between cars and public transport. It was inaugurated on 12 July 2010.

In addition, the municipality has introduced a Tramway between Mezzana station in the suburbs and Ajaccio station located in the centre.

The city is served by an Ajaccio Napoleon Bonaparte Airport which is the headquarters of Air Corsica, a Corsican airline. It connects Ajaccio to a number of cities in mainland France (including Paris, Marseille, Nice, and Brive) and to places in Europe to serve the tourist industry.

The airline CCM Airlines also has its head office on the grounds of the Airport.

The port of Ajaccio is connected to the French mainland on an almost daily basis (Marseille, Toulon, Nice). There are also occasional links to the Italian mainland (Livorno) and to Sardinia, as well as a seasonal service serving Calvi and Propriano. The two major shipping companies providing these links are SNCM and Corsica Ferries.

Ajaccio has also become a stopover for cruises with a total of 418,086 passengers in 2007by far the largest in Corsica and the second-largest in France (after Marseille, but ahead of Nice/Villefranche-sur-Mer and Cannes). The goal is for Ajaccio to eventually become the premier French port for cruises as well as being a main departure point.

The Port function of the city is also served by the commercial, pleasure craft, and artisanal fisheries (3 ports).

The railway station in Ajaccio belongs to "Chemins de Fer de la Corse" and is located near the port at the "Square Pierre Griffi". It connects Ajaccio to Corte, Bastia (3h 25min) and Calvi.

There are two optional stops:

Ajaccio was successively:

Ajaccio remained (with some interruptions) an electoral stronghold of the Bonapartist (CCB) party until the municipal elections of 2001. The outgoing municipality was then beaten by a left-wing coalition led by Simon Renucci which gathered Social Democrats, Communists, and Charles Napoleon - the pretender to the imperial throne.

List of Successive Mayors of Ajaccio

10 Quarters are recognized by the municipality.

Since December 2001, Ajaccio has been part of the "Communauté d'agglomération du Pays Ajaccien" with nine other communes: Afa, Alata, Appietto, Cuttoli-Corticchiato, Peri, Sarrola-Carcopino, Tavaco, Valle-di-Mezzana, and Villanova.

The geopolitical arrangements of the commune are slightly different from those typical of Corsica and France. Usually an arrondissement includes cantons and a canton includes one to several communes including the chef-lieu, "chief place", from which the canton takes its name. The city of Ajaccio is one commune, but it contains four cantons, Cantons 1–4, and a fraction of Canton 5. The latter contains three other communes: Bastelicaccia, Alata and Villanova, making a total of four communes for the five cantons of Ajaccio.

Each canton contains a certain number of quartiers, "quarters". Cantons 1, 2, 3, 4 are located along the Gulf of Ajaccio from west to east, while 5 is a little further up the valleys of the Gravona and the Prunelli Rivers. These political divisions subdivide the population of Ajaccio into units that can be more democratically served but they do not give a true picture of the size of Ajaccio. In general language, "greater Ajaccio" includes about 100,000 people with all the medical, educational, utility and transportational facilities of a big city. Up until World War II it was still possible to regard the city as being a settlement of narrow streets localized to a part of the harbour or the Gulf of Ajaccio: such bucolic descriptions do not fit the city of today, and travellogues intended for mountain or coastal recreational areas do not generally apply to Corsica's few big cities.

The arrondissement contains other cantons that extend generally up the two rivers into central Corsica.

Ajaccio has twinning associations with:


The demographic development of Ajaccio occurred mainly between 1945 and 1975 with a doubling of the population of the city in that period. This is explicable in the 1950s by the rural exodus. From the 1960s, the city saw the coming of "Pied-Noirs" (French Algerians) including immigrants from the Maghreb and French from mainland France.

Ajaccio has three hospital sites:

Ajaccio is the headquarters of the Academy of Corsica.

The city of Ajaccio has:

Higher education is undeveloped except for a few BTS and IFSI, the University of Corsica Pascal Paoli is located in Corte. A research facility of INRA is also located on Ajaccio.

Ajaccio has a varied tourism potential, with both a cultural framework in the centre of the city and a natural heritage around the coves and beaches of the Mediterranean Sea, as well as the Natura 2000 reserve of the "îles Sanguinaires".

The commune has many buildings and structures that are registered as historical monuments:


The town is the seat of a bishopric dating at least from the 7th century. It has tribunals of first instance and of commerce, training colleges, a communal college, a museum and a library; the three latter are established in the Palais Fesch, founded by Cardinal Fesch, who was born at Ajaccio in 1763.

The commune has several religious buildings and structures that are registered as historical monuments:





There are various sports facilities developed throughout the city.



Units that were stationed in Ajaccio:




</doc>
<doc id="2641" url="https://en.wikipedia.org/wiki?curid=2641" title="Ajaigarh">
Ajaigarh

Ajaigarh or Adjygurh is a town and a nagar panchayat in the Panna District of Madhya Pradesh state in central India.

Ajaigarh was the capital of a princely state of the same name during the British Raj. Ajaigarh was founded in 1765 by Guman Singh, a bundela Rajput who was the nephew of Raja Pahar Singh of Jaitpur. After Ajaigarh was captured by the British in 1809, it became a princely state in the Bundelkhand Agency of the Central India Agency. It had an area of , and a population of 78,236 in 1901. The rulers bore the title of "sawai maharaja". He commanded an estimated annual revenue of about £15,000/-, and paid a tribute of £460/-. The chief resided at the town of Nowgong, at the foot of the hill-fortress of Ajaigarh, from which the state took its name. This fort, situated on a steep hill, towers more than 800 ft (244 m) above the eponymous township, and contains the ruins of several temples adorned with elaborately carved sculptures. The town was often afflicted by malaria, and suffered severely from famine in 1868–1869 and 1896–1897.

The state acceded to the Government of India on 1 January 1950; the ruling chief was granted a privy purse of Rs. 74,700/-, and the courtesy use of his styles and titles. All of these were revoked by the government of India in 1971, at the time when these privileges were revoked from all erstwhile princes. The former princely state became part of the new Indian state of Vindhya Pradesh, and most of the territory of the former state, including the town of Ajaigarh, became part of Panna District, with a smaller portion going to Chhatarpur District. Vindhya Pradesh was merged into Madhya Pradesh on 1 November 1956.

 Maharajadhiraja Chhatrasal : 1649–1731
Devendra Vijay Singh :born 1913-died 1984

Ajaigarh or Ajaygarh Fort is listed among the top attractions of the region. It stands alone on a hilltop in the district of Panna and is easily accessible from Khajuraho. The fort is bordered by beautiful Vindhya Hills and provides absolutely stunning views of the Ken River. This grand fort is noted for its rich historical past and architectural beauty, which speaks volumes about the Chandela dynasty.

There is plenty to explore at the fort, which makes it a treat for history and art lovers. Reminiscent of old times, this fort has two gates (earlier there were five), two temples and two rock-cut tanks, close to the northern gate. These tanks have been named as Ganga and Yamuna.

As of 2001 India census, Ajaigarh had a population of 13,979. Males constitute 53% of the population and females 47%. Ajaigarh has an average literacy rate of 59%, which is lower than the national average of 59.5%; with 61% of the males and 39% of females literate. 16% of the population is under 6 years of age.

Ajaigarh Fort was sold to Oberoi Group and they plan to develop a tiger resort there.



</doc>
<doc id="2642" url="https://en.wikipedia.org/wiki?curid=2642" title="Ajanta Caves">
Ajanta Caves

The Ajanta Caves are 30 (approximately) rock-cut Buddhist cave monuments which date from the 2nd century BCE to about 480 CE in Aurangabad district of Maharashtra state of India. The caves include paintings and rock-cut sculptures described as among the finest surviving examples of ancient Indian art, particularly expressive paintings that present emotion through gesture, pose and form.

According to UNESCO, these are masterpieces of Buddhist religious art that influenced the Indian art that followed. The caves were built in two phases, the first phase starting around the 2nd century BCE, while the second phase was built around 400–650 CE, according to older accounts, or in a brief period of 460–480 CE according to later scholarship. The site is a protected monument in the care of the Archaeological Survey of India, and since 1983, the Ajanta Caves have been a UNESCO World Heritage Site.

The Ajanta Caves constitute ancient monasteries and worship-halls of different Buddhist traditions carved into a wall of rock. The caves also present paintings depicting the past lives and rebirths of the Buddha, pictorial tales from Aryasura's "Jatakamala", and rock-cut sculptures of Buddhist deities. Textual records suggest that these caves served as a monsoon retreat for monks, as well as a resting site for merchants and pilgrims in ancient India. While vivid colours and mural wall-painting were abundant in Indian history as evidenced by historical records, Caves 16, 17, 1 and 2 of Ajanta form the largest corpus of surviving ancient Indian wall-painting.
The Ajanta Caves are mentioned in the memoirs of several medieval-era Chinese Buddhist travellers to India and by a Mughal-era official of Akbar era in the early 17th century. They were covered by jungle until accidentally "discovered" and brought to Western attention in 1819 by a colonial British officer Captain John Smith on a tiger-hunting party. The caves are in the rocky northern wall of the U-shaped gorge of the river Waghur, in the Deccan plateau. Within the gorge are a number of waterfalls, audible from outside the caves when the river is high.

With the Ellora Caves, Ajanta is one of the major tourist attractions of Maharashtra. It is about

The Ajanta Caves are generally agreed to have been made in two distinct periods, the first during the 2nd century BCE to 1st century CE, and a second several centuries later.

The caves consist of 36 identifiable foundations, some of them discovered after the original numbering of the caves from 1 through 29. The later-identified caves have been suffixed with the letters of the alphabet, such as 15A, identified between originally numbered caves 15 and 16. The cave numbering is a convention of convenience, and does not reflect the chronological order of their construction.

The earliest group consists of caves 9, 10, 12, 13 and 15A. This grouping, and their belonging to the Hinayana (Theravada) tradition of Buddhism, is generally accepted by scholars, but there are differing opinions on which century in which the early caves were built. According to Walter Spink, they were made during the period 100 BCE to 100 CE, probably under the patronage of the Hindu Satavahana dynasty (230 BCE – c. 220 CE) who ruled the region. Other datings prefer the period of the Maurya Empire (300 BCE to 100 BCE). Of these, caves 9 and 10 are stupa containing worship halls of "chaitya-griha" form, and caves 12, 13, and 15A are "vihāras" (see the architecture section below for descriptions of these types). The first Satavahana period caves lacked figurative sculpture, emphasizing the stupa instead.

According to Spink, once the Satavahana period caves were made, the site was not further developed for a considerable period until the mid-5th century. However, the early caves were in use during this dormant period, and Buddhist pilgrims visited the site, according to the records left by Chinese pilgrim Faxian around 400 CE.

The second phase of construction at the Ajanta Caves site began in the 5th century. For a long time it was thought that the later caves were made over an extended period from the 4th to the 7th centuries CE, but in recent decades a series of studies by the leading expert on the caves, Walter M. Spink, have argued that most of the work took place over the very brief period from 460 to 480 CE, during the reign of Hindu Emperor Harishena of the Vākāṭaka dynasty. This view has been criticised by some scholars, but is now broadly accepted by most authors of general books on Indian art, for example, Huntington and Harle.
The second phase is attributed to the theistic Mahāyāna, or Greater Vehicle tradition of Buddhism. Caves of the second period are 1–8, 11, 14–29, some possibly extensions of earlier caves. Caves 19, 26, and 29 are "chaitya-grihas", the rest "viharas". The most elaborate caves were produced in this period, which included some refurbishing and repainting of the early caves.

Spink states that it is possible to establish dating for this period with a very high level of precision; a fuller account of his chronology is given below. Although debate continues, Spink's ideas are increasingly widely accepted, at least in their broad conclusions. The Archaeological Survey of India website still presents the traditional dating: "The second phase of paintings started around 5th–6th centuries A.D. and continued for the next two centuries".

According to Spink, the construction activity at the incomplete Ajanta Caves was abandoned by wealthy patrons in about 480 CE, a few years after the death of Harishena. However, states Spink, the caves appear to have been in use for a period of time as evidenced by the wear of the pivot holes caves constructed close to 480 CE. The second phase of constructions and decorations at Ajanta corresponds to the very apogee of Classical India, or India's golden age.

According to Richard Cohen, a description of the caves by 7th-century Chinese traveler Xuanzang and scattered medieval graffiti suggest that the Ajanta Caves were known and probably in use subsequently, but without a stable or steady Buddhist community presence. The Ajanta caves are mentioned in the 17th-century text "Ain-i-Akbari" by Abu al-Fazl, as twenty four rock-cut cave temples each with remarkable idols.

On 28 April 1819, a British officer named John Smith, of the 28th Cavalry, while hunting tigers, "discovered" the entrance to Cave No. 10 when a local shepherd boy guided him to the location and the door. The caves were well known by locals already. Captain Smith went to a nearby village and asked the villagers to come to the site with axes, spears, torches, and drums, to cut down the tangled jungle growth that made entering the cave difficult. He then vandalised the wall by scratching his name and the date over the painting of a bodhisattva. Since he stood on a five-foot high pile of rubble collected over the years, the inscription is well above the eye-level gaze of an adult today. A paper on the caves by William Erskine was read to the Bombay Literary Society in 1822.
Within a few decades, the caves became famous for their "exotic" setting, impressive architecture, and above all their exceptional and unique paintings. A number of large projects to copy the paintings were made in the century after rediscovery. In 1848, the Royal Asiatic Society established the "Bombay Cave Temple Commission" to clear, tidy and record the most important rock-cut sites in the Bombay Presidency, with John Wilson as president. In 1861 this became the nucleus of the new Archaeological Survey of India.

During the colonial era, the Ajanta site was in the territory of the princely state of the Hyderabad and not British India. In the early 1920s, the Nizam of Hyderabad appointed people to restore the artwork, converted the site into a museum and built a road to bring tourists to the site for a fee. These efforts resulted in early mismanagement, states Richard Cohen, and hastened the deterioration of the site. Post-independence, the state government of Maharashtra built arrival, transport, facilities, and better site management. The modern Visitor Center has good parking facilities and public conveniences and ASI operated buses run at regular intervals from Visitor Center to the caves.

The Ajanta Caves, along with the Ellora Caves, have become the most popular tourist destination in Maharashtra, and are often crowded at holiday times, increasing the threat to the caves, especially the paintings. In 2012, the Maharashtra Tourism Development Corporation announced plans to add to the ASI visitor centre at the entrance complete replicas of caves 1, 2, 16 & 17 to reduce crowding in the originals, and enable visitors to receive a better visual idea of the paintings, which are dimly-lit and hard to read in the caves.

The caves are carved out of flood basalt rock of a cliff, part of the Deccan Traps formed by successive volcanic eruptions at the end of the Cretaceous geological period. The rock is layered horizontally, and somewhat variable in quality. This variation within the rock layers required the artists to amend their carving methods and plans in places. The inhomogeneity in the rock have also led to cracks and collapses in the centuries that followed, as with the lost portico to cave 1. Excavation began by cutting a narrow tunnel at roof level, which was expanded downwards and outwards; as evidenced by some of the incomplete caves such as the partially-built "vihara" caves 21 through 24 and the abandoned incomplete cave 28.

The sculpture artists likely worked at both excavating the rocks and making the intricate carvings of pillars, roof, and idols; further, the sculpture and painting work inside a cave were integrated parallel tasks. A grand gateway to the site was carved, at the apex of the gorge's horseshoe between caves 15 and 16, as approached from the river, and it is decorated with elephants on either side and a nāga, or protective Naga (snake) deity. Similar methods and application of artist talent is observed in other cave temples of India, such as those from Hinduism and Jainism. These include the Ellora caves, Ghototkacha caves, Elephanta Caves, Bagh Caves, Badami Caves, Aurangabad Caves and Shivleni Caves.

The caves from the first period seem to have been paid for by a number of different patrons to gain merit, with several inscriptions recording the donation of particular portions of a single cave. The later caves were each commissioned as a complete unit by a single patron from the local rulers or their court elites, again for merit in Buddhist afterlife beliefs as evidenced by inscriptions such as those in Cave 17. After the death of Harisena, smaller donors motivated by getting merit added small "shrinelets" between the caves or add statues to existing caves, and some two hundred of these "intrusive" additions were made in sculpture, with a further number of intrusive paintings, up to three hundred in cave 10 alone.

The majority of the caves are "vihara" halls with symmetrical square plans. To each vihara hall are attached smaller square dormitory cells cut into the walls. A vast majority of the caves were carved in the second period, wherein a shrine or sanctuary is appended at the rear of the cave, centred on a large statue of the Buddha, along with exuberantly detailed reliefs and deities near him as well as on the pillars and walls, all carved out of the natural rock. This change reflects the shift from Hinayana to Mahāyāna Buddhism. These caves are often called monasteries.

The central square space of the interior of the viharas is defined by square columns forming a more-or-less square open area. Outside this are long rectangular aisles on each side, forming a kind of cloister. Along the side and rear walls are a number of small cells entered by a narrow doorway; these are roughly square, and have small niches on their back walls. Originally they had wooden doors. The centre of the rear wall has a larger shrine-room behind, containing a large Buddha statue.

The viharas of the earlier period are much simpler, and lack shrines. Spink places the change to a design with a shrine to the middle of the second period, with many caves being adapted to add a shrine in mid-excavation, or after the original phase.

The plan of Cave 1 shows one of the largest viharas, but is fairly typical of the later group. Many others, such as Cave 16, lack the vestibule to the shrine, which leads straight off the main hall. Cave 6 is two viharas, one above the other, connected by internal stairs, with sanctuaries on both levels.

The other type of main hall architecture is the narrower rectangular plan with high arched ceiling type "chaitya-griha" – literally, "the house of stupa". This hall is longitudinally divided into a nave and two narrower side aisles separated by a symmetrical row of pillars, with a stupa in the apse. The stupa is surrounded by pillars and concentric walking space for circumambulation. Some of the caves have elaborate carved entrances, some with large windows over the door to admit light. There is often a colonnaded porch or verandah, with another space inside the doors running the width of the cave. The oldest worship halls at Ajanta were built in the 2nd to 1st century BCE, the newest ones in the late 5th century CE, and the architecture of both resembles the architecture of a Christian church, but without the crossing or chapel chevette. The Ajanta Caves follow the Cathedral-style architecture found in still older rock-cut cave carvings of ancient India, such as the Lomas Rishi Cave of the Ajivikas near Gaya in Bihar dated to the 3rd century BCE. These chaitya-griha are called worship or prayer halls.

The four completed "chaitya" halls are caves 9 and 10 from the early period, and caves 19 and 26 from the later period of construction. All follow the typical form found elsewhere, with high ceilings and a central "nave" leading to the stupa, which is near the back, but allows walking behind it, as walking around stupas was (and remains) a common element of Buddhist worship ("pradakshina"). The later two have high ribbed roofs carved into the rock, which reflect timber forms, and the earlier two are thought to have used actual timber ribs and are now smooth, the original wood presumed to have perished. The two later halls have a rather unusual arrangement (also found in Cave 10 at Ellora) where the stupa is fronted by a large relief sculpture of the Buddha, standing in Cave 19 and seated in Cave 26. Cave 29 is a late and very incomplete "chaitya" hall.

The form of columns in the work of the first period is very plain and un-embellished, with both "chaitya" halls using simple octagonal columns, which were later painted with images of the Buddha, people and monks in robes. In the second period columns were far more varied and inventive, often changing profile over their height, and with elaborate carved capitals, often spreading wide. Many columns are carved over all their surface with floral motifs and Mahayana deities, some fluted and others carved with decoration all over, as in cave 1.

The paintings in the Ajanta caves predominantly narrate the Jataka tales. These are Buddhist legends describing the previous births of the Buddha. These fables embed ancient morals and cultural lores that are also found in the fables and legends of Hindu and Jain texts. The Jataka tales are exemplified through the life example and sacrifices that the Buddha made in hundreds of his past incarnations, where he is depicted as having been reborn as an animal or human.

Mural paintings survive from both the earlier and later groups of caves. Several fragments of murals preserved from the earlier caves (Caves 10 and 11) are effectively unique survivals of ancient painting in India from this period, and "show that by Sātavāhana times, if not earlier, the Indian painters had mastered an easy and fluent naturalistic style, dealing with large groups of people in a manner comparable to the reliefs of the Sāñcī toraņa crossbars". Some connections with the art of Gandhara can also be noted, and there is evidence of a shared artistic idiom.

Four of the later caves have large and relatively well-preserved mural paintings which, states James Harle, "have come to represent Indian mural painting to the non-specialist", and represent "the great glories not only of Gupta but of all Indian art". They fall into two stylistic groups, with the most famous in Caves 16 and 17, and apparently later paintings in Caves 1 and 2. The latter group were thought to be a century or later than the others, but the revised chronology proposed by Spink would place them in the 5th century as well, perhaps contemporary with it in a more progressive style, or one reflecting a team from a different region. The Ajanta frescos are classical paintings and the work of confident artists, without cliches, rich and full. They are luxurious, sensuous and celebrate physical beauty, aspects that early Western observers felt were shockingly out of place in these caves presumed to be meant for religious worship and ascetic monastic life.

The paintings are in "dry fresco", painted on top of a dry plaster surface rather than into wet plaster. All the paintings appear to be the work of painters supported by discriminating connoisseurship and sophisticated patrons from an urban atmosphere. We know from literary sources that painting was widely practised and appreciated in the Gupta period. Unlike much Indian mural painting, compositions are not laid out in horizontal bands like a frieze, but show large scenes spreading in all directions from a single figure or group at the centre. The ceilings are also painted with sophisticated and elaborate decorative motifs, many derived from sculpture. The paintings in cave 1, which according to Spink was commissioned by Harisena himself, concentrate on those Jataka tales which show previous lives of the Buddha as a king, rather than as deer or elephant or another Jataka animal. The scenes depict the Buddha as about to renounce the royal life.

In general the later caves seem to have been painted on finished areas as excavating work continued elsewhere in the cave, as shown in caves 2 and 16 in particular. According to Spink's account of the chronology of the caves, the abandonment of work in 478 after a brief busy period accounts for the absence of painting in places including cave 4 and the shrine of cave 17, the later being plastered in preparation for paintings that were never done.
Walter M. Spink has over recent decades developed a very precise and circumstantial chronology for the second period of work on the site, which unlike earlier scholars, he places entirely in the 5th century. This is based on evidence such as the inscriptions and artistic style, dating of nearby cave temple sites, comparative chronology of the dynasties, combined with the many uncompleted elements of the caves. He believes the earlier group of caves, which like other scholars he dates only approximately, to the period "between 100 BCE – 100 CE", were at some later point completely abandoned and remained so "for over three centuries". This changed during the Hindu emperor Harishena of the Vakataka Dynasty, who reigned from 460 to his death in 477, who sponsored numerous new caves during his reign. Harisena's rule extended the Central Indian Vakataka Empire to include a stretch of the east coast of India; the Gupta Empire ruled northern India at the same period, and the Pallava dynasty much of the south.
According to Spink, Harisena encouraged a group of associates, including his prime minister Varahadeva and Upendragupta, the sub-king in whose territory Ajanta was, to dig out new caves, which were individually commissioned, some containing inscriptions recording the donation. This activity began in many caves simultaneously about 462. This activity was mostly suspended in 468 because of threats from the neighbouring Asmaka kings. Thereafter work continued on only Caves 1, Harisena's own commission, and 17–20, commissioned by Upendragupta. In 472 the situation was such that work was suspended completely, in a period that Spink calls "the Hiatus", which lasted until about 475, by which time the Asmakas had replaced Upendragupta as the local rulers.

Work was then resumed, but again disrupted by Harisena's death in 477, soon after which major excavation ceased, except at cave 26, which the Asmakas were sponsoring themselves. The Asmakas launched a revolt against Harisena's son, which brought about the end of the Vakataka Dynasty. In the years 478–480 CE major excavation by important patrons was replaced by a rash of "intrusions" – statues added to existing caves, and small shrines dotted about where there was space between them. These were commissioned by less powerful individuals, some monks, who had not previously been able to make additions to the large excavations of the rulers and courtiers. They were added to the facades, the return sides of the entrances, and to walls inside the caves. According to Spink, "After 480, not a single image was ever made again at the site". However, there exists a Rashtrakuta inscription outside of cave 26 dateable to end of seventh or early 8th century, suggesting the caves were not abandoned until then.

Spink does not use "circa" in his dates, but says that "one should allow a margin of error of one year or perhaps even two in all cases".

The Ajanta Caves were built in a period when both the Buddha and the Hindu gods were simultaneously revered in Indian culture. According to Spink and other scholars, not only the Ajanta Caves but other nearby cave temples were sponsored and built by Hindus. This is evidenced by inscriptions wherein the role, as well as the Hindu heritage of the donor, is proudly proclaimed. According to Spink,

The role of Hindu artisans is confirmed by archaeological excavations across the river from the Ajanta caves. The caves must have employed a large workforce of artisans who likely lived for extended period of time nearby, across from the river near the site. Excavations have uncovered extensive brick structures for workers and visiting elite sponsors, along with Shaiva and Shakta Hindu deities such as a red sandstone image of Durga Mahishasuramardini. According to Yuko Yokoschi and Walter Spink, these excavated artifacts of the 5th century near the site suggest that the Ajanta caves deployed a huge number of builders.

Cave 1 was built on the eastern end of the horseshoe-shaped scarp and is now the first cave the visitor encounters. This cave, when first made, would have been a less prominent position, right at the end of the row. According to Spink, it is one of the last caves to have been excavated, when the best sites had been taken, and was never fully inaugurated for worship by the dedication of the Buddha image in the central shrine. This is shown by the absence of sooty deposits from butter lamps on the base of the shrine image, and the lack of damage to the paintings that would have happened if the garland-hooks around the shrine had been in use for any period of time. Spink states that the Vākāţaka Emperor Harishena was the benefactor of the work, and this is reflected in the emphasis on imagery of royalty in the cave, with those Jataka tales being selected that tell of those previous lives of the Buddha in which he was royal.

The cliff has a more steep slope here than at other caves, so to achieve a tall grand facade it was necessary to cut far back into the slope, giving a large courtyard in front of the facade. There was originally a columned portico in front of the present facade, which can be seen "half-intact in the 1880s" in pictures of the site, but this fell down completely and the remains, despite containing fine carvings, were carelessly thrown down the slope into the river, from where they have been lost.
This cave (35.7 m x 27.6 m) has one of the most elaborate carved façades, with relief sculptures on entablature and ridges, and most surfaces embellished with decorative carving. There are scenes carved from the life of the Buddha as well as a number of decorative motifs. A two-pillared portico, visible in the 19th-century photographs, has since perished. The cave has a frontcourt with cells fronted by pillared vestibules on either side. These have a high plinth level. The cave has a porch with simple cells on both ends. The absence of pillared vestibules on the ends suggests that the porch was not excavated in the latest phase of Ajanta when pillared vestibules had become customary. Most areas of the porch were once covered with murals, of which many fragments remain, especially on the ceiling. There are three doorways: a central doorway and two side doorways. Two square windows were carved between the doorways to brighten the interiors.

Each wall of the hall inside is nearly long and high. Twelve pillars make a square colonnade inside supporting the ceiling, and creating spacious aisles along the walls. There is a shrine carved on the rear wall to house an impressive seated image of the Buddha, his hands being in the "dharmachakrapravartana mudra." There are four cells on each of the left, rear, and the right walls, though due to rock fault there are none at the ends of the rear aisle.

Cave 2, adjacent to Cave 1, is known for the paintings that have been preserved on its walls, ceilings, and pillars. It looks similar to Cave 1 and is in a better state of preservation. This cave is best known for its feminine focus, intricate rock carvings and paint artwork yet it is incomplete and lacks consistency. One of the 5th-century frescos in this cave also shows children at a school, with those in the front rows paying attention to the teacher, while those in the back row are shown distracted and acting.

Cave 2 (35.7 m x 21.6 m) was started in the 460s, but mostly carved between 475 and 477 CE, probably sponsored and influenced by a woman closely related to emperor Harisena. It has a porch quite different from Cave 1. Even the façade carvings seem to be different. The cave is supported by robust pillars, ornamented with designs. The front porch consists of cells supported by pillared vestibules on both ends.
The hall has four colonnades which are supporting the ceiling and surrounding a square in the center of the hall. Each arm or colonnade of the square is parallel to the respective walls of the hall, making an aisle in between. The colonnades have rock-beams above and below them. The capitals are carved and painted with various decorative themes that include ornamental, human, animal, vegetative, and semi-divine motifs. Major carvings include that of goddess Hariti. She is a Buddhist deity who originally was the demoness of smallpox and a child eater, who the Buddha converted into a guardian goddess of fertility, easy child birth and one who protects babies.

Cave 3 is merely a start of an excavation; according to Spink it was begun right at the end of the final period of work and soon abandoned.

This is an incomplete monastery and only the preliminary excavations of pillared veranda exist. The cave was one of the very last projects to start at the site. Its date could be ascribed to circa 477 CE, just before the sudden death of Emperor Harisena. The work stopped after the scooping out of a rough entrance of the hall.

Cave 4, a vihara, was sponsored by Mathura, likely not a noble or courtly official, rather a wealthy devotee. This is the largest vihara in the inaugural group, which suggests he had immense wealth and influence without being a state official. It is placed at a significantly higher level, possibly because the artists realized that the rock quality at the lower and same level of other caves was poor and they had a better chance of a major vihara at an upper location. Another likely possibility is that the planners wanted to carve into the rock another large cistern to the left courtside for more residents, mirroring the right, a plan implied by the height of the forward cells on the left side.

The Archaeological Survey of India dates it to the 6th century CE. Spink, in contrast, dates this cave's inauguration a century earlier, to about 463 CE, based on construction style and other inscriptions. Cave 4 shows evidence of a dramatic collapse of its ceiling in the central hall, likely in the 6th century, something caused by the vastness of the cave and geological flaws in the rock. Later, the artists attempted to overcome this geological flaw by raising the height of the ceiling through deeper excavation of the embedded basalt lava.
The cave has a squarish plan, houses a colossal image of the Buddha in preaching pose flanked by bodhisattvas and celestial nymphs hovering above. It consists, of a verandah, a hypostylar hall, sanctum with an antechamber and a series of unfinished cells. This monastery is the largest among the Ajanta caves and it measures nearly (35m x 28m). The door frame is exquisitely sculpted flanking to the right is carved Bodhisattva as reliever of Eight Great Perils. The rear wall of the verandah contains the panel of litany of Avalokiteśvara. The cave's ceiling collapse likely affected its overall plan, caused it being left incomplete. Only the Buddha's statue and the major sculptures were completed, and except for what the sponsor considered most important elements all other elements inside the cave were never painted.

 was planned as a monastery (10.32 X 16.8 m). Cave 5 is devoid of sculpture and architectural elements except the door frame. The ornate carvings on the frame has female figures with mythical "makara" creatures found in ancient and medieval era Indian arts. The cave's construction was likely initiated about 465 CE but abandoned because the rock has geological flaws. The construction was resumed in 475 CE after Asmakas restarted work at the Ajanta caves, but abandoned again as the artists and sponsor redesigned and focussed on an expanded Cave 6 that abuts Cave 5.

Cave 6 is two storey monastery (16.85 X 18.07 m). It consists of a sanctum, a hall on both levels. The lower level is pillared and has attached cells. The upper hall also has subsidiary cells. The sanctums on both level feature a Buddha in the teaching posture. Elsewhere, the Buddha is shown in different mudras. The lower level walls depict the Miracle of Sravasti and the Temptation of Mara legends. Only the lower floor of cave 6 was finished. The unfinished upper floor of cave 6 has many private votive sculptures, and a shrine Buddha.

The lower level of the Cave 6 likely was the earliest excavation in the second stage of construction. This stage marked the Mahayana theme and Vakataka renaissance period of Ajanta reconstruction that started about four centuries after the earlier Hinayana theme construction. The upper storey was not envisioned in the beginning, it was added as an afterthought, likely around the time when the architects and artists abandoned further work on the geologically-flawed rock of Cave 5 immediately next to it. Both lower and upper Cave 6 show crude experimentation and construction errors. The cave work was most likely in progress between 460 and 470 CE, and it is the first that shows attendant Bodhisattvas. The upper cave construction probably began in 465, progressed swiftly, and much deeper into the rock than the lower level.

The walls and sanctum's door frame of the both levels are intricately carved. These show themes such as "makaras" and other mythical creatures, apsaras, elephants in different stages of activity, females in waving or welcoming gesture. The upper level of Cave 6 is significant in that it shows a devotee in a kneeling posture at the Buddha's feet, an indication of devotional worship practices by the 5th century. The colossal Buddha of the shrine has an elaborate throne back, but was hastily finished in 477/478 CE, when king Harisena died. The shrine antechamber of the cave features an unfinished sculptural group of the Six Buddhas of the Past, of which only five statues were carved. This idea may have been influenced from those in Bagh Caves of Madhya Pradesh.

The Cave 7 is also a monastery (15.55 X 31.25 m) but a single storey. It consists of a sanctum, a hall with octagonal pillars, and eight small rooms for monks. The sanctum Buddha is shown in preaching posture. There are many art panels narrating Buddhist themes, including those of the Buddha with Nagamuchalinda and Miracle of Sravasti.

Cave 7 has a grand facade with two porticos. The veranda has eight pillars of two types. One has an octagonal base with amalaka and lotus capital. The other lacks a distinctly shaped base, features an octagonal shaft instead with a plain capital. The veranda opens into an antechamber. On the left side in this antechamber are seated or standing sculptures such as those of 25 carved seated Buddhas in various postures and facial expressions, while on the right side are 58 seated Buddha reliefs in different postures, all placed on lotus. These Buddhas and others on the inner walls of the antechamber are a sculptural depiction of the Miracle of Sravasti in Buddhist theology. The bottom row shows two Nagas (serpents with hoods) holding the blooming lotus stalk. The antechamber leads to the sanctum through a door frame. On this frame are carved two females standing on "makaras" (mythical sea creatures). Inside the sanctum is the Buddha sitting on a lion throne in cross legged posture, surrounded by other Bodhisattva figures, two attendants with "chauris" and flying apsaras above.

Perhaps because of faults in the rock, Cave 7 was never taken very deep into the cliff. It consists only of the two porticos and a shrine room with antechamber, with no central hall. Some cells were fitted in. The cave artwork likely underwent revisions and refurbishments over time. The first version was complete by about 469 CE, the myriad Buddhas added and painted a few years later between 476 and 478 CE.

Cave 8 is another unfinished monastery (15.24 X 24.64 m). For many decades in the 20th-century, this cave was used as a storage and generator room. It is at the river level with easy access, relatively lower than other caves, and according to Archaeological Survey of India it is possibly one of the earliest monasteries. Much of its front is damaged, likely from a landslide. The cave excavation proved difficult and probably abandoned after a geological fault consisting of a mineral layer proved disruptive to stable carvings.

Spink, in contrast, states that Cave 8 is perhaps the earliest cave from the second period, its shrine an "afterthought". It may well be the oldest Mahayana monastery excavated in India, according to Spink. The statue may have been loose rather than carved from the living rock, as it has now vanished. The cave was painted, but only traces remain.

Caves 9 and 10 are the two "chaitya" or worship halls from the 2nd to 1st century BCE – the first period of construction, though both were reworked upon the end of the second period of construction in the 5th century CE.

Cave 9 (18.24 m x 8.04 m) is smaller than Cave 10 (30.5 m x 12.2 m), but more complex. This has led Spink to the view that Cave 10 was perhaps originally of the 1st century BCE, and cave 9 about a hundred years later. The small "shrinelets" called caves 9A to 9D and 10A also date from the second period. These were commissioned by individuals. Cave 9 arch has remnant profile that suggests that it likely had wooden fittings.

The cave has a distinct apsidal shape, nave, aisle and an apse with an icon, architecture, and plan that reminds one of cathedrals built in Europe many centuries later. The aisle has a row of 23 pillars. The ceiling is vaulted. The stupa is at the center of the apse, with a circumambulation path around it. The stupa sits on a high cylindrical base. On the left wall of the cave are votaries approaching the stupa, which suggests a devotional tradition.

According to Spink, the paintings in this cave, including the intrusive standing Buddhas on the pillars, were added in the 5th century. Above the pillars and also behind the stupa are colorful paintings of the Buddha with Padmapani and Vajrapani next to him, they wear jewels and necklaces, while yogis, citizens and Buddhist "bhikshu" are shown approaching the Buddha with garlands and offerings, with men wearing "dhoti" and turbans wrapped around their heads. On the walls are friezes of Jataka tales, but likely from the Hinayana phase of early construction. Some of the panels and reliefs inside as well as outside Cave 10 do not make narrative sense, but are related to Buddhist legends. This lack of narrative flow may be because these were added by different monks and official donors in the 5th century wherever empty space was available. This devotionalism and the worship hall character of this cave is the likely reason why four additional shrinelets 9A, 9B, 9C, and 9D were added between Cave 9 and 10.

Cave 10, a vast prayer hall or Chaitya, is dated to about the 1st century BCE, together with the nearby vihara cave No 12. These two caves are thus among the earliest of the Ajanta complex. It has a large central apsidal hall with a row of 39 octagonal pillars, a nave separating its aisle and stupa at the end for worship. The stupa has a "pradakshina patha" (circumambulatory path).

This cave is significant because its scale confirms the influence of Buddhism in South Asia by the 1st century BCE and its continued though declining influence in India through the 5th century CE. Further, the cave includes a number of inscriptions where parts of the cave are "gifts of prasada" by different individuals, which in turn suggests that the cave was sponsored as a community effort rather than a single king or one elite official. Cave 10 is also historically important because in April 1819, a British Army officer John Smith saw its arch and introduced his discovery to the attention to the Western audience.

Several others caves were also built in Western India around the same period under royal sponsorship. It is thought that the chronology of these early Chaitya Caves is as follows: first Cave 9 at Kondivite Caves and then Cave 12 at the Bhaja Caves, which both predate Cave 10 of Ajanta. Then, after Cave 10 of Ajanta, in chronological order: Cave 3 at Pitalkhora, Cave 1 at Kondana Caves, Cave 9 at Ajanta, which, with its more ornate designs, may have been built about a century later, Cave 18 at Nasik Caves, and Cave 7 at Bedse Caves, to finally culminate with the "final perfection" of the Great Chaitya at Karla Caves.


Cave 10 features a Sanskrit inscription in Brahmi script that is archaeologically important. The inscription is the oldest of the Ajanta site and reads:
 include some surviving from the early period, many from an incomplete programme of modernisation in the second period, and a very large number of smaller late intrusive images for votive purposes, around the 479–480 CE, nearly all Buddhas and many with donor inscriptions from individuals. These mostly avoided over-painting the "official" programme and after the best positions were used up are tucked away in less prominent positions not yet painted; the total of these (including those now lost) was probably over 300, and the hands of many different artists are visible. The paintings are numerous and from two periods, many narrating the Jataka tales in a clockwise sequence. Both Hinayana and Mahayana stage paintings are discernable, though the former are more faded and begrimed with early centuries of Hinayana worship. Of interest here is the Saddanta Jataka tale – the fable about six tusked elephant, and the Shyama Jataka – the story about the man who dedicates his life serving his blind parents. According to Stella Kramrisch, the oldest layer of the Cave 10 paintings date from about 100 BCE, and the principles behind their composition are analogous to those from the same era at Sanchi and Amaravati.

The Cave 11 is a monastery (19.87 X 17.35 m) from the later 5th century. The cave veranda has pillars with octagonal shafts and square bases. The ceiling of the veranda shows evidence of floral designs and eroded reliefs. Only the center panel is discernible wherein the Buddha is seen with votaries lining up to pray before him. Inside, the cave consists of a hall with a long rock bench opening into six rooms. Similar stone benches are found in Nasik caves. Another pillared verandah ends in a sanctum with seated Buddha against an incomplete stupa, and has four cells.

The cave has a few paintings showing Bodhisattvas and the Buddha. Of these, the Padmapani, a couple gathered to pray, a pair of peafowl, and a female figure painting have survived in the best condition. The sanctum of this cave may be among the last structures built at Ajanta because it features a circumambulation path around the seated Buddha.

According to Archaeological Survey of India (ASI), Cave 12 is an early stage Hinayana (Theravada) monastery (14.9 X 17.82 m) from the 2nd to 1st century BCE. Spink however only dates it to the 1st century BCE.

The cave is damaged with its front wall completely collapsed. Its three sides inside have twelve cells, each with two stone beds.

Cave 13 is another small monastery from the early period, consisting of a hall with seven cells, each also with two stone beds, all carved out of the rock. Each cell has rock-cut beds for the monks. In contrast to ASI's estimate, Gupte and Mahajan date both these caves about two to three centuries later, between 1st and 2nd-century CE.

Cave 14 is another unfinished monastery (13.43 X 19.28 m) but carved above Cave 13. The entrance door frame shows "sala bhanjikas".

Cave 15 is a more complete monastery (19.62 X 15.98 m) with evidence that it had paintings. The cave consists of an eight-celled hall ending in a sanctum, an antechamber and a verandah with pillars. The reliefs show the Buddha, while the sanctum Buddha is shown seated in the Simhasana posture. Cave 15 door frame has carvings of pigeons eating corn.

Cave 15A is the smallest cave with a hall and one cell on each side. Its entrance is located just to the right of the elephant-decorated entrance to Cave 16. It is an ancient Hinayana cave with three cells opening around a minuscule central hall. The doors are decorated with a rail and arch pattern. It had an inscription in an ancient script, which has been lost.

Cave 16 occupies a prime position near the middle of site, and was sponsored by Varahadeva, minister of Vakataka king Harishena (r. c. 475 – c. 500 CE). He devoted it to the community of monks, with an inscription that expresses his wish, may "the entire world (...) enter that peaceful and noble state free from sorrow and disease". He was, states Spink, someone who revered both the Buddha and the Hindu gods. The 7th-century Chinese traveler Xuan Zang described the cave as the entrance to the site.

Cave 16 (19.5 m x 22.25 m x 4.6 m) influenced the architecture of the entire site. Spink and other scholars call it the "crucial cave" that helps trace the chronology of the second and closing stages of the entire cave complex's construction. Cave 16 is a Mahayana monastery and has the standard arrangement of a main doorway, two windows, and two aisle doorways. The veranda of this monastery is 19.5 m x 3 m, while the main hall is almost a perfect square with 19.5 m side.

The Mahaummagga Jataka frescos are found on the left wall of the corridor, which narrates the story of a child Bodhisattva. Thereafter, in the left corridor is the legend surrounding the conversion of Nanda – the half brother of the Buddha. The story depicted is one of the two major versions of the Nanda legend in the Buddhist tradition, one where Nanda wants to lead a sensuous life with the girl he had just wed and the Buddha takes him to heaven and later hell to show the spiritual dangers of a sensual life. After the Nanda-related frescos, the cave presents Manushi Buddhas, followed by flying votaries with offerings to worship the Buddha and the Buddha seated in teaching asana and "dharma chakra mudra".

The right wall of the corridor show the scenes from the life of the Buddha. These include Sujata offering food to the Buddha with a begging bowl in white dress, Tapussa and Bhalluka next to the Buddha after they offering wheat and honey to the Buddha as monk, the future Buddha sitting alone under a tree, and the Buddha at a ploughing festival. One mural shows Buddha's parents trying to dissuade him from becoming a monk. Another shows the Buddha at the palace surrounded by men in "dhoti" and women in "sari" as his behavior presents the four signs that he is likely to renounce. On this side of the corridor are also paintings that show the future Buddha as a baby with sage Asita with rishi-like looks. According to Spink, some of the Cave 16 paintings were left incomplete.

Cave 17 (34.5 m x 25.63 m) along with Cave 16 with two great stone elephants at the entrance and Cave 26 with sleeping Buddha, were some of the many caves sponsored by the Hindu Vakataka prime minister Varahadeva. Cave 17 had additional donors such as the local king Upendragupta, as evidenced by the inscription therein.

The cave features a large and most sophisticated vihara design, along with some of the best-preserved and well-known paintings of all the caves. While Cave 16 is known for depicting the life stories of the Buddha, the Cave 17 paintings has attracted much attention for extolling human virtues by narrating the Jataka tales. The narration includes attention to details and a realism which Stella Kramrisch calls "lavish elegance" accomplished by efficient craftsmen. The ancient artists, states Kramrisch, tried to show wind passing over a crop by showing it bending in waves, and a similar profusion of rhythmic sequences that unroll story after story, visually presenting the metaphysical.
The Cave 17 monastery includes a colonnaded porch, a number of pillars each with a distinct style, a peristyle design for the interior hall, a shrine antechamber located deep in the cave, larger windows and doors for more light, along with extensive integrated carvings of Indian gods and goddesses. The hall of this monastery is a square, with 20 pillars. The grand scale of the carving also introduced errors of taking out too much rock to shape the walls, states Spink, which led to the cave being splayed out toward the rear.

Cave 17 has one long inscription by king Upendragupta, in which he explains that he has "expended abundant wealth” on building this vihara, bringing much satisfaction to the devotees. Altogether, Upendragupta is known to have sponsored at least 5 of the caves in Ajanta. He may have spent too much wealth on religious pursuits however, as he was ultimately defeated by the attacks of the Asmaka.

Cave 17 has thirty major murals. depict Buddha in various forms and postures – Vipasyi, Sikhi, Visvbhu, Krakuchchanda, Kanakamuni, Kashyapa and Sakyamuni. Also depicted are Avalokitesvara, the story of Udayin and Gupta, the story of Nalagiri, the Wheel of life, a panel celebrating various ancient Indian musicians and a panel that tells of Prince Simhala's expedition to Sri Lanka. The narrative frescos depict the various Jataka tales such as the Shaddanta, Hasti, Hamsa, Vessantara, Sutasoma, Mahakapi (in two versions), Sarabhamiga, Machchha, Matiposaka, Shyama, Mahisha, Valahassa, Sibi, Ruru and Nigrodamiga Jatakas. The depictions weave in the norms of the early 1st millennium culture and the society. They show themes as diverse as a shipwreck, a princess applying makeup, lovers in scenes of dalliance, and a wine drinking scene of a couple with the woman and man amorously seated. Some frescos attempt to show the key characters from various parts of a Jataka tale by co-depicting animals and attendants in the same scene.

Cave 18 is a small rectangular space (3.38 X 11.66 m) with two octagonal pillars and it joins into another cell. Its role is unclear.

Cave 19 is a worship hall (chaitya griha, 16.05 X 7.09 m) datable to the fifth century CE. The hall shows painted Buddha, depicted in different postures. This worship hall is now visited through what was previously a carved room. The presence of this room before the hall suggests that the original plan included a mandala style courtyard for devotees to gather and wait, an entrance and facade to this courtyard, all of whose ruins are now lost to history. Cave 19 is one of the caves known for its sculpture. It includes Naga figures with a serpent canopy protecting the Buddha, similar to those found for spiritual icons in the ancient Jain and Hindu traditions. It includes Yaksha "dvarapala" (guardian) images on the side of its "vatayana" (arches), flying couples, sitting Buddha, standing Buddhas and evidence that its ceiling was once painted.

The Cave 19 drew upon on the plan and experimentation in Cave 9. It made a major departure from the earlier Hinayana tradition, by carving a Buddha into the stupa, a decision that states Spink must have come from "the highest levels" in the 5th-century Mahayana Buddhist establishment because the king and dynasty that built this cave was from the Shaivism Hindu tradition. Cave 19 excavation and stupa was likely in place by 467 CE, and its finishing and artistic work continued into the early 470s, but it too was an incomplete cave when it was dedicated in 471 CE.

The entrance facade of the Cave 19 worship hall is ornate. Two round pillars with fluted floral patterns and carved garlands support a porch. Its capital is an inverted lotus connecting to an "amalaka". To its left is standing Buddha in "varada hasta mudra" with a devotee prostrating at his feet. On right is a relief of woman with one hand holding a pitcher and other touching her chin. Above is a seated Buddha in meditating mudra. Towards the right of the entrance is the "Mother and Child" sculpture. A figure with begging bowl is the Buddha, watching him are his wife and son.

The worship hall is apsidal, with 15 pillars dividing it into two side aisles and one nave. The round pillars have floral reliefs and a fluted shaft topped with Buddha in its capitals. Next, to the Buddha in the capitals are elephants, horses and flying apsara friezes found elsewhere in India, reflecting the style of the Gupta Empire artwork. According to Sharma, the similarities at the Karla caves Great Chaitya, built in the 2nd century CE, suggest that Cave 19 may have been modeled after it.

The walls and the ceiling of the side aisles inside the worship hall are covered with paintings. These show the Buddha, flowers, and in the left aisle the "Mother and Child" legend again.

Cave 20 is a monastery hall (16.2 X 17.91 m) from the 5th century. Its construction, states Spink, was started in the 460s by king Upendragupta, with his expressed desire "to make the great tree of religious merit grow". The work on Cave 20 was pursued in parallel with other caves. Cave 20 has exquisite detailing, states Spink, but it was relatively lower on priority than Caves 17 and 19. The work on Cave 20 was intermittently stopped and then continued in the following decade.

The vihara consists of a sanctum, four cells for monks and a pillared verandah with two stone cut windows for light. Prior to entering the main hall, on the left of veranda are two Buddhas carved above the window and side cell. The ceiling of the main hall has remnants of painting. The sanctum Buddha is in preaching posture. The cave is known for the sculpture showing seven Buddhas with attendants on its lintel. The cave has a dedicatory Sanskrit inscription in Brahmi script in its verandah, and it calls the cave as a "mandapa".

Many of the figural and ornamental carvings in Cave 20 are similar to Cave 19, and to a lesser degree to those found in Cave 17. This may be because the same architects and artisans were responsible for the evolution of the three caves. The door frames in Cave 20 are quasi-structural, something unique at the Ajanta site. The decorations are also innovative in Cave 20, such as one showing the Buddha seated against two pillows and "a richly laden mango tree behind him", states Spink.

Cave 21, 22, 23 and 24 are all monasteries, representing the final phases of Ajanta's construction. Cave 21 is a hall (28.56 X 28.03 m) with twelve rock cut rooms for monks, a sanctum, twelve pillared and pilastered verandah. The carvings on the pilaster include those of animals and flowers. The pillars feature reliefs of apsaras, Nagaraja and Nagarani, as well as devotees bowing with the namaste mudra. The hall shows evidence that it used to be completely painted. The sanctum Buddha is shown in preaching posture.

Cave 22 is a small vihara (12.72 X 11.58 m) with a narrow veranda and four unfinished cells. It is excavated at a higher level and has to be reached by a flight of steps. Inside, the Buddha is seated in pralamba-padasana. The painted figures in Cave 22 show Manushi-Buddhas with Maitreya. A pilaster on the left side of the Cave 22 veranda has a Sanskrit prose inscription. It is damaged in parts, and the legible parts state that this is a "meritorious gift of a mandapa by Jayata", calling Jayata's family as "a great Upasaka", and ending the inscription with "may the merit of this be for excellent knowledge to all sentient beings, beginning with father and mother".

The Cave 23 is also unfinished, consisting of a hall (28.32 X 22.52 m) but a design similar to Cave 21. The cave differs in its pillar decorations and the naga doorkeepers.
Cave 24 is like Cave 21, unfinished but much larger. It features the second largest monastery hall (29.3 X 29.3 m) after Cave 4. The cave 24 monastery has been important to scholarly studies of the site because it shows how multiple crews of workers completed their objectives in parallel. The cell construction began as soon as the aisle had been excavated and while the main hall and sanctum were under construction. The construction of Cave 24 was planned in 467 CE, but likely started in 475 CE, with support from Buddhabhadra, then abruptly ended in 477 with the sponsor king Harisena's death.

Cave 24 is significant in having one of the most complex capitals on a pillar at the Ajanta site, an indication of how the artists excelled and continuously improved their sophistication as they worked with the rock inside the cave. The artists carved fourteen complex miniature figures on the central panel of the right center porch pillar, while working in dim light in a cramped cave space. The medallion reliefs in Cave 24 similarly show loving couples and anthropomorphic arts, rather than flowers of earlier construction. Cave 24's sanctum has a seated Buddha in pralamba-padasana.

Cave 25 is a monastery. Its hall (11.37 X 12.24 m) is similar to other monasteries, but has no sanctum, includes an enclosed courtyard and is excavated at an upper level.

Cave 26 is a worship hall (chaityagriha, 25.34 X 11.52 m) similar in plan to Cave 19, but much larger and with elements of a vihara design. An inscription states that a monk Buddhabhadra and his friend minister serving king of Asmaka gifted this vast cave. The inscription includes a vision statement and the aim to make "a memorial on the mountain that will endure for as long as the moon and the sun continue", translates Walter Spink. It is likely that the builders focussed on sculpture, rather than paintings, in Cave 26 because they believed stone sculpture will far more endure than paintings on the wall.

The cave drew upon the experiences in building Cave 10, with attached wings similar to the ancient Cave 12 Hinayana-style vihara. The Cave 26 complex has two upper stories and it shows evidence that four wings of the cave were planned, but these were abandoned and only the carved Buddhas on the right and left wall were completed.

At the center of the apse is a rock-cut stupa. The stupa has an image of the Buddha on its front, 18 panels on its base, 18 panels above these, a three tiered "torana" above him, and apsaras are carved on the "anda" (hemispherical egg) stupa. On top of the dagoba is a nine-tiered "harmika", a symbolism for the nine saṃsāra (Buddhism) heavens in Mahayana cosmology. The walls, pillars, brackets and the triforium are extensively carved with Buddhist themes. Many of the wall reliefs and images in this cave were badly damaged, and have been restored as a part of the site conservation efforts.

Between cave 26 and its left wing, there is an inscription by a courtier of Rashtrakuta Nanaraj (who is mentioned in the Multai and Sangaloda plates), from late 7th or early 8th century. It is the last inscription in Ajanta.

Cave 27 is a monastery and it may have been planned as an attachment to Cave 26. It is damaged two storeys, with the upper level partially collapsed. Its plan is similar to other monasteries. Cave 28 is an unfinished monastery, partially excavated, at the westernmost end of the Ajanta complex and barely accessible.

Cave 29 is an unfinished monastery at the highest level of the Ajanta complex, apparently unnoticed when the initial numbering system was established, and physically located between Caves 20 and 21.

In 1956, a landslide covered the footpath leading to Cave 16. In the attempts to clear and restore the walkway, a small aperture and votive stupa were noticed in the debris by the workers, in a location near the stream bed. Further tracing and excavations led to a previously unknown Hinayana monastery cave dated to the 2nd and 1st century BCE. Cave 30 may actually be the oldest cave of the Ajanta complex. It is a 3.66 m x 3.66 m cave with three cells, each with two stone beds and stone pillows on the side of each cell. The cell door lintels show lotus and garland carvings. The cave has two inscriptions in an unknown script. It also has a platform on its veranda with a fine view of the river ravine below and the forest cover. According to Gupte and Mahajan, this cave may have been closed at some point with large carefully carved pieces as it distracted the entrance view of Cave 16.

Over 80% of the Ajanta caves were "vihara" (temporary traveler residences, monasteries). The designers and artisans who built these caves included facilities for collecting donations and storing grains and food for the visitors and monks. Many of the caves include large repositories cut into the floor. The largest storage spaces are found, states Spink, in the "very commodious recesses in the shrines of both Ajanta Cave Lower 6 and Cave 11". These caves were probably chosen because of their relative convenience and the security they offered due to their higher level. The choice of integrating covered vaults cut into the floor may have been driven by the need to provide sleeping space and logistical ease.

The paintings have deteriorated significantly since they were rediscovered, and a number of 19th-century copies and drawings are important for a complete understanding of the works. A number of attempts to copy the Ajanta paintings began in the 19th-century for European and Japanese museums. Some of these works have later been lost in natural and fire disasters. In 1846 for example, Major Robert Gill, an Army officer from Madras Presidency and a painter, was appointed by the Royal Asiatic Society to make copies of the frescos on the cave walls. Gill worked on his painting at the site from 1844 to 1863. He made 27 copies of large sections of murals, but all but four were destroyed in a fire at the Crystal Palace in London in 1866, where they were on display. Gill returned to the site, and recommenced his labours, replicating the murals until his death in 1875.
Another attempt was made in 1872 when the Bombay Presidency commissioned John Griffiths to work with his students to make copies of Ajanta paintings, again for shipping to England. They worked on this for thirteen years and some 300 canvases were produced, many of which were displayed at the Imperial Institute on Exhibition Road in London, one of the forerunners of the Victoria and Albert Museum. But in 1885 another fire destroyed over a hundred of the paintings in storage in a wing of the museum. The V&A still has 166 paintings surviving from both sets, though none have been on permanent display since 1955. The largest are some . A conservation project was undertaken on about half of them in 2006, also involving the University of Northumbria. Griffith and his students had unfortunately painted many of the paintings with "cheap varnish" in order to make them easier to see, which has added to the deterioration of the originals, as has, according to Spink and others, recent cleaning by the ASI.
A further set of copies were made between 1909 and 1911 by Christiana Herringham (Lady Herringham) and a group of students from the Calcutta School of Art that included the future Indian Modernist painter Nandalal Bose. The copies were published in full colour as the first publication of London's fledgling India Society. More than the earlier copies, these aimed to fill in holes and damage to recreate the original condition rather than record the state of the paintings as she was seeing them. According to one writer, unlike the paintings created by her predecessors Griffiths and Gill, whose copies were influenced by British Victorian styles of painting, those of the Herringham expedition preferred an 'Indian Renascence' aesthetic of the type pioneered by Abanindranath Tagore.

Early photographic surveys were made by Robert Gill, who learnt to use a camera from about 1856, and whose photos, including some using stereoscopy, were used in books by him and Fergusson (many are available online from the British Library), then Victor Goloubew in 1911 and E.L. Vassey, who took the photos in the four volume study of the caves by Ghulam Yazdani (published 1930–1955).
Some slightly creative copies of Ajanta frescos, especially the painting of the Adoration of the Buddha from the shrine antechamber of Cave 17, were commissioned by Thomas Holbein Hendley (1847–1917) for the decoration of the walls of the hall of the Albert Hall Museum, Jaipur, India. He had the work painted by a local artist variously named Murli or Murali. The museum was opened to the public in 1887. This work is otherwise presented as characteristic of the end of the 19th century.

Another attempt to make copies of the murals was made by the Japanese artist Arai Kampō (荒井寛方:1878–1945) after being invited by Rabindranath Tagore to India to teach Japanese painting techniques. He worked on making copies with tracings on Japanese paper from 1916 to 1918 and his work was conserved at Tokyo Imperial University until the materials perished during the 1923 Great Kantō earthquake.

The Ajanta cave arts are a window into the culture, society and religiosity of the native population of India between the 2nd century BCE and 5th century CE. Different scholars have variously interpreted them from the perspective of gender studies, history, sociology, and the anthropology of South Asia. The dress, the jewelry, the gender relations, the social activities depicted showcase at least a lifestyle of the royalty and elite, and in others definitely the costumes of the common man, monks and rishi depicted therein. They shine "light on life in India" around mid 1st millennium CE.

The Ajanta artworks provide a contrast between the spiritual life of monks who had given up all materialistic possessions versus the sensual life of those it considered materialistic, luxurious, symbols of wealth, leisurely and high fashion. Many frescos show scenes from shops, festivals, jesters at processions, palaces and performance art pavilions. These friezes share themes and details of those found in Bharhut, Sanchi, Amaravati, Ellora, Bagh, Aihole, Badami and other archaeological sites in India. Ajanta caves contributes to visual and descriptive sense of the ancient and early medieval Indian culture and artistic traditions, particularly those around the Gupta Empire era period.

The early colonial era description of Ajanta caves was largely orientalist and critical, inconsistent with the Victorian values and stereotyping. According to William Dalrymple, the themes and arts in the Ajanta caves were puzzling to the 19th-century Orientalists. Lacking the Asian cultural heritage and framework that sees "nothing odd in the juxtaposition of monk and dancing girl", and with no knowledge of Jataka Tales or equivalent Indian fables, they could not comprehend it. They projected their own views and assumptions, calling it something that lacks reason and rationale, something that is meaningless crude representation of royalty and foreigners with mysticism and sensuousness. The 19th-century views and interpretations of the Ajanta Caves were conditioned by ideas and assumptions in the colonial mind, saw what they wanted to see.

To many who are unaware of the premises of Indian religions in general, and Buddhism in particular, the significance of Ajanta Caves has been like rest of Indian art. According to Richard Cohen, Ajanta Caves to them has been yet another example of "worship this stock, or that stone, or monstrous idol". In contrast, to the Indian mind and the larger Buddhist community, it is everything that art ought to be, the religious and the secular, the spiritual and the social fused to enlightened perfection.

According to Walter Spink – one of the most respected Art historians on Ajanta, these caves were by 475 CE a much-revered site to the Indians, with throngs of "travelers, pilgrims, monks and traders". The site was vastly transformed into its current form in just 20 years, between early 460 CE to early 480 CE, by regional architects and artisans. This accomplishment, states Spink, makes Ajanta, "one of the most remarkable creative achievements in man's history".

The Ajanta Caves painting are a significant source of socio-economic information in ancient India, particularly in relation to the interactions of India with foreign cultures at the time most of the paintings were made, in the 5th century CE. Depictions of foreigners abound: according to Spink, "Ajanta’s paintings are filled with such foreign types." They have sometimes been a source of misinterpretation as in the so-called "Persian Embassy Scene". These foreigners may reflect the Sassanian merchants, visitors and the flourishing trade routes of the day.


Cave 1, for example, shows a mural fresco with characters with foreigner faces or dresses, the so-called "Persian Embassy Scene". This scene is located at the right of the entrance door upon entering the hall. According to Spink, James Fergusson, a 19th-century architectural historian, had decided that this scene corresponded to the Persian ambassador in 625 CE to the court of the Hindu Chalukya king Pulakeshin II. An alternate theory has been that the fresco represents a Hindu ambassador visiting the Persian king Khusrau II in 625 CE, a theory that Fergusson disagreed with. These assumptions by colonial British era art historians, state Spink and other scholars, has been responsible for wrongly dating this painting to the 7th century, when in fact this reflects an incomplete Harisena-era painting of a Jataka tale (the Mahasudarsana jataka, in which the enthroned king is actually the Buddha in one of his previous lives as King) with the representation of trade between India and distant lands such as Sassanian near East that was common by the 5th century.

The Cave 1 has several frescos with characters with foreigner faces or dresses. Similar depictions are found in the paintings of Cave 17. Such murals, states Pia Brancaccio, suggest a prosperous and multicultural society in 5th-century India active in international trade. These also suggest that this trade was economically important enough to the Deccan region that the artists chose to include it with precision.

Additional evidence of international trade includes the use of the blue lapis lazuli pigment to depict foreigners in the Ajanta paintings, which must have been imported from Afghanistan or Iran. It also suggests, states Branacaccio, that the Buddhist monastic world was closely connected with trading guilds and the court culture in this period. A small number of scenes show foreigners drinking wine in Caves 1 and 2. Some show foreign Near East kings with wine and their retinue which presumably add to the "general regal emphasis" of the cave. According to Brancaccio, the Ajanta paintings show a variety of colorful, delicate textiles and women making cotton. Textile probably was one of the major exports to foreign lands, along with gems. These were exported first through the Red Sea, and later through the Persian Gulf, thereby bringing a period of economic and cultural exchange between the Indians, the Sasanian Empire and the Persian merchants before Islam was founded in the Arabian peninsula.
While scholars generally agree that these murals confirm trade and cultural connections between India and Sassanian west, their specific significance and interpretation varies. Brancaccio, for example, suggests that the ship and jars in them probably reflect foreign ships carrying wine imported to India. In contrast, Schlinghoff interprets the jars to be holding water, and ships shown as Indian ships used in international trade.

Similar depictions are found in the paintings of Cave 17, but this time in direct relation to the worship of the Buddha. In Cave 17, a painting of the Buddha descending from the Trayastrimsa Heaven shows he being attended by many foreigners. Many foreigners in this painting are thus shown as listeners to the Buddhist Dharma. The ethnic diversity is depicted in the painting in the clothes (kaftans, Sasanian helmets, round caps), haridos and skin colors. In the Visvantara Jataka of Cave 17, according to Brancaccio, the scene probably shows a servant from Central Asia holding a foreign metal ewer, while a dark-complexioned servant holds a cup to an amorous couple. In another painting in Cave 17, relating to the conversion of Nanda, a man possibly from northeast Africa appears as a servant. These representations show, states Brancaccio, that the artists were familiar with people of Sogdia, Central Asia, Persia and possibly East Africa. Another hypothesis is offered by Upadhya, who states that the artists who built Ajanta caves "very probably included foreigners".

Paintings and the cave artwork have become eroded due to decay and human interference. Therefore, many areas of the painted walls, ceilings, and pillars are fragmentary. The painted narratives of the Jataka tales are depicted only on the walls, which demanded the special attention of the devotees. They are didactic in nature, meant to inform the community about the Buddha's teachings and life through successive rebirths. Their placement on the walls required the devotee to walk through the aisles and 'read' the narratives depicted in various episodes. The narrative episodes are depicted one after another, although not in a linear order. Their identification has been a core area of research since the site's discovery in 1819.

The Ajanta paintings, or more likely the general style they come from, influenced painting in Tibet and Sri Lanka.

The rediscovery of ancient Indian paintings at Ajanta provided Indian artists examples from ancient India to follow. Nandalal Bose experimented with techniques to follow the ancient style which allowed him to develop his unique style. Abanindranath Tagore and Syed Thajudeen also used the Ajanta paintings for inspiration.





</doc>
<doc id="2645" url="https://en.wikipedia.org/wiki?curid=2645" title="Ajmer">
Ajmer

Ajmer is one of the major and oldest cities in the Indian state of Rajasthan and the centre of the eponymous Ajmer District. It is located at the centre of Rajasthan, and is home to the Ajmer Sharif shrine.

The city was established as ""Ajayameru"" (Translated as "'Invincible Hills"') by a Shakambhari Chahamana (Chauhan) ruler, either Ajayaraja I or Ajayaraja II, and served as the "Chahamana" capital until the 12th century CE.

Ajmer is surrounded by the Aravalli Mountains. It is the base for visiting Pushkar (11 km), an ancient Hindu pilgrimage city, famous for the temple of Lord Brahma. Ajmer had been a municipality since 1869.

Ajmer has been selected as one of the heritage cities for the HRIDAY - Heritage City Development and Augmentation Yojana and Smart City Mission schemes of Government of India.

Ajmer was originally known as "Ajayameru". The 12th century text "Prithviraja Vijaya" states that the Shakambhari Chahamana (Chauhan) king Ajayaraja II (ruled 1135 CE) established the city of Ajayameru. Historian Dasharatha Sharma notes that the earliest mention of the city's name occurs in Palha's "Pattavali", which was copied in 1113 CE (1170 VS) at Dhara. This suggests that Ajmer was founded sometime before 1113 CE. A "prashasti" (eulogistic inscription), issued by Vigraharaja IV and found at Adhai Din Ka Jhonpra, states Ajayadeva (that is, Ajayaraja II) moved his residence to Ajmer.

The later text "Prabandha-Kosha" states that it was the 8th-century king Ajayaraja I who commissioned the Ajayameru fort, which later came to be known as the Taragarh fort of Ajmer. According to historian R. B. Singh, this claim appears to be true, as inscriptions dated to the 8th century CE have been found at Ajmer. Singh theorizes that Ajayaraja II later expanded the town area, constructed palaces, and moved the Chahamana capital from Shakambhari to Ajmer.

Mughal prince Dara Shikoh was born here in 1615. Jahanara Begum powerful Mughal princess also born here.

During Colonial times Ajmer city served as the headquarters of Ajmer - Merwara Province and possessed a Central jail, a large General Hospital, and two smaller hospitals according to Gazetteer, 1908. It was the headquarters of a native regiment and of a Railway Volunteer corps. From the 1900s, United Free Church of Scotland, the church of England, the Roman Catholics, and the American Episcopal Methodists have mission establishments here. At that time there were twelve printing presses in the city, from which eight weekly newspapers were published.

At the time of Independence Ajmer Continued as a separate state with its own legislature until its merger with erstwhile Rajputana province then called Rajasthan. The Legislature of Ajmer State was housed in the building which now houses T.T. College. It had 30 MLAs. and Haribhau Upadhaya was the first Chief Minister of the erstwhile state and Bhagirath Chaudhary as the first Vidhan Sabha Speaker. In 1956, After acceptance of the proposal by Fazil Ali, Ajmer was merged into Rajasthan to form Ajmer District with the addition of Kishangarh sub-division of Jaipur district.

Gujarati Historic Novel named "Gujaratno Jay" written by Zaverchand Meghani based on various Jain Prabandhas describes city as "Sapadlakshan" (સપાદલક્ષણ).

Ajmer is in the northwest of India and is surrounded by the Aravali Mountains. It is situated on the lower slopes of the Taragarh Hill of that range. To the northwest is the Nagapathar Range of the Aravali Mountain Ranges which protects it from desertification from the Thar Desert.

Ajmer has a hot, semi-arid climate with over of rain every year, but most of the rain occurs in the monsoon months, between June and September. Temperatures remain relatively high throughout the year, with the summer months of April to early July having an average daily temperature of about . During the monsoon there is frequent heavy rain and thunderstorms, but flooding is not a common occurrence. The winter months of November to February are mild and temperate with average temperatures ranging from with little or no humidity. There are, however, occasional cold weather fronts that cause temperatures to fall to near freezing levels.

The Kishangarh Airport is the nearest Airport. It was inaugurated by Former Prime Minister Manmohan Singh in September 2013. The airport was inaugurated by Union Minister of State for Civil Aviation Jayant Sinha and Chief Minister Vasundhara Raje on 11 October 2017.

The Ajmer Junction is the main railway station situated in the city. and was built during colonial times.







Ajmer is called as the Education City of Rajasthan. The Mayo College and the Government Arts college were the principal educational institutions in the Ajmer - Merwara during late 19th century. Ajmer is also home to the Sophia Girls' School, Sophia College, and the Ajmer Music College, founded in 1942, the first accredited institution in Rajputana for teaching classical Hindustani music.

According to the 2011 census, Ajmer had a population of 542,321 in the city, 551,101 including its suburbs.

The female to male ratio in the city was 947/1,000. The literacy rate in the city was 86.52%, male literacy being 92.08% and female literacy being 80.69%.

Ajmer's population growth in the decade was 18.48%; this compares to a growth figure of 20.93% in the previous decade.




</doc>
<doc id="2646" url="https://en.wikipedia.org/wiki?curid=2646" title="Ajmer-Merwara">
Ajmer-Merwara

Ajmer-Merwara, also known as Ajmir Province and as Ajmer-Merwara-Kekri, is a former province of British India in the historical Ajmer region. The territory was ceded to the British by Daulat Rao Sindhia by a treaty on 25 June 1818. 
It was under the Bengal Presidency until 1836 when it became part of the North-Western Provinces comissionat el 1842. Finally on 1 April 1871 it became a separate province as Ajmer-Merwara-Kekri. 
It became a part of independent India on 15 August 1947 when the British left India.

The province consisted of the districts of Ajmer and Merwar, which were physically separated from the rest of British India forming an enclave amidst the many princely states of Rajputana. Unlike these states, which were ruled by local nobles who acknowledged British suzerainty, Ajmer-Merwara was administered directly by the British.

In 1842 the two districts were under a single commissioner, then they were separated in 1856 and were administered by the East India Company. Finally, after 1858, by a chief commissioner who was subordinate to the Governor-General of India's agent for the Rajputana Agency.

The area of the province was . The plateau, on whose centre stands the town of Ajmer, may be considered as the highest point in the plains of North India; from the circle of hills which hem it in, the country slopes away on every side - towards river valleys on the east, south, west and towards the Thar Desert region on the north. The Aravalli Range is the distinguishing feature of the district. The range of hills which runs between Ajmer and Nasirabad marks the watershed of the continent of India. The rain which falls on the southeastern slopes drains into the Chambal, and so into the Bay of Bengal; that which falls on the northwest side into the Luni River, which discharges itself into the Rann of Kutch.

The province is on the border of what may be called the arid zone; it is the debatable land between the north-eastern and south-western monsoons, and beyond the influence of either. The south-west monsoon sweeps up the Narmada valley from Bombay and crossing the tableland at Neemuch gives copious supplies to Malwa, Jhalawar and Kota and the countries which lie in the course of the Chambal River.

The clouds which strike Kathiawar and Kutch are deprived of a great deal of their moisture by the hills in those countries (now the majority of this region is in Gujarat state within independent India), and the greater part of the remainder is deposited on Mount Abu and the higher slopes of the Aravalli Range, leaving but little for Merwara, where the hills are lower, and still less for Ajmer. It is only when the monsoon is in considerable force that Merwara gets a plentiful supply from it. The north-eastern monsoon sweeps up the valley of the Ganges from the Bay of Bengal and waters the northern part of Rajasthan, but hardly penetrates farther west than the longitude of Ajmer. The rainfall of the district depends on the varying strength of these two monsoons. The agriculturist of Ajmer-Merwara could never rely upon two good harvests in succession.

In ancient times, the Mair Gurjars were the dominant inhabitants. They were defeated by the Chauhan Kings Rao Anoop and Rao Anhal, whose descendents the Chauhan Rajputs were the dominant group here. The rajputs continued to have influence on the politics of the region.

Before the arrival of the British, Chauhan Rajputs were land-holders, as well as cultivators. "Thakur" was the title of the Rajputs, 11 prominent Rajput chieftains were Bhinai, Pisangan, Kharwa, Masuda, Bandanwara, Para, Kairot, Junia, Baghera, Tanoti, and Bagsuri.These were prominent Rajput Thikanas of the Mertia/Jodha clan. Prominent chieftains of the Mehrats were the lords of Athoon, Chaang, Shyamgarh, Borwa etc. "Chauhan" was the title of Mehrat Rajputs, such as the Chauhahan of Athun, a major Thikana of the Rajput clan, The two major thikanas of Chauhan Rajputs are Bhim ruled by the sujawat clan and Diver, ruled by the Varaat clan .Thakur is the title used by the Chauhan Rajputs and many Mehrats who refer each other as Thaakar in general conversation.

Part of the Ajmer region, the territory of the future province was ceded to the British by Daulat Rao Sindhia of Gwalior State as part of a treaty dated 25 June 1818. Then in May 1823 the Merwara (Mewar) part was ceded to Britain by Udaipur State. Thereafter Ajmer-Merwara was administered directly by the British East India Company. After the Indian Mutiny of 1857, in 1858 the powers of the Company were transferred to the British Crown and the Governor-General of India. His administration of Ajmer-Merwara was controlled by a chief commissioner who was subordinate to the British agent for the Rajputana Agency.





From the date of partition and independence in 1947 until 1950, Ajmer-Merwara remained a province of the new Dominion of India. In 1950 it became Ajmer State, which on 1 November 1956, was merged into the state of Rajasthan.

The Rajasthan Land Reforms and Resumption of Jagirs Act, 1952 was the landmark in the legal history of land reforms in Rajasthan which was followed by Rajasthan Tenancy Act, 1955 that became applicable to the whole of Rajasthan. The overriding effect of this Act provided relief to the existing tenants and the rights accrued to tenants accordingly. Now the Jats are major land holders in the region.



</doc>
<doc id="2654" url="https://en.wikipedia.org/wiki?curid=2654" title="Abatement of debts and legacies">
Abatement of debts and legacies

Abatement of debts and legacies is a common law doctrine of wills that holds that when the equitable assets of a deceased person are not sufficient to satisfy fully all the creditors, their debts must abate proportionately, and they must accept a dividend.

In the case of legacies when the funds or assets out of which they are payable are not sufficient to pay them in full, the legacies abate in proportion, unless there is a priority given specially to any particular legacy. Annuities are also subject to the same rule as general legacies.

The order of abatement is usually:
Non-probate property—"i.e.", life insurance policies—do not abate.

A specific devise, is a specific gift in a will to a specific person other than an amount of money. For example, if James's will states that he is leaving his $500,000 yacht to his brother Mike, the yacht would be a specific devise.

A general devise, is a monetary gift to a specific person to be satisfied out of the overall estate. For example, if James's will states that he is leaving $500,000 to his son Sam then the money would be a general devise.

A demonstrative devise, is money given from a particular account. For example, "$10,000 to be paid from the sale of my GM stock."

A residual devise is one left to a devisee after all specific and general devices have been made. For example, James's will might say: "I give all the rest, residue and remainder of my estate to my daughter Lilly." Lilly would be the residual devisee and entitled to James's residuary estate.


</doc>
<doc id="2661" url="https://en.wikipedia.org/wiki?curid=2661" title="Affection">
Affection

Affection, attraction, infatuation, or fondness is a "disposition or state of mind or body" that is often associated with a feeling or type of love. It has given rise to a number of branches of philosophy and psychology concerning emotion, disease, influence, and state of being. "Affection" is popularly used to denote a feeling or type of love, amounting to more than goodwill or friendship. Writers on ethics generally use the word to refer to distinct states of feeling, both lasting and spasmodic. Some contrast it with "passion" as being free from the distinctively sensual element.

Even a very simple demonstration of affection can have a broad variety of emotional reactions, from embarrassment to disgust to pleasure and annoyance. It also has a different physical effect on the giver and the receiver.

More specifically, the word has been restricted to emotional states, the object of which is a living thing such as a human or animal. Affection is compared with passion, from the Greek "pathos". As such it appears in the writings of French philosopher René Descartes, Dutch philosopher Baruch Spinoza, and most of the writings of early British ethicists. However, on various grounds (e.g., that it does not involve anxiety or excitement and that it is comparatively inert and compatible with the entire absence of the sensuous element), it is generally and usefully distinguished from passion. In this narrower sense, the word has played a great part in ethical systems, which have spoken of the social or parental "affections" as in some sense a part of moral obligations. For a consideration of these and similar problems, which depend ultimately on the degree in which the affections are regarded as voluntary.

Affection can be communicated by looks, words, gestures, or touches. It conveys love and social connection. Affectionate behavior may have evolved from parental nurturing behavior due to its associations with hormonal rewards. Such affection has been shown to influence brain development in infants. 
Expressions of affection can be unwelcome if they pose implied threats to one's well being. If welcomed, affectionate behavior may be associated with various health benefits. It has been proposed that positive sentiments increase the propensity of people to interact and that familiarity gained through affection increases positive sentiments among them. A slap on the back is usually a male equivalent to a good close hug.

Affection exchange is seen as an adaptive human behavior that contributes to greater physical and mental well-being. The expression of affection mediates emotional, physical, and relational benefits for the individual and significant counterparts. The communication of positive feelings towards others has shown health benefits that include; lower stress hormones, lower cholesterol, lower blood pressure and stronger immune system. Affection Expression Benefits are internally noticed when the emotion is expressed and not merely felt, if affection is not reciprocated through the receiver, effects of the affection are still felt through the giver.

Affectionate behavior is often regarded as the result of parental nurturing behavior due to its associations with hormonal rewards. Positive and negative parental behaviors can be linked to later life health problems. Abuse is a common attribute to poor health in later life, as the lack of affection leads to naturally poorer well-being and mental health. A 2013 study, UCLA affection showed the effects of early child abuse and the outcome between lack of affection and the strong biological link for how these negative early-life experiences affect physical health.

Affectionism is a school of thought which considers affections as central importance. Although it is not found in mainstream Western philosophy, it does exist in Indian philosophy.



</doc>
<doc id="2662" url="https://en.wikipedia.org/wiki?curid=2662" title="Affiliation (family law)">
Affiliation (family law)

In law, affiliation (from Latin "affiliare", "to adopt as a son") was previously the term to describe legal establishment of paternity. The following description, for the most part, was written in the early 20th century, and it should be understood as a historical document.

In England a number of statutes on the subject have been passed, the chief being the Bastardy Act of the Parliament of 1845, and the Bastardy Laws Amendment Acts of 1872 and 1873.
The mother of a bastard may summon the putative father to petty sessions within 12 months of the birth (or at any later time if he is proved to have contributed to the child's support within 12 months after the birth), and the justices, after hearing evidence on both sides, may, if the mother's evidence be corroborated in some material particular, adjudge the man to be the putative father of the child, and order him to pay a sum not exceeding five shillings a week for its maintenance, together with a sum for expenses incidental to the birth, or the funeral expenses, if it has died before the date of order, and the costs of the proceedings. An order ceases to be valid after the child reaches the age of 13, but the justices (also referred to as Gold writers under these circumstances) may in the order direct the payments to be continued until the child is 16 years of age. 

An appeal to quarter sessions is open to the defendant, and a further appeal on questions of law to the King's Bench by rule "nisi or certiorari". Should the child afterwards become chargeable to the parish, the sum due by the father may be received by the parish officer. When a bastard child, whose mother has not obtained an order, becomes chargeable to the parish, the guardians may proceed against the putative father for a contribution.

Any woman who is single, a widow, or a married woman living apart from her husband, may make an application for a summons, and it is immaterial where the child is begotten, provided it is born in England. An application for a summons may be made before the birth of the child, but in this case, the statement of the mother must be in the form of a sworn deposition. The defendant must be over 14 years of age. No agreement on the part of the woman to take a sum down in a discharge of the liability of the father is a bar to the making of an affiliation order. In the case of twins, it is usual to make separate applications and obtain separate summonses.

The Summary Jurisdiction Act (1879) makes due provision for the enforcement of an order of affiliation. In the case of soldiers an affiliation order cannot be enforced in the usual way, but by the Army Act (1881), if an order has been made against a soldier of the regular forces, and a copy of such order be sent to the secretary of state, he may order a portion of the soldier's pay to be retained. There is no such special legislation with regard to sailors in the Royal Navy.

In the British colonies, and in the states of the United States (with the exception of California, Idaho, Missouri, Oregon, Texas and Utah), there is some procedure (usually termed "filiation") akin to that described above, by means of which a mother can obtain a contribution to the support of her illegitimate child from the putative father. The amount ordered to be paid may subsequently be increased or diminished (1905; 94 N.Y. Supplt. 372).

On the continent of Europe, however, the legislation of the various countries differs rather widely. France, Belgium, the Netherlands, Italy, Russia, Serbia and the canton of Geneva provide no means of inquiry into the paternity of an illegitimate child, and consequently all support of the child falls upon the mother; on the other hand, Germany, Austria, Norway, Sweden, Denmark and the majority of the Swiss cantons provide for an inquiry into the paternity of illegitimate children, and the law casts a certain amount of responsibility upon the father.

Affiliation, in France, is a term applied to a species of adoption by which the person adopted succeeds equally with other heirs to the acquired, but not to the inherited, property of the deceased.

In India, affiliation cases are decided by section 125 of Criminal Procedure Code (Cr.P.C.). According to this section - among other things - if a person having sufficient means neglects or refuses to maintain his illegitimate child, a magistrate of the first class may, upon proof of such neglect or refusal, order such person to make a monthly allowance for the maintenance of such child.



</doc>
<doc id="2663" url="https://en.wikipedia.org/wiki?curid=2663" title="Affinity">
Affinity

Affinity may refer to:











</doc>
<doc id="2665" url="https://en.wikipedia.org/wiki?curid=2665" title="Affray">
Affray

In many legal jurisdictions related to English common law, affray is a public order offence consisting of the fighting of one or more persons in a public place to the terror (in ) of ordinary people. Depending on their actions, and the laws of the prevailing jurisdiction, those engaged in an affray may also render themselves liable to prosecution for assault, unlawful assembly, or riot; if so, it is for one of these offences that they are usually charged.

The common law offence of affray was abolished for England and Wales on 1 April 1987. Affray is now a statutory offence that is triable either way. It is created by section 3 of the Public Order Act 1986 which provides:
The term "violence" is defined by section 8.

Section 3(6) once provided that a constable could arrest without warrant anyone he reasonably suspected to be committing affray, but that subsection was repealed by paragraph 26(2) of Schedule 7 to, and Schedule 17 to, the Serious Organised Crime and Police Act 2005.

The "mens rea" of affray is that person is guilty of affray only if he intends to use or threaten violence or is aware that his conduct may be violent or threaten violence.

The offence of affray has been used by HM Government to address the problem of drunken or violent individuals who cause serious trouble on airliners.

In "R v Childs & Price" 2015, the Court of Appeal quashed a murder verdict and replaced it with affray, having dismissed an allegation of common purpose.

Affray is a serious offence for the purposes of Chapter 3 of the Criminal Justice (Northern Ireland) Order 2008.

In New South Wales, section 93C of the Crimes Act of 1900 defines that a person will be guilty of affray if he or she threatens unlawful violence towards another and his or her conduct is such as would cause a person of reasonable firmness present at the scene to fear for his or her personal safety. A person will only be guilty of affray if the person intends to use or threaten violence or is aware that his or her conduct may be violent or threaten violence. The maximum penalty for an offence of affray contrary to section 93C is a period of imprisonment of 10 years.

In Queensland, section 72 of the Criminal Code of 1899 defines affray as taking part in a fight in a public highway or taking part in a fight of such a nature as to alarm the public in any other place to which the public have access. This definition is taken from that in the English Criminal Code Bill of 1880, cl. 96. Section 72 says "Any person who takes part in a fight in a public place, or takes part in a fight of such a nature as to alarm the public in any other place to which the public have access, commits a misdemeanour. Maximum penalty—1 year’s imprisonment."

The Indian Penal Code (sect. 159) adopts the old English common law definition of affray, with the substitution of "actual disturbance of the peace for causing terror to the "lieges"".

In New Zealand affray has been codified as "fighting in a public place" by section 7 of the Summary Offences Act 1981.

Under the Roman-Dutch law in force in South Africa affray falls within the definition of "vis publica".

In the United States the English common law as to affray applies, subject to certain modifications by the statutes of particular states.




</doc>
<doc id="2667" url="https://en.wikipedia.org/wiki?curid=2667" title="Afghan Turkestan">
Afghan Turkestan

Afghan Turkestan (Persian/Uzbek/Turkmen/Pashto: ) is a region in northern Afghanistan, on the border with the former Soviet republics of Turkmenistan, Uzbekistan and Tajikistan. In the 19th century there was a province in Afghanistan named Turkestan Province until abolished by Abdur Rahman, and was centred on Mazari Sharif and included territory in the modern provinces of Balkh, Kunduz, Jowzjan, Sar-e Pol, and Faryab. The whole territory, from the junction of the Kokcha river with the Amu Darya on the north-east to the province of Herat on the south-west, was some in length, with an average width from the Russian frontier to the Hindu Kush of 114 miles (183 km). It thus comprised about or roughly two-ninths of the former Kingdom of Afghanistan.

The area is agriculturally poor except in the river valleys, being rough and mountainous towards the south, but subsiding into undulating wastes and pasture-lands towards the Karakum Desert.

The province included the khanates of Kunduz, Tashkurgan, Balkh, and Akcha in the east and the four khanates or "Chahar Vilayet" ("four domains") of Saripul, Shibarghan, Andkhoy, and Maymana in the west.

The bulk of the people are Uzbek and Turkmen with large concentrations of Hazara, Tajik and Pashtun.

Ancient Balkh or Bactria was an integral part of Bactria–Margiana Archaeological Complex, and was occupied by Indo-Iranians. In the 5th century BCE, it became a province of the Achaemenian Empire and later became part of the Seleucid Empire. About 250 BC Diodotus (Theodotus), governor of Bactria under the Seleucidae, declared his independence, and commenced the history of the Greco-Bactrian dynasties, which succumbed to Parthian and nomadic movements about 126 BC. After this came a Buddhist era which has left its traces in the gigantic sculptures at Bamian and the rock-cut topes of Haibak. The district was devastated by Genghis Khan, and has never since fully recovered its prosperity. For about a century it belonged to the Delhi empire, and then fell into Uzbek hands. In the 18th century it formed part of the dominion of Ahmad Shah Durrani, and so remained under his son Timur. But under the fratricidal wars of Timur's sons the separate khanates fell back under the independent rule of various Uzbek chiefs. At the beginning of the 19th century they belonged to Bukhara; but under the emir Dost Mahommed the Afghans recovered Balkh and Tashkurgan in 1850, Akcha and the four western khanates in 1855, and Kunduz in 1859. The sovereignty over Andkhoy, Shibarghan, Saripul, and Maymana was in dispute between Bukhara and Kabul until settled by the Anglo-Russian agreement of 1873 in favour of the Afghan claim. Under the strong rule of Abdur Rahman these outlying territories were closely welded to Kabul; but after the accession of Habibullah the bonds once more relaxed. In the late 19th and 20th centuries, many ethnic Pashtuns either voluntarily or involuntarily settled in Afghan Turkestan.

In 1890, the district of Qataghan and Badakhshan was divided from Afghan Turkestan and made into the Qataghan-Badakhshan Province. Administration of the province was assigned to the Northern Bureau in Kabul.


</doc>
<doc id="2668" url="https://en.wikipedia.org/wiki?curid=2668" title="Afyonkarahisar">
Afyonkarahisar

Afyonkarahisar (, "poppy, opium", "kara" "black", "hisar" "fortress") is a city in western Turkey, the capital of Afyon Province. Afyon is in mountainous countryside inland from the Aegean coast, south-west of Ankara along the Akarçay River. Elevation . Population (2010 census) 173,100 
In Turkey, Afyonkarahisar stands out as a capital city of thermal and spa, an important junction of railway, highway and air traffic in West-Turkey, and the grounds where independence had been won.
In addition, Afyonkarahisar is one of the top leading provinces in agriculture, globally renowned for its marble and globally largest producer of pharmaceutical opium.

The name Afyon Kara Hisar (literally "opium black castle" in Turkish), since opium was widely grown here and there is a castle on a black rock. Also known simply as Afyon. Older spellings include Karahisar-i Sahip, Afium-Kara-hissar and Afyon Karahisar. The city was known as Afyon (opium), until the name was changed to Afyonkarahisar by the Turkish Parliament in 2004.

The top of the rock in Afyon has been fortified for a long time. It was known to the Hittites as Hapanuwa, and was later occupied by Phrygians, Lydians and Achaemenid Persians until it was conquered by Alexander the Great. After the death of Alexander the city (now known as Akroinοn (Ακροϊνόν) or Nikopolis (Νικόπολις) in Ancient Greek), was ruled by the Seleucids and the kings of Pergamon, then Rome and Byzantium. The Byzantine emperor Leo III after his victory over Arab besiegers in 740 renamed the city Nicopolis (Greek for "city of victory"). The Seljuq Turks then arrived in 1071 and changed its name to Kara Hissar ("black castle") after the ancient fortress situated upon a volcanic rock 201 meters above the town. Following the dispersal of the Seljuqs the town was occupied by the Sâhib Ata and then the Germiyanids.

The castle was much fought over during the Crusades and was finally conquered by the Ottoman Sultan Beyazid I in 1392 but was lost after the invasion of Timur Lenk in 1402. It was recaptured in 1428 or 1429.

The area thrived during the Ottoman Empire, as the centre of opium production and Afyon became a wealthy city. In 1902, a fire burning for 32 hours destroyed parts of the city.

During the 1st World War British prisoners of war who had been captured at Gallipoli were housed here in an empty Armenian church at the foot of the rock. During the Greco-Turkish War (1919-1922) campaign (part of the Turkish War of Independence) Afyon and the surrounding hills were occupied by Greek forces. However, it was recovered on 27 August 1922, a key moment in the Turkish counter-attack in the Aegean region. After 1923 Afyon became a part of the Republic of Turkey.

The region was a major producer of raw opium (hence the name "Afyon") until the late 1960s when under international pressure, from the US in particular, the fields were burnt and production ceased. Now poppies are grown under a strict licensing regime. They do not produce raw opium any more but derive Morphine and other opiates using the poppy straw method of extraction.

Afyon was depicted on the reverse of the Turkish 50 lira banknote of 1927-1938.

The economy of Afyonkarahisar is based on agriculture, industries and thermal tourism. 
Especially its agriculture is strongly developed from the fact, a large part of its population living in the countrysides. Which stimulated agricultural activities greatly.

Afyonkarahisar produces an important chunk of Turkish processed marbles, it ranks second on processed marble exports and fourth on travertine. Afyon holds an important share of Turkish marble reserves, with some 12,2% of total Turkish reserves.

Afyon has unique marble types and colors, which were historically very renown and are unique to Afyon. Like "Afyon white", historically known as "Synnadic white". "Afyon Menekse", historically known as "Pavonazzetto" and "Afyon kaplan postu", this type wasn't popular.
Historically marble from Afyon was generally referred to as "Docimeaen marble".
Docimian marble was highly admired and valued for its unique colors and fine grained quality, by ancients such as Romans. When the Romans took control over Docimian quarries, they were blown away about the beautiful color combinations of Docimian Pavonazzetto, which is a type of white marble with purple veins. A trend started about it right away. Emperors Augustus, Trajan, Hadrian, all made extensive use of Docimian marble to all their major building projects.

Docimian Pavonazzetto was extensively used in major building projects in the very heart of Rome aka Forum Romanum and all over the empire. Pavonazzetto was used on the most eye catching places such as, columns, wall and floor veneer and wall reliefs. Other marbles from all corners of the empire were used in combination, whenever Pavonazzetto was used as floor cover, it was usually in combination with other decorative marbles. But, the Pavonazzetto being a white marble was mostly the dominant color and gave the buildings a freshening white color. 

One of the greatest Roman architectural piece, the Pantheon contains Docimian Pavonazzetto as floor pavement along with other marble types. The dominant white color is the Pavonazzetto, also some of the interior main columns and pilasters are made from Docimian marble.
Other buildings in Roman capital which contains or contained Docimian marble were, 
Forum of Augustus, Forum of Trajan (floor and 184 column shafts), Temple of Mars Ultor (floor), Temple of Apollo (floor), Basilica Aemelia (20 statues), Basilica Julia (floor and some columns), Basilica Ulpia (some of the columns),
Basilica San Paolo Fuori Le Mura (24 columns, destroyed by fire in 1823),
The eight statues on the Arch of Constantine,
The greatest Roman bath, Baths of Caracalla (some of the columns and wall veneer.

Other major buildings outside Italy, Rome were :

The Hagia Sophia, one of the greatest buildings ever built, has Docimian marble as veneer on the aisles and galleries.

The heart of Catholic Christianity, Saint Peter's Basilica, as veneer.

Lepcis Magna, former limestone columns were replaced with Pavonazzetto. 
Library of Celsus, the columns on the famous wall.

Ancient City of Sagalassos, as wall and floor covering, 40 tons of veneer were recovered.

Temple of Zeus and Hera in Greece, 100 columns and wall.

Docimian marble was also preferred for sarcophagi sculpting, some emperors preferred this marble for its high value and majestic looks. As a result, one of the greatest masterpieces were made from this material. Such as sarcophagus of, Sidamara, Silifkeh, Seleukeia, Eudocia, Heraclius...several hundreds sarcophagi were constructed.

The geography of Afyon has great geothermal activity. Hence, the place has plenty thermal springs, there are about 5 main springs. Each of them have high mineral contents and high degree's, 40 °C-100 °C. The waters have strong healing properties to some diseases.
As a result, plenty of thermals commenced over time.

In time Afyon has developed it's thermal sector with more capacity, comfort and innovation. Afyon combined the traditional bath houses with 5 star resorts, the health benefits of the natural springs have put the thermal resorts further then a mere attraction.
Hospitals and universities have come in association with thermal resorts, to utilize the full health potentials of the thermals. 
As such, Kocatepe University Physical Therapy and Rehabilitation Hospital opened for that purpose. 
Afyon now has the largest residence capacity of thermal resorts, of which a large part are 5 star thermal hotels which give medical care with qualified personnel.

Kizilay, was the first mineral water factory in Turkey which opened in Afyon, in 1926 by Atatürk. After the mineral water from Gazligöl springs, healed Ataturks kidneys and proved its health benefits. Since its foundation, "Kizilay Spa Water" grew as the biggest spa water distributor in Turkey, Middle-East and Balkans.

Almost a third of all the morphine produced in the world derives from alkaloids factory in Afyon, named as "Afyon Alkaloids". this large capacity is the byproduct of Afyon's poppy plantations. The pharmaceuticals derive from the opium of the poppy capsules. 
"Afyon Alkaloids" factory is the largest of its kind in the world, with high capacity processing ability and modern laboratories. The raw opium is put through a chain of biochemical processes, resulting into several types of morphine.

In the Alkaloid Extraction Unit only base morphine is produced. In the adjacent Derivatives Unit half of the morphine extracted is converted to morphine hydrochloride, codeine, codeine phosphate, codeine sulphate, codeine hydrochloride, morphine sulphate, ethylmorphine hydrochloride.

Livestocks
Afyon breeds a large amount of livestocks, its landscape and demography is suitable for this field. As such it ranks in the top 10 within Turkey in terms of amounts of sheep and cattle it has.

Meat and meat products
As a result of being an important source of livestock, related sectors such as meat and meat products are also very productive in afyon. Its one of the leading provinces in red meat production and has very prestigious brand marks of sausages, such as "Cumhuriyet Sausages".

Eggs
Afyon is the sole leader in egg production within Turkey. It has the largest amount of laying hens, with a figure of 12,7 million. And produces a record amount of 6 million eggs per day.

Cherries and sour cherries
Sour cherries are cultivated in Afyon in very large numbers, so much so that it became very iconic to Afyon. Every year, a sour cherry festival takes place in the Cay district. It is the largest producer of sour cherries in Turkey. The sour cherries grown in Afyon are of excellent quality because of the ideal climate they're grown in. For the same reason Afyon is also an ideal place for cherry cultivation. First quality cherries known as "Napolyon Cherries" are grown in abundance, its one of the top 5 leading provinces.
Poppy
One of the iconic agricultural practices of Afyon is the cultivation of poppy. Afyon's climate is ideal for the cultivation of this plant, hence a large amount of poppy plantation occurs in this region. Though, a strong limitation came some decades ago from international laws, cause of the opium content of poppy plants peels. Nevertheless, Afyon is the largest producer of poppy in Turkey and accounts for a large amount of global production.

Potatoes and sugar-beets
Afyon has a durable reputation in potato production, it produces around 8% of Turkish potato need. It ranks in the top 5 in potato, sugar-beets, cucumber and barley production.

Afyonkarahisar has a hot and dry summer continental climate (Dsa) under the Köppen classification and a hot summer continental (Dca) or hot summer oceanic climate (Doa) under the Trewartha classification. The winters are cold and snowy winters and the summers are hot and dry with cool nights. Rainfall occurs mostly during the spring and autumn.

Afyon is the centre of an agricultural area and the city has a country town feel to it. There is little in the way of bars, cafes, live music or other cultural amenities, and the standards of education are low for a city in the west of Turkey. Afyon Kocatepe University. Afyon is known for its marble (in 2005 there were 355 marble quarries in the province of Afyon producing high quality white stone), its "sucuk" (spiced sausages), its "kaymak" (meaning either "cream" or a white Turkish Delight) and various handmade weavings. There is also a large cement factory.

This is a natural crossroads, the routes from Ankara to İzmir and from Istanbul to Antalya intersect here and Afyon is a popular stopping-place on these journeys. There are a number of well-established roadside restaurants for travellers to breakfast on the local cuisine. Some of these places are modern well-equipped hotels and spas; the mineral waters of Afyon are renowned for their healing qualities. There is also a long string of roadside kiosks selling the local Turkish delight.

Afyon is also an important rail junction between İzmir, Konya, Ankara and Istanbul. Afyon is on the route of the planned high-speed rail line between Ankara and Izmir.



With its rich architectural heritage, the city is a member of the European Association of Historic Towns and Regions .


Following list is alphabetically sorted after family name.




</doc>
<doc id="2670" url="https://en.wikipedia.org/wiki?curid=2670" title="Abba Arikha">
Abba Arikha

Abba Arikha (175–247) (Talmudic Aramaic: ; born: "Rav Abba bar Aybo", ), commonly known as Rav (), was a Jewish amora of the 3rd century. He was born and lived in Kafri, Sassanid Babylonia. He established at Sura the systematic study of the rabbinic traditions, which, using the Mishnah as text, led to the compilation of the Talmud. With him began the long period of ascendancy of the great academies of Babylonia, around the year 220. In the Talmud, he is frequently associated with Samuel of Nehardea, with whom he debated on many major issues.

His surname, Arikha (English, "Long"—that is, "Tall"; it occurs only once—"Hullin" 137b), he owed to his height, which, according to a reliable record, exceeded that of his contemporaries. Others, reading Arekha, consider it an honorary title, "Lecturer". In the traditional literature he is referred to almost exclusively as Rav, "the Master", (both his contemporaries and posterity recognizing in him a master), just as his teacher, Judah HaNasi, was known simply as "Rabbi". He is called Rabbi Abba only in the "tannaitic" literature, where a number of his sayings are preserved. He occupies a middle position between the "Tannaim" and the "Amoraim", and is accorded the right, rarely conceded to one who is only an " 'amora", of disputing the opinion of a "tanna".

Rav was a descendant of a distinguished Babylonian family which claimed to trace its origin to Shimei, brother of King David. His father, Aibo, was a brother of Hiyya the Great who lived in Palestine, and was a highly esteemed scholar in the collegiate circle of the patriarch Judah haNasi. From his associations in the house of his uncle, and later as his uncle's disciple and as a member of the academy at Sepphoris, Rav acquired such knowledge of the tradition as to make him its foremost exponent in Babylonia. While Judah haNasi was still living, Rav, having been ordained as teacher (with certain restrictions), returned to Babylonia, where he at once began a career that was destined to mark an epoch in the development of Babylonian Judaism.

In the annals of the Babylonian schools, the year of his arrival is recorded as the starting-point in the chronology of the Talmudic age. It was the 530th year of the Seleucidan and the 219th year of the common era. As the scene of his activity, Rav first chose Nehardea, where the exilarch appointed him "agoranomos", or market-master, and Rabbi Shela made him lecturer ("amora") of his college. Then he moved to Sura, on the Euphrates, where he established a school of his own, which soon became the intellectual center of the Babylonian Jews. As a renowned teacher of the Law and with hosts of disciples, who came from all sections of the Jewish world, Rav lived and worked in Sura until his death. Samuel, another disciple of Judah haNasi, at the same time brought to the academy at Nehardea a high degree of prosperity; in fact, it was at the school of Rav that Jewish learning in Babylonia found its permanent home and center. Rav's activity made Babylonia independent of Palestine, and gave it that predominant position which it was destined to occupy for several centuries.

Little is known of Rav's personal life. That he was rich seems probable; for he appears to have occupied himself for a time with commerce and afterward with agriculture. He is referred to as the son of noblemen, but it is not clear if this is an affectionate term or a true description of his status. Rashi does tell us that he is being described as the son of great men. He was highly respected by the Gentiles as well as by the Jews of Babylonia, as shown by the friendship which existed between him and the last Parthian king, Artaban. He was deeply affected by the death of Artaban (226) and the downfall of the Arsacid dynasty, and does not appear to have sought the friendship of Ardeshir, founder of the Sassanian dynasty, although Samuel of Nehardea probably did so.

Rav became closely related, through the marriage of one of his daughters, to the family of the exilarch. Her sons, Mar Ukba and Nehemiah, were considered types of the highest aristocracy. Rav had many sons, several of whom are mentioned in the Talmud, the most distinguished being the eldest, Chiyya. Chiyya did not, however, succeed his father as head of the academy: this post fell to Rav's disciple Rav Huna. Two of his grandsons occupied in succession the office of exilarch.

Rav died at an advanced age, deeply mourned by numerous disciples and the entire Babylonian Jewry, which he had raised from comparative insignificance to the leading position in Judaism.

The method of treatment of the traditional material to which the Talmud owes its origin was established in Babylonia by Rav. That method takes the Mishnah of Judah haNasi as a text or foundation, adding to it the other "tannaitic" traditions, and deriving from all of them the theoretical explanations and practical applications of the religious Law. The legal and ritual opinions recorded in Rav's name and his disputes with Samuel constitute the main body of the Babylonian Talmud. His numerous disciples—some of whom were very influential and who, for the most part, were also disciples of Samuel—amplified and, in their capacity as instructors and by their discussions, continued the work of Rav. In the Babylonian schools, Rav was rightly referred to as "our great master." Rav also exercised a great influence for good upon the moral and religious conditions of his native land, not only indirectly through his disciples, but directly by reason of the strictness with which he repressed abuses in matters of marriage and divorce, and denounced ignorance and negligence in matters of ritual observance.

Rav, says tradition, found an open, neglected field and fenced it in.

He gave special attention to the liturgy of the synagogue. The Aleinu prayer first appeared in the manuscript of the Rosh Hashana liturgy by Rav. He included it in the Rosh Hashana mussaf service as a prologue to the Kingship portion of the Amidah. For that reason some attribute to Rav the authorship, or at least the revising, of Aleinu. In this noble prayer are evinced profound religious feeling and exalted thought, as well as ability to use the Hebrew language in a natural, expressive, and classical manner.

The many homiletic and ethical sayings recorded of him show similar ability. The greatest aggadist among Babylonian "Amoraim", he is the only one of them whose aggadic utterances approach in number and contents those of the Palestinian haggadists. The Jerusalem Talmud has preserved a large number of his halakhic and aggadic utterances; and the Palestinian "Midrashim" also contain many of his "aggadot". Rav delivered homiletic discourses, both in the Beth midrash and in the synagogues. He especially loved to treat in his homilies of the events and personages of Biblical history; and many beautiful and genuinely poetic embellishments of the Biblical record, which have become common possession of the aggadah, are his creations. His "aggadah" is particularly rich in thoughts concerning the moral life and the relations of human beings to one another. A few of these utterances may be quoted here:

Rav loved the "Book of Ecclesiasticus" (Sirach), and warned his disciple Hamnuna against unjustifiable asceticism by quoting advice contained therein—that considering the transitoriness of human life, one should not despise the good things of this world.

To the celestial joys of the future he was accustomed to refer in the following poetic words: 

Rav also devoted much attention to mystical and transcendental speculations regarding Maaseh Bereshit, Maaseh Merkabah, and the Divine Name. Many of his important utterances testify to his tendency in this direction.


</doc>
<doc id="2671" url="https://en.wikipedia.org/wiki?curid=2671" title="Abbahu">
Abbahu

Abbahu () was a Jewish Talmudist, known as an "amora", who lived in the Land of Israel, of the 3rd amoraic generation (about 279-320), sometimes cited as R. Abbahu of Caesarea (Ḳisrin). His rabbinic education was acquired mainly at Tiberias, in the academy presided over by R. Johanan, with whom his relations were almost those of a son. He frequently made pilgrimages to Tiberias, even after he had become well known as rector of the Caesarean Academy.

Abbahu was an authority on weights and measures. He encouraged the study of Greek by Jews. He learned Greek himself in order to become useful to his people, then under the Roman "proconsuls", that language having become, to a considerable extent, the rival of the Hebrew even in prayer. In spite of the bitter protest of Simon b. Abba, he also taught his daughters Greek. Indeed, it was said of Abbahu that he was a living illustration of the maxim (Ecc.; compare Targum), "It is good that you should take hold of this [the study of the Law]; yea, also from that [other branches of knowledge] withdraw not your hand: for he that fears God shall come forth of them all".

Being wise, handsome, and wealthy, Abbahu became not only popular with his coreligionists, but also influential with the proconsular government. On one occasion, when his senior colleagues, Ḥiyya b. Abba, Rabbi Ammi, and Rabbi Assi, had punished a certain woman, and feared the wrath of the proconsul, Abbahu was deputed to intercede for them. He had, however, anticipated the rabbis' request, and wrote them that he had appeased the informers but not the accuser. The witty enigmatic letter describing this incident, preserved in the Talmud, is in the main pure Hebrew, and even includes Hebrew translations of Greek proper names, to avoid the danger of possible exposure should the letter have fallen into the hands of enemies and informers.

After his ordination he declined a teacher's position, recommending in his stead a more needy friend, R. Abba of Acre (Acco), as worthier than himself. He thereby illustrated his own doctrine that it is a divine virtue to sympathize with a friend in his troubles as well as to partake of his joys. Later he assumed the office of rector in Caesarea, the former seat of Hoshaiah Rabbah, and established himself at the so-called Kenishta Maradta (Insurrectionary Synagogue); from which some of the most prominent teachers of the next generation issued. He did not, however, confine his activity to Caesarea, where he originated several ritualistic rules, one of which—that regulating the sounding of the shofar—has since been universally adopted, and is referred to by medieval Jewish casuists as ""Takkanat R. Abbahu"" (the Enactment of R. Abbahu). He also visited and taught in many other Jewish towns.

While on these journeys, Abbahu gathered so many "Halakot" that scholars turned to him for information on mooted questions. In the course of these travels he made a point of complying with all local enactments, even where such compliance laid him open to the charge of inconsistency. On the other hand, where circumstances required it, he did not spare even the princes of his people. Where, however, the rigorous exposition of laws worked hardship on the masses, he did not scruple to modify the decisions of his colleagues for the benefit of the community. As for himself, he was very strict in the observance of the laws. On one occasion he ordered some Samaritan wine, but subsequently learning that there were no longer any strict observers of the dietary laws among the Samaritans, with the assistance of his colleagues, Ḥiyya b. Abba, Rabbi Ammi, and Rabbi Assi, he investigated the report, and, ascertaining it to be well founded, did not hesitate to declare the Samaritans, for all ritualistic purposes, Gentiles.

R. Abbahu's chief characteristic seems to have been modesty. While lecturing in different towns, he met R. Ḥiyya b. Abba, who was lecturing on intricate "halakic" themes. As Abbahu delivered popular sermons, the masses naturally crowded to hear him, and deserted the halakist. At this apparent slight, R. Ḥiyya manifested chagrin, and R. Abbahu hastened to comfort him by comparing himself to the pedler of glittering fineries that always attracted the eyes of the masses, while his rival was a trader in precious stones, the virtues and values of which were appreciated only by the connoisseur. This speech not having the desired effect, R. Abbahu showed special respect for his slighted colleague by following him for the remainder of that day. "What," said Abbahu, "is my modesty as compared with that of R. Abba of Acre, who does not even remonstrate with his interpreter for interpolating his own comments in the lecturer's expositions." When his wife reported to him that his interpreter's wife had boasted of her own husband's greatness, R. Abbahu simply said, "What difference does it make which of us is really the greater, so long as through both of us heaven is glorified?" His principle of life he expressed in the maxim,

R. Abbahu, though eminent as a halakist, was more distinguished as an aggadist and controversialist. He had many interesting disputes with the Christians of his day. Sometimes these disputes were of a jocular nature. Thus, a heretic bearing the name of Sason (=Joy) once remarked to him, "In the next world your people will have to draw water for me; for thus it is written in the Bible, 'With joy shall ye draw water.'" To this R. Abbahu replied, "Had the Bible said 'for joy' ["le-sason"], it would mean as you say, but since it says 'with joy' ["be-sason"], it means that we shall make bottles of your skin and fill them with water". These controversies, though forced on him, provoked resentment, and it is even related that his physician, Jacob the Schismatic ("Minaah"), was slowly poisoning him, but R. Ammi and R. Assi discovered the crime in time.

Abbahu had two sons, Zeira and Hanina. Some writers ascribe to him a third son, Abimi. Abbahu sent Hanina to the academy at Tiberias, where he himself had studied, but the youth occupied himself with the burial of the dead, and on hearing of this, the father sent him a reproachful message in this laconic style: "Is it because there are no graves in Caesarea that I have sent you off to Tiberias? Study must precede practice". Abbahu left behind him a number of disciples, the most prominent among whom were the leaders of the 4th amoraic generation, R. Jonah and R. Jose. At Abbahu's death the mourning was so great that it was said, "Even the statues of Caesarea shed tears".

There are several other Abbahus mentioned in the Talmudim and Midrashim, prominent among whom is Abbahu (Abuha, Aibut) b. Ihi (Ittai), a Babylonian halakist, contemporary of Samuel and Anan, and brother of Minyamin (Benjamin) bar Ihi. While this Abbahu repeatedly applied to Samuel for information, Samuel in return learned many halakhot from him.

A Christian ("Minaah") once asked Abbahu "When does your Messiah come?" in a tone of mockery. Abbahu replied: "When you will be wrapped in darkness, for it says, 'Behold, darkness shall cover the earth, and gross darkness the nations; then shall the Lord rise upon you and His glory shall be seen on you'." A Christian came to Abbahu with the quibbling question: "How could your God in His priestly holiness bury Moses without providing for purificatory rites, yet oceans are declared insufficient?" Abbahu replied: "Does it not say, 'The Lord comes with fire'? Fire is the true element of purification, according to Numbers 31:23." Another question of the same character: "Why the boastful claim, 'What nation on earth is like Your people Israel', since we read, 'All the nations are as nothing before Him'?" Abbahu replied: "Do we not read of Israel, he 'shall not be reckoned among the nations'?"

Abbahu made a notable exception with reference to the Tosefta's statement that the "Gilyonim" (Evangels) and other books of the Mineans ("Minnin") are not to be saved from a fire on Shabbat: "the books of those [written by "Minnin" for the purpose of debating with Jews] at Abidan may or may not be saved." In regard to the line ""Barukh Shem Kevod Malkhuto"" (Blessed be the Name of His glorious Kingdom) recited after the Shema, Abbahu says that in Palestine, where the Christians look for points of controversy, the words should be recited aloud (lest the Jews be accused of silently tampering with the unity of God proclaimed in the "Shema"), whereas in the Babylonian city of Nehardea, where there are no Christians, the words are recited with a low voice. Preaching directly against the Christian dogma, Abbahu says: "A king of flesh and blood may have a father, a brother, or a son to share in or dispute his sovereignty, but the Lord says, 'I am the Lord your God! I am the first - that is, I have no father; and I am the last - that is, I have no brother; and besides me there is no God - that is, I have no son'". His comment on Numbers 23:19 has a still more polemical tone: "God is not a man that he should lie; neither the son of man, that he should repent; if a man says: 'I am God,' he is a liar; if he says: 'I am a son of man,' he will have cause to regret it; and if he says, 'I will go up to heaven,' he has said ["something"] but will not keep his word".

Some of his controversies on Christian theological subjects, as on Adam, on Enoch, and on the resurrection, are less clear and direct.

 It has the following bibliography:


</doc>
<doc id="2673" url="https://en.wikipedia.org/wiki?curid=2673" title="Abbreviator">
Abbreviator

An Abbreviator (plural "Abbreviators" in English and "Abbreviatores" in Latin) or Breviator was a writer of the Papal Chancery who adumbrated and prepared in correct form Papal bulls, briefs, and consistorial decrees before these were written out "in extenso" by the "scriptores".

They are first mentioned in the Papal bull "Extravagantes" of Pope John XXII and in a Papal bull of Pope Benedict XII.

After the protonotaries left the adumbration of the minutes to the Abbreviators, those "de Parco majori" of the dignity of prelate were the most important officers of the Papal Chancery. By the pontificate of Pope Martin V their signature was essential to the validity of the acts of the Chancery. Over time they obtained many important privileges.

Abbreviators make an abridgment or abstract of a long writing or discourse by contracting the parts, i. e., the words and sentences; an abbreviated form of writing common among the ancient Romans. Abbreviations were of two kinds: the use of a single letter for a single word and the use of a sign, note, or mark for a word or phrase.
The Emperor Justinian forbade the use of abbreviations in the compilation of the "Digest" and afterward extended his prohibition to all other writings. This prohibition was not universally obeyed. The Abbreviators found it convenient to use the abbreviated form, and this was especially the case in Rome. The early Christians practised the abbreviated mode, no doubt as an easy and safe way of communicating with one another and safeguarding their secrets from enemies and false brethren.

In course of time the Papal Chancery adopted this mode of writing as the "curial" style, still further abridging by omitting the diphthongs "ae" and "oe", and likewise all lines and marks of punctuation. The "Abbreviatores" were officials of the Roman Curia.

The scope of its labour, as well as the number of its officials, varied over time. Up to the twelfth or thirteenth century, the duty of the Apostolic – or Roman – Chancery was to prepare and expedite the Papal letters and writs for collation of ecclesiastical dignitaries and other matters of grave importance which were discussed and decided in Papal consistory. About the thirteenth or fourteenth century, the Popes, then residing in Avignon, France, began to reserve the collation of a great many benefices, so that all the benefices, especially the greater ones, were to be conferred through the Roman Curia (Lega, "Praelectiones Jur. Can.", 1, 2, 287). As a consequence, the labour was immensely augmented, and the number of "Abbreviatores" necessarily increased. To regulate the proper expedition of these reserved benefices, Pope John XXII instituted the rules of chancery to determine the competency and mode of procedure of the Chancery. Afterwards the establishment of the "Dataria Apostolica" and the Secretariate of Briefs lightened the work of the Chancery and led to a reduction in the number of "Abbreviatores".

According to Ciampini ("Lib. de abbreviatorum de parco majore etc.", Cap. 1) the institution of curial abbreviators was very ancient, succeeding after the persecutions to the notaries who recorded the acts of the martyrs. Other authors reject this early institution and ascribe it to Pope John XXII in 1316. It is certain that he uses the name ""abbreviatores"", but speaks as if they had existed before his time, and had, by over-taxation of their labour, caused much complaint and protest. He ("Extravag. Joan.", Tit. 13, "Cum ad Sacrosanctae Romanae Ecclesiae") prescribed their work, determined how much they could charge for their labour, fixed a certain tax for an abstract or abridgment of twenty-five words or their equivalent at 150 letters, forbade them to charge more, even though the abstract was over twenty-five words but less than fifty words, enacted that the basis of the tax was the labour employed in writing, expediting, etc. the bulls, and by no means the emoluments that accrued to the recipient of the favour or benefice conferred by the bull, and declared that whoever charged more than the tax fixed by him was suspended for six months from office, and upon a second violation of the law, was deprived of it altogether, and if the delinquent was an abbreviator, he was excommunicated. Should a large letter have to be rewritten, owing to the inexact copy of the abbreviator, the abbreviator and not the receiver of the bull had to pay the extra charge for the extra labour to the Apostolic writer.

Whatever may be the date of the institution of the office of abbreviator, it is certain that it became of greater importance and more highly privileged upon its erection into a college of prelates. Pope Martin V (Constit. 3 "In Apostolicae", 2 and 5) fixed the manner for their examination and approbation and also the tax they could demand for their labour and the punishment for overcharge. He also assigned to them certain remunerations. The Abbreviators of the lower, or lesser, were to be promoted to the higher, or greater, bar or presidency. Their offices were compatible with other offices, i. e. they could hold two benefices or offices simultaneously, some conferred by the Cardinal Vice Chancellor, others by the Pope.

In the pontificate of Pope Pius II, their number, which had been fixed at twenty-four, had overgrown to such an extent as to diminish considerably the individual remuneration, and, as a consequence, competent men no longer sought the office, and hence the old style of writing and expediting the bulls was no longer used, to the great injury of justice, the interested parties, and the dignity of the Apostolic See. To remedy this and to restore the old established chancery style, the Pope selected out of the many then living Abbreviators seventy, and formed them into a college of prelates denominated the "College of Abbreviators", and decreed that their office should be perpetual, that certain remunerations should be attached to it, and granted certain privileges to the possessors of the same. He ordained further that some should be called "Abbreviators of the Upper Bar" ("Abbreviatores de Parco Majori"; the name derived from a place in the Chancery that was surrounded by a grating, in which the officials sat, which is called higher or lower (major or minor) according to the proximity of the seats to that of the Vice Chancellor), the others of the Lower Bar ("Abbreviatores de Parco Minori"); that the former should sit upon a slightly raised portion of the chamber, separated from the rest of the chamber by lattice work, assist the Cardinal Vice-Chancellor, subscribe the letters and have the principal part in examining, revising, and expediting the Apostolic letters to be issued with the leaden seal; that the latter, however, should sit among the Apostolic writers upon benches in the lower part of the chamber, and their duty was to carry the signed schedules or supplications to the prelates of the Upper Bar. Then one of the prelates of the Upper Bar made an abstract, and another prelate of the same bar revised it. Prelates of the Upper Bar formed a quasi-tribunal, in which as a college they decided all doubts that might arise about the form and quality of the letters, of the clauses and decrees to be adjoined to the Apostolic letters, and sometimes about the payment of the remunerations and other contingencies. Their opinion about questions concerning Chancery business was held in the highest estimation by all the Roman tribunals.

Pope Paul II suppressed the College; but Pope Sixtus IV ("Constitutio" 16, "Divina") re-instituted it. He appointed seventy-two abbreviators, of whom twelve were of the upper, or greater, and twenty-two of the lower, or lesser, presidency ("parco"), and thirty-eight examiners on first appearance of letters. They were bound to be in attendance on certain days under penalty of fine, and sign letters and diplomas. Ciampini mentions a decree of the Vice Chancellor by which absentees were mulcted in the loss of their share of the remuneration of the following session of the Chancery. The same Pope also granted many privileges to the College of Abbreviators, but especially to the members of the greater presidency.

Pope Pius VII suppressed many of the offices of the Chancery, and so the Tribunal of Correctors and the Abbreviators of the lower presidency disappeared. Of the Tribunal of Correctors, a substitute-corrector alone remains. Bouix ("Curia Romana", edit. 1859) chronicled the suppression of the lower presidency and put the number of Abbreviators at that date at eleven. Later the College consisted of seventeen prelates, six substitutes, and one sub-substitute, all of whom, except the prelates, were clerics or laity. Although the duty of Abbreviators was originally to make abstracts and abridgments of the Apostolic letters, diplomas, et cetera, using the legal abbreviations, clauses, and formularies, in course of time, as their office grew in importance they delegated that part of their office to their substitute and confined themselves to overseeing the proper expedition of the Apostolic letters. Prior to 1878, all Apostolic letters and briefs requiring for their validity the leaden seal were engrossed upon rough parchment in Gothic characters or round letters, also called "Gallicum" and commonly "Bollatico", but in Italy "Teutonic", without lines, diphthongs, or marks of punctuation. Bulls engrossed on a different parchment, or in different characters with lines and punctuation marks, or without the accustomed abbreviations, clauses, and formularies, were rejected as spurious. Pope Leo XIII in his "Constitutio Universae Eccles." of 29 December 1878 ordained that they should be written henceforth in ordinary Latin characters upon ordinary parchment and that no abbreviations were to be used except those easily understood.

Many great privileges were conferred upon Abbreviators. By decree of Pope Leo X they were elevated as Papal nobles, ranking as "Comes palatinus" ("Count Palatine"), familiars and members of the Papal household, so that they might enjoy all the privileges of domestic prelates and of prelates in actual attendance on the Pope, as regards plurality of benefices as well as expectives. They and their clerics and their properties were exempt from all jurisdiction except the immediate jurisdiction of the Pope, and they were not subject to the judgments of the Auditor of Causes or the Cardinal Vicar. He also empowered them to confer, later within strict limitations, the degree of Doctor, with all university privileges, institute notaries (later abrogated), legitimize children so as to make them eligible to receive benefices vacated by their fathers (later revoked), also to ennoble three persons and to make Knights of the Order of St. Sylvester ("Militiae Aureae"), the same to enjoy and to wear the insignia of nobility. Pope Gregory XVI rescinded this privilege and reserved to the Pope the right of institution of such knights ("Acta Pont. Greg. XVI", Vol. 3, 178-179-180).

Pope Paul V, who in early manhood was a member of the College (Const. 2, "Romani"), made them Referendaries of Favours, and after three years of service, Referendaries of Justice, enjoying the privileges of Referendaries and permitting one to assist in the signatures before the Pope, giving all a right to a portion in the Papal palace and exempting them from the registration of favours as required by Pope Pius IV (Const., 98) with regard to matters pertaining to the Apostolic Chamber.

They followed immediately after the twelve voting members of the Signature "in capella". Abbreviators of the greater presidency were permitted to wear the purple cassock and "cappa", as also rochet "in capella". Abbreviators of the lower presidency before their suppression were simple clerics, and according to permission granted by Pope Sixtus IV (loc. cit.) might be even married.

These offices becoming vacant by death of the Abbreviator, no matter where the death occurred, were reserved to the Roman Curia. The prelates could resign their office in favour of others. Formerly these offices as well as those of the other Chancery officers from the Regent down were occasions of venality, until Popes, especially Pope Benedict XIV and Pope Pius VII, gradually abolished that. Pope Leo XIII in a motu proprio of 4 July 1898 most solemnly decreed the abolition of all venality in the transfer or collation of the said offices.

As domestic prelates, prelates of the Roman Curia, they had personal preeminence in every diocese of the world. They were addressed as "Reverendissimus", "Right Reverend", and "Monsignor". As prelates, and therefore possessing the legal dignity, they were competent to receive and execute Papal commands. Pope Benedict XIV (Const. 3, "Maximo") granted prelates of the greater presidency the privilege of wearing a hat with a purple band, which right they held even after they ceased to be abbreviators.

Pope Pius X abrogated the College in 1908 and their obligations were transferred to the "protonotarii apostolici participantes".


</doc>
<doc id="2674" url="https://en.wikipedia.org/wiki?curid=2674" title="Abd al-Latif al-Baghdadi">
Abd al-Latif al-Baghdadi

Abd al-Latif al-Baghdadi or Abdallatif al-Baghdadi (, 1162 in Baghdad–1231), short for Muwaffaq al-Din Muhammad Abd al-Latif ibn Yusuf al-Baghdadi (), was a physician, historian, Egyptologist and traveler, and one of the most voluminous writers of the Near East in his time.

Many details of Abd al-Latif's life are known from his autobiography. As a young man, he studied grammar, law, tradition, medicine, alchemy and philosophy. He focused his studies on ancient authors, in particular Aristotle, after first adopting Avicenna as his philosophical mentor at the suggestion of a wandering scholar from the Maghreb. He traveled extensively and resided for a while in Mosul (in 1189) where he studied the works of al-Suhrawardi before traveling on to Damascus (1190) and the camp of Saladin outside Acre (1191). It was at the latter location that he met Baha’ al-Din Ibn Shaddad and ‘Imad al-Din al-Isfahani and acquired the qadi al-Fadil's patronage. He went on to Cairo, where he met Abu'l-Qasim al-Shari'i, who introduced him to the works of al-Farabi, Alexander of Aphrodisias, and Themistius and (according to al-Latif) turned him away from Avicenna and alchemy.

He met Saladin himself in 1192 in Jerusalem, then went to Damascus again before returning to Cairo. In later years he again journeyed to Jerusalem and to Damascus in 1207-8, and eventually made his way via Aleppo to Erzindjan, where he remained at the court of Ala’-al-Din Da’ud until the city was conquered by the Seljuk ruler Kayqubadh. ‘Abd al-Latif returned to Baghdad in 1229, travelling back via Erzerum, Kamakh, Diwrigi and Malatiya. He died in Baghdad two years later.

Abdullatif was undoubtedly a man of great knowledge and of an inquisitive and penetrating mind. Of the numerous works (mostly on medicine) which Osaiba ascribes to him, one only, his graphic and detailed "Account of Egypt" (in two parts), appears to be known in Europe.

Abd-al-Latif was well aware of the value of ancient monuments and praised Muslim rulers for preserving and protecting pre-Islamic artifacts and monuments. He noted that the preservation of antiquities presented a number of benefits for Muslims:

While discussing the profession of treasure hunting, he notes that poorer treasure hunters were often sponsored by rich businessmen to go on archeological expeditions. In some cases, an expedition could turn out to be fraud, with the treasure hunter disappearing with large amounts of money extracted from sponsors. This fraudulent practice continues to the present day, with rich businessmen in Egypt still being deceived by local treasure hunters.

This work was one of the earliest works on Egyptology. It contains a vivid description of a famine caused, during the author's residence in Egypt, by the Nile failing to overflow its banks. He also wrote detailed descriptions on ancient Egyptian monuments.

Al-Baghdadi wrote that during the famine in Egypt in 597 AH (1200 AD), he had the opportunity to observe and examine a large number of skeletons. This was one of the earliest examples of a postmortem autopsy, through which he discovered that Galen was incorrect regarding the formation of the bones of the lower jaw and sacrum.

The Arabic manuscript was discovered in 1665 by Edward Pococke the orientalist, and preserved in the Bodleian Library. He then published the Arabic manuscript in the 1680s. His son, Edward Pococke the Younger, translated the work into Latin, though he was only able to publish less than half of his work. Thomas Hunt attempted to publish Pococke's complete translation in 1746, though his attempt was unsuccessful. Pococke's complete Latin translation was eventually published by Joseph White of Oxford in 1800. The work was then translated into French, with valuable notes, by Silvestre de Sacy in 1810.

Al-Baghdadi's "Mukhtarat fi al-Tibb" was one of the earliest works on hirudotherapy. He introduced a more modern use for medicinal leech, stating that leech could be used for cleaning the tissues after surgical operations. He did, however, understand that there is a risk over using leech, and advised patients that leech need to be cleaned before being used and that the dirt or dust "clinging to a leech should be wiped off" before application. He further writes that after the leech has sucked out the blood, salt should be "sprinkled on the affected part of the human body".

He wrote a book called "Al-Tibb min al-Kitab wa-al-Sunna" ("Medicine from the Book and the Life of the Prophet") describing the Islamic medical practices from the time of Muhammad.

Al-Baghdadi was also the author of a major book dealing with diabetes.



</doc>
<doc id="2676" url="https://en.wikipedia.org/wiki?curid=2676" title="Abd al-Rahman I">
Abd al-Rahman I

Abd al-Rahman I, more fully Abd al-Rahman ibn Mu'awiya ibn Hisham ibn Abd al-Malik ibn Marwan (731–788)() , was the founder of a Muslim dynasty that ruled the greater part of Iberia for nearly three centuries (including the succeeding Caliphate of Córdoba). Abd al-Rahman was a member of the Umayyad dynasty in Damascus, and his establishment of a government in Iberia represented a break with the Abbasids, who had overthrown the Umayyads in 750.

He was also known by the surnames "al-Dakhil" ("the Entrant"), "Saqr Quraish" ("the Falcon of the Quraysh") and the "Falcon of Andalus". Variations of the spelling of his name include Abd ar-Rahman I, Abdul Rahman I, Abdar Rahman I, and Abderraman I.

Born near Damascus in Syria, Abd al-Rahman was the son of the Umayyad prince Mu'awiya ibn Hisham and his concubine Ra'ha, a black Berber woman from Nefzaoua, and thus the grandson of Hisham ibn Abd al-Malik, caliph from 724 to 743. He was twenty when his family, the ruling Umayyads, were overthrown by the Abbasid Revolution in 748–750. Abd al-Rahman and a small part of his family fled Damascus, where the center of Umayyad power had been; people moving with him include his brother Yahya, his four-year-old son Sulayman, and some of his sisters, as well as his Greek freedman, Bedr. The family fled from Damascus to the River Euphrates. All along the way the path was filled with danger, as the Abbasids had dispatched horsemen across the region to try to find the Umayyad prince and kill him. The Abbasids were merciless with all Umayyads that they found. Abbasid agents closed in on Abd al-Rahman and his family while they were hiding in a small village. He left his young son with his sisters and fled with Yahya. Accounts vary, but Bedr likely escaped with Abd ar-Rahman. Some histories indicate that Bedr met up with Abd al-Rahman at a later date.

Abd al-Rahman, Yahya, and Bedr quit the village, narrowly escaping the Abbasid assassins. On the way south, Abbasid horsemen again caught up with the trio. Abd al-Rahman and his companions then threw themselves into the River Euphrates. The horsemen urged them to return, promising that no harm would come to them; and Yahya, perhaps from fear of drowning, turned back. The 17th-century historian Ahmed Mohammed al-Maqqari poignantly described Abd al-Rahman's reaction as he implored Yahya to keep going: "O brother! Come to me, come to me!" Yahya returned to the near shore, and was quickly dispatched by the horsemen. They cut off his head and left his body to rot. Al-Maqqari quotes earlier historians reporting that Abd al-Rahman was so overcome with fear that from the far shore he ran until exhaustion overcame him. Only he and Bedr were left to face the unknown.

After barely escaping with their lives, Abd al-Rahman and Bedr continued south through Palestine, the Sinai, and then into Egypt. Abd al-Rahman had to keep a low profile as he traveled. It may be assumed that he intended to go at least as far as northwestern Africa (Maghreb), the land of his mother, which had been partly conquered by his Umayyad predecessors. The journey across Egypt would prove perilous. At the time, Abd al-Rahman ibn Habib al-Fihri was the semi-autonomous governor of Ifriqiya (roughly, modern Tunisia) and a former Umayyad vassal. The ambitious Ibn Habib, a member of the illustrious Fihrid family, had long sought to carve out Ifriqiya as a private dominion for himself. At first, he sought an understanding with the Abbasids, but when they refused his terms and demanded his submission, Ibn Habib broke openly with the Abbasids and invited the remnants of the Umayyad dynasty to take refuge in his dominions. Abd al-Rahman was only one of several surviving Umayyad family members to make their way to Ifriqiya at this time.

But Ibn Habib soon changed his mind. He feared the presence of prominent Umayyad exiles in Ifriqiya, a family more illustrious than his own, might become a focal point for intrigue among local nobles against his own usurped powers. Around 755, believing he had discovered plots involving some of the more prominent Umayyad exiles in Kairouan, Ibn Habib turned against them. At the time, Abd al-Rahman and Bedr were keeping a low profile, staying in Kabylie, at the camp of a black Nafza Berber chieftain friendly to their plight. Ibn Habib dispatched spies to look for the Umayyad prince. When Ibn Habib's soldiers entered the camp, the Berber chieftain's wife Tekfah hid Abd al-Rahman under her personal belongings to help him go unnoticed. Once they were gone, Abd a-Rahman and Bedr immediately set off westwards.

In 755, Abd al-Rahman and Bedr reached modern-day Morocco near Ceuta. Their next step would be to cross the sea to al-Andalus, where Abd al-Rahman could not have been sure whether or not he would be welcomed. Following the Berber Revolt of the 740s, the province was in a state of confusion, with the Muslim community torn by tribal dissensions among the Arabs (the Qays–Yemeni feud) and racial tensions between the Arabs and Berbers. At that moment, the nominal ruler of al-Andalus, emir Yusuf ibn 'Abd al-Rahman al-Fihri—another member of the Fihrid family and a favorite of the old Arab settlers ("baladiyun"), mostly of south Arabian or "Yemeni" tribal stock—was locked in a contest with his vizier (and son-in-law) al-Sumayl ibn Hatim al-Kilabi, the head of the "Syrians"—the "shamiyum", drawn from the "junds" or military regiments of Syria, mostly of north Arabian Qaysid tribes—who had arrived in 742.

Among the Syrian "junds" were contingents of old Umayyad clients, numbering perhaps 500, and Abd al-Rahman believed he might tug on old loyalties and get them to receive him. Bedr was dispatched across the straits to make contact. Bedr managed to line up three Syrian commanders—Ubayd Allah ibn Uthman and Abd Allah ibn Khalid, both originally of Damascus, and Yusuf ibn Bukht of Qinnasrin. The trio approached the Syrian arch-commander al-Sumayl (then in Zaragoza) to get his consent, but al-Sumayl refused, fearing Abd al-Rahman would try to make himself emir. As a result, Bedr and the Umayyad clients sent out feelers to their rivals, the Yemenite commanders. Although the Yemenites were not natural allies (the Umayyads are a Qaysid tribe), their interest was piqued. The emir Yusuf al-Fihri had proven himself unable to keep the powerful al-Sumayl in check and several Yemenite chieftains felt their future prospects were poor, whether in a Fihrid or Syrian-dominated Spain, so that they had a better chance of advancement if they hitched themselves to the glitter of the Umayyad name. Although the Umayyads did not have a historical presence in the region (no member of the Umayyad family was known to have ever set foot in al-Andalus before) and there were grave concerns about young Abd al-Rahman's inexperience, several of the lower-ranking Yemenite commanders felt they had little to lose and much to gain, and agreed to support the prince.

Bedr returned to Africa to tell Abd al-Rahman of the invitation of the Umayyad clients in al-Andalus. Shortly thereafter, they set off with a small group of followers for Europe. When some local Berber tribesmen learned of Abd al-Rahman's intent to set sail for al-Andalus, they quickly rode to catch up with him on the coast. The tribesmen might have figured that they could hold Abd al-Rahman as hostage, and force him to buy his way out of Africa. He did indeed hand over some amount of dinars to the suddenly hostile local Berbers. Just as Abd al-Rahman launched his boat, another group of Berbers arrived. They also tried to obtain a fee from him for leaving. One of the Berbers held on to Abd al-Rahman's vessel as it made for al-Andalus, and allegedly had his hand cut off by one of the boat's crew.

Abd al-Rahman landed at Almuñécar in al-Andalus, to the east of Málaga, in September 755; however his landing site was unconfirmed.

Upon landing in al-Andalus, Abd al-Rahman was greeted by clients Abu Uthman and Ibn Khalid and an escort of 300 cavalry. During his brief time in Málaga, he was able to amass local support quickly. Waves of people made their way to Málaga to pay respect to the prince they thought was dead, including many of the aforementioned Syrians. One famous story that persisted through history related to a gift Abd al-Rahman was given while in Málaga. The gift was a beautiful young slave girl, but Abd al-Rahman humbly returned her to her previous master.

News of the prince's arrival spread like wildfire throughout the peninsula. During this time, emir al-Fihri and the Syrian commander al-Sumayl pondered what to do about the new threat to their shaky hold on power. They decided to try to marry Abd al-Rahman into their family. If that did not work, then Abd al-Rahman would have to be killed. Abd al-Rahman was apparently sagacious enough to expect such a plot. In order to help speed his ascension to power, he was prepared to take advantage of the feuds and dissensions. However, before anything could be done, trouble broke out in northern al-Andalus. Zaragoza, an important trade city on the Upper March of al-Andalus, made a bid for autonomy. Al-Fihri and al-Sumayl rode north to quash the rebellion. This might have been fortunate timing for Abd al-Rahman, since he was still getting a solid foothold in al-Andalus. By March 756, Abd al-Rahman and his growing following of Umayyad clients and Yemenite "junds", were able to take Sevilla without violence. He managed to break the rebellion attempt in Zaragoza, but just about that time the Cordovan governor received news of a Basque rebellion in Pamplona. An important detachment was sent by Yusuf ibn 'Abd al-Rahman to quash it, but his troops were annihilated. After the setback, al-Fihri turned his army back south to face the "pretender". The fight for the right to rule al-Andalus was about to begin. The two contingents met on opposite sides of the River Guadalquivir, just outside the capital of Córdoba on the plains of Musarah.

The river was, for the first time in years, overflowing its banks, heralding the end of a long drought. Nevertheless, food was still scarce, and Abd al-Rahman's army suffered from hunger. In an attempt to demoralize Abd al-Rahman's troops, al-Fihri ensured that his troops not only were well fed, but also ate gluttonous amounts of food in full view of the Umayyad lines. An attempt at negotiations soon followed in which it is likely that Abd al-Rahman was offered the hand of al-Fihri's daughter in marriage and great wealth. Abd ar-Rahman, however, would settle for nothing less than control of the emirate, and an impasse was reached. Even before the fight began, dissension spread through some of Abd al-Rahman's lines. Specifically, the Yemeni Arabs were unhappy that the prince was mounted on a fine Spanish steed. And the prince's mettle was untried in battle, after all! The Yemenis observed significantly that such a fine horse would provide an excellent mount to escape from battle.

Being the ever-wary politician, Abd al-Rahman acted quickly to regain Yemeni support, and rode to a Yemeni chief who was mounted on a mule named "Lightning". Abd al-Rahman averred that his horse proved difficult to ride and was wont to buck him out of the saddle. He offered to exchange his horse for the mule, a deal to which the surprised chief readily agreed. The swap quelled the simmering Yemeni rebellion. Soon both armies were in their lines on the same bank of the Guadalquivir. Abd al-Rahman had no banner, and so one was improvised by unwinding a green turban and binding it round the head of a spear. Subsequently, the turban and the spear became the banner and symbol of the Andalusian Umayyads. Abd al-Rahman led the charge toward al-Fihri's army. Al-Sumayl in turn advanced his cavalry out to meet the Umayyad threat. After a long and difficult fight "Abd ar-Rahman obtained a most complete victory, and the field was strewn with the bodies of the enemy.". Both al-Fihri and al-Sumayl managed to escape the field (probably) with parts of the army too. Abd al-Rahman triumphantly marched into the capital, Córdoba. Danger was not far behind, as al-Fihri planned a counterattack. He reorganized his forces and set out for the capital Abd al-Rahman had usurped from him. Again Abd al-Rahman met al-Fihri with his army; this time negotiations were successful, although the terms were somewhat changed. In exchange for al-Fihri's life and wealth, he would be a prisoner and not allowed to leave the city limits of Córdoba. Al-Fihri would have to report once a day to Abd al-Rahman, as well as turn over some of his sons and daughters as hostages. For a while al-Fihri met the obligations of the one-sided truce, but he still had many people loyal to him; people who would have liked to see him back in power.

Al-Fihri eventually did make another bid for power. He quit Córdoba and quickly started gathering supporters. While at large, al-Fihri managed to gather an army allegedly numbering to 20,000. It is doubtful, however, that his troops were "regular" soldiers, but rather a hodge-podge of men from various parts of al-Andalus. Abd ar-Rahman's appointed governor in Sevilla took up the chase, and after a series of small fights, managed to defeat al-Fihri's army. Al-Fihri himself managed to escape to the former Visigoth capital of Toledo in central al-Andalus; once there, he was promptly killed. Al-Fihri's head was sent to Córdoba, where Abd al-Rahman had it nailed to a bridge. With this act, Abd ar-Rahman proclaimed himself the emir of al-Andalus. However, one final act to take over southern Iberia had to be performed: al-Fihri's general, al-Sumayl, had to be dealt with, and he was garroted in Córdoba's jail. Now most of central and northern al-Andalus (Toledo, Zaragoza, Barcelona, etc.) was out of his rule, with large swathes remaining in the hands of Yusuf ibn 'Abd al-Rahman al-Fihri's supporters until 779 (submission of Zaragoza).

It is unclear whether Abd al-Rahman proclaimed himself caliph. There are documents in the archives of Cordoba that state that this was his first act upon entering the city. He himself believed he was destined to be Caliph because of prophesies he had heard as a boy, so it seems likely he would. However, historically he is recorded as Emir and not Caliph. Abd al-Rahman's 7th descendent, Abd al-Rahman III, would, however, take up the title of caliph. In the meantime, a call went out through the Muslim world that al-Andalus was a safe haven for friends of the house of Umayya, if not for Abd al-Rahman's scattered family that managed to evade the Abbasids. Abd al-Rahman probably was quite happy to see his call answered by waves of Umayyad faithful and family. He was finally reacquainted with his son Sulayman, whom he last saw weeping on the banks of the Euphrates with his sisters. Abd ar-Rahman's sisters were unable to make the long voyage to al-Andalus. Abd al-Rahman placed his family members in high offices across the land, as he felt he could trust them more than non-family. The Umayyad family would again grow large and prosperous over successive generations. However, by 763 Abd ar-Rahman had to get back to the business of war. Al-Andalus had been invaded by an Abbasid army.

Far away in Baghdad, the current Abbasid caliph, al-Mansur, had long been planning to depose the Umayyad who dared to call himself emir of al-Andalus. Al-Mansur installed al-Ala ibn-Mugith (also known as al-Ala) as governor of Africa (whose title gave him dominion over the province of al-Andalus). It was al-Ala who headed the Abbasid army that landed in al-Andalus, possibly near Beja (in modern-day Portugal). Much of the surrounding area of Beja capitulated to al-Ala, and in fact rallied under the Abbasid banners against Abd al-Rahman. Abd al-Rahman had to act quickly. The Abbasid contingent was vastly superior in size, said to have numbered 7,000 men. The emir quickly made for the redoubt of Carmona with his army. The Abbasid army was fast on their heels, and laid siege to Carmona for approximately two months. Abd al-Rahman must have sensed that time was against him as food and water became scarce, and his troops morale likely came into question. Finally Abd al-Rahman gathered his men as he was "resolved on an audacious sally". Abd al-Rahman hand-picked 700 fighters from his army and led them to Carmona's main gate. There, he started a great fire and threw his scabbard into the flames. Abd al-Rahman told his men that time had come to go down fighting rather than die of hunger.
The gate lifted and Abd ar-Rahman's men fell upon the unsuspecting Abbasids, thoroughly routing them. Most of the Abbasid army was killed. The heads of the main Abbasid leaders were cut off. Their heads were preserved in salt, and identifying tags pinned to their ears. The heads were bundled together in a gruesome package and sent to the Abbasid caliph who was on pilgrimage at Mecca. Upon receiving the evidence of al-Ala's defeat in al-Andalus, al-Mansur is said to have gasped, "God be praised for placing a sea between us!" Al-Mansur hated, and yet apparently respected Abd al-Rahman to such a degree that he dubbed him the "Hawk of Quraysh" (The Umayyads were from a branch of the Quraysh tribe.)

Despite such a tremendous victory, Abd al-Rahman had to continuously put down rebellions in al-Andalus. Various Arab and Berber tribes fought each other for varying degrees of power, some cities tried to break away and form their own state, and even members of Abd al-Rahman's family tried to wrest power from him. During a large revolt, dissidents marched on Córdoba itself; However, Abd al-Rahman always managed to stay one step ahead, and crushed all opposition; as he always dealt severely with dissidence in al-Andalus. However, this assumption needs to be in perspective, since in 756 he was in charge of a limited number of southern strongholds and he faced resistance to submit from other towns during the next 25 years, rather than revolts.

Despite all this turmoil in al-Andalus, Abd al-Rahman wanted to take the fight back east to Baghdad. Revenge for the massacre of his family at the hands of the Abbasids must surely have been the driving factor in Abd al-Rahman's war plans. However his war against Baghdad was put on hold by more internal problems. The city of Zaragoza on the Upper March remained out of reach of the Umayyad leader since the times of Yusuf ibn 'Abd al-Rahman al-Fihri, bidding for autonomy. Little could Abd al-Rahman have known that as he set off to settle matters in that northern city, his hopes of warring against Baghdad would be indefinitely put on hold.

Zaragoza proved to be a most difficult city to reign over for not only Abd ar-Rahman, but his successors as well. In the year 777–778, several notable men including Sulayman ibn Yokdan al-Arabi al-Kelbi, the self-appointed governor of Zaragoza, met with delegates of the leader of the Franks, Charlemagne. "(Charlemagne's) army was enlisted to help the Muslim governors of Barcelona and Zaragoza against the Umayyad (emir) in Cordoba..." Essentially Charlemagne was being hired as a mercenary, even though he likely had other plans of acquiring the area for his own empire. After Charlemagne's columns arrived at the gates of Zaragoza, Sulayman got cold feet and refused to let the Franks into the city, after his subordinate, al-Husayn ibn Yahiya, had successfully defeated and captured Abd al-Rahman's most trusted general, Thalaba Ibn Ubayd. It is possible that he realized that Charlemagne would want to usurp power from him. After capturing Sulayman, Charlemagne's force eventually headed back to France via a narrow pass in the Pyrenees, where his rearguard was wiped out by Basque and Gascon rebels (this disaster inspired the epic Chanson de Roland)., Charlemagne also suffered attack from Sulayman's relatives, who had freed Sulayman.

Now Abd al-Rahman could deal with Sulayman and the city of Zaragoza without having to fight a massive Christian army. In 779 Abd al-Rahman offered Husayn, one of Sulayman's allies, the job of Zaragoza's governorship. The temptation was too much for al-Husayn, who murdered his colleague Sulayman. As promised, al-Husayn was awarded Zaragoza with the expectation that he would always be a subordinate of Córdoba. However, within two years al-Husayn broke off relations with Abd al-Rahman and announced that Zaragoza would be an independent city-state. Once again Abd al-Rahman had to be concerned with developments in the Upper March. He was intent on keeping this important northern border city within the Umayyad fold. By 783 Abd al-Rahman's army advanced on Zaragoza. It appeared as though Abd al-Rahman wanted to make clear to this troublesome city that independence was out of the question. Included in the arsenal of Abd al-Rahman's army were thirty-six siege engines. Zaragoza's famous white granite defensive walls were breached under a torrent of ordnance from the Umayyad lines. Abd al-Rahman's warriors spilled into the city's streets, quickly thwarting al-Husayn's desires for independence.

After the aforementioned period of conflict, Abd al-Rahman continued in his improvement of al-Andalus' infrastructure. He ensured roadways were begun, aqueducts were constructed or improved, and that a new mosque was well funded in his capital at Córdoba. Construction on what would in time become the world-famous Great Mosque of Córdoba was started circa the year 786. Abd al-Rahman knew that one of his sons would one day inherit the rule of al-Andalus, but that it was a land torn by strife. In order to successfully rule in such a situation, Abd al-Rahman needed to create a reliable civil service and organize a standing army. He felt that he could not always rely on the local populace in providing a loyal army; and therefore bought a massive standing army consisting mainly of Berbers from North Africa as well as slaves from other areas. The total number of army-men under his command were nearly 40,000. As was common during the years of Islamic expansion from Arabia, religious tolerance was practiced. Abd al-Rahman continued to allow Jews and Christians and other monotheistic religions to retain and practice their faiths. They did,and have to pay a tribute tax for this privilege. Abd al-Rahman's policy of taxing non-Muslims, which was often carried out by later rulers, changed the religious dynamic of al-Andalus. Possibly because of excessive tribute taxes "the bulk of the country's population must have become Muslim". However, other scholars have argued that though 80% of al-Andalus converted to Islam, it did not truly occur until near the 10th century.

Christians more often converted to Islam than Jews although there were converted Jews among the new followers of Islam. There was a great deal of freedom of interaction between the groups: for example, Sarah, the granddaughter of the Visigoth king Wittiza, married a Muslim man and bore two sons who were later counted among the ranks of the highest Arab nobility.

Abd al-Rahman I was able to forge a new Umayyad dynasty by standing successfully against Charlemagne, the Abassids, the Berbers, and other Muslim Spaniards. There is some dispute as to whether what he created was an extension of the Umayyad Dynasty or a new Caliphate of Cordoba.

The date of Abd al-Rahman's death is approximately in 788. Abd al-Rahman died in his adopted city of Córdoba, and was supposedly buried under the site of the Mezquita. Abd al-Rahman's alleged favorite son was his choice for successor, and would later be known as Hisham I. Abd ar-Rahman's progeny would continue to rule al-Andalus in the name of the house of Umayyad for several generations, with the zenith of their power coming during the reign of Abd al-Rahman III.

Abd al-Rahman was the son of Mu'awiya, son of Hisham, son of Abd al-Malik according to Abd el-Wahid Merrakechi when reciting his ancestry. Abd al-Rahman's mother was a member from the Nafza Berbers with whom he found refuge after the murder of his family in 750.

Abd al-Rahman married a woman named Hulal. She is said to be the mother of Hisham. Abd al-Rahman was the father of several sons, but the identity of their mother(s) is not clear:

In his lifetime, Abd al-Rahman was known as "al Dakhil" ("the Entrant"). But he was also known as "Saqr Quraish" ("The Falcon of the Quraish"), bestowed on him by one of his greatest enemies, the Abbasid caliph al-Mansur.

According to the chroniclers, the Abbasid caliph al-Mansur once asked his courtiers who deserved the exalted title of "Falcon of the Quraysh" ("Saqr Quraish", foremost of the Prophet's tribe). The obsequious courtiers naturally replied "You, O Commander of the Faithful!", but the Caliph said no. Then they suggested Mu'awiya (founder of the Umayyad Caliphate), but the Caliph again said no. Then they suggested Abd al-Malik ibn Marwan (one of the greatest of the Umayyad caliphs), but again no. Then who, they asked, and the Caliph al-Mansur replied:




</doc>
<doc id="2677" url="https://en.wikipedia.org/wiki?curid=2677" title="Abd al-Rahman II">
Abd al-Rahman II

Abd ar-Rahman II () (792–852) was the fourth Umayyad Emir of Córdoba in the Al-Andalus Iberia from 822 until his death.

Abd ar-Rahman II was born in Toledo, the son of Emir Al-Hakam I. In his youth he took part in the so-called "massacre of the ditch", when from 700 to 5,000 people come to pay homage to the princes who were killed by order of Al-Hakam.

He succeeded his father as Emir of Córdoba in 822 and engaged in nearly continuous warfare against Alfonso II of Asturias, whose southward advance he halted (822–842). 
In 837, he suppressed a revolt of Christians and Jews in Toledo. 
He issued a decree by which the Christians were forbidden to seek martyrdom, and he had a Christian synod held to forbid martyrdom.

In 844, Abd ar-Rahman repulsed an assault by Vikings who had disembarked in Cádiz, conquered Seville (with the exception of its citadel) and attacked Córdoba itself. 
Thereafter he constructed a fleet and naval arsenal at Seville to repel future raids.

He responded to William of Septimania's requests of assistance in his struggle against Charles the Bald's nominations.

Abd ar-Rahman was famous for his public building program in Córdoba where he died in 852. He made additions to the Mosque–Cathedral of Córdoba. A vigorous and effective frontier warrior, he was also well known as a patron of the arts. 
He was also involved in the execution of the "Martyrs of Córdoba".


</doc>
<doc id="2678" url="https://en.wikipedia.org/wiki?curid=2678" title="Abd al-Rahman III">
Abd al-Rahman III

Abd al-Rahman III ("′Abd al-Rahmān ibn Muhammad ibn ′Abd Allāh ibn Muhammad ibn ′abd al-Rahman ibn al-Hakam al-Rabdi ibn Hisham ibn ′abd al-Rahman al-Dakhil"; (); 11 January 889/9115 October 961) was an Arab Emir and Caliph of Córdoba (912–961) of the Umayyad dynasty in al-Andalus. Called "al-Nasir li-Din Allah" ("the Defender of God's Faith"), he ascended the throne in his early 20s and reigned for half a century as the most powerful prince of Iberia. Although people of all creeds enjoyed tolerance and freedom of religion under his rule, he repelled the Fatimids, partly by supporting their Maghrawa enemies in North Africa, and partly by claiming the title Caliph (ruler of the Islamic world) for himself.

Abd al-Rahman was born in Córdoba, the grandson of Abdullah ibn Muhammad al-Umawi, seventh independent Umayyad emir of al-Andalus. His parents were Abdullah's son Muhammad and Muzna (or Muzayna), a Christian concubine. His paternal grandmother was also a Christian, the royal infanta Onneca Fortúnez, daughter of the captive king Fortún Garcés of Pamplona. Abd al-Rahman was thus nephew in the half-blood of queen Toda of Pamplona. He is described as having "white skin, blue eyes and attractive face; good looking, although somewhat sturdy and stout. His legs were short, to the point that the stirrups of his saddle were mounted just one palm under it. When mounted, he looked tall, but on his feet he was quite short. He dyed his beard black.

Muhammad was assassinated by his brother Al-Mutarrif, who had allegedly grown jealous of the favour Muhammad had gained in the eyes of their father Abdallah. Al-Mutarrif had accused Muhammad of plotting with the rebel Umar ibn Hafsun, and Muhammad had been imprisoned. According to some sources, the emir himself was behind Muhammad's fall, as well as Al-Mutarrif's death in 895. Abd al-Rahman spent his youth in his mother's harem. Al-Mutarrif's sister, known as "al-Sayyida" ("the Lady"), was entrusted with his education. She made sure that Abd al-Rahman's education was conducted with some rigor.

Emir Abdallah died at the age of 72. Despite the fact that four of his sons (Aban, Abd al Rahman, Muhammad and Ahmad) were alive at the time of his death, all of them were passed over for succession. Abdallah instead chose as his successor his grandson, Abd al-Rahman III (the son of his first son). This came as no surprise, since Abdallah had already demonstrated his affection for his grandson in many ways, namely by allowing him to live in his own tower (something he did not allow for any of his sons), and allowing him to sit on the throne on some festive occasions. Most importantly Abdallah gave Abd al-Rahman his ring, the symbol of power, when Abdallah fell ill prior to his death. Abd al-Rahman succeeded Abdallah the day after his death, 16 October 912. Historiographers of the time, such as "Al-Bayan al-Mughrib" and the "Crónica anónima de Abd al-Rahman III", state that his succession was "without incident". At the time, Abd al-Rahman was about 21 or 22 years old. He inherited an emirate on the verge of dissolution, his power extending not far beyond the vicinity of Córdoba. To the north, the Christian Kingdom of Asturias was continuing its program of "Reconquista" in the Douro valley. To the south in Ifriqiya, the Fatimids had created an independent caliphate that threatened to attract the allegiance of the Muslim population, who had suffered under the harsh rule of Abdullah. On the internal front the discontented Muladi families (Muslims of Iberian origin) represented a constant danger for the Córdoban emir. The most powerful of the latter was Umar ibn Hafsun, who, from his impregnable fortress of Umar ibn Hafsun, controlled much of eastern Al-Andalus.

From the very early stages of his reign, Abd al-Rahman showed a firm resolve to quash the rebels of al-Andalus, consolidate centralized power, and reestablish internal order within the emirate. Within 10 days of taking the throne, he exhibited the head of a rebel leader in Cordoba. From this point on he led annual expeditions against the northern and southern tribes to maintain control over them. To accomplish his aims he introduced into the court the "saqalibah", slaves of East European origin. The "saqalibah" represented a third ethnic group that could neutralize the endless strife between his subjects of Muslim Arab heritage, and those of Muslim Berber heritage.

Hasdai ibn Shaprut, a Jewish courtier of the king's court who served as financier to the king, wrote of the king's revenues on this wise:

During the first 20 years of his rule, Abd al-Rahman avoided military action against the northern Christian kingdoms, Asturias and the Kingdom of Navarre. The Muladi rebels were the first problem he confronted. Those powerful families were supported by Iberians who were openly or secretly Christians and had acted with the rebels. These elements, which formed the bulk of the population, were not averse to supporting a strong ruler who would protect them against the Arab aristocracy. Abd al-Rahman moved to subdue them by means of a mercenary army that included Christians.
He first had to suppress the rebel Umar ibn Hafsun. On 1 January 913 an army, led by the eunuch Badr, conquered the fortress of Écija, at some from the capital. All the city's fortifications were destroyed, aside from the citadel, which was left as residence of the governor and a garrison for the emiral troops. In the following spring, after sixty-five days of meticulous preparations, Abd al-Rahman personally led an expedition to the south of his realm. His troops were able to recover the "coras" (provinces) of Jaén and Granada, while a cavalry detachment was sent to free Málaga from ibn Hafsun's siege. He also obtained the capitulation of Fiñana (in the modern province of Almería), after setting fire to its suburbs. Subsequently, he moved against the castle of Juviles in the Alpujarras. After devastating its countryside to deprive it of any resource, he encircled it. Finding it difficult to bombard with catapults, he ordered the construction of a platform where his siege engines could be mounted to greater effect, and cut the water supply. The Muladi defenders surrendered after a few days: their lives, apart from fifty-five die-hards who were beheaded, were spared in exchange of their allegiance to the emir. The campaign continued in a similar vein, lasting for a total of ninety days. Abd al-Rahman forced the defeated Muladi to send hostages and treasures to Córdoba, in order to secure their continued submission.

In the first year of his reign, Abd al-Rahman took advantage of the rivalries between the Banu Hayyay lords of Seville and Carmona to force them to submit. He initially sent a special corps ("hasam") under Ahmad ibn Muhammad ibn Hudayr, governor of Écija, to Seville, to obtain their submission. This attempt failed, but gained him the support of Muhammad ibn Ibrahim ibn Hayyay, lord of Carmona, and a cousin of the Sevillan lord, Ahmad ibn Maslama. When the latter was surrounded by Umayyad troops, he sued for help to Ibn Hafsun, but the latter was defeated by the besiegers and returned to Bobastro. He next went after the forts in the provinces of Elvira, Granada, and Jaen, all of which were either directly or indirectly controlled by Hafsun. Seville finally capitulated on 20 December 913. Ibn al-Mundir al-Qurays, a member of the royal family, was named governor of the city, while the Lord of Carmona obtained the title of vizier. Muhammad ibn Ibrahim enjoyed his office for only a single day, for Abd al-Rahman soon discovered his collusion with the rebel governor of Carmona. Muhammad was sent to prison, where he later met his death.

The region of Valencia submitted peacefully in 915.

Abd al-Rahman's next objective was to quash the longstanding rebellion of Umar ibn Hafsun.

His troops left Córdoba on 7 May 914 and, after a few days, encamped before the walls of Balda (identified with today's Cuevas de San Marcos). His cavalry ravaged the nearby woods and the countryside, while the rest of the troopes moved to Turrus, a castle located in the present municipality of Algarinejo, which was surrounded within five days, while its environs were also devastated.

The Umayyad army then moved to the citadel of Umar ibn Hafsun, while the cavalry was sent to the castle of Sant Batir, which was abandoned by the defenders, allowing Abd al-Rahman's troops to secure a large booty. Then it was the turn of the castles of Olías and Reina. The latter fell after a violent fight, leaving the road open to the major city and provincial capital of Málaga, which he captured after one day. Abd al-Rahman then turned and followed the coast by Montemayor, near Benahavís, Suhayl (Fuengirola) and another castle called "Turrus "or "Turrus Jusayn" (identified by Évariste Lévi-Provençal as Ojén). He finally arrived at Algeciras on 1 June 914. He ordered a patrol of the coast to destroy the boats that supplied the citadel of Umar ibn Hafsun from the Maghreb. Many of them were captured and set afire in front of the emir. The rebellious castles near Algeciras surrendered as soon as the Cordoban army manifested itself.

Abd al-Rahman launched three different campaigns against Ibn Hafsun (who died in 917) and his sons. Among them, Jafar ibn Hafsun held the stronghold of Toledo. Abd al-Rahman ordered ravaged the city's countryside. Jafar, after two years of siege, escaped the city to ask for help in the northern Christian kingdoms. In the meantime Abd al-Rahman obtained the surrender of the city from its population, after promising them immunity, although 4,000 rebel men escaped in a night sally. The city surrendered on 2 August 932, after a siege of two years.

In 921 the Banu Muhallab of Guadix submitted, followed by those of Jerez de la Frontera and Cádiz, as well as the trading republic of Pechina (922). In 927, Abd al-Rahman also launched a campaign against the rebel Banu Qasi, but was forced to break it off by the intervention of Jimeno Garcés of Pamplona.

The last of Ibn Hafsun to fall was Hafs, who commanded his powerful fortress of Umar ibn Hafsun. Surrounded by Abd al-Rahman's vizier Said ibn al-Mundhir who had ordered the construction of bastions around the city, he resisted the siege for six months, until he surrendered in 928 and had his life spared.

The continued expeditions against the Hafsunids did not distract Abd ad-Rahman III from the situation of other regions in al-Andalus, which recognized him only nominally, if not being in open revolt. Most of the loyal governors of the cities were in a weak position, such as the governor of Évora, who could not prevent the attack of the king of Galicia (future king of León), Ordoño II, who captured the city in the summer of 913, taking back a sizable booty and 4,000 prisoners and massacring many Muslims.

In much of the eastern and western province, Abd al-Rahman's authority was completely unrecognized. The lord of Badajoz, Abd Allah ibn Muhammad, grandson of Abd al-Rahman ibn Marwan al-Yilliqi, not only fortified his city against a possible attack from Ordoño, but also acted in complete independence from Córdoba. To avoid the fall of Évora into the hands of the Berber groups of the region, he ordered the destruction of its defensive towers and lowered the walls, though a year later he decided to reconstruct it, giving its control to his ally Masud ibn Sa' dun al-Surunbaqi. The Algarve was dominated completely by a muladí coalition led by Sa'id ibn Mal, who had expelled the Arabs from Beja, and the lords of Ocsónoba, Yahya ibn Bakr, and of Niebla, Ibn Ufayr. Alcácer do Sal and Lisbon were under control of the Banu Dānis.

The absence of royal authority enabled Ordoño II to easily campaign in this area, his main objective being the city of Mérida, in the summer of 915. Abd al-Rahman III did not send an army and only several local Berber "jefes" offered some resistance which was ineffective.

In the next year, despite having defeated only some of the rebels, Abd al-Rahman III considered himself powerful enough to declare himself Caliph of Córdoba (16 January 929), effectively breaking his allegiance to, and ties with, the Fatimid and Abbasid caliphs. The caliphate was thought only to belong to the Emperor who ruled over the sacred cities of Mecca and Medina, and his ancestors had until then been content with the title of emir. But the force of this tradition had weakened over time; and the title increased Abd al-Rahman's prestige with his subjects, both in Iberia and Africa. He based his claim to the caliphate on his Umayyad ancestors who had held undisputed control of the caliphate until they were overthrown by the Abbasids.

Abd al-Rahman's move made him both the political and the religious leader of all the Muslims in al-Andalus, as well as the protector of his Christian and Jewish subjects. The symbols of his new caliphate power were a scepter ("jayzuran") and the throne ("sarir"). In the mint he had founded in November 928, Abd al-Rahman started to mint gold dinars and silver dirhams, replacing the "al-Andalus" title with his name.

In his new role of caliph, he achieved the surrender of Ibn Marwan of Badajoz in 930 as well as the surrender of the Banu Dānis of Alcácer do Sal. On the southern front, to counter the increasing Fatimid power in North Africa, abd al-Rahmad ordered the construction of a fleet based in Almeria. The caliph helped the Maghrawa Berbers conquer Melilla (927), Ceuta (931) and Tangiers (951), which accepted his suzerainty. However, he was unable to defeat Jawhar al-Siqilli of the Fatamids. In 951 he signed a peace with the new king of León, Ordoño III, in order to have a free hand against the Fatimids whose ships were harassing the caliphate ones in the Mediterranean and had even launched an assault against Almeria. Abd al-Rahman's force, led by prime minister Ahmad ibn Said, besieged the Fatimid port of Tunis, which bought its safety through paying a huge sum.

In the end he was able to create a protectorate covering the northern and central Maghreb, supporting the Idrisid dynasty; the caliphate influence in the area disappeared after a Fatimid offensive in 958, after which abd al-Rahman kept only the strongholds of Ceuta and Tangiers.

Even before al-Andalus was firmly under his rule, he had restarted the war against King Ordoño II of León, who had taken advantage of the previous troublesome situation to capture some boundary areas and menace the Umayyad territory. In 917 the then emir had sent a large army under his general Ahmad ibn Abi Abda against León, but this force was destroyed at the Battle of San Esteban de Gormaz in September of that year.

Recognizing he had underestimated the power of Ordoño II, in 920 Abd al-Rahman mustered another powerful army to reclaim the territories lost after the previous campaign. He captured the forts of Osma and San Esteban de Gormaz. After defeating King Sancho Garcés I of Navarre and the king of Leon at Valdejunquera on 26 July, he penetrated into Navarre, overcoming Aragon by the classic route of the invasions from the south. Abd al-Rahman reached the Basque city of Pamplona, which was sacked and its cathedral church demolished.

In 924 Abd al-Rahman felt obliged to avenge the massacre of Viguera castle perpetrated by King Sancho Ordóñez of Navarre one year earlier. he launched counter offensive against Sancho in which Abd al-Rahman devastated a large area of Basque territory.

The succession crisis which struck León after Ordoño II's death in the same year caused hostilities to cease until Ramiro II obtained the throne in 932; a first attempt by him to assist the besieged rebels in Toledo was repelled in 932, despite the Christian king capturing Madrid and scoring a victory at Osma.

In 934, after reasserting supremacy over Pamplona and Álava, Abd al-Rahmad forced Ramiro to retreat to Burgos, and forced the Navarrese queen Toda, his aunt, to submit to him as a vassal and withdraw from direct rule as regent for her son García Sánchez I. In 937 Abd al-Rahmad conquered some thirty castles in León. Next he turned to Muhammad ibn Hashim al-Tugib, governor of Zaragoza, who had allied with Ramiro but was pardoned after the capture of his city.

Despite early defeats, Ramiro and García were able to crush the caliphate army in 939 at the Battle of Simancas, and almost kill Abd al-Rahman, due, most likely, to treason by Arab elements in the caliph's army. After this defeat, Abd al-Rahman stopped taking personal command of his military campaigns. His cause was helped, however, by Fernán González of Castile, one of the Christian leaders at Simancas, who subsequently launched a sustained rebellion against Ramiro. The victory of Simancas enabled the Christian kingdom to maintain the military initiative in the peninsula until the defeat of Ramiro's successor, Ordoño III of León, in 956. However they did not press this advantage as civil war broke out in the Christian territories.
In 950 Abd al-Rahman received in Córdoba an embassy from count Borrell II of Barcelona, by which the northern county recognized caliphate supremacy in exchange for peace and mutual support. In 958, Sancho, the exiled king of Leon, Garcia Sanchez, King of Navarre, and Queen Toda all paid homage to Abd al-Rahman in Cordoba.

Until 961, the caliphate played an active role in the dynastic strife characterizing the Christian kingdom during the period. Ordoño III's half-brother and successor, Sancho the Fat, had been deposed by his cousin Ordoño IV. Together with his grandmother Toda of Navarre, Sancho sought an alliance with Córdoba. In exchange for some castles, Abd al-Rahman helped them to take back Zamora (959) and Oviedo (960) and to overthrow Ordoño IV.

Abd al-Rahman was accused of having sunk in his later years into the self-indulgent habits of the harem. He is known to have openly kept a male as well as a female harem. This likely influenced the polemical story of his falling in love with a 13-year-old boy (later enshrined as a Christian martyr and canonised as Saint Pelagius of Córdoba) who refused the Caliph's advances. The love story may have been a construct on top of an original tale, however, in which he ordered the boy-slave to convert to Islam. Either way, enraged, he had the boy tortured and dismembered, thus contributing to the Christian perception of Muslim brutality.

Abd al-Rahman spent the rest of his years in his new palace outside Córdoba. He died in October 961 and was succeeded by his son al-Hakam II.

Abd al-Rahman was a great humanist and patron of arts, especially architecture. A third of his revenue sufficed for the ordinary expenses of government, a third was hoarded, and a third was spent on buildings. After declaring the caliphate, he had a massive palace complex, known as the Medina Azahara, built some five kilometers north of Córdoba. The Medina Azahara was modeled after the old Umayyad palace in Damascus and served as a symbolic tie between the new caliph and his ancestors. It was said that Cordoba contained 3000 mosques and 100,000 shops and homes during his reign.

Under his reign, Córdoba became the most important intellectual centre of Western Europe. He expanded the city's library, which would be further enriched by his successors.

He also reinforced the Iberian fleet, which became the most powerful in Mediterranean Europe. Iberian raiders moved up to Galicia, Asturias, and North Africa. The colonizers of Fraxinetum came from al-Andalus as well.

Due to his consolidation of power, Muslim Iberia became a power for a few centuries. It also brought prosperity, and with this he created mints where pure gold and silver coins were created. He renovated and added to the Mosque–Cathedral of Córdoba.

He was very wary of losing control and kept tight reins in his family. In 949, he executed one of his sons for conspiring against him. He was tolerant of non-Muslims, Jews and Christians who were treated fairly. European nations sent emissaries such as from Otto I of Germany, and the Byzantine emperor.

Abd al-Rahman III's mother Muzna was a Christian captive, possibly from the Pyrenean region. His paternal grandmother Onneca Fortúnez was a Christian princess from the Kingdom of Pamplona. In his immediate ancestry, Abd al-Rahman III was Arab and Hispano–Basque.

 


</doc>
<doc id="2679" url="https://en.wikipedia.org/wiki?curid=2679" title="Abd al-Rahman IV">
Abd al-Rahman IV

Abd ar-Rahman IV Mortada () was the Caliph of Córdoba in the Umayyad dynasty in Al-Andalus, succeeding Sulayman ibn al-Hakam, in 1018. That same year, he was murdered at Cadiz while fleeing from a battle in which he had been deserted by the very supporters which had brought him into power. His brief reign was similar to that of Abd ar-Rahman V Mostadir.


</doc>
<doc id="2680" url="https://en.wikipedia.org/wiki?curid=2680" title="Abd al-Rahman V">
Abd al-Rahman V

Abd ar-Rahman V () was an Umayyad Caliph of Córdoba.

In the agony of the Umayyad dynasty in the Al-Andalus (Moorish Iberia), two princes of the house were proclaimed Caliph of Córdoba for a very short time, Abd-ar-Rahman IV Mortada (1017), and Abd-ar-Rahman V Mostadir (1023–1024). Both were the mere puppets of factions, who deserted them at once. Abd-ar-Rahman IV was murdered the same year he was proclaimed at Cadiz, in flight from a battle in which he had been deserted by his supporters. Abd-ar-Rahman V was proclaimed caliph in December 1023 at Córdoba, and murdered in January 1024 by a mob of unemployed workmen, headed by one of his own cousins.


</doc>
